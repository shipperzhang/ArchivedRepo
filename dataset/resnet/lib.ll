; ModuleID = 'fused_layout_transform_50'
source_filename = "fused_layout_transform_50"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%0 = type { i32*, i32 }
%1 = type { i8*, %2, i32, %3, i64*, i64*, i64 }
%2 = type { i32, i32 }
%3 = type { i8, i8, i16 }
%4 = type { i8*, i8* }
%5 = type { i8*, i8* }
%6 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%7 = type { i8*, i8* }
%8 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%9 = type { i8*, i8* }
%10 = type { i8*, i8* }
%11 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%12 = type { i8*, i8* }
%13 = type { i8*, i8* }
%14 = type { i8*, i8*, i8*, i8*, i8*, i8* }
%15 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%16 = type { i8*, i8* }
%17 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%18 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%19 = type { i8*, i8*, i8*, i8*, i8* }
%20 = type { i8*, i8* }
%21 = type { i8*, i8* }
%22 = type { i8*, i8* }
%23 = type { i8*, i8*, i8*, i8*, i8* }
%24 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%25 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8* }
%26 = type { i8*, i8* }
%27 = type { i8*, i8* }
%28 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%29 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%30 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%31 = type { i8*, i8* }
%32 = type { i8*, i8*, i8*, i8*, i8* }
%33 = type { i8*, i8* }
%34 = type { i8*, i8* }
%35 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%36 = type { i8*, i8* }
%37 = type { i8*, i8*, i8*, i8*, i8* }
%38 = type { i8*, i8* }
%39 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%40 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%41 = type { i8*, i8* }
%42 = type { i8*, i8* }
%43 = type { i8*, i8* }
%44 = type { i8*, i8* }
%45 = type { i8*, i8* }
%46 = type { i8*, i8* }
%47 = type { i8*, i8* }
%48 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%49 = type { i8*, i8*, i8* }
%50 = type { i8*, i8* }
%51 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%52 = type { i8*, i8* }

@__TVMAPISetLastError = linkonce dllexport local_unnamed_addr global void (i8*)* null, align 8
@__TVMBackendParallelLaunch = linkonce dllexport local_unnamed_addr global i32 (i32 (i32, %0*, i8*)*, i8*, i32)* null, align 8
@.str = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_50: num_args should be 2\00", align 1
@.str.1 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_50: Expect arg[0] to be pointer\00", align 1
@.str.2 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_50: Expect arg[1] to be pointer\00", align 1
@.str.3 = private constant [55 x i8] c"Assert fail: (dev_type == 1), device_type need to be 1\00", align 1
@.str.4 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg0, 0, 4)), arg0.ndim is expected to equal 5\00", align 1
@.str.5 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg0, 0, 5) == (uint8)2) && (tvm_struct_get(arg0, 0, 6) == (uint8)32)) && (tvm_struct_get(arg0, 0, 7) == (uint16)1)), arg0.dtype is expected to be float32\00", align 1
@.str.6 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[0])), Argument arg0.shape[0] has an unsatisfied constraint\00", align 1
@.str.7 = private constant [96 x i8] c"Assert fail: (16 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.8 = private constant [96 x i8] c"Assert fail: (14 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.9 = private constant [96 x i8] c"Assert fail: (14 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.10 = private constant [96 x i8] c"Assert fail: (64 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.11 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (64 == int32(arg0.strides[3]))) && (896 == int32(arg0.strides[2]))) && (12544 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.12 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg0, 0, 8)), Argument arg0.byte_offset has an unsatisfied constraint\00", align 1
@.str.13 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg1, 0, 4)), arg1.ndim is expected to equal 5\00", align 1
@.str.14 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg1, 0, 5) == (uint8)2) && (tvm_struct_get(arg1, 0, 6) == (uint8)32)) && (tvm_struct_get(arg1, 0, 7) == (uint16)1)), arg1.dtype is expected to be float32\00", align 1
@.str.15 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.16 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.17 = private constant [96 x i8] c"Assert fail: (14 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.18 = private constant [96 x i8] c"Assert fail: (14 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.19 = private constant [98 x i8] c"Assert fail: (1024 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.20 = private constant [244 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (1024 == int32(arg1.strides[3]))) && (14336 == int32(arg1.strides[2]))) && (200704 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.21 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg1, 0, 8)), Argument arg1.byte_offset has an unsatisfied constraint\00", align 1
@.str.22 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg1, 0, 10)), Argument arg1.device_type has an unsatisfied constraint\00", align 1
@.str.23 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg1, 0, 9)), Argument arg1.device_id has an unsatisfied constraint\00", align 1
@.str.24 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_49: num_args should be 2\00", align 1
@.str.25 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_49: Expect arg[0] to be pointer\00", align 1
@.str.26 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_49: Expect arg[1] to be pointer\00", align 1
@.str.27 = private constant [95 x i8] c"Assert fail: (8 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.28 = private constant [96 x i8] c"Assert fail: (28 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.29 = private constant [96 x i8] c"Assert fail: (28 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.30 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (64 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (50176 == int32(arg0.strides[1]))) && (401408 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.31 = private constant [96 x i8] c"Assert fail: (16 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.32 = private constant [96 x i8] c"Assert fail: (28 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.33 = private constant [96 x i8] c"Assert fail: (28 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.34 = private constant [96 x i8] c"Assert fail: (32 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.35 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (32 == int32(arg1.strides[3]))) && (896 == int32(arg1.strides[2]))) && (25088 == int32(arg1.strides[1]))) && (401408 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.37 = private constant [101 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11: num_args should be 5\00", align 1
@.str.38 = private constant [176 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11: Expect arg[0] to be pointer\00", align 1
@.str.39 = private constant [176 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11: Expect arg[1] to be pointer\00", align 1
@.str.40 = private constant [176 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11: Expect arg[2] to be pointer\00", align 1
@.str.41 = private constant [176 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11: Expect arg[3] to be pointer\00", align 1
@.str.42 = private constant [176 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11: Expect arg[4] to be pointer\00", align 1
@.str.43 = private constant [95 x i8] c"Assert fail: (4 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.44 = private constant [96 x i8] c"Assert fail: (56 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.45 = private constant [96 x i8] c"Assert fail: (56 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.46 = private constant [96 x i8] c"Assert fail: (16 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.47 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (16 == int32(arg0.strides[3]))) && (896 == int32(arg0.strides[2]))) && (50176 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.48 = private constant [81 x i8] c"Assert fail: (6 == tvm_struct_get(arg1, 0, 4)), arg1.ndim is expected to equal 6\00", align 1
@.str.49 = private constant [95 x i8] c"Assert fail: (4 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.50 = private constant [95 x i8] c"Assert fail: (4 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.51 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.52 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.53 = private constant [96 x i8] c"Assert fail: (16 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.54 = private constant [96 x i8] c"Assert fail: (16 == int32(arg1.shape[5])), Argument arg1.shape[5] has an unsatisfied constraint\00", align 1
@.str.55 = private constant [272 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (16 == int32(arg1.strides[4]))) && (256 == int32(arg1.strides[3]))) && (256 == int32(arg1.strides[2]))) && (256 == int32(arg1.strides[1]))) && (1024 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.56 = private constant [81 x i8] c"Assert fail: (4 == tvm_struct_get(arg2, 0, 4)), arg2.ndim is expected to equal 4\00", align 1
@.str.57 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg2, 0, 5) == (uint8)2) && (tvm_struct_get(arg2, 0, 6) == (uint8)32)) && (tvm_struct_get(arg2, 0, 7) == (uint16)1)), arg2.dtype is expected to be float32\00", align 1
@.str.58 = private constant [95 x i8] c"Assert fail: (4 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.59 = private constant [95 x i8] c"Assert fail: (1 == int32(arg2.shape[1])), Argument arg2.shape[1] has an unsatisfied constraint\00", align 1
@.str.60 = private constant [95 x i8] c"Assert fail: (1 == int32(arg2.shape[2])), Argument arg2.shape[2] has an unsatisfied constraint\00", align 1
@.str.61 = private constant [96 x i8] c"Assert fail: (16 == int32(arg2.shape[3])), Argument arg2.shape[3] has an unsatisfied constraint\00", align 1
@.str.62 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg2.strides[3])) && (16 == int32(arg2.strides[2]))) && (16 == int32(arg2.strides[1]))) && (16 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.63 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg2, 0, 8)), Argument arg2.byte_offset has an unsatisfied constraint\00", align 1
@.str.64 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg2, 0, 10)), Argument arg2.device_type has an unsatisfied constraint\00", align 1
@.str.65 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg2, 0, 9)), Argument arg2.device_id has an unsatisfied constraint\00", align 1
@.str.66 = private constant [81 x i8] c"Assert fail: (4 == tvm_struct_get(arg3, 0, 4)), arg3.ndim is expected to equal 4\00", align 1
@.str.67 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg3, 0, 5) == (uint8)2) && (tvm_struct_get(arg3, 0, 6) == (uint8)32)) && (tvm_struct_get(arg3, 0, 7) == (uint16)1)), arg3.dtype is expected to be float32\00", align 1
@.str.68 = private constant [95 x i8] c"Assert fail: (4 == int32(arg3.shape[0])), Argument arg3.shape[0] has an unsatisfied constraint\00", align 1
@.str.69 = private constant [95 x i8] c"Assert fail: (1 == int32(arg3.shape[1])), Argument arg3.shape[1] has an unsatisfied constraint\00", align 1
@.str.70 = private constant [95 x i8] c"Assert fail: (1 == int32(arg3.shape[2])), Argument arg3.shape[2] has an unsatisfied constraint\00", align 1
@.str.71 = private constant [96 x i8] c"Assert fail: (16 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.72 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg3.strides[3])) && (16 == int32(arg3.strides[2]))) && (16 == int32(arg3.strides[1]))) && (16 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.73 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg3, 0, 8)), Argument arg3.byte_offset has an unsatisfied constraint\00", align 1
@.str.74 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg3, 0, 10)), Argument arg3.device_type has an unsatisfied constraint\00", align 1
@.str.75 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg3, 0, 9)), Argument arg3.device_id has an unsatisfied constraint\00", align 1
@.str.76 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg4, 0, 4)), arg4.ndim is expected to equal 5\00", align 1
@.str.77 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg4, 0, 5) == (uint8)2) && (tvm_struct_get(arg4, 0, 6) == (uint8)32)) && (tvm_struct_get(arg4, 0, 7) == (uint16)1)), arg4.dtype is expected to be float32\00", align 1
@.str.78 = private constant [95 x i8] c"Assert fail: (1 == int32(arg4.shape[0])), Argument arg4.shape[0] has an unsatisfied constraint\00", align 1
@.str.79 = private constant [95 x i8] c"Assert fail: (4 == int32(arg4.shape[1])), Argument arg4.shape[1] has an unsatisfied constraint\00", align 1
@.str.80 = private constant [96 x i8] c"Assert fail: (56 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.81 = private constant [96 x i8] c"Assert fail: (56 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.82 = private constant [96 x i8] c"Assert fail: (16 == int32(arg4.shape[4])), Argument arg4.shape[4] has an unsatisfied constraint\00", align 1
@.str.83 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (16 == int32(arg4.strides[3]))) && (896 == int32(arg4.strides[2]))) && (50176 == int32(arg4.strides[1]))) && (200704 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.84 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg4, 0, 8)), Argument arg4.byte_offset has an unsatisfied constraint\00", align 1
@.str.85 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg4, 0, 10)), Argument arg4.device_type has an unsatisfied constraint\00", align 1
@.str.86 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg4, 0, 9)), Argument arg4.device_id has an unsatisfied constraint\00", align 1
@__TVMBackendAllocWorkspace = linkonce dllexport local_unnamed_addr global i8* (i32, i32, i64, i32, i32)* null, align 8
@__TVMBackendFreeWorkspace = linkonce dllexport local_unnamed_addr global i32 (i32, i32, i8*)* null, align 8
@.str.88 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_46: num_args should be 2\00", align 1
@.str.89 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_46: Expect arg[0] to be pointer\00", align 1
@.str.90 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_46: Expect arg[1] to be pointer\00", align 1
@.str.91 = private constant [96 x i8] c"Assert fail: (56 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.92 = private constant [96 x i8] c"Assert fail: (56 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.93 = private constant [96 x i8] c"Assert fail: (64 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.94 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (64 == int32(arg1.strides[3]))) && (3584 == int32(arg1.strides[2]))) && (200704 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.96 = private constant [101 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10: num_args should be 5\00", align 1
@.str.97 = private constant [176 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10: Expect arg[0] to be pointer\00", align 1
@.str.98 = private constant [176 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10: Expect arg[1] to be pointer\00", align 1
@.str.99 = private constant [176 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10: Expect arg[2] to be pointer\00", align 1
@.str.100 = private constant [176 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10: Expect arg[3] to be pointer\00", align 1
@.str.101 = private constant [176 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10: Expect arg[4] to be pointer\00", align 1
@.str.102 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.103 = private constant [97 x i8] c"Assert fail: (256 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.104 = private constant [243 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (256 == int32(arg0.strides[3]))) && (14336 == int32(arg0.strides[2]))) && (802816 == int32(arg0.strides[1]))) && (802816 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.105 = private constant [95 x i8] c"Assert fail: (2 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.106 = private constant [97 x i8] c"Assert fail: (256 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.107 = private constant [96 x i8] c"Assert fail: (32 == int32(arg1.shape[5])), Argument arg1.shape[5] has an unsatisfied constraint\00", align 1
@.str.108 = private constant [275 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (8192 == int32(arg1.strides[3]))) && (8192 == int32(arg1.strides[2]))) && (8192 == int32(arg1.strides[1]))) && (8192 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.109 = private constant [95 x i8] c"Assert fail: (2 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.110 = private constant [96 x i8] c"Assert fail: (32 == int32(arg2.shape[3])), Argument arg2.shape[3] has an unsatisfied constraint\00", align 1
@.str.111 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg2.strides[3])) && (32 == int32(arg2.strides[2]))) && (32 == int32(arg2.strides[1]))) && (32 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.112 = private constant [95 x i8] c"Assert fail: (2 == int32(arg3.shape[0])), Argument arg3.shape[0] has an unsatisfied constraint\00", align 1
@.str.113 = private constant [96 x i8] c"Assert fail: (32 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.114 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg3.strides[3])) && (32 == int32(arg3.strides[2]))) && (32 == int32(arg3.strides[1]))) && (32 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.115 = private constant [95 x i8] c"Assert fail: (2 == int32(arg4.shape[1])), Argument arg4.shape[1] has an unsatisfied constraint\00", align 1
@.str.116 = private constant [96 x i8] c"Assert fail: (32 == int32(arg4.shape[4])), Argument arg4.shape[4] has an unsatisfied constraint\00", align 1
@.str.117 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (32 == int32(arg4.strides[3]))) && (1792 == int32(arg4.strides[2]))) && (100352 == int32(arg4.strides[1]))) && (200704 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.119 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_45: num_args should be 2\00", align 1
@.str.120 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_45: Expect arg[0] to be pointer\00", align 1
@.str.121 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_45: Expect arg[1] to be pointer\00", align 1
@.str.122 = private constant [95 x i8] c"Assert fail: (2 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.123 = private constant [96 x i8] c"Assert fail: (32 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.124 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (100352 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.126 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9: num_args should be 5\00", align 1
@.str.127 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9: Expect arg[0] to be pointer\00", align 1
@.str.128 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9: Expect arg[1] to be pointer\00", align 1
@.str.129 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9: Expect arg[2] to be pointer\00", align 1
@.str.130 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9: Expect arg[3] to be pointer\00", align 1
@.str.131 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9: Expect arg[4] to be pointer\00", align 1
@.str.132 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (64 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (200704 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.133 = private constant [95 x i8] c"Assert fail: (3 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.134 = private constant [95 x i8] c"Assert fail: (3 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.135 = private constant [277 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (2048 == int32(arg1.strides[3]))) && (6144 == int32(arg1.strides[2]))) && (18432 == int32(arg1.strides[1]))) && (18432 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.138 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_44: num_args should be 2\00", align 1
@.str.139 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_44: Expect arg[0] to be pointer\00", align 1
@.str.140 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_44: Expect arg[1] to be pointer\00", align 1
@.str.141 = private constant [95 x i8] c"Assert fail: (4 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.142 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (4 == int32(arg1.strides[3]))) && (224 == int32(arg1.strides[2]))) && (12544 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.144 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_43: num_args should be 2\00", align 1
@.str.145 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_43: Expect arg[0] to be pointer\00", align 1
@.str.146 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_43: Expect arg[1] to be pointer\00", align 1
@.str.147 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (100352 == int32(arg0.strides[1]))) && (802816 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.148 = private constant [243 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (256 == int32(arg1.strides[3]))) && (14336 == int32(arg1.strides[2]))) && (802816 == int32(arg1.strides[1]))) && (802816 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.150 = private constant [101 x i8] c"Assert fail: (num_args == 6), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3: num_args should be 6\00", align 1
@.str.151 = private constant [176 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3: Expect arg[0] to be pointer\00", align 1
@.str.152 = private constant [176 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3: Expect arg[1] to be pointer\00", align 1
@.str.153 = private constant [176 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3: Expect arg[2] to be pointer\00", align 1
@.str.154 = private constant [176 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3: Expect arg[3] to be pointer\00", align 1
@.str.155 = private constant [176 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3: Expect arg[4] to be pointer\00", align 1
@.str.156 = private constant [176 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3: Expect arg[5] to be pointer\00", align 1
@.str.157 = private constant [98 x i8] c"Assert fail: (1024 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.158 = private constant [244 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (1024 == int32(arg0.strides[3]))) && (14336 == int32(arg0.strides[2]))) && (200704 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.159 = private constant [96 x i8] c"Assert fail: (64 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.160 = private constant [279 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (32768 == int32(arg1.strides[3]))) && (32768 == int32(arg1.strides[2]))) && (32768 == int32(arg1.strides[1]))) && (32768 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.161 = private constant [96 x i8] c"Assert fail: (64 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.162 = private constant [96 x i8] c"Assert fail: (64 == int32(arg3.shape[0])), Argument arg3.shape[0] has an unsatisfied constraint\00", align 1
@.str.163 = private constant [81 x i8] c"Assert fail: (4 == tvm_struct_get(arg4, 0, 4)), arg4.ndim is expected to equal 4\00", align 1
@.str.164 = private constant [96 x i8] c"Assert fail: (64 == int32(arg4.shape[0])), Argument arg4.shape[0] has an unsatisfied constraint\00", align 1
@.str.165 = private constant [95 x i8] c"Assert fail: (1 == int32(arg4.shape[1])), Argument arg4.shape[1] has an unsatisfied constraint\00", align 1
@.str.166 = private constant [95 x i8] c"Assert fail: (1 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.167 = private constant [96 x i8] c"Assert fail: (32 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.168 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg4.strides[3])) && (32 == int32(arg4.strides[2]))) && (32 == int32(arg4.strides[1]))) && (32 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.169 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg5, 0, 4)), arg5.ndim is expected to equal 5\00", align 1
@.str.170 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg5, 0, 5) == (uint8)2) && (tvm_struct_get(arg5, 0, 6) == (uint8)32)) && (tvm_struct_get(arg5, 0, 7) == (uint16)1)), arg5.dtype is expected to be float32\00", align 1
@.str.171 = private constant [95 x i8] c"Assert fail: (1 == int32(arg5.shape[0])), Argument arg5.shape[0] has an unsatisfied constraint\00", align 1
@.str.172 = private constant [96 x i8] c"Assert fail: (64 == int32(arg5.shape[1])), Argument arg5.shape[1] has an unsatisfied constraint\00", align 1
@.str.173 = private constant [95 x i8] c"Assert fail: (7 == int32(arg5.shape[2])), Argument arg5.shape[2] has an unsatisfied constraint\00", align 1
@.str.174 = private constant [95 x i8] c"Assert fail: (7 == int32(arg5.shape[3])), Argument arg5.shape[3] has an unsatisfied constraint\00", align 1
@.str.175 = private constant [96 x i8] c"Assert fail: (32 == int32(arg5.shape[4])), Argument arg5.shape[4] has an unsatisfied constraint\00", align 1
@.str.176 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg5.strides[4])) && (32 == int32(arg5.strides[3]))) && (224 == int32(arg5.strides[2]))) && (1568 == int32(arg5.strides[1]))) && (100352 == int32(arg5.strides[0]))), arg5.strides: expected to be compact array\00", align 1
@.str.177 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg5, 0, 8)), Argument arg5.byte_offset has an unsatisfied constraint\00", align 1
@.str.178 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg5, 0, 10)), Argument arg5.device_type has an unsatisfied constraint\00", align 1
@.str.179 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg5, 0, 9)), Argument arg5.device_id has an unsatisfied constraint\00", align 1
@.str.181 = private constant [99 x i8] c"Assert fail: (num_args == 6), fused_nn_contrib_conv2d_NCHWc_add_multiply_add: num_args should be 6\00", align 1
@.str.182 = private constant [174 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add: Expect arg[0] to be pointer\00", align 1
@.str.183 = private constant [174 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add: Expect arg[1] to be pointer\00", align 1
@.str.184 = private constant [174 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add: Expect arg[2] to be pointer\00", align 1
@.str.185 = private constant [174 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add: Expect arg[3] to be pointer\00", align 1
@.str.186 = private constant [174 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add: Expect arg[4] to be pointer\00", align 1
@.str.187 = private constant [174 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add: Expect arg[5] to be pointer\00", align 1
@.str.188 = private constant [95 x i8] c"Assert fail: (4 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.189 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (4 == int32(arg0.strides[3]))) && (224 == int32(arg0.strides[2]))) && (12544 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.190 = private constant [95 x i8] c"Assert fail: (8 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.191 = private constant [272 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (128 == int32(arg1.strides[3]))) && (128 == int32(arg1.strides[2]))) && (128 == int32(arg1.strides[1]))) && (2048 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.192 = private constant [95 x i8] c"Assert fail: (8 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.193 = private constant [95 x i8] c"Assert fail: (8 == int32(arg3.shape[0])), Argument arg3.shape[0] has an unsatisfied constraint\00", align 1
@.str.194 = private constant [95 x i8] c"Assert fail: (8 == int32(arg4.shape[0])), Argument arg4.shape[0] has an unsatisfied constraint\00", align 1
@.str.195 = private constant [95 x i8] c"Assert fail: (8 == int32(arg5.shape[1])), Argument arg5.shape[1] has an unsatisfied constraint\00", align 1
@.str.196 = private constant [96 x i8] c"Assert fail: (56 == int32(arg5.shape[2])), Argument arg5.shape[2] has an unsatisfied constraint\00", align 1
@.str.197 = private constant [96 x i8] c"Assert fail: (56 == int32(arg5.shape[3])), Argument arg5.shape[3] has an unsatisfied constraint\00", align 1
@.str.198 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg5.strides[4])) && (32 == int32(arg5.strides[3]))) && (1792 == int32(arg5.strides[2]))) && (100352 == int32(arg5.strides[1]))) && (802816 == int32(arg5.strides[0]))), arg5.strides: expected to be compact array\00", align 1
@.str.200 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_47: num_args should be 2\00", align 1
@.str.201 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_47: Expect arg[0] to be pointer\00", align 1
@.str.202 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_47: Expect arg[1] to be pointer\00", align 1
@.str.203 = private constant [81 x i8] c"Assert fail: (4 == tvm_struct_get(arg0, 0, 4)), arg0.ndim is expected to equal 4\00", align 1
@.str.204 = private constant [96 x i8] c"Assert fail: (64 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.205 = private constant [201 x i8] c"Assert fail: ((((1 == int32(arg0.strides[3])) && (56 == int32(arg0.strides[2]))) && (3136 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.206 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (16 == int32(arg1.strides[3]))) && (896 == int32(arg1.strides[2]))) && (50176 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.208 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8: num_args should be 5\00", align 1
@.str.209 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8: Expect arg[0] to be pointer\00", align 1
@.str.210 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8: Expect arg[1] to be pointer\00", align 1
@.str.211 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8: Expect arg[2] to be pointer\00", align 1
@.str.212 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8: Expect arg[3] to be pointer\00", align 1
@.str.213 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8: Expect arg[4] to be pointer\00", align 1
@.str.214 = private constant [96 x i8] c"Assert fail: (28 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.215 = private constant [96 x i8] c"Assert fail: (28 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.216 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (32 == int32(arg4.strides[3]))) && (896 == int32(arg4.strides[2]))) && (25088 == int32(arg4.strides[1]))) && (100352 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.218 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7: num_args should be 5\00", align 1
@.str.219 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7: Expect arg[0] to be pointer\00", align 1
@.str.220 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7: Expect arg[1] to be pointer\00", align 1
@.str.221 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7: Expect arg[2] to be pointer\00", align 1
@.str.222 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7: Expect arg[3] to be pointer\00", align 1
@.str.223 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7: Expect arg[4] to be pointer\00", align 1
@.str.224 = private constant [97 x i8] c"Assert fail: (512 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.225 = private constant [243 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (512 == int32(arg0.strides[3]))) && (14336 == int32(arg0.strides[2]))) && (401408 == int32(arg0.strides[1]))) && (401408 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.226 = private constant [97 x i8] c"Assert fail: (512 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.227 = private constant [96 x i8] c"Assert fail: (64 == int32(arg1.shape[5])), Argument arg1.shape[5] has an unsatisfied constraint\00", align 1
@.str.228 = private constant [279 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (64 == int32(arg1.strides[4]))) && (32768 == int32(arg1.strides[3]))) && (32768 == int32(arg1.strides[2]))) && (32768 == int32(arg1.strides[1]))) && (32768 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.229 = private constant [96 x i8] c"Assert fail: (64 == int32(arg2.shape[3])), Argument arg2.shape[3] has an unsatisfied constraint\00", align 1
@.str.230 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg2.strides[3])) && (64 == int32(arg2.strides[2]))) && (64 == int32(arg2.strides[1]))) && (64 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.231 = private constant [96 x i8] c"Assert fail: (64 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.232 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg3.strides[3])) && (64 == int32(arg3.strides[2]))) && (64 == int32(arg3.strides[1]))) && (64 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.233 = private constant [96 x i8] c"Assert fail: (64 == int32(arg4.shape[4])), Argument arg4.shape[4] has an unsatisfied constraint\00", align 1
@.str.234 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (64 == int32(arg4.strides[3]))) && (1792 == int32(arg4.strides[2]))) && (50176 == int32(arg4.strides[1]))) && (100352 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.236 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: num_args should be 5\00", align 1
@.str.237 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[0] to be pointer\00", align 1
@.str.238 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[1] to be pointer\00", align 1
@.str.239 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[2] to be pointer\00", align 1
@.str.240 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[3] to be pointer\00", align 1
@.str.241 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[4] to be pointer\00", align 1
@.str.242 = private constant [97 x i8] c"Assert fail: (512 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.243 = private constant [95 x i8] c"Assert fail: (7 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.244 = private constant [95 x i8] c"Assert fail: (7 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.245 = private constant [235 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (4 == int32(arg0.strides[3]))) && (28 == int32(arg0.strides[2]))) && (196 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.246 = private constant [96 x i8] c"Assert fail: (16 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.247 = private constant [97 x i8] c"Assert fail: (512 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.248 = private constant [273 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (128 == int32(arg1.strides[3]))) && (128 == int32(arg1.strides[2]))) && (128 == int32(arg1.strides[1]))) && (65536 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.249 = private constant [96 x i8] c"Assert fail: (16 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.250 = private constant [96 x i8] c"Assert fail: (16 == int32(arg3.shape[0])), Argument arg3.shape[0] has an unsatisfied constraint\00", align 1
@.str.251 = private constant [96 x i8] c"Assert fail: (16 == int32(arg4.shape[1])), Argument arg4.shape[1] has an unsatisfied constraint\00", align 1
@.str.252 = private constant [95 x i8] c"Assert fail: (7 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.253 = private constant [95 x i8] c"Assert fail: (7 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.254 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (32 == int32(arg4.strides[3]))) && (224 == int32(arg4.strides[2]))) && (1568 == int32(arg4.strides[1]))) && (25088 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.256 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_48: num_args should be 2\00", align 1
@.str.257 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_48: Expect arg[0] to be pointer\00", align 1
@.str.258 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_48: Expect arg[1] to be pointer\00", align 1
@.str.260 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_36: num_args should be 2\00", align 1
@.str.261 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_36: Expect arg[0] to be pointer\00", align 1
@.str.262 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_36: Expect arg[1] to be pointer\00", align 1
@.str.263 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (16 == int32(arg0.strides[3]))) && (224 == int32(arg0.strides[2]))) && (3136 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.264 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (256 == int32(arg1.strides[3]))) && (3584 == int32(arg1.strides[2]))) && (50176 == int32(arg1.strides[1]))) && (50176 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.266 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_42: num_args should be 2\00", align 1
@.str.267 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_42: Expect arg[0] to be pointer\00", align 1
@.str.268 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_42: Expect arg[1] to be pointer\00", align 1
@.str.269 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (896 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.270 = private constant [97 x i8] c"Assert fail: (128 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.271 = private constant [242 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (128 == int32(arg1.strides[3]))) && (3584 == int32(arg1.strides[2]))) && (100352 == int32(arg1.strides[1]))) && (100352 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.273 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: num_args should be 5\00", align 1
@.str.274 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[0] to be pointer\00", align 1
@.str.275 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[1] to be pointer\00", align 1
@.str.276 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[2] to be pointer\00", align 1
@.str.277 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[3] to be pointer\00", align 1
@.str.278 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[4] to be pointer\00", align 1
@.str.279 = private constant [242 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (512 == int32(arg0.strides[3]))) && (7168 == int32(arg0.strides[2]))) && (100352 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.280 = private constant [95 x i8] c"Assert fail: (2 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.281 = private constant [279 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (16384 == int32(arg1.strides[3]))) && (16384 == int32(arg1.strides[2]))) && (16384 == int32(arg1.strides[1]))) && (32768 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.283 = private constant [101 x i8] c"Assert fail: (num_args == 6), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1: num_args should be 6\00", align 1
@.str.284 = private constant [176 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1: Expect arg[0] to be pointer\00", align 1
@.str.285 = private constant [176 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1: Expect arg[1] to be pointer\00", align 1
@.str.286 = private constant [176 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1: Expect arg[2] to be pointer\00", align 1
@.str.287 = private constant [176 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1: Expect arg[3] to be pointer\00", align 1
@.str.288 = private constant [176 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1: Expect arg[4] to be pointer\00", align 1
@.str.289 = private constant [176 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1: Expect arg[5] to be pointer\00", align 1
@.str.290 = private constant [279 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (64 == int32(arg1.strides[4]))) && (16384 == int32(arg1.strides[3]))) && (16384 == int32(arg1.strides[2]))) && (16384 == int32(arg1.strides[1]))) && (16384 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.291 = private constant [96 x i8] c"Assert fail: (64 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.292 = private constant [195 x i8] c"Assert fail: ((((1 == int32(arg4.strides[3])) && (64 == int32(arg4.strides[2]))) && (64 == int32(arg4.strides[1]))) && (64 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.293 = private constant [96 x i8] c"Assert fail: (28 == int32(arg5.shape[2])), Argument arg5.shape[2] has an unsatisfied constraint\00", align 1
@.str.294 = private constant [96 x i8] c"Assert fail: (28 == int32(arg5.shape[3])), Argument arg5.shape[3] has an unsatisfied constraint\00", align 1
@.str.295 = private constant [96 x i8] c"Assert fail: (64 == int32(arg5.shape[4])), Argument arg5.shape[4] has an unsatisfied constraint\00", align 1
@.str.296 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg5.strides[4])) && (64 == int32(arg5.strides[3]))) && (1792 == int32(arg5.strides[2]))) && (50176 == int32(arg5.strides[1]))) && (401408 == int32(arg5.strides[0]))), arg5.strides: expected to be compact array\00", align 1
@.str.298 = private constant [111 x i8] c"Assert fail: (num_args == 7), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: num_args should be 7\00", align 1
@.str.299 = private constant [186 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: Expect arg[0] to be pointer\00", align 1
@.str.300 = private constant [186 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: Expect arg[1] to be pointer\00", align 1
@.str.301 = private constant [186 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: Expect arg[2] to be pointer\00", align 1
@.str.302 = private constant [186 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: Expect arg[3] to be pointer\00", align 1
@.str.303 = private constant [186 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: Expect arg[4] to be pointer\00", align 1
@.str.304 = private constant [186 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: Expect arg[5] to be pointer\00", align 1
@.str.305 = private constant [186 x i8] c"Assert fail: ((((arg6.code == 3) || (arg6.code == 13)) || (arg6.code == 7)) || (arg6.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu: Expect arg[6] to be pointer\00", align 1
@.str.306 = private constant [97 x i8] c"Assert fail: (128 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.307 = private constant [234 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (4 == int32(arg0.strides[3]))) && (28 == int32(arg0.strides[2]))) && (196 == int32(arg0.strides[1]))) && (25088 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.308 = private constant [97 x i8] c"Assert fail: (128 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.309 = private constant [273 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (128 == int32(arg1.strides[3]))) && (128 == int32(arg1.strides[2]))) && (128 == int32(arg1.strides[1]))) && (16384 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.310 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg6, 0, 4)), arg6.ndim is expected to equal 5\00", align 1
@.str.311 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg6, 0, 5) == (uint8)2) && (tvm_struct_get(arg6, 0, 6) == (uint8)32)) && (tvm_struct_get(arg6, 0, 7) == (uint16)1)), arg6.dtype is expected to be float32\00", align 1
@.str.312 = private constant [95 x i8] c"Assert fail: (1 == int32(arg6.shape[0])), Argument arg6.shape[0] has an unsatisfied constraint\00", align 1
@.str.313 = private constant [96 x i8] c"Assert fail: (64 == int32(arg6.shape[1])), Argument arg6.shape[1] has an unsatisfied constraint\00", align 1
@.str.314 = private constant [95 x i8] c"Assert fail: (7 == int32(arg6.shape[2])), Argument arg6.shape[2] has an unsatisfied constraint\00", align 1
@.str.315 = private constant [95 x i8] c"Assert fail: (7 == int32(arg6.shape[3])), Argument arg6.shape[3] has an unsatisfied constraint\00", align 1
@.str.316 = private constant [96 x i8] c"Assert fail: (32 == int32(arg6.shape[4])), Argument arg6.shape[4] has an unsatisfied constraint\00", align 1
@.str.317 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg6.strides[4])) && (32 == int32(arg6.strides[3]))) && (224 == int32(arg6.strides[2]))) && (1568 == int32(arg6.strides[1]))) && (100352 == int32(arg6.strides[0]))), arg6.strides: expected to be compact array\00", align 1
@.str.318 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg6, 0, 8)), Argument arg6.byte_offset has an unsatisfied constraint\00", align 1
@.str.319 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg6, 0, 10)), Argument arg6.device_type has an unsatisfied constraint\00", align 1
@.str.320 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg6, 0, 9)), Argument arg6.device_id has an unsatisfied constraint\00", align 1
@.str.322 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_32: num_args should be 2\00", align 1
@.str.323 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_32: Expect arg[0] to be pointer\00", align 1
@.str.324 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_32: Expect arg[1] to be pointer\00", align 1
@.str.325 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (224 == int32(arg0.strides[2]))) && (1568 == int32(arg0.strides[1]))) && (25088 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.326 = private constant [95 x i8] c"Assert fail: (7 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.327 = private constant [95 x i8] c"Assert fail: (7 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.328 = private constant [234 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (4 == int32(arg1.strides[3]))) && (28 == int32(arg1.strides[2]))) && (196 == int32(arg1.strides[1]))) && (25088 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.330 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_41: num_args should be 2\00", align 1
@.str.331 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_41: Expect arg[0] to be pointer\00", align 1
@.str.332 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_41: Expect arg[1] to be pointer\00", align 1
@.str.333 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (896 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (401408 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.334 = private constant [243 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (512 == int32(arg1.strides[3]))) && (14336 == int32(arg1.strides[2]))) && (401408 == int32(arg1.strides[1]))) && (401408 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.336 = private constant [102 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_transpose_nn_batch_flatten: num_args should be 2\00", align 1
@.str.337 = private constant [177 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_transpose_nn_batch_flatten: Expect arg[0] to be pointer\00", align 1
@.str.338 = private constant [177 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_transpose_nn_batch_flatten: Expect arg[1] to be pointer\00", align 1
@.str.339 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.340 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.341 = private constant [233 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (32 == int32(arg0.strides[2]))) && (32 == int32(arg0.strides[1]))) && (2048 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.342 = private constant [81 x i8] c"Assert fail: (2 == tvm_struct_get(arg1, 0, 4)), arg1.ndim is expected to equal 2\00", align 1
@.str.343 = private constant [98 x i8] c"Assert fail: (2048 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.344 = private constant [125 x i8] c"Assert fail: ((1 == int32(arg1.strides[1])) && (2048 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.345 = private constant [107 x i8] c"Assert fail: (num_args == 6), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu: num_args should be 6\00", align 1
@.str.346 = private constant [182 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu: Expect arg[0] to be pointer\00", align 1
@.str.347 = private constant [182 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu: Expect arg[1] to be pointer\00", align 1
@.str.348 = private constant [182 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu: Expect arg[2] to be pointer\00", align 1
@.str.349 = private constant [182 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu: Expect arg[3] to be pointer\00", align 1
@.str.350 = private constant [182 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu: Expect arg[4] to be pointer\00", align 1
@.str.351 = private constant [182 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu: Expect arg[5] to be pointer\00", align 1
@.str.352 = private constant [97 x i8] c"Assert fail: (230 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.353 = private constant [97 x i8] c"Assert fail: (230 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.354 = private constant [95 x i8] c"Assert fail: (3 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.355 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (3 == int32(arg0.strides[3]))) && (690 == int32(arg0.strides[2]))) && (158700 == int32(arg0.strides[1]))) && (158700 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.356 = private constant [95 x i8] c"Assert fail: (3 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.357 = private constant [95 x i8] c"Assert fail: (8 == int32(arg1.shape[5])), Argument arg1.shape[5] has an unsatisfied constraint\00", align 1
@.str.358 = private constant [271 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (8 == int32(arg1.strides[4]))) && (24 == int32(arg1.strides[3]))) && (168 == int32(arg1.strides[2]))) && (1176 == int32(arg1.strides[1]))) && (1176 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.359 = private constant [95 x i8] c"Assert fail: (8 == int32(arg2.shape[3])), Argument arg2.shape[3] has an unsatisfied constraint\00", align 1
@.str.360 = private constant [192 x i8] c"Assert fail: ((((1 == int32(arg2.strides[3])) && (8 == int32(arg2.strides[2]))) && (8 == int32(arg2.strides[1]))) && (8 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.361 = private constant [95 x i8] c"Assert fail: (8 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.362 = private constant [192 x i8] c"Assert fail: ((((1 == int32(arg3.strides[3])) && (8 == int32(arg3.strides[2]))) && (8 == int32(arg3.strides[1]))) && (8 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.363 = private constant [95 x i8] c"Assert fail: (8 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.364 = private constant [192 x i8] c"Assert fail: ((((1 == int32(arg4.strides[3])) && (8 == int32(arg4.strides[2]))) && (8 == int32(arg4.strides[1]))) && (8 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.365 = private constant [97 x i8] c"Assert fail: (112 == int32(arg5.shape[2])), Argument arg5.shape[2] has an unsatisfied constraint\00", align 1
@.str.366 = private constant [97 x i8] c"Assert fail: (112 == int32(arg5.shape[3])), Argument arg5.shape[3] has an unsatisfied constraint\00", align 1
@.str.367 = private constant [95 x i8] c"Assert fail: (8 == int32(arg5.shape[4])), Argument arg5.shape[4] has an unsatisfied constraint\00", align 1
@.str.368 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg5.strides[4])) && (8 == int32(arg5.strides[3]))) && (896 == int32(arg5.strides[2]))) && (100352 == int32(arg5.strides[1]))) && (802816 == int32(arg5.strides[0]))), arg5.strides: expected to be compact array\00", align 1
@.str.370 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5: num_args should be 5\00", align 1
@.str.371 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5: Expect arg[0] to be pointer\00", align 1
@.str.372 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5: Expect arg[1] to be pointer\00", align 1
@.str.373 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5: Expect arg[2] to be pointer\00", align 1
@.str.374 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5: Expect arg[3] to be pointer\00", align 1
@.str.375 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5: Expect arg[4] to be pointer\00", align 1
@.str.376 = private constant [95 x i8] c"Assert fail: (8 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.377 = private constant [276 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (64 == int32(arg1.strides[4]))) && (4096 == int32(arg1.strides[3]))) && (4096 == int32(arg1.strides[2]))) && (4096 == int32(arg1.strides[1]))) && (32768 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.378 = private constant [96 x i8] c"Assert fail: (14 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.379 = private constant [96 x i8] c"Assert fail: (14 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.380 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (64 == int32(arg4.strides[3]))) && (896 == int32(arg4.strides[2]))) && (12544 == int32(arg4.strides[1]))) && (50176 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.382 = private constant [113 x i8] c"Assert fail: (num_args == 7), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: num_args should be 7\00", align 1
@.str.383 = private constant [188 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: Expect arg[0] to be pointer\00", align 1
@.str.384 = private constant [188 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: Expect arg[1] to be pointer\00", align 1
@.str.385 = private constant [188 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: Expect arg[2] to be pointer\00", align 1
@.str.386 = private constant [188 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: Expect arg[3] to be pointer\00", align 1
@.str.387 = private constant [188 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: Expect arg[4] to be pointer\00", align 1
@.str.388 = private constant [188 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: Expect arg[5] to be pointer\00", align 1
@.str.389 = private constant [188 x i8] c"Assert fail: ((((arg6.code == 3) || (arg6.code == 13)) || (arg6.code == 7)) || (arg6.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3: Expect arg[6] to be pointer\00", align 1
@.str.390 = private constant [95 x i8] c"Assert fail: (8 == int32(arg6.shape[1])), Argument arg6.shape[1] has an unsatisfied constraint\00", align 1
@.str.391 = private constant [96 x i8] c"Assert fail: (56 == int32(arg6.shape[2])), Argument arg6.shape[2] has an unsatisfied constraint\00", align 1
@.str.392 = private constant [96 x i8] c"Assert fail: (56 == int32(arg6.shape[3])), Argument arg6.shape[3] has an unsatisfied constraint\00", align 1
@.str.393 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg6.strides[4])) && (32 == int32(arg6.strides[3]))) && (1792 == int32(arg6.strides[2]))) && (100352 == int32(arg6.strides[1]))) && (802816 == int32(arg6.strides[0]))), arg6.strides: expected to be compact array\00", align 1
@.str.395 = private constant [98 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: num_args should be 5\00", align 1
@.str.396 = private constant [173 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[0] to be pointer\00", align 1
@.str.397 = private constant [173 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[1] to be pointer\00", align 1
@.str.398 = private constant [173 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[2] to be pointer\00", align 1
@.str.399 = private constant [173 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[3] to be pointer\00", align 1
@.str.400 = private constant [173 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[4] to be pointer\00", align 1
@.str.401 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (512 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (25088 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.402 = private constant [281 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (16384 == int32(arg1.strides[3]))) && (49152 == int32(arg1.strides[2]))) && (147456 == int32(arg1.strides[1]))) && (147456 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.405 = private constant [79 x i8] c"Assert fail: (num_args == 2), fused_nn_global_avg_pool2d: num_args should be 2\00", align 1
@.str.406 = private constant [154 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_global_avg_pool2d: Expect arg[0] to be pointer\00", align 1
@.str.407 = private constant [154 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_global_avg_pool2d: Expect arg[1] to be pointer\00", align 1
@.str.408 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (224 == int32(arg0.strides[2]))) && (1568 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.409 = private constant [96 x i8] c"Assert fail: (64 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.410 = private constant [233 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (32 == int32(arg1.strides[3]))) && (32 == int32(arg1.strides[2]))) && (32 == int32(arg1.strides[1]))) && (2048 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.412 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_34: num_args should be 2\00", align 1
@.str.413 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_34: Expect arg[0] to be pointer\00", align 1
@.str.414 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_34: Expect arg[1] to be pointer\00", align 1
@.str.415 = private constant [235 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (4 == int32(arg1.strides[3]))) && (28 == int32(arg1.strides[2]))) && (196 == int32(arg1.strides[1]))) && (100352 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.417 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4: num_args should be 5\00", align 1
@.str.418 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4: Expect arg[0] to be pointer\00", align 1
@.str.419 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4: Expect arg[1] to be pointer\00", align 1
@.str.420 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4: Expect arg[2] to be pointer\00", align 1
@.str.421 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4: Expect arg[3] to be pointer\00", align 1
@.str.422 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4: Expect arg[4] to be pointer\00", align 1
@.str.423 = private constant [279 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (64 == int32(arg1.strides[4]))) && (32768 == int32(arg1.strides[3]))) && (32768 == int32(arg1.strides[2]))) && (32768 == int32(arg1.strides[1]))) && (65536 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.425 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: num_args should be 5\00", align 1
@.str.426 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[0] to be pointer\00", align 1
@.str.427 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[1] to be pointer\00", align 1
@.str.428 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[2] to be pointer\00", align 1
@.str.429 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[3] to be pointer\00", align 1
@.str.430 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[4] to be pointer\00", align 1
@.str.431 = private constant [97 x i8] c"Assert fail: (128 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.432 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (128 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.433 = private constant [277 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (16 == int32(arg1.strides[4]))) && (2048 == int32(arg1.strides[3]))) && (6144 == int32(arg1.strides[2]))) && (18432 == int32(arg1.strides[1]))) && (36864 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.434 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (16 == int32(arg4.strides[3]))) && (224 == int32(arg4.strides[2]))) && (3136 == int32(arg4.strides[1]))) && (50176 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.437 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_35: num_args should be 2\00", align 1
@.str.438 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_35: Expect arg[0] to be pointer\00", align 1
@.str.439 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_35: Expect arg[1] to be pointer\00", align 1
@.str.440 = private constant [242 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (512 == int32(arg1.strides[3]))) && (7168 == int32(arg1.strides[2]))) && (100352 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.442 = private constant [113 x i8] c"Assert fail: (num_args == 7), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: num_args should be 7\00", align 1
@.str.443 = private constant [188 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: Expect arg[0] to be pointer\00", align 1
@.str.444 = private constant [188 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: Expect arg[1] to be pointer\00", align 1
@.str.445 = private constant [188 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: Expect arg[2] to be pointer\00", align 1
@.str.446 = private constant [188 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: Expect arg[3] to be pointer\00", align 1
@.str.447 = private constant [188 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: Expect arg[4] to be pointer\00", align 1
@.str.448 = private constant [188 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: Expect arg[5] to be pointer\00", align 1
@.str.449 = private constant [188 x i8] c"Assert fail: ((((arg6.code == 3) || (arg6.code == 13)) || (arg6.code == 7)) || (arg6.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1: Expect arg[6] to be pointer\00", align 1
@.str.450 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (256 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (50176 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.451 = private constant [96 x i8] c"Assert fail: (16 == int32(arg4.shape[0])), Argument arg4.shape[0] has an unsatisfied constraint\00", align 1
@.str.452 = private constant [96 x i8] c"Assert fail: (16 == int32(arg5.shape[1])), Argument arg5.shape[1] has an unsatisfied constraint\00", align 1
@.str.453 = private constant [96 x i8] c"Assert fail: (14 == int32(arg5.shape[2])), Argument arg5.shape[2] has an unsatisfied constraint\00", align 1
@.str.454 = private constant [96 x i8] c"Assert fail: (14 == int32(arg5.shape[3])), Argument arg5.shape[3] has an unsatisfied constraint\00", align 1
@.str.455 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg5.strides[4])) && (64 == int32(arg5.strides[3]))) && (896 == int32(arg5.strides[2]))) && (12544 == int32(arg5.strides[1]))) && (200704 == int32(arg5.strides[0]))), arg5.strides: expected to be compact array\00", align 1
@.str.456 = private constant [96 x i8] c"Assert fail: (16 == int32(arg6.shape[1])), Argument arg6.shape[1] has an unsatisfied constraint\00", align 1
@.str.457 = private constant [96 x i8] c"Assert fail: (14 == int32(arg6.shape[2])), Argument arg6.shape[2] has an unsatisfied constraint\00", align 1
@.str.458 = private constant [96 x i8] c"Assert fail: (14 == int32(arg6.shape[3])), Argument arg6.shape[3] has an unsatisfied constraint\00", align 1
@.str.459 = private constant [96 x i8] c"Assert fail: (64 == int32(arg6.shape[4])), Argument arg6.shape[4] has an unsatisfied constraint\00", align 1
@.str.460 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg6.strides[4])) && (64 == int32(arg6.strides[3]))) && (896 == int32(arg6.strides[2]))) && (12544 == int32(arg6.strides[1]))) && (200704 == int32(arg6.strides[0]))), arg6.strides: expected to be compact array\00", align 1
@.str.462 = private constant [101 x i8] c"Assert fail: (num_args == 6), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2: num_args should be 6\00", align 1
@.str.463 = private constant [176 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2: Expect arg[0] to be pointer\00", align 1
@.str.464 = private constant [176 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2: Expect arg[1] to be pointer\00", align 1
@.str.465 = private constant [176 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2: Expect arg[2] to be pointer\00", align 1
@.str.466 = private constant [176 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2: Expect arg[3] to be pointer\00", align 1
@.str.467 = private constant [176 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2: Expect arg[4] to be pointer\00", align 1
@.str.468 = private constant [176 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2: Expect arg[5] to be pointer\00", align 1
@.str.470 = private constant [82 x i8] c"Assert fail: (num_args == 2), fused_nn_pad_layout_transform: num_args should be 2\00", align 1
@.str.471 = private constant [157 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_pad_layout_transform: Expect arg[0] to be pointer\00", align 1
@.str.472 = private constant [157 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_pad_layout_transform: Expect arg[1] to be pointer\00", align 1
@.str.473 = private constant [95 x i8] c"Assert fail: (3 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.474 = private constant [97 x i8] c"Assert fail: (224 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.475 = private constant [97 x i8] c"Assert fail: (224 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.476 = private constant [203 x i8] c"Assert fail: ((((1 == int32(arg0.strides[3])) && (224 == int32(arg0.strides[2]))) && (50176 == int32(arg0.strides[1]))) && (150528 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.477 = private constant [97 x i8] c"Assert fail: (230 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.478 = private constant [97 x i8] c"Assert fail: (230 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.479 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (3 == int32(arg1.strides[3]))) && (690 == int32(arg1.strides[2]))) && (158700 == int32(arg1.strides[1]))) && (158700 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.481 = private constant [72 x i8] c"Assert fail: (num_args == 2), fused_nn_max_pool2d: num_args should be 2\00", align 1
@.str.482 = private constant [147 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_max_pool2d: Expect arg[0] to be pointer\00", align 1
@.str.483 = private constant [147 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_max_pool2d: Expect arg[1] to be pointer\00", align 1
@.str.484 = private constant [97 x i8] c"Assert fail: (114 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.485 = private constant [97 x i8] c"Assert fail: (114 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.486 = private constant [203 x i8] c"Assert fail: ((((1 == int32(arg0.strides[3])) && (114 == int32(arg0.strides[2]))) && (12996 == int32(arg0.strides[1]))) && (831744 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.487 = private constant [81 x i8] c"Assert fail: (4 == tvm_struct_get(arg1, 0, 4)), arg1.ndim is expected to equal 4\00", align 1
@.str.488 = private constant [201 x i8] c"Assert fail: ((((1 == int32(arg1.strides[3])) && (56 == int32(arg1.strides[2]))) && (3136 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.490 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_33: num_args should be 2\00", align 1
@.str.491 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_33: Expect arg[0] to be pointer\00", align 1
@.str.492 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_33: Expect arg[1] to be pointer\00", align 1
@.str.493 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (512 == int32(arg1.strides[3]))) && (3584 == int32(arg1.strides[2]))) && (25088 == int32(arg1.strides[1]))) && (25088 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.495 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_38: num_args should be 2\00", align 1
@.str.496 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_38: Expect arg[0] to be pointer\00", align 1
@.str.497 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_38: Expect arg[1] to be pointer\00", align 1
@.str.498 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (64 == int32(arg1.strides[3]))) && (1792 == int32(arg1.strides[2]))) && (50176 == int32(arg1.strides[1]))) && (401408 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.500 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_37: num_args should be 2\00", align 1
@.str.501 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_37: Expect arg[0] to be pointer\00", align 1
@.str.502 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_37: Expect arg[1] to be pointer\00", align 1
@.str.503 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (64 == int32(arg0.strides[3]))) && (896 == int32(arg0.strides[2]))) && (12544 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.504 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (128 == int32(arg1.strides[3]))) && (1792 == int32(arg1.strides[2]))) && (25088 == int32(arg1.strides[1]))) && (50176 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.506 = private constant [82 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_nn_pad: num_args should be 2\00", align 1
@.str.507 = private constant [157 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_nn_pad: Expect arg[0] to be pointer\00", align 1
@.str.508 = private constant [157 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_nn_pad: Expect arg[1] to be pointer\00", align 1
@.str.509 = private constant [97 x i8] c"Assert fail: (112 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.510 = private constant [97 x i8] c"Assert fail: (112 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.511 = private constant [95 x i8] c"Assert fail: (8 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.512 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (8 == int32(arg0.strides[3]))) && (896 == int32(arg0.strides[2]))) && (100352 == int32(arg0.strides[1]))) && (802816 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.513 = private constant [97 x i8] c"Assert fail: (114 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.514 = private constant [97 x i8] c"Assert fail: (114 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.515 = private constant [203 x i8] c"Assert fail: ((((1 == int32(arg1.strides[3])) && (114 == int32(arg1.strides[2]))) && (12996 == int32(arg1.strides[1]))) && (831744 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.517 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_39: num_args should be 2\00", align 1
@.str.518 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_39: Expect arg[0] to be pointer\00", align 1
@.str.519 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_39: Expect arg[1] to be pointer\00", align 1
@.str.520 = private constant [96 x i8] c"Assert fail: (32 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.521 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (4 == int32(arg1.strides[3]))) && (112 == int32(arg1.strides[2]))) && (3136 == int32(arg1.strides[1]))) && (100352 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.523 = private constant [69 x i8] c"Assert fail: (num_args == 2), fused_nn_softmax: num_args should be 2\00", align 1
@.str.524 = private constant [144 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_softmax: Expect arg[0] to be pointer\00", align 1
@.str.525 = private constant [144 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_softmax: Expect arg[1] to be pointer\00", align 1
@.str.526 = private constant [81 x i8] c"Assert fail: (2 == tvm_struct_get(arg0, 0, 4)), arg0.ndim is expected to equal 2\00", align 1
@.str.527 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.528 = private constant [125 x i8] c"Assert fail: ((1 == int32(arg0.strides[1])) && (1000 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.529 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.530 = private constant [125 x i8] c"Assert fail: ((1 == int32(arg1.strides[1])) && (1000 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.531 = private constant [113 x i8] c"Assert fail: (num_args == 7), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: num_args should be 7\00", align 1
@.str.532 = private constant [188 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: Expect arg[0] to be pointer\00", align 1
@.str.533 = private constant [188 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: Expect arg[1] to be pointer\00", align 1
@.str.534 = private constant [188 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: Expect arg[2] to be pointer\00", align 1
@.str.535 = private constant [188 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: Expect arg[3] to be pointer\00", align 1
@.str.536 = private constant [188 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: Expect arg[4] to be pointer\00", align 1
@.str.537 = private constant [188 x i8] c"Assert fail: ((((arg5.code == 3) || (arg5.code == 13)) || (arg5.code == 7)) || (arg5.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: Expect arg[5] to be pointer\00", align 1
@.str.538 = private constant [188 x i8] c"Assert fail: ((((arg6.code == 3) || (arg6.code == 13)) || (arg6.code == 7)) || (arg6.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2: Expect arg[6] to be pointer\00", align 1
@.str.539 = private constant [96 x i8] c"Assert fail: (32 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.540 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (4 == int32(arg0.strides[3]))) && (112 == int32(arg0.strides[2]))) && (3136 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.541 = private constant [272 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (128 == int32(arg1.strides[3]))) && (128 == int32(arg1.strides[2]))) && (128 == int32(arg1.strides[1]))) && (4096 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.542 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg5.strides[4])) && (32 == int32(arg5.strides[3]))) && (896 == int32(arg5.strides[2]))) && (25088 == int32(arg5.strides[1]))) && (401408 == int32(arg5.strides[0]))), arg5.strides: expected to be compact array\00", align 1
@.str.543 = private constant [96 x i8] c"Assert fail: (28 == int32(arg6.shape[2])), Argument arg6.shape[2] has an unsatisfied constraint\00", align 1
@.str.544 = private constant [96 x i8] c"Assert fail: (28 == int32(arg6.shape[3])), Argument arg6.shape[3] has an unsatisfied constraint\00", align 1
@.str.545 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg6.strides[4])) && (32 == int32(arg6.strides[3]))) && (896 == int32(arg6.strides[2]))) && (25088 == int32(arg6.strides[1]))) && (401408 == int32(arg6.strides[0]))), arg6.strides: expected to be compact array\00", align 1
@.str.547 = private constant [71 x i8] c"Assert fail: (num_args == 4), fused_nn_dense_add: num_args should be 4\00", align 1
@.str.548 = private constant [146 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_dense_add: Expect arg[0] to be pointer\00", align 1
@.str.549 = private constant [146 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_dense_add: Expect arg[1] to be pointer\00", align 1
@.str.550 = private constant [146 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_dense_add: Expect arg[2] to be pointer\00", align 1
@.str.551 = private constant [146 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_dense_add: Expect arg[3] to be pointer\00", align 1
@.str.552 = private constant [98 x i8] c"Assert fail: (2048 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.553 = private constant [125 x i8] c"Assert fail: ((1 == int32(arg0.strides[1])) && (2048 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.554 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.555 = private constant [81 x i8] c"Assert fail: (1 == tvm_struct_get(arg2, 0, 4)), arg2.ndim is expected to equal 1\00", align 1
@.str.556 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.557 = private constant [87 x i8] c"Assert fail: (1 == int32(arg2.strides[0])), arg2.strides: expected to be compact array\00", align 1
@.str.558 = private constant [81 x i8] c"Assert fail: (2 == tvm_struct_get(arg3, 0, 4)), arg3.ndim is expected to equal 2\00", align 1
@.str.559 = private constant [95 x i8] c"Assert fail: (1 == int32(arg3.shape[0])), Argument arg3.shape[0] has an unsatisfied constraint\00", align 1
@.str.560 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg3.shape[1])), Argument arg3.shape[1] has an unsatisfied constraint\00", align 1
@.str.561 = private constant [125 x i8] c"Assert fail: ((1 == int32(arg3.strides[1])) && (1000 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.563 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6: num_args should be 5\00", align 1
@.str.564 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6: Expect arg[0] to be pointer\00", align 1
@.str.565 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6: Expect arg[1] to be pointer\00", align 1
@.str.566 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6: Expect arg[2] to be pointer\00", align 1
@.str.567 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6: Expect arg[3] to be pointer\00", align 1
@.str.568 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6: Expect arg[4] to be pointer\00", align 1
@.str.569 = private constant [242 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (128 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (100352 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.570 = private constant [278 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (4096 == int32(arg1.strides[3]))) && (12288 == int32(arg1.strides[2]))) && (36864 == int32(arg1.strides[1]))) && (36864 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.573 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_40: num_args should be 2\00", align 1
@.str.574 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_40: Expect arg[0] to be pointer\00", align 1
@.str.575 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_40: Expect arg[1] to be pointer\00", align 1
@.str.576 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (64 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (50176 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@__tvm_main__ = weak local_unnamed_addr constant [26 x i8] c"fused_layout_transform_50\00", align 1

define dllexport i32 @fused_layout_transform_50(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !9
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.1, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !23
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.2, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !25
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !39
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 16
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !41
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 14
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !44
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 14
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !46
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 64
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !51
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 200704, i32 12544, i32 896, i32 64>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !63
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.11, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !67
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !81
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !83
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 14
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.17, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !86
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 14
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.18, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !88
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 1024
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !92
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 200704, i32 200704, i32 14336, i32 1024>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !104
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([244 x i8], [244 x i8]* @.str.20, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_50_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_50_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %4, align 8
  %3 = getelementptr inbounds %4, %4* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %4, %4* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %4* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 13
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 14
  %15 = select i1 %14, i32 %13, i32 14
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 14
  %18 = select i1 %17, i32 %16, i32 14
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 14336
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body5 ]
  %27 = add nsw i64 %24, %indvars.iv
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 63
  %30 = lshr i32 %28, 6
  %31 = mul nsw i32 %30, 12544
  %32 = add i32 %26, %31
  %33 = or i32 %32, %29
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to i32*
  %37 = load i32, i32* %36, align 4, !tbaa !108
  %38 = getelementptr inbounds float, float* %4, i64 %27
  %39 = bitcast float* %38 to i32*
  store i32 %37, i32* %39, align 4, !tbaa !111
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %40 = or i64 %24, 1024
  %41 = or i32 %26, 64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %42 = add nsw i64 %40, %indvars.iv.1
  %43 = trunc i64 %indvars.iv.1 to i32
  %44 = and i32 %43, 63
  %45 = lshr i32 %43, 6
  %46 = mul nsw i32 %45, 12544
  %47 = add i32 %41, %46
  %48 = or i32 %47, %44
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to i32*
  %52 = load i32, i32* %51, align 4, !tbaa !108
  %53 = getelementptr inbounds float, float* %4, i64 %42
  %54 = bitcast float* %53 to i32*
  store i32 %52, i32* %54, align 4, !tbaa !111
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 1024
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %55 = add nsw i64 %24, 2048
  %56 = add i32 %26, 128
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %57 = add nsw i64 %55, %indvars.iv.2
  %58 = trunc i64 %indvars.iv.2 to i32
  %59 = and i32 %58, 63
  %60 = lshr i32 %58, 6
  %61 = mul nsw i32 %60, 12544
  %62 = add i32 %56, %61
  %63 = or i32 %62, %59
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float* %7, i64 %64
  %66 = bitcast float* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !108
  %68 = getelementptr inbounds float, float* %4, i64 %57
  %69 = bitcast float* %68 to i32*
  store i32 %67, i32* %69, align 4, !tbaa !111
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 1024
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %70 = add nsw i64 %24, 3072
  %71 = add i32 %26, 192
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %72 = add nsw i64 %70, %indvars.iv.3
  %73 = trunc i64 %indvars.iv.3 to i32
  %74 = and i32 %73, 63
  %75 = lshr i32 %73, 6
  %76 = mul nsw i32 %75, 12544
  %77 = add i32 %71, %76
  %78 = or i32 %77, %74
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %7, i64 %79
  %81 = bitcast float* %80 to i32*
  %82 = load i32, i32* %81, align 4, !tbaa !108
  %83 = getelementptr inbounds float, float* %4, i64 %72
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4, !tbaa !111
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 1024
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  %85 = add nsw i64 %24, 4096
  %86 = add i32 %26, 256
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %87 = add nsw i64 %85, %indvars.iv.4
  %88 = trunc i64 %indvars.iv.4 to i32
  %89 = and i32 %88, 63
  %90 = lshr i32 %88, 6
  %91 = mul nsw i32 %90, 12544
  %92 = add i32 %86, %91
  %93 = or i32 %92, %89
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !108
  %98 = getelementptr inbounds float, float* %4, i64 %87
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !111
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 1024
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  %100 = add nsw i64 %24, 5120
  %101 = add i32 %26, 320
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %102 = add nsw i64 %100, %indvars.iv.5
  %103 = trunc i64 %indvars.iv.5 to i32
  %104 = and i32 %103, 63
  %105 = lshr i32 %103, 6
  %106 = mul nsw i32 %105, 12544
  %107 = add i32 %101, %106
  %108 = or i32 %107, %104
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !108
  %113 = getelementptr inbounds float, float* %4, i64 %102
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !111
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 1024
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  %115 = add nsw i64 %24, 6144
  %116 = add i32 %26, 384
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %117 = add nsw i64 %115, %indvars.iv.6
  %118 = trunc i64 %indvars.iv.6 to i32
  %119 = and i32 %118, 63
  %120 = lshr i32 %118, 6
  %121 = mul nsw i32 %120, 12544
  %122 = add i32 %116, %121
  %123 = or i32 %122, %119
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to i32*
  %127 = load i32, i32* %126, align 4, !tbaa !108
  %128 = getelementptr inbounds float, float* %4, i64 %117
  %129 = bitcast float* %128 to i32*
  store i32 %127, i32* %129, align 4, !tbaa !111
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 1024
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  %130 = add nsw i64 %24, 7168
  %131 = add i32 %26, 448
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %132 = add nsw i64 %130, %indvars.iv.7
  %133 = trunc i64 %indvars.iv.7 to i32
  %134 = and i32 %133, 63
  %135 = lshr i32 %133, 6
  %136 = mul nsw i32 %135, 12544
  %137 = add i32 %131, %136
  %138 = or i32 %137, %134
  %139 = sext i32 %138 to i64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to i32*
  %142 = load i32, i32* %141, align 4, !tbaa !108
  %143 = getelementptr inbounds float, float* %4, i64 %132
  %144 = bitcast float* %143 to i32*
  store i32 %142, i32* %144, align 4, !tbaa !111
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 1024
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !50

for_end6.7:                                       ; preds = %for_body5.7
  %145 = add nsw i64 %24, 8192
  %146 = add i32 %26, 512
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %147 = add nsw i64 %145, %indvars.iv.8
  %148 = trunc i64 %indvars.iv.8 to i32
  %149 = and i32 %148, 63
  %150 = lshr i32 %148, 6
  %151 = mul nsw i32 %150, 12544
  %152 = add i32 %146, %151
  %153 = or i32 %152, %149
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to i32*
  %157 = load i32, i32* %156, align 4, !tbaa !108
  %158 = getelementptr inbounds float, float* %4, i64 %147
  %159 = bitcast float* %158 to i32*
  store i32 %157, i32* %159, align 4, !tbaa !111
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 1024
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !50

for_end6.8:                                       ; preds = %for_body5.8
  %160 = add nsw i64 %24, 9216
  %161 = add i32 %26, 576
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %162 = add nsw i64 %160, %indvars.iv.9
  %163 = trunc i64 %indvars.iv.9 to i32
  %164 = and i32 %163, 63
  %165 = lshr i32 %163, 6
  %166 = mul nsw i32 %165, 12544
  %167 = add i32 %161, %166
  %168 = or i32 %167, %164
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to i32*
  %172 = load i32, i32* %171, align 4, !tbaa !108
  %173 = getelementptr inbounds float, float* %4, i64 %162
  %174 = bitcast float* %173 to i32*
  store i32 %172, i32* %174, align 4, !tbaa !111
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 1024
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !50

for_end6.9:                                       ; preds = %for_body5.9
  %175 = add nsw i64 %24, 10240
  %176 = add i32 %26, 640
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %177 = add nsw i64 %175, %indvars.iv.10
  %178 = trunc i64 %indvars.iv.10 to i32
  %179 = and i32 %178, 63
  %180 = lshr i32 %178, 6
  %181 = mul nsw i32 %180, 12544
  %182 = add i32 %176, %181
  %183 = or i32 %182, %179
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to i32*
  %187 = load i32, i32* %186, align 4, !tbaa !108
  %188 = getelementptr inbounds float, float* %4, i64 %177
  %189 = bitcast float* %188 to i32*
  store i32 %187, i32* %189, align 4, !tbaa !111
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 1024
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !50

for_end6.10:                                      ; preds = %for_body5.10
  %190 = add nsw i64 %24, 11264
  %191 = add i32 %26, 704
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %192 = add nsw i64 %190, %indvars.iv.11
  %193 = trunc i64 %indvars.iv.11 to i32
  %194 = and i32 %193, 63
  %195 = lshr i32 %193, 6
  %196 = mul nsw i32 %195, 12544
  %197 = add i32 %191, %196
  %198 = or i32 %197, %194
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds float, float* %7, i64 %199
  %201 = bitcast float* %200 to i32*
  %202 = load i32, i32* %201, align 4, !tbaa !108
  %203 = getelementptr inbounds float, float* %4, i64 %192
  %204 = bitcast float* %203 to i32*
  store i32 %202, i32* %204, align 4, !tbaa !111
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 1024
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !50

for_end6.11:                                      ; preds = %for_body5.11
  %205 = add nsw i64 %24, 12288
  %206 = add i32 %26, 768
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %207 = add nsw i64 %205, %indvars.iv.12
  %208 = trunc i64 %indvars.iv.12 to i32
  %209 = and i32 %208, 63
  %210 = lshr i32 %208, 6
  %211 = mul nsw i32 %210, 12544
  %212 = add i32 %206, %211
  %213 = or i32 %212, %209
  %214 = sext i32 %213 to i64
  %215 = getelementptr inbounds float, float* %7, i64 %214
  %216 = bitcast float* %215 to i32*
  %217 = load i32, i32* %216, align 4, !tbaa !108
  %218 = getelementptr inbounds float, float* %4, i64 %207
  %219 = bitcast float* %218 to i32*
  store i32 %217, i32* %219, align 4, !tbaa !111
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 1024
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !50

for_end6.12:                                      ; preds = %for_body5.12
  %220 = add nsw i64 %24, 13312
  %221 = add i32 %26, 832
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %222 = add nsw i64 %220, %indvars.iv.13
  %223 = trunc i64 %indvars.iv.13 to i32
  %224 = and i32 %223, 63
  %225 = lshr i32 %223, 6
  %226 = mul nsw i32 %225, 12544
  %227 = add i32 %221, %226
  %228 = or i32 %227, %224
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to i32*
  %232 = load i32, i32* %231, align 4, !tbaa !108
  %233 = getelementptr inbounds float, float* %4, i64 %222
  %234 = bitcast float* %233 to i32*
  store i32 %232, i32* %234, align 4, !tbaa !111
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 1024
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !50

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %235 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %235, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_49(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.24, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !114
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.25, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !128
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.26, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !130
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !144
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 8
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !146
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 28
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !149
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 28
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !151
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 64
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !155
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 401408, i32 50176, i32 1792, i32 64>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !167
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.30, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !171
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !185
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 16
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.31, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !187
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 28
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !190
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 28
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !192
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 32
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.34, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !196
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 401408, i32 25088, i32 896, i32 32>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !208
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.35, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_49_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_49_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %5, align 8
  %3 = getelementptr inbounds %5, %5* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %5, %5* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %5* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.36, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.36(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 447
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 448
  %15 = select i1 %14, i32 %13, i32 448
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 448
  %18 = select i1 %17, i32 %16, i32 448
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 896
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = sdiv i32 %25, 28
  %27 = shl nsw i32 %26, 5
  %28 = srem i32 %25, 28
  %29 = mul nsw i32 %28, 1792
  %30 = sext i32 %27 to i64
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %31 = shl i64 %indvars.iv7, 5
  %32 = add nsw i64 %31, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %33 = shl i32 %indvars.iv7.tr, 6
  %34 = add i32 %29, %33
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %35 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %35, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %36 = add nsw i64 %32, %indvars.iv
  %37 = add nuw nsw i64 %indvars.iv, %30
  %38 = trunc i64 %37 to i32
  %39 = ashr i32 %38, 6
  %40 = mul nsw i32 %39, 50176
  %41 = add i32 %34, %40
  %42 = trunc i64 %37 to i32
  %43 = and i32 %42, 63
  %44 = or i32 %41, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = bitcast float* %46 to i32*
  %48 = load i32, i32* %47, align 4, !tbaa !212
  %49 = getelementptr inbounds float, float* %4, i64 %36
  %50 = bitcast float* %49 to i32*
  store i32 %48, i32* %50, align 4, !tbaa !215
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([101 x i8], [101 x i8]* @.str.37, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !218
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !232
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !235
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !237
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.38, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !241
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.39, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !243
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !257
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 4
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !259
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 56
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !262
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 56
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !264
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 16
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.46, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !268
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 200704, i32 50176, i32 896, i32 16>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !280
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !284
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 4
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !298
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 4
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !300
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !303
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !305
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 16
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !309
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 16
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !311
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 1024, i32 256, i32 256, i32 256>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !323
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 16
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !327
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([272 x i8], [272 x i8]* @.str.55, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !329
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 4
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !343
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !345
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !348
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 16
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !350
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 16, i32 16, i32 16, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !362
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 4
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !376
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !378
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !381
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 16
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !383
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 16, i32 16, i32 16, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !395
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !409
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 4
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.79, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !411
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 56
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.80, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !414
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 56
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.81, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !416
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 16
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.82, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !420
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 200704, i32 50176, i32 896, i32 16>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !432
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.83, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_11_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %6, align 8
  %7 = getelementptr inbounds %6, %6* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %6, %6* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %6, %6* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %6, %6* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %6, %6* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %6, %6* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %6* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.87, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.87(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 223
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 224
  %27 = select i1 %26, i32 %25, i32 224
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 224
  %30 = select i1 %29, i32 %28, i32 224
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body, label %for_end, !prof !5

for_body:                                         ; preds = %entry, %for_end12
  %32 = phi i32 [ %385, %for_end12 ], [ %30, %entry ]
  %33 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %34 = tail call i8* %33(i32 1, i32 %19, i64 3584, i32 2, i32 32)
  %35 = bitcast i8* %34 to float*
  %36 = srem i32 %32, 56
  %37 = mul nsw i32 %36, 896
  %38 = sdiv i32 %32, 56
  %39 = shl i32 %38, 10
  %40 = sext i32 %39 to i64
  %41 = sext i32 %37 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end12, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end6
  %42 = mul nsw i32 %32, 896
  %43 = shl nsw i32 %38, 4
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds float, float* %16, i64 %44
  %46 = bitcast float* %45 to <16 x float>*
  %47 = load <16 x float>, <16 x float>* %46, align 64, !tbaa !436
  %48 = getelementptr inbounds float, float* %13, i64 %44
  %49 = bitcast float* %48 to <16 x float>*
  %50 = load <16 x float>, <16 x float>* %49, align 64, !tbaa !439
  br label %for_begin13.preheader

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv90 = phi i64 [ 0, %for_body ], [ %indvars.iv.next91, %for_end6 ]
  %51 = mul nuw nsw i64 %indvars.iv90, 224
  %52 = getelementptr inbounds float, float* %35, i64 %51
  %53 = bitcast float* %52 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %53, align 64, !tbaa !442
  %54 = or i64 %51, 16
  %55 = getelementptr inbounds float, float* %35, i64 %54
  %56 = bitcast float* %55 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %56, align 64, !tbaa !442
  %57 = add nuw nsw i64 %51, 32
  %58 = getelementptr inbounds float, float* %35, i64 %57
  %59 = bitcast float* %58 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %59, align 64, !tbaa !442
  %60 = add nuw nsw i64 %51, 48
  %61 = getelementptr inbounds float, float* %35, i64 %60
  %62 = bitcast float* %61 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %62, align 64, !tbaa !442
  %63 = add nuw nsw i64 %51, 64
  %64 = getelementptr inbounds float, float* %35, i64 %63
  %65 = bitcast float* %64 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %65, align 64, !tbaa !442
  %66 = add nuw nsw i64 %51, 80
  %67 = getelementptr inbounds float, float* %35, i64 %66
  %68 = bitcast float* %67 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %68, align 64, !tbaa !442
  %69 = add nuw nsw i64 %51, 96
  %70 = getelementptr inbounds float, float* %35, i64 %69
  %71 = bitcast float* %70 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %71, align 64, !tbaa !442
  %72 = add nuw nsw i64 %51, 112
  %73 = getelementptr inbounds float, float* %35, i64 %72
  %74 = bitcast float* %73 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %74, align 64, !tbaa !442
  %75 = add nuw nsw i64 %51, 128
  %76 = getelementptr inbounds float, float* %35, i64 %75
  %77 = bitcast float* %76 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %77, align 64, !tbaa !442
  %78 = add nuw nsw i64 %51, 144
  %79 = getelementptr inbounds float, float* %35, i64 %78
  %80 = bitcast float* %79 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %80, align 64, !tbaa !442
  %81 = add nuw nsw i64 %51, 160
  %82 = getelementptr inbounds float, float* %35, i64 %81
  %83 = bitcast float* %82 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %83, align 64, !tbaa !442
  %84 = add nuw nsw i64 %51, 176
  %85 = getelementptr inbounds float, float* %35, i64 %84
  %86 = bitcast float* %85 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %86, align 64, !tbaa !442
  %87 = add nuw nsw i64 %51, 192
  %88 = getelementptr inbounds float, float* %35, i64 %87
  %89 = bitcast float* %88 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %89, align 64, !tbaa !442
  %90 = add nuw nsw i64 %51, 208
  %91 = getelementptr inbounds float, float* %35, i64 %90
  %92 = bitcast float* %91 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %92, align 64, !tbaa !442
  %93 = add nsw i64 %51, %41
  br label %for_begin7.preheader

for_begin7.preheader:                             ; preds = %for_end9, %for_body2
  %indvars.iv87 = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next88, %for_end9 ]
  %.lcssa4673 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %200, %for_end9 ]
  %.lcssa4471 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %194, %for_end9 ]
  %.lcssa4269 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %188, %for_end9 ]
  %.lcssa4067 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %182, %for_end9 ]
  %.lcssa3865 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %176, %for_end9 ]
  %.lcssa3663 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %170, %for_end9 ]
  %.lcssa3461 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %164, %for_end9 ]
  %.lcssa3259 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %158, %for_end9 ]
  %.lcssa3057 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %152, %for_end9 ]
  %.lcssa2855 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %146, %for_end9 ]
  %.lcssa2653 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %140, %for_end9 ]
  %.lcssa2451 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %134, %for_end9 ]
  %.lcssa2249 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %128, %for_end9 ]
  %.lcssa48 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %122, %for_end9 ]
  %94 = mul nuw nsw i64 %indvars.iv87, 50176
  %95 = add nsw i64 %93, %94
  %96 = shl i64 %indvars.iv87, 8
  %97 = add nuw nsw i64 %96, %40
  br label %for_body8

for_end6:                                         ; preds = %for_end9
  store <16 x float> %122, <16 x float>* %53, align 64, !tbaa !442
  store <16 x float> %128, <16 x float>* %56, align 64, !tbaa !442
  store <16 x float> %134, <16 x float>* %59, align 64, !tbaa !442
  store <16 x float> %140, <16 x float>* %62, align 64, !tbaa !442
  store <16 x float> %146, <16 x float>* %65, align 64, !tbaa !442
  store <16 x float> %152, <16 x float>* %68, align 64, !tbaa !442
  store <16 x float> %158, <16 x float>* %71, align 64, !tbaa !442
  store <16 x float> %164, <16 x float>* %74, align 64, !tbaa !442
  store <16 x float> %170, <16 x float>* %77, align 64, !tbaa !442
  store <16 x float> %176, <16 x float>* %80, align 64, !tbaa !442
  store <16 x float> %182, <16 x float>* %83, align 64, !tbaa !442
  store <16 x float> %188, <16 x float>* %86, align 64, !tbaa !442
  store <16 x float> %194, <16 x float>* %89, align 64, !tbaa !442
  store <16 x float> %200, <16 x float>* %92, align 64, !tbaa !442
  %indvars.iv.next91 = add nuw nsw i64 %indvars.iv90, 1
  %exitcond92 = icmp eq i64 %indvars.iv.next91, 4
  br i1 %exitcond92, label %for_begin10.preheader, label %for_body2, !prof !50

for_body8:                                        ; preds = %for_body8, %for_begin7.preheader
  %indvars.iv = phi i64 [ 0, %for_begin7.preheader ], [ %indvars.iv.next, %for_body8 ]
  %98 = phi <16 x float> [ %.lcssa4673, %for_begin7.preheader ], [ %200, %for_body8 ]
  %99 = phi <16 x float> [ %.lcssa4471, %for_begin7.preheader ], [ %194, %for_body8 ]
  %100 = phi <16 x float> [ %.lcssa4269, %for_begin7.preheader ], [ %188, %for_body8 ]
  %101 = phi <16 x float> [ %.lcssa4067, %for_begin7.preheader ], [ %182, %for_body8 ]
  %102 = phi <16 x float> [ %.lcssa3865, %for_begin7.preheader ], [ %176, %for_body8 ]
  %103 = phi <16 x float> [ %.lcssa3663, %for_begin7.preheader ], [ %170, %for_body8 ]
  %104 = phi <16 x float> [ %.lcssa3461, %for_begin7.preheader ], [ %164, %for_body8 ]
  %105 = phi <16 x float> [ %.lcssa3259, %for_begin7.preheader ], [ %158, %for_body8 ]
  %106 = phi <16 x float> [ %.lcssa3057, %for_begin7.preheader ], [ %152, %for_body8 ]
  %107 = phi <16 x float> [ %.lcssa2855, %for_begin7.preheader ], [ %146, %for_body8 ]
  %108 = phi <16 x float> [ %.lcssa2653, %for_begin7.preheader ], [ %140, %for_body8 ]
  %109 = phi <16 x float> [ %.lcssa2451, %for_begin7.preheader ], [ %134, %for_body8 ]
  %110 = phi <16 x float> [ %.lcssa2249, %for_begin7.preheader ], [ %128, %for_body8 ]
  %111 = phi <16 x float> [ %.lcssa48, %for_begin7.preheader ], [ %122, %for_body8 ]
  %112 = add nsw i64 %95, %indvars.iv
  %113 = getelementptr inbounds float, float* %4, i64 %112
  %114 = load float, float* %113, align 4, !tbaa !445
  %115 = insertelement <16 x float> undef, float %114, i32 0
  %116 = shufflevector <16 x float> %115, <16 x float> undef, <16 x i32> zeroinitializer
  %117 = shl i64 %indvars.iv, 4
  %118 = add nuw nsw i64 %97, %117
  %119 = getelementptr inbounds float, float* %7, i64 %118
  %120 = bitcast float* %119 to <16 x float>*
  %121 = load <16 x float>, <16 x float>* %120, align 64, !tbaa !448
  %122 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %116, <16 x float> %121, <16 x float> %111)
  %123 = add nsw i64 %112, 16
  %124 = getelementptr inbounds float, float* %4, i64 %123
  %125 = load float, float* %124, align 4, !tbaa !445
  %126 = insertelement <16 x float> undef, float %125, i32 0
  %127 = shufflevector <16 x float> %126, <16 x float> undef, <16 x i32> zeroinitializer
  %128 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %127, <16 x float> %121, <16 x float> %110)
  %129 = add nsw i64 %112, 32
  %130 = getelementptr inbounds float, float* %4, i64 %129
  %131 = load float, float* %130, align 4, !tbaa !445
  %132 = insertelement <16 x float> undef, float %131, i32 0
  %133 = shufflevector <16 x float> %132, <16 x float> undef, <16 x i32> zeroinitializer
  %134 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %133, <16 x float> %121, <16 x float> %109)
  %135 = add nsw i64 %112, 48
  %136 = getelementptr inbounds float, float* %4, i64 %135
  %137 = load float, float* %136, align 4, !tbaa !445
  %138 = insertelement <16 x float> undef, float %137, i32 0
  %139 = shufflevector <16 x float> %138, <16 x float> undef, <16 x i32> zeroinitializer
  %140 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %139, <16 x float> %121, <16 x float> %108)
  %141 = add nsw i64 %112, 64
  %142 = getelementptr inbounds float, float* %4, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !445
  %144 = insertelement <16 x float> undef, float %143, i32 0
  %145 = shufflevector <16 x float> %144, <16 x float> undef, <16 x i32> zeroinitializer
  %146 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %145, <16 x float> %121, <16 x float> %107)
  %147 = add nsw i64 %112, 80
  %148 = getelementptr inbounds float, float* %4, i64 %147
  %149 = load float, float* %148, align 4, !tbaa !445
  %150 = insertelement <16 x float> undef, float %149, i32 0
  %151 = shufflevector <16 x float> %150, <16 x float> undef, <16 x i32> zeroinitializer
  %152 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %151, <16 x float> %121, <16 x float> %106)
  %153 = add nsw i64 %112, 96
  %154 = getelementptr inbounds float, float* %4, i64 %153
  %155 = load float, float* %154, align 4, !tbaa !445
  %156 = insertelement <16 x float> undef, float %155, i32 0
  %157 = shufflevector <16 x float> %156, <16 x float> undef, <16 x i32> zeroinitializer
  %158 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %157, <16 x float> %121, <16 x float> %105)
  %159 = add nsw i64 %112, 112
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = load float, float* %160, align 4, !tbaa !445
  %162 = insertelement <16 x float> undef, float %161, i32 0
  %163 = shufflevector <16 x float> %162, <16 x float> undef, <16 x i32> zeroinitializer
  %164 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %163, <16 x float> %121, <16 x float> %104)
  %165 = add nsw i64 %112, 128
  %166 = getelementptr inbounds float, float* %4, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !445
  %168 = insertelement <16 x float> undef, float %167, i32 0
  %169 = shufflevector <16 x float> %168, <16 x float> undef, <16 x i32> zeroinitializer
  %170 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %169, <16 x float> %121, <16 x float> %103)
  %171 = add nsw i64 %112, 144
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !445
  %174 = insertelement <16 x float> undef, float %173, i32 0
  %175 = shufflevector <16 x float> %174, <16 x float> undef, <16 x i32> zeroinitializer
  %176 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %175, <16 x float> %121, <16 x float> %102)
  %177 = add nsw i64 %112, 160
  %178 = getelementptr inbounds float, float* %4, i64 %177
  %179 = load float, float* %178, align 4, !tbaa !445
  %180 = insertelement <16 x float> undef, float %179, i32 0
  %181 = shufflevector <16 x float> %180, <16 x float> undef, <16 x i32> zeroinitializer
  %182 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %181, <16 x float> %121, <16 x float> %101)
  %183 = add nsw i64 %112, 176
  %184 = getelementptr inbounds float, float* %4, i64 %183
  %185 = load float, float* %184, align 4, !tbaa !445
  %186 = insertelement <16 x float> undef, float %185, i32 0
  %187 = shufflevector <16 x float> %186, <16 x float> undef, <16 x i32> zeroinitializer
  %188 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %187, <16 x float> %121, <16 x float> %100)
  %189 = add nsw i64 %112, 192
  %190 = getelementptr inbounds float, float* %4, i64 %189
  %191 = load float, float* %190, align 4, !tbaa !445
  %192 = insertelement <16 x float> undef, float %191, i32 0
  %193 = shufflevector <16 x float> %192, <16 x float> undef, <16 x i32> zeroinitializer
  %194 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %193, <16 x float> %121, <16 x float> %99)
  %195 = add nsw i64 %112, 208
  %196 = getelementptr inbounds float, float* %4, i64 %195
  %197 = load float, float* %196, align 4, !tbaa !445
  %198 = insertelement <16 x float> undef, float %197, i32 0
  %199 = shufflevector <16 x float> %198, <16 x float> undef, <16 x i32> zeroinitializer
  %200 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %199, <16 x float> %121, <16 x float> %98)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %indvars.iv.next88 = add nuw nsw i64 %indvars.iv87, 1
  %exitcond89 = icmp eq i64 %indvars.iv.next88, 4
  br i1 %exitcond89, label %for_end6, label %for_begin7.preheader, !prof !50

for_begin13.preheader:                            ; preds = %for_begin13.preheader, %for_begin10.preheader
  %indvars.iv96 = phi i64 [ 0, %for_begin10.preheader ], [ %indvars.iv.next97, %for_begin13.preheader ]
  %201 = mul nuw nsw i64 %indvars.iv96, 224
  %202 = trunc i64 %201 to i32
  %203 = add i32 %42, %202
  %204 = getelementptr inbounds float, float* %35, i64 %201
  %205 = bitcast float* %204 to <16 x float>*
  %206 = load <16 x float>, <16 x float>* %205, align 64, !tbaa !442
  %207 = fadd <16 x float> %50, %206
  %208 = fadd <16 x float> %47, %207
  %209 = fcmp ogt <16 x float> %208, zeroinitializer
  %210 = select <16 x i1> %209, <16 x float> %208, <16 x float> zeroinitializer
  %211 = sext i32 %203 to i64
  %212 = getelementptr inbounds float, float* %10, i64 %211
  %213 = bitcast float* %212 to <16 x float>*
  store <16 x float> %210, <16 x float>* %213, align 64, !tbaa !451
  %214 = or i64 %201, 16
  %215 = trunc i64 %214 to i32
  %216 = add i32 %42, %215
  %217 = getelementptr inbounds float, float* %35, i64 %214
  %218 = bitcast float* %217 to <16 x float>*
  %219 = load <16 x float>, <16 x float>* %218, align 64, !tbaa !442
  %220 = fadd <16 x float> %50, %219
  %221 = fadd <16 x float> %47, %220
  %222 = fcmp ogt <16 x float> %221, zeroinitializer
  %223 = select <16 x i1> %222, <16 x float> %221, <16 x float> zeroinitializer
  %224 = sext i32 %216 to i64
  %225 = getelementptr inbounds float, float* %10, i64 %224
  %226 = bitcast float* %225 to <16 x float>*
  store <16 x float> %223, <16 x float>* %226, align 64, !tbaa !451
  %227 = add nuw nsw i64 %201, 32
  %228 = trunc i64 %227 to i32
  %229 = add i32 %42, %228
  %230 = getelementptr inbounds float, float* %35, i64 %227
  %231 = bitcast float* %230 to <16 x float>*
  %232 = load <16 x float>, <16 x float>* %231, align 64, !tbaa !442
  %233 = fadd <16 x float> %50, %232
  %234 = fadd <16 x float> %47, %233
  %235 = fcmp ogt <16 x float> %234, zeroinitializer
  %236 = select <16 x i1> %235, <16 x float> %234, <16 x float> zeroinitializer
  %237 = sext i32 %229 to i64
  %238 = getelementptr inbounds float, float* %10, i64 %237
  %239 = bitcast float* %238 to <16 x float>*
  store <16 x float> %236, <16 x float>* %239, align 64, !tbaa !451
  %240 = add nuw nsw i64 %201, 48
  %241 = trunc i64 %240 to i32
  %242 = add i32 %42, %241
  %243 = getelementptr inbounds float, float* %35, i64 %240
  %244 = bitcast float* %243 to <16 x float>*
  %245 = load <16 x float>, <16 x float>* %244, align 64, !tbaa !442
  %246 = fadd <16 x float> %50, %245
  %247 = fadd <16 x float> %47, %246
  %248 = fcmp ogt <16 x float> %247, zeroinitializer
  %249 = select <16 x i1> %248, <16 x float> %247, <16 x float> zeroinitializer
  %250 = sext i32 %242 to i64
  %251 = getelementptr inbounds float, float* %10, i64 %250
  %252 = bitcast float* %251 to <16 x float>*
  store <16 x float> %249, <16 x float>* %252, align 64, !tbaa !451
  %253 = add nuw nsw i64 %201, 64
  %254 = trunc i64 %253 to i32
  %255 = add i32 %42, %254
  %256 = getelementptr inbounds float, float* %35, i64 %253
  %257 = bitcast float* %256 to <16 x float>*
  %258 = load <16 x float>, <16 x float>* %257, align 64, !tbaa !442
  %259 = fadd <16 x float> %50, %258
  %260 = fadd <16 x float> %47, %259
  %261 = fcmp ogt <16 x float> %260, zeroinitializer
  %262 = select <16 x i1> %261, <16 x float> %260, <16 x float> zeroinitializer
  %263 = sext i32 %255 to i64
  %264 = getelementptr inbounds float, float* %10, i64 %263
  %265 = bitcast float* %264 to <16 x float>*
  store <16 x float> %262, <16 x float>* %265, align 64, !tbaa !451
  %266 = add nuw nsw i64 %201, 80
  %267 = trunc i64 %266 to i32
  %268 = add i32 %42, %267
  %269 = getelementptr inbounds float, float* %35, i64 %266
  %270 = bitcast float* %269 to <16 x float>*
  %271 = load <16 x float>, <16 x float>* %270, align 64, !tbaa !442
  %272 = fadd <16 x float> %50, %271
  %273 = fadd <16 x float> %47, %272
  %274 = fcmp ogt <16 x float> %273, zeroinitializer
  %275 = select <16 x i1> %274, <16 x float> %273, <16 x float> zeroinitializer
  %276 = sext i32 %268 to i64
  %277 = getelementptr inbounds float, float* %10, i64 %276
  %278 = bitcast float* %277 to <16 x float>*
  store <16 x float> %275, <16 x float>* %278, align 64, !tbaa !451
  %279 = add nuw nsw i64 %201, 96
  %280 = trunc i64 %279 to i32
  %281 = add i32 %42, %280
  %282 = getelementptr inbounds float, float* %35, i64 %279
  %283 = bitcast float* %282 to <16 x float>*
  %284 = load <16 x float>, <16 x float>* %283, align 64, !tbaa !442
  %285 = fadd <16 x float> %50, %284
  %286 = fadd <16 x float> %47, %285
  %287 = fcmp ogt <16 x float> %286, zeroinitializer
  %288 = select <16 x i1> %287, <16 x float> %286, <16 x float> zeroinitializer
  %289 = sext i32 %281 to i64
  %290 = getelementptr inbounds float, float* %10, i64 %289
  %291 = bitcast float* %290 to <16 x float>*
  store <16 x float> %288, <16 x float>* %291, align 64, !tbaa !451
  %292 = add nuw nsw i64 %201, 112
  %293 = trunc i64 %292 to i32
  %294 = add i32 %42, %293
  %295 = getelementptr inbounds float, float* %35, i64 %292
  %296 = bitcast float* %295 to <16 x float>*
  %297 = load <16 x float>, <16 x float>* %296, align 64, !tbaa !442
  %298 = fadd <16 x float> %50, %297
  %299 = fadd <16 x float> %47, %298
  %300 = fcmp ogt <16 x float> %299, zeroinitializer
  %301 = select <16 x i1> %300, <16 x float> %299, <16 x float> zeroinitializer
  %302 = sext i32 %294 to i64
  %303 = getelementptr inbounds float, float* %10, i64 %302
  %304 = bitcast float* %303 to <16 x float>*
  store <16 x float> %301, <16 x float>* %304, align 64, !tbaa !451
  %305 = add nuw nsw i64 %201, 128
  %306 = trunc i64 %305 to i32
  %307 = add i32 %42, %306
  %308 = getelementptr inbounds float, float* %35, i64 %305
  %309 = bitcast float* %308 to <16 x float>*
  %310 = load <16 x float>, <16 x float>* %309, align 64, !tbaa !442
  %311 = fadd <16 x float> %50, %310
  %312 = fadd <16 x float> %47, %311
  %313 = fcmp ogt <16 x float> %312, zeroinitializer
  %314 = select <16 x i1> %313, <16 x float> %312, <16 x float> zeroinitializer
  %315 = sext i32 %307 to i64
  %316 = getelementptr inbounds float, float* %10, i64 %315
  %317 = bitcast float* %316 to <16 x float>*
  store <16 x float> %314, <16 x float>* %317, align 64, !tbaa !451
  %318 = add nuw nsw i64 %201, 144
  %319 = trunc i64 %318 to i32
  %320 = add i32 %42, %319
  %321 = getelementptr inbounds float, float* %35, i64 %318
  %322 = bitcast float* %321 to <16 x float>*
  %323 = load <16 x float>, <16 x float>* %322, align 64, !tbaa !442
  %324 = fadd <16 x float> %50, %323
  %325 = fadd <16 x float> %47, %324
  %326 = fcmp ogt <16 x float> %325, zeroinitializer
  %327 = select <16 x i1> %326, <16 x float> %325, <16 x float> zeroinitializer
  %328 = sext i32 %320 to i64
  %329 = getelementptr inbounds float, float* %10, i64 %328
  %330 = bitcast float* %329 to <16 x float>*
  store <16 x float> %327, <16 x float>* %330, align 64, !tbaa !451
  %331 = add nuw nsw i64 %201, 160
  %332 = trunc i64 %331 to i32
  %333 = add i32 %42, %332
  %334 = getelementptr inbounds float, float* %35, i64 %331
  %335 = bitcast float* %334 to <16 x float>*
  %336 = load <16 x float>, <16 x float>* %335, align 64, !tbaa !442
  %337 = fadd <16 x float> %50, %336
  %338 = fadd <16 x float> %47, %337
  %339 = fcmp ogt <16 x float> %338, zeroinitializer
  %340 = select <16 x i1> %339, <16 x float> %338, <16 x float> zeroinitializer
  %341 = sext i32 %333 to i64
  %342 = getelementptr inbounds float, float* %10, i64 %341
  %343 = bitcast float* %342 to <16 x float>*
  store <16 x float> %340, <16 x float>* %343, align 64, !tbaa !451
  %344 = add nuw nsw i64 %201, 176
  %345 = trunc i64 %344 to i32
  %346 = add i32 %42, %345
  %347 = getelementptr inbounds float, float* %35, i64 %344
  %348 = bitcast float* %347 to <16 x float>*
  %349 = load <16 x float>, <16 x float>* %348, align 64, !tbaa !442
  %350 = fadd <16 x float> %50, %349
  %351 = fadd <16 x float> %47, %350
  %352 = fcmp ogt <16 x float> %351, zeroinitializer
  %353 = select <16 x i1> %352, <16 x float> %351, <16 x float> zeroinitializer
  %354 = sext i32 %346 to i64
  %355 = getelementptr inbounds float, float* %10, i64 %354
  %356 = bitcast float* %355 to <16 x float>*
  store <16 x float> %353, <16 x float>* %356, align 64, !tbaa !451
  %357 = add nuw nsw i64 %201, 192
  %358 = trunc i64 %357 to i32
  %359 = add i32 %42, %358
  %360 = getelementptr inbounds float, float* %35, i64 %357
  %361 = bitcast float* %360 to <16 x float>*
  %362 = load <16 x float>, <16 x float>* %361, align 64, !tbaa !442
  %363 = fadd <16 x float> %50, %362
  %364 = fadd <16 x float> %47, %363
  %365 = fcmp ogt <16 x float> %364, zeroinitializer
  %366 = select <16 x i1> %365, <16 x float> %364, <16 x float> zeroinitializer
  %367 = sext i32 %359 to i64
  %368 = getelementptr inbounds float, float* %10, i64 %367
  %369 = bitcast float* %368 to <16 x float>*
  store <16 x float> %366, <16 x float>* %369, align 64, !tbaa !451
  %370 = add nuw nsw i64 %201, 208
  %371 = trunc i64 %370 to i32
  %372 = add i32 %42, %371
  %373 = getelementptr inbounds float, float* %35, i64 %370
  %374 = bitcast float* %373 to <16 x float>*
  %375 = load <16 x float>, <16 x float>* %374, align 64, !tbaa !442
  %376 = fadd <16 x float> %50, %375
  %377 = fadd <16 x float> %47, %376
  %378 = fcmp ogt <16 x float> %377, zeroinitializer
  %379 = select <16 x i1> %378, <16 x float> %377, <16 x float> zeroinitializer
  %380 = sext i32 %372 to i64
  %381 = getelementptr inbounds float, float* %10, i64 %380
  %382 = bitcast float* %381 to <16 x float>*
  store <16 x float> %379, <16 x float>* %382, align 64, !tbaa !451
  %indvars.iv.next97 = add nuw nsw i64 %indvars.iv96, 1
  %exitcond98 = icmp eq i64 %indvars.iv.next97, 4
  br i1 %exitcond98, label %for_end12, label %for_begin13.preheader, !prof !50

for_end12:                                        ; preds = %for_begin13.preheader
  %383 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %384 = tail call i32 %383(i32 1, i32 %19, i8* nonnull %34)
  %385 = add nsw i32 %32, 1
  %386 = icmp slt i32 %385, %27
  br i1 %386, label %for_body, label %for_end, !prof !5
}

; Function Attrs: nounwind readnone speculatable
declare <16 x float> @llvm.fmuladd.v16f32(<16 x float>, <16 x float>, <16 x float>) #2

define dllexport i32 @fused_layout_transform_46(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.88, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !454
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.89, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !468
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.90, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !470
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !484
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 4
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !486
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 56
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !489
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 56
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !491
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 16
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.46, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !495
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 200704, i32 50176, i32 896, i32 16>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !507
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !511
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !525
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !527
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 56
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !530
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 56
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !532
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 64
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !536
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 200704, i32 200704, i32 3584, i32 64>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !548
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.94, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_46_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_46_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %7, align 8
  %3 = getelementptr inbounds %7, %7* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %7, %7* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %7* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.95, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.95(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 6
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 4
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 15
  %35 = lshr i32 %33, 4
  %36 = mul nsw i32 %35, 50176
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !552
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !555
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 56
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([101 x i8], [101 x i8]* @.str.96, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !558
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !572
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !575
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !577
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !581
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.98, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.99, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.101, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !583
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !597
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 1
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !599
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 56
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !602
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 56
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !604
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 256
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !608
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 802816, i32 802816, i32 14336, i32 256>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !620
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([243 x i8], [243 x i8]* @.str.104, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !624
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 2
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.105, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !638
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !640
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !643
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !645
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 256
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !649
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 32
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !651
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 8192, i32 8192, i32 8192, i32 8192>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !663
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 32
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !667
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([275 x i8], [275 x i8]* @.str.108, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !669
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 2
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.109, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !683
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !685
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !688
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 32
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !690
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !702
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 2
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.112, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !716
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !718
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !721
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 32
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !723
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !735
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !749
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 2
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.115, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !751
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 56
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.80, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !754
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 56
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.81, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !756
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 32
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !760
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 200704, i32 100352, i32 1792, i32 32>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !772
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.117, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_10_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %8, align 8
  %7 = getelementptr inbounds %8, %8* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %8, %8* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %8, %8* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %8, %8* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %8, %8* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %8, %8* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %8* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.118, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.118(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 111
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 112
  %30 = select i1 %29, i32 %28, i32 112
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body, label %for_end, !prof !5

for_body:                                         ; preds = %entry, %for_end9
  %32 = phi i32 [ %221, %for_end9 ], [ %30, %entry ]
  %33 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %34 = tail call i8* %33(i32 1, i32 %19, i64 7168, i32 2, i32 32)
  %35 = bitcast i8* %34 to float*
  %36 = srem i32 %32, 56
  %37 = mul nsw i32 %36, 14336
  %38 = sdiv i32 %32, 56
  %39 = shl i32 %38, 13
  %40 = sext i32 %39 to i64
  %41 = sext i32 %37 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end9, %entry
  ret i32 0

for_begin7.preheader:                             ; preds = %for_end6
  %42 = mul nsw i32 %32, 1792
  %43 = shl nsw i32 %38, 5
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds float, float* %16, i64 %44
  %46 = bitcast float* %45 to <32 x float>*
  %47 = load <32 x float>, <32 x float>* %46, align 64, !tbaa !776
  %48 = getelementptr inbounds float, float* %13, i64 %44
  %49 = bitcast float* %48 to <32 x float>*
  %50 = load <32 x float>, <32 x float>* %49, align 64, !tbaa !779
  br label %for_begin10.preheader

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv36 = phi i64 [ 0, %for_body ], [ %indvars.iv.next37, %for_end6 ]
  %51 = mul nuw nsw i64 %indvars.iv36, 224
  %52 = getelementptr inbounds float, float* %35, i64 %51
  %53 = bitcast float* %52 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %53, align 64, !tbaa !782
  %54 = add nuw nsw i64 %51, 32
  %55 = getelementptr inbounds float, float* %35, i64 %54
  %56 = bitcast float* %55 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %56, align 64, !tbaa !782
  %57 = add nuw nsw i64 %51, 64
  %58 = getelementptr inbounds float, float* %35, i64 %57
  %59 = bitcast float* %58 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %59, align 64, !tbaa !782
  %60 = add nuw nsw i64 %51, 96
  %61 = getelementptr inbounds float, float* %35, i64 %60
  %62 = bitcast float* %61 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %62, align 64, !tbaa !782
  %63 = add nuw nsw i64 %51, 128
  %64 = getelementptr inbounds float, float* %35, i64 %63
  %65 = bitcast float* %64 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %65, align 64, !tbaa !782
  %66 = add nuw nsw i64 %51, 160
  %67 = getelementptr inbounds float, float* %35, i64 %66
  %68 = bitcast float* %67 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %68, align 64, !tbaa !782
  %69 = add nuw nsw i64 %51, 192
  %70 = getelementptr inbounds float, float* %35, i64 %69
  %71 = bitcast float* %70 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %71, align 64, !tbaa !782
  %72 = mul nuw nsw i64 %indvars.iv36, 1792
  %73 = add nsw i64 %72, %41
  br label %for_body5

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %74 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %127, %for_body5 ]
  %75 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %121, %for_body5 ]
  %76 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %115, %for_body5 ]
  %77 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %109, %for_body5 ]
  %78 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %103, %for_body5 ]
  %79 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %97, %for_body5 ]
  %80 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %91, %for_body5 ]
  %81 = add nsw i64 %73, %indvars.iv
  %82 = getelementptr inbounds float, float* %4, i64 %81
  %83 = load float, float* %82, align 4, !tbaa !785
  %84 = insertelement <32 x float> undef, float %83, i32 0
  %85 = shufflevector <32 x float> %84, <32 x float> undef, <32 x i32> zeroinitializer
  %86 = shl i64 %indvars.iv, 5
  %87 = add nuw nsw i64 %86, %40
  %88 = getelementptr inbounds float, float* %7, i64 %87
  %89 = bitcast float* %88 to <32 x float>*
  %90 = load <32 x float>, <32 x float>* %89, align 64, !tbaa !788
  %91 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %85, <32 x float> %90, <32 x float> %80)
  %92 = add nsw i64 %81, 256
  %93 = getelementptr inbounds float, float* %4, i64 %92
  %94 = load float, float* %93, align 4, !tbaa !785
  %95 = insertelement <32 x float> undef, float %94, i32 0
  %96 = shufflevector <32 x float> %95, <32 x float> undef, <32 x i32> zeroinitializer
  %97 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %96, <32 x float> %90, <32 x float> %79)
  %98 = add nsw i64 %81, 512
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !785
  %101 = insertelement <32 x float> undef, float %100, i32 0
  %102 = shufflevector <32 x float> %101, <32 x float> undef, <32 x i32> zeroinitializer
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %102, <32 x float> %90, <32 x float> %78)
  %104 = add nsw i64 %81, 768
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !785
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %90, <32 x float> %77)
  %110 = add nsw i64 %81, 1024
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !785
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %90, <32 x float> %76)
  %116 = add nsw i64 %81, 1280
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !785
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %90, <32 x float> %75)
  %122 = add nsw i64 %81, 1536
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !785
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %90, <32 x float> %74)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  store <32 x float> %91, <32 x float>* %53, align 64, !tbaa !782
  store <32 x float> %97, <32 x float>* %56, align 64, !tbaa !782
  store <32 x float> %103, <32 x float>* %59, align 64, !tbaa !782
  store <32 x float> %109, <32 x float>* %62, align 64, !tbaa !782
  store <32 x float> %115, <32 x float>* %65, align 64, !tbaa !782
  store <32 x float> %121, <32 x float>* %68, align 64, !tbaa !782
  store <32 x float> %127, <32 x float>* %71, align 64, !tbaa !782
  %indvars.iv.next37 = add nuw nsw i64 %indvars.iv36, 1
  %exitcond38 = icmp eq i64 %indvars.iv.next37, 8
  br i1 %exitcond38, label %for_begin7.preheader, label %for_body2, !prof !50

for_begin10.preheader:                            ; preds = %for_begin10.preheader, %for_begin7.preheader
  %indvars.iv42 = phi i64 [ 0, %for_begin7.preheader ], [ %indvars.iv.next43, %for_begin10.preheader ]
  %128 = mul nuw nsw i64 %indvars.iv42, 224
  %129 = trunc i64 %128 to i32
  %130 = add i32 %42, %129
  %131 = getelementptr inbounds float, float* %35, i64 %128
  %132 = bitcast float* %131 to <32 x float>*
  %133 = load <32 x float>, <32 x float>* %132, align 64, !tbaa !782
  %134 = fadd <32 x float> %50, %133
  %135 = fadd <32 x float> %47, %134
  %136 = fcmp ogt <32 x float> %135, zeroinitializer
  %137 = select <32 x i1> %136, <32 x float> %135, <32 x float> zeroinitializer
  %138 = sext i32 %130 to i64
  %139 = getelementptr inbounds float, float* %10, i64 %138
  %140 = bitcast float* %139 to <32 x float>*
  store <32 x float> %137, <32 x float>* %140, align 64, !tbaa !791
  %141 = add nuw nsw i64 %128, 32
  %142 = trunc i64 %141 to i32
  %143 = add i32 %42, %142
  %144 = getelementptr inbounds float, float* %35, i64 %141
  %145 = bitcast float* %144 to <32 x float>*
  %146 = load <32 x float>, <32 x float>* %145, align 64, !tbaa !782
  %147 = fadd <32 x float> %50, %146
  %148 = fadd <32 x float> %47, %147
  %149 = fcmp ogt <32 x float> %148, zeroinitializer
  %150 = select <32 x i1> %149, <32 x float> %148, <32 x float> zeroinitializer
  %151 = sext i32 %143 to i64
  %152 = getelementptr inbounds float, float* %10, i64 %151
  %153 = bitcast float* %152 to <32 x float>*
  store <32 x float> %150, <32 x float>* %153, align 64, !tbaa !791
  %154 = add nuw nsw i64 %128, 64
  %155 = trunc i64 %154 to i32
  %156 = add i32 %42, %155
  %157 = getelementptr inbounds float, float* %35, i64 %154
  %158 = bitcast float* %157 to <32 x float>*
  %159 = load <32 x float>, <32 x float>* %158, align 64, !tbaa !782
  %160 = fadd <32 x float> %50, %159
  %161 = fadd <32 x float> %47, %160
  %162 = fcmp ogt <32 x float> %161, zeroinitializer
  %163 = select <32 x i1> %162, <32 x float> %161, <32 x float> zeroinitializer
  %164 = sext i32 %156 to i64
  %165 = getelementptr inbounds float, float* %10, i64 %164
  %166 = bitcast float* %165 to <32 x float>*
  store <32 x float> %163, <32 x float>* %166, align 64, !tbaa !791
  %167 = add nuw nsw i64 %128, 96
  %168 = trunc i64 %167 to i32
  %169 = add i32 %42, %168
  %170 = getelementptr inbounds float, float* %35, i64 %167
  %171 = bitcast float* %170 to <32 x float>*
  %172 = load <32 x float>, <32 x float>* %171, align 64, !tbaa !782
  %173 = fadd <32 x float> %50, %172
  %174 = fadd <32 x float> %47, %173
  %175 = fcmp ogt <32 x float> %174, zeroinitializer
  %176 = select <32 x i1> %175, <32 x float> %174, <32 x float> zeroinitializer
  %177 = sext i32 %169 to i64
  %178 = getelementptr inbounds float, float* %10, i64 %177
  %179 = bitcast float* %178 to <32 x float>*
  store <32 x float> %176, <32 x float>* %179, align 64, !tbaa !791
  %180 = add nuw nsw i64 %128, 128
  %181 = trunc i64 %180 to i32
  %182 = add i32 %42, %181
  %183 = getelementptr inbounds float, float* %35, i64 %180
  %184 = bitcast float* %183 to <32 x float>*
  %185 = load <32 x float>, <32 x float>* %184, align 64, !tbaa !782
  %186 = fadd <32 x float> %50, %185
  %187 = fadd <32 x float> %47, %186
  %188 = fcmp ogt <32 x float> %187, zeroinitializer
  %189 = select <32 x i1> %188, <32 x float> %187, <32 x float> zeroinitializer
  %190 = sext i32 %182 to i64
  %191 = getelementptr inbounds float, float* %10, i64 %190
  %192 = bitcast float* %191 to <32 x float>*
  store <32 x float> %189, <32 x float>* %192, align 64, !tbaa !791
  %193 = add nuw nsw i64 %128, 160
  %194 = trunc i64 %193 to i32
  %195 = add i32 %42, %194
  %196 = getelementptr inbounds float, float* %35, i64 %193
  %197 = bitcast float* %196 to <32 x float>*
  %198 = load <32 x float>, <32 x float>* %197, align 64, !tbaa !782
  %199 = fadd <32 x float> %50, %198
  %200 = fadd <32 x float> %47, %199
  %201 = fcmp ogt <32 x float> %200, zeroinitializer
  %202 = select <32 x i1> %201, <32 x float> %200, <32 x float> zeroinitializer
  %203 = sext i32 %195 to i64
  %204 = getelementptr inbounds float, float* %10, i64 %203
  %205 = bitcast float* %204 to <32 x float>*
  store <32 x float> %202, <32 x float>* %205, align 64, !tbaa !791
  %206 = add nuw nsw i64 %128, 192
  %207 = trunc i64 %206 to i32
  %208 = add i32 %42, %207
  %209 = getelementptr inbounds float, float* %35, i64 %206
  %210 = bitcast float* %209 to <32 x float>*
  %211 = load <32 x float>, <32 x float>* %210, align 64, !tbaa !782
  %212 = fadd <32 x float> %50, %211
  %213 = fadd <32 x float> %47, %212
  %214 = fcmp ogt <32 x float> %213, zeroinitializer
  %215 = select <32 x i1> %214, <32 x float> %213, <32 x float> zeroinitializer
  %216 = sext i32 %208 to i64
  %217 = getelementptr inbounds float, float* %10, i64 %216
  %218 = bitcast float* %217 to <32 x float>*
  store <32 x float> %215, <32 x float>* %218, align 64, !tbaa !791
  %indvars.iv.next43 = add nuw nsw i64 %indvars.iv42, 1
  %exitcond44 = icmp eq i64 %indvars.iv.next43, 8
  br i1 %exitcond44, label %for_end9, label %for_begin10.preheader, !prof !50

for_end9:                                         ; preds = %for_begin10.preheader
  %219 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %220 = tail call i32 %219(i32 1, i32 %19, i8* nonnull %34)
  %221 = add nsw i32 %32, 1
  %222 = icmp slt i32 %221, %27
  br i1 %222, label %for_body, label %for_end, !prof !5
}

; Function Attrs: nounwind readnone speculatable
declare <32 x float> @llvm.fmuladd.v32f32(<32 x float>, <32 x float>, <32 x float>) #2

define dllexport i32 @fused_layout_transform_45(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.119, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !794
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.120, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !808
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.121, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !810
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !824
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 2
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.122, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !826
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 56
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !829
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 56
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !831
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !835
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 200704, i32 100352, i32 1792, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !847
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.124, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !851
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !865
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !867
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 56
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !870
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 56
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !872
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 64
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !876
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 200704, i32 200704, i32 3584, i32 64>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !888
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.94, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_45_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_45_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %9, align 8
  %3 = getelementptr inbounds %9, %9* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %9, %9* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %9* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.125, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.125(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 6
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 100352
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !892
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !895
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 56
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.126, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !898
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !912
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !915
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !917
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.127, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !921
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.128, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.129, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.130, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.131, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !923
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !937
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 1
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !939
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 56
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !942
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 56
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !944
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 64
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !948
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 200704, i32 200704, i32 3584, i32 64>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !960
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.132, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !964
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 2
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.105, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !978
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !980
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 3
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.133, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !983
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 3
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.134, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !985
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 64
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !989
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 32
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !991
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 18432, i32 18432, i32 6144, i32 2048>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !1003
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 32
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !1007
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([277 x i8], [277 x i8]* @.str.135, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !1009
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 2
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.109, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !1023
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !1025
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !1028
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 32
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !1030
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !1042
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 2
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.112, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !1056
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !1058
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !1061
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 32
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !1063
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !1075
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !1089
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 2
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.115, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !1091
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 56
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.80, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !1094
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 56
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.81, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !1096
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 32
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !1100
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 200704, i32 100352, i32 1792, i32 32>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !1112
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.117, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_9_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 861184, i32 2, i32 32)
  %8 = alloca %10, align 8
  %9 = getelementptr inbounds %10, %10* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %10, %10* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %10* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.136, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %24, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %11, align 8
  %16 = getelementptr inbounds %11, %11* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %11, %11* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %11, %11* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %11, %11* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %11, %11* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = getelementptr inbounds %11, %11* %15, i64 0, i32 5
  store i32 %5, i32* %21, align 8
  %22 = bitcast %11* %15 to i8*
  %23 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %24 = call i32 %23(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.137, i8* nonnull %22, i32 0)
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %26 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %27 = call i32 %26(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.136(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 57
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 58
  %15 = select i1 %14, i32 %13, i32 58
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 58
  %18 = select i1 %17, i32 %16, i32 58
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = mul i32 %11, %0
  %21 = icmp slt i32 %20, 58
  %22 = select i1 %21, i32 %20, i32 58
  %smax = xor i32 %22, -1
  %23 = mul i32 %smax, -3584
  %24 = add i32 %23, -7680
  %25 = or i32 %24, 448
  %26 = zext i32 %25 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvar = phi i64 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %27 = phi i32 [ %18, %for_begin1.preheader.preheader ], [ %436, %for_end3 ]
  %28 = mul i64 %indvar, 3584
  %29 = add i64 %28, %26
  %30 = mul nsw i32 %27, 3712
  %.off = add i32 %27, -1
  %31 = icmp ult i32 %.off, 56
  %32 = mul nsw i32 %27, 3584
  br i1 %31, label %for_begin4.preheader.us, label %for_begin4.preheader

for_begin4.preheader.us:                          ; preds = %for_begin1.preheader, %for_end6.us
  %indvars.iv24 = phi i64 [ %indvars.iv.next25, %for_end6.us ], [ 0, %for_begin1.preheader ]
  %33 = shl nsw i64 %indvars.iv24, 6
  %34 = trunc i64 %indvars.iv24 to i32
  %35 = add i32 %34, -1
  %36 = icmp ult i32 %35, 56
  br i1 %36, label %vector.scevcheck, label %vector.body35

vector.body35:                                    ; preds = %for_begin4.preheader.us
  %37 = trunc i64 %33 to i32
  %38 = add i32 %30, %37
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %4, i64 %39
  %41 = bitcast float* %40 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %41, align 4, !tbaa !1116
  %42 = trunc i64 %33 to i32
  %43 = or i32 %42, 4
  %44 = add i32 %30, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %4, i64 %45
  %47 = bitcast float* %46 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %47, align 4, !tbaa !1116
  %48 = trunc i64 %33 to i32
  %49 = or i32 %48, 8
  %50 = add i32 %30, %49
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds float, float* %4, i64 %51
  %53 = bitcast float* %52 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %53, align 4, !tbaa !1116
  %54 = trunc i64 %33 to i32
  %55 = or i32 %54, 12
  %56 = add i32 %30, %55
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds float, float* %4, i64 %57
  %59 = bitcast float* %58 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %59, align 4, !tbaa !1116
  %60 = trunc i64 %33 to i32
  %61 = or i32 %60, 16
  %62 = add i32 %30, %61
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %4, i64 %63
  %65 = bitcast float* %64 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %65, align 4, !tbaa !1116
  %66 = trunc i64 %33 to i32
  %67 = or i32 %66, 20
  %68 = add i32 %30, %67
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %4, i64 %69
  %71 = bitcast float* %70 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %71, align 4, !tbaa !1116
  %72 = trunc i64 %33 to i32
  %73 = or i32 %72, 24
  %74 = add i32 %30, %73
  %75 = sext i32 %74 to i64
  %76 = getelementptr inbounds float, float* %4, i64 %75
  %77 = bitcast float* %76 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %77, align 4, !tbaa !1116
  %78 = trunc i64 %33 to i32
  %79 = or i32 %78, 28
  %80 = add i32 %30, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %4, i64 %81
  %83 = bitcast float* %82 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %83, align 4, !tbaa !1116
  %84 = trunc i64 %33 to i32
  %85 = or i32 %84, 32
  %86 = add i32 %30, %85
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds float, float* %4, i64 %87
  %89 = bitcast float* %88 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %89, align 4, !tbaa !1116
  %90 = trunc i64 %33 to i32
  %91 = or i32 %90, 36
  %92 = add i32 %30, %91
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %4, i64 %93
  %95 = bitcast float* %94 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %95, align 4, !tbaa !1116
  %96 = trunc i64 %33 to i32
  %97 = or i32 %96, 40
  %98 = add i32 %30, %97
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds float, float* %4, i64 %99
  %101 = bitcast float* %100 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %101, align 4, !tbaa !1116
  %102 = trunc i64 %33 to i32
  %103 = or i32 %102, 44
  %104 = add i32 %30, %103
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds float, float* %4, i64 %105
  %107 = bitcast float* %106 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %107, align 4, !tbaa !1116
  %108 = trunc i64 %33 to i32
  %109 = or i32 %108, 48
  %110 = add i32 %30, %109
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %4, i64 %111
  %113 = bitcast float* %112 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %113, align 4, !tbaa !1116
  %114 = trunc i64 %33 to i32
  %115 = or i32 %114, 52
  %116 = add i32 %30, %115
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %4, i64 %117
  %119 = bitcast float* %118 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %119, align 4, !tbaa !1116
  %120 = trunc i64 %33 to i32
  %121 = or i32 %120, 56
  %122 = add i32 %30, %121
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds float, float* %4, i64 %123
  %125 = bitcast float* %124 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %125, align 4, !tbaa !1116
  %126 = trunc i64 %33 to i32
  %127 = or i32 %126, 60
  %128 = add i32 %30, %127
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds float, float* %4, i64 %129
  %131 = bitcast float* %130 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %131, align 4, !tbaa !1116
  br label %for_end6.us

vector.scevcheck:                                 ; preds = %for_begin4.preheader.us
  %132 = shl i64 %indvars.iv24, 6
  %133 = add i64 %29, %132
  %134 = trunc i64 %133 to i32
  %135 = icmp sgt i32 %134, 2147483584
  br i1 %135, label %for_body5.us.us, label %vector.body

vector.body:                                      ; preds = %vector.scevcheck
  %136 = trunc i64 %33 to i32
  %137 = add i32 %30, %136
  %138 = trunc i64 %33 to i32
  %139 = add i32 %138, -3648
  %140 = add i32 %139, %32
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %143, align 4, !tbaa !1119
  %144 = sext i32 %137 to i64
  %145 = getelementptr inbounds float, float* %4, i64 %144
  %146 = bitcast float* %145 to <4 x i32>*
  store <4 x i32> %wide.load, <4 x i32>* %146, align 4, !tbaa !1116
  %147 = or i64 %33, 4
  %148 = trunc i64 %147 to i32
  %149 = add i32 %30, %148
  %150 = trunc i64 %147 to i32
  %151 = add i32 %150, -3648
  %152 = add i32 %151, %32
  %153 = sext i32 %152 to i64
  %154 = getelementptr inbounds float, float* %7, i64 %153
  %155 = bitcast float* %154 to <4 x i32>*
  %wide.load.1 = load <4 x i32>, <4 x i32>* %155, align 4, !tbaa !1119
  %156 = sext i32 %149 to i64
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = bitcast float* %157 to <4 x i32>*
  store <4 x i32> %wide.load.1, <4 x i32>* %158, align 4, !tbaa !1116
  %159 = or i64 %33, 8
  %160 = trunc i64 %159 to i32
  %161 = add i32 %30, %160
  %162 = trunc i64 %159 to i32
  %163 = add i32 %162, -3648
  %164 = add i32 %163, %32
  %165 = sext i32 %164 to i64
  %166 = getelementptr inbounds float, float* %7, i64 %165
  %167 = bitcast float* %166 to <4 x i32>*
  %wide.load.2 = load <4 x i32>, <4 x i32>* %167, align 4, !tbaa !1119
  %168 = sext i32 %161 to i64
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = bitcast float* %169 to <4 x i32>*
  store <4 x i32> %wide.load.2, <4 x i32>* %170, align 4, !tbaa !1116
  %171 = or i64 %33, 12
  %172 = trunc i64 %171 to i32
  %173 = add i32 %30, %172
  %174 = trunc i64 %171 to i32
  %175 = add i32 %174, -3648
  %176 = add i32 %175, %32
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds float, float* %7, i64 %177
  %179 = bitcast float* %178 to <4 x i32>*
  %wide.load.3 = load <4 x i32>, <4 x i32>* %179, align 4, !tbaa !1119
  %180 = sext i32 %173 to i64
  %181 = getelementptr inbounds float, float* %4, i64 %180
  %182 = bitcast float* %181 to <4 x i32>*
  store <4 x i32> %wide.load.3, <4 x i32>* %182, align 4, !tbaa !1116
  %183 = or i64 %33, 16
  %184 = trunc i64 %183 to i32
  %185 = add i32 %30, %184
  %186 = trunc i64 %183 to i32
  %187 = add i32 %186, -3648
  %188 = add i32 %187, %32
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to <4 x i32>*
  %wide.load.4 = load <4 x i32>, <4 x i32>* %191, align 4, !tbaa !1119
  %192 = sext i32 %185 to i64
  %193 = getelementptr inbounds float, float* %4, i64 %192
  %194 = bitcast float* %193 to <4 x i32>*
  store <4 x i32> %wide.load.4, <4 x i32>* %194, align 4, !tbaa !1116
  %195 = or i64 %33, 20
  %196 = trunc i64 %195 to i32
  %197 = add i32 %30, %196
  %198 = trunc i64 %195 to i32
  %199 = add i32 %198, -3648
  %200 = add i32 %199, %32
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds float, float* %7, i64 %201
  %203 = bitcast float* %202 to <4 x i32>*
  %wide.load.5 = load <4 x i32>, <4 x i32>* %203, align 4, !tbaa !1119
  %204 = sext i32 %197 to i64
  %205 = getelementptr inbounds float, float* %4, i64 %204
  %206 = bitcast float* %205 to <4 x i32>*
  store <4 x i32> %wide.load.5, <4 x i32>* %206, align 4, !tbaa !1116
  %207 = or i64 %33, 24
  %208 = trunc i64 %207 to i32
  %209 = add i32 %30, %208
  %210 = trunc i64 %207 to i32
  %211 = add i32 %210, -3648
  %212 = add i32 %211, %32
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %7, i64 %213
  %215 = bitcast float* %214 to <4 x i32>*
  %wide.load.6 = load <4 x i32>, <4 x i32>* %215, align 4, !tbaa !1119
  %216 = sext i32 %209 to i64
  %217 = getelementptr inbounds float, float* %4, i64 %216
  %218 = bitcast float* %217 to <4 x i32>*
  store <4 x i32> %wide.load.6, <4 x i32>* %218, align 4, !tbaa !1116
  %219 = or i64 %33, 28
  %220 = trunc i64 %219 to i32
  %221 = add i32 %30, %220
  %222 = trunc i64 %219 to i32
  %223 = add i32 %222, -3648
  %224 = add i32 %223, %32
  %225 = sext i32 %224 to i64
  %226 = getelementptr inbounds float, float* %7, i64 %225
  %227 = bitcast float* %226 to <4 x i32>*
  %wide.load.7 = load <4 x i32>, <4 x i32>* %227, align 4, !tbaa !1119
  %228 = sext i32 %221 to i64
  %229 = getelementptr inbounds float, float* %4, i64 %228
  %230 = bitcast float* %229 to <4 x i32>*
  store <4 x i32> %wide.load.7, <4 x i32>* %230, align 4, !tbaa !1116
  %231 = or i64 %33, 32
  %232 = trunc i64 %231 to i32
  %233 = add i32 %30, %232
  %234 = trunc i64 %231 to i32
  %235 = add i32 %234, -3648
  %236 = add i32 %235, %32
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds float, float* %7, i64 %237
  %239 = bitcast float* %238 to <4 x i32>*
  %wide.load.8 = load <4 x i32>, <4 x i32>* %239, align 4, !tbaa !1119
  %240 = sext i32 %233 to i64
  %241 = getelementptr inbounds float, float* %4, i64 %240
  %242 = bitcast float* %241 to <4 x i32>*
  store <4 x i32> %wide.load.8, <4 x i32>* %242, align 4, !tbaa !1116
  %243 = or i64 %33, 36
  %244 = trunc i64 %243 to i32
  %245 = add i32 %30, %244
  %246 = trunc i64 %243 to i32
  %247 = add i32 %246, -3648
  %248 = add i32 %247, %32
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds float, float* %7, i64 %249
  %251 = bitcast float* %250 to <4 x i32>*
  %wide.load.9 = load <4 x i32>, <4 x i32>* %251, align 4, !tbaa !1119
  %252 = sext i32 %245 to i64
  %253 = getelementptr inbounds float, float* %4, i64 %252
  %254 = bitcast float* %253 to <4 x i32>*
  store <4 x i32> %wide.load.9, <4 x i32>* %254, align 4, !tbaa !1116
  %255 = or i64 %33, 40
  %256 = trunc i64 %255 to i32
  %257 = add i32 %30, %256
  %258 = trunc i64 %255 to i32
  %259 = add i32 %258, -3648
  %260 = add i32 %259, %32
  %261 = sext i32 %260 to i64
  %262 = getelementptr inbounds float, float* %7, i64 %261
  %263 = bitcast float* %262 to <4 x i32>*
  %wide.load.10 = load <4 x i32>, <4 x i32>* %263, align 4, !tbaa !1119
  %264 = sext i32 %257 to i64
  %265 = getelementptr inbounds float, float* %4, i64 %264
  %266 = bitcast float* %265 to <4 x i32>*
  store <4 x i32> %wide.load.10, <4 x i32>* %266, align 4, !tbaa !1116
  %267 = or i64 %33, 44
  %268 = trunc i64 %267 to i32
  %269 = add i32 %30, %268
  %270 = trunc i64 %267 to i32
  %271 = add i32 %270, -3648
  %272 = add i32 %271, %32
  %273 = sext i32 %272 to i64
  %274 = getelementptr inbounds float, float* %7, i64 %273
  %275 = bitcast float* %274 to <4 x i32>*
  %wide.load.11 = load <4 x i32>, <4 x i32>* %275, align 4, !tbaa !1119
  %276 = sext i32 %269 to i64
  %277 = getelementptr inbounds float, float* %4, i64 %276
  %278 = bitcast float* %277 to <4 x i32>*
  store <4 x i32> %wide.load.11, <4 x i32>* %278, align 4, !tbaa !1116
  %279 = or i64 %33, 48
  %280 = trunc i64 %279 to i32
  %281 = add i32 %30, %280
  %282 = trunc i64 %279 to i32
  %283 = add i32 %282, -3648
  %284 = add i32 %283, %32
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds float, float* %7, i64 %285
  %287 = bitcast float* %286 to <4 x i32>*
  %wide.load.12 = load <4 x i32>, <4 x i32>* %287, align 4, !tbaa !1119
  %288 = sext i32 %281 to i64
  %289 = getelementptr inbounds float, float* %4, i64 %288
  %290 = bitcast float* %289 to <4 x i32>*
  store <4 x i32> %wide.load.12, <4 x i32>* %290, align 4, !tbaa !1116
  %291 = or i64 %33, 52
  %292 = trunc i64 %291 to i32
  %293 = add i32 %30, %292
  %294 = trunc i64 %291 to i32
  %295 = add i32 %294, -3648
  %296 = add i32 %295, %32
  %297 = sext i32 %296 to i64
  %298 = getelementptr inbounds float, float* %7, i64 %297
  %299 = bitcast float* %298 to <4 x i32>*
  %wide.load.13 = load <4 x i32>, <4 x i32>* %299, align 4, !tbaa !1119
  %300 = sext i32 %293 to i64
  %301 = getelementptr inbounds float, float* %4, i64 %300
  %302 = bitcast float* %301 to <4 x i32>*
  store <4 x i32> %wide.load.13, <4 x i32>* %302, align 4, !tbaa !1116
  %303 = or i64 %33, 56
  %304 = trunc i64 %303 to i32
  %305 = add i32 %30, %304
  %306 = trunc i64 %303 to i32
  %307 = add i32 %306, -3648
  %308 = add i32 %307, %32
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds float, float* %7, i64 %309
  %311 = bitcast float* %310 to <4 x i32>*
  %wide.load.14 = load <4 x i32>, <4 x i32>* %311, align 4, !tbaa !1119
  %312 = sext i32 %305 to i64
  %313 = getelementptr inbounds float, float* %4, i64 %312
  %314 = bitcast float* %313 to <4 x i32>*
  store <4 x i32> %wide.load.14, <4 x i32>* %314, align 4, !tbaa !1116
  %315 = or i64 %33, 60
  %316 = trunc i64 %315 to i32
  %317 = add i32 %30, %316
  %318 = trunc i64 %315 to i32
  %319 = add i32 %318, -3648
  %320 = add i32 %319, %32
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds float, float* %7, i64 %321
  %323 = bitcast float* %322 to <4 x i32>*
  %wide.load.15 = load <4 x i32>, <4 x i32>* %323, align 4, !tbaa !1119
  %324 = sext i32 %317 to i64
  %325 = getelementptr inbounds float, float* %4, i64 %324
  %326 = bitcast float* %325 to <4 x i32>*
  store <4 x i32> %wide.load.15, <4 x i32>* %326, align 4, !tbaa !1116
  br label %for_end6.us

for_end6.us:                                      ; preds = %for_body5.us.us, %vector.body35, %vector.body
  %indvars.iv.next25 = add nuw nsw i64 %indvars.iv24, 1
  %exitcond27 = icmp eq i64 %indvars.iv.next25, 58
  br i1 %exitcond27, label %for_end3, label %for_begin4.preheader.us, !prof !50

for_body5.us.us:                                  ; preds = %vector.scevcheck, %for_body5.us.us
  %indvars.iv21 = phi i64 [ %indvars.iv.next22, %for_body5.us.us ], [ 0, %vector.scevcheck ]
  %327 = add nuw nsw i64 %indvars.iv21, %33
  %328 = trunc i64 %327 to i32
  %329 = add i32 %30, %328
  %330 = trunc i64 %327 to i32
  %331 = add i32 %330, -3648
  %332 = add i32 %331, %32
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds float, float* %7, i64 %333
  %335 = bitcast float* %334 to i32*
  %336 = load i32, i32* %335, align 4, !tbaa !1119
  %337 = sext i32 %329 to i64
  %338 = getelementptr inbounds float, float* %4, i64 %337
  %339 = bitcast float* %338 to i32*
  store i32 %336, i32* %339, align 4, !tbaa !1116
  %indvars.iv.next22 = add nuw nsw i64 %indvars.iv21, 1
  %exitcond23 = icmp eq i64 %indvars.iv.next22, 64
  br i1 %exitcond23, label %for_end6.us, label %for_body5.us.us, !prof !50, !llvm.loop !1122

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_begin1.preheader, %for_begin4.preheader
  %indvars.iv15 = phi i64 [ %indvars.iv.next16, %for_begin4.preheader ], [ 0, %for_begin1.preheader ]
  %340 = shl nsw i64 %indvars.iv15, 6
  %341 = trunc i64 %340 to i32
  %342 = add i32 %30, %341
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds float, float* %4, i64 %343
  %345 = bitcast float* %344 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %345, align 4, !tbaa !1116
  %346 = trunc i64 %340 to i32
  %347 = or i32 %346, 4
  %348 = add i32 %30, %347
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds float, float* %4, i64 %349
  %351 = bitcast float* %350 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %351, align 4, !tbaa !1116
  %352 = trunc i64 %340 to i32
  %353 = or i32 %352, 8
  %354 = add i32 %30, %353
  %355 = sext i32 %354 to i64
  %356 = getelementptr inbounds float, float* %4, i64 %355
  %357 = bitcast float* %356 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %357, align 4, !tbaa !1116
  %358 = trunc i64 %340 to i32
  %359 = or i32 %358, 12
  %360 = add i32 %30, %359
  %361 = sext i32 %360 to i64
  %362 = getelementptr inbounds float, float* %4, i64 %361
  %363 = bitcast float* %362 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %363, align 4, !tbaa !1116
  %364 = trunc i64 %340 to i32
  %365 = or i32 %364, 16
  %366 = add i32 %30, %365
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds float, float* %4, i64 %367
  %369 = bitcast float* %368 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %369, align 4, !tbaa !1116
  %370 = trunc i64 %340 to i32
  %371 = or i32 %370, 20
  %372 = add i32 %30, %371
  %373 = sext i32 %372 to i64
  %374 = getelementptr inbounds float, float* %4, i64 %373
  %375 = bitcast float* %374 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %375, align 4, !tbaa !1116
  %376 = trunc i64 %340 to i32
  %377 = or i32 %376, 24
  %378 = add i32 %30, %377
  %379 = sext i32 %378 to i64
  %380 = getelementptr inbounds float, float* %4, i64 %379
  %381 = bitcast float* %380 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %381, align 4, !tbaa !1116
  %382 = trunc i64 %340 to i32
  %383 = or i32 %382, 28
  %384 = add i32 %30, %383
  %385 = sext i32 %384 to i64
  %386 = getelementptr inbounds float, float* %4, i64 %385
  %387 = bitcast float* %386 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %387, align 4, !tbaa !1116
  %388 = trunc i64 %340 to i32
  %389 = or i32 %388, 32
  %390 = add i32 %30, %389
  %391 = sext i32 %390 to i64
  %392 = getelementptr inbounds float, float* %4, i64 %391
  %393 = bitcast float* %392 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %393, align 4, !tbaa !1116
  %394 = trunc i64 %340 to i32
  %395 = or i32 %394, 36
  %396 = add i32 %30, %395
  %397 = sext i32 %396 to i64
  %398 = getelementptr inbounds float, float* %4, i64 %397
  %399 = bitcast float* %398 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %399, align 4, !tbaa !1116
  %400 = trunc i64 %340 to i32
  %401 = or i32 %400, 40
  %402 = add i32 %30, %401
  %403 = sext i32 %402 to i64
  %404 = getelementptr inbounds float, float* %4, i64 %403
  %405 = bitcast float* %404 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %405, align 4, !tbaa !1116
  %406 = trunc i64 %340 to i32
  %407 = or i32 %406, 44
  %408 = add i32 %30, %407
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds float, float* %4, i64 %409
  %411 = bitcast float* %410 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %411, align 4, !tbaa !1116
  %412 = trunc i64 %340 to i32
  %413 = or i32 %412, 48
  %414 = add i32 %30, %413
  %415 = sext i32 %414 to i64
  %416 = getelementptr inbounds float, float* %4, i64 %415
  %417 = bitcast float* %416 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %417, align 4, !tbaa !1116
  %418 = trunc i64 %340 to i32
  %419 = or i32 %418, 52
  %420 = add i32 %30, %419
  %421 = sext i32 %420 to i64
  %422 = getelementptr inbounds float, float* %4, i64 %421
  %423 = bitcast float* %422 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %423, align 4, !tbaa !1116
  %424 = trunc i64 %340 to i32
  %425 = or i32 %424, 56
  %426 = add i32 %30, %425
  %427 = sext i32 %426 to i64
  %428 = getelementptr inbounds float, float* %4, i64 %427
  %429 = bitcast float* %428 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %429, align 4, !tbaa !1116
  %430 = trunc i64 %340 to i32
  %431 = or i32 %430, 60
  %432 = add i32 %30, %431
  %433 = sext i32 %432 to i64
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = bitcast float* %434 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %435, align 4, !tbaa !1116
  %indvars.iv.next16 = add nuw nsw i64 %indvars.iv15, 1
  %exitcond17 = icmp eq i64 %indvars.iv.next16, 58
  br i1 %exitcond17, label %for_end3, label %for_begin4.preheader, !prof !50

for_end3:                                         ; preds = %for_begin4.preheader, %for_end6.us
  %436 = add nsw i32 %27, 1
  %437 = icmp slt i32 %436, %15
  %indvar.next = add i64 %indvar, 1
  br i1 %437, label %for_begin1.preheader, label %for_end, !prof !5
}

define private i32 @__tvm_parallel_lambda.137(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to float**
  %18 = load float*, float** %17, align 8
  %19 = getelementptr inbounds i8, i8* %2, i64 40
  %20 = bitcast i8* %19 to i32*
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, 111
  %25 = sdiv i32 %24, %23
  %26 = add nsw i32 %0, 1
  %27 = mul nsw i32 %25, %26
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = mul nsw i32 %25, %0
  %31 = icmp slt i32 %30, 112
  %32 = select i1 %31, i32 %30, i32 112
  %33 = icmp slt i32 %32, %29
  br i1 %33, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %34 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %35 = bitcast float* %34 to <32 x float>*
  %36 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %37 = bitcast float* %36 to <32 x float>*
  %38 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %39 = bitcast float* %38 to <32 x float>*
  %40 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %41 = bitcast float* %40 to <32 x float>*
  %42 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %43 = bitcast float* %42 to <32 x float>*
  %44 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %45 = bitcast float* %44 to <32 x float>*
  %46 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end15
  %47 = phi i32 [ %32, %for_body.lr.ph ], [ %257, %for_end15 ]
  %48 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %49 = tail call i8* %48(i32 1, i32 %21, i64 7168, i32 2, i32 32)
  %50 = srem i32 %47, 56
  %51 = sdiv i32 %47, 56
  %52 = mul nsw i32 %51, 18432
  %53 = sext i32 %52 to i64
  %54 = mul nsw i32 %50, 3712
  %55 = sext i32 %54 to i64
  %56 = mul nsw i32 %50, 3712
  %57 = add nsw i32 %56, 3712
  %58 = sext i32 %57 to i64
  %59 = add nsw i64 %53, 6144
  %60 = mul nsw i32 %50, 3712
  %61 = add nsw i32 %60, 7424
  %62 = sext i32 %61 to i64
  %63 = add nsw i64 %53, 12288
  br label %for_body2

for_end:                                          ; preds = %for_end15, %entry
  ret i32 0

for_begin13.preheader:                            ; preds = %for_end9.2
  %64 = mul nsw i32 %47, 1792
  %65 = shl nsw i32 %51, 5
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds float, float* %18, i64 %66
  %68 = bitcast float* %67 to <32 x float>*
  %69 = load <32 x float>, <32 x float>* %68, align 64, !tbaa !1124
  %70 = getelementptr inbounds float, float* %15, i64 %66
  %71 = bitcast float* %70 to <32 x float>*
  %72 = load <32 x float>, <32 x float>* %71, align 64, !tbaa !1127
  %73 = bitcast i8* %49 to float*
  br label %for_begin16.preheader

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %74 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %49, i64 %74
  %75 = mul nuw nsw i64 %indvar, 448
  %76 = add nsw i64 %75, %55
  call void @llvm.memset.p0i8.i64(i8* nonnull align 128 %46, i8 0, i64 896, i1 false)
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %77 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %162, %for_body8 ]
  %78 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %156, %for_body8 ]
  %79 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %155, %for_body8 ]
  %80 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %154, %for_body8 ]
  %81 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %153, %for_body8 ]
  %82 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %152, %for_body8 ]
  %83 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %151, %for_body8 ]
  %84 = add nsw i64 %76, %indvars.iv
  %85 = getelementptr inbounds float, float* %6, i64 %84
  %86 = load float, float* %85, align 4, !tbaa !1116
  %87 = insertelement <32 x float> undef, float %86, i32 0
  %88 = shufflevector <32 x float> %87, <32 x float> undef, <32 x i32> zeroinitializer
  %89 = shl nsw i64 %indvars.iv, 5
  %90 = add nsw i64 %89, %53
  %91 = getelementptr inbounds float, float* %9, i64 %90
  %92 = bitcast float* %91 to <32 x float>*
  %93 = load <32 x float>, <32 x float>* %92, align 64, !tbaa !1130
  %94 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %88, <32 x float> %93, <32 x float> %83)
  %95 = add nsw i64 %84, 64
  %96 = getelementptr inbounds float, float* %6, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !1116
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %93, <32 x float> %82)
  %101 = add nsw i64 %84, 128
  %102 = getelementptr inbounds float, float* %6, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !1116
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %93, <32 x float> %81)
  %107 = add nsw i64 %84, 192
  %108 = getelementptr inbounds float, float* %6, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !1116
  %110 = insertelement <32 x float> undef, float %109, i32 0
  %111 = shufflevector <32 x float> %110, <32 x float> undef, <32 x i32> zeroinitializer
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %93, <32 x float> %80)
  %113 = add nsw i64 %84, 256
  %114 = getelementptr inbounds float, float* %6, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !1116
  %116 = insertelement <32 x float> undef, float %115, i32 0
  %117 = shufflevector <32 x float> %116, <32 x float> undef, <32 x i32> zeroinitializer
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %93, <32 x float> %79)
  %119 = add nsw i64 %84, 320
  %120 = getelementptr inbounds float, float* %6, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !1116
  %122 = insertelement <32 x float> undef, float %121, i32 0
  %123 = shufflevector <32 x float> %122, <32 x float> undef, <32 x i32> zeroinitializer
  %124 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %93, <32 x float> %78)
  %125 = add nsw i64 %84, 384
  %126 = getelementptr inbounds float, float* %6, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !1116
  %128 = insertelement <32 x float> undef, float %127, i32 0
  %129 = shufflevector <32 x float> %128, <32 x float> undef, <32 x i32> zeroinitializer
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %93, <32 x float> %77)
  %131 = add nsw i64 %90, 2048
  %132 = getelementptr inbounds float, float* %9, i64 %131
  %133 = bitcast float* %132 to <32 x float>*
  %134 = load <32 x float>, <32 x float>* %133, align 64, !tbaa !1130
  %135 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %134, <32 x float> %94)
  %136 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %134, <32 x float> %100)
  %137 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %134, <32 x float> %106)
  %138 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %134, <32 x float> %112)
  %139 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %134, <32 x float> %118)
  %140 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %134, <32 x float> %124)
  %141 = add nsw i64 %84, 448
  %142 = getelementptr inbounds float, float* %6, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !1116
  %144 = insertelement <32 x float> undef, float %143, i32 0
  %145 = shufflevector <32 x float> %144, <32 x float> undef, <32 x i32> zeroinitializer
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %145, <32 x float> %134, <32 x float> %130)
  %147 = add nsw i64 %90, 4096
  %148 = getelementptr inbounds float, float* %9, i64 %147
  %149 = bitcast float* %148 to <32 x float>*
  %150 = load <32 x float>, <32 x float>* %149, align 64, !tbaa !1130
  %151 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %150, <32 x float> %135)
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %150, <32 x float> %136)
  %153 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %150, <32 x float> %137)
  %154 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %150, <32 x float> %138)
  %155 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %150, <32 x float> %139)
  %156 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %145, <32 x float> %150, <32 x float> %140)
  %157 = add nsw i64 %84, 512
  %158 = getelementptr inbounds float, float* %6, i64 %157
  %159 = load float, float* %158, align 4, !tbaa !1116
  %160 = insertelement <32 x float> undef, float %159, i32 0
  %161 = shufflevector <32 x float> %160, <32 x float> undef, <32 x i32> zeroinitializer
  %162 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %150, <32 x float> %146)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %163 = add nsw i64 %75, %58
  br label %for_body8.1

for_begin16.preheader:                            ; preds = %for_begin16.preheader, %for_begin13.preheader
  %indvars.iv65 = phi i64 [ 0, %for_begin13.preheader ], [ %indvars.iv.next66, %for_begin16.preheader ]
  %164 = mul nuw nsw i64 %indvars.iv65, 224
  %165 = trunc i64 %164 to i32
  %166 = add i32 %64, %165
  %167 = getelementptr inbounds float, float* %73, i64 %164
  %168 = bitcast float* %167 to <32 x float>*
  %169 = load <32 x float>, <32 x float>* %168, align 64, !tbaa !1133
  %170 = fadd <32 x float> %72, %169
  %171 = fadd <32 x float> %69, %170
  %172 = fcmp ogt <32 x float> %171, zeroinitializer
  %173 = select <32 x i1> %172, <32 x float> %171, <32 x float> zeroinitializer
  %174 = sext i32 %166 to i64
  %175 = getelementptr inbounds float, float* %12, i64 %174
  %176 = bitcast float* %175 to <32 x float>*
  store <32 x float> %173, <32 x float>* %176, align 64, !tbaa !1136
  %177 = add nuw nsw i64 %164, 32
  %178 = trunc i64 %177 to i32
  %179 = add i32 %64, %178
  %180 = getelementptr inbounds float, float* %73, i64 %177
  %181 = bitcast float* %180 to <32 x float>*
  %182 = load <32 x float>, <32 x float>* %181, align 64, !tbaa !1133
  %183 = fadd <32 x float> %72, %182
  %184 = fadd <32 x float> %69, %183
  %185 = fcmp ogt <32 x float> %184, zeroinitializer
  %186 = select <32 x i1> %185, <32 x float> %184, <32 x float> zeroinitializer
  %187 = sext i32 %179 to i64
  %188 = getelementptr inbounds float, float* %12, i64 %187
  %189 = bitcast float* %188 to <32 x float>*
  store <32 x float> %186, <32 x float>* %189, align 64, !tbaa !1136
  %190 = add nuw nsw i64 %164, 64
  %191 = trunc i64 %190 to i32
  %192 = add i32 %64, %191
  %193 = getelementptr inbounds float, float* %73, i64 %190
  %194 = bitcast float* %193 to <32 x float>*
  %195 = load <32 x float>, <32 x float>* %194, align 64, !tbaa !1133
  %196 = fadd <32 x float> %72, %195
  %197 = fadd <32 x float> %69, %196
  %198 = fcmp ogt <32 x float> %197, zeroinitializer
  %199 = select <32 x i1> %198, <32 x float> %197, <32 x float> zeroinitializer
  %200 = sext i32 %192 to i64
  %201 = getelementptr inbounds float, float* %12, i64 %200
  %202 = bitcast float* %201 to <32 x float>*
  store <32 x float> %199, <32 x float>* %202, align 64, !tbaa !1136
  %203 = add nuw nsw i64 %164, 96
  %204 = trunc i64 %203 to i32
  %205 = add i32 %64, %204
  %206 = getelementptr inbounds float, float* %73, i64 %203
  %207 = bitcast float* %206 to <32 x float>*
  %208 = load <32 x float>, <32 x float>* %207, align 64, !tbaa !1133
  %209 = fadd <32 x float> %72, %208
  %210 = fadd <32 x float> %69, %209
  %211 = fcmp ogt <32 x float> %210, zeroinitializer
  %212 = select <32 x i1> %211, <32 x float> %210, <32 x float> zeroinitializer
  %213 = sext i32 %205 to i64
  %214 = getelementptr inbounds float, float* %12, i64 %213
  %215 = bitcast float* %214 to <32 x float>*
  store <32 x float> %212, <32 x float>* %215, align 64, !tbaa !1136
  %216 = add nuw nsw i64 %164, 128
  %217 = trunc i64 %216 to i32
  %218 = add i32 %64, %217
  %219 = getelementptr inbounds float, float* %73, i64 %216
  %220 = bitcast float* %219 to <32 x float>*
  %221 = load <32 x float>, <32 x float>* %220, align 64, !tbaa !1133
  %222 = fadd <32 x float> %72, %221
  %223 = fadd <32 x float> %69, %222
  %224 = fcmp ogt <32 x float> %223, zeroinitializer
  %225 = select <32 x i1> %224, <32 x float> %223, <32 x float> zeroinitializer
  %226 = sext i32 %218 to i64
  %227 = getelementptr inbounds float, float* %12, i64 %226
  %228 = bitcast float* %227 to <32 x float>*
  store <32 x float> %225, <32 x float>* %228, align 64, !tbaa !1136
  %229 = add nuw nsw i64 %164, 160
  %230 = trunc i64 %229 to i32
  %231 = add i32 %64, %230
  %232 = getelementptr inbounds float, float* %73, i64 %229
  %233 = bitcast float* %232 to <32 x float>*
  %234 = load <32 x float>, <32 x float>* %233, align 64, !tbaa !1133
  %235 = fadd <32 x float> %72, %234
  %236 = fadd <32 x float> %69, %235
  %237 = fcmp ogt <32 x float> %236, zeroinitializer
  %238 = select <32 x i1> %237, <32 x float> %236, <32 x float> zeroinitializer
  %239 = sext i32 %231 to i64
  %240 = getelementptr inbounds float, float* %12, i64 %239
  %241 = bitcast float* %240 to <32 x float>*
  store <32 x float> %238, <32 x float>* %241, align 64, !tbaa !1136
  %242 = add nuw nsw i64 %164, 192
  %243 = trunc i64 %242 to i32
  %244 = add i32 %64, %243
  %245 = getelementptr inbounds float, float* %73, i64 %242
  %246 = bitcast float* %245 to <32 x float>*
  %247 = load <32 x float>, <32 x float>* %246, align 64, !tbaa !1133
  %248 = fadd <32 x float> %72, %247
  %249 = fadd <32 x float> %69, %248
  %250 = fcmp ogt <32 x float> %249, zeroinitializer
  %251 = select <32 x i1> %250, <32 x float> %249, <32 x float> zeroinitializer
  %252 = sext i32 %244 to i64
  %253 = getelementptr inbounds float, float* %12, i64 %252
  %254 = bitcast float* %253 to <32 x float>*
  store <32 x float> %251, <32 x float>* %254, align 64, !tbaa !1136
  %indvars.iv.next66 = add nuw nsw i64 %indvars.iv65, 1
  %exitcond67 = icmp eq i64 %indvars.iv.next66, 8
  br i1 %exitcond67, label %for_end15, label %for_begin16.preheader, !prof !50

for_end15:                                        ; preds = %for_begin16.preheader
  %255 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %256 = tail call i32 %255(i32 1, i32 %21, i8* nonnull %49)
  %257 = add nsw i32 %47, 1
  %258 = icmp slt i32 %257, %29
  br i1 %258, label %for_body, label %for_end, !prof !5

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %259 = phi <32 x float> [ %162, %for_end9 ], [ %344, %for_body8.1 ]
  %260 = phi <32 x float> [ %156, %for_end9 ], [ %338, %for_body8.1 ]
  %261 = phi <32 x float> [ %155, %for_end9 ], [ %337, %for_body8.1 ]
  %262 = phi <32 x float> [ %154, %for_end9 ], [ %336, %for_body8.1 ]
  %263 = phi <32 x float> [ %153, %for_end9 ], [ %335, %for_body8.1 ]
  %264 = phi <32 x float> [ %152, %for_end9 ], [ %334, %for_body8.1 ]
  %265 = phi <32 x float> [ %151, %for_end9 ], [ %333, %for_body8.1 ]
  %266 = add nsw i64 %163, %indvars.iv.1
  %267 = getelementptr inbounds float, float* %6, i64 %266
  %268 = load float, float* %267, align 4, !tbaa !1116
  %269 = insertelement <32 x float> undef, float %268, i32 0
  %270 = shufflevector <32 x float> %269, <32 x float> undef, <32 x i32> zeroinitializer
  %271 = shl nsw i64 %indvars.iv.1, 5
  %272 = add nsw i64 %59, %271
  %273 = getelementptr inbounds float, float* %9, i64 %272
  %274 = bitcast float* %273 to <32 x float>*
  %275 = load <32 x float>, <32 x float>* %274, align 64, !tbaa !1130
  %276 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %270, <32 x float> %275, <32 x float> %265)
  %277 = add nsw i64 %266, 64
  %278 = getelementptr inbounds float, float* %6, i64 %277
  %279 = load float, float* %278, align 4, !tbaa !1116
  %280 = insertelement <32 x float> undef, float %279, i32 0
  %281 = shufflevector <32 x float> %280, <32 x float> undef, <32 x i32> zeroinitializer
  %282 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %281, <32 x float> %275, <32 x float> %264)
  %283 = add nsw i64 %266, 128
  %284 = getelementptr inbounds float, float* %6, i64 %283
  %285 = load float, float* %284, align 4, !tbaa !1116
  %286 = insertelement <32 x float> undef, float %285, i32 0
  %287 = shufflevector <32 x float> %286, <32 x float> undef, <32 x i32> zeroinitializer
  %288 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %287, <32 x float> %275, <32 x float> %263)
  %289 = add nsw i64 %266, 192
  %290 = getelementptr inbounds float, float* %6, i64 %289
  %291 = load float, float* %290, align 4, !tbaa !1116
  %292 = insertelement <32 x float> undef, float %291, i32 0
  %293 = shufflevector <32 x float> %292, <32 x float> undef, <32 x i32> zeroinitializer
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %293, <32 x float> %275, <32 x float> %262)
  %295 = add nsw i64 %266, 256
  %296 = getelementptr inbounds float, float* %6, i64 %295
  %297 = load float, float* %296, align 4, !tbaa !1116
  %298 = insertelement <32 x float> undef, float %297, i32 0
  %299 = shufflevector <32 x float> %298, <32 x float> undef, <32 x i32> zeroinitializer
  %300 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %299, <32 x float> %275, <32 x float> %261)
  %301 = add nsw i64 %266, 320
  %302 = getelementptr inbounds float, float* %6, i64 %301
  %303 = load float, float* %302, align 4, !tbaa !1116
  %304 = insertelement <32 x float> undef, float %303, i32 0
  %305 = shufflevector <32 x float> %304, <32 x float> undef, <32 x i32> zeroinitializer
  %306 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %275, <32 x float> %260)
  %307 = add nsw i64 %266, 384
  %308 = getelementptr inbounds float, float* %6, i64 %307
  %309 = load float, float* %308, align 4, !tbaa !1116
  %310 = insertelement <32 x float> undef, float %309, i32 0
  %311 = shufflevector <32 x float> %310, <32 x float> undef, <32 x i32> zeroinitializer
  %312 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %311, <32 x float> %275, <32 x float> %259)
  %313 = add nsw i64 %272, 2048
  %314 = getelementptr inbounds float, float* %9, i64 %313
  %315 = bitcast float* %314 to <32 x float>*
  %316 = load <32 x float>, <32 x float>* %315, align 64, !tbaa !1130
  %317 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %281, <32 x float> %316, <32 x float> %276)
  %318 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %287, <32 x float> %316, <32 x float> %282)
  %319 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %293, <32 x float> %316, <32 x float> %288)
  %320 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %299, <32 x float> %316, <32 x float> %294)
  %321 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %316, <32 x float> %300)
  %322 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %311, <32 x float> %316, <32 x float> %306)
  %323 = add nsw i64 %266, 448
  %324 = getelementptr inbounds float, float* %6, i64 %323
  %325 = load float, float* %324, align 4, !tbaa !1116
  %326 = insertelement <32 x float> undef, float %325, i32 0
  %327 = shufflevector <32 x float> %326, <32 x float> undef, <32 x i32> zeroinitializer
  %328 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %327, <32 x float> %316, <32 x float> %312)
  %329 = add nsw i64 %272, 4096
  %330 = getelementptr inbounds float, float* %9, i64 %329
  %331 = bitcast float* %330 to <32 x float>*
  %332 = load <32 x float>, <32 x float>* %331, align 64, !tbaa !1130
  %333 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %287, <32 x float> %332, <32 x float> %317)
  %334 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %293, <32 x float> %332, <32 x float> %318)
  %335 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %299, <32 x float> %332, <32 x float> %319)
  %336 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %332, <32 x float> %320)
  %337 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %311, <32 x float> %332, <32 x float> %321)
  %338 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %327, <32 x float> %332, <32 x float> %322)
  %339 = add nsw i64 %266, 512
  %340 = getelementptr inbounds float, float* %6, i64 %339
  %341 = load float, float* %340, align 4, !tbaa !1116
  %342 = insertelement <32 x float> undef, float %341, i32 0
  %343 = shufflevector <32 x float> %342, <32 x float> undef, <32 x i32> zeroinitializer
  %344 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %343, <32 x float> %332, <32 x float> %328)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 64
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %345 = add nsw i64 %75, %62
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %346 = phi <32 x float> [ %344, %for_end9.1 ], [ %431, %for_body8.2 ]
  %347 = phi <32 x float> [ %338, %for_end9.1 ], [ %425, %for_body8.2 ]
  %348 = phi <32 x float> [ %337, %for_end9.1 ], [ %424, %for_body8.2 ]
  %349 = phi <32 x float> [ %336, %for_end9.1 ], [ %423, %for_body8.2 ]
  %350 = phi <32 x float> [ %335, %for_end9.1 ], [ %422, %for_body8.2 ]
  %351 = phi <32 x float> [ %334, %for_end9.1 ], [ %421, %for_body8.2 ]
  %352 = phi <32 x float> [ %333, %for_end9.1 ], [ %420, %for_body8.2 ]
  %353 = add nsw i64 %345, %indvars.iv.2
  %354 = getelementptr inbounds float, float* %6, i64 %353
  %355 = load float, float* %354, align 4, !tbaa !1116
  %356 = insertelement <32 x float> undef, float %355, i32 0
  %357 = shufflevector <32 x float> %356, <32 x float> undef, <32 x i32> zeroinitializer
  %358 = shl nsw i64 %indvars.iv.2, 5
  %359 = add nsw i64 %63, %358
  %360 = getelementptr inbounds float, float* %9, i64 %359
  %361 = bitcast float* %360 to <32 x float>*
  %362 = load <32 x float>, <32 x float>* %361, align 64, !tbaa !1130
  %363 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %357, <32 x float> %362, <32 x float> %352)
  %364 = add nsw i64 %353, 64
  %365 = getelementptr inbounds float, float* %6, i64 %364
  %366 = load float, float* %365, align 4, !tbaa !1116
  %367 = insertelement <32 x float> undef, float %366, i32 0
  %368 = shufflevector <32 x float> %367, <32 x float> undef, <32 x i32> zeroinitializer
  %369 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %368, <32 x float> %362, <32 x float> %351)
  %370 = add nsw i64 %353, 128
  %371 = getelementptr inbounds float, float* %6, i64 %370
  %372 = load float, float* %371, align 4, !tbaa !1116
  %373 = insertelement <32 x float> undef, float %372, i32 0
  %374 = shufflevector <32 x float> %373, <32 x float> undef, <32 x i32> zeroinitializer
  %375 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %374, <32 x float> %362, <32 x float> %350)
  %376 = add nsw i64 %353, 192
  %377 = getelementptr inbounds float, float* %6, i64 %376
  %378 = load float, float* %377, align 4, !tbaa !1116
  %379 = insertelement <32 x float> undef, float %378, i32 0
  %380 = shufflevector <32 x float> %379, <32 x float> undef, <32 x i32> zeroinitializer
  %381 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %380, <32 x float> %362, <32 x float> %349)
  %382 = add nsw i64 %353, 256
  %383 = getelementptr inbounds float, float* %6, i64 %382
  %384 = load float, float* %383, align 4, !tbaa !1116
  %385 = insertelement <32 x float> undef, float %384, i32 0
  %386 = shufflevector <32 x float> %385, <32 x float> undef, <32 x i32> zeroinitializer
  %387 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %386, <32 x float> %362, <32 x float> %348)
  %388 = add nsw i64 %353, 320
  %389 = getelementptr inbounds float, float* %6, i64 %388
  %390 = load float, float* %389, align 4, !tbaa !1116
  %391 = insertelement <32 x float> undef, float %390, i32 0
  %392 = shufflevector <32 x float> %391, <32 x float> undef, <32 x i32> zeroinitializer
  %393 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %392, <32 x float> %362, <32 x float> %347)
  %394 = add nsw i64 %353, 384
  %395 = getelementptr inbounds float, float* %6, i64 %394
  %396 = load float, float* %395, align 4, !tbaa !1116
  %397 = insertelement <32 x float> undef, float %396, i32 0
  %398 = shufflevector <32 x float> %397, <32 x float> undef, <32 x i32> zeroinitializer
  %399 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %398, <32 x float> %362, <32 x float> %346)
  %400 = add nsw i64 %359, 2048
  %401 = getelementptr inbounds float, float* %9, i64 %400
  %402 = bitcast float* %401 to <32 x float>*
  %403 = load <32 x float>, <32 x float>* %402, align 64, !tbaa !1130
  %404 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %368, <32 x float> %403, <32 x float> %363)
  %405 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %374, <32 x float> %403, <32 x float> %369)
  %406 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %380, <32 x float> %403, <32 x float> %375)
  %407 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %386, <32 x float> %403, <32 x float> %381)
  %408 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %392, <32 x float> %403, <32 x float> %387)
  %409 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %398, <32 x float> %403, <32 x float> %393)
  %410 = add nsw i64 %353, 448
  %411 = getelementptr inbounds float, float* %6, i64 %410
  %412 = load float, float* %411, align 4, !tbaa !1116
  %413 = insertelement <32 x float> undef, float %412, i32 0
  %414 = shufflevector <32 x float> %413, <32 x float> undef, <32 x i32> zeroinitializer
  %415 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %414, <32 x float> %403, <32 x float> %399)
  %416 = add nsw i64 %359, 4096
  %417 = getelementptr inbounds float, float* %9, i64 %416
  %418 = bitcast float* %417 to <32 x float>*
  %419 = load <32 x float>, <32 x float>* %418, align 64, !tbaa !1130
  %420 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %374, <32 x float> %419, <32 x float> %404)
  %421 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %380, <32 x float> %419, <32 x float> %405)
  %422 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %386, <32 x float> %419, <32 x float> %406)
  %423 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %392, <32 x float> %419, <32 x float> %407)
  %424 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %398, <32 x float> %419, <32 x float> %408)
  %425 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %414, <32 x float> %419, <32 x float> %409)
  %426 = add nsw i64 %353, 512
  %427 = getelementptr inbounds float, float* %6, i64 %426
  %428 = load float, float* %427, align 4, !tbaa !1116
  %429 = insertelement <32 x float> undef, float %428, i32 0
  %430 = shufflevector <32 x float> %429, <32 x float> undef, <32 x i32> zeroinitializer
  %431 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %430, <32 x float> %419, <32 x float> %415)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 64
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %420, <32 x float>* %.sub, align 128, !tbaa !1139
  store <32 x float> %421, <32 x float>* %35, align 128, !tbaa !1139
  store <32 x float> %422, <32 x float>* %37, align 128, !tbaa !1139
  store <32 x float> %423, <32 x float>* %39, align 128, !tbaa !1139
  store <32 x float> %424, <32 x float>* %41, align 128, !tbaa !1139
  store <32 x float> %425, <32 x float>* %43, align 128, !tbaa !1139
  store <32 x float> %431, <32 x float>* %45, align 128, !tbaa !1139
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %scevgep, i8* nonnull align 128 %4, i64 896, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond61 = icmp eq i64 %indvar.next, 8
  br i1 %exitcond61, label %for_begin13.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_layout_transform_44(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.138, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !1148
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.139, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !1162
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.140, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !1164
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !1178
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 2
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.122, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !1180
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 56
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !1183
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 56
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !1185
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !1189
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 200704, i32 100352, i32 1792, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !1201
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.124, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !1205
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !1219
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 16
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.31, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !1221
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 56
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !1224
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 56
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !1226
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 4
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !1230
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 200704, i32 12544, i32 224, i32 4>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !1242
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.142, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_44_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_44_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %12, align 8
  %3 = getelementptr inbounds %12, %12* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %12, %12* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %12* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.143, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.143(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 895
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 896
  %15 = select i1 %14, i32 %13, i32 896
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 896
  %18 = select i1 %17, i32 %16, i32 896
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 224
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = sdiv i32 %25, 56
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 56
  %29 = mul nsw i32 %28, 1792
  %30 = and i32 %27, 28
  %31 = ashr i32 %26, 3
  %32 = mul nsw i32 %31, 100352
  %33 = and i32 %27, 28
  %34 = or i32 %33, 1
  %35 = ashr i32 %26, 3
  %36 = mul nsw i32 %35, 100352
  %37 = and i32 %27, 28
  %38 = or i32 %37, 2
  %39 = ashr i32 %26, 3
  %40 = mul nsw i32 %39, 100352
  %41 = and i32 %27, 28
  %42 = or i32 %41, 3
  %43 = ashr i32 %26, 3
  %44 = mul nsw i32 %43, 100352
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_begin4.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_begin4.preheader ]
  %45 = shl i64 %indvars.iv, 2
  %46 = add nsw i64 %45, %24
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %47 = shl i32 %indvars.iv.tr, 5
  %48 = add i32 %29, %47
  %49 = add i32 %48, %32
  %50 = or i32 %49, %30
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds float, float* %7, i64 %51
  %53 = bitcast float* %52 to i32*
  %54 = load i32, i32* %53, align 4, !tbaa !1246
  %55 = getelementptr inbounds float, float* %4, i64 %46
  %56 = bitcast float* %55 to i32*
  store i32 %54, i32* %56, align 4, !tbaa !1249
  %57 = or i64 %46, 1
  %58 = add i32 %48, %36
  %59 = or i32 %58, %34
  %60 = sext i32 %59 to i64
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = bitcast float* %61 to i32*
  %63 = load i32, i32* %62, align 4, !tbaa !1246
  %64 = getelementptr inbounds float, float* %4, i64 %57
  %65 = bitcast float* %64 to i32*
  store i32 %63, i32* %65, align 4, !tbaa !1249
  %66 = or i64 %46, 2
  %67 = add i32 %48, %40
  %68 = or i32 %67, %38
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to i32*
  %72 = load i32, i32* %71, align 4, !tbaa !1246
  %73 = getelementptr inbounds float, float* %4, i64 %66
  %74 = bitcast float* %73 to i32*
  store i32 %72, i32* %74, align 4, !tbaa !1249
  %75 = or i64 %46, 3
  %76 = add i32 %48, %44
  %77 = or i32 %76, %42
  %78 = sext i32 %77 to i64
  %79 = getelementptr inbounds float, float* %7, i64 %78
  %80 = bitcast float* %79 to i32*
  %81 = load i32, i32* %80, align 4, !tbaa !1246
  %82 = getelementptr inbounds float, float* %4, i64 %75
  %83 = bitcast float* %82 to i32*
  store i32 %81, i32* %83, align 4, !tbaa !1249
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_begin4.preheader, !prof !50

for_end3:                                         ; preds = %for_begin4.preheader
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %84 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %84, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_43(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.144, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !1252
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.145, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !1266
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.146, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !1268
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !1282
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 8
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !1284
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 56
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !1287
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 56
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !1289
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !1293
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 802816, i32 100352, i32 1792, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !1305
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.147, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !1309
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !1323
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !1325
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 56
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !1328
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 56
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !1330
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 256
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !1334
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 802816, i32 802816, i32 14336, i32 256>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !1346
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([243 x i8], [243 x i8]* @.str.148, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_43_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_43_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %13, align 8
  %3 = getelementptr inbounds %13, %13* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %13, %13* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %13* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.149, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.149(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 14336
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 8
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 100352
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !1350
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !1353
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 56
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 6
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([101 x i8], [101 x i8]* @.str.150, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !1356
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !1370
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !1373
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !1375
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !1379
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.151, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %77 = getelementptr inbounds i8, i8* %1, i64 4
  %78 = bitcast i8* %77 to i32*
  %79 = load i32, i32* %78, align 4, !tbaa !1381
  switch i32 %79, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.152, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %81 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %81(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.153, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.154, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %83 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %83(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.155, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.156, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  %85 = icmp eq i32 %43, 1
  br i1 %85, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %86 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %86(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %87 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %88 = load i32, i32* %87, align 4
  %89 = icmp eq i32 %88, 5
  br i1 %89, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %91 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %92 = load i16, i16* %91, align 2
  %93 = icmp eq i16 %92, 1
  %94 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %95 = load i8, i8* %94, align 1
  %96 = icmp eq i8 %95, 32
  %97 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %98 = load i8, i8* %97, align 1
  %99 = icmp eq i8 %98, 2
  %100 = and i1 %96, %99
  %101 = and i1 %93, %100
  br i1 %101, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %103 = load i64, i64* %39, align 8, !tbaa !1383
  %104 = trunc i64 %103 to i32
  %105 = icmp eq i32 %104, 1
  br i1 %105, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %107 = getelementptr inbounds i64, i64* %39, i64 1
  %108 = load i64, i64* %107, align 8, !tbaa !1397
  %109 = trunc i64 %108 to i32
  %110 = icmp eq i32 %109, 1
  br i1 %110, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %111 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %111(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %112 = getelementptr inbounds i64, i64* %39, i64 2
  %113 = load i64, i64* %112, align 8, !tbaa !1399
  %114 = trunc i64 %113 to i32
  %115 = icmp eq i32 %114, 14
  br i1 %115, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %116 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %116(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %117 = getelementptr inbounds i64, i64* %39, i64 3
  %118 = load i64, i64* %117, align 8, !tbaa !1402
  %119 = trunc i64 %118 to i32
  %120 = icmp eq i32 %119, 14
  br i1 %120, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %121 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %121(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %122 = getelementptr inbounds i64, i64* %39, i64 4
  %123 = load i64, i64* %122, align 8, !tbaa !1404
  %124 = trunc i64 %123 to i32
  %125 = icmp eq i32 %124, 1024
  br i1 %125, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %126 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %126(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.157, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %127 = icmp eq i64* %41, null
  br i1 %127, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end28
  %128 = bitcast i64* %41 to <4 x i64>*
  %129 = load <4 x i64>, <4 x i64>* %128, align 8, !tbaa !1408
  %130 = trunc <4 x i64> %129 to <4 x i32>
  %131 = icmp eq <4 x i32> %130, <i32 200704, i32 200704, i32 14336, i32 1024>
  %132 = getelementptr inbounds i64, i64* %41, i64 4
  %133 = load i64, i64* %132, align 8, !tbaa !1420
  %134 = trunc i64 %133 to i32
  %135 = icmp eq i32 %134, 1
  %rdx.shuf167 = shufflevector <4 x i1> %131, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx168 = and <4 x i1> %131, %rdx.shuf167
  %rdx.shuf169 = shufflevector <4 x i1> %bin.rdx168, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx170 = and <4 x i1> %bin.rdx168, %rdx.shuf169
  %136 = extractelement <4 x i1> %bin.rdx170, i32 0
  %137 = and i1 %136, %135
  br i1 %137, label %if_end, label %assert_fail29, !prof !5

if_end:                                           ; preds = %assert_end28, %if_then
  %138 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %139 = load i64, i64* %138, align 8
  %140 = icmp eq i64 %139, 0
  br i1 %140, label %assert_end32, label %assert_fail31, !prof !5

assert_fail29:                                    ; preds = %if_then
  %141 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %141(i8* getelementptr inbounds ([244 x i8], [244 x i8]* @.str.158, i64 0, i64 0))
  ret i32 -1

assert_fail31:                                    ; preds = %if_end
  %142 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %142(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %if_end
  %143 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %144 = load i32, i32* %143, align 4
  %145 = icmp eq i32 %144, 6
  br i1 %145, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %148 = load i16, i16* %147, align 2
  %149 = icmp eq i16 %148, 1
  %150 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %151 = load i8, i8* %150, align 1
  %152 = icmp eq i8 %151, 32
  %153 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %154 = load i8, i8* %153, align 1
  %155 = icmp eq i8 %154, 2
  %156 = and i1 %152, %155
  %157 = and i1 %149, %156
  br i1 %157, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %159 = load i64, i64* %49, align 8, !tbaa !1424
  %160 = trunc i64 %159 to i32
  %161 = icmp eq i32 %160, 64
  br i1 %161, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %162 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %162(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %163 = getelementptr inbounds i64, i64* %49, i64 1
  %164 = load i64, i64* %163, align 8, !tbaa !1438
  %165 = trunc i64 %164 to i32
  %166 = icmp eq i32 %165, 1
  br i1 %166, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %167 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %167(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %168 = getelementptr inbounds i64, i64* %49, i64 2
  %169 = load i64, i64* %168, align 8, !tbaa !1440
  %170 = trunc i64 %169 to i32
  %171 = icmp eq i32 %170, 1
  br i1 %171, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %172 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %172(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %173 = getelementptr inbounds i64, i64* %49, i64 3
  %174 = load i64, i64* %173, align 8, !tbaa !1443
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  br i1 %176, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %177 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %177(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %178 = getelementptr inbounds i64, i64* %49, i64 4
  %179 = load i64, i64* %178, align 8, !tbaa !1445
  %180 = trunc i64 %179 to i32
  %181 = icmp eq i32 %180, 1024
  br i1 %181, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %182 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %182(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %183 = getelementptr inbounds i64, i64* %49, i64 5
  %184 = load i64, i64* %183, align 8, !tbaa !1449
  %185 = trunc i64 %184 to i32
  %186 = icmp eq i32 %185, 32
  br i1 %186, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %187 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %187(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %188 = icmp eq i64* %51, null
  br i1 %188, label %if_end50, label %if_then49, !prof !50

if_then49:                                        ; preds = %assert_end48
  %189 = bitcast i64* %51 to <4 x i64>*
  %190 = load <4 x i64>, <4 x i64>* %189, align 8, !tbaa !1451
  %191 = trunc <4 x i64> %190 to <4 x i32>
  %192 = icmp eq <4 x i32> %191, <i32 32768, i32 32768, i32 32768, i32 32768>
  %193 = getelementptr inbounds i64, i64* %51, i64 4
  %194 = load i64, i64* %193, align 8, !tbaa !1463
  %195 = trunc i64 %194 to i32
  %196 = icmp eq i32 %195, 32
  %197 = getelementptr inbounds i64, i64* %51, i64 5
  %198 = load i64, i64* %197, align 8, !tbaa !1467
  %199 = trunc i64 %198 to i32
  %200 = icmp eq i32 %199, 1
  %rdx.shuf163 = shufflevector <4 x i1> %192, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx164 = and <4 x i1> %192, %rdx.shuf163
  %rdx.shuf165 = shufflevector <4 x i1> %bin.rdx164, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx166 = and <4 x i1> %bin.rdx164, %rdx.shuf165
  %201 = extractelement <4 x i1> %bin.rdx166, i32 0
  %202 = and i1 %201, %196
  %203 = and i1 %202, %200
  br i1 %203, label %if_end50, label %assert_fail51, !prof !5

if_end50:                                         ; preds = %assert_end48, %if_then49
  %204 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %205 = load i64, i64* %204, align 8
  %206 = icmp eq i64 %205, 0
  br i1 %206, label %assert_end54, label %assert_fail53, !prof !5

assert_fail51:                                    ; preds = %if_then49
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([279 x i8], [279 x i8]* @.str.160, i64 0, i64 0))
  ret i32 -1

assert_fail53:                                    ; preds = %if_end50
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %if_end50
  %209 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %210 = load i32, i32* %209, align 4
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %213 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %214 = load i32, i32* %213, align 4
  %215 = icmp eq i32 %45, %214
  br i1 %215, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %216 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %216(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %217 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %218 = load i32, i32* %217, align 4
  %219 = icmp eq i32 %218, 4
  br i1 %219, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %221 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %222 = load i16, i16* %221, align 2
  %223 = icmp eq i16 %222, 1
  %224 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %225 = load i8, i8* %224, align 1
  %226 = icmp eq i8 %225, 32
  %227 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %228 = load i8, i8* %227, align 1
  %229 = icmp eq i8 %228, 2
  %230 = and i1 %226, %229
  %231 = and i1 %223, %230
  br i1 %231, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %233 = load i64, i64* %55, align 8, !tbaa !1469
  %234 = trunc i64 %233 to i32
  %235 = icmp eq i32 %234, 64
  br i1 %235, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %236 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %236(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.161, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %237 = getelementptr inbounds i64, i64* %55, i64 1
  %238 = load i64, i64* %237, align 8, !tbaa !1483
  %239 = trunc i64 %238 to i32
  %240 = icmp eq i32 %239, 1
  br i1 %240, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %241 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %241(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %242 = getelementptr inbounds i64, i64* %55, i64 2
  %243 = load i64, i64* %242, align 8, !tbaa !1485
  %244 = trunc i64 %243 to i32
  %245 = icmp eq i32 %244, 1
  br i1 %245, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %246 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %246(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %247 = getelementptr inbounds i64, i64* %55, i64 3
  %248 = load i64, i64* %247, align 8, !tbaa !1488
  %249 = trunc i64 %248 to i32
  %250 = icmp eq i32 %249, 32
  br i1 %250, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %251 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %251(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %252 = icmp eq i64* %57, null
  br i1 %252, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %253 = bitcast i64* %57 to <4 x i64>*
  %254 = load <4 x i64>, <4 x i64>* %253, align 8, !tbaa !1490
  %255 = trunc <4 x i64> %254 to <4 x i32>
  %256 = icmp eq <4 x i32> %255, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf159 = shufflevector <4 x i1> %256, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx160 = and <4 x i1> %256, %rdx.shuf159
  %rdx.shuf161 = shufflevector <4 x i1> %bin.rdx160, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx162 = and <4 x i1> %bin.rdx160, %rdx.shuf161
  %257 = extractelement <4 x i1> %bin.rdx162, i32 0
  br i1 %257, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %258 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %259 = load i64, i64* %258, align 8
  %260 = icmp eq i64 %259, 0
  br i1 %260, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %262 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %262(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %263 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %264 = load i32, i32* %263, align 4
  %265 = icmp eq i32 %264, 1
  br i1 %265, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %266 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %266(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %267 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %268 = load i32, i32* %267, align 4
  %269 = icmp eq i32 %45, %268
  br i1 %269, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %270 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %270(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %271 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %272 = load i32, i32* %271, align 4
  %273 = icmp eq i32 %272, 4
  br i1 %273, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %275 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %276 = load i16, i16* %275, align 2
  %277 = icmp eq i16 %276, 1
  %278 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %279 = load i8, i8* %278, align 1
  %280 = icmp eq i8 %279, 32
  %281 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %282 = load i8, i8* %281, align 1
  %283 = icmp eq i8 %282, 2
  %284 = and i1 %280, %283
  %285 = and i1 %277, %284
  br i1 %285, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %287 = load i64, i64* %61, align 8, !tbaa !1502
  %288 = trunc i64 %287 to i32
  %289 = icmp eq i32 %288, 64
  br i1 %289, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %290 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %290(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.162, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %291 = getelementptr inbounds i64, i64* %61, i64 1
  %292 = load i64, i64* %291, align 8, !tbaa !1516
  %293 = trunc i64 %292 to i32
  %294 = icmp eq i32 %293, 1
  br i1 %294, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %295 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %295(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %296 = getelementptr inbounds i64, i64* %61, i64 2
  %297 = load i64, i64* %296, align 8, !tbaa !1518
  %298 = trunc i64 %297 to i32
  %299 = icmp eq i32 %298, 1
  br i1 %299, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %300 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %300(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %301 = getelementptr inbounds i64, i64* %61, i64 3
  %302 = load i64, i64* %301, align 8, !tbaa !1521
  %303 = trunc i64 %302 to i32
  %304 = icmp eq i32 %303, 32
  br i1 %304, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %305 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %305(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %306 = icmp eq i64* %63, null
  br i1 %306, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %307 = bitcast i64* %63 to <4 x i64>*
  %308 = load <4 x i64>, <4 x i64>* %307, align 8, !tbaa !1523
  %309 = trunc <4 x i64> %308 to <4 x i32>
  %310 = icmp eq <4 x i32> %309, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf155 = shufflevector <4 x i1> %310, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx156 = and <4 x i1> %310, %rdx.shuf155
  %rdx.shuf157 = shufflevector <4 x i1> %bin.rdx156, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx158 = and <4 x i1> %bin.rdx156, %rdx.shuf157
  %311 = extractelement <4 x i1> %bin.rdx158, i32 0
  br i1 %311, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %312 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %313 = load i64, i64* %312, align 8
  %314 = icmp eq i64 %313, 0
  br i1 %314, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %317 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %318, 1
  br i1 %319, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %321 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %322 = load i32, i32* %321, align 4
  %323 = icmp eq i32 %45, %322
  br i1 %323, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %325 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %326 = load i32, i32* %325, align 4
  %327 = icmp eq i32 %326, 4
  br i1 %327, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %329 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %330 = load i16, i16* %329, align 2
  %331 = icmp eq i16 %330, 1
  %332 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %333 = load i8, i8* %332, align 1
  %334 = icmp eq i8 %333, 32
  %335 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %336 = load i8, i8* %335, align 1
  %337 = icmp eq i8 %336, 2
  %338 = and i1 %334, %337
  %339 = and i1 %331, %338
  br i1 %339, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %340 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %340(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %341 = load i64, i64* %67, align 8, !tbaa !1535
  %342 = trunc i64 %341 to i32
  %343 = icmp eq i32 %342, 64
  br i1 %343, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %344 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %344(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.164, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %345 = getelementptr inbounds i64, i64* %67, i64 1
  %346 = load i64, i64* %345, align 8, !tbaa !1549
  %347 = trunc i64 %346 to i32
  %348 = icmp eq i32 %347, 1
  br i1 %348, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %350 = getelementptr inbounds i64, i64* %67, i64 2
  %351 = load i64, i64* %350, align 8, !tbaa !1551
  %352 = trunc i64 %351 to i32
  %353 = icmp eq i32 %352, 1
  br i1 %353, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %354 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %354(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %355 = getelementptr inbounds i64, i64* %67, i64 3
  %356 = load i64, i64* %355, align 8, !tbaa !1554
  %357 = trunc i64 %356 to i32
  %358 = icmp eq i32 %357, 32
  br i1 %358, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %359 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %359(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.167, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %360 = icmp eq i64* %69, null
  br i1 %360, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %361 = bitcast i64* %69 to <4 x i64>*
  %362 = load <4 x i64>, <4 x i64>* %361, align 8, !tbaa !1556
  %363 = trunc <4 x i64> %362 to <4 x i32>
  %364 = icmp eq <4 x i32> %363, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf151 = shufflevector <4 x i1> %364, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx152 = and <4 x i1> %364, %rdx.shuf151
  %rdx.shuf153 = shufflevector <4 x i1> %bin.rdx152, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx154 = and <4 x i1> %bin.rdx152, %rdx.shuf153
  %365 = extractelement <4 x i1> %bin.rdx154, i32 0
  br i1 %365, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %366 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %367 = load i64, i64* %366, align 8
  %368 = icmp eq i64 %367, 0
  br i1 %368, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %369 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %369(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.168, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %370 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %370(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %371 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %372 = load i32, i32* %371, align 4
  %373 = icmp eq i32 %372, 1
  br i1 %373, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %374 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %374(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %375 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %376 = load i32, i32* %375, align 4
  %377 = icmp eq i32 %45, %376
  br i1 %377, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %378 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %378(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %379 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %380 = load i32, i32* %379, align 4
  %381 = icmp eq i32 %380, 5
  br i1 %381, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %383 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %384 = load i16, i16* %383, align 2
  %385 = icmp eq i16 %384, 1
  %386 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %387 = load i8, i8* %386, align 1
  %388 = icmp eq i8 %387, 32
  %389 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %390 = load i8, i8* %389, align 1
  %391 = icmp eq i8 %390, 2
  %392 = and i1 %388, %391
  %393 = and i1 %385, %392
  br i1 %393, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %394 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %394(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %395 = load i64, i64* %73, align 8, !tbaa !1568
  %396 = trunc i64 %395 to i32
  %397 = icmp eq i32 %396, 1
  br i1 %397, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %398 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %398(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %399 = getelementptr inbounds i64, i64* %73, i64 1
  %400 = load i64, i64* %399, align 8, !tbaa !1582
  %401 = trunc i64 %400 to i32
  %402 = icmp eq i32 %401, 64
  br i1 %402, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %403 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %403(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.172, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %404 = getelementptr inbounds i64, i64* %73, i64 2
  %405 = load i64, i64* %404, align 8, !tbaa !1584
  %406 = trunc i64 %405 to i32
  %407 = icmp eq i32 %406, 7
  br i1 %407, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %408 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %408(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.173, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %409 = getelementptr inbounds i64, i64* %73, i64 3
  %410 = load i64, i64* %409, align 8, !tbaa !1587
  %411 = trunc i64 %410 to i32
  %412 = icmp eq i32 %411, 7
  br i1 %412, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %413 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %413(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.174, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %414 = getelementptr inbounds i64, i64* %73, i64 4
  %415 = load i64, i64* %414, align 8, !tbaa !1589
  %416 = trunc i64 %415 to i32
  %417 = icmp eq i32 %416, 32
  br i1 %417, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %418 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %418(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.175, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %419 = icmp eq i64* %75, null
  br i1 %419, label %if_end140, label %if_then139, !prof !50

if_then139:                                       ; preds = %assert_end138
  %420 = bitcast i64* %75 to <4 x i64>*
  %421 = load <4 x i64>, <4 x i64>* %420, align 8, !tbaa !1593
  %422 = trunc <4 x i64> %421 to <4 x i32>
  %423 = icmp eq <4 x i32> %422, <i32 100352, i32 1568, i32 224, i32 32>
  %424 = getelementptr inbounds i64, i64* %75, i64 4
  %425 = load i64, i64* %424, align 8, !tbaa !1605
  %426 = trunc i64 %425 to i32
  %427 = icmp eq i32 %426, 1
  %rdx.shuf = shufflevector <4 x i1> %423, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %423, %rdx.shuf
  %rdx.shuf149 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx150 = and <4 x i1> %bin.rdx, %rdx.shuf149
  %428 = extractelement <4 x i1> %bin.rdx150, i32 0
  %429 = and i1 %428, %427
  br i1 %429, label %if_end140, label %assert_fail141, !prof !5

if_end140:                                        ; preds = %assert_end138, %if_then139
  %430 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %431 = load i64, i64* %430, align 8
  %432 = icmp eq i64 %431, 0
  br i1 %432, label %assert_end144, label %assert_fail143, !prof !5

assert_fail141:                                   ; preds = %if_then139
  %433 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %433(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.176, i64 0, i64 0))
  ret i32 -1

assert_fail143:                                   ; preds = %if_end140
  %434 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %434(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end144:                                    ; preds = %if_end140
  %435 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %436 = load i32, i32* %435, align 4
  %437 = icmp eq i32 %436, 1
  br i1 %437, label %assert_end146, label %assert_fail145, !prof !5

assert_fail145:                                   ; preds = %assert_end144
  %438 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %438(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %assert_end144
  %439 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %440 = load i32, i32* %439, align 4
  %441 = icmp eq i32 %45, %440
  br i1 %441, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %442 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %442(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %443 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3_compute_(i8* %37, i8* %47, i8* %71, i8* %53, i8* %59, i8* %65)
  ret i32 %443
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %6 = alloca %14, align 8
  %7 = getelementptr inbounds %14, %14* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %14, %14* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %14, %14* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %14, %14* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %14, %14* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %14, %14* %6, i64 0, i32 5
  store i8* %5, i8** %12, align 8
  %13 = bitcast %14* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.180, i8* nonnull %13, i32 0)
  ret i32 %15
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.180(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 447
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 448
  %27 = select i1 %26, i32 %25, i32 448
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 448
  %30 = select i1 %29, i32 %28, i32 448
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin4.preheader
  %indvars.iv29 = phi i64 [ %34, %for_body.lr.ph ], [ %indvars.iv.next30, %for_begin4.preheader ]
  %36 = trunc i64 %indvars.iv29 to i32
  %37 = srem i32 %36, 7
  %38 = mul nsw i32 %37, 28672
  %39 = sdiv i32 %36, 7
  %40 = shl i32 %39, 15
  %41 = sext i32 %38 to i64
  %42 = sext i32 %40 to i64
  br label %for_body2

for_end:                                          ; preds = %for_begin4.preheader, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_body2
  %43 = mul nsw i64 %indvars.iv29, 224
  %44 = shl nsw i32 %39, 5
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %13, i64 %45
  %47 = bitcast float* %46 to <32 x float>*
  %48 = load <32 x float>, <32 x float>* %47, align 64, !tbaa !1609
  %49 = getelementptr inbounds float, float* %16, i64 %45
  %50 = bitcast float* %49 to <32 x float>*
  %51 = load <32 x float>, <32 x float>* %50, align 64, !tbaa !1612
  %52 = getelementptr inbounds float, float* %19, i64 %45
  %53 = bitcast float* %52 to <32 x float>*
  %54 = load <32 x float>, <32 x float>* %53, align 64, !tbaa !1615
  %55 = fadd <32 x float> %48, %107
  %56 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %55, <32 x float> %51, <32 x float> %54)
  %57 = getelementptr inbounds float, float* %10, i64 %43
  %58 = bitcast float* %57 to <32 x float>*
  store <32 x float> %56, <32 x float>* %58, align 64, !tbaa !1618
  %59 = add nsw i64 %43, 32
  %60 = fadd <32 x float> %48, %113
  %61 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %60, <32 x float> %51, <32 x float> %54)
  %62 = getelementptr inbounds float, float* %10, i64 %59
  %63 = bitcast float* %62 to <32 x float>*
  store <32 x float> %61, <32 x float>* %63, align 64, !tbaa !1618
  %64 = add nsw i64 %43, 64
  %65 = fadd <32 x float> %48, %119
  %66 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %51, <32 x float> %54)
  %67 = getelementptr inbounds float, float* %10, i64 %64
  %68 = bitcast float* %67 to <32 x float>*
  store <32 x float> %66, <32 x float>* %68, align 64, !tbaa !1618
  %69 = add nsw i64 %43, 96
  %70 = fadd <32 x float> %48, %125
  %71 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %70, <32 x float> %51, <32 x float> %54)
  %72 = getelementptr inbounds float, float* %10, i64 %69
  %73 = bitcast float* %72 to <32 x float>*
  store <32 x float> %71, <32 x float>* %73, align 64, !tbaa !1618
  %74 = add nsw i64 %43, 128
  %75 = fadd <32 x float> %48, %131
  %76 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %75, <32 x float> %51, <32 x float> %54)
  %77 = getelementptr inbounds float, float* %10, i64 %74
  %78 = bitcast float* %77 to <32 x float>*
  store <32 x float> %76, <32 x float>* %78, align 64, !tbaa !1618
  %79 = add nsw i64 %43, 160
  %80 = fadd <32 x float> %48, %137
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %51, <32 x float> %54)
  %82 = getelementptr inbounds float, float* %10, i64 %79
  %83 = bitcast float* %82 to <32 x float>*
  store <32 x float> %81, <32 x float>* %83, align 64, !tbaa !1618
  %84 = add nsw i64 %43, 192
  %85 = fadd <32 x float> %48, %143
  %86 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %85, <32 x float> %51, <32 x float> %54)
  %87 = getelementptr inbounds float, float* %10, i64 %84
  %88 = bitcast float* %87 to <32 x float>*
  store <32 x float> %86, <32 x float>* %88, align 64, !tbaa !1618
  %indvars.iv.next30 = add nsw i64 %indvars.iv29, 1
  %89 = icmp slt i64 %indvars.iv.next30, %35
  br i1 %89, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %90 = phi <32 x float> [ zeroinitializer, %for_body ], [ %143, %for_body2 ]
  %91 = phi <32 x float> [ zeroinitializer, %for_body ], [ %137, %for_body2 ]
  %92 = phi <32 x float> [ zeroinitializer, %for_body ], [ %131, %for_body2 ]
  %93 = phi <32 x float> [ zeroinitializer, %for_body ], [ %125, %for_body2 ]
  %94 = phi <32 x float> [ zeroinitializer, %for_body ], [ %119, %for_body2 ]
  %95 = phi <32 x float> [ zeroinitializer, %for_body ], [ %113, %for_body2 ]
  %96 = phi <32 x float> [ zeroinitializer, %for_body ], [ %107, %for_body2 ]
  %97 = add nuw nsw i64 %indvars.iv, %41
  %98 = getelementptr inbounds float, float* %4, i64 %97
  %99 = load float, float* %98, align 4, !tbaa !1621
  %100 = insertelement <32 x float> undef, float %99, i32 0
  %101 = shufflevector <32 x float> %100, <32 x float> undef, <32 x i32> zeroinitializer
  %102 = shl i64 %indvars.iv, 5
  %103 = add nuw nsw i64 %102, %42
  %104 = getelementptr inbounds float, float* %7, i64 %103
  %105 = bitcast float* %104 to <32 x float>*
  %106 = load <32 x float>, <32 x float>* %105, align 64, !tbaa !1624
  %107 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %101, <32 x float> %106, <32 x float> %96)
  %108 = add nuw nsw i64 %97, 2048
  %109 = getelementptr inbounds float, float* %4, i64 %108
  %110 = load float, float* %109, align 4, !tbaa !1621
  %111 = insertelement <32 x float> undef, float %110, i32 0
  %112 = shufflevector <32 x float> %111, <32 x float> undef, <32 x i32> zeroinitializer
  %113 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %112, <32 x float> %106, <32 x float> %95)
  %114 = add nsw i64 %97, 4096
  %115 = getelementptr inbounds float, float* %4, i64 %114
  %116 = load float, float* %115, align 4, !tbaa !1621
  %117 = insertelement <32 x float> undef, float %116, i32 0
  %118 = shufflevector <32 x float> %117, <32 x float> undef, <32 x i32> zeroinitializer
  %119 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %118, <32 x float> %106, <32 x float> %94)
  %120 = add nsw i64 %97, 6144
  %121 = getelementptr inbounds float, float* %4, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !1621
  %123 = insertelement <32 x float> undef, float %122, i32 0
  %124 = shufflevector <32 x float> %123, <32 x float> undef, <32 x i32> zeroinitializer
  %125 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %124, <32 x float> %106, <32 x float> %93)
  %126 = add nsw i64 %97, 8192
  %127 = getelementptr inbounds float, float* %4, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !1621
  %129 = insertelement <32 x float> undef, float %128, i32 0
  %130 = shufflevector <32 x float> %129, <32 x float> undef, <32 x i32> zeroinitializer
  %131 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %130, <32 x float> %106, <32 x float> %92)
  %132 = add nsw i64 %97, 10240
  %133 = getelementptr inbounds float, float* %4, i64 %132
  %134 = load float, float* %133, align 4, !tbaa !1621
  %135 = insertelement <32 x float> undef, float %134, i32 0
  %136 = shufflevector <32 x float> %135, <32 x float> undef, <32 x i32> zeroinitializer
  %137 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %136, <32 x float> %106, <32 x float> %91)
  %138 = add nsw i64 %97, 12288
  %139 = getelementptr inbounds float, float* %4, i64 %138
  %140 = load float, float* %139, align 4, !tbaa !1621
  %141 = insertelement <32 x float> undef, float %140, i32 0
  %142 = shufflevector <32 x float> %141, <32 x float> undef, <32 x i32> zeroinitializer
  %143 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %142, <32 x float> %106, <32 x float> %90)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for_begin4.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 6
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([99 x i8], [99 x i8]* @.str.181, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !1627
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !1641
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !1644
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !1646
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !1650
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([174 x i8], [174 x i8]* @.str.182, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %77 = getelementptr inbounds i8, i8* %1, i64 4
  %78 = bitcast i8* %77 to i32*
  %79 = load i32, i32* %78, align 4, !tbaa !1652
  switch i32 %79, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([174 x i8], [174 x i8]* @.str.183, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %81 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %81(i8* getelementptr inbounds ([174 x i8], [174 x i8]* @.str.184, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([174 x i8], [174 x i8]* @.str.185, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %83 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %83(i8* getelementptr inbounds ([174 x i8], [174 x i8]* @.str.186, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([174 x i8], [174 x i8]* @.str.187, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  %85 = icmp eq i32 %43, 1
  br i1 %85, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %86 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %86(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %87 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %88 = load i32, i32* %87, align 4
  %89 = icmp eq i32 %88, 5
  br i1 %89, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %91 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %92 = load i16, i16* %91, align 2
  %93 = icmp eq i16 %92, 1
  %94 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %95 = load i8, i8* %94, align 1
  %96 = icmp eq i8 %95, 32
  %97 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %98 = load i8, i8* %97, align 1
  %99 = icmp eq i8 %98, 2
  %100 = and i1 %96, %99
  %101 = and i1 %93, %100
  br i1 %101, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %103 = load i64, i64* %39, align 8, !tbaa !1654
  %104 = trunc i64 %103 to i32
  %105 = icmp eq i32 %104, 1
  br i1 %105, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %107 = getelementptr inbounds i64, i64* %39, i64 1
  %108 = load i64, i64* %107, align 8, !tbaa !1668
  %109 = trunc i64 %108 to i32
  %110 = icmp eq i32 %109, 16
  br i1 %110, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %111 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %111(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %112 = getelementptr inbounds i64, i64* %39, i64 2
  %113 = load i64, i64* %112, align 8, !tbaa !1670
  %114 = trunc i64 %113 to i32
  %115 = icmp eq i32 %114, 56
  br i1 %115, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %116 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %116(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %117 = getelementptr inbounds i64, i64* %39, i64 3
  %118 = load i64, i64* %117, align 8, !tbaa !1673
  %119 = trunc i64 %118 to i32
  %120 = icmp eq i32 %119, 56
  br i1 %120, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %121 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %121(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %122 = getelementptr inbounds i64, i64* %39, i64 4
  %123 = load i64, i64* %122, align 8, !tbaa !1675
  %124 = trunc i64 %123 to i32
  %125 = icmp eq i32 %124, 4
  br i1 %125, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %126 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %126(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %127 = icmp eq i64* %41, null
  br i1 %127, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end28
  %128 = bitcast i64* %41 to <4 x i64>*
  %129 = load <4 x i64>, <4 x i64>* %128, align 8, !tbaa !1679
  %130 = trunc <4 x i64> %129 to <4 x i32>
  %131 = icmp eq <4 x i32> %130, <i32 200704, i32 12544, i32 224, i32 4>
  %132 = getelementptr inbounds i64, i64* %41, i64 4
  %133 = load i64, i64* %132, align 8, !tbaa !1691
  %134 = trunc i64 %133 to i32
  %135 = icmp eq i32 %134, 1
  %rdx.shuf167 = shufflevector <4 x i1> %131, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx168 = and <4 x i1> %131, %rdx.shuf167
  %rdx.shuf169 = shufflevector <4 x i1> %bin.rdx168, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx170 = and <4 x i1> %bin.rdx168, %rdx.shuf169
  %136 = extractelement <4 x i1> %bin.rdx170, i32 0
  %137 = and i1 %136, %135
  br i1 %137, label %if_end, label %assert_fail29, !prof !5

if_end:                                           ; preds = %assert_end28, %if_then
  %138 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %139 = load i64, i64* %138, align 8
  %140 = icmp eq i64 %139, 0
  br i1 %140, label %assert_end32, label %assert_fail31, !prof !5

assert_fail29:                                    ; preds = %if_then
  %141 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %141(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_fail31:                                    ; preds = %if_end
  %142 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %142(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %if_end
  %143 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %144 = load i32, i32* %143, align 4
  %145 = icmp eq i32 %144, 6
  br i1 %145, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %148 = load i16, i16* %147, align 2
  %149 = icmp eq i16 %148, 1
  %150 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %151 = load i8, i8* %150, align 1
  %152 = icmp eq i8 %151, 32
  %153 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %154 = load i8, i8* %153, align 1
  %155 = icmp eq i8 %154, 2
  %156 = and i1 %152, %155
  %157 = and i1 %149, %156
  br i1 %157, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %159 = load i64, i64* %49, align 8, !tbaa !1695
  %160 = trunc i64 %159 to i32
  %161 = icmp eq i32 %160, 8
  br i1 %161, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %162 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %162(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.190, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %163 = getelementptr inbounds i64, i64* %49, i64 1
  %164 = load i64, i64* %163, align 8, !tbaa !1709
  %165 = trunc i64 %164 to i32
  %166 = icmp eq i32 %165, 16
  br i1 %166, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %167 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %167(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.31, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %168 = getelementptr inbounds i64, i64* %49, i64 2
  %169 = load i64, i64* %168, align 8, !tbaa !1711
  %170 = trunc i64 %169 to i32
  %171 = icmp eq i32 %170, 1
  br i1 %171, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %172 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %172(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %173 = getelementptr inbounds i64, i64* %49, i64 3
  %174 = load i64, i64* %173, align 8, !tbaa !1714
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  br i1 %176, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %177 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %177(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %178 = getelementptr inbounds i64, i64* %49, i64 4
  %179 = load i64, i64* %178, align 8, !tbaa !1716
  %180 = trunc i64 %179 to i32
  %181 = icmp eq i32 %180, 4
  br i1 %181, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %182 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %182(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %183 = getelementptr inbounds i64, i64* %49, i64 5
  %184 = load i64, i64* %183, align 8, !tbaa !1720
  %185 = trunc i64 %184 to i32
  %186 = icmp eq i32 %185, 32
  br i1 %186, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %187 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %187(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %188 = icmp eq i64* %51, null
  br i1 %188, label %if_end50, label %if_then49, !prof !50

if_then49:                                        ; preds = %assert_end48
  %189 = bitcast i64* %51 to <4 x i64>*
  %190 = load <4 x i64>, <4 x i64>* %189, align 8, !tbaa !1722
  %191 = trunc <4 x i64> %190 to <4 x i32>
  %192 = icmp eq <4 x i32> %191, <i32 2048, i32 128, i32 128, i32 128>
  %193 = getelementptr inbounds i64, i64* %51, i64 4
  %194 = load i64, i64* %193, align 8, !tbaa !1734
  %195 = trunc i64 %194 to i32
  %196 = icmp eq i32 %195, 32
  %197 = getelementptr inbounds i64, i64* %51, i64 5
  %198 = load i64, i64* %197, align 8, !tbaa !1738
  %199 = trunc i64 %198 to i32
  %200 = icmp eq i32 %199, 1
  %rdx.shuf163 = shufflevector <4 x i1> %192, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx164 = and <4 x i1> %192, %rdx.shuf163
  %rdx.shuf165 = shufflevector <4 x i1> %bin.rdx164, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx166 = and <4 x i1> %bin.rdx164, %rdx.shuf165
  %201 = extractelement <4 x i1> %bin.rdx166, i32 0
  %202 = and i1 %201, %196
  %203 = and i1 %202, %200
  br i1 %203, label %if_end50, label %assert_fail51, !prof !5

if_end50:                                         ; preds = %assert_end48, %if_then49
  %204 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %205 = load i64, i64* %204, align 8
  %206 = icmp eq i64 %205, 0
  br i1 %206, label %assert_end54, label %assert_fail53, !prof !5

assert_fail51:                                    ; preds = %if_then49
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([272 x i8], [272 x i8]* @.str.191, i64 0, i64 0))
  ret i32 -1

assert_fail53:                                    ; preds = %if_end50
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %if_end50
  %209 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %210 = load i32, i32* %209, align 4
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %213 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %214 = load i32, i32* %213, align 4
  %215 = icmp eq i32 %45, %214
  br i1 %215, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %216 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %216(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %217 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %218 = load i32, i32* %217, align 4
  %219 = icmp eq i32 %218, 4
  br i1 %219, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %221 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %222 = load i16, i16* %221, align 2
  %223 = icmp eq i16 %222, 1
  %224 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %225 = load i8, i8* %224, align 1
  %226 = icmp eq i8 %225, 32
  %227 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %228 = load i8, i8* %227, align 1
  %229 = icmp eq i8 %228, 2
  %230 = and i1 %226, %229
  %231 = and i1 %223, %230
  br i1 %231, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %233 = load i64, i64* %55, align 8, !tbaa !1740
  %234 = trunc i64 %233 to i32
  %235 = icmp eq i32 %234, 8
  br i1 %235, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %236 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %236(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.192, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %237 = getelementptr inbounds i64, i64* %55, i64 1
  %238 = load i64, i64* %237, align 8, !tbaa !1754
  %239 = trunc i64 %238 to i32
  %240 = icmp eq i32 %239, 1
  br i1 %240, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %241 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %241(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %242 = getelementptr inbounds i64, i64* %55, i64 2
  %243 = load i64, i64* %242, align 8, !tbaa !1756
  %244 = trunc i64 %243 to i32
  %245 = icmp eq i32 %244, 1
  br i1 %245, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %246 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %246(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %247 = getelementptr inbounds i64, i64* %55, i64 3
  %248 = load i64, i64* %247, align 8, !tbaa !1759
  %249 = trunc i64 %248 to i32
  %250 = icmp eq i32 %249, 32
  br i1 %250, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %251 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %251(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %252 = icmp eq i64* %57, null
  br i1 %252, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %253 = bitcast i64* %57 to <4 x i64>*
  %254 = load <4 x i64>, <4 x i64>* %253, align 8, !tbaa !1761
  %255 = trunc <4 x i64> %254 to <4 x i32>
  %256 = icmp eq <4 x i32> %255, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf159 = shufflevector <4 x i1> %256, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx160 = and <4 x i1> %256, %rdx.shuf159
  %rdx.shuf161 = shufflevector <4 x i1> %bin.rdx160, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx162 = and <4 x i1> %bin.rdx160, %rdx.shuf161
  %257 = extractelement <4 x i1> %bin.rdx162, i32 0
  br i1 %257, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %258 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %259 = load i64, i64* %258, align 8
  %260 = icmp eq i64 %259, 0
  br i1 %260, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %262 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %262(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %263 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %264 = load i32, i32* %263, align 4
  %265 = icmp eq i32 %264, 1
  br i1 %265, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %266 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %266(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %267 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %268 = load i32, i32* %267, align 4
  %269 = icmp eq i32 %45, %268
  br i1 %269, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %270 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %270(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %271 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %272 = load i32, i32* %271, align 4
  %273 = icmp eq i32 %272, 4
  br i1 %273, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %275 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %276 = load i16, i16* %275, align 2
  %277 = icmp eq i16 %276, 1
  %278 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %279 = load i8, i8* %278, align 1
  %280 = icmp eq i8 %279, 32
  %281 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %282 = load i8, i8* %281, align 1
  %283 = icmp eq i8 %282, 2
  %284 = and i1 %280, %283
  %285 = and i1 %277, %284
  br i1 %285, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %287 = load i64, i64* %61, align 8, !tbaa !1773
  %288 = trunc i64 %287 to i32
  %289 = icmp eq i32 %288, 8
  br i1 %289, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %290 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %290(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.193, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %291 = getelementptr inbounds i64, i64* %61, i64 1
  %292 = load i64, i64* %291, align 8, !tbaa !1787
  %293 = trunc i64 %292 to i32
  %294 = icmp eq i32 %293, 1
  br i1 %294, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %295 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %295(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %296 = getelementptr inbounds i64, i64* %61, i64 2
  %297 = load i64, i64* %296, align 8, !tbaa !1789
  %298 = trunc i64 %297 to i32
  %299 = icmp eq i32 %298, 1
  br i1 %299, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %300 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %300(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %301 = getelementptr inbounds i64, i64* %61, i64 3
  %302 = load i64, i64* %301, align 8, !tbaa !1792
  %303 = trunc i64 %302 to i32
  %304 = icmp eq i32 %303, 32
  br i1 %304, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %305 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %305(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %306 = icmp eq i64* %63, null
  br i1 %306, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %307 = bitcast i64* %63 to <4 x i64>*
  %308 = load <4 x i64>, <4 x i64>* %307, align 8, !tbaa !1794
  %309 = trunc <4 x i64> %308 to <4 x i32>
  %310 = icmp eq <4 x i32> %309, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf155 = shufflevector <4 x i1> %310, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx156 = and <4 x i1> %310, %rdx.shuf155
  %rdx.shuf157 = shufflevector <4 x i1> %bin.rdx156, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx158 = and <4 x i1> %bin.rdx156, %rdx.shuf157
  %311 = extractelement <4 x i1> %bin.rdx158, i32 0
  br i1 %311, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %312 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %313 = load i64, i64* %312, align 8
  %314 = icmp eq i64 %313, 0
  br i1 %314, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %317 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %318, 1
  br i1 %319, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %321 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %322 = load i32, i32* %321, align 4
  %323 = icmp eq i32 %45, %322
  br i1 %323, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %325 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %326 = load i32, i32* %325, align 4
  %327 = icmp eq i32 %326, 4
  br i1 %327, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %329 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %330 = load i16, i16* %329, align 2
  %331 = icmp eq i16 %330, 1
  %332 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %333 = load i8, i8* %332, align 1
  %334 = icmp eq i8 %333, 32
  %335 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %336 = load i8, i8* %335, align 1
  %337 = icmp eq i8 %336, 2
  %338 = and i1 %334, %337
  %339 = and i1 %331, %338
  br i1 %339, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %340 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %340(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %341 = load i64, i64* %67, align 8, !tbaa !1806
  %342 = trunc i64 %341 to i32
  %343 = icmp eq i32 %342, 8
  br i1 %343, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %344 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %344(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.194, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %345 = getelementptr inbounds i64, i64* %67, i64 1
  %346 = load i64, i64* %345, align 8, !tbaa !1820
  %347 = trunc i64 %346 to i32
  %348 = icmp eq i32 %347, 1
  br i1 %348, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %350 = getelementptr inbounds i64, i64* %67, i64 2
  %351 = load i64, i64* %350, align 8, !tbaa !1822
  %352 = trunc i64 %351 to i32
  %353 = icmp eq i32 %352, 1
  br i1 %353, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %354 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %354(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %355 = getelementptr inbounds i64, i64* %67, i64 3
  %356 = load i64, i64* %355, align 8, !tbaa !1825
  %357 = trunc i64 %356 to i32
  %358 = icmp eq i32 %357, 32
  br i1 %358, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %359 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %359(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.167, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %360 = icmp eq i64* %69, null
  br i1 %360, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %361 = bitcast i64* %69 to <4 x i64>*
  %362 = load <4 x i64>, <4 x i64>* %361, align 8, !tbaa !1827
  %363 = trunc <4 x i64> %362 to <4 x i32>
  %364 = icmp eq <4 x i32> %363, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf151 = shufflevector <4 x i1> %364, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx152 = and <4 x i1> %364, %rdx.shuf151
  %rdx.shuf153 = shufflevector <4 x i1> %bin.rdx152, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx154 = and <4 x i1> %bin.rdx152, %rdx.shuf153
  %365 = extractelement <4 x i1> %bin.rdx154, i32 0
  br i1 %365, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %366 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %367 = load i64, i64* %366, align 8
  %368 = icmp eq i64 %367, 0
  br i1 %368, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %369 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %369(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.168, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %370 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %370(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %371 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %372 = load i32, i32* %371, align 4
  %373 = icmp eq i32 %372, 1
  br i1 %373, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %374 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %374(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %375 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %376 = load i32, i32* %375, align 4
  %377 = icmp eq i32 %45, %376
  br i1 %377, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %378 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %378(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %379 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %380 = load i32, i32* %379, align 4
  %381 = icmp eq i32 %380, 5
  br i1 %381, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %383 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %384 = load i16, i16* %383, align 2
  %385 = icmp eq i16 %384, 1
  %386 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %387 = load i8, i8* %386, align 1
  %388 = icmp eq i8 %387, 32
  %389 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %390 = load i8, i8* %389, align 1
  %391 = icmp eq i8 %390, 2
  %392 = and i1 %388, %391
  %393 = and i1 %385, %392
  br i1 %393, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %394 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %394(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %395 = load i64, i64* %73, align 8, !tbaa !1839
  %396 = trunc i64 %395 to i32
  %397 = icmp eq i32 %396, 1
  br i1 %397, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %398 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %398(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %399 = getelementptr inbounds i64, i64* %73, i64 1
  %400 = load i64, i64* %399, align 8, !tbaa !1853
  %401 = trunc i64 %400 to i32
  %402 = icmp eq i32 %401, 8
  br i1 %402, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %403 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %403(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.195, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %404 = getelementptr inbounds i64, i64* %73, i64 2
  %405 = load i64, i64* %404, align 8, !tbaa !1855
  %406 = trunc i64 %405 to i32
  %407 = icmp eq i32 %406, 56
  br i1 %407, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %408 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %408(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.196, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %409 = getelementptr inbounds i64, i64* %73, i64 3
  %410 = load i64, i64* %409, align 8, !tbaa !1858
  %411 = trunc i64 %410 to i32
  %412 = icmp eq i32 %411, 56
  br i1 %412, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %413 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %413(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.197, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %414 = getelementptr inbounds i64, i64* %73, i64 4
  %415 = load i64, i64* %414, align 8, !tbaa !1860
  %416 = trunc i64 %415 to i32
  %417 = icmp eq i32 %416, 32
  br i1 %417, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %418 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %418(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.175, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %419 = icmp eq i64* %75, null
  br i1 %419, label %if_end140, label %if_then139, !prof !50

if_then139:                                       ; preds = %assert_end138
  %420 = bitcast i64* %75 to <4 x i64>*
  %421 = load <4 x i64>, <4 x i64>* %420, align 8, !tbaa !1864
  %422 = trunc <4 x i64> %421 to <4 x i32>
  %423 = icmp eq <4 x i32> %422, <i32 802816, i32 100352, i32 1792, i32 32>
  %424 = getelementptr inbounds i64, i64* %75, i64 4
  %425 = load i64, i64* %424, align 8, !tbaa !1876
  %426 = trunc i64 %425 to i32
  %427 = icmp eq i32 %426, 1
  %rdx.shuf = shufflevector <4 x i1> %423, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %423, %rdx.shuf
  %rdx.shuf149 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx150 = and <4 x i1> %bin.rdx, %rdx.shuf149
  %428 = extractelement <4 x i1> %bin.rdx150, i32 0
  %429 = and i1 %428, %427
  br i1 %429, label %if_end140, label %assert_fail141, !prof !5

if_end140:                                        ; preds = %assert_end138, %if_then139
  %430 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %431 = load i64, i64* %430, align 8
  %432 = icmp eq i64 %431, 0
  br i1 %432, label %assert_end144, label %assert_fail143, !prof !5

assert_fail141:                                   ; preds = %if_then139
  %433 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %433(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.198, i64 0, i64 0))
  ret i32 -1

assert_fail143:                                   ; preds = %if_end140
  %434 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %434(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end144:                                    ; preds = %if_end140
  %435 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %436 = load i32, i32* %435, align 4
  %437 = icmp eq i32 %436, 1
  br i1 %437, label %assert_end146, label %assert_fail145, !prof !5

assert_fail145:                                   ; preds = %assert_end144
  %438 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %438(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %assert_end144
  %439 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %440 = load i32, i32* %439, align 4
  %441 = icmp eq i32 %45, %440
  br i1 %441, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %442 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %442(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %443 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_compute_(i8* %37, i8* %47, i8* %71, i8* %53, i8* %59, i8* %65, i32 %45)
  ret i32 %443
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %15, align 8
  %8 = getelementptr inbounds %15, %15* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %15, %15* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %15, %15* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %15, %15* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %15, %15* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %15, %15* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %15, %15* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %15* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.199, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.199(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 447
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 448
  %30 = select i1 %29, i32 %28, i32 448
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 448
  %33 = select i1 %32, i32 %31, i32 448
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_begin10.preheader
  %indvars.iv61 = phi i64 [ %37, %for_body.preheader ], [ %indvars.iv.next62, %for_begin10.preheader ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %40 = tail call i8* %39(i32 1, i32 %22, i64 7168, i32 2, i32 32)
  %41 = bitcast i8* %40 to float*
  %42 = trunc i64 %indvars.iv61 to i32
  %43 = srem i32 %42, 56
  %44 = mul nsw i32 %43, 224
  %45 = sdiv i32 %42, 56
  %46 = shl i32 %45, 11
  %47 = sext i32 %46 to i64
  %48 = sext i32 %44 to i64
  br label %for_body2

for_end:                                          ; preds = %for_begin10.preheader, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end6
  %49 = mul nsw i64 %indvars.iv61, 1792
  %50 = shl nsw i32 %45, 5
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds float, float* %13, i64 %51
  %53 = bitcast float* %52 to <32 x float>*
  %54 = load <32 x float>, <32 x float>* %53, align 64, !tbaa !1880
  %55 = getelementptr inbounds float, float* %16, i64 %51
  %56 = bitcast float* %55 to <32 x float>*
  %57 = load <32 x float>, <32 x float>* %56, align 64, !tbaa !1883
  %58 = getelementptr inbounds float, float* %19, i64 %51
  %59 = bitcast float* %58 to <32 x float>*
  %60 = load <32 x float>, <32 x float>* %59, align 64, !tbaa !1886
  %61 = bitcast i8* %40 to <32 x float>*
  %62 = load <32 x float>, <32 x float>* %61, align 64, !tbaa !1889
  %63 = fadd <32 x float> %54, %62
  %64 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %63, <32 x float> %57, <32 x float> %60)
  %65 = getelementptr inbounds float, float* %10, i64 %49
  %66 = bitcast float* %65 to <32 x float>*
  store <32 x float> %64, <32 x float>* %66, align 64, !tbaa !1892
  %67 = getelementptr inbounds i8, i8* %40, i64 128
  %68 = bitcast i8* %67 to <32 x float>*
  %69 = load <32 x float>, <32 x float>* %68, align 64, !tbaa !1889
  %70 = fadd <32 x float> %54, %69
  %71 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %70, <32 x float> %57, <32 x float> %60)
  %72 = mul i64 %indvars.iv61, 7696581394432
  %sext = ashr exact i64 %72, 32
  %73 = or i64 %sext, 32
  %74 = getelementptr inbounds float, float* %10, i64 %73
  %75 = bitcast float* %74 to <32 x float>*
  store <32 x float> %71, <32 x float>* %75, align 64, !tbaa !1892
  %76 = getelementptr inbounds i8, i8* %40, i64 256
  %77 = bitcast i8* %76 to <32 x float>*
  %78 = load <32 x float>, <32 x float>* %77, align 64, !tbaa !1889
  %79 = fadd <32 x float> %54, %78
  %80 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %79, <32 x float> %57, <32 x float> %60)
  %81 = mul i64 %indvars.iv61, 7696581394432
  %sext63 = ashr exact i64 %81, 32
  %82 = or i64 %sext63, 64
  %83 = getelementptr inbounds float, float* %10, i64 %82
  %84 = bitcast float* %83 to <32 x float>*
  store <32 x float> %80, <32 x float>* %84, align 64, !tbaa !1892
  %85 = getelementptr inbounds i8, i8* %40, i64 384
  %86 = bitcast i8* %85 to <32 x float>*
  %87 = load <32 x float>, <32 x float>* %86, align 64, !tbaa !1889
  %88 = fadd <32 x float> %54, %87
  %89 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %88, <32 x float> %57, <32 x float> %60)
  %90 = mul i64 %indvars.iv61, 7696581394432
  %sext64 = ashr exact i64 %90, 32
  %91 = or i64 %sext64, 96
  %92 = getelementptr inbounds float, float* %10, i64 %91
  %93 = bitcast float* %92 to <32 x float>*
  store <32 x float> %89, <32 x float>* %93, align 64, !tbaa !1892
  %94 = getelementptr inbounds i8, i8* %40, i64 512
  %95 = bitcast i8* %94 to <32 x float>*
  %96 = load <32 x float>, <32 x float>* %95, align 64, !tbaa !1889
  %97 = fadd <32 x float> %54, %96
  %98 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %97, <32 x float> %57, <32 x float> %60)
  %99 = mul i64 %indvars.iv61, 7696581394432
  %sext65 = ashr exact i64 %99, 32
  %100 = or i64 %sext65, 128
  %101 = getelementptr inbounds float, float* %10, i64 %100
  %102 = bitcast float* %101 to <32 x float>*
  store <32 x float> %98, <32 x float>* %102, align 64, !tbaa !1892
  %103 = getelementptr inbounds i8, i8* %40, i64 640
  %104 = bitcast i8* %103 to <32 x float>*
  %105 = load <32 x float>, <32 x float>* %104, align 64, !tbaa !1889
  %106 = fadd <32 x float> %54, %105
  %107 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %106, <32 x float> %57, <32 x float> %60)
  %108 = mul i64 %indvars.iv61, 7696581394432
  %sext66 = ashr exact i64 %108, 32
  %109 = or i64 %sext66, 160
  %110 = getelementptr inbounds float, float* %10, i64 %109
  %111 = bitcast float* %110 to <32 x float>*
  store <32 x float> %107, <32 x float>* %111, align 64, !tbaa !1892
  %112 = getelementptr inbounds i8, i8* %40, i64 768
  %113 = bitcast i8* %112 to <32 x float>*
  %114 = load <32 x float>, <32 x float>* %113, align 64, !tbaa !1889
  %115 = fadd <32 x float> %54, %114
  %116 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %115, <32 x float> %57, <32 x float> %60)
  %117 = mul i64 %indvars.iv61, 7696581394432
  %sext67 = ashr exact i64 %117, 32
  %118 = or i64 %sext67, 192
  %119 = getelementptr inbounds float, float* %10, i64 %118
  %120 = bitcast float* %119 to <32 x float>*
  store <32 x float> %116, <32 x float>* %120, align 64, !tbaa !1892
  %121 = getelementptr inbounds i8, i8* %40, i64 896
  %122 = bitcast i8* %121 to <32 x float>*
  %123 = load <32 x float>, <32 x float>* %122, align 64, !tbaa !1889
  %124 = fadd <32 x float> %54, %123
  %125 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %124, <32 x float> %57, <32 x float> %60)
  %126 = mul i64 %indvars.iv61, 7696581394432
  %sext68 = ashr exact i64 %126, 32
  %127 = or i64 %sext68, 224
  %128 = getelementptr inbounds float, float* %10, i64 %127
  %129 = bitcast float* %128 to <32 x float>*
  store <32 x float> %125, <32 x float>* %129, align 64, !tbaa !1892
  %130 = getelementptr inbounds i8, i8* %40, i64 1024
  %131 = bitcast i8* %130 to <32 x float>*
  %132 = load <32 x float>, <32 x float>* %131, align 64, !tbaa !1889
  %133 = fadd <32 x float> %54, %132
  %134 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %133, <32 x float> %57, <32 x float> %60)
  %135 = mul i64 %indvars.iv61, 7696581394432
  %sext69 = add i64 %135, 1099511627776
  %136 = ashr exact i64 %sext69, 32
  %137 = getelementptr inbounds float, float* %10, i64 %136
  %138 = bitcast float* %137 to <32 x float>*
  store <32 x float> %134, <32 x float>* %138, align 64, !tbaa !1892
  %139 = getelementptr inbounds i8, i8* %40, i64 1152
  %140 = bitcast i8* %139 to <32 x float>*
  %141 = load <32 x float>, <32 x float>* %140, align 64, !tbaa !1889
  %142 = fadd <32 x float> %54, %141
  %143 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %142, <32 x float> %57, <32 x float> %60)
  %144 = mul i64 %indvars.iv61, 7696581394432
  %sext70 = add i64 %144, 1236950581248
  %145 = ashr exact i64 %sext70, 32
  %146 = getelementptr inbounds float, float* %10, i64 %145
  %147 = bitcast float* %146 to <32 x float>*
  store <32 x float> %143, <32 x float>* %147, align 64, !tbaa !1892
  %148 = getelementptr inbounds i8, i8* %40, i64 1280
  %149 = bitcast i8* %148 to <32 x float>*
  %150 = load <32 x float>, <32 x float>* %149, align 64, !tbaa !1889
  %151 = fadd <32 x float> %54, %150
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %151, <32 x float> %57, <32 x float> %60)
  %153 = mul i64 %indvars.iv61, 7696581394432
  %sext71 = add i64 %153, 1374389534720
  %154 = ashr exact i64 %sext71, 32
  %155 = getelementptr inbounds float, float* %10, i64 %154
  %156 = bitcast float* %155 to <32 x float>*
  store <32 x float> %152, <32 x float>* %156, align 64, !tbaa !1892
  %157 = getelementptr inbounds i8, i8* %40, i64 1408
  %158 = bitcast i8* %157 to <32 x float>*
  %159 = load <32 x float>, <32 x float>* %158, align 64, !tbaa !1889
  %160 = fadd <32 x float> %54, %159
  %161 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %160, <32 x float> %57, <32 x float> %60)
  %162 = mul i64 %indvars.iv61, 7696581394432
  %sext72 = add i64 %162, 1511828488192
  %163 = ashr exact i64 %sext72, 32
  %164 = getelementptr inbounds float, float* %10, i64 %163
  %165 = bitcast float* %164 to <32 x float>*
  store <32 x float> %161, <32 x float>* %165, align 64, !tbaa !1892
  %166 = getelementptr inbounds i8, i8* %40, i64 1536
  %167 = bitcast i8* %166 to <32 x float>*
  %168 = load <32 x float>, <32 x float>* %167, align 64, !tbaa !1889
  %169 = fadd <32 x float> %54, %168
  %170 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %169, <32 x float> %57, <32 x float> %60)
  %171 = mul i64 %indvars.iv61, 7696581394432
  %sext73 = add i64 %171, 1649267441664
  %172 = ashr exact i64 %sext73, 32
  %173 = getelementptr inbounds float, float* %10, i64 %172
  %174 = bitcast float* %173 to <32 x float>*
  store <32 x float> %170, <32 x float>* %174, align 64, !tbaa !1892
  %175 = getelementptr inbounds i8, i8* %40, i64 1664
  %176 = bitcast i8* %175 to <32 x float>*
  %177 = load <32 x float>, <32 x float>* %176, align 64, !tbaa !1889
  %178 = fadd <32 x float> %54, %177
  %179 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %178, <32 x float> %57, <32 x float> %60)
  %180 = mul i64 %indvars.iv61, 7696581394432
  %sext74 = add i64 %180, 1786706395136
  %181 = ashr exact i64 %sext74, 32
  %182 = getelementptr inbounds float, float* %10, i64 %181
  %183 = bitcast float* %182 to <32 x float>*
  store <32 x float> %179, <32 x float>* %183, align 64, !tbaa !1892
  %184 = getelementptr inbounds i8, i8* %40, i64 1792
  %185 = bitcast i8* %184 to <32 x float>*
  %186 = load <32 x float>, <32 x float>* %185, align 64, !tbaa !1889
  %187 = fadd <32 x float> %54, %186
  %188 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %187, <32 x float> %57, <32 x float> %60)
  %189 = mul i64 %indvars.iv61, 7696581394432
  %sext75 = add i64 %189, 1924145348608
  %190 = ashr exact i64 %sext75, 32
  %191 = getelementptr inbounds float, float* %10, i64 %190
  %192 = bitcast float* %191 to <32 x float>*
  store <32 x float> %188, <32 x float>* %192, align 64, !tbaa !1892
  %193 = getelementptr inbounds i8, i8* %40, i64 1920
  %194 = bitcast i8* %193 to <32 x float>*
  %195 = load <32 x float>, <32 x float>* %194, align 64, !tbaa !1889
  %196 = fadd <32 x float> %54, %195
  %197 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %196, <32 x float> %57, <32 x float> %60)
  %198 = mul i64 %indvars.iv61, 7696581394432
  %sext76 = add i64 %198, 2061584302080
  %199 = ashr exact i64 %sext76, 32
  %200 = getelementptr inbounds float, float* %10, i64 %199
  %201 = bitcast float* %200 to <32 x float>*
  store <32 x float> %197, <32 x float>* %201, align 64, !tbaa !1892
  %202 = getelementptr inbounds i8, i8* %40, i64 2048
  %203 = bitcast i8* %202 to <32 x float>*
  %204 = load <32 x float>, <32 x float>* %203, align 64, !tbaa !1889
  %205 = fadd <32 x float> %54, %204
  %206 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %205, <32 x float> %57, <32 x float> %60)
  %207 = mul i64 %indvars.iv61, 7696581394432
  %sext77 = add i64 %207, 2199023255552
  %208 = ashr exact i64 %sext77, 32
  %209 = getelementptr inbounds float, float* %10, i64 %208
  %210 = bitcast float* %209 to <32 x float>*
  store <32 x float> %206, <32 x float>* %210, align 64, !tbaa !1892
  %211 = getelementptr inbounds i8, i8* %40, i64 2176
  %212 = bitcast i8* %211 to <32 x float>*
  %213 = load <32 x float>, <32 x float>* %212, align 64, !tbaa !1889
  %214 = fadd <32 x float> %54, %213
  %215 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %214, <32 x float> %57, <32 x float> %60)
  %216 = mul i64 %indvars.iv61, 7696581394432
  %sext78 = add i64 %216, 2336462209024
  %217 = ashr exact i64 %sext78, 32
  %218 = getelementptr inbounds float, float* %10, i64 %217
  %219 = bitcast float* %218 to <32 x float>*
  store <32 x float> %215, <32 x float>* %219, align 64, !tbaa !1892
  %220 = getelementptr inbounds i8, i8* %40, i64 2304
  %221 = bitcast i8* %220 to <32 x float>*
  %222 = load <32 x float>, <32 x float>* %221, align 64, !tbaa !1889
  %223 = fadd <32 x float> %54, %222
  %224 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %223, <32 x float> %57, <32 x float> %60)
  %225 = mul i64 %indvars.iv61, 7696581394432
  %sext79 = add i64 %225, 2473901162496
  %226 = ashr exact i64 %sext79, 32
  %227 = getelementptr inbounds float, float* %10, i64 %226
  %228 = bitcast float* %227 to <32 x float>*
  store <32 x float> %224, <32 x float>* %228, align 64, !tbaa !1892
  %229 = getelementptr inbounds i8, i8* %40, i64 2432
  %230 = bitcast i8* %229 to <32 x float>*
  %231 = load <32 x float>, <32 x float>* %230, align 64, !tbaa !1889
  %232 = fadd <32 x float> %54, %231
  %233 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %232, <32 x float> %57, <32 x float> %60)
  %234 = mul i64 %indvars.iv61, 7696581394432
  %sext80 = add i64 %234, 2611340115968
  %235 = ashr exact i64 %sext80, 32
  %236 = getelementptr inbounds float, float* %10, i64 %235
  %237 = bitcast float* %236 to <32 x float>*
  store <32 x float> %233, <32 x float>* %237, align 64, !tbaa !1892
  %238 = getelementptr inbounds i8, i8* %40, i64 2560
  %239 = bitcast i8* %238 to <32 x float>*
  %240 = load <32 x float>, <32 x float>* %239, align 64, !tbaa !1889
  %241 = fadd <32 x float> %54, %240
  %242 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %241, <32 x float> %57, <32 x float> %60)
  %243 = mul i64 %indvars.iv61, 7696581394432
  %sext81 = add i64 %243, 2748779069440
  %244 = ashr exact i64 %sext81, 32
  %245 = getelementptr inbounds float, float* %10, i64 %244
  %246 = bitcast float* %245 to <32 x float>*
  store <32 x float> %242, <32 x float>* %246, align 64, !tbaa !1892
  %247 = getelementptr inbounds i8, i8* %40, i64 2688
  %248 = bitcast i8* %247 to <32 x float>*
  %249 = load <32 x float>, <32 x float>* %248, align 64, !tbaa !1889
  %250 = fadd <32 x float> %54, %249
  %251 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %250, <32 x float> %57, <32 x float> %60)
  %252 = mul i64 %indvars.iv61, 7696581394432
  %sext82 = add i64 %252, 2886218022912
  %253 = ashr exact i64 %sext82, 32
  %254 = getelementptr inbounds float, float* %10, i64 %253
  %255 = bitcast float* %254 to <32 x float>*
  store <32 x float> %251, <32 x float>* %255, align 64, !tbaa !1892
  %256 = getelementptr inbounds i8, i8* %40, i64 2816
  %257 = bitcast i8* %256 to <32 x float>*
  %258 = load <32 x float>, <32 x float>* %257, align 64, !tbaa !1889
  %259 = fadd <32 x float> %54, %258
  %260 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %259, <32 x float> %57, <32 x float> %60)
  %261 = mul i64 %indvars.iv61, 7696581394432
  %sext83 = add i64 %261, 3023656976384
  %262 = ashr exact i64 %sext83, 32
  %263 = getelementptr inbounds float, float* %10, i64 %262
  %264 = bitcast float* %263 to <32 x float>*
  store <32 x float> %260, <32 x float>* %264, align 64, !tbaa !1892
  %265 = getelementptr inbounds i8, i8* %40, i64 2944
  %266 = bitcast i8* %265 to <32 x float>*
  %267 = load <32 x float>, <32 x float>* %266, align 64, !tbaa !1889
  %268 = fadd <32 x float> %54, %267
  %269 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %268, <32 x float> %57, <32 x float> %60)
  %270 = mul i64 %indvars.iv61, 7696581394432
  %sext84 = add i64 %270, 3161095929856
  %271 = ashr exact i64 %sext84, 32
  %272 = getelementptr inbounds float, float* %10, i64 %271
  %273 = bitcast float* %272 to <32 x float>*
  store <32 x float> %269, <32 x float>* %273, align 64, !tbaa !1892
  %274 = getelementptr inbounds i8, i8* %40, i64 3072
  %275 = bitcast i8* %274 to <32 x float>*
  %276 = load <32 x float>, <32 x float>* %275, align 64, !tbaa !1889
  %277 = fadd <32 x float> %54, %276
  %278 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %277, <32 x float> %57, <32 x float> %60)
  %279 = mul i64 %indvars.iv61, 7696581394432
  %sext85 = add i64 %279, 3298534883328
  %280 = ashr exact i64 %sext85, 32
  %281 = getelementptr inbounds float, float* %10, i64 %280
  %282 = bitcast float* %281 to <32 x float>*
  store <32 x float> %278, <32 x float>* %282, align 64, !tbaa !1892
  %283 = getelementptr inbounds i8, i8* %40, i64 3200
  %284 = bitcast i8* %283 to <32 x float>*
  %285 = load <32 x float>, <32 x float>* %284, align 64, !tbaa !1889
  %286 = fadd <32 x float> %54, %285
  %287 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %286, <32 x float> %57, <32 x float> %60)
  %288 = mul i64 %indvars.iv61, 7696581394432
  %sext86 = add i64 %288, 3435973836800
  %289 = ashr exact i64 %sext86, 32
  %290 = getelementptr inbounds float, float* %10, i64 %289
  %291 = bitcast float* %290 to <32 x float>*
  store <32 x float> %287, <32 x float>* %291, align 64, !tbaa !1892
  %292 = getelementptr inbounds i8, i8* %40, i64 3328
  %293 = bitcast i8* %292 to <32 x float>*
  %294 = load <32 x float>, <32 x float>* %293, align 64, !tbaa !1889
  %295 = fadd <32 x float> %54, %294
  %296 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %295, <32 x float> %57, <32 x float> %60)
  %297 = mul i64 %indvars.iv61, 7696581394432
  %sext87 = add i64 %297, 3573412790272
  %298 = ashr exact i64 %sext87, 32
  %299 = getelementptr inbounds float, float* %10, i64 %298
  %300 = bitcast float* %299 to <32 x float>*
  store <32 x float> %296, <32 x float>* %300, align 64, !tbaa !1892
  %301 = getelementptr inbounds i8, i8* %40, i64 3456
  %302 = bitcast i8* %301 to <32 x float>*
  %303 = load <32 x float>, <32 x float>* %302, align 64, !tbaa !1889
  %304 = fadd <32 x float> %54, %303
  %305 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %304, <32 x float> %57, <32 x float> %60)
  %306 = mul i64 %indvars.iv61, 7696581394432
  %sext88 = add i64 %306, 3710851743744
  %307 = ashr exact i64 %sext88, 32
  %308 = getelementptr inbounds float, float* %10, i64 %307
  %309 = bitcast float* %308 to <32 x float>*
  store <32 x float> %305, <32 x float>* %309, align 64, !tbaa !1892
  %310 = getelementptr inbounds i8, i8* %40, i64 3584
  %311 = bitcast i8* %310 to <32 x float>*
  %312 = load <32 x float>, <32 x float>* %311, align 64, !tbaa !1889
  %313 = fadd <32 x float> %54, %312
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %313, <32 x float> %57, <32 x float> %60)
  %315 = mul i64 %indvars.iv61, 7696581394432
  %sext89 = add i64 %315, 3848290697216
  %316 = ashr exact i64 %sext89, 32
  %317 = getelementptr inbounds float, float* %10, i64 %316
  %318 = bitcast float* %317 to <32 x float>*
  store <32 x float> %314, <32 x float>* %318, align 64, !tbaa !1892
  %319 = getelementptr inbounds i8, i8* %40, i64 3712
  %320 = bitcast i8* %319 to <32 x float>*
  %321 = load <32 x float>, <32 x float>* %320, align 64, !tbaa !1889
  %322 = fadd <32 x float> %54, %321
  %323 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %322, <32 x float> %57, <32 x float> %60)
  %324 = mul i64 %indvars.iv61, 7696581394432
  %sext90 = add i64 %324, 3985729650688
  %325 = ashr exact i64 %sext90, 32
  %326 = getelementptr inbounds float, float* %10, i64 %325
  %327 = bitcast float* %326 to <32 x float>*
  store <32 x float> %323, <32 x float>* %327, align 64, !tbaa !1892
  %328 = getelementptr inbounds i8, i8* %40, i64 3840
  %329 = bitcast i8* %328 to <32 x float>*
  %330 = load <32 x float>, <32 x float>* %329, align 64, !tbaa !1889
  %331 = fadd <32 x float> %54, %330
  %332 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %331, <32 x float> %57, <32 x float> %60)
  %333 = mul i64 %indvars.iv61, 7696581394432
  %sext91 = add i64 %333, 4123168604160
  %334 = ashr exact i64 %sext91, 32
  %335 = getelementptr inbounds float, float* %10, i64 %334
  %336 = bitcast float* %335 to <32 x float>*
  store <32 x float> %332, <32 x float>* %336, align 64, !tbaa !1892
  %337 = getelementptr inbounds i8, i8* %40, i64 3968
  %338 = bitcast i8* %337 to <32 x float>*
  %339 = load <32 x float>, <32 x float>* %338, align 64, !tbaa !1889
  %340 = fadd <32 x float> %54, %339
  %341 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %340, <32 x float> %57, <32 x float> %60)
  %342 = mul i64 %indvars.iv61, 7696581394432
  %sext92 = add i64 %342, 4260607557632
  %343 = ashr exact i64 %sext92, 32
  %344 = getelementptr inbounds float, float* %10, i64 %343
  %345 = bitcast float* %344 to <32 x float>*
  store <32 x float> %341, <32 x float>* %345, align 64, !tbaa !1892
  %346 = getelementptr inbounds i8, i8* %40, i64 4096
  %347 = bitcast i8* %346 to <32 x float>*
  %348 = load <32 x float>, <32 x float>* %347, align 64, !tbaa !1889
  %349 = fadd <32 x float> %54, %348
  %350 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %349, <32 x float> %57, <32 x float> %60)
  %351 = mul i64 %indvars.iv61, 7696581394432
  %sext93 = add i64 %351, 4398046511104
  %352 = ashr exact i64 %sext93, 32
  %353 = getelementptr inbounds float, float* %10, i64 %352
  %354 = bitcast float* %353 to <32 x float>*
  store <32 x float> %350, <32 x float>* %354, align 64, !tbaa !1892
  %355 = getelementptr inbounds i8, i8* %40, i64 4224
  %356 = bitcast i8* %355 to <32 x float>*
  %357 = load <32 x float>, <32 x float>* %356, align 64, !tbaa !1889
  %358 = fadd <32 x float> %54, %357
  %359 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %358, <32 x float> %57, <32 x float> %60)
  %360 = mul i64 %indvars.iv61, 7696581394432
  %sext94 = add i64 %360, 4535485464576
  %361 = ashr exact i64 %sext94, 32
  %362 = getelementptr inbounds float, float* %10, i64 %361
  %363 = bitcast float* %362 to <32 x float>*
  store <32 x float> %359, <32 x float>* %363, align 64, !tbaa !1892
  %364 = getelementptr inbounds i8, i8* %40, i64 4352
  %365 = bitcast i8* %364 to <32 x float>*
  %366 = load <32 x float>, <32 x float>* %365, align 64, !tbaa !1889
  %367 = fadd <32 x float> %54, %366
  %368 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %367, <32 x float> %57, <32 x float> %60)
  %369 = mul i64 %indvars.iv61, 7696581394432
  %sext95 = add i64 %369, 4672924418048
  %370 = ashr exact i64 %sext95, 32
  %371 = getelementptr inbounds float, float* %10, i64 %370
  %372 = bitcast float* %371 to <32 x float>*
  store <32 x float> %368, <32 x float>* %372, align 64, !tbaa !1892
  %373 = getelementptr inbounds i8, i8* %40, i64 4480
  %374 = bitcast i8* %373 to <32 x float>*
  %375 = load <32 x float>, <32 x float>* %374, align 64, !tbaa !1889
  %376 = fadd <32 x float> %54, %375
  %377 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %376, <32 x float> %57, <32 x float> %60)
  %378 = mul i64 %indvars.iv61, 7696581394432
  %sext96 = add i64 %378, 4810363371520
  %379 = ashr exact i64 %sext96, 32
  %380 = getelementptr inbounds float, float* %10, i64 %379
  %381 = bitcast float* %380 to <32 x float>*
  store <32 x float> %377, <32 x float>* %381, align 64, !tbaa !1892
  %382 = getelementptr inbounds i8, i8* %40, i64 4608
  %383 = bitcast i8* %382 to <32 x float>*
  %384 = load <32 x float>, <32 x float>* %383, align 64, !tbaa !1889
  %385 = fadd <32 x float> %54, %384
  %386 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %385, <32 x float> %57, <32 x float> %60)
  %387 = mul i64 %indvars.iv61, 7696581394432
  %sext97 = add i64 %387, 4947802324992
  %388 = ashr exact i64 %sext97, 32
  %389 = getelementptr inbounds float, float* %10, i64 %388
  %390 = bitcast float* %389 to <32 x float>*
  store <32 x float> %386, <32 x float>* %390, align 64, !tbaa !1892
  %391 = getelementptr inbounds i8, i8* %40, i64 4736
  %392 = bitcast i8* %391 to <32 x float>*
  %393 = load <32 x float>, <32 x float>* %392, align 64, !tbaa !1889
  %394 = fadd <32 x float> %54, %393
  %395 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %394, <32 x float> %57, <32 x float> %60)
  %396 = mul i64 %indvars.iv61, 7696581394432
  %sext98 = add i64 %396, 5085241278464
  %397 = ashr exact i64 %sext98, 32
  %398 = getelementptr inbounds float, float* %10, i64 %397
  %399 = bitcast float* %398 to <32 x float>*
  store <32 x float> %395, <32 x float>* %399, align 64, !tbaa !1892
  %400 = getelementptr inbounds i8, i8* %40, i64 4864
  %401 = bitcast i8* %400 to <32 x float>*
  %402 = load <32 x float>, <32 x float>* %401, align 64, !tbaa !1889
  %403 = fadd <32 x float> %54, %402
  %404 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %403, <32 x float> %57, <32 x float> %60)
  %405 = mul i64 %indvars.iv61, 7696581394432
  %sext99 = add i64 %405, 5222680231936
  %406 = ashr exact i64 %sext99, 32
  %407 = getelementptr inbounds float, float* %10, i64 %406
  %408 = bitcast float* %407 to <32 x float>*
  store <32 x float> %404, <32 x float>* %408, align 64, !tbaa !1892
  %409 = getelementptr inbounds i8, i8* %40, i64 4992
  %410 = bitcast i8* %409 to <32 x float>*
  %411 = load <32 x float>, <32 x float>* %410, align 64, !tbaa !1889
  %412 = fadd <32 x float> %54, %411
  %413 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %412, <32 x float> %57, <32 x float> %60)
  %414 = mul i64 %indvars.iv61, 7696581394432
  %sext100 = add i64 %414, 5360119185408
  %415 = ashr exact i64 %sext100, 32
  %416 = getelementptr inbounds float, float* %10, i64 %415
  %417 = bitcast float* %416 to <32 x float>*
  store <32 x float> %413, <32 x float>* %417, align 64, !tbaa !1892
  %418 = getelementptr inbounds i8, i8* %40, i64 5120
  %419 = bitcast i8* %418 to <32 x float>*
  %420 = load <32 x float>, <32 x float>* %419, align 64, !tbaa !1889
  %421 = fadd <32 x float> %54, %420
  %422 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %57, <32 x float> %60)
  %423 = mul i64 %indvars.iv61, 7696581394432
  %sext101 = add i64 %423, 5497558138880
  %424 = ashr exact i64 %sext101, 32
  %425 = getelementptr inbounds float, float* %10, i64 %424
  %426 = bitcast float* %425 to <32 x float>*
  store <32 x float> %422, <32 x float>* %426, align 64, !tbaa !1892
  %427 = getelementptr inbounds i8, i8* %40, i64 5248
  %428 = bitcast i8* %427 to <32 x float>*
  %429 = load <32 x float>, <32 x float>* %428, align 64, !tbaa !1889
  %430 = fadd <32 x float> %54, %429
  %431 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %430, <32 x float> %57, <32 x float> %60)
  %432 = mul i64 %indvars.iv61, 7696581394432
  %sext102 = add i64 %432, 5634997092352
  %433 = ashr exact i64 %sext102, 32
  %434 = getelementptr inbounds float, float* %10, i64 %433
  %435 = bitcast float* %434 to <32 x float>*
  store <32 x float> %431, <32 x float>* %435, align 64, !tbaa !1892
  %436 = getelementptr inbounds i8, i8* %40, i64 5376
  %437 = bitcast i8* %436 to <32 x float>*
  %438 = load <32 x float>, <32 x float>* %437, align 64, !tbaa !1889
  %439 = fadd <32 x float> %54, %438
  %440 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %439, <32 x float> %57, <32 x float> %60)
  %441 = mul i64 %indvars.iv61, 7696581394432
  %sext103 = add i64 %441, 5772436045824
  %442 = ashr exact i64 %sext103, 32
  %443 = getelementptr inbounds float, float* %10, i64 %442
  %444 = bitcast float* %443 to <32 x float>*
  store <32 x float> %440, <32 x float>* %444, align 64, !tbaa !1892
  %445 = getelementptr inbounds i8, i8* %40, i64 5504
  %446 = bitcast i8* %445 to <32 x float>*
  %447 = load <32 x float>, <32 x float>* %446, align 64, !tbaa !1889
  %448 = fadd <32 x float> %54, %447
  %449 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %448, <32 x float> %57, <32 x float> %60)
  %450 = mul i64 %indvars.iv61, 7696581394432
  %sext104 = add i64 %450, 5909874999296
  %451 = ashr exact i64 %sext104, 32
  %452 = getelementptr inbounds float, float* %10, i64 %451
  %453 = bitcast float* %452 to <32 x float>*
  store <32 x float> %449, <32 x float>* %453, align 64, !tbaa !1892
  %454 = getelementptr inbounds i8, i8* %40, i64 5632
  %455 = bitcast i8* %454 to <32 x float>*
  %456 = load <32 x float>, <32 x float>* %455, align 64, !tbaa !1889
  %457 = fadd <32 x float> %54, %456
  %458 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %457, <32 x float> %57, <32 x float> %60)
  %459 = mul i64 %indvars.iv61, 7696581394432
  %sext105 = add i64 %459, 6047313952768
  %460 = ashr exact i64 %sext105, 32
  %461 = getelementptr inbounds float, float* %10, i64 %460
  %462 = bitcast float* %461 to <32 x float>*
  store <32 x float> %458, <32 x float>* %462, align 64, !tbaa !1892
  %463 = getelementptr inbounds i8, i8* %40, i64 5760
  %464 = bitcast i8* %463 to <32 x float>*
  %465 = load <32 x float>, <32 x float>* %464, align 64, !tbaa !1889
  %466 = fadd <32 x float> %54, %465
  %467 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %466, <32 x float> %57, <32 x float> %60)
  %468 = mul i64 %indvars.iv61, 7696581394432
  %sext106 = add i64 %468, 6184752906240
  %469 = ashr exact i64 %sext106, 32
  %470 = getelementptr inbounds float, float* %10, i64 %469
  %471 = bitcast float* %470 to <32 x float>*
  store <32 x float> %467, <32 x float>* %471, align 64, !tbaa !1892
  %472 = getelementptr inbounds i8, i8* %40, i64 5888
  %473 = bitcast i8* %472 to <32 x float>*
  %474 = load <32 x float>, <32 x float>* %473, align 64, !tbaa !1889
  %475 = fadd <32 x float> %54, %474
  %476 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %475, <32 x float> %57, <32 x float> %60)
  %477 = mul i64 %indvars.iv61, 7696581394432
  %sext107 = add i64 %477, 6322191859712
  %478 = ashr exact i64 %sext107, 32
  %479 = getelementptr inbounds float, float* %10, i64 %478
  %480 = bitcast float* %479 to <32 x float>*
  store <32 x float> %476, <32 x float>* %480, align 64, !tbaa !1892
  %481 = getelementptr inbounds i8, i8* %40, i64 6016
  %482 = bitcast i8* %481 to <32 x float>*
  %483 = load <32 x float>, <32 x float>* %482, align 64, !tbaa !1889
  %484 = fadd <32 x float> %54, %483
  %485 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %484, <32 x float> %57, <32 x float> %60)
  %486 = mul i64 %indvars.iv61, 7696581394432
  %sext108 = add i64 %486, 6459630813184
  %487 = ashr exact i64 %sext108, 32
  %488 = getelementptr inbounds float, float* %10, i64 %487
  %489 = bitcast float* %488 to <32 x float>*
  store <32 x float> %485, <32 x float>* %489, align 64, !tbaa !1892
  %490 = getelementptr inbounds i8, i8* %40, i64 6144
  %491 = bitcast i8* %490 to <32 x float>*
  %492 = load <32 x float>, <32 x float>* %491, align 64, !tbaa !1889
  %493 = fadd <32 x float> %54, %492
  %494 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %493, <32 x float> %57, <32 x float> %60)
  %495 = mul i64 %indvars.iv61, 7696581394432
  %sext109 = add i64 %495, 6597069766656
  %496 = ashr exact i64 %sext109, 32
  %497 = getelementptr inbounds float, float* %10, i64 %496
  %498 = bitcast float* %497 to <32 x float>*
  store <32 x float> %494, <32 x float>* %498, align 64, !tbaa !1892
  %499 = getelementptr inbounds i8, i8* %40, i64 6272
  %500 = bitcast i8* %499 to <32 x float>*
  %501 = load <32 x float>, <32 x float>* %500, align 64, !tbaa !1889
  %502 = fadd <32 x float> %54, %501
  %503 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %502, <32 x float> %57, <32 x float> %60)
  %504 = mul i64 %indvars.iv61, 7696581394432
  %sext110 = add i64 %504, 6734508720128
  %505 = ashr exact i64 %sext110, 32
  %506 = getelementptr inbounds float, float* %10, i64 %505
  %507 = bitcast float* %506 to <32 x float>*
  store <32 x float> %503, <32 x float>* %507, align 64, !tbaa !1892
  %508 = getelementptr inbounds i8, i8* %40, i64 6400
  %509 = bitcast i8* %508 to <32 x float>*
  %510 = load <32 x float>, <32 x float>* %509, align 64, !tbaa !1889
  %511 = fadd <32 x float> %54, %510
  %512 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %511, <32 x float> %57, <32 x float> %60)
  %513 = mul i64 %indvars.iv61, 7696581394432
  %sext111 = add i64 %513, 6871947673600
  %514 = ashr exact i64 %sext111, 32
  %515 = getelementptr inbounds float, float* %10, i64 %514
  %516 = bitcast float* %515 to <32 x float>*
  store <32 x float> %512, <32 x float>* %516, align 64, !tbaa !1892
  %517 = getelementptr inbounds i8, i8* %40, i64 6528
  %518 = bitcast i8* %517 to <32 x float>*
  %519 = load <32 x float>, <32 x float>* %518, align 64, !tbaa !1889
  %520 = fadd <32 x float> %54, %519
  %521 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %57, <32 x float> %60)
  %522 = mul i64 %indvars.iv61, 7696581394432
  %sext112 = add i64 %522, 7009386627072
  %523 = ashr exact i64 %sext112, 32
  %524 = getelementptr inbounds float, float* %10, i64 %523
  %525 = bitcast float* %524 to <32 x float>*
  store <32 x float> %521, <32 x float>* %525, align 64, !tbaa !1892
  %526 = getelementptr inbounds i8, i8* %40, i64 6656
  %527 = bitcast i8* %526 to <32 x float>*
  %528 = load <32 x float>, <32 x float>* %527, align 64, !tbaa !1889
  %529 = fadd <32 x float> %54, %528
  %530 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %529, <32 x float> %57, <32 x float> %60)
  %531 = mul i64 %indvars.iv61, 7696581394432
  %sext113 = add i64 %531, 7146825580544
  %532 = ashr exact i64 %sext113, 32
  %533 = getelementptr inbounds float, float* %10, i64 %532
  %534 = bitcast float* %533 to <32 x float>*
  store <32 x float> %530, <32 x float>* %534, align 64, !tbaa !1892
  %535 = getelementptr inbounds i8, i8* %40, i64 6784
  %536 = bitcast i8* %535 to <32 x float>*
  %537 = load <32 x float>, <32 x float>* %536, align 64, !tbaa !1889
  %538 = fadd <32 x float> %54, %537
  %539 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %538, <32 x float> %57, <32 x float> %60)
  %540 = mul i64 %indvars.iv61, 7696581394432
  %sext114 = add i64 %540, 7284264534016
  %541 = ashr exact i64 %sext114, 32
  %542 = getelementptr inbounds float, float* %10, i64 %541
  %543 = bitcast float* %542 to <32 x float>*
  store <32 x float> %539, <32 x float>* %543, align 64, !tbaa !1892
  %544 = getelementptr inbounds i8, i8* %40, i64 6912
  %545 = bitcast i8* %544 to <32 x float>*
  %546 = load <32 x float>, <32 x float>* %545, align 64, !tbaa !1889
  %547 = fadd <32 x float> %54, %546
  %548 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %547, <32 x float> %57, <32 x float> %60)
  %549 = mul i64 %indvars.iv61, 7696581394432
  %sext115 = add i64 %549, 7421703487488
  %550 = ashr exact i64 %sext115, 32
  %551 = getelementptr inbounds float, float* %10, i64 %550
  %552 = bitcast float* %551 to <32 x float>*
  store <32 x float> %548, <32 x float>* %552, align 64, !tbaa !1892
  %553 = getelementptr inbounds i8, i8* %40, i64 7040
  %554 = bitcast i8* %553 to <32 x float>*
  %555 = load <32 x float>, <32 x float>* %554, align 64, !tbaa !1889
  %556 = fadd <32 x float> %54, %555
  %557 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %556, <32 x float> %57, <32 x float> %60)
  %558 = mul i64 %indvars.iv61, 7696581394432
  %sext116 = add i64 %558, 7559142440960
  %559 = ashr exact i64 %sext116, 32
  %560 = getelementptr inbounds float, float* %10, i64 %559
  %561 = bitcast float* %560 to <32 x float>*
  store <32 x float> %557, <32 x float>* %561, align 64, !tbaa !1892
  %562 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %563 = tail call i32 %562(i32 1, i32 %22, i8* nonnull %40)
  %indvars.iv.next62 = add nsw i64 %indvars.iv61, 1
  %564 = icmp slt i64 %indvars.iv.next62, %38
  br i1 %564, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv52 = phi i64 [ 0, %for_body ], [ %indvars.iv.next53, %for_end6 ]
  %565 = mul nuw nsw i64 %indvars.iv52, 224
  %566 = getelementptr inbounds float, float* %41, i64 %565
  %567 = bitcast float* %566 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %567, align 64, !tbaa !1889
  %568 = add nuw nsw i64 %565, 32
  %569 = getelementptr inbounds float, float* %41, i64 %568
  %570 = bitcast float* %569 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %570, align 64, !tbaa !1889
  %571 = add nuw nsw i64 %565, 64
  %572 = getelementptr inbounds float, float* %41, i64 %571
  %573 = bitcast float* %572 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %573, align 64, !tbaa !1889
  %574 = add nuw nsw i64 %565, 96
  %575 = getelementptr inbounds float, float* %41, i64 %574
  %576 = bitcast float* %575 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %576, align 64, !tbaa !1889
  %577 = add nuw nsw i64 %565, 128
  %578 = getelementptr inbounds float, float* %41, i64 %577
  %579 = bitcast float* %578 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %579, align 64, !tbaa !1889
  %580 = add nuw nsw i64 %565, 160
  %581 = getelementptr inbounds float, float* %41, i64 %580
  %582 = bitcast float* %581 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %582, align 64, !tbaa !1889
  %583 = add nuw nsw i64 %565, 192
  %584 = getelementptr inbounds float, float* %41, i64 %583
  %585 = bitcast float* %584 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %585, align 64, !tbaa !1889
  %586 = mul nuw nsw i64 %indvars.iv52, 28
  %587 = add nsw i64 %586, %48
  br label %for_begin7.preheader

for_begin7.preheader:                             ; preds = %for_begin7.preheader, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_begin7.preheader ]
  %.lcssa3245 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %773, %for_begin7.preheader ]
  %.lcssa3043 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %767, %for_begin7.preheader ]
  %.lcssa2841 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %761, %for_begin7.preheader ]
  %.lcssa2639 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %755, %for_begin7.preheader ]
  %.lcssa2437 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %749, %for_begin7.preheader ]
  %.lcssa2235 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %743, %for_begin7.preheader ]
  %.lcssa34 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %737, %for_begin7.preheader ]
  %588 = mul nuw nsw i64 %indvars.iv, 12544
  %589 = add nsw i64 %587, %588
  %590 = shl i64 %indvars.iv, 7
  %591 = add nuw nsw i64 %590, %47
  %592 = getelementptr inbounds float, float* %4, i64 %589
  %593 = load float, float* %592, align 4, !tbaa !1895
  %594 = insertelement <32 x float> undef, float %593, i32 0
  %595 = shufflevector <32 x float> %594, <32 x float> undef, <32 x i32> zeroinitializer
  %596 = getelementptr inbounds float, float* %7, i64 %591
  %597 = bitcast float* %596 to <32 x float>*
  %598 = load <32 x float>, <32 x float>* %597, align 64, !tbaa !1898
  %599 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %598, <32 x float> %.lcssa34)
  %600 = add nsw i64 %589, 4
  %601 = getelementptr inbounds float, float* %4, i64 %600
  %602 = load float, float* %601, align 4, !tbaa !1895
  %603 = insertelement <32 x float> undef, float %602, i32 0
  %604 = shufflevector <32 x float> %603, <32 x float> undef, <32 x i32> zeroinitializer
  %605 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %604, <32 x float> %598, <32 x float> %.lcssa2235)
  %606 = add nsw i64 %589, 8
  %607 = getelementptr inbounds float, float* %4, i64 %606
  %608 = load float, float* %607, align 4, !tbaa !1895
  %609 = insertelement <32 x float> undef, float %608, i32 0
  %610 = shufflevector <32 x float> %609, <32 x float> undef, <32 x i32> zeroinitializer
  %611 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %610, <32 x float> %598, <32 x float> %.lcssa2437)
  %612 = add nsw i64 %589, 12
  %613 = getelementptr inbounds float, float* %4, i64 %612
  %614 = load float, float* %613, align 4, !tbaa !1895
  %615 = insertelement <32 x float> undef, float %614, i32 0
  %616 = shufflevector <32 x float> %615, <32 x float> undef, <32 x i32> zeroinitializer
  %617 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %616, <32 x float> %598, <32 x float> %.lcssa2639)
  %618 = add nsw i64 %589, 16
  %619 = getelementptr inbounds float, float* %4, i64 %618
  %620 = load float, float* %619, align 4, !tbaa !1895
  %621 = insertelement <32 x float> undef, float %620, i32 0
  %622 = shufflevector <32 x float> %621, <32 x float> undef, <32 x i32> zeroinitializer
  %623 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %622, <32 x float> %598, <32 x float> %.lcssa2841)
  %624 = add nsw i64 %589, 20
  %625 = getelementptr inbounds float, float* %4, i64 %624
  %626 = load float, float* %625, align 4, !tbaa !1895
  %627 = insertelement <32 x float> undef, float %626, i32 0
  %628 = shufflevector <32 x float> %627, <32 x float> undef, <32 x i32> zeroinitializer
  %629 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %628, <32 x float> %598, <32 x float> %.lcssa3043)
  %630 = add nsw i64 %589, 24
  %631 = getelementptr inbounds float, float* %4, i64 %630
  %632 = load float, float* %631, align 4, !tbaa !1895
  %633 = insertelement <32 x float> undef, float %632, i32 0
  %634 = shufflevector <32 x float> %633, <32 x float> undef, <32 x i32> zeroinitializer
  %635 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %634, <32 x float> %598, <32 x float> %.lcssa3245)
  %636 = or i64 %589, 1
  %637 = getelementptr inbounds float, float* %4, i64 %636
  %638 = load float, float* %637, align 4, !tbaa !1895
  %639 = insertelement <32 x float> undef, float %638, i32 0
  %640 = shufflevector <32 x float> %639, <32 x float> undef, <32 x i32> zeroinitializer
  %641 = or i64 %591, 32
  %642 = getelementptr inbounds float, float* %7, i64 %641
  %643 = bitcast float* %642 to <32 x float>*
  %644 = load <32 x float>, <32 x float>* %643, align 64, !tbaa !1898
  %645 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %640, <32 x float> %644, <32 x float> %599)
  %646 = add nsw i64 %636, 4
  %647 = getelementptr inbounds float, float* %4, i64 %646
  %648 = load float, float* %647, align 4, !tbaa !1895
  %649 = insertelement <32 x float> undef, float %648, i32 0
  %650 = shufflevector <32 x float> %649, <32 x float> undef, <32 x i32> zeroinitializer
  %651 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %650, <32 x float> %644, <32 x float> %605)
  %652 = add nsw i64 %636, 8
  %653 = getelementptr inbounds float, float* %4, i64 %652
  %654 = load float, float* %653, align 4, !tbaa !1895
  %655 = insertelement <32 x float> undef, float %654, i32 0
  %656 = shufflevector <32 x float> %655, <32 x float> undef, <32 x i32> zeroinitializer
  %657 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %656, <32 x float> %644, <32 x float> %611)
  %658 = add nsw i64 %636, 12
  %659 = getelementptr inbounds float, float* %4, i64 %658
  %660 = load float, float* %659, align 4, !tbaa !1895
  %661 = insertelement <32 x float> undef, float %660, i32 0
  %662 = shufflevector <32 x float> %661, <32 x float> undef, <32 x i32> zeroinitializer
  %663 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %662, <32 x float> %644, <32 x float> %617)
  %664 = add nsw i64 %636, 16
  %665 = getelementptr inbounds float, float* %4, i64 %664
  %666 = load float, float* %665, align 4, !tbaa !1895
  %667 = insertelement <32 x float> undef, float %666, i32 0
  %668 = shufflevector <32 x float> %667, <32 x float> undef, <32 x i32> zeroinitializer
  %669 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %668, <32 x float> %644, <32 x float> %623)
  %670 = add nsw i64 %636, 20
  %671 = getelementptr inbounds float, float* %4, i64 %670
  %672 = load float, float* %671, align 4, !tbaa !1895
  %673 = insertelement <32 x float> undef, float %672, i32 0
  %674 = shufflevector <32 x float> %673, <32 x float> undef, <32 x i32> zeroinitializer
  %675 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %674, <32 x float> %644, <32 x float> %629)
  %676 = add nsw i64 %636, 24
  %677 = getelementptr inbounds float, float* %4, i64 %676
  %678 = load float, float* %677, align 4, !tbaa !1895
  %679 = insertelement <32 x float> undef, float %678, i32 0
  %680 = shufflevector <32 x float> %679, <32 x float> undef, <32 x i32> zeroinitializer
  %681 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %680, <32 x float> %644, <32 x float> %635)
  %682 = or i64 %589, 2
  %683 = getelementptr inbounds float, float* %4, i64 %682
  %684 = load float, float* %683, align 4, !tbaa !1895
  %685 = insertelement <32 x float> undef, float %684, i32 0
  %686 = shufflevector <32 x float> %685, <32 x float> undef, <32 x i32> zeroinitializer
  %687 = or i64 %591, 64
  %688 = getelementptr inbounds float, float* %7, i64 %687
  %689 = bitcast float* %688 to <32 x float>*
  %690 = load <32 x float>, <32 x float>* %689, align 64, !tbaa !1898
  %691 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %686, <32 x float> %690, <32 x float> %645)
  %692 = add nsw i64 %682, 4
  %693 = getelementptr inbounds float, float* %4, i64 %692
  %694 = load float, float* %693, align 4, !tbaa !1895
  %695 = insertelement <32 x float> undef, float %694, i32 0
  %696 = shufflevector <32 x float> %695, <32 x float> undef, <32 x i32> zeroinitializer
  %697 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %696, <32 x float> %690, <32 x float> %651)
  %698 = add nsw i64 %682, 8
  %699 = getelementptr inbounds float, float* %4, i64 %698
  %700 = load float, float* %699, align 4, !tbaa !1895
  %701 = insertelement <32 x float> undef, float %700, i32 0
  %702 = shufflevector <32 x float> %701, <32 x float> undef, <32 x i32> zeroinitializer
  %703 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %702, <32 x float> %690, <32 x float> %657)
  %704 = add nsw i64 %682, 12
  %705 = getelementptr inbounds float, float* %4, i64 %704
  %706 = load float, float* %705, align 4, !tbaa !1895
  %707 = insertelement <32 x float> undef, float %706, i32 0
  %708 = shufflevector <32 x float> %707, <32 x float> undef, <32 x i32> zeroinitializer
  %709 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %708, <32 x float> %690, <32 x float> %663)
  %710 = add nsw i64 %682, 16
  %711 = getelementptr inbounds float, float* %4, i64 %710
  %712 = load float, float* %711, align 4, !tbaa !1895
  %713 = insertelement <32 x float> undef, float %712, i32 0
  %714 = shufflevector <32 x float> %713, <32 x float> undef, <32 x i32> zeroinitializer
  %715 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %714, <32 x float> %690, <32 x float> %669)
  %716 = add nsw i64 %682, 20
  %717 = getelementptr inbounds float, float* %4, i64 %716
  %718 = load float, float* %717, align 4, !tbaa !1895
  %719 = insertelement <32 x float> undef, float %718, i32 0
  %720 = shufflevector <32 x float> %719, <32 x float> undef, <32 x i32> zeroinitializer
  %721 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %720, <32 x float> %690, <32 x float> %675)
  %722 = add nsw i64 %682, 24
  %723 = getelementptr inbounds float, float* %4, i64 %722
  %724 = load float, float* %723, align 4, !tbaa !1895
  %725 = insertelement <32 x float> undef, float %724, i32 0
  %726 = shufflevector <32 x float> %725, <32 x float> undef, <32 x i32> zeroinitializer
  %727 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %726, <32 x float> %690, <32 x float> %681)
  %728 = or i64 %589, 3
  %729 = getelementptr inbounds float, float* %4, i64 %728
  %730 = load float, float* %729, align 4, !tbaa !1895
  %731 = insertelement <32 x float> undef, float %730, i32 0
  %732 = shufflevector <32 x float> %731, <32 x float> undef, <32 x i32> zeroinitializer
  %733 = or i64 %591, 96
  %734 = getelementptr inbounds float, float* %7, i64 %733
  %735 = bitcast float* %734 to <32 x float>*
  %736 = load <32 x float>, <32 x float>* %735, align 64, !tbaa !1898
  %737 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %732, <32 x float> %736, <32 x float> %691)
  %738 = add nsw i64 %728, 4
  %739 = getelementptr inbounds float, float* %4, i64 %738
  %740 = load float, float* %739, align 4, !tbaa !1895
  %741 = insertelement <32 x float> undef, float %740, i32 0
  %742 = shufflevector <32 x float> %741, <32 x float> undef, <32 x i32> zeroinitializer
  %743 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %742, <32 x float> %736, <32 x float> %697)
  %744 = add nsw i64 %728, 8
  %745 = getelementptr inbounds float, float* %4, i64 %744
  %746 = load float, float* %745, align 4, !tbaa !1895
  %747 = insertelement <32 x float> undef, float %746, i32 0
  %748 = shufflevector <32 x float> %747, <32 x float> undef, <32 x i32> zeroinitializer
  %749 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %748, <32 x float> %736, <32 x float> %703)
  %750 = add nsw i64 %728, 12
  %751 = getelementptr inbounds float, float* %4, i64 %750
  %752 = load float, float* %751, align 4, !tbaa !1895
  %753 = insertelement <32 x float> undef, float %752, i32 0
  %754 = shufflevector <32 x float> %753, <32 x float> undef, <32 x i32> zeroinitializer
  %755 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %754, <32 x float> %736, <32 x float> %709)
  %756 = add nsw i64 %728, 16
  %757 = getelementptr inbounds float, float* %4, i64 %756
  %758 = load float, float* %757, align 4, !tbaa !1895
  %759 = insertelement <32 x float> undef, float %758, i32 0
  %760 = shufflevector <32 x float> %759, <32 x float> undef, <32 x i32> zeroinitializer
  %761 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %760, <32 x float> %736, <32 x float> %715)
  %762 = add nsw i64 %728, 20
  %763 = getelementptr inbounds float, float* %4, i64 %762
  %764 = load float, float* %763, align 4, !tbaa !1895
  %765 = insertelement <32 x float> undef, float %764, i32 0
  %766 = shufflevector <32 x float> %765, <32 x float> undef, <32 x i32> zeroinitializer
  %767 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %766, <32 x float> %736, <32 x float> %721)
  %768 = add nsw i64 %728, 24
  %769 = getelementptr inbounds float, float* %4, i64 %768
  %770 = load float, float* %769, align 4, !tbaa !1895
  %771 = insertelement <32 x float> undef, float %770, i32 0
  %772 = shufflevector <32 x float> %771, <32 x float> undef, <32 x i32> zeroinitializer
  %773 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %772, <32 x float> %736, <32 x float> %727)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for_end6, label %for_begin7.preheader, !prof !50

for_end6:                                         ; preds = %for_begin7.preheader
  store <32 x float> %737, <32 x float>* %567, align 64, !tbaa !1889
  store <32 x float> %743, <32 x float>* %570, align 64, !tbaa !1889
  store <32 x float> %749, <32 x float>* %573, align 64, !tbaa !1889
  store <32 x float> %755, <32 x float>* %576, align 64, !tbaa !1889
  store <32 x float> %761, <32 x float>* %579, align 64, !tbaa !1889
  store <32 x float> %767, <32 x float>* %582, align 64, !tbaa !1889
  store <32 x float> %773, <32 x float>* %585, align 64, !tbaa !1889
  %indvars.iv.next53 = add nuw nsw i64 %indvars.iv52, 1
  %exitcond54 = icmp eq i64 %indvars.iv.next53, 8
  br i1 %exitcond54, label %for_begin10.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_layout_transform_47(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.200, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !1901
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.201, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !1915
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.202, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 4
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.203, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !1917
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !1931
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 64
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !1933
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 56
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !1936
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 56
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = icmp eq i64* %17, null
  br i1 %70, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end18
  %71 = bitcast i64* %17 to <4 x i64>*
  %72 = load <4 x i64>, <4 x i64>* %71, align 8, !tbaa !1938
  %73 = trunc <4 x i64> %72 to <4 x i32>
  %74 = icmp eq <4 x i32> %73, <i32 200704, i32 3136, i32 56, i32 1>
  %rdx.shuf49 = shufflevector <4 x i1> %74, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %74, %rdx.shuf49
  %rdx.shuf51 = shufflevector <4 x i1> %bin.rdx50, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %bin.rdx50, %rdx.shuf51
  %75 = extractelement <4 x i1> %bin.rdx52, i32 0
  br i1 %75, label %if_end, label %assert_fail19, !prof !5

if_end:                                           ; preds = %assert_end18, %if_then
  %76 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %77 = load i64, i64* %76, align 8
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %assert_end22, label %assert_fail21, !prof !5

assert_fail19:                                    ; preds = %if_then
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([201 x i8], [201 x i8]* @.str.205, i64 0, i64 0))
  ret i32 -1

assert_fail21:                                    ; preds = %if_end
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %if_end
  %81 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %82 = load i32, i32* %81, align 4
  %83 = icmp eq i32 %82, 5
  br i1 %83, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %85 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %86 = load i16, i16* %85, align 2
  %87 = icmp eq i16 %86, 1
  %88 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %89 = load i8, i8* %88, align 1
  %90 = icmp eq i8 %89, 32
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %92 = load i8, i8* %91, align 1
  %93 = icmp eq i8 %92, 2
  %94 = and i1 %90, %93
  %95 = and i1 %87, %94
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = load i64, i64* %25, align 8, !tbaa !1950
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 1
  br i1 %99, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %101 = getelementptr inbounds i64, i64* %25, i64 1
  %102 = load i64, i64* %101, align 8, !tbaa !1964
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 4
  br i1 %104, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %106 = getelementptr inbounds i64, i64* %25, i64 2
  %107 = load i64, i64* %106, align 8, !tbaa !1966
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 56
  br i1 %109, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %111 = getelementptr inbounds i64, i64* %25, i64 3
  %112 = load i64, i64* %111, align 8, !tbaa !1969
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 56
  br i1 %114, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %116 = getelementptr inbounds i64, i64* %25, i64 4
  %117 = load i64, i64* %116, align 8, !tbaa !1971
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 16
  br i1 %119, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %121 = icmp eq i64* %27, null
  br i1 %121, label %if_end38, label %if_then37, !prof !50

if_then37:                                        ; preds = %assert_end36
  %122 = bitcast i64* %27 to <4 x i64>*
  %123 = load <4 x i64>, <4 x i64>* %122, align 8, !tbaa !1975
  %124 = trunc <4 x i64> %123 to <4 x i32>
  %125 = icmp eq <4 x i32> %124, <i32 200704, i32 50176, i32 896, i32 16>
  %126 = getelementptr inbounds i64, i64* %27, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !1987
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 1
  %rdx.shuf = shufflevector <4 x i1> %125, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %125, %rdx.shuf
  %rdx.shuf47 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx48 = and <4 x i1> %bin.rdx, %rdx.shuf47
  %130 = extractelement <4 x i1> %bin.rdx48, i32 0
  %131 = and i1 %130, %129
  br i1 %131, label %if_end38, label %assert_fail39, !prof !5

if_end38:                                         ; preds = %assert_end36, %if_then37
  %132 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %133 = load i64, i64* %132, align 8
  %134 = icmp eq i64 %133, 0
  br i1 %134, label %assert_end42, label %assert_fail41, !prof !5

assert_fail39:                                    ; preds = %if_then37
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.206, i64 0, i64 0))
  ret i32 -1

assert_fail41:                                    ; preds = %if_end38
  %136 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %136(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %if_end38
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %138 = load i32, i32* %137, align 4
  %139 = icmp eq i32 %138, 1
  br i1 %139, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %140 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %140(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %141 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %142 = load i32, i32* %141, align 4
  %143 = icmp eq i32 %21, %142
  br i1 %143, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %144 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %144(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %145 = tail call fastcc i32 @fused_layout_transform_47_compute_(i8* %23, i8* %13)
  ret i32 %145
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_47_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %16, align 8
  %3 = getelementptr inbounds %16, %16* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %16, %16* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %16* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.207, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.207(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 223
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 224
  %15 = select i1 %14, i32 %13, i32 224
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 224
  %18 = select i1 %17, i32 %16, i32 224
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 896
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = srem i32 %25, 56
  %27 = mul nsw i32 %26, 56
  %28 = sdiv i32 %25, 56
  %29 = mul nsw i32 %28, 50176
  %30 = add i32 %27, %29
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_begin4.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_begin4.preheader ]
  %31 = shl i64 %indvars.iv, 4
  %32 = add nsw i64 %31, %24
  %33 = trunc i64 %indvars.iv to i32
  %34 = add i32 %30, %33
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds float, float* %7, i64 %35
  %37 = bitcast float* %36 to i32*
  %38 = load i32, i32* %37, align 4, !tbaa !1991
  %39 = getelementptr inbounds float, float* %4, i64 %32
  %40 = bitcast float* %39 to i32*
  store i32 %38, i32* %40, align 4, !tbaa !1994
  %41 = or i64 %32, 1
  %42 = add i32 %34, 3136
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds float, float* %7, i64 %43
  %45 = bitcast float* %44 to i32*
  %46 = load i32, i32* %45, align 4, !tbaa !1991
  %47 = getelementptr inbounds float, float* %4, i64 %41
  %48 = bitcast float* %47 to i32*
  store i32 %46, i32* %48, align 4, !tbaa !1994
  %49 = or i64 %32, 2
  %50 = add i32 %34, 6272
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds float, float* %7, i64 %51
  %53 = bitcast float* %52 to i32*
  %54 = load i32, i32* %53, align 4, !tbaa !1991
  %55 = getelementptr inbounds float, float* %4, i64 %49
  %56 = bitcast float* %55 to i32*
  store i32 %54, i32* %56, align 4, !tbaa !1994
  %57 = or i64 %32, 3
  %58 = add i32 %34, 9408
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds float, float* %7, i64 %59
  %61 = bitcast float* %60 to i32*
  %62 = load i32, i32* %61, align 4, !tbaa !1991
  %63 = getelementptr inbounds float, float* %4, i64 %57
  %64 = bitcast float* %63 to i32*
  store i32 %62, i32* %64, align 4, !tbaa !1994
  %65 = or i64 %32, 4
  %66 = add i32 %34, 12544
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds float, float* %7, i64 %67
  %69 = bitcast float* %68 to i32*
  %70 = load i32, i32* %69, align 4, !tbaa !1991
  %71 = getelementptr inbounds float, float* %4, i64 %65
  %72 = bitcast float* %71 to i32*
  store i32 %70, i32* %72, align 4, !tbaa !1994
  %73 = or i64 %32, 5
  %74 = add i32 %34, 15680
  %75 = sext i32 %74 to i64
  %76 = getelementptr inbounds float, float* %7, i64 %75
  %77 = bitcast float* %76 to i32*
  %78 = load i32, i32* %77, align 4, !tbaa !1991
  %79 = getelementptr inbounds float, float* %4, i64 %73
  %80 = bitcast float* %79 to i32*
  store i32 %78, i32* %80, align 4, !tbaa !1994
  %81 = or i64 %32, 6
  %82 = add i32 %34, 18816
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = bitcast float* %84 to i32*
  %86 = load i32, i32* %85, align 4, !tbaa !1991
  %87 = getelementptr inbounds float, float* %4, i64 %81
  %88 = bitcast float* %87 to i32*
  store i32 %86, i32* %88, align 4, !tbaa !1994
  %89 = or i64 %32, 7
  %90 = add i32 %34, 21952
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds float, float* %7, i64 %91
  %93 = bitcast float* %92 to i32*
  %94 = load i32, i32* %93, align 4, !tbaa !1991
  %95 = getelementptr inbounds float, float* %4, i64 %89
  %96 = bitcast float* %95 to i32*
  store i32 %94, i32* %96, align 4, !tbaa !1994
  %97 = or i64 %32, 8
  %98 = add i32 %34, 25088
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds float, float* %7, i64 %99
  %101 = bitcast float* %100 to i32*
  %102 = load i32, i32* %101, align 4, !tbaa !1991
  %103 = getelementptr inbounds float, float* %4, i64 %97
  %104 = bitcast float* %103 to i32*
  store i32 %102, i32* %104, align 4, !tbaa !1994
  %105 = or i64 %32, 9
  %106 = add i32 %34, 28224
  %107 = sext i32 %106 to i64
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to i32*
  %110 = load i32, i32* %109, align 4, !tbaa !1991
  %111 = getelementptr inbounds float, float* %4, i64 %105
  %112 = bitcast float* %111 to i32*
  store i32 %110, i32* %112, align 4, !tbaa !1994
  %113 = or i64 %32, 10
  %114 = add i32 %34, 31360
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds float, float* %7, i64 %115
  %117 = bitcast float* %116 to i32*
  %118 = load i32, i32* %117, align 4, !tbaa !1991
  %119 = getelementptr inbounds float, float* %4, i64 %113
  %120 = bitcast float* %119 to i32*
  store i32 %118, i32* %120, align 4, !tbaa !1994
  %121 = or i64 %32, 11
  %122 = add i32 %34, 34496
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds float, float* %7, i64 %123
  %125 = bitcast float* %124 to i32*
  %126 = load i32, i32* %125, align 4, !tbaa !1991
  %127 = getelementptr inbounds float, float* %4, i64 %121
  %128 = bitcast float* %127 to i32*
  store i32 %126, i32* %128, align 4, !tbaa !1994
  %129 = or i64 %32, 12
  %130 = add i32 %34, 37632
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %7, i64 %131
  %133 = bitcast float* %132 to i32*
  %134 = load i32, i32* %133, align 4, !tbaa !1991
  %135 = getelementptr inbounds float, float* %4, i64 %129
  %136 = bitcast float* %135 to i32*
  store i32 %134, i32* %136, align 4, !tbaa !1994
  %137 = or i64 %32, 13
  %138 = add i32 %34, 40768
  %139 = sext i32 %138 to i64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to i32*
  %142 = load i32, i32* %141, align 4, !tbaa !1991
  %143 = getelementptr inbounds float, float* %4, i64 %137
  %144 = bitcast float* %143 to i32*
  store i32 %142, i32* %144, align 4, !tbaa !1994
  %145 = or i64 %32, 14
  %146 = add i32 %34, 43904
  %147 = sext i32 %146 to i64
  %148 = getelementptr inbounds float, float* %7, i64 %147
  %149 = bitcast float* %148 to i32*
  %150 = load i32, i32* %149, align 4, !tbaa !1991
  %151 = getelementptr inbounds float, float* %4, i64 %145
  %152 = bitcast float* %151 to i32*
  store i32 %150, i32* %152, align 4, !tbaa !1994
  %153 = or i64 %32, 15
  %154 = add i32 %34, 47040
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds float, float* %7, i64 %155
  %157 = bitcast float* %156 to i32*
  %158 = load i32, i32* %157, align 4, !tbaa !1991
  %159 = getelementptr inbounds float, float* %4, i64 %153
  %160 = bitcast float* %159 to i32*
  store i32 %158, i32* %160, align 4, !tbaa !1994
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_begin4.preheader, !prof !50

for_end3:                                         ; preds = %for_begin4.preheader
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %161 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %161, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.208, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !1997
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !2011
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !2014
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !2016
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.209, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !2020
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.210, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.211, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.212, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.213, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !2022
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !2036
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 1
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !2038
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 56
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !2041
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 56
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !2043
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 256
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !2047
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 802816, i32 802816, i32 14336, i32 256>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !2059
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([243 x i8], [243 x i8]* @.str.104, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !2063
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 4
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !2077
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !2079
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !2082
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !2084
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 256
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !2088
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 32
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !2090
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 8192, i32 8192, i32 8192, i32 8192>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !2102
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 32
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !2106
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([275 x i8], [275 x i8]* @.str.108, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !2108
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 4
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !2122
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !2124
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !2127
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 32
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !2129
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !2141
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 4
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !2155
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !2157
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !2160
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 32
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !2162
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !2174
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !2188
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 4
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.79, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !2190
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 28
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.214, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !2193
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 28
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.215, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !2195
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 32
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !2199
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 100352, i32 25088, i32 896, i32 32>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !2211
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.216, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_8_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %17, align 8
  %7 = getelementptr inbounds %17, %17* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %17, %17* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %17, %17* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %17, %17* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %17, %17* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %17, %17* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %17* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.217, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.217(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 111
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 112
  %30 = select i1 %29, i32 %28, i32 112
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end6.3
  %indvars.iv45 = phi i64 [ %34, %for_body.preheader ], [ %indvars.iv.next46, %for_end6.3 ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %37 = tail call i8* %36(i32 1, i32 %19, i64 3584, i32 2, i32 32)
  %38 = trunc i64 %indvars.iv45 to i32
  %39 = srem i32 %38, 28
  %40 = mul nsw i32 %39, 28672
  %41 = sdiv i32 %38, 28
  %42 = shl i32 %41, 13
  %43 = sext i32 %42 to i64
  %44 = sext i32 %40 to i64
  %45 = bitcast i8* %37 to <32 x float>*
  %46 = getelementptr inbounds i8, i8* %37, i64 128
  %47 = bitcast i8* %46 to <32 x float>*
  %48 = getelementptr inbounds i8, i8* %37, i64 256
  %49 = bitcast i8* %48 to <32 x float>*
  %50 = getelementptr inbounds i8, i8* %37, i64 384
  %51 = bitcast i8* %50 to <32 x float>*
  %52 = getelementptr inbounds i8, i8* %37, i64 512
  %53 = bitcast i8* %52 to <32 x float>*
  %54 = getelementptr inbounds i8, i8* %37, i64 640
  %55 = bitcast i8* %54 to <32 x float>*
  %56 = getelementptr inbounds i8, i8* %37, i64 768
  %57 = bitcast i8* %56 to <32 x float>*
  call void @llvm.memset.p0i8.i64(i8* align 64 %37, i8 0, i64 896, i1 false)
  br label %for_body5

for_end:                                          ; preds = %for_end6.3, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %58 = phi <32 x float> [ zeroinitializer, %for_body ], [ %111, %for_body5 ]
  %59 = phi <32 x float> [ zeroinitializer, %for_body ], [ %105, %for_body5 ]
  %60 = phi <32 x float> [ zeroinitializer, %for_body ], [ %99, %for_body5 ]
  %61 = phi <32 x float> [ zeroinitializer, %for_body ], [ %93, %for_body5 ]
  %62 = phi <32 x float> [ zeroinitializer, %for_body ], [ %87, %for_body5 ]
  %63 = phi <32 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %64 = phi <32 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %65 = add nsw i64 %indvars.iv, %44
  %66 = getelementptr inbounds float, float* %4, i64 %65
  %67 = load float, float* %66, align 4, !tbaa !2215
  %68 = insertelement <32 x float> undef, float %67, i32 0
  %69 = shufflevector <32 x float> %68, <32 x float> undef, <32 x i32> zeroinitializer
  %70 = shl i64 %indvars.iv, 5
  %71 = add nuw nsw i64 %70, %43
  %72 = getelementptr inbounds float, float* %7, i64 %71
  %73 = bitcast float* %72 to <32 x float>*
  %74 = load <32 x float>, <32 x float>* %73, align 64, !tbaa !2218
  %75 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %69, <32 x float> %74, <32 x float> %64)
  %76 = add nsw i64 %65, 512
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !2215
  %79 = insertelement <32 x float> undef, float %78, i32 0
  %80 = shufflevector <32 x float> %79, <32 x float> undef, <32 x i32> zeroinitializer
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %74, <32 x float> %63)
  %82 = add nsw i64 %65, 1024
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !2215
  %85 = insertelement <32 x float> undef, float %84, i32 0
  %86 = shufflevector <32 x float> %85, <32 x float> undef, <32 x i32> zeroinitializer
  %87 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %74, <32 x float> %62)
  %88 = add nsw i64 %65, 1536
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !2215
  %91 = insertelement <32 x float> undef, float %90, i32 0
  %92 = shufflevector <32 x float> %91, <32 x float> undef, <32 x i32> zeroinitializer
  %93 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %74, <32 x float> %61)
  %94 = add nsw i64 %65, 2048
  %95 = getelementptr inbounds float, float* %4, i64 %94
  %96 = load float, float* %95, align 4, !tbaa !2215
  %97 = insertelement <32 x float> undef, float %96, i32 0
  %98 = shufflevector <32 x float> %97, <32 x float> undef, <32 x i32> zeroinitializer
  %99 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %98, <32 x float> %74, <32 x float> %60)
  %100 = add nsw i64 %65, 2560
  %101 = getelementptr inbounds float, float* %4, i64 %100
  %102 = load float, float* %101, align 4, !tbaa !2215
  %103 = insertelement <32 x float> undef, float %102, i32 0
  %104 = shufflevector <32 x float> %103, <32 x float> undef, <32 x i32> zeroinitializer
  %105 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %104, <32 x float> %74, <32 x float> %59)
  %106 = add nsw i64 %65, 3072
  %107 = getelementptr inbounds float, float* %4, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !2215
  %109 = insertelement <32 x float> undef, float %108, i32 0
  %110 = shufflevector <32 x float> %109, <32 x float> undef, <32 x i32> zeroinitializer
  %111 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %110, <32 x float> %74, <32 x float> %58)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  store <32 x float> %75, <32 x float>* %45, align 64, !tbaa !2221
  store <32 x float> %81, <32 x float>* %47, align 64, !tbaa !2221
  store <32 x float> %87, <32 x float>* %49, align 64, !tbaa !2221
  store <32 x float> %93, <32 x float>* %51, align 64, !tbaa !2221
  store <32 x float> %99, <32 x float>* %53, align 64, !tbaa !2221
  store <32 x float> %105, <32 x float>* %55, align 64, !tbaa !2221
  store <32 x float> %111, <32 x float>* %57, align 64, !tbaa !2221
  %112 = getelementptr inbounds i8, i8* %37, i64 896
  %113 = bitcast i8* %112 to <32 x float>*
  %114 = getelementptr inbounds i8, i8* %37, i64 1024
  %115 = bitcast i8* %114 to <32 x float>*
  %116 = getelementptr inbounds i8, i8* %37, i64 1152
  %117 = bitcast i8* %116 to <32 x float>*
  %118 = getelementptr inbounds i8, i8* %37, i64 1280
  %119 = bitcast i8* %118 to <32 x float>*
  %120 = getelementptr inbounds i8, i8* %37, i64 1408
  %121 = bitcast i8* %120 to <32 x float>*
  %122 = getelementptr inbounds i8, i8* %37, i64 1536
  %123 = bitcast i8* %122 to <32 x float>*
  %124 = getelementptr inbounds i8, i8* %37, i64 1664
  %125 = bitcast i8* %124 to <32 x float>*
  %126 = or i64 %44, 3584
  call void @llvm.memset.p0i8.i64(i8* nonnull align 64 %112, i8 0, i64 896, i1 false)
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %127 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %180, %for_body5.1 ]
  %128 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %174, %for_body5.1 ]
  %129 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %168, %for_body5.1 ]
  %130 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %162, %for_body5.1 ]
  %131 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %156, %for_body5.1 ]
  %132 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %150, %for_body5.1 ]
  %133 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %144, %for_body5.1 ]
  %134 = add nsw i64 %126, %indvars.iv.1
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !2215
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = shl i64 %indvars.iv.1, 5
  %140 = add nuw nsw i64 %139, %43
  %141 = getelementptr inbounds float, float* %7, i64 %140
  %142 = bitcast float* %141 to <32 x float>*
  %143 = load <32 x float>, <32 x float>* %142, align 64, !tbaa !2218
  %144 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %143, <32 x float> %133)
  %145 = add nsw i64 %134, 512
  %146 = getelementptr inbounds float, float* %4, i64 %145
  %147 = load float, float* %146, align 4, !tbaa !2215
  %148 = insertelement <32 x float> undef, float %147, i32 0
  %149 = shufflevector <32 x float> %148, <32 x float> undef, <32 x i32> zeroinitializer
  %150 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %149, <32 x float> %143, <32 x float> %132)
  %151 = add nsw i64 %134, 1024
  %152 = getelementptr inbounds float, float* %4, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !2215
  %154 = insertelement <32 x float> undef, float %153, i32 0
  %155 = shufflevector <32 x float> %154, <32 x float> undef, <32 x i32> zeroinitializer
  %156 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %143, <32 x float> %131)
  %157 = add nsw i64 %134, 1536
  %158 = getelementptr inbounds float, float* %4, i64 %157
  %159 = load float, float* %158, align 4, !tbaa !2215
  %160 = insertelement <32 x float> undef, float %159, i32 0
  %161 = shufflevector <32 x float> %160, <32 x float> undef, <32 x i32> zeroinitializer
  %162 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %143, <32 x float> %130)
  %163 = add nsw i64 %134, 2048
  %164 = getelementptr inbounds float, float* %4, i64 %163
  %165 = load float, float* %164, align 4, !tbaa !2215
  %166 = insertelement <32 x float> undef, float %165, i32 0
  %167 = shufflevector <32 x float> %166, <32 x float> undef, <32 x i32> zeroinitializer
  %168 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %167, <32 x float> %143, <32 x float> %129)
  %169 = add nsw i64 %134, 2560
  %170 = getelementptr inbounds float, float* %4, i64 %169
  %171 = load float, float* %170, align 4, !tbaa !2215
  %172 = insertelement <32 x float> undef, float %171, i32 0
  %173 = shufflevector <32 x float> %172, <32 x float> undef, <32 x i32> zeroinitializer
  %174 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %173, <32 x float> %143, <32 x float> %128)
  %175 = add nsw i64 %134, 3072
  %176 = getelementptr inbounds float, float* %4, i64 %175
  %177 = load float, float* %176, align 4, !tbaa !2215
  %178 = insertelement <32 x float> undef, float %177, i32 0
  %179 = shufflevector <32 x float> %178, <32 x float> undef, <32 x i32> zeroinitializer
  %180 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %143, <32 x float> %127)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  store <32 x float> %144, <32 x float>* %113, align 64, !tbaa !2221
  store <32 x float> %150, <32 x float>* %115, align 64, !tbaa !2221
  store <32 x float> %156, <32 x float>* %117, align 64, !tbaa !2221
  store <32 x float> %162, <32 x float>* %119, align 64, !tbaa !2221
  store <32 x float> %168, <32 x float>* %121, align 64, !tbaa !2221
  store <32 x float> %174, <32 x float>* %123, align 64, !tbaa !2221
  store <32 x float> %180, <32 x float>* %125, align 64, !tbaa !2221
  %181 = getelementptr inbounds i8, i8* %37, i64 1792
  %182 = bitcast i8* %181 to <32 x float>*
  %183 = getelementptr inbounds i8, i8* %37, i64 1920
  %184 = bitcast i8* %183 to <32 x float>*
  %185 = getelementptr inbounds i8, i8* %37, i64 2048
  %186 = bitcast i8* %185 to <32 x float>*
  %187 = getelementptr inbounds i8, i8* %37, i64 2176
  %188 = bitcast i8* %187 to <32 x float>*
  %189 = getelementptr inbounds i8, i8* %37, i64 2304
  %190 = bitcast i8* %189 to <32 x float>*
  %191 = getelementptr inbounds i8, i8* %37, i64 2432
  %192 = bitcast i8* %191 to <32 x float>*
  %193 = getelementptr inbounds i8, i8* %37, i64 2560
  %194 = bitcast i8* %193 to <32 x float>*
  %195 = add nsw i64 %44, 7168
  call void @llvm.memset.p0i8.i64(i8* nonnull align 64 %181, i8 0, i64 896, i1 false)
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %196 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %249, %for_body5.2 ]
  %197 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %243, %for_body5.2 ]
  %198 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %237, %for_body5.2 ]
  %199 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %231, %for_body5.2 ]
  %200 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %225, %for_body5.2 ]
  %201 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %219, %for_body5.2 ]
  %202 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %213, %for_body5.2 ]
  %203 = add nsw i64 %195, %indvars.iv.2
  %204 = getelementptr inbounds float, float* %4, i64 %203
  %205 = load float, float* %204, align 4, !tbaa !2215
  %206 = insertelement <32 x float> undef, float %205, i32 0
  %207 = shufflevector <32 x float> %206, <32 x float> undef, <32 x i32> zeroinitializer
  %208 = shl i64 %indvars.iv.2, 5
  %209 = add nuw nsw i64 %208, %43
  %210 = getelementptr inbounds float, float* %7, i64 %209
  %211 = bitcast float* %210 to <32 x float>*
  %212 = load <32 x float>, <32 x float>* %211, align 64, !tbaa !2218
  %213 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %207, <32 x float> %212, <32 x float> %202)
  %214 = add nsw i64 %203, 512
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !2215
  %217 = insertelement <32 x float> undef, float %216, i32 0
  %218 = shufflevector <32 x float> %217, <32 x float> undef, <32 x i32> zeroinitializer
  %219 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %212, <32 x float> %201)
  %220 = add nsw i64 %203, 1024
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !2215
  %223 = insertelement <32 x float> undef, float %222, i32 0
  %224 = shufflevector <32 x float> %223, <32 x float> undef, <32 x i32> zeroinitializer
  %225 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %224, <32 x float> %212, <32 x float> %200)
  %226 = add nsw i64 %203, 1536
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = load float, float* %227, align 4, !tbaa !2215
  %229 = insertelement <32 x float> undef, float %228, i32 0
  %230 = shufflevector <32 x float> %229, <32 x float> undef, <32 x i32> zeroinitializer
  %231 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %230, <32 x float> %212, <32 x float> %199)
  %232 = add nsw i64 %203, 2048
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !2215
  %235 = insertelement <32 x float> undef, float %234, i32 0
  %236 = shufflevector <32 x float> %235, <32 x float> undef, <32 x i32> zeroinitializer
  %237 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %236, <32 x float> %212, <32 x float> %198)
  %238 = add nsw i64 %203, 2560
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !2215
  %241 = insertelement <32 x float> undef, float %240, i32 0
  %242 = shufflevector <32 x float> %241, <32 x float> undef, <32 x i32> zeroinitializer
  %243 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %212, <32 x float> %197)
  %244 = add nsw i64 %203, 3072
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !2215
  %247 = insertelement <32 x float> undef, float %246, i32 0
  %248 = shufflevector <32 x float> %247, <32 x float> undef, <32 x i32> zeroinitializer
  %249 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %212, <32 x float> %196)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  store <32 x float> %213, <32 x float>* %182, align 64, !tbaa !2221
  store <32 x float> %219, <32 x float>* %184, align 64, !tbaa !2221
  store <32 x float> %225, <32 x float>* %186, align 64, !tbaa !2221
  store <32 x float> %231, <32 x float>* %188, align 64, !tbaa !2221
  store <32 x float> %237, <32 x float>* %190, align 64, !tbaa !2221
  store <32 x float> %243, <32 x float>* %192, align 64, !tbaa !2221
  store <32 x float> %249, <32 x float>* %194, align 64, !tbaa !2221
  %250 = getelementptr inbounds i8, i8* %37, i64 2688
  %251 = bitcast i8* %250 to <32 x float>*
  %252 = getelementptr inbounds i8, i8* %37, i64 2816
  %253 = bitcast i8* %252 to <32 x float>*
  %254 = getelementptr inbounds i8, i8* %37, i64 2944
  %255 = bitcast i8* %254 to <32 x float>*
  %256 = getelementptr inbounds i8, i8* %37, i64 3072
  %257 = bitcast i8* %256 to <32 x float>*
  %258 = getelementptr inbounds i8, i8* %37, i64 3200
  %259 = bitcast i8* %258 to <32 x float>*
  %260 = getelementptr inbounds i8, i8* %37, i64 3328
  %261 = bitcast i8* %260 to <32 x float>*
  %262 = getelementptr inbounds i8, i8* %37, i64 3456
  %263 = bitcast i8* %262 to <32 x float>*
  %264 = add nsw i64 %44, 10752
  call void @llvm.memset.p0i8.i64(i8* nonnull align 64 %250, i8 0, i64 896, i1 false)
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %265 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %318, %for_body5.3 ]
  %266 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %312, %for_body5.3 ]
  %267 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %306, %for_body5.3 ]
  %268 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %300, %for_body5.3 ]
  %269 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %294, %for_body5.3 ]
  %270 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %288, %for_body5.3 ]
  %271 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %282, %for_body5.3 ]
  %272 = add nsw i64 %264, %indvars.iv.3
  %273 = getelementptr inbounds float, float* %4, i64 %272
  %274 = load float, float* %273, align 4, !tbaa !2215
  %275 = insertelement <32 x float> undef, float %274, i32 0
  %276 = shufflevector <32 x float> %275, <32 x float> undef, <32 x i32> zeroinitializer
  %277 = shl i64 %indvars.iv.3, 5
  %278 = add nuw nsw i64 %277, %43
  %279 = getelementptr inbounds float, float* %7, i64 %278
  %280 = bitcast float* %279 to <32 x float>*
  %281 = load <32 x float>, <32 x float>* %280, align 64, !tbaa !2218
  %282 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %276, <32 x float> %281, <32 x float> %271)
  %283 = add nsw i64 %272, 512
  %284 = getelementptr inbounds float, float* %4, i64 %283
  %285 = load float, float* %284, align 4, !tbaa !2215
  %286 = insertelement <32 x float> undef, float %285, i32 0
  %287 = shufflevector <32 x float> %286, <32 x float> undef, <32 x i32> zeroinitializer
  %288 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %287, <32 x float> %281, <32 x float> %270)
  %289 = add nsw i64 %272, 1024
  %290 = getelementptr inbounds float, float* %4, i64 %289
  %291 = load float, float* %290, align 4, !tbaa !2215
  %292 = insertelement <32 x float> undef, float %291, i32 0
  %293 = shufflevector <32 x float> %292, <32 x float> undef, <32 x i32> zeroinitializer
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %293, <32 x float> %281, <32 x float> %269)
  %295 = add nsw i64 %272, 1536
  %296 = getelementptr inbounds float, float* %4, i64 %295
  %297 = load float, float* %296, align 4, !tbaa !2215
  %298 = insertelement <32 x float> undef, float %297, i32 0
  %299 = shufflevector <32 x float> %298, <32 x float> undef, <32 x i32> zeroinitializer
  %300 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %299, <32 x float> %281, <32 x float> %268)
  %301 = add nsw i64 %272, 2048
  %302 = getelementptr inbounds float, float* %4, i64 %301
  %303 = load float, float* %302, align 4, !tbaa !2215
  %304 = insertelement <32 x float> undef, float %303, i32 0
  %305 = shufflevector <32 x float> %304, <32 x float> undef, <32 x i32> zeroinitializer
  %306 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %281, <32 x float> %267)
  %307 = add nsw i64 %272, 2560
  %308 = getelementptr inbounds float, float* %4, i64 %307
  %309 = load float, float* %308, align 4, !tbaa !2215
  %310 = insertelement <32 x float> undef, float %309, i32 0
  %311 = shufflevector <32 x float> %310, <32 x float> undef, <32 x i32> zeroinitializer
  %312 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %311, <32 x float> %281, <32 x float> %266)
  %313 = add nsw i64 %272, 3072
  %314 = getelementptr inbounds float, float* %4, i64 %313
  %315 = load float, float* %314, align 4, !tbaa !2215
  %316 = insertelement <32 x float> undef, float %315, i32 0
  %317 = shufflevector <32 x float> %316, <32 x float> undef, <32 x i32> zeroinitializer
  %318 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %317, <32 x float> %281, <32 x float> %265)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  store <32 x float> %282, <32 x float>* %251, align 64, !tbaa !2221
  store <32 x float> %288, <32 x float>* %253, align 64, !tbaa !2221
  store <32 x float> %294, <32 x float>* %255, align 64, !tbaa !2221
  store <32 x float> %300, <32 x float>* %257, align 64, !tbaa !2221
  store <32 x float> %306, <32 x float>* %259, align 64, !tbaa !2221
  store <32 x float> %312, <32 x float>* %261, align 64, !tbaa !2221
  store <32 x float> %318, <32 x float>* %263, align 64, !tbaa !2221
  %319 = mul nsw i64 %indvars.iv45, 896
  %320 = shl nsw i32 %41, 5
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds float, float* %16, i64 %321
  %323 = bitcast float* %322 to <32 x float>*
  %324 = load <32 x float>, <32 x float>* %323, align 64, !tbaa !2224
  %325 = getelementptr inbounds float, float* %13, i64 %321
  %326 = bitcast float* %325 to <32 x float>*
  %327 = load <32 x float>, <32 x float>* %326, align 64, !tbaa !2227
  %328 = fadd <32 x float> %327, %75
  %329 = fadd <32 x float> %324, %328
  %330 = fcmp ogt <32 x float> %329, zeroinitializer
  %331 = select <32 x i1> %330, <32 x float> %329, <32 x float> zeroinitializer
  %332 = getelementptr inbounds float, float* %10, i64 %319
  %333 = bitcast float* %332 to <32 x float>*
  store <32 x float> %331, <32 x float>* %333, align 64, !tbaa !2230
  %334 = fadd <32 x float> %327, %81
  %335 = fadd <32 x float> %324, %334
  %336 = fcmp ogt <32 x float> %335, zeroinitializer
  %337 = select <32 x i1> %336, <32 x float> %335, <32 x float> zeroinitializer
  %338 = mul i64 %indvars.iv45, 3848290697216
  %sext = ashr exact i64 %338, 32
  %339 = or i64 %sext, 32
  %340 = getelementptr inbounds float, float* %10, i64 %339
  %341 = bitcast float* %340 to <32 x float>*
  store <32 x float> %337, <32 x float>* %341, align 64, !tbaa !2230
  %342 = fadd <32 x float> %327, %87
  %343 = fadd <32 x float> %324, %342
  %344 = fcmp ogt <32 x float> %343, zeroinitializer
  %345 = select <32 x i1> %344, <32 x float> %343, <32 x float> zeroinitializer
  %346 = mul i64 %indvars.iv45, 3848290697216
  %sext47 = ashr exact i64 %346, 32
  %347 = or i64 %sext47, 64
  %348 = getelementptr inbounds float, float* %10, i64 %347
  %349 = bitcast float* %348 to <32 x float>*
  store <32 x float> %345, <32 x float>* %349, align 64, !tbaa !2230
  %350 = fadd <32 x float> %327, %93
  %351 = fadd <32 x float> %324, %350
  %352 = fcmp ogt <32 x float> %351, zeroinitializer
  %353 = select <32 x i1> %352, <32 x float> %351, <32 x float> zeroinitializer
  %354 = mul i64 %indvars.iv45, 3848290697216
  %sext48 = ashr exact i64 %354, 32
  %355 = or i64 %sext48, 96
  %356 = getelementptr inbounds float, float* %10, i64 %355
  %357 = bitcast float* %356 to <32 x float>*
  store <32 x float> %353, <32 x float>* %357, align 64, !tbaa !2230
  %358 = fadd <32 x float> %327, %99
  %359 = fadd <32 x float> %324, %358
  %360 = fcmp ogt <32 x float> %359, zeroinitializer
  %361 = select <32 x i1> %360, <32 x float> %359, <32 x float> zeroinitializer
  %362 = mul i64 %indvars.iv45, 3848290697216
  %sext49 = add i64 %362, 549755813888
  %363 = ashr exact i64 %sext49, 32
  %364 = getelementptr inbounds float, float* %10, i64 %363
  %365 = bitcast float* %364 to <32 x float>*
  store <32 x float> %361, <32 x float>* %365, align 64, !tbaa !2230
  %366 = fadd <32 x float> %327, %105
  %367 = fadd <32 x float> %324, %366
  %368 = fcmp ogt <32 x float> %367, zeroinitializer
  %369 = select <32 x i1> %368, <32 x float> %367, <32 x float> zeroinitializer
  %370 = mul i64 %indvars.iv45, 3848290697216
  %sext50 = add i64 %370, 687194767360
  %371 = ashr exact i64 %sext50, 32
  %372 = getelementptr inbounds float, float* %10, i64 %371
  %373 = bitcast float* %372 to <32 x float>*
  store <32 x float> %369, <32 x float>* %373, align 64, !tbaa !2230
  %374 = fadd <32 x float> %327, %111
  %375 = fadd <32 x float> %324, %374
  %376 = fcmp ogt <32 x float> %375, zeroinitializer
  %377 = select <32 x i1> %376, <32 x float> %375, <32 x float> zeroinitializer
  %378 = mul i64 %indvars.iv45, 3848290697216
  %sext51 = add i64 %378, 824633720832
  %379 = ashr exact i64 %sext51, 32
  %380 = getelementptr inbounds float, float* %10, i64 %379
  %381 = bitcast float* %380 to <32 x float>*
  store <32 x float> %377, <32 x float>* %381, align 64, !tbaa !2230
  %382 = fadd <32 x float> %327, %144
  %383 = fadd <32 x float> %324, %382
  %384 = fcmp ogt <32 x float> %383, zeroinitializer
  %385 = select <32 x i1> %384, <32 x float> %383, <32 x float> zeroinitializer
  %386 = mul i64 %indvars.iv45, 3848290697216
  %sext52 = add i64 %386, 962072674304
  %387 = ashr exact i64 %sext52, 32
  %388 = getelementptr inbounds float, float* %10, i64 %387
  %389 = bitcast float* %388 to <32 x float>*
  store <32 x float> %385, <32 x float>* %389, align 64, !tbaa !2230
  %390 = fadd <32 x float> %327, %150
  %391 = fadd <32 x float> %324, %390
  %392 = fcmp ogt <32 x float> %391, zeroinitializer
  %393 = select <32 x i1> %392, <32 x float> %391, <32 x float> zeroinitializer
  %394 = mul i64 %indvars.iv45, 3848290697216
  %sext53 = add i64 %394, 1099511627776
  %395 = ashr exact i64 %sext53, 32
  %396 = getelementptr inbounds float, float* %10, i64 %395
  %397 = bitcast float* %396 to <32 x float>*
  store <32 x float> %393, <32 x float>* %397, align 64, !tbaa !2230
  %398 = fadd <32 x float> %327, %156
  %399 = fadd <32 x float> %324, %398
  %400 = fcmp ogt <32 x float> %399, zeroinitializer
  %401 = select <32 x i1> %400, <32 x float> %399, <32 x float> zeroinitializer
  %402 = mul i64 %indvars.iv45, 3848290697216
  %sext54 = add i64 %402, 1236950581248
  %403 = ashr exact i64 %sext54, 32
  %404 = getelementptr inbounds float, float* %10, i64 %403
  %405 = bitcast float* %404 to <32 x float>*
  store <32 x float> %401, <32 x float>* %405, align 64, !tbaa !2230
  %406 = load <32 x float>, <32 x float>* %119, align 64, !tbaa !2221
  %407 = fadd <32 x float> %327, %406
  %408 = fadd <32 x float> %324, %407
  %409 = fcmp ogt <32 x float> %408, zeroinitializer
  %410 = select <32 x i1> %409, <32 x float> %408, <32 x float> zeroinitializer
  %411 = mul i64 %indvars.iv45, 3848290697216
  %sext55 = add i64 %411, 1374389534720
  %412 = ashr exact i64 %sext55, 32
  %413 = getelementptr inbounds float, float* %10, i64 %412
  %414 = bitcast float* %413 to <32 x float>*
  store <32 x float> %410, <32 x float>* %414, align 64, !tbaa !2230
  %415 = load <32 x float>, <32 x float>* %121, align 64, !tbaa !2221
  %416 = fadd <32 x float> %327, %415
  %417 = fadd <32 x float> %324, %416
  %418 = fcmp ogt <32 x float> %417, zeroinitializer
  %419 = select <32 x i1> %418, <32 x float> %417, <32 x float> zeroinitializer
  %420 = mul i64 %indvars.iv45, 3848290697216
  %sext56 = add i64 %420, 1511828488192
  %421 = ashr exact i64 %sext56, 32
  %422 = getelementptr inbounds float, float* %10, i64 %421
  %423 = bitcast float* %422 to <32 x float>*
  store <32 x float> %419, <32 x float>* %423, align 64, !tbaa !2230
  %424 = load <32 x float>, <32 x float>* %123, align 64, !tbaa !2221
  %425 = fadd <32 x float> %327, %424
  %426 = fadd <32 x float> %324, %425
  %427 = fcmp ogt <32 x float> %426, zeroinitializer
  %428 = select <32 x i1> %427, <32 x float> %426, <32 x float> zeroinitializer
  %429 = mul i64 %indvars.iv45, 3848290697216
  %sext57 = add i64 %429, 1649267441664
  %430 = ashr exact i64 %sext57, 32
  %431 = getelementptr inbounds float, float* %10, i64 %430
  %432 = bitcast float* %431 to <32 x float>*
  store <32 x float> %428, <32 x float>* %432, align 64, !tbaa !2230
  %433 = load <32 x float>, <32 x float>* %125, align 64, !tbaa !2221
  %434 = fadd <32 x float> %327, %433
  %435 = fadd <32 x float> %324, %434
  %436 = fcmp ogt <32 x float> %435, zeroinitializer
  %437 = select <32 x i1> %436, <32 x float> %435, <32 x float> zeroinitializer
  %438 = mul i64 %indvars.iv45, 3848290697216
  %sext58 = add i64 %438, 1786706395136
  %439 = ashr exact i64 %sext58, 32
  %440 = getelementptr inbounds float, float* %10, i64 %439
  %441 = bitcast float* %440 to <32 x float>*
  store <32 x float> %437, <32 x float>* %441, align 64, !tbaa !2230
  %442 = load <32 x float>, <32 x float>* %182, align 64, !tbaa !2221
  %443 = fadd <32 x float> %327, %442
  %444 = fadd <32 x float> %324, %443
  %445 = fcmp ogt <32 x float> %444, zeroinitializer
  %446 = select <32 x i1> %445, <32 x float> %444, <32 x float> zeroinitializer
  %447 = mul i64 %indvars.iv45, 3848290697216
  %sext59 = add i64 %447, 1924145348608
  %448 = ashr exact i64 %sext59, 32
  %449 = getelementptr inbounds float, float* %10, i64 %448
  %450 = bitcast float* %449 to <32 x float>*
  store <32 x float> %446, <32 x float>* %450, align 64, !tbaa !2230
  %451 = load <32 x float>, <32 x float>* %184, align 64, !tbaa !2221
  %452 = fadd <32 x float> %327, %451
  %453 = fadd <32 x float> %324, %452
  %454 = fcmp ogt <32 x float> %453, zeroinitializer
  %455 = select <32 x i1> %454, <32 x float> %453, <32 x float> zeroinitializer
  %456 = mul i64 %indvars.iv45, 3848290697216
  %sext60 = add i64 %456, 2061584302080
  %457 = ashr exact i64 %sext60, 32
  %458 = getelementptr inbounds float, float* %10, i64 %457
  %459 = bitcast float* %458 to <32 x float>*
  store <32 x float> %455, <32 x float>* %459, align 64, !tbaa !2230
  %460 = load <32 x float>, <32 x float>* %186, align 64, !tbaa !2221
  %461 = fadd <32 x float> %327, %460
  %462 = fadd <32 x float> %324, %461
  %463 = fcmp ogt <32 x float> %462, zeroinitializer
  %464 = select <32 x i1> %463, <32 x float> %462, <32 x float> zeroinitializer
  %465 = mul i64 %indvars.iv45, 3848290697216
  %sext61 = add i64 %465, 2199023255552
  %466 = ashr exact i64 %sext61, 32
  %467 = getelementptr inbounds float, float* %10, i64 %466
  %468 = bitcast float* %467 to <32 x float>*
  store <32 x float> %464, <32 x float>* %468, align 64, !tbaa !2230
  %469 = load <32 x float>, <32 x float>* %188, align 64, !tbaa !2221
  %470 = fadd <32 x float> %327, %469
  %471 = fadd <32 x float> %324, %470
  %472 = fcmp ogt <32 x float> %471, zeroinitializer
  %473 = select <32 x i1> %472, <32 x float> %471, <32 x float> zeroinitializer
  %474 = mul i64 %indvars.iv45, 3848290697216
  %sext62 = add i64 %474, 2336462209024
  %475 = ashr exact i64 %sext62, 32
  %476 = getelementptr inbounds float, float* %10, i64 %475
  %477 = bitcast float* %476 to <32 x float>*
  store <32 x float> %473, <32 x float>* %477, align 64, !tbaa !2230
  %478 = load <32 x float>, <32 x float>* %190, align 64, !tbaa !2221
  %479 = fadd <32 x float> %327, %478
  %480 = fadd <32 x float> %324, %479
  %481 = fcmp ogt <32 x float> %480, zeroinitializer
  %482 = select <32 x i1> %481, <32 x float> %480, <32 x float> zeroinitializer
  %483 = mul i64 %indvars.iv45, 3848290697216
  %sext63 = add i64 %483, 2473901162496
  %484 = ashr exact i64 %sext63, 32
  %485 = getelementptr inbounds float, float* %10, i64 %484
  %486 = bitcast float* %485 to <32 x float>*
  store <32 x float> %482, <32 x float>* %486, align 64, !tbaa !2230
  %487 = load <32 x float>, <32 x float>* %192, align 64, !tbaa !2221
  %488 = fadd <32 x float> %327, %487
  %489 = fadd <32 x float> %324, %488
  %490 = fcmp ogt <32 x float> %489, zeroinitializer
  %491 = select <32 x i1> %490, <32 x float> %489, <32 x float> zeroinitializer
  %492 = mul i64 %indvars.iv45, 3848290697216
  %sext64 = add i64 %492, 2611340115968
  %493 = ashr exact i64 %sext64, 32
  %494 = getelementptr inbounds float, float* %10, i64 %493
  %495 = bitcast float* %494 to <32 x float>*
  store <32 x float> %491, <32 x float>* %495, align 64, !tbaa !2230
  %496 = load <32 x float>, <32 x float>* %194, align 64, !tbaa !2221
  %497 = fadd <32 x float> %327, %496
  %498 = fadd <32 x float> %324, %497
  %499 = fcmp ogt <32 x float> %498, zeroinitializer
  %500 = select <32 x i1> %499, <32 x float> %498, <32 x float> zeroinitializer
  %501 = mul i64 %indvars.iv45, 3848290697216
  %sext65 = add i64 %501, 2748779069440
  %502 = ashr exact i64 %sext65, 32
  %503 = getelementptr inbounds float, float* %10, i64 %502
  %504 = bitcast float* %503 to <32 x float>*
  store <32 x float> %500, <32 x float>* %504, align 64, !tbaa !2230
  %505 = load <32 x float>, <32 x float>* %251, align 64, !tbaa !2221
  %506 = fadd <32 x float> %327, %505
  %507 = fadd <32 x float> %324, %506
  %508 = fcmp ogt <32 x float> %507, zeroinitializer
  %509 = select <32 x i1> %508, <32 x float> %507, <32 x float> zeroinitializer
  %510 = mul i64 %indvars.iv45, 3848290697216
  %sext66 = add i64 %510, 2886218022912
  %511 = ashr exact i64 %sext66, 32
  %512 = getelementptr inbounds float, float* %10, i64 %511
  %513 = bitcast float* %512 to <32 x float>*
  store <32 x float> %509, <32 x float>* %513, align 64, !tbaa !2230
  %514 = load <32 x float>, <32 x float>* %253, align 64, !tbaa !2221
  %515 = fadd <32 x float> %327, %514
  %516 = fadd <32 x float> %324, %515
  %517 = fcmp ogt <32 x float> %516, zeroinitializer
  %518 = select <32 x i1> %517, <32 x float> %516, <32 x float> zeroinitializer
  %519 = mul i64 %indvars.iv45, 3848290697216
  %sext67 = add i64 %519, 3023656976384
  %520 = ashr exact i64 %sext67, 32
  %521 = getelementptr inbounds float, float* %10, i64 %520
  %522 = bitcast float* %521 to <32 x float>*
  store <32 x float> %518, <32 x float>* %522, align 64, !tbaa !2230
  %523 = load <32 x float>, <32 x float>* %255, align 64, !tbaa !2221
  %524 = fadd <32 x float> %327, %523
  %525 = fadd <32 x float> %324, %524
  %526 = fcmp ogt <32 x float> %525, zeroinitializer
  %527 = select <32 x i1> %526, <32 x float> %525, <32 x float> zeroinitializer
  %528 = mul i64 %indvars.iv45, 3848290697216
  %sext68 = add i64 %528, 3161095929856
  %529 = ashr exact i64 %sext68, 32
  %530 = getelementptr inbounds float, float* %10, i64 %529
  %531 = bitcast float* %530 to <32 x float>*
  store <32 x float> %527, <32 x float>* %531, align 64, !tbaa !2230
  %532 = load <32 x float>, <32 x float>* %257, align 64, !tbaa !2221
  %533 = fadd <32 x float> %327, %532
  %534 = fadd <32 x float> %324, %533
  %535 = fcmp ogt <32 x float> %534, zeroinitializer
  %536 = select <32 x i1> %535, <32 x float> %534, <32 x float> zeroinitializer
  %537 = mul i64 %indvars.iv45, 3848290697216
  %sext69 = add i64 %537, 3298534883328
  %538 = ashr exact i64 %sext69, 32
  %539 = getelementptr inbounds float, float* %10, i64 %538
  %540 = bitcast float* %539 to <32 x float>*
  store <32 x float> %536, <32 x float>* %540, align 64, !tbaa !2230
  %541 = load <32 x float>, <32 x float>* %259, align 64, !tbaa !2221
  %542 = fadd <32 x float> %327, %541
  %543 = fadd <32 x float> %324, %542
  %544 = fcmp ogt <32 x float> %543, zeroinitializer
  %545 = select <32 x i1> %544, <32 x float> %543, <32 x float> zeroinitializer
  %546 = mul i64 %indvars.iv45, 3848290697216
  %sext70 = add i64 %546, 3435973836800
  %547 = ashr exact i64 %sext70, 32
  %548 = getelementptr inbounds float, float* %10, i64 %547
  %549 = bitcast float* %548 to <32 x float>*
  store <32 x float> %545, <32 x float>* %549, align 64, !tbaa !2230
  %550 = load <32 x float>, <32 x float>* %261, align 64, !tbaa !2221
  %551 = fadd <32 x float> %327, %550
  %552 = fadd <32 x float> %324, %551
  %553 = fcmp ogt <32 x float> %552, zeroinitializer
  %554 = select <32 x i1> %553, <32 x float> %552, <32 x float> zeroinitializer
  %555 = mul i64 %indvars.iv45, 3848290697216
  %sext71 = add i64 %555, 3573412790272
  %556 = ashr exact i64 %sext71, 32
  %557 = getelementptr inbounds float, float* %10, i64 %556
  %558 = bitcast float* %557 to <32 x float>*
  store <32 x float> %554, <32 x float>* %558, align 64, !tbaa !2230
  %559 = load <32 x float>, <32 x float>* %263, align 64, !tbaa !2221
  %560 = fadd <32 x float> %327, %559
  %561 = fadd <32 x float> %324, %560
  %562 = fcmp ogt <32 x float> %561, zeroinitializer
  %563 = select <32 x i1> %562, <32 x float> %561, <32 x float> zeroinitializer
  %564 = mul i64 %indvars.iv45, 3848290697216
  %sext72 = add i64 %564, 3710851743744
  %565 = ashr exact i64 %sext72, 32
  %566 = getelementptr inbounds float, float* %10, i64 %565
  %567 = bitcast float* %566 to <32 x float>*
  store <32 x float> %563, <32 x float>* %567, align 64, !tbaa !2230
  %568 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %569 = tail call i32 %568(i32 1, i32 %19, i8* %37)
  %indvars.iv.next46 = add nsw i64 %indvars.iv45, 1
  %570 = icmp slt i64 %indvars.iv.next46, %35
  br i1 %570, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.218, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !2233
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !2247
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !2250
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !2252
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.219, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !2256
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.220, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.221, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.222, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.223, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !2258
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !2272
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 1
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !2274
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 28
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !2277
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 28
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !2279
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 512
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !2283
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 401408, i32 401408, i32 14336, i32 512>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !2295
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([243 x i8], [243 x i8]* @.str.225, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !2299
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 2
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.105, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !2313
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !2315
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !2318
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !2320
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 512
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !2324
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 64
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.227, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !2326
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 32768, i32 32768, i32 32768, i32 32768>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !2338
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 64
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !2342
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([279 x i8], [279 x i8]* @.str.228, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !2344
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 2
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.109, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !2358
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !2360
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !2363
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 64
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.229, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !2365
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.230, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !2377
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 2
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.112, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !2391
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !2393
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !2396
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 64
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.231, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !2398
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.232, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !2410
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !2424
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 2
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.115, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !2426
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 28
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.214, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !2429
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 28
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.215, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !2431
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 64
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.233, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !2435
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 100352, i32 50176, i32 1792, i32 64>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !2447
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.234, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_7_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %18, align 8
  %7 = getelementptr inbounds %18, %18* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %18, %18* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %18, %18* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %18, %18* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %18, %18* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %18, %18* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %18* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.235, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.235(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 55
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 56
  %27 = select i1 %26, i32 %25, i32 56
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 56
  %30 = select i1 %29, i32 %28, i32 56
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end6.6
  %indvars.iv36 = phi i64 [ %34, %for_body.preheader ], [ %indvars.iv.next37, %for_end6.6 ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %37 = tail call i8* %36(i32 1, i32 %19, i64 7168, i32 2, i32 32)
  %38 = trunc i64 %indvars.iv36 to i32
  %39 = srem i32 %38, 28
  %40 = mul nsw i32 %39, 14336
  %41 = sdiv i32 %38, 28
  %42 = shl i32 %41, 15
  %43 = sext i32 %42 to i64
  %44 = sext i32 %40 to i64
  %45 = bitcast i8* %37 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %45, align 64, !tbaa !2451
  %46 = getelementptr inbounds i8, i8* %37, i64 256
  %47 = bitcast i8* %46 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %47, align 64, !tbaa !2451
  %48 = getelementptr inbounds i8, i8* %37, i64 512
  %49 = bitcast i8* %48 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %49, align 64, !tbaa !2451
  %50 = getelementptr inbounds i8, i8* %37, i64 768
  %51 = bitcast i8* %50 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %51, align 64, !tbaa !2451
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %52 = phi <64 x float> [ zeroinitializer, %for_body ], [ %84, %for_body5 ]
  %53 = phi <64 x float> [ zeroinitializer, %for_body ], [ %78, %for_body5 ]
  %54 = phi <64 x float> [ zeroinitializer, %for_body ], [ %72, %for_body5 ]
  %55 = phi <64 x float> [ zeroinitializer, %for_body ], [ %66, %for_body5 ]
  %56 = add nsw i64 %indvars.iv, %44
  %57 = getelementptr inbounds float, float* %4, i64 %56
  %58 = load float, float* %57, align 4, !tbaa !2454
  %59 = insertelement <64 x float> undef, float %58, i32 0
  %60 = shufflevector <64 x float> %59, <64 x float> undef, <64 x i32> zeroinitializer
  %61 = shl i64 %indvars.iv, 6
  %62 = add nuw nsw i64 %61, %43
  %63 = getelementptr inbounds float, float* %7, i64 %62
  %64 = bitcast float* %63 to <64 x float>*
  %65 = load <64 x float>, <64 x float>* %64, align 64, !tbaa !2457
  %66 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %60, <64 x float> %65, <64 x float> %55)
  %67 = add nsw i64 %56, 512
  %68 = getelementptr inbounds float, float* %4, i64 %67
  %69 = load float, float* %68, align 4, !tbaa !2454
  %70 = insertelement <64 x float> undef, float %69, i32 0
  %71 = shufflevector <64 x float> %70, <64 x float> undef, <64 x i32> zeroinitializer
  %72 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %71, <64 x float> %65, <64 x float> %54)
  %73 = add nsw i64 %56, 1024
  %74 = getelementptr inbounds float, float* %4, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !2454
  %76 = insertelement <64 x float> undef, float %75, i32 0
  %77 = shufflevector <64 x float> %76, <64 x float> undef, <64 x i32> zeroinitializer
  %78 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %77, <64 x float> %65, <64 x float> %53)
  %79 = add nsw i64 %56, 1536
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !2454
  %82 = insertelement <64 x float> undef, float %81, i32 0
  %83 = shufflevector <64 x float> %82, <64 x float> undef, <64 x i32> zeroinitializer
  %84 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %83, <64 x float> %65, <64 x float> %52)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  store <64 x float> %66, <64 x float>* %45, align 64, !tbaa !2451
  store <64 x float> %72, <64 x float>* %47, align 64, !tbaa !2451
  store <64 x float> %78, <64 x float>* %49, align 64, !tbaa !2451
  store <64 x float> %84, <64 x float>* %51, align 64, !tbaa !2451
  %85 = getelementptr inbounds i8, i8* %37, i64 1024
  %86 = bitcast i8* %85 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %86, align 64, !tbaa !2451
  %87 = getelementptr inbounds i8, i8* %37, i64 1280
  %88 = bitcast i8* %87 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %88, align 64, !tbaa !2451
  %89 = getelementptr inbounds i8, i8* %37, i64 1536
  %90 = bitcast i8* %89 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %90, align 64, !tbaa !2451
  %91 = getelementptr inbounds i8, i8* %37, i64 1792
  %92 = bitcast i8* %91 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %92, align 64, !tbaa !2451
  %93 = add nsw i64 %44, 2048
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %94 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %126, %for_body5.1 ]
  %95 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %120, %for_body5.1 ]
  %96 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %114, %for_body5.1 ]
  %97 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %108, %for_body5.1 ]
  %98 = add nsw i64 %93, %indvars.iv.1
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !2454
  %101 = insertelement <64 x float> undef, float %100, i32 0
  %102 = shufflevector <64 x float> %101, <64 x float> undef, <64 x i32> zeroinitializer
  %103 = shl i64 %indvars.iv.1, 6
  %104 = add nuw nsw i64 %103, %43
  %105 = getelementptr inbounds float, float* %7, i64 %104
  %106 = bitcast float* %105 to <64 x float>*
  %107 = load <64 x float>, <64 x float>* %106, align 64, !tbaa !2457
  %108 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %102, <64 x float> %107, <64 x float> %97)
  %109 = add nsw i64 %98, 512
  %110 = getelementptr inbounds float, float* %4, i64 %109
  %111 = load float, float* %110, align 4, !tbaa !2454
  %112 = insertelement <64 x float> undef, float %111, i32 0
  %113 = shufflevector <64 x float> %112, <64 x float> undef, <64 x i32> zeroinitializer
  %114 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %113, <64 x float> %107, <64 x float> %96)
  %115 = add nsw i64 %98, 1024
  %116 = getelementptr inbounds float, float* %4, i64 %115
  %117 = load float, float* %116, align 4, !tbaa !2454
  %118 = insertelement <64 x float> undef, float %117, i32 0
  %119 = shufflevector <64 x float> %118, <64 x float> undef, <64 x i32> zeroinitializer
  %120 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %119, <64 x float> %107, <64 x float> %95)
  %121 = add nsw i64 %98, 1536
  %122 = getelementptr inbounds float, float* %4, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !2454
  %124 = insertelement <64 x float> undef, float %123, i32 0
  %125 = shufflevector <64 x float> %124, <64 x float> undef, <64 x i32> zeroinitializer
  %126 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %125, <64 x float> %107, <64 x float> %94)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %108, <64 x float>* %86, align 64, !tbaa !2451
  store <64 x float> %114, <64 x float>* %88, align 64, !tbaa !2451
  store <64 x float> %120, <64 x float>* %90, align 64, !tbaa !2451
  store <64 x float> %126, <64 x float>* %92, align 64, !tbaa !2451
  %127 = getelementptr inbounds i8, i8* %37, i64 2048
  %128 = bitcast i8* %127 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %128, align 64, !tbaa !2451
  %129 = getelementptr inbounds i8, i8* %37, i64 2304
  %130 = bitcast i8* %129 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %130, align 64, !tbaa !2451
  %131 = getelementptr inbounds i8, i8* %37, i64 2560
  %132 = bitcast i8* %131 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %132, align 64, !tbaa !2451
  %133 = getelementptr inbounds i8, i8* %37, i64 2816
  %134 = bitcast i8* %133 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %134, align 64, !tbaa !2451
  %135 = add nsw i64 %44, 4096
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %136 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %168, %for_body5.2 ]
  %137 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %162, %for_body5.2 ]
  %138 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %156, %for_body5.2 ]
  %139 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %150, %for_body5.2 ]
  %140 = add nsw i64 %135, %indvars.iv.2
  %141 = getelementptr inbounds float, float* %4, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !2454
  %143 = insertelement <64 x float> undef, float %142, i32 0
  %144 = shufflevector <64 x float> %143, <64 x float> undef, <64 x i32> zeroinitializer
  %145 = shl i64 %indvars.iv.2, 6
  %146 = add nuw nsw i64 %145, %43
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = bitcast float* %147 to <64 x float>*
  %149 = load <64 x float>, <64 x float>* %148, align 64, !tbaa !2457
  %150 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %144, <64 x float> %149, <64 x float> %139)
  %151 = add nsw i64 %140, 512
  %152 = getelementptr inbounds float, float* %4, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !2454
  %154 = insertelement <64 x float> undef, float %153, i32 0
  %155 = shufflevector <64 x float> %154, <64 x float> undef, <64 x i32> zeroinitializer
  %156 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %155, <64 x float> %149, <64 x float> %138)
  %157 = add nsw i64 %140, 1024
  %158 = getelementptr inbounds float, float* %4, i64 %157
  %159 = load float, float* %158, align 4, !tbaa !2454
  %160 = insertelement <64 x float> undef, float %159, i32 0
  %161 = shufflevector <64 x float> %160, <64 x float> undef, <64 x i32> zeroinitializer
  %162 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %161, <64 x float> %149, <64 x float> %137)
  %163 = add nsw i64 %140, 1536
  %164 = getelementptr inbounds float, float* %4, i64 %163
  %165 = load float, float* %164, align 4, !tbaa !2454
  %166 = insertelement <64 x float> undef, float %165, i32 0
  %167 = shufflevector <64 x float> %166, <64 x float> undef, <64 x i32> zeroinitializer
  %168 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %167, <64 x float> %149, <64 x float> %136)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %150, <64 x float>* %128, align 64, !tbaa !2451
  store <64 x float> %156, <64 x float>* %130, align 64, !tbaa !2451
  store <64 x float> %162, <64 x float>* %132, align 64, !tbaa !2451
  store <64 x float> %168, <64 x float>* %134, align 64, !tbaa !2451
  %169 = getelementptr inbounds i8, i8* %37, i64 3072
  %170 = bitcast i8* %169 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %170, align 64, !tbaa !2451
  %171 = getelementptr inbounds i8, i8* %37, i64 3328
  %172 = bitcast i8* %171 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %172, align 64, !tbaa !2451
  %173 = getelementptr inbounds i8, i8* %37, i64 3584
  %174 = bitcast i8* %173 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %174, align 64, !tbaa !2451
  %175 = getelementptr inbounds i8, i8* %37, i64 3840
  %176 = bitcast i8* %175 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %176, align 64, !tbaa !2451
  %177 = add nsw i64 %44, 6144
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %178 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %210, %for_body5.3 ]
  %179 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %204, %for_body5.3 ]
  %180 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %198, %for_body5.3 ]
  %181 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %192, %for_body5.3 ]
  %182 = add nsw i64 %177, %indvars.iv.3
  %183 = getelementptr inbounds float, float* %4, i64 %182
  %184 = load float, float* %183, align 4, !tbaa !2454
  %185 = insertelement <64 x float> undef, float %184, i32 0
  %186 = shufflevector <64 x float> %185, <64 x float> undef, <64 x i32> zeroinitializer
  %187 = shl i64 %indvars.iv.3, 6
  %188 = add nuw nsw i64 %187, %43
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to <64 x float>*
  %191 = load <64 x float>, <64 x float>* %190, align 64, !tbaa !2457
  %192 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %186, <64 x float> %191, <64 x float> %181)
  %193 = add nsw i64 %182, 512
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = load float, float* %194, align 4, !tbaa !2454
  %196 = insertelement <64 x float> undef, float %195, i32 0
  %197 = shufflevector <64 x float> %196, <64 x float> undef, <64 x i32> zeroinitializer
  %198 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %197, <64 x float> %191, <64 x float> %180)
  %199 = add nsw i64 %182, 1024
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !2454
  %202 = insertelement <64 x float> undef, float %201, i32 0
  %203 = shufflevector <64 x float> %202, <64 x float> undef, <64 x i32> zeroinitializer
  %204 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %203, <64 x float> %191, <64 x float> %179)
  %205 = add nsw i64 %182, 1536
  %206 = getelementptr inbounds float, float* %4, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !2454
  %208 = insertelement <64 x float> undef, float %207, i32 0
  %209 = shufflevector <64 x float> %208, <64 x float> undef, <64 x i32> zeroinitializer
  %210 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %209, <64 x float> %191, <64 x float> %178)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %192, <64 x float>* %170, align 64, !tbaa !2451
  store <64 x float> %198, <64 x float>* %172, align 64, !tbaa !2451
  store <64 x float> %204, <64 x float>* %174, align 64, !tbaa !2451
  store <64 x float> %210, <64 x float>* %176, align 64, !tbaa !2451
  %211 = getelementptr inbounds i8, i8* %37, i64 4096
  %212 = bitcast i8* %211 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %212, align 64, !tbaa !2451
  %213 = getelementptr inbounds i8, i8* %37, i64 4352
  %214 = bitcast i8* %213 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %214, align 64, !tbaa !2451
  %215 = getelementptr inbounds i8, i8* %37, i64 4608
  %216 = bitcast i8* %215 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %216, align 64, !tbaa !2451
  %217 = getelementptr inbounds i8, i8* %37, i64 4864
  %218 = bitcast i8* %217 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %218, align 64, !tbaa !2451
  %219 = add nsw i64 %44, 8192
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %220 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %252, %for_body5.4 ]
  %221 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %246, %for_body5.4 ]
  %222 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %240, %for_body5.4 ]
  %223 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %234, %for_body5.4 ]
  %224 = add nsw i64 %219, %indvars.iv.4
  %225 = getelementptr inbounds float, float* %4, i64 %224
  %226 = load float, float* %225, align 4, !tbaa !2454
  %227 = insertelement <64 x float> undef, float %226, i32 0
  %228 = shufflevector <64 x float> %227, <64 x float> undef, <64 x i32> zeroinitializer
  %229 = shl i64 %indvars.iv.4, 6
  %230 = add nuw nsw i64 %229, %43
  %231 = getelementptr inbounds float, float* %7, i64 %230
  %232 = bitcast float* %231 to <64 x float>*
  %233 = load <64 x float>, <64 x float>* %232, align 64, !tbaa !2457
  %234 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %228, <64 x float> %233, <64 x float> %223)
  %235 = add nsw i64 %224, 512
  %236 = getelementptr inbounds float, float* %4, i64 %235
  %237 = load float, float* %236, align 4, !tbaa !2454
  %238 = insertelement <64 x float> undef, float %237, i32 0
  %239 = shufflevector <64 x float> %238, <64 x float> undef, <64 x i32> zeroinitializer
  %240 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %239, <64 x float> %233, <64 x float> %222)
  %241 = add nsw i64 %224, 1024
  %242 = getelementptr inbounds float, float* %4, i64 %241
  %243 = load float, float* %242, align 4, !tbaa !2454
  %244 = insertelement <64 x float> undef, float %243, i32 0
  %245 = shufflevector <64 x float> %244, <64 x float> undef, <64 x i32> zeroinitializer
  %246 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %245, <64 x float> %233, <64 x float> %221)
  %247 = add nsw i64 %224, 1536
  %248 = getelementptr inbounds float, float* %4, i64 %247
  %249 = load float, float* %248, align 4, !tbaa !2454
  %250 = insertelement <64 x float> undef, float %249, i32 0
  %251 = shufflevector <64 x float> %250, <64 x float> undef, <64 x i32> zeroinitializer
  %252 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %251, <64 x float> %233, <64 x float> %220)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %234, <64 x float>* %212, align 64, !tbaa !2451
  store <64 x float> %240, <64 x float>* %214, align 64, !tbaa !2451
  store <64 x float> %246, <64 x float>* %216, align 64, !tbaa !2451
  store <64 x float> %252, <64 x float>* %218, align 64, !tbaa !2451
  %253 = getelementptr inbounds i8, i8* %37, i64 5120
  %254 = bitcast i8* %253 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %254, align 64, !tbaa !2451
  %255 = getelementptr inbounds i8, i8* %37, i64 5376
  %256 = bitcast i8* %255 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %256, align 64, !tbaa !2451
  %257 = getelementptr inbounds i8, i8* %37, i64 5632
  %258 = bitcast i8* %257 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %258, align 64, !tbaa !2451
  %259 = getelementptr inbounds i8, i8* %37, i64 5888
  %260 = bitcast i8* %259 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %260, align 64, !tbaa !2451
  %261 = add nsw i64 %44, 10240
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %262 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %294, %for_body5.5 ]
  %263 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %288, %for_body5.5 ]
  %264 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %282, %for_body5.5 ]
  %265 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %276, %for_body5.5 ]
  %266 = add nsw i64 %261, %indvars.iv.5
  %267 = getelementptr inbounds float, float* %4, i64 %266
  %268 = load float, float* %267, align 4, !tbaa !2454
  %269 = insertelement <64 x float> undef, float %268, i32 0
  %270 = shufflevector <64 x float> %269, <64 x float> undef, <64 x i32> zeroinitializer
  %271 = shl i64 %indvars.iv.5, 6
  %272 = add nuw nsw i64 %271, %43
  %273 = getelementptr inbounds float, float* %7, i64 %272
  %274 = bitcast float* %273 to <64 x float>*
  %275 = load <64 x float>, <64 x float>* %274, align 64, !tbaa !2457
  %276 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %270, <64 x float> %275, <64 x float> %265)
  %277 = add nsw i64 %266, 512
  %278 = getelementptr inbounds float, float* %4, i64 %277
  %279 = load float, float* %278, align 4, !tbaa !2454
  %280 = insertelement <64 x float> undef, float %279, i32 0
  %281 = shufflevector <64 x float> %280, <64 x float> undef, <64 x i32> zeroinitializer
  %282 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %281, <64 x float> %275, <64 x float> %264)
  %283 = add nsw i64 %266, 1024
  %284 = getelementptr inbounds float, float* %4, i64 %283
  %285 = load float, float* %284, align 4, !tbaa !2454
  %286 = insertelement <64 x float> undef, float %285, i32 0
  %287 = shufflevector <64 x float> %286, <64 x float> undef, <64 x i32> zeroinitializer
  %288 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %287, <64 x float> %275, <64 x float> %263)
  %289 = add nsw i64 %266, 1536
  %290 = getelementptr inbounds float, float* %4, i64 %289
  %291 = load float, float* %290, align 4, !tbaa !2454
  %292 = insertelement <64 x float> undef, float %291, i32 0
  %293 = shufflevector <64 x float> %292, <64 x float> undef, <64 x i32> zeroinitializer
  %294 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %293, <64 x float> %275, <64 x float> %262)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %276, <64 x float>* %254, align 64, !tbaa !2451
  store <64 x float> %282, <64 x float>* %256, align 64, !tbaa !2451
  store <64 x float> %288, <64 x float>* %258, align 64, !tbaa !2451
  store <64 x float> %294, <64 x float>* %260, align 64, !tbaa !2451
  %295 = getelementptr inbounds i8, i8* %37, i64 6144
  %296 = bitcast i8* %295 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %296, align 64, !tbaa !2451
  %297 = getelementptr inbounds i8, i8* %37, i64 6400
  %298 = bitcast i8* %297 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %298, align 64, !tbaa !2451
  %299 = getelementptr inbounds i8, i8* %37, i64 6656
  %300 = bitcast i8* %299 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %300, align 64, !tbaa !2451
  %301 = getelementptr inbounds i8, i8* %37, i64 6912
  %302 = bitcast i8* %301 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %302, align 64, !tbaa !2451
  %303 = add nsw i64 %44, 12288
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %304 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %336, %for_body5.6 ]
  %305 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %330, %for_body5.6 ]
  %306 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %324, %for_body5.6 ]
  %307 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %318, %for_body5.6 ]
  %308 = add nsw i64 %303, %indvars.iv.6
  %309 = getelementptr inbounds float, float* %4, i64 %308
  %310 = load float, float* %309, align 4, !tbaa !2454
  %311 = insertelement <64 x float> undef, float %310, i32 0
  %312 = shufflevector <64 x float> %311, <64 x float> undef, <64 x i32> zeroinitializer
  %313 = shl i64 %indvars.iv.6, 6
  %314 = add nuw nsw i64 %313, %43
  %315 = getelementptr inbounds float, float* %7, i64 %314
  %316 = bitcast float* %315 to <64 x float>*
  %317 = load <64 x float>, <64 x float>* %316, align 64, !tbaa !2457
  %318 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %312, <64 x float> %317, <64 x float> %307)
  %319 = add nsw i64 %308, 512
  %320 = getelementptr inbounds float, float* %4, i64 %319
  %321 = load float, float* %320, align 4, !tbaa !2454
  %322 = insertelement <64 x float> undef, float %321, i32 0
  %323 = shufflevector <64 x float> %322, <64 x float> undef, <64 x i32> zeroinitializer
  %324 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %323, <64 x float> %317, <64 x float> %306)
  %325 = add nsw i64 %308, 1024
  %326 = getelementptr inbounds float, float* %4, i64 %325
  %327 = load float, float* %326, align 4, !tbaa !2454
  %328 = insertelement <64 x float> undef, float %327, i32 0
  %329 = shufflevector <64 x float> %328, <64 x float> undef, <64 x i32> zeroinitializer
  %330 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %329, <64 x float> %317, <64 x float> %305)
  %331 = add nsw i64 %308, 1536
  %332 = getelementptr inbounds float, float* %4, i64 %331
  %333 = load float, float* %332, align 4, !tbaa !2454
  %334 = insertelement <64 x float> undef, float %333, i32 0
  %335 = shufflevector <64 x float> %334, <64 x float> undef, <64 x i32> zeroinitializer
  %336 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %335, <64 x float> %317, <64 x float> %304)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %318, <64 x float>* %296, align 64, !tbaa !2451
  store <64 x float> %324, <64 x float>* %298, align 64, !tbaa !2451
  store <64 x float> %330, <64 x float>* %300, align 64, !tbaa !2451
  store <64 x float> %336, <64 x float>* %302, align 64, !tbaa !2451
  %337 = mul nsw i64 %indvars.iv36, 1792
  %338 = shl nsw i32 %41, 6
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds float, float* %16, i64 %339
  %341 = bitcast float* %340 to <64 x float>*
  %342 = load <64 x float>, <64 x float>* %341, align 64, !tbaa !2460
  %343 = getelementptr inbounds float, float* %13, i64 %339
  %344 = bitcast float* %343 to <64 x float>*
  %345 = load <64 x float>, <64 x float>* %344, align 64, !tbaa !2463
  %346 = bitcast i8* %37 to <64 x float>*
  %347 = load <64 x float>, <64 x float>* %346, align 64, !tbaa !2451
  %348 = fadd <64 x float> %345, %347
  %349 = fadd <64 x float> %342, %348
  %350 = fcmp ogt <64 x float> %349, zeroinitializer
  %351 = select <64 x i1> %350, <64 x float> %349, <64 x float> zeroinitializer
  %352 = getelementptr inbounds float, float* %10, i64 %337
  %353 = bitcast float* %352 to <64 x float>*
  store <64 x float> %351, <64 x float>* %353, align 64, !tbaa !2466
  %354 = getelementptr inbounds i8, i8* %37, i64 256
  %355 = bitcast i8* %354 to <64 x float>*
  %356 = load <64 x float>, <64 x float>* %355, align 64, !tbaa !2451
  %357 = fadd <64 x float> %345, %356
  %358 = fadd <64 x float> %342, %357
  %359 = fcmp ogt <64 x float> %358, zeroinitializer
  %360 = select <64 x i1> %359, <64 x float> %358, <64 x float> zeroinitializer
  %361 = mul i64 %indvars.iv36, 7696581394432
  %sext = ashr exact i64 %361, 32
  %362 = or i64 %sext, 64
  %363 = getelementptr inbounds float, float* %10, i64 %362
  %364 = bitcast float* %363 to <64 x float>*
  store <64 x float> %360, <64 x float>* %364, align 64, !tbaa !2466
  %365 = getelementptr inbounds i8, i8* %37, i64 512
  %366 = bitcast i8* %365 to <64 x float>*
  %367 = load <64 x float>, <64 x float>* %366, align 64, !tbaa !2451
  %368 = fadd <64 x float> %345, %367
  %369 = fadd <64 x float> %342, %368
  %370 = fcmp ogt <64 x float> %369, zeroinitializer
  %371 = select <64 x i1> %370, <64 x float> %369, <64 x float> zeroinitializer
  %372 = mul i64 %indvars.iv36, 7696581394432
  %sext38 = ashr exact i64 %372, 32
  %373 = or i64 %sext38, 128
  %374 = getelementptr inbounds float, float* %10, i64 %373
  %375 = bitcast float* %374 to <64 x float>*
  store <64 x float> %371, <64 x float>* %375, align 64, !tbaa !2466
  %376 = getelementptr inbounds i8, i8* %37, i64 768
  %377 = bitcast i8* %376 to <64 x float>*
  %378 = load <64 x float>, <64 x float>* %377, align 64, !tbaa !2451
  %379 = fadd <64 x float> %345, %378
  %380 = fadd <64 x float> %342, %379
  %381 = fcmp ogt <64 x float> %380, zeroinitializer
  %382 = select <64 x i1> %381, <64 x float> %380, <64 x float> zeroinitializer
  %383 = mul i64 %indvars.iv36, 7696581394432
  %sext39 = ashr exact i64 %383, 32
  %384 = or i64 %sext39, 192
  %385 = getelementptr inbounds float, float* %10, i64 %384
  %386 = bitcast float* %385 to <64 x float>*
  store <64 x float> %382, <64 x float>* %386, align 64, !tbaa !2466
  %387 = getelementptr inbounds i8, i8* %37, i64 1024
  %388 = bitcast i8* %387 to <64 x float>*
  %389 = load <64 x float>, <64 x float>* %388, align 64, !tbaa !2451
  %390 = fadd <64 x float> %345, %389
  %391 = fadd <64 x float> %342, %390
  %392 = fcmp ogt <64 x float> %391, zeroinitializer
  %393 = select <64 x i1> %392, <64 x float> %391, <64 x float> zeroinitializer
  %394 = mul i64 %indvars.iv36, 7696581394432
  %sext40 = add i64 %394, 1099511627776
  %395 = ashr exact i64 %sext40, 32
  %396 = getelementptr inbounds float, float* %10, i64 %395
  %397 = bitcast float* %396 to <64 x float>*
  store <64 x float> %393, <64 x float>* %397, align 64, !tbaa !2466
  %398 = getelementptr inbounds i8, i8* %37, i64 1280
  %399 = bitcast i8* %398 to <64 x float>*
  %400 = load <64 x float>, <64 x float>* %399, align 64, !tbaa !2451
  %401 = fadd <64 x float> %345, %400
  %402 = fadd <64 x float> %342, %401
  %403 = fcmp ogt <64 x float> %402, zeroinitializer
  %404 = select <64 x i1> %403, <64 x float> %402, <64 x float> zeroinitializer
  %405 = mul i64 %indvars.iv36, 7696581394432
  %sext41 = add i64 %405, 1374389534720
  %406 = ashr exact i64 %sext41, 32
  %407 = getelementptr inbounds float, float* %10, i64 %406
  %408 = bitcast float* %407 to <64 x float>*
  store <64 x float> %404, <64 x float>* %408, align 64, !tbaa !2466
  %409 = getelementptr inbounds i8, i8* %37, i64 1536
  %410 = bitcast i8* %409 to <64 x float>*
  %411 = load <64 x float>, <64 x float>* %410, align 64, !tbaa !2451
  %412 = fadd <64 x float> %345, %411
  %413 = fadd <64 x float> %342, %412
  %414 = fcmp ogt <64 x float> %413, zeroinitializer
  %415 = select <64 x i1> %414, <64 x float> %413, <64 x float> zeroinitializer
  %416 = mul i64 %indvars.iv36, 7696581394432
  %sext42 = add i64 %416, 1649267441664
  %417 = ashr exact i64 %sext42, 32
  %418 = getelementptr inbounds float, float* %10, i64 %417
  %419 = bitcast float* %418 to <64 x float>*
  store <64 x float> %415, <64 x float>* %419, align 64, !tbaa !2466
  %420 = getelementptr inbounds i8, i8* %37, i64 1792
  %421 = bitcast i8* %420 to <64 x float>*
  %422 = load <64 x float>, <64 x float>* %421, align 64, !tbaa !2451
  %423 = fadd <64 x float> %345, %422
  %424 = fadd <64 x float> %342, %423
  %425 = fcmp ogt <64 x float> %424, zeroinitializer
  %426 = select <64 x i1> %425, <64 x float> %424, <64 x float> zeroinitializer
  %427 = mul i64 %indvars.iv36, 7696581394432
  %sext43 = add i64 %427, 1924145348608
  %428 = ashr exact i64 %sext43, 32
  %429 = getelementptr inbounds float, float* %10, i64 %428
  %430 = bitcast float* %429 to <64 x float>*
  store <64 x float> %426, <64 x float>* %430, align 64, !tbaa !2466
  %431 = getelementptr inbounds i8, i8* %37, i64 2048
  %432 = bitcast i8* %431 to <64 x float>*
  %433 = load <64 x float>, <64 x float>* %432, align 64, !tbaa !2451
  %434 = fadd <64 x float> %345, %433
  %435 = fadd <64 x float> %342, %434
  %436 = fcmp ogt <64 x float> %435, zeroinitializer
  %437 = select <64 x i1> %436, <64 x float> %435, <64 x float> zeroinitializer
  %438 = mul i64 %indvars.iv36, 7696581394432
  %sext44 = add i64 %438, 2199023255552
  %439 = ashr exact i64 %sext44, 32
  %440 = getelementptr inbounds float, float* %10, i64 %439
  %441 = bitcast float* %440 to <64 x float>*
  store <64 x float> %437, <64 x float>* %441, align 64, !tbaa !2466
  %442 = getelementptr inbounds i8, i8* %37, i64 2304
  %443 = bitcast i8* %442 to <64 x float>*
  %444 = load <64 x float>, <64 x float>* %443, align 64, !tbaa !2451
  %445 = fadd <64 x float> %345, %444
  %446 = fadd <64 x float> %342, %445
  %447 = fcmp ogt <64 x float> %446, zeroinitializer
  %448 = select <64 x i1> %447, <64 x float> %446, <64 x float> zeroinitializer
  %449 = mul i64 %indvars.iv36, 7696581394432
  %sext45 = add i64 %449, 2473901162496
  %450 = ashr exact i64 %sext45, 32
  %451 = getelementptr inbounds float, float* %10, i64 %450
  %452 = bitcast float* %451 to <64 x float>*
  store <64 x float> %448, <64 x float>* %452, align 64, !tbaa !2466
  %453 = getelementptr inbounds i8, i8* %37, i64 2560
  %454 = bitcast i8* %453 to <64 x float>*
  %455 = load <64 x float>, <64 x float>* %454, align 64, !tbaa !2451
  %456 = fadd <64 x float> %345, %455
  %457 = fadd <64 x float> %342, %456
  %458 = fcmp ogt <64 x float> %457, zeroinitializer
  %459 = select <64 x i1> %458, <64 x float> %457, <64 x float> zeroinitializer
  %460 = mul i64 %indvars.iv36, 7696581394432
  %sext46 = add i64 %460, 2748779069440
  %461 = ashr exact i64 %sext46, 32
  %462 = getelementptr inbounds float, float* %10, i64 %461
  %463 = bitcast float* %462 to <64 x float>*
  store <64 x float> %459, <64 x float>* %463, align 64, !tbaa !2466
  %464 = getelementptr inbounds i8, i8* %37, i64 2816
  %465 = bitcast i8* %464 to <64 x float>*
  %466 = load <64 x float>, <64 x float>* %465, align 64, !tbaa !2451
  %467 = fadd <64 x float> %345, %466
  %468 = fadd <64 x float> %342, %467
  %469 = fcmp ogt <64 x float> %468, zeroinitializer
  %470 = select <64 x i1> %469, <64 x float> %468, <64 x float> zeroinitializer
  %471 = mul i64 %indvars.iv36, 7696581394432
  %sext47 = add i64 %471, 3023656976384
  %472 = ashr exact i64 %sext47, 32
  %473 = getelementptr inbounds float, float* %10, i64 %472
  %474 = bitcast float* %473 to <64 x float>*
  store <64 x float> %470, <64 x float>* %474, align 64, !tbaa !2466
  %475 = getelementptr inbounds i8, i8* %37, i64 3072
  %476 = bitcast i8* %475 to <64 x float>*
  %477 = load <64 x float>, <64 x float>* %476, align 64, !tbaa !2451
  %478 = fadd <64 x float> %345, %477
  %479 = fadd <64 x float> %342, %478
  %480 = fcmp ogt <64 x float> %479, zeroinitializer
  %481 = select <64 x i1> %480, <64 x float> %479, <64 x float> zeroinitializer
  %482 = mul i64 %indvars.iv36, 7696581394432
  %sext48 = add i64 %482, 3298534883328
  %483 = ashr exact i64 %sext48, 32
  %484 = getelementptr inbounds float, float* %10, i64 %483
  %485 = bitcast float* %484 to <64 x float>*
  store <64 x float> %481, <64 x float>* %485, align 64, !tbaa !2466
  %486 = getelementptr inbounds i8, i8* %37, i64 3328
  %487 = bitcast i8* %486 to <64 x float>*
  %488 = load <64 x float>, <64 x float>* %487, align 64, !tbaa !2451
  %489 = fadd <64 x float> %345, %488
  %490 = fadd <64 x float> %342, %489
  %491 = fcmp ogt <64 x float> %490, zeroinitializer
  %492 = select <64 x i1> %491, <64 x float> %490, <64 x float> zeroinitializer
  %493 = mul i64 %indvars.iv36, 7696581394432
  %sext49 = add i64 %493, 3573412790272
  %494 = ashr exact i64 %sext49, 32
  %495 = getelementptr inbounds float, float* %10, i64 %494
  %496 = bitcast float* %495 to <64 x float>*
  store <64 x float> %492, <64 x float>* %496, align 64, !tbaa !2466
  %497 = getelementptr inbounds i8, i8* %37, i64 3584
  %498 = bitcast i8* %497 to <64 x float>*
  %499 = load <64 x float>, <64 x float>* %498, align 64, !tbaa !2451
  %500 = fadd <64 x float> %345, %499
  %501 = fadd <64 x float> %342, %500
  %502 = fcmp ogt <64 x float> %501, zeroinitializer
  %503 = select <64 x i1> %502, <64 x float> %501, <64 x float> zeroinitializer
  %504 = mul i64 %indvars.iv36, 7696581394432
  %sext50 = add i64 %504, 3848290697216
  %505 = ashr exact i64 %sext50, 32
  %506 = getelementptr inbounds float, float* %10, i64 %505
  %507 = bitcast float* %506 to <64 x float>*
  store <64 x float> %503, <64 x float>* %507, align 64, !tbaa !2466
  %508 = getelementptr inbounds i8, i8* %37, i64 3840
  %509 = bitcast i8* %508 to <64 x float>*
  %510 = load <64 x float>, <64 x float>* %509, align 64, !tbaa !2451
  %511 = fadd <64 x float> %345, %510
  %512 = fadd <64 x float> %342, %511
  %513 = fcmp ogt <64 x float> %512, zeroinitializer
  %514 = select <64 x i1> %513, <64 x float> %512, <64 x float> zeroinitializer
  %515 = mul i64 %indvars.iv36, 7696581394432
  %sext51 = add i64 %515, 4123168604160
  %516 = ashr exact i64 %sext51, 32
  %517 = getelementptr inbounds float, float* %10, i64 %516
  %518 = bitcast float* %517 to <64 x float>*
  store <64 x float> %514, <64 x float>* %518, align 64, !tbaa !2466
  %519 = getelementptr inbounds i8, i8* %37, i64 4096
  %520 = bitcast i8* %519 to <64 x float>*
  %521 = load <64 x float>, <64 x float>* %520, align 64, !tbaa !2451
  %522 = fadd <64 x float> %345, %521
  %523 = fadd <64 x float> %342, %522
  %524 = fcmp ogt <64 x float> %523, zeroinitializer
  %525 = select <64 x i1> %524, <64 x float> %523, <64 x float> zeroinitializer
  %526 = mul i64 %indvars.iv36, 7696581394432
  %sext52 = add i64 %526, 4398046511104
  %527 = ashr exact i64 %sext52, 32
  %528 = getelementptr inbounds float, float* %10, i64 %527
  %529 = bitcast float* %528 to <64 x float>*
  store <64 x float> %525, <64 x float>* %529, align 64, !tbaa !2466
  %530 = getelementptr inbounds i8, i8* %37, i64 4352
  %531 = bitcast i8* %530 to <64 x float>*
  %532 = load <64 x float>, <64 x float>* %531, align 64, !tbaa !2451
  %533 = fadd <64 x float> %345, %532
  %534 = fadd <64 x float> %342, %533
  %535 = fcmp ogt <64 x float> %534, zeroinitializer
  %536 = select <64 x i1> %535, <64 x float> %534, <64 x float> zeroinitializer
  %537 = mul i64 %indvars.iv36, 7696581394432
  %sext53 = add i64 %537, 4672924418048
  %538 = ashr exact i64 %sext53, 32
  %539 = getelementptr inbounds float, float* %10, i64 %538
  %540 = bitcast float* %539 to <64 x float>*
  store <64 x float> %536, <64 x float>* %540, align 64, !tbaa !2466
  %541 = getelementptr inbounds i8, i8* %37, i64 4608
  %542 = bitcast i8* %541 to <64 x float>*
  %543 = load <64 x float>, <64 x float>* %542, align 64, !tbaa !2451
  %544 = fadd <64 x float> %345, %543
  %545 = fadd <64 x float> %342, %544
  %546 = fcmp ogt <64 x float> %545, zeroinitializer
  %547 = select <64 x i1> %546, <64 x float> %545, <64 x float> zeroinitializer
  %548 = mul i64 %indvars.iv36, 7696581394432
  %sext54 = add i64 %548, 4947802324992
  %549 = ashr exact i64 %sext54, 32
  %550 = getelementptr inbounds float, float* %10, i64 %549
  %551 = bitcast float* %550 to <64 x float>*
  store <64 x float> %547, <64 x float>* %551, align 64, !tbaa !2466
  %552 = getelementptr inbounds i8, i8* %37, i64 4864
  %553 = bitcast i8* %552 to <64 x float>*
  %554 = load <64 x float>, <64 x float>* %553, align 64, !tbaa !2451
  %555 = fadd <64 x float> %345, %554
  %556 = fadd <64 x float> %342, %555
  %557 = fcmp ogt <64 x float> %556, zeroinitializer
  %558 = select <64 x i1> %557, <64 x float> %556, <64 x float> zeroinitializer
  %559 = mul i64 %indvars.iv36, 7696581394432
  %sext55 = add i64 %559, 5222680231936
  %560 = ashr exact i64 %sext55, 32
  %561 = getelementptr inbounds float, float* %10, i64 %560
  %562 = bitcast float* %561 to <64 x float>*
  store <64 x float> %558, <64 x float>* %562, align 64, !tbaa !2466
  %563 = getelementptr inbounds i8, i8* %37, i64 5120
  %564 = bitcast i8* %563 to <64 x float>*
  %565 = load <64 x float>, <64 x float>* %564, align 64, !tbaa !2451
  %566 = fadd <64 x float> %345, %565
  %567 = fadd <64 x float> %342, %566
  %568 = fcmp ogt <64 x float> %567, zeroinitializer
  %569 = select <64 x i1> %568, <64 x float> %567, <64 x float> zeroinitializer
  %570 = mul i64 %indvars.iv36, 7696581394432
  %sext56 = add i64 %570, 5497558138880
  %571 = ashr exact i64 %sext56, 32
  %572 = getelementptr inbounds float, float* %10, i64 %571
  %573 = bitcast float* %572 to <64 x float>*
  store <64 x float> %569, <64 x float>* %573, align 64, !tbaa !2466
  %574 = getelementptr inbounds i8, i8* %37, i64 5376
  %575 = bitcast i8* %574 to <64 x float>*
  %576 = load <64 x float>, <64 x float>* %575, align 64, !tbaa !2451
  %577 = fadd <64 x float> %345, %576
  %578 = fadd <64 x float> %342, %577
  %579 = fcmp ogt <64 x float> %578, zeroinitializer
  %580 = select <64 x i1> %579, <64 x float> %578, <64 x float> zeroinitializer
  %581 = mul i64 %indvars.iv36, 7696581394432
  %sext57 = add i64 %581, 5772436045824
  %582 = ashr exact i64 %sext57, 32
  %583 = getelementptr inbounds float, float* %10, i64 %582
  %584 = bitcast float* %583 to <64 x float>*
  store <64 x float> %580, <64 x float>* %584, align 64, !tbaa !2466
  %585 = getelementptr inbounds i8, i8* %37, i64 5632
  %586 = bitcast i8* %585 to <64 x float>*
  %587 = load <64 x float>, <64 x float>* %586, align 64, !tbaa !2451
  %588 = fadd <64 x float> %345, %587
  %589 = fadd <64 x float> %342, %588
  %590 = fcmp ogt <64 x float> %589, zeroinitializer
  %591 = select <64 x i1> %590, <64 x float> %589, <64 x float> zeroinitializer
  %592 = mul i64 %indvars.iv36, 7696581394432
  %sext58 = add i64 %592, 6047313952768
  %593 = ashr exact i64 %sext58, 32
  %594 = getelementptr inbounds float, float* %10, i64 %593
  %595 = bitcast float* %594 to <64 x float>*
  store <64 x float> %591, <64 x float>* %595, align 64, !tbaa !2466
  %596 = getelementptr inbounds i8, i8* %37, i64 5888
  %597 = bitcast i8* %596 to <64 x float>*
  %598 = load <64 x float>, <64 x float>* %597, align 64, !tbaa !2451
  %599 = fadd <64 x float> %345, %598
  %600 = fadd <64 x float> %342, %599
  %601 = fcmp ogt <64 x float> %600, zeroinitializer
  %602 = select <64 x i1> %601, <64 x float> %600, <64 x float> zeroinitializer
  %603 = mul i64 %indvars.iv36, 7696581394432
  %sext59 = add i64 %603, 6322191859712
  %604 = ashr exact i64 %sext59, 32
  %605 = getelementptr inbounds float, float* %10, i64 %604
  %606 = bitcast float* %605 to <64 x float>*
  store <64 x float> %602, <64 x float>* %606, align 64, !tbaa !2466
  %607 = getelementptr inbounds i8, i8* %37, i64 6144
  %608 = bitcast i8* %607 to <64 x float>*
  %609 = load <64 x float>, <64 x float>* %608, align 64, !tbaa !2451
  %610 = fadd <64 x float> %345, %609
  %611 = fadd <64 x float> %342, %610
  %612 = fcmp ogt <64 x float> %611, zeroinitializer
  %613 = select <64 x i1> %612, <64 x float> %611, <64 x float> zeroinitializer
  %614 = mul i64 %indvars.iv36, 7696581394432
  %sext60 = add i64 %614, 6597069766656
  %615 = ashr exact i64 %sext60, 32
  %616 = getelementptr inbounds float, float* %10, i64 %615
  %617 = bitcast float* %616 to <64 x float>*
  store <64 x float> %613, <64 x float>* %617, align 64, !tbaa !2466
  %618 = getelementptr inbounds i8, i8* %37, i64 6400
  %619 = bitcast i8* %618 to <64 x float>*
  %620 = load <64 x float>, <64 x float>* %619, align 64, !tbaa !2451
  %621 = fadd <64 x float> %345, %620
  %622 = fadd <64 x float> %342, %621
  %623 = fcmp ogt <64 x float> %622, zeroinitializer
  %624 = select <64 x i1> %623, <64 x float> %622, <64 x float> zeroinitializer
  %625 = mul i64 %indvars.iv36, 7696581394432
  %sext61 = add i64 %625, 6871947673600
  %626 = ashr exact i64 %sext61, 32
  %627 = getelementptr inbounds float, float* %10, i64 %626
  %628 = bitcast float* %627 to <64 x float>*
  store <64 x float> %624, <64 x float>* %628, align 64, !tbaa !2466
  %629 = getelementptr inbounds i8, i8* %37, i64 6656
  %630 = bitcast i8* %629 to <64 x float>*
  %631 = load <64 x float>, <64 x float>* %630, align 64, !tbaa !2451
  %632 = fadd <64 x float> %345, %631
  %633 = fadd <64 x float> %342, %632
  %634 = fcmp ogt <64 x float> %633, zeroinitializer
  %635 = select <64 x i1> %634, <64 x float> %633, <64 x float> zeroinitializer
  %636 = mul i64 %indvars.iv36, 7696581394432
  %sext62 = add i64 %636, 7146825580544
  %637 = ashr exact i64 %sext62, 32
  %638 = getelementptr inbounds float, float* %10, i64 %637
  %639 = bitcast float* %638 to <64 x float>*
  store <64 x float> %635, <64 x float>* %639, align 64, !tbaa !2466
  %640 = getelementptr inbounds i8, i8* %37, i64 6912
  %641 = bitcast i8* %640 to <64 x float>*
  %642 = load <64 x float>, <64 x float>* %641, align 64, !tbaa !2451
  %643 = fadd <64 x float> %345, %642
  %644 = fadd <64 x float> %342, %643
  %645 = fcmp ogt <64 x float> %644, zeroinitializer
  %646 = select <64 x i1> %645, <64 x float> %644, <64 x float> zeroinitializer
  %647 = mul i64 %indvars.iv36, 7696581394432
  %sext63 = add i64 %647, 7421703487488
  %648 = ashr exact i64 %sext63, 32
  %649 = getelementptr inbounds float, float* %10, i64 %648
  %650 = bitcast float* %649 to <64 x float>*
  store <64 x float> %646, <64 x float>* %650, align 64, !tbaa !2466
  %651 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %652 = tail call i32 %651(i32 1, i32 %19, i8* nonnull %37)
  %indvars.iv.next37 = add nsw i64 %indvars.iv36, 1
  %653 = icmp slt i64 %indvars.iv.next37, %35
  br i1 %653, label %for_body, label %for_end, !prof !5
}

; Function Attrs: nounwind readnone speculatable
declare <64 x float> @llvm.fmuladd.v64f32(<64 x float>, <64 x float>, <64 x float>) #2

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.236, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !2469
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !2483
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !2486
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !2488
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.237, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !2492
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.238, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.239, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.240, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.241, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !2494
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !2508
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 512
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.242, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !2510
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 7
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !2513
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 7
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !2515
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 4
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !2519
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 100352, i32 196, i32 28, i32 4>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !2531
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([235 x i8], [235 x i8]* @.str.245, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !2535
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 16
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !2549
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 512
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.247, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !2551
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !2554
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !2556
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 4
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !2560
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 32
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !2562
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 65536, i32 128, i32 128, i32 128>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !2574
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 32
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !2578
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([273 x i8], [273 x i8]* @.str.248, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !2580
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 16
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !2594
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !2596
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !2599
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 32
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !2601
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !2613
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 16
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.250, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !2627
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !2629
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !2632
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 32
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !2634
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !2646
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !2660
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 16
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.251, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !2662
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 7
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.252, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !2665
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 7
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.253, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !2667
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 32
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !2671
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 25088, i32 1568, i32 224, i32 32>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !2683
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.254, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %5 = alloca %19, align 8
  %6 = getelementptr inbounds %19, %19* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %19, %19* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %19, %19* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %19, %19* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %19, %19* %5, i64 0, i32 4
  store i8* %4, i8** %10, align 8
  %11 = bitcast %19* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.255, i8* nonnull %11, i32 0)
  ret i32 %13
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.255(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin7.preheader
  %indvars.iv45 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next46, %for_begin7.preheader ]
  %33 = trunc i64 %indvars.iv45 to i32
  %34 = srem i32 %33, 7
  %35 = mul nsw i32 %34, 28
  %36 = sdiv i32 %33, 7
  %37 = shl i32 %36, 16
  %38 = sext i32 %35 to i64
  %39 = sext i32 %37 to i64
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_begin7.preheader, %entry
  ret i32 0

for_begin7.preheader:                             ; preds = %for_begin4.preheader
  %40 = mul nsw i64 %indvars.iv45, 224
  %41 = shl nsw i32 %36, 5
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds float, float* %16, i64 %42
  %44 = bitcast float* %43 to <32 x float>*
  %45 = load <32 x float>, <32 x float>* %44, align 64, !tbaa !2687
  %46 = getelementptr inbounds float, float* %13, i64 %42
  %47 = bitcast float* %46 to <32 x float>*
  %48 = load <32 x float>, <32 x float>* %47, align 64, !tbaa !2690
  %49 = fadd <32 x float> %48, %247
  %50 = fadd <32 x float> %45, %49
  %51 = fcmp ogt <32 x float> %50, zeroinitializer
  %52 = select <32 x i1> %51, <32 x float> %50, <32 x float> zeroinitializer
  %53 = getelementptr inbounds float, float* %10, i64 %40
  %54 = bitcast float* %53 to <32 x float>*
  store <32 x float> %52, <32 x float>* %54, align 64, !tbaa !2693
  %55 = add nsw i64 %40, 32
  %56 = fadd <32 x float> %48, %253
  %57 = fadd <32 x float> %45, %56
  %58 = fcmp ogt <32 x float> %57, zeroinitializer
  %59 = select <32 x i1> %58, <32 x float> %57, <32 x float> zeroinitializer
  %60 = getelementptr inbounds float, float* %10, i64 %55
  %61 = bitcast float* %60 to <32 x float>*
  store <32 x float> %59, <32 x float>* %61, align 64, !tbaa !2693
  %62 = add nsw i64 %40, 64
  %63 = fadd <32 x float> %48, %259
  %64 = fadd <32 x float> %45, %63
  %65 = fcmp ogt <32 x float> %64, zeroinitializer
  %66 = select <32 x i1> %65, <32 x float> %64, <32 x float> zeroinitializer
  %67 = getelementptr inbounds float, float* %10, i64 %62
  %68 = bitcast float* %67 to <32 x float>*
  store <32 x float> %66, <32 x float>* %68, align 64, !tbaa !2693
  %69 = add nsw i64 %40, 96
  %70 = fadd <32 x float> %48, %265
  %71 = fadd <32 x float> %45, %70
  %72 = fcmp ogt <32 x float> %71, zeroinitializer
  %73 = select <32 x i1> %72, <32 x float> %71, <32 x float> zeroinitializer
  %74 = getelementptr inbounds float, float* %10, i64 %69
  %75 = bitcast float* %74 to <32 x float>*
  store <32 x float> %73, <32 x float>* %75, align 64, !tbaa !2693
  %76 = add nsw i64 %40, 128
  %77 = fadd <32 x float> %48, %271
  %78 = fadd <32 x float> %45, %77
  %79 = fcmp ogt <32 x float> %78, zeroinitializer
  %80 = select <32 x i1> %79, <32 x float> %78, <32 x float> zeroinitializer
  %81 = getelementptr inbounds float, float* %10, i64 %76
  %82 = bitcast float* %81 to <32 x float>*
  store <32 x float> %80, <32 x float>* %82, align 64, !tbaa !2693
  %83 = add nsw i64 %40, 160
  %84 = fadd <32 x float> %48, %277
  %85 = fadd <32 x float> %45, %84
  %86 = fcmp ogt <32 x float> %85, zeroinitializer
  %87 = select <32 x i1> %86, <32 x float> %85, <32 x float> zeroinitializer
  %88 = getelementptr inbounds float, float* %10, i64 %83
  %89 = bitcast float* %88 to <32 x float>*
  store <32 x float> %87, <32 x float>* %89, align 64, !tbaa !2693
  %90 = add nsw i64 %40, 192
  %91 = fadd <32 x float> %48, %283
  %92 = fadd <32 x float> %45, %91
  %93 = fcmp ogt <32 x float> %92, zeroinitializer
  %94 = select <32 x i1> %93, <32 x float> %92, <32 x float> zeroinitializer
  %95 = getelementptr inbounds float, float* %10, i64 %90
  %96 = bitcast float* %95 to <32 x float>*
  store <32 x float> %94, <32 x float>* %96, align 64, !tbaa !2693
  %indvars.iv.next46 = add nsw i64 %indvars.iv45, 1
  %97 = icmp slt i64 %indvars.iv.next46, %32
  br i1 %97, label %for_body, label %for_end, !prof !5

for_begin4.preheader:                             ; preds = %for_begin4.preheader, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_begin4.preheader ]
  %.lcssa2235 = phi <32 x float> [ zeroinitializer, %for_body ], [ %283, %for_begin4.preheader ]
  %.lcssa2033 = phi <32 x float> [ zeroinitializer, %for_body ], [ %277, %for_begin4.preheader ]
  %.lcssa1831 = phi <32 x float> [ zeroinitializer, %for_body ], [ %271, %for_begin4.preheader ]
  %.lcssa1629 = phi <32 x float> [ zeroinitializer, %for_body ], [ %265, %for_begin4.preheader ]
  %.lcssa1427 = phi <32 x float> [ zeroinitializer, %for_body ], [ %259, %for_begin4.preheader ]
  %.lcssa1226 = phi <32 x float> [ zeroinitializer, %for_body ], [ %253, %for_begin4.preheader ]
  %.lcssa24 = phi <32 x float> [ zeroinitializer, %for_body ], [ %247, %for_begin4.preheader ]
  %98 = mul nuw nsw i64 %indvars.iv, 196
  %99 = add nsw i64 %98, %38
  %100 = shl i64 %indvars.iv, 7
  %101 = add nuw nsw i64 %100, %39
  %102 = getelementptr inbounds float, float* %4, i64 %99
  %103 = load float, float* %102, align 4, !tbaa !2696
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = getelementptr inbounds float, float* %7, i64 %101
  %107 = bitcast float* %106 to <32 x float>*
  %108 = load <32 x float>, <32 x float>* %107, align 64, !tbaa !2699
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %108, <32 x float> %.lcssa24)
  %110 = add nsw i64 %99, 4
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !2696
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %108, <32 x float> %.lcssa1226)
  %116 = add nsw i64 %99, 8
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !2696
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %108, <32 x float> %.lcssa1427)
  %122 = add nsw i64 %99, 12
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !2696
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %108, <32 x float> %.lcssa1629)
  %128 = add nsw i64 %99, 16
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = load float, float* %129, align 4, !tbaa !2696
  %131 = insertelement <32 x float> undef, float %130, i32 0
  %132 = shufflevector <32 x float> %131, <32 x float> undef, <32 x i32> zeroinitializer
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %132, <32 x float> %108, <32 x float> %.lcssa1831)
  %134 = add nsw i64 %99, 20
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !2696
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %108, <32 x float> %.lcssa2033)
  %140 = add nsw i64 %99, 24
  %141 = getelementptr inbounds float, float* %4, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !2696
  %143 = insertelement <32 x float> undef, float %142, i32 0
  %144 = shufflevector <32 x float> %143, <32 x float> undef, <32 x i32> zeroinitializer
  %145 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %144, <32 x float> %108, <32 x float> %.lcssa2235)
  %146 = or i64 %99, 1
  %147 = getelementptr inbounds float, float* %4, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !2696
  %149 = insertelement <32 x float> undef, float %148, i32 0
  %150 = shufflevector <32 x float> %149, <32 x float> undef, <32 x i32> zeroinitializer
  %151 = or i64 %101, 32
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = bitcast float* %152 to <32 x float>*
  %154 = load <32 x float>, <32 x float>* %153, align 64, !tbaa !2699
  %155 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %150, <32 x float> %154, <32 x float> %109)
  %156 = add nsw i64 %146, 4
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !2696
  %159 = insertelement <32 x float> undef, float %158, i32 0
  %160 = shufflevector <32 x float> %159, <32 x float> undef, <32 x i32> zeroinitializer
  %161 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %160, <32 x float> %154, <32 x float> %115)
  %162 = add nsw i64 %146, 8
  %163 = getelementptr inbounds float, float* %4, i64 %162
  %164 = load float, float* %163, align 4, !tbaa !2696
  %165 = insertelement <32 x float> undef, float %164, i32 0
  %166 = shufflevector <32 x float> %165, <32 x float> undef, <32 x i32> zeroinitializer
  %167 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %166, <32 x float> %154, <32 x float> %121)
  %168 = add nsw i64 %146, 12
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = load float, float* %169, align 4, !tbaa !2696
  %171 = insertelement <32 x float> undef, float %170, i32 0
  %172 = shufflevector <32 x float> %171, <32 x float> undef, <32 x i32> zeroinitializer
  %173 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %172, <32 x float> %154, <32 x float> %127)
  %174 = add nsw i64 %146, 16
  %175 = getelementptr inbounds float, float* %4, i64 %174
  %176 = load float, float* %175, align 4, !tbaa !2696
  %177 = insertelement <32 x float> undef, float %176, i32 0
  %178 = shufflevector <32 x float> %177, <32 x float> undef, <32 x i32> zeroinitializer
  %179 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %178, <32 x float> %154, <32 x float> %133)
  %180 = add nsw i64 %146, 20
  %181 = getelementptr inbounds float, float* %4, i64 %180
  %182 = load float, float* %181, align 4, !tbaa !2696
  %183 = insertelement <32 x float> undef, float %182, i32 0
  %184 = shufflevector <32 x float> %183, <32 x float> undef, <32 x i32> zeroinitializer
  %185 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %184, <32 x float> %154, <32 x float> %139)
  %186 = add nsw i64 %146, 24
  %187 = getelementptr inbounds float, float* %4, i64 %186
  %188 = load float, float* %187, align 4, !tbaa !2696
  %189 = insertelement <32 x float> undef, float %188, i32 0
  %190 = shufflevector <32 x float> %189, <32 x float> undef, <32 x i32> zeroinitializer
  %191 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %190, <32 x float> %154, <32 x float> %145)
  %192 = or i64 %99, 2
  %193 = getelementptr inbounds float, float* %4, i64 %192
  %194 = load float, float* %193, align 4, !tbaa !2696
  %195 = insertelement <32 x float> undef, float %194, i32 0
  %196 = shufflevector <32 x float> %195, <32 x float> undef, <32 x i32> zeroinitializer
  %197 = or i64 %101, 64
  %198 = getelementptr inbounds float, float* %7, i64 %197
  %199 = bitcast float* %198 to <32 x float>*
  %200 = load <32 x float>, <32 x float>* %199, align 64, !tbaa !2699
  %201 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %196, <32 x float> %200, <32 x float> %155)
  %202 = add nsw i64 %192, 4
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !2696
  %205 = insertelement <32 x float> undef, float %204, i32 0
  %206 = shufflevector <32 x float> %205, <32 x float> undef, <32 x i32> zeroinitializer
  %207 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %206, <32 x float> %200, <32 x float> %161)
  %208 = add nsw i64 %192, 8
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !2696
  %211 = insertelement <32 x float> undef, float %210, i32 0
  %212 = shufflevector <32 x float> %211, <32 x float> undef, <32 x i32> zeroinitializer
  %213 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %212, <32 x float> %200, <32 x float> %167)
  %214 = add nsw i64 %192, 12
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !2696
  %217 = insertelement <32 x float> undef, float %216, i32 0
  %218 = shufflevector <32 x float> %217, <32 x float> undef, <32 x i32> zeroinitializer
  %219 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %200, <32 x float> %173)
  %220 = add nsw i64 %192, 16
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !2696
  %223 = insertelement <32 x float> undef, float %222, i32 0
  %224 = shufflevector <32 x float> %223, <32 x float> undef, <32 x i32> zeroinitializer
  %225 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %224, <32 x float> %200, <32 x float> %179)
  %226 = add nsw i64 %192, 20
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = load float, float* %227, align 4, !tbaa !2696
  %229 = insertelement <32 x float> undef, float %228, i32 0
  %230 = shufflevector <32 x float> %229, <32 x float> undef, <32 x i32> zeroinitializer
  %231 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %230, <32 x float> %200, <32 x float> %185)
  %232 = add nsw i64 %192, 24
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !2696
  %235 = insertelement <32 x float> undef, float %234, i32 0
  %236 = shufflevector <32 x float> %235, <32 x float> undef, <32 x i32> zeroinitializer
  %237 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %236, <32 x float> %200, <32 x float> %191)
  %238 = or i64 %99, 3
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !2696
  %241 = insertelement <32 x float> undef, float %240, i32 0
  %242 = shufflevector <32 x float> %241, <32 x float> undef, <32 x i32> zeroinitializer
  %243 = or i64 %101, 96
  %244 = getelementptr inbounds float, float* %7, i64 %243
  %245 = bitcast float* %244 to <32 x float>*
  %246 = load <32 x float>, <32 x float>* %245, align 64, !tbaa !2699
  %247 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %246, <32 x float> %201)
  %248 = add nsw i64 %238, 4
  %249 = getelementptr inbounds float, float* %4, i64 %248
  %250 = load float, float* %249, align 4, !tbaa !2696
  %251 = insertelement <32 x float> undef, float %250, i32 0
  %252 = shufflevector <32 x float> %251, <32 x float> undef, <32 x i32> zeroinitializer
  %253 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %252, <32 x float> %246, <32 x float> %207)
  %254 = add nsw i64 %238, 8
  %255 = getelementptr inbounds float, float* %4, i64 %254
  %256 = load float, float* %255, align 4, !tbaa !2696
  %257 = insertelement <32 x float> undef, float %256, i32 0
  %258 = shufflevector <32 x float> %257, <32 x float> undef, <32 x i32> zeroinitializer
  %259 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %258, <32 x float> %246, <32 x float> %213)
  %260 = add nsw i64 %238, 12
  %261 = getelementptr inbounds float, float* %4, i64 %260
  %262 = load float, float* %261, align 4, !tbaa !2696
  %263 = insertelement <32 x float> undef, float %262, i32 0
  %264 = shufflevector <32 x float> %263, <32 x float> undef, <32 x i32> zeroinitializer
  %265 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %264, <32 x float> %246, <32 x float> %219)
  %266 = add nsw i64 %238, 16
  %267 = getelementptr inbounds float, float* %4, i64 %266
  %268 = load float, float* %267, align 4, !tbaa !2696
  %269 = insertelement <32 x float> undef, float %268, i32 0
  %270 = shufflevector <32 x float> %269, <32 x float> undef, <32 x i32> zeroinitializer
  %271 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %270, <32 x float> %246, <32 x float> %225)
  %272 = add nsw i64 %238, 20
  %273 = getelementptr inbounds float, float* %4, i64 %272
  %274 = load float, float* %273, align 4, !tbaa !2696
  %275 = insertelement <32 x float> undef, float %274, i32 0
  %276 = shufflevector <32 x float> %275, <32 x float> undef, <32 x i32> zeroinitializer
  %277 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %276, <32 x float> %246, <32 x float> %231)
  %278 = add nsw i64 %238, 24
  %279 = getelementptr inbounds float, float* %4, i64 %278
  %280 = load float, float* %279, align 4, !tbaa !2696
  %281 = insertelement <32 x float> undef, float %280, i32 0
  %282 = shufflevector <32 x float> %281, <32 x float> undef, <32 x i32> zeroinitializer
  %283 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %282, <32 x float> %246, <32 x float> %237)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_begin7.preheader, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_48(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.256, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !2702
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.257, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !2716
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.258, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 4
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.203, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !2718
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !2732
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 64
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !2734
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 56
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !2737
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 56
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = icmp eq i64* %17, null
  br i1 %70, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end18
  %71 = bitcast i64* %17 to <4 x i64>*
  %72 = load <4 x i64>, <4 x i64>* %71, align 8, !tbaa !2739
  %73 = trunc <4 x i64> %72 to <4 x i32>
  %74 = icmp eq <4 x i32> %73, <i32 200704, i32 3136, i32 56, i32 1>
  %rdx.shuf49 = shufflevector <4 x i1> %74, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %74, %rdx.shuf49
  %rdx.shuf51 = shufflevector <4 x i1> %bin.rdx50, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %bin.rdx50, %rdx.shuf51
  %75 = extractelement <4 x i1> %bin.rdx52, i32 0
  br i1 %75, label %if_end, label %assert_fail19, !prof !5

if_end:                                           ; preds = %assert_end18, %if_then
  %76 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %77 = load i64, i64* %76, align 8
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %assert_end22, label %assert_fail21, !prof !5

assert_fail19:                                    ; preds = %if_then
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([201 x i8], [201 x i8]* @.str.205, i64 0, i64 0))
  ret i32 -1

assert_fail21:                                    ; preds = %if_end
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %if_end
  %81 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %82 = load i32, i32* %81, align 4
  %83 = icmp eq i32 %82, 5
  br i1 %83, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %85 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %86 = load i16, i16* %85, align 2
  %87 = icmp eq i16 %86, 1
  %88 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %89 = load i8, i8* %88, align 1
  %90 = icmp eq i8 %89, 32
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %92 = load i8, i8* %91, align 1
  %93 = icmp eq i8 %92, 2
  %94 = and i1 %90, %93
  %95 = and i1 %87, %94
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = load i64, i64* %25, align 8, !tbaa !2751
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 1
  br i1 %99, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %101 = getelementptr inbounds i64, i64* %25, i64 1
  %102 = load i64, i64* %101, align 8, !tbaa !2765
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 16
  br i1 %104, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.31, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %106 = getelementptr inbounds i64, i64* %25, i64 2
  %107 = load i64, i64* %106, align 8, !tbaa !2767
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 56
  br i1 %109, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %111 = getelementptr inbounds i64, i64* %25, i64 3
  %112 = load i64, i64* %111, align 8, !tbaa !2770
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 56
  br i1 %114, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %116 = getelementptr inbounds i64, i64* %25, i64 4
  %117 = load i64, i64* %116, align 8, !tbaa !2772
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 4
  br i1 %119, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %121 = icmp eq i64* %27, null
  br i1 %121, label %if_end38, label %if_then37, !prof !50

if_then37:                                        ; preds = %assert_end36
  %122 = bitcast i64* %27 to <4 x i64>*
  %123 = load <4 x i64>, <4 x i64>* %122, align 8, !tbaa !2776
  %124 = trunc <4 x i64> %123 to <4 x i32>
  %125 = icmp eq <4 x i32> %124, <i32 200704, i32 12544, i32 224, i32 4>
  %126 = getelementptr inbounds i64, i64* %27, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !2788
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 1
  %rdx.shuf = shufflevector <4 x i1> %125, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %125, %rdx.shuf
  %rdx.shuf47 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx48 = and <4 x i1> %bin.rdx, %rdx.shuf47
  %130 = extractelement <4 x i1> %bin.rdx48, i32 0
  %131 = and i1 %130, %129
  br i1 %131, label %if_end38, label %assert_fail39, !prof !5

if_end38:                                         ; preds = %assert_end36, %if_then37
  %132 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %133 = load i64, i64* %132, align 8
  %134 = icmp eq i64 %133, 0
  br i1 %134, label %assert_end42, label %assert_fail41, !prof !5

assert_fail39:                                    ; preds = %if_then37
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.142, i64 0, i64 0))
  ret i32 -1

assert_fail41:                                    ; preds = %if_end38
  %136 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %136(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %if_end38
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %138 = load i32, i32* %137, align 4
  %139 = icmp eq i32 %138, 1
  br i1 %139, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %140 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %140(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %141 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %142 = load i32, i32* %141, align 4
  %143 = icmp eq i32 %21, %142
  br i1 %143, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %144 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %144(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %145 = tail call fastcc i32 @fused_layout_transform_48_compute_(i8* %23, i8* %13)
  ret i32 %145
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_48_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %20, align 8
  %3 = getelementptr inbounds %20, %20* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %20, %20* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %20* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.259, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.259(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 895
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 896
  %15 = select i1 %14, i32 %13, i32 896
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 896
  %18 = select i1 %17, i32 %16, i32 896
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  %24 = getelementptr inbounds float, float* %4, i64 -3
  %25 = getelementptr inbounds float, float* %4, i64 -3
  %26 = getelementptr inbounds float, float* %4, i64 -3
  %27 = getelementptr inbounds float, float* %4, i64 -3
  %28 = getelementptr inbounds float, float* %4, i64 -3
  %29 = getelementptr inbounds float, float* %4, i64 -3
  %30 = getelementptr inbounds float, float* %4, i64 -3
  %31 = getelementptr inbounds float, float* %4, i64 -3
  %32 = getelementptr inbounds float, float* %4, i64 -3
  %33 = getelementptr inbounds float, float* %4, i64 -3
  %34 = getelementptr inbounds float, float* %4, i64 -3
  %35 = getelementptr inbounds float, float* %4, i64 -3
  %36 = getelementptr inbounds float, float* %4, i64 -3
  %37 = getelementptr inbounds float, float* %4, i64 -3
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next8, %for_end3 ]
  %38 = mul nsw i64 %indvars.iv7, 224
  %39 = trunc i64 %indvars.iv7 to i32
  %40 = srem i32 %39, 56
  %41 = mul nsw i32 %40, 56
  %42 = sdiv i32 %39, 56
  %43 = mul nsw i32 %42, 12544
  %44 = add i32 %41, %43
  %45 = mul i32 %42, 12544
  %46 = add i32 %45, %41
  %47 = icmp sgt i32 %46, 2147483592
  %48 = add i32 %45, 3136
  %49 = add i32 %48, %41
  %50 = icmp sgt i32 %49, 2147483592
  %51 = or i1 %47, %50
  %52 = add i32 %45, 6272
  %53 = add i32 %52, %41
  %54 = icmp sgt i32 %53, 2147483592
  %55 = or i1 %51, %54
  %56 = add i32 %45, 9408
  %57 = add i32 %56, %41
  %58 = icmp sgt i32 %57, 2147483592
  %59 = or i1 %55, %58
  br i1 %59, label %for_begin4.preheader, label %vector.body

vector.body:                                      ; preds = %for_begin1.preheader
  %60 = sext i32 %44 to i64
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = bitcast float* %61 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %62, align 4, !tbaa !2792
  %63 = add i32 %44, 3136
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float* %7, i64 %64
  %66 = bitcast float* %65 to <4 x i32>*
  %wide.load21 = load <4 x i32>, <4 x i32>* %66, align 4, !tbaa !2792
  %67 = add i32 %44, 6272
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = bitcast float* %69 to <4 x i32>*
  %wide.load22 = load <4 x i32>, <4 x i32>* %70, align 4, !tbaa !2792
  %71 = or i64 %38, 3
  %72 = add i32 %44, 9408
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = bitcast float* %74 to <4 x i32>*
  %wide.load23 = load <4 x i32>, <4 x i32>* %75, align 4, !tbaa !2792
  %76 = getelementptr inbounds float, float* %24, i64 %71
  %77 = bitcast float* %76 to <16 x i32>*
  %78 = shufflevector <4 x i32> %wide.load, <4 x i32> %wide.load21, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %79 = shufflevector <4 x i32> %wide.load22, <4 x i32> %wide.load23, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec = shufflevector <8 x i32> %78, <8 x i32> %79, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec, <16 x i32>* %77, align 4, !tbaa !2795
  %80 = or i32 %44, 4
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <4 x i32>*
  %wide.load.1 = load <4 x i32>, <4 x i32>* %83, align 4, !tbaa !2792
  %84 = add i32 %80, 3136
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds float, float* %7, i64 %85
  %87 = bitcast float* %86 to <4 x i32>*
  %wide.load21.1 = load <4 x i32>, <4 x i32>* %87, align 4, !tbaa !2792
  %88 = add i32 %80, 6272
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds float, float* %7, i64 %89
  %91 = bitcast float* %90 to <4 x i32>*
  %wide.load22.1 = load <4 x i32>, <4 x i32>* %91, align 4, !tbaa !2792
  %92 = or i64 %38, 19
  %93 = add i32 %80, 9408
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to <4 x i32>*
  %wide.load23.1 = load <4 x i32>, <4 x i32>* %96, align 4, !tbaa !2792
  %97 = getelementptr inbounds float, float* %25, i64 %92
  %98 = bitcast float* %97 to <16 x i32>*
  %99 = shufflevector <4 x i32> %wide.load.1, <4 x i32> %wide.load21.1, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %100 = shufflevector <4 x i32> %wide.load22.1, <4 x i32> %wide.load23.1, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.1 = shufflevector <8 x i32> %99, <8 x i32> %100, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.1, <16 x i32>* %98, align 4, !tbaa !2795
  %101 = add nsw i64 %38, 32
  %102 = add i32 %44, 8
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %7, i64 %103
  %105 = bitcast float* %104 to <4 x i32>*
  %wide.load.2 = load <4 x i32>, <4 x i32>* %105, align 4, !tbaa !2792
  %106 = add i32 %44, 3144
  %107 = sext i32 %106 to i64
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to <4 x i32>*
  %wide.load21.2 = load <4 x i32>, <4 x i32>* %109, align 4, !tbaa !2792
  %110 = add i32 %44, 6280
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = bitcast float* %112 to <4 x i32>*
  %wide.load22.2 = load <4 x i32>, <4 x i32>* %113, align 4, !tbaa !2792
  %114 = or i64 %101, 3
  %115 = add i32 %44, 9416
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = bitcast float* %117 to <4 x i32>*
  %wide.load23.2 = load <4 x i32>, <4 x i32>* %118, align 4, !tbaa !2792
  %119 = getelementptr inbounds float, float* %26, i64 %114
  %120 = bitcast float* %119 to <16 x i32>*
  %121 = shufflevector <4 x i32> %wide.load.2, <4 x i32> %wide.load21.2, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %122 = shufflevector <4 x i32> %wide.load22.2, <4 x i32> %wide.load23.2, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.2 = shufflevector <8 x i32> %121, <8 x i32> %122, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.2, <16 x i32>* %120, align 4, !tbaa !2795
  %123 = add nsw i64 %38, 48
  %124 = add i32 %44, 12
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = bitcast float* %126 to <4 x i32>*
  %wide.load.3 = load <4 x i32>, <4 x i32>* %127, align 4, !tbaa !2792
  %128 = add i32 %44, 3148
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds float, float* %7, i64 %129
  %131 = bitcast float* %130 to <4 x i32>*
  %wide.load21.3 = load <4 x i32>, <4 x i32>* %131, align 4, !tbaa !2792
  %132 = add i32 %44, 6284
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds float, float* %7, i64 %133
  %135 = bitcast float* %134 to <4 x i32>*
  %wide.load22.3 = load <4 x i32>, <4 x i32>* %135, align 4, !tbaa !2792
  %136 = or i64 %123, 3
  %137 = add i32 %44, 9420
  %138 = sext i32 %137 to i64
  %139 = getelementptr inbounds float, float* %7, i64 %138
  %140 = bitcast float* %139 to <4 x i32>*
  %wide.load23.3 = load <4 x i32>, <4 x i32>* %140, align 4, !tbaa !2792
  %141 = getelementptr inbounds float, float* %27, i64 %136
  %142 = bitcast float* %141 to <16 x i32>*
  %143 = shufflevector <4 x i32> %wide.load.3, <4 x i32> %wide.load21.3, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %144 = shufflevector <4 x i32> %wide.load22.3, <4 x i32> %wide.load23.3, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.3 = shufflevector <8 x i32> %143, <8 x i32> %144, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.3, <16 x i32>* %142, align 4, !tbaa !2795
  %145 = add nsw i64 %38, 64
  %146 = add i32 %44, 16
  %147 = sext i32 %146 to i64
  %148 = getelementptr inbounds float, float* %7, i64 %147
  %149 = bitcast float* %148 to <4 x i32>*
  %wide.load.4 = load <4 x i32>, <4 x i32>* %149, align 4, !tbaa !2792
  %150 = add i32 %44, 3152
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = bitcast float* %152 to <4 x i32>*
  %wide.load21.4 = load <4 x i32>, <4 x i32>* %153, align 4, !tbaa !2792
  %154 = add i32 %44, 6288
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds float, float* %7, i64 %155
  %157 = bitcast float* %156 to <4 x i32>*
  %wide.load22.4 = load <4 x i32>, <4 x i32>* %157, align 4, !tbaa !2792
  %158 = or i64 %145, 3
  %159 = add i32 %44, 9424
  %160 = sext i32 %159 to i64
  %161 = getelementptr inbounds float, float* %7, i64 %160
  %162 = bitcast float* %161 to <4 x i32>*
  %wide.load23.4 = load <4 x i32>, <4 x i32>* %162, align 4, !tbaa !2792
  %163 = getelementptr inbounds float, float* %28, i64 %158
  %164 = bitcast float* %163 to <16 x i32>*
  %165 = shufflevector <4 x i32> %wide.load.4, <4 x i32> %wide.load21.4, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %166 = shufflevector <4 x i32> %wide.load22.4, <4 x i32> %wide.load23.4, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.4 = shufflevector <8 x i32> %165, <8 x i32> %166, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.4, <16 x i32>* %164, align 4, !tbaa !2795
  %167 = add nsw i64 %38, 80
  %168 = add i32 %44, 20
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to <4 x i32>*
  %wide.load.5 = load <4 x i32>, <4 x i32>* %171, align 4, !tbaa !2792
  %172 = add i32 %44, 3156
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to <4 x i32>*
  %wide.load21.5 = load <4 x i32>, <4 x i32>* %175, align 4, !tbaa !2792
  %176 = add i32 %44, 6292
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds float, float* %7, i64 %177
  %179 = bitcast float* %178 to <4 x i32>*
  %wide.load22.5 = load <4 x i32>, <4 x i32>* %179, align 4, !tbaa !2792
  %180 = or i64 %167, 3
  %181 = add i32 %44, 9428
  %182 = sext i32 %181 to i64
  %183 = getelementptr inbounds float, float* %7, i64 %182
  %184 = bitcast float* %183 to <4 x i32>*
  %wide.load23.5 = load <4 x i32>, <4 x i32>* %184, align 4, !tbaa !2792
  %185 = getelementptr inbounds float, float* %29, i64 %180
  %186 = bitcast float* %185 to <16 x i32>*
  %187 = shufflevector <4 x i32> %wide.load.5, <4 x i32> %wide.load21.5, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %188 = shufflevector <4 x i32> %wide.load22.5, <4 x i32> %wide.load23.5, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.5 = shufflevector <8 x i32> %187, <8 x i32> %188, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.5, <16 x i32>* %186, align 4, !tbaa !2795
  %189 = add nsw i64 %38, 96
  %190 = add i32 %44, 24
  %191 = sext i32 %190 to i64
  %192 = getelementptr inbounds float, float* %7, i64 %191
  %193 = bitcast float* %192 to <4 x i32>*
  %wide.load.6 = load <4 x i32>, <4 x i32>* %193, align 4, !tbaa !2792
  %194 = add i32 %44, 3160
  %195 = sext i32 %194 to i64
  %196 = getelementptr inbounds float, float* %7, i64 %195
  %197 = bitcast float* %196 to <4 x i32>*
  %wide.load21.6 = load <4 x i32>, <4 x i32>* %197, align 4, !tbaa !2792
  %198 = add i32 %44, 6296
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds float, float* %7, i64 %199
  %201 = bitcast float* %200 to <4 x i32>*
  %wide.load22.6 = load <4 x i32>, <4 x i32>* %201, align 4, !tbaa !2792
  %202 = or i64 %189, 3
  %203 = add i32 %44, 9432
  %204 = sext i32 %203 to i64
  %205 = getelementptr inbounds float, float* %7, i64 %204
  %206 = bitcast float* %205 to <4 x i32>*
  %wide.load23.6 = load <4 x i32>, <4 x i32>* %206, align 4, !tbaa !2792
  %207 = getelementptr inbounds float, float* %30, i64 %202
  %208 = bitcast float* %207 to <16 x i32>*
  %209 = shufflevector <4 x i32> %wide.load.6, <4 x i32> %wide.load21.6, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %210 = shufflevector <4 x i32> %wide.load22.6, <4 x i32> %wide.load23.6, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.6 = shufflevector <8 x i32> %209, <8 x i32> %210, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.6, <16 x i32>* %208, align 4, !tbaa !2795
  %211 = add nsw i64 %38, 112
  %212 = add i32 %44, 28
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %7, i64 %213
  %215 = bitcast float* %214 to <4 x i32>*
  %wide.load.7 = load <4 x i32>, <4 x i32>* %215, align 4, !tbaa !2792
  %216 = add i32 %44, 3164
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds float, float* %7, i64 %217
  %219 = bitcast float* %218 to <4 x i32>*
  %wide.load21.7 = load <4 x i32>, <4 x i32>* %219, align 4, !tbaa !2792
  %220 = add i32 %44, 6300
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds float, float* %7, i64 %221
  %223 = bitcast float* %222 to <4 x i32>*
  %wide.load22.7 = load <4 x i32>, <4 x i32>* %223, align 4, !tbaa !2792
  %224 = or i64 %211, 3
  %225 = add i32 %44, 9436
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds float, float* %7, i64 %226
  %228 = bitcast float* %227 to <4 x i32>*
  %wide.load23.7 = load <4 x i32>, <4 x i32>* %228, align 4, !tbaa !2792
  %229 = getelementptr inbounds float, float* %31, i64 %224
  %230 = bitcast float* %229 to <16 x i32>*
  %231 = shufflevector <4 x i32> %wide.load.7, <4 x i32> %wide.load21.7, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %232 = shufflevector <4 x i32> %wide.load22.7, <4 x i32> %wide.load23.7, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.7 = shufflevector <8 x i32> %231, <8 x i32> %232, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.7, <16 x i32>* %230, align 4, !tbaa !2795
  %233 = add nsw i64 %38, 128
  %234 = add i32 %44, 32
  %235 = sext i32 %234 to i64
  %236 = getelementptr inbounds float, float* %7, i64 %235
  %237 = bitcast float* %236 to <4 x i32>*
  %wide.load.8 = load <4 x i32>, <4 x i32>* %237, align 4, !tbaa !2792
  %238 = add i32 %44, 3168
  %239 = sext i32 %238 to i64
  %240 = getelementptr inbounds float, float* %7, i64 %239
  %241 = bitcast float* %240 to <4 x i32>*
  %wide.load21.8 = load <4 x i32>, <4 x i32>* %241, align 4, !tbaa !2792
  %242 = add i32 %44, 6304
  %243 = sext i32 %242 to i64
  %244 = getelementptr inbounds float, float* %7, i64 %243
  %245 = bitcast float* %244 to <4 x i32>*
  %wide.load22.8 = load <4 x i32>, <4 x i32>* %245, align 4, !tbaa !2792
  %246 = or i64 %233, 3
  %247 = add i32 %44, 9440
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds float, float* %7, i64 %248
  %250 = bitcast float* %249 to <4 x i32>*
  %wide.load23.8 = load <4 x i32>, <4 x i32>* %250, align 4, !tbaa !2792
  %251 = getelementptr inbounds float, float* %32, i64 %246
  %252 = bitcast float* %251 to <16 x i32>*
  %253 = shufflevector <4 x i32> %wide.load.8, <4 x i32> %wide.load21.8, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %254 = shufflevector <4 x i32> %wide.load22.8, <4 x i32> %wide.load23.8, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.8 = shufflevector <8 x i32> %253, <8 x i32> %254, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.8, <16 x i32>* %252, align 4, !tbaa !2795
  %255 = add nsw i64 %38, 144
  %256 = add i32 %44, 36
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds float, float* %7, i64 %257
  %259 = bitcast float* %258 to <4 x i32>*
  %wide.load.9 = load <4 x i32>, <4 x i32>* %259, align 4, !tbaa !2792
  %260 = add i32 %44, 3172
  %261 = sext i32 %260 to i64
  %262 = getelementptr inbounds float, float* %7, i64 %261
  %263 = bitcast float* %262 to <4 x i32>*
  %wide.load21.9 = load <4 x i32>, <4 x i32>* %263, align 4, !tbaa !2792
  %264 = add i32 %44, 6308
  %265 = sext i32 %264 to i64
  %266 = getelementptr inbounds float, float* %7, i64 %265
  %267 = bitcast float* %266 to <4 x i32>*
  %wide.load22.9 = load <4 x i32>, <4 x i32>* %267, align 4, !tbaa !2792
  %268 = or i64 %255, 3
  %269 = add i32 %44, 9444
  %270 = sext i32 %269 to i64
  %271 = getelementptr inbounds float, float* %7, i64 %270
  %272 = bitcast float* %271 to <4 x i32>*
  %wide.load23.9 = load <4 x i32>, <4 x i32>* %272, align 4, !tbaa !2792
  %273 = getelementptr inbounds float, float* %33, i64 %268
  %274 = bitcast float* %273 to <16 x i32>*
  %275 = shufflevector <4 x i32> %wide.load.9, <4 x i32> %wide.load21.9, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %276 = shufflevector <4 x i32> %wide.load22.9, <4 x i32> %wide.load23.9, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.9 = shufflevector <8 x i32> %275, <8 x i32> %276, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.9, <16 x i32>* %274, align 4, !tbaa !2795
  %277 = add nsw i64 %38, 160
  %278 = add i32 %44, 40
  %279 = sext i32 %278 to i64
  %280 = getelementptr inbounds float, float* %7, i64 %279
  %281 = bitcast float* %280 to <4 x i32>*
  %wide.load.10 = load <4 x i32>, <4 x i32>* %281, align 4, !tbaa !2792
  %282 = add i32 %44, 3176
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds float, float* %7, i64 %283
  %285 = bitcast float* %284 to <4 x i32>*
  %wide.load21.10 = load <4 x i32>, <4 x i32>* %285, align 4, !tbaa !2792
  %286 = add i32 %44, 6312
  %287 = sext i32 %286 to i64
  %288 = getelementptr inbounds float, float* %7, i64 %287
  %289 = bitcast float* %288 to <4 x i32>*
  %wide.load22.10 = load <4 x i32>, <4 x i32>* %289, align 4, !tbaa !2792
  %290 = or i64 %277, 3
  %291 = add i32 %44, 9448
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds float, float* %7, i64 %292
  %294 = bitcast float* %293 to <4 x i32>*
  %wide.load23.10 = load <4 x i32>, <4 x i32>* %294, align 4, !tbaa !2792
  %295 = getelementptr inbounds float, float* %34, i64 %290
  %296 = bitcast float* %295 to <16 x i32>*
  %297 = shufflevector <4 x i32> %wide.load.10, <4 x i32> %wide.load21.10, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %298 = shufflevector <4 x i32> %wide.load22.10, <4 x i32> %wide.load23.10, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.10 = shufflevector <8 x i32> %297, <8 x i32> %298, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.10, <16 x i32>* %296, align 4, !tbaa !2795
  %299 = add nsw i64 %38, 176
  %300 = add i32 %44, 44
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds float, float* %7, i64 %301
  %303 = bitcast float* %302 to <4 x i32>*
  %wide.load.11 = load <4 x i32>, <4 x i32>* %303, align 4, !tbaa !2792
  %304 = add i32 %44, 3180
  %305 = sext i32 %304 to i64
  %306 = getelementptr inbounds float, float* %7, i64 %305
  %307 = bitcast float* %306 to <4 x i32>*
  %wide.load21.11 = load <4 x i32>, <4 x i32>* %307, align 4, !tbaa !2792
  %308 = add i32 %44, 6316
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds float, float* %7, i64 %309
  %311 = bitcast float* %310 to <4 x i32>*
  %wide.load22.11 = load <4 x i32>, <4 x i32>* %311, align 4, !tbaa !2792
  %312 = or i64 %299, 3
  %313 = add i32 %44, 9452
  %314 = sext i32 %313 to i64
  %315 = getelementptr inbounds float, float* %7, i64 %314
  %316 = bitcast float* %315 to <4 x i32>*
  %wide.load23.11 = load <4 x i32>, <4 x i32>* %316, align 4, !tbaa !2792
  %317 = getelementptr inbounds float, float* %35, i64 %312
  %318 = bitcast float* %317 to <16 x i32>*
  %319 = shufflevector <4 x i32> %wide.load.11, <4 x i32> %wide.load21.11, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %320 = shufflevector <4 x i32> %wide.load22.11, <4 x i32> %wide.load23.11, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.11 = shufflevector <8 x i32> %319, <8 x i32> %320, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.11, <16 x i32>* %318, align 4, !tbaa !2795
  %321 = add nsw i64 %38, 192
  %322 = add i32 %44, 48
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds float, float* %7, i64 %323
  %325 = bitcast float* %324 to <4 x i32>*
  %wide.load.12 = load <4 x i32>, <4 x i32>* %325, align 4, !tbaa !2792
  %326 = add i32 %44, 3184
  %327 = sext i32 %326 to i64
  %328 = getelementptr inbounds float, float* %7, i64 %327
  %329 = bitcast float* %328 to <4 x i32>*
  %wide.load21.12 = load <4 x i32>, <4 x i32>* %329, align 4, !tbaa !2792
  %330 = add i32 %44, 6320
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds float, float* %7, i64 %331
  %333 = bitcast float* %332 to <4 x i32>*
  %wide.load22.12 = load <4 x i32>, <4 x i32>* %333, align 4, !tbaa !2792
  %334 = or i64 %321, 3
  %335 = add i32 %44, 9456
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds float, float* %7, i64 %336
  %338 = bitcast float* %337 to <4 x i32>*
  %wide.load23.12 = load <4 x i32>, <4 x i32>* %338, align 4, !tbaa !2792
  %339 = getelementptr inbounds float, float* %36, i64 %334
  %340 = bitcast float* %339 to <16 x i32>*
  %341 = shufflevector <4 x i32> %wide.load.12, <4 x i32> %wide.load21.12, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %342 = shufflevector <4 x i32> %wide.load22.12, <4 x i32> %wide.load23.12, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.12 = shufflevector <8 x i32> %341, <8 x i32> %342, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.12, <16 x i32>* %340, align 4, !tbaa !2795
  %343 = add nsw i64 %38, 208
  %344 = add i32 %44, 52
  %345 = sext i32 %344 to i64
  %346 = getelementptr inbounds float, float* %7, i64 %345
  %347 = bitcast float* %346 to <4 x i32>*
  %wide.load.13 = load <4 x i32>, <4 x i32>* %347, align 4, !tbaa !2792
  %348 = add i32 %44, 3188
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds float, float* %7, i64 %349
  %351 = bitcast float* %350 to <4 x i32>*
  %wide.load21.13 = load <4 x i32>, <4 x i32>* %351, align 4, !tbaa !2792
  %352 = add i32 %44, 6324
  %353 = sext i32 %352 to i64
  %354 = getelementptr inbounds float, float* %7, i64 %353
  %355 = bitcast float* %354 to <4 x i32>*
  %wide.load22.13 = load <4 x i32>, <4 x i32>* %355, align 4, !tbaa !2792
  %356 = or i64 %343, 3
  %357 = add i32 %44, 9460
  %358 = sext i32 %357 to i64
  %359 = getelementptr inbounds float, float* %7, i64 %358
  %360 = bitcast float* %359 to <4 x i32>*
  %wide.load23.13 = load <4 x i32>, <4 x i32>* %360, align 4, !tbaa !2792
  %361 = getelementptr inbounds float, float* %37, i64 %356
  %362 = bitcast float* %361 to <16 x i32>*
  %363 = shufflevector <4 x i32> %wide.load.13, <4 x i32> %wide.load21.13, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %364 = shufflevector <4 x i32> %wide.load22.13, <4 x i32> %wide.load23.13, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %interleaved.vec.13 = shufflevector <8 x i32> %363, <8 x i32> %364, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 1, i32 5, i32 9, i32 13, i32 2, i32 6, i32 10, i32 14, i32 3, i32 7, i32 11, i32 15>
  store <16 x i32> %interleaved.vec.13, <16 x i32>* %362, align 4, !tbaa !2795
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_begin1.preheader, %for_begin4.preheader
  %indvars.iv = phi i64 [ %indvars.iv.next, %for_begin4.preheader ], [ 0, %for_begin1.preheader ]
  %365 = shl i64 %indvars.iv, 2
  %366 = add nsw i64 %365, %38
  %367 = trunc i64 %indvars.iv to i32
  %368 = add i32 %44, %367
  %369 = sext i32 %368 to i64
  %370 = getelementptr inbounds float, float* %7, i64 %369
  %371 = bitcast float* %370 to i32*
  %372 = load i32, i32* %371, align 4, !tbaa !2792
  %373 = getelementptr inbounds float, float* %4, i64 %366
  %374 = bitcast float* %373 to i32*
  store i32 %372, i32* %374, align 4, !tbaa !2795
  %375 = or i64 %366, 1
  %376 = add i32 %368, 3136
  %377 = sext i32 %376 to i64
  %378 = getelementptr inbounds float, float* %7, i64 %377
  %379 = bitcast float* %378 to i32*
  %380 = load i32, i32* %379, align 4, !tbaa !2792
  %381 = getelementptr inbounds float, float* %4, i64 %375
  %382 = bitcast float* %381 to i32*
  store i32 %380, i32* %382, align 4, !tbaa !2795
  %383 = or i64 %366, 2
  %384 = add i32 %368, 6272
  %385 = sext i32 %384 to i64
  %386 = getelementptr inbounds float, float* %7, i64 %385
  %387 = bitcast float* %386 to i32*
  %388 = load i32, i32* %387, align 4, !tbaa !2792
  %389 = getelementptr inbounds float, float* %4, i64 %383
  %390 = bitcast float* %389 to i32*
  store i32 %388, i32* %390, align 4, !tbaa !2795
  %391 = or i64 %366, 3
  %392 = add i32 %368, 9408
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds float, float* %7, i64 %393
  %395 = bitcast float* %394 to i32*
  %396 = load i32, i32* %395, align 4, !tbaa !2792
  %397 = getelementptr inbounds float, float* %4, i64 %391
  %398 = bitcast float* %397 to i32*
  store i32 %396, i32* %398, align 4, !tbaa !2795
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_begin4.preheader, !prof !50, !llvm.loop !2798

for_end3:                                         ; preds = %for_begin4.preheader, %vector.body
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %399 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %399, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_36(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.260, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !2799
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.261, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !2813
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.262, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !2815
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !2829
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 16
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !2831
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 14
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !2834
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 14
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !2836
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 16
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.46, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !2840
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 50176, i32 3136, i32 224, i32 16>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !2852
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.263, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !2856
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !2870
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !2872
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 14
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.17, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !2875
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 14
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.18, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !2877
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 256
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !2881
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 50176, i32 50176, i32 3584, i32 256>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !2893
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.264, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_36_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_36_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %21, align 8
  %3 = getelementptr inbounds %21, %21* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %21, %21* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %21* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.265, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.265(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 13
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 14
  %15 = select i1 %14, i32 %13, i32 14
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 14
  %18 = select i1 %17, i32 %16, i32 14
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 224
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body5 ]
  %27 = add nsw i64 %24, %indvars.iv
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 15
  %30 = lshr i32 %28, 4
  %31 = mul nsw i32 %30, 3136
  %32 = add i32 %26, %31
  %33 = or i32 %32, %29
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to i32*
  %37 = load i32, i32* %36, align 4, !tbaa !2897
  %38 = getelementptr inbounds float, float* %4, i64 %27
  %39 = bitcast float* %38 to i32*
  store i32 %37, i32* %39, align 4, !tbaa !2900
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %40 = or i64 %24, 256
  %41 = or i32 %26, 16
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %42 = add nsw i64 %40, %indvars.iv.1
  %43 = trunc i64 %indvars.iv.1 to i32
  %44 = and i32 %43, 15
  %45 = lshr i32 %43, 4
  %46 = mul nsw i32 %45, 3136
  %47 = add i32 %41, %46
  %48 = or i32 %47, %44
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to i32*
  %52 = load i32, i32* %51, align 4, !tbaa !2897
  %53 = getelementptr inbounds float, float* %4, i64 %42
  %54 = bitcast float* %53 to i32*
  store i32 %52, i32* %54, align 4, !tbaa !2900
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %55 = add nsw i64 %24, 512
  %56 = add i32 %26, 32
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %57 = add nsw i64 %55, %indvars.iv.2
  %58 = trunc i64 %indvars.iv.2 to i32
  %59 = and i32 %58, 15
  %60 = lshr i32 %58, 4
  %61 = mul nsw i32 %60, 3136
  %62 = add i32 %56, %61
  %63 = or i32 %62, %59
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float* %7, i64 %64
  %66 = bitcast float* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !2897
  %68 = getelementptr inbounds float, float* %4, i64 %57
  %69 = bitcast float* %68 to i32*
  store i32 %67, i32* %69, align 4, !tbaa !2900
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %70 = add nsw i64 %24, 768
  %71 = add i32 %26, 48
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %72 = add nsw i64 %70, %indvars.iv.3
  %73 = trunc i64 %indvars.iv.3 to i32
  %74 = and i32 %73, 15
  %75 = lshr i32 %73, 4
  %76 = mul nsw i32 %75, 3136
  %77 = add i32 %71, %76
  %78 = or i32 %77, %74
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %7, i64 %79
  %81 = bitcast float* %80 to i32*
  %82 = load i32, i32* %81, align 4, !tbaa !2897
  %83 = getelementptr inbounds float, float* %4, i64 %72
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4, !tbaa !2900
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  %85 = add nsw i64 %24, 1024
  %86 = add i32 %26, 64
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %87 = add nsw i64 %85, %indvars.iv.4
  %88 = trunc i64 %indvars.iv.4 to i32
  %89 = and i32 %88, 15
  %90 = lshr i32 %88, 4
  %91 = mul nsw i32 %90, 3136
  %92 = add i32 %86, %91
  %93 = or i32 %92, %89
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !2897
  %98 = getelementptr inbounds float, float* %4, i64 %87
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !2900
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 256
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  %100 = add nsw i64 %24, 1280
  %101 = add i32 %26, 80
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %102 = add nsw i64 %100, %indvars.iv.5
  %103 = trunc i64 %indvars.iv.5 to i32
  %104 = and i32 %103, 15
  %105 = lshr i32 %103, 4
  %106 = mul nsw i32 %105, 3136
  %107 = add i32 %101, %106
  %108 = or i32 %107, %104
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !2897
  %113 = getelementptr inbounds float, float* %4, i64 %102
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !2900
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 256
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  %115 = add nsw i64 %24, 1536
  %116 = add i32 %26, 96
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %117 = add nsw i64 %115, %indvars.iv.6
  %118 = trunc i64 %indvars.iv.6 to i32
  %119 = and i32 %118, 15
  %120 = lshr i32 %118, 4
  %121 = mul nsw i32 %120, 3136
  %122 = add i32 %116, %121
  %123 = or i32 %122, %119
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to i32*
  %127 = load i32, i32* %126, align 4, !tbaa !2897
  %128 = getelementptr inbounds float, float* %4, i64 %117
  %129 = bitcast float* %128 to i32*
  store i32 %127, i32* %129, align 4, !tbaa !2900
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 256
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  %130 = add nsw i64 %24, 1792
  %131 = add i32 %26, 112
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %132 = add nsw i64 %130, %indvars.iv.7
  %133 = trunc i64 %indvars.iv.7 to i32
  %134 = and i32 %133, 15
  %135 = lshr i32 %133, 4
  %136 = mul nsw i32 %135, 3136
  %137 = add i32 %131, %136
  %138 = or i32 %137, %134
  %139 = sext i32 %138 to i64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to i32*
  %142 = load i32, i32* %141, align 4, !tbaa !2897
  %143 = getelementptr inbounds float, float* %4, i64 %132
  %144 = bitcast float* %143 to i32*
  store i32 %142, i32* %144, align 4, !tbaa !2900
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 256
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !50

for_end6.7:                                       ; preds = %for_body5.7
  %145 = add nsw i64 %24, 2048
  %146 = add i32 %26, 128
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %147 = add nsw i64 %145, %indvars.iv.8
  %148 = trunc i64 %indvars.iv.8 to i32
  %149 = and i32 %148, 15
  %150 = lshr i32 %148, 4
  %151 = mul nsw i32 %150, 3136
  %152 = add i32 %146, %151
  %153 = or i32 %152, %149
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to i32*
  %157 = load i32, i32* %156, align 4, !tbaa !2897
  %158 = getelementptr inbounds float, float* %4, i64 %147
  %159 = bitcast float* %158 to i32*
  store i32 %157, i32* %159, align 4, !tbaa !2900
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 256
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !50

for_end6.8:                                       ; preds = %for_body5.8
  %160 = add nsw i64 %24, 2304
  %161 = add i32 %26, 144
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %162 = add nsw i64 %160, %indvars.iv.9
  %163 = trunc i64 %indvars.iv.9 to i32
  %164 = and i32 %163, 15
  %165 = lshr i32 %163, 4
  %166 = mul nsw i32 %165, 3136
  %167 = add i32 %161, %166
  %168 = or i32 %167, %164
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to i32*
  %172 = load i32, i32* %171, align 4, !tbaa !2897
  %173 = getelementptr inbounds float, float* %4, i64 %162
  %174 = bitcast float* %173 to i32*
  store i32 %172, i32* %174, align 4, !tbaa !2900
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 256
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !50

for_end6.9:                                       ; preds = %for_body5.9
  %175 = add nsw i64 %24, 2560
  %176 = add i32 %26, 160
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %177 = add nsw i64 %175, %indvars.iv.10
  %178 = trunc i64 %indvars.iv.10 to i32
  %179 = and i32 %178, 15
  %180 = lshr i32 %178, 4
  %181 = mul nsw i32 %180, 3136
  %182 = add i32 %176, %181
  %183 = or i32 %182, %179
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to i32*
  %187 = load i32, i32* %186, align 4, !tbaa !2897
  %188 = getelementptr inbounds float, float* %4, i64 %177
  %189 = bitcast float* %188 to i32*
  store i32 %187, i32* %189, align 4, !tbaa !2900
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 256
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !50

for_end6.10:                                      ; preds = %for_body5.10
  %190 = add nsw i64 %24, 2816
  %191 = add i32 %26, 176
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %192 = add nsw i64 %190, %indvars.iv.11
  %193 = trunc i64 %indvars.iv.11 to i32
  %194 = and i32 %193, 15
  %195 = lshr i32 %193, 4
  %196 = mul nsw i32 %195, 3136
  %197 = add i32 %191, %196
  %198 = or i32 %197, %194
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds float, float* %7, i64 %199
  %201 = bitcast float* %200 to i32*
  %202 = load i32, i32* %201, align 4, !tbaa !2897
  %203 = getelementptr inbounds float, float* %4, i64 %192
  %204 = bitcast float* %203 to i32*
  store i32 %202, i32* %204, align 4, !tbaa !2900
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 256
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !50

for_end6.11:                                      ; preds = %for_body5.11
  %205 = add nsw i64 %24, 3072
  %206 = add i32 %26, 192
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %207 = add nsw i64 %205, %indvars.iv.12
  %208 = trunc i64 %indvars.iv.12 to i32
  %209 = and i32 %208, 15
  %210 = lshr i32 %208, 4
  %211 = mul nsw i32 %210, 3136
  %212 = add i32 %206, %211
  %213 = or i32 %212, %209
  %214 = sext i32 %213 to i64
  %215 = getelementptr inbounds float, float* %7, i64 %214
  %216 = bitcast float* %215 to i32*
  %217 = load i32, i32* %216, align 4, !tbaa !2897
  %218 = getelementptr inbounds float, float* %4, i64 %207
  %219 = bitcast float* %218 to i32*
  store i32 %217, i32* %219, align 4, !tbaa !2900
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 256
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !50

for_end6.12:                                      ; preds = %for_body5.12
  %220 = add nsw i64 %24, 3328
  %221 = add i32 %26, 208
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %222 = add nsw i64 %220, %indvars.iv.13
  %223 = trunc i64 %indvars.iv.13 to i32
  %224 = and i32 %223, 15
  %225 = lshr i32 %223, 4
  %226 = mul nsw i32 %225, 3136
  %227 = add i32 %221, %226
  %228 = or i32 %227, %224
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to i32*
  %232 = load i32, i32* %231, align 4, !tbaa !2897
  %233 = getelementptr inbounds float, float* %4, i64 %222
  %234 = bitcast float* %233 to i32*
  store i32 %232, i32* %234, align 4, !tbaa !2900
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 256
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !50

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %235 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %235, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_42(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.266, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !2903
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.267, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !2917
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.268, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !2919
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !2933
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 4
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !2935
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 28
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !2938
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 28
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !2940
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !2944
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 100352, i32 25088, i32 896, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !2956
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.269, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !2960
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !2974
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !2976
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 28
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !2979
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 28
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !2981
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 128
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.270, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !2985
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 100352, i32 100352, i32 3584, i32 128>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !2997
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.271, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_42_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_42_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %22, align 8
  %3 = getelementptr inbounds %22, %22* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %22, %22* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %22* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.272, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.272(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 7
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 25088
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !3001
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !3004
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.273, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !3007
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !3021
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !3024
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !3026
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.274, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !3030
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.275, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.276, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.277, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.278, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !3032
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !3046
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 2
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.122, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !3048
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 14
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !3051
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 14
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !3053
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 512
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !3057
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 200704, i32 100352, i32 7168, i32 512>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !3069
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.279, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !3073
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 16
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !3087
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 2
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.280, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !3089
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !3092
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !3094
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 512
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !3098
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 32
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !3100
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 32768, i32 16384, i32 16384, i32 16384>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !3112
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 32
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !3116
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([279 x i8], [279 x i8]* @.str.281, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !3118
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 16
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !3132
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !3134
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !3137
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 32
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !3139
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !3151
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 16
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.250, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !3165
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !3167
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !3170
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 32
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !3172
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !3184
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !3198
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 16
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.251, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !3200
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 7
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.252, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !3203
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 7
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.253, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !3205
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 32
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !3209
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 25088, i32 1568, i32 224, i32 32>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !3221
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.254, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %5 = alloca %23, align 8
  %6 = getelementptr inbounds %23, %23* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %23, %23* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %23, %23* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %23, %23* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %23, %23* %5, i64 0, i32 4
  store i8* %4, i8** %10, align 8
  %11 = bitcast %23* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.282, i8* nonnull %11, i32 0)
  ret i32 %13
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.282(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv48 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next49, %for_end6.1 ]
  %33 = trunc i64 %indvars.iv48 to i32
  %34 = srem i32 %33, 7
  %35 = mul nsw i32 %34, 14336
  %36 = sdiv i32 %33, 7
  %37 = shl i32 %36, 15
  %38 = sext i32 %35 to i64
  %39 = sext i32 %37 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %93, %for_body5 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %87, %for_body5 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %44 = phi <32 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %45 = phi <32 x float> [ zeroinitializer, %for_body ], [ %63, %for_body5 ]
  %46 = phi <32 x float> [ zeroinitializer, %for_body ], [ %57, %for_body5 ]
  %47 = add nsw i64 %indvars.iv, %38
  %48 = getelementptr inbounds float, float* %4, i64 %47
  %49 = load float, float* %48, align 4, !tbaa !3225
  %50 = insertelement <32 x float> undef, float %49, i32 0
  %51 = shufflevector <32 x float> %50, <32 x float> undef, <32 x i32> zeroinitializer
  %52 = shl i64 %indvars.iv, 5
  %53 = add nuw nsw i64 %52, %39
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <32 x float>*
  %56 = load <32 x float>, <32 x float>* %55, align 64, !tbaa !3228
  %57 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %51, <32 x float> %56, <32 x float> %46)
  %58 = add nsw i64 %47, 1024
  %59 = getelementptr inbounds float, float* %4, i64 %58
  %60 = load float, float* %59, align 4, !tbaa !3225
  %61 = insertelement <32 x float> undef, float %60, i32 0
  %62 = shufflevector <32 x float> %61, <32 x float> undef, <32 x i32> zeroinitializer
  %63 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %56, <32 x float> %45)
  %64 = add nsw i64 %47, 2048
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !3225
  %67 = insertelement <32 x float> undef, float %66, i32 0
  %68 = shufflevector <32 x float> %67, <32 x float> undef, <32 x i32> zeroinitializer
  %69 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %56, <32 x float> %44)
  %70 = add nsw i64 %47, 3072
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !3225
  %73 = insertelement <32 x float> undef, float %72, i32 0
  %74 = shufflevector <32 x float> %73, <32 x float> undef, <32 x i32> zeroinitializer
  %75 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %56, <32 x float> %43)
  %76 = add nsw i64 %47, 4096
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !3225
  %79 = insertelement <32 x float> undef, float %78, i32 0
  %80 = shufflevector <32 x float> %79, <32 x float> undef, <32 x i32> zeroinitializer
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %56, <32 x float> %42)
  %82 = add nsw i64 %47, 5120
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !3225
  %85 = insertelement <32 x float> undef, float %84, i32 0
  %86 = shufflevector <32 x float> %85, <32 x float> undef, <32 x i32> zeroinitializer
  %87 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %56, <32 x float> %41)
  %88 = add nsw i64 %47, 6144
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !3225
  %91 = insertelement <32 x float> undef, float %90, i32 0
  %92 = shufflevector <32 x float> %91, <32 x float> undef, <32 x i32> zeroinitializer
  %93 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %56, <32 x float> %40)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %94 = add nsw i64 %38, 100352
  %95 = or i64 %39, 16384
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %96 = phi <32 x float> [ %93, %for_end6 ], [ %149, %for_body5.1 ]
  %97 = phi <32 x float> [ %87, %for_end6 ], [ %143, %for_body5.1 ]
  %98 = phi <32 x float> [ %81, %for_end6 ], [ %137, %for_body5.1 ]
  %99 = phi <32 x float> [ %75, %for_end6 ], [ %131, %for_body5.1 ]
  %100 = phi <32 x float> [ %69, %for_end6 ], [ %125, %for_body5.1 ]
  %101 = phi <32 x float> [ %63, %for_end6 ], [ %119, %for_body5.1 ]
  %102 = phi <32 x float> [ %57, %for_end6 ], [ %113, %for_body5.1 ]
  %103 = add nsw i64 %94, %indvars.iv.1
  %104 = getelementptr inbounds float, float* %4, i64 %103
  %105 = load float, float* %104, align 4, !tbaa !3225
  %106 = insertelement <32 x float> undef, float %105, i32 0
  %107 = shufflevector <32 x float> %106, <32 x float> undef, <32 x i32> zeroinitializer
  %108 = shl i64 %indvars.iv.1, 5
  %109 = add nuw nsw i64 %95, %108
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to <32 x float>*
  %112 = load <32 x float>, <32 x float>* %111, align 64, !tbaa !3228
  %113 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %107, <32 x float> %112, <32 x float> %102)
  %114 = add nsw i64 %103, 1024
  %115 = getelementptr inbounds float, float* %4, i64 %114
  %116 = load float, float* %115, align 4, !tbaa !3225
  %117 = insertelement <32 x float> undef, float %116, i32 0
  %118 = shufflevector <32 x float> %117, <32 x float> undef, <32 x i32> zeroinitializer
  %119 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %118, <32 x float> %112, <32 x float> %101)
  %120 = add nsw i64 %103, 2048
  %121 = getelementptr inbounds float, float* %4, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !3225
  %123 = insertelement <32 x float> undef, float %122, i32 0
  %124 = shufflevector <32 x float> %123, <32 x float> undef, <32 x i32> zeroinitializer
  %125 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %124, <32 x float> %112, <32 x float> %100)
  %126 = add nsw i64 %103, 3072
  %127 = getelementptr inbounds float, float* %4, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !3225
  %129 = insertelement <32 x float> undef, float %128, i32 0
  %130 = shufflevector <32 x float> %129, <32 x float> undef, <32 x i32> zeroinitializer
  %131 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %130, <32 x float> %112, <32 x float> %99)
  %132 = add nsw i64 %103, 4096
  %133 = getelementptr inbounds float, float* %4, i64 %132
  %134 = load float, float* %133, align 4, !tbaa !3225
  %135 = insertelement <32 x float> undef, float %134, i32 0
  %136 = shufflevector <32 x float> %135, <32 x float> undef, <32 x i32> zeroinitializer
  %137 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %136, <32 x float> %112, <32 x float> %98)
  %138 = add nsw i64 %103, 5120
  %139 = getelementptr inbounds float, float* %4, i64 %138
  %140 = load float, float* %139, align 4, !tbaa !3225
  %141 = insertelement <32 x float> undef, float %140, i32 0
  %142 = shufflevector <32 x float> %141, <32 x float> undef, <32 x i32> zeroinitializer
  %143 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %142, <32 x float> %112, <32 x float> %97)
  %144 = add nsw i64 %103, 6144
  %145 = getelementptr inbounds float, float* %4, i64 %144
  %146 = load float, float* %145, align 4, !tbaa !3225
  %147 = insertelement <32 x float> undef, float %146, i32 0
  %148 = shufflevector <32 x float> %147, <32 x float> undef, <32 x i32> zeroinitializer
  %149 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %148, <32 x float> %112, <32 x float> %96)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %150 = mul nsw i64 %indvars.iv48, 224
  %151 = shl nsw i32 %36, 5
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds float, float* %16, i64 %152
  %154 = bitcast float* %153 to <32 x float>*
  %155 = load <32 x float>, <32 x float>* %154, align 64, !tbaa !3231
  %156 = getelementptr inbounds float, float* %13, i64 %152
  %157 = bitcast float* %156 to <32 x float>*
  %158 = load <32 x float>, <32 x float>* %157, align 64, !tbaa !3234
  %159 = fadd <32 x float> %158, %113
  %160 = fadd <32 x float> %155, %159
  %161 = fcmp ogt <32 x float> %160, zeroinitializer
  %162 = select <32 x i1> %161, <32 x float> %160, <32 x float> zeroinitializer
  %163 = getelementptr inbounds float, float* %10, i64 %150
  %164 = bitcast float* %163 to <32 x float>*
  store <32 x float> %162, <32 x float>* %164, align 64, !tbaa !3237
  %165 = add nsw i64 %150, 32
  %166 = fadd <32 x float> %158, %119
  %167 = fadd <32 x float> %155, %166
  %168 = fcmp ogt <32 x float> %167, zeroinitializer
  %169 = select <32 x i1> %168, <32 x float> %167, <32 x float> zeroinitializer
  %170 = getelementptr inbounds float, float* %10, i64 %165
  %171 = bitcast float* %170 to <32 x float>*
  store <32 x float> %169, <32 x float>* %171, align 64, !tbaa !3237
  %172 = add nsw i64 %150, 64
  %173 = fadd <32 x float> %158, %125
  %174 = fadd <32 x float> %155, %173
  %175 = fcmp ogt <32 x float> %174, zeroinitializer
  %176 = select <32 x i1> %175, <32 x float> %174, <32 x float> zeroinitializer
  %177 = getelementptr inbounds float, float* %10, i64 %172
  %178 = bitcast float* %177 to <32 x float>*
  store <32 x float> %176, <32 x float>* %178, align 64, !tbaa !3237
  %179 = add nsw i64 %150, 96
  %180 = fadd <32 x float> %158, %131
  %181 = fadd <32 x float> %155, %180
  %182 = fcmp ogt <32 x float> %181, zeroinitializer
  %183 = select <32 x i1> %182, <32 x float> %181, <32 x float> zeroinitializer
  %184 = getelementptr inbounds float, float* %10, i64 %179
  %185 = bitcast float* %184 to <32 x float>*
  store <32 x float> %183, <32 x float>* %185, align 64, !tbaa !3237
  %186 = add nsw i64 %150, 128
  %187 = fadd <32 x float> %158, %137
  %188 = fadd <32 x float> %155, %187
  %189 = fcmp ogt <32 x float> %188, zeroinitializer
  %190 = select <32 x i1> %189, <32 x float> %188, <32 x float> zeroinitializer
  %191 = getelementptr inbounds float, float* %10, i64 %186
  %192 = bitcast float* %191 to <32 x float>*
  store <32 x float> %190, <32 x float>* %192, align 64, !tbaa !3237
  %193 = add nsw i64 %150, 160
  %194 = fadd <32 x float> %158, %143
  %195 = fadd <32 x float> %155, %194
  %196 = fcmp ogt <32 x float> %195, zeroinitializer
  %197 = select <32 x i1> %196, <32 x float> %195, <32 x float> zeroinitializer
  %198 = getelementptr inbounds float, float* %10, i64 %193
  %199 = bitcast float* %198 to <32 x float>*
  store <32 x float> %197, <32 x float>* %199, align 64, !tbaa !3237
  %200 = add nsw i64 %150, 192
  %201 = fadd <32 x float> %158, %149
  %202 = fadd <32 x float> %155, %201
  %203 = fcmp ogt <32 x float> %202, zeroinitializer
  %204 = select <32 x i1> %203, <32 x float> %202, <32 x float> zeroinitializer
  %205 = getelementptr inbounds float, float* %10, i64 %200
  %206 = bitcast float* %205 to <32 x float>*
  store <32 x float> %204, <32 x float>* %206, align 64, !tbaa !3237
  %indvars.iv.next49 = add nsw i64 %indvars.iv48, 1
  %207 = icmp slt i64 %indvars.iv.next49, %32
  br i1 %207, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 6
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([101 x i8], [101 x i8]* @.str.283, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !3240
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !3254
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !3257
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !3259
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !3263
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.284, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %77 = getelementptr inbounds i8, i8* %1, i64 4
  %78 = bitcast i8* %77 to i32*
  %79 = load i32, i32* %78, align 4, !tbaa !3265
  switch i32 %79, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.285, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %81 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %81(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.286, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.287, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %83 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %83(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.288, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.289, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  %85 = icmp eq i32 %43, 1
  br i1 %85, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %86 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %86(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %87 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %88 = load i32, i32* %87, align 4
  %89 = icmp eq i32 %88, 5
  br i1 %89, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %91 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %92 = load i16, i16* %91, align 2
  %93 = icmp eq i16 %92, 1
  %94 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %95 = load i8, i8* %94, align 1
  %96 = icmp eq i8 %95, 32
  %97 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %98 = load i8, i8* %97, align 1
  %99 = icmp eq i8 %98, 2
  %100 = and i1 %96, %99
  %101 = and i1 %93, %100
  br i1 %101, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %103 = load i64, i64* %39, align 8, !tbaa !3267
  %104 = trunc i64 %103 to i32
  %105 = icmp eq i32 %104, 1
  br i1 %105, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %107 = getelementptr inbounds i64, i64* %39, i64 1
  %108 = load i64, i64* %107, align 8, !tbaa !3281
  %109 = trunc i64 %108 to i32
  %110 = icmp eq i32 %109, 1
  br i1 %110, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %111 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %111(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %112 = getelementptr inbounds i64, i64* %39, i64 2
  %113 = load i64, i64* %112, align 8, !tbaa !3283
  %114 = trunc i64 %113 to i32
  %115 = icmp eq i32 %114, 56
  br i1 %115, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %116 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %116(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %117 = getelementptr inbounds i64, i64* %39, i64 3
  %118 = load i64, i64* %117, align 8, !tbaa !3286
  %119 = trunc i64 %118 to i32
  %120 = icmp eq i32 %119, 56
  br i1 %120, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %121 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %121(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %122 = getelementptr inbounds i64, i64* %39, i64 4
  %123 = load i64, i64* %122, align 8, !tbaa !3288
  %124 = trunc i64 %123 to i32
  %125 = icmp eq i32 %124, 256
  br i1 %125, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %126 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %126(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %127 = icmp eq i64* %41, null
  br i1 %127, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end28
  %128 = bitcast i64* %41 to <4 x i64>*
  %129 = load <4 x i64>, <4 x i64>* %128, align 8, !tbaa !3292
  %130 = trunc <4 x i64> %129 to <4 x i32>
  %131 = icmp eq <4 x i32> %130, <i32 802816, i32 802816, i32 14336, i32 256>
  %132 = getelementptr inbounds i64, i64* %41, i64 4
  %133 = load i64, i64* %132, align 8, !tbaa !3304
  %134 = trunc i64 %133 to i32
  %135 = icmp eq i32 %134, 1
  %rdx.shuf167 = shufflevector <4 x i1> %131, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx168 = and <4 x i1> %131, %rdx.shuf167
  %rdx.shuf169 = shufflevector <4 x i1> %bin.rdx168, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx170 = and <4 x i1> %bin.rdx168, %rdx.shuf169
  %136 = extractelement <4 x i1> %bin.rdx170, i32 0
  %137 = and i1 %136, %135
  br i1 %137, label %if_end, label %assert_fail29, !prof !5

if_end:                                           ; preds = %assert_end28, %if_then
  %138 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %139 = load i64, i64* %138, align 8
  %140 = icmp eq i64 %139, 0
  br i1 %140, label %assert_end32, label %assert_fail31, !prof !5

assert_fail29:                                    ; preds = %if_then
  %141 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %141(i8* getelementptr inbounds ([243 x i8], [243 x i8]* @.str.104, i64 0, i64 0))
  ret i32 -1

assert_fail31:                                    ; preds = %if_end
  %142 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %142(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %if_end
  %143 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %144 = load i32, i32* %143, align 4
  %145 = icmp eq i32 %144, 6
  br i1 %145, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %148 = load i16, i16* %147, align 2
  %149 = icmp eq i16 %148, 1
  %150 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %151 = load i8, i8* %150, align 1
  %152 = icmp eq i8 %151, 32
  %153 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %154 = load i8, i8* %153, align 1
  %155 = icmp eq i8 %154, 2
  %156 = and i1 %152, %155
  %157 = and i1 %149, %156
  br i1 %157, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %159 = load i64, i64* %49, align 8, !tbaa !3308
  %160 = trunc i64 %159 to i32
  %161 = icmp eq i32 %160, 8
  br i1 %161, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %162 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %162(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.190, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %163 = getelementptr inbounds i64, i64* %49, i64 1
  %164 = load i64, i64* %163, align 8, !tbaa !3322
  %165 = trunc i64 %164 to i32
  %166 = icmp eq i32 %165, 1
  br i1 %166, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %167 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %167(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %168 = getelementptr inbounds i64, i64* %49, i64 2
  %169 = load i64, i64* %168, align 8, !tbaa !3324
  %170 = trunc i64 %169 to i32
  %171 = icmp eq i32 %170, 1
  br i1 %171, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %172 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %172(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %173 = getelementptr inbounds i64, i64* %49, i64 3
  %174 = load i64, i64* %173, align 8, !tbaa !3327
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  br i1 %176, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %177 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %177(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %178 = getelementptr inbounds i64, i64* %49, i64 4
  %179 = load i64, i64* %178, align 8, !tbaa !3329
  %180 = trunc i64 %179 to i32
  %181 = icmp eq i32 %180, 256
  br i1 %181, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %182 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %182(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %183 = getelementptr inbounds i64, i64* %49, i64 5
  %184 = load i64, i64* %183, align 8, !tbaa !3333
  %185 = trunc i64 %184 to i32
  %186 = icmp eq i32 %185, 64
  br i1 %186, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %187 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %187(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.227, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %188 = icmp eq i64* %51, null
  br i1 %188, label %if_end50, label %if_then49, !prof !50

if_then49:                                        ; preds = %assert_end48
  %189 = bitcast i64* %51 to <4 x i64>*
  %190 = load <4 x i64>, <4 x i64>* %189, align 8, !tbaa !3335
  %191 = trunc <4 x i64> %190 to <4 x i32>
  %192 = icmp eq <4 x i32> %191, <i32 16384, i32 16384, i32 16384, i32 16384>
  %193 = getelementptr inbounds i64, i64* %51, i64 4
  %194 = load i64, i64* %193, align 8, !tbaa !3347
  %195 = trunc i64 %194 to i32
  %196 = icmp eq i32 %195, 64
  %197 = getelementptr inbounds i64, i64* %51, i64 5
  %198 = load i64, i64* %197, align 8, !tbaa !3351
  %199 = trunc i64 %198 to i32
  %200 = icmp eq i32 %199, 1
  %rdx.shuf163 = shufflevector <4 x i1> %192, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx164 = and <4 x i1> %192, %rdx.shuf163
  %rdx.shuf165 = shufflevector <4 x i1> %bin.rdx164, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx166 = and <4 x i1> %bin.rdx164, %rdx.shuf165
  %201 = extractelement <4 x i1> %bin.rdx166, i32 0
  %202 = and i1 %201, %196
  %203 = and i1 %202, %200
  br i1 %203, label %if_end50, label %assert_fail51, !prof !5

if_end50:                                         ; preds = %assert_end48, %if_then49
  %204 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %205 = load i64, i64* %204, align 8
  %206 = icmp eq i64 %205, 0
  br i1 %206, label %assert_end54, label %assert_fail53, !prof !5

assert_fail51:                                    ; preds = %if_then49
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([279 x i8], [279 x i8]* @.str.290, i64 0, i64 0))
  ret i32 -1

assert_fail53:                                    ; preds = %if_end50
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %if_end50
  %209 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %210 = load i32, i32* %209, align 4
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %213 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %214 = load i32, i32* %213, align 4
  %215 = icmp eq i32 %45, %214
  br i1 %215, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %216 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %216(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %217 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %218 = load i32, i32* %217, align 4
  %219 = icmp eq i32 %218, 4
  br i1 %219, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %221 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %222 = load i16, i16* %221, align 2
  %223 = icmp eq i16 %222, 1
  %224 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %225 = load i8, i8* %224, align 1
  %226 = icmp eq i8 %225, 32
  %227 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %228 = load i8, i8* %227, align 1
  %229 = icmp eq i8 %228, 2
  %230 = and i1 %226, %229
  %231 = and i1 %223, %230
  br i1 %231, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %233 = load i64, i64* %55, align 8, !tbaa !3353
  %234 = trunc i64 %233 to i32
  %235 = icmp eq i32 %234, 8
  br i1 %235, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %236 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %236(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.192, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %237 = getelementptr inbounds i64, i64* %55, i64 1
  %238 = load i64, i64* %237, align 8, !tbaa !3367
  %239 = trunc i64 %238 to i32
  %240 = icmp eq i32 %239, 1
  br i1 %240, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %241 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %241(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %242 = getelementptr inbounds i64, i64* %55, i64 2
  %243 = load i64, i64* %242, align 8, !tbaa !3369
  %244 = trunc i64 %243 to i32
  %245 = icmp eq i32 %244, 1
  br i1 %245, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %246 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %246(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %247 = getelementptr inbounds i64, i64* %55, i64 3
  %248 = load i64, i64* %247, align 8, !tbaa !3372
  %249 = trunc i64 %248 to i32
  %250 = icmp eq i32 %249, 64
  br i1 %250, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %251 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %251(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.229, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %252 = icmp eq i64* %57, null
  br i1 %252, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %253 = bitcast i64* %57 to <4 x i64>*
  %254 = load <4 x i64>, <4 x i64>* %253, align 8, !tbaa !3374
  %255 = trunc <4 x i64> %254 to <4 x i32>
  %256 = icmp eq <4 x i32> %255, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf159 = shufflevector <4 x i1> %256, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx160 = and <4 x i1> %256, %rdx.shuf159
  %rdx.shuf161 = shufflevector <4 x i1> %bin.rdx160, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx162 = and <4 x i1> %bin.rdx160, %rdx.shuf161
  %257 = extractelement <4 x i1> %bin.rdx162, i32 0
  br i1 %257, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %258 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %259 = load i64, i64* %258, align 8
  %260 = icmp eq i64 %259, 0
  br i1 %260, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.230, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %262 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %262(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %263 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %264 = load i32, i32* %263, align 4
  %265 = icmp eq i32 %264, 1
  br i1 %265, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %266 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %266(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %267 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %268 = load i32, i32* %267, align 4
  %269 = icmp eq i32 %45, %268
  br i1 %269, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %270 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %270(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %271 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %272 = load i32, i32* %271, align 4
  %273 = icmp eq i32 %272, 4
  br i1 %273, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %275 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %276 = load i16, i16* %275, align 2
  %277 = icmp eq i16 %276, 1
  %278 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %279 = load i8, i8* %278, align 1
  %280 = icmp eq i8 %279, 32
  %281 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %282 = load i8, i8* %281, align 1
  %283 = icmp eq i8 %282, 2
  %284 = and i1 %280, %283
  %285 = and i1 %277, %284
  br i1 %285, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %287 = load i64, i64* %61, align 8, !tbaa !3386
  %288 = trunc i64 %287 to i32
  %289 = icmp eq i32 %288, 8
  br i1 %289, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %290 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %290(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.193, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %291 = getelementptr inbounds i64, i64* %61, i64 1
  %292 = load i64, i64* %291, align 8, !tbaa !3400
  %293 = trunc i64 %292 to i32
  %294 = icmp eq i32 %293, 1
  br i1 %294, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %295 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %295(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %296 = getelementptr inbounds i64, i64* %61, i64 2
  %297 = load i64, i64* %296, align 8, !tbaa !3402
  %298 = trunc i64 %297 to i32
  %299 = icmp eq i32 %298, 1
  br i1 %299, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %300 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %300(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %301 = getelementptr inbounds i64, i64* %61, i64 3
  %302 = load i64, i64* %301, align 8, !tbaa !3405
  %303 = trunc i64 %302 to i32
  %304 = icmp eq i32 %303, 64
  br i1 %304, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %305 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %305(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.231, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %306 = icmp eq i64* %63, null
  br i1 %306, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %307 = bitcast i64* %63 to <4 x i64>*
  %308 = load <4 x i64>, <4 x i64>* %307, align 8, !tbaa !3407
  %309 = trunc <4 x i64> %308 to <4 x i32>
  %310 = icmp eq <4 x i32> %309, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf155 = shufflevector <4 x i1> %310, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx156 = and <4 x i1> %310, %rdx.shuf155
  %rdx.shuf157 = shufflevector <4 x i1> %bin.rdx156, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx158 = and <4 x i1> %bin.rdx156, %rdx.shuf157
  %311 = extractelement <4 x i1> %bin.rdx158, i32 0
  br i1 %311, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %312 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %313 = load i64, i64* %312, align 8
  %314 = icmp eq i64 %313, 0
  br i1 %314, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.232, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %317 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %318, 1
  br i1 %319, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %321 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %322 = load i32, i32* %321, align 4
  %323 = icmp eq i32 %45, %322
  br i1 %323, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %325 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %326 = load i32, i32* %325, align 4
  %327 = icmp eq i32 %326, 4
  br i1 %327, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %329 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %330 = load i16, i16* %329, align 2
  %331 = icmp eq i16 %330, 1
  %332 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %333 = load i8, i8* %332, align 1
  %334 = icmp eq i8 %333, 32
  %335 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %336 = load i8, i8* %335, align 1
  %337 = icmp eq i8 %336, 2
  %338 = and i1 %334, %337
  %339 = and i1 %331, %338
  br i1 %339, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %340 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %340(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %341 = load i64, i64* %67, align 8, !tbaa !3419
  %342 = trunc i64 %341 to i32
  %343 = icmp eq i32 %342, 8
  br i1 %343, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %344 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %344(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.194, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %345 = getelementptr inbounds i64, i64* %67, i64 1
  %346 = load i64, i64* %345, align 8, !tbaa !3433
  %347 = trunc i64 %346 to i32
  %348 = icmp eq i32 %347, 1
  br i1 %348, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %350 = getelementptr inbounds i64, i64* %67, i64 2
  %351 = load i64, i64* %350, align 8, !tbaa !3435
  %352 = trunc i64 %351 to i32
  %353 = icmp eq i32 %352, 1
  br i1 %353, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %354 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %354(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %355 = getelementptr inbounds i64, i64* %67, i64 3
  %356 = load i64, i64* %355, align 8, !tbaa !3438
  %357 = trunc i64 %356 to i32
  %358 = icmp eq i32 %357, 64
  br i1 %358, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %359 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %359(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.291, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %360 = icmp eq i64* %69, null
  br i1 %360, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %361 = bitcast i64* %69 to <4 x i64>*
  %362 = load <4 x i64>, <4 x i64>* %361, align 8, !tbaa !3440
  %363 = trunc <4 x i64> %362 to <4 x i32>
  %364 = icmp eq <4 x i32> %363, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf151 = shufflevector <4 x i1> %364, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx152 = and <4 x i1> %364, %rdx.shuf151
  %rdx.shuf153 = shufflevector <4 x i1> %bin.rdx152, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx154 = and <4 x i1> %bin.rdx152, %rdx.shuf153
  %365 = extractelement <4 x i1> %bin.rdx154, i32 0
  br i1 %365, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %366 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %367 = load i64, i64* %366, align 8
  %368 = icmp eq i64 %367, 0
  br i1 %368, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %369 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %369(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.292, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %370 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %370(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %371 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %372 = load i32, i32* %371, align 4
  %373 = icmp eq i32 %372, 1
  br i1 %373, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %374 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %374(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %375 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %376 = load i32, i32* %375, align 4
  %377 = icmp eq i32 %45, %376
  br i1 %377, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %378 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %378(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %379 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %380 = load i32, i32* %379, align 4
  %381 = icmp eq i32 %380, 5
  br i1 %381, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %383 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %384 = load i16, i16* %383, align 2
  %385 = icmp eq i16 %384, 1
  %386 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %387 = load i8, i8* %386, align 1
  %388 = icmp eq i8 %387, 32
  %389 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %390 = load i8, i8* %389, align 1
  %391 = icmp eq i8 %390, 2
  %392 = and i1 %388, %391
  %393 = and i1 %385, %392
  br i1 %393, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %394 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %394(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %395 = load i64, i64* %73, align 8, !tbaa !3452
  %396 = trunc i64 %395 to i32
  %397 = icmp eq i32 %396, 1
  br i1 %397, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %398 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %398(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %399 = getelementptr inbounds i64, i64* %73, i64 1
  %400 = load i64, i64* %399, align 8, !tbaa !3466
  %401 = trunc i64 %400 to i32
  %402 = icmp eq i32 %401, 8
  br i1 %402, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %403 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %403(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.195, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %404 = getelementptr inbounds i64, i64* %73, i64 2
  %405 = load i64, i64* %404, align 8, !tbaa !3468
  %406 = trunc i64 %405 to i32
  %407 = icmp eq i32 %406, 28
  br i1 %407, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %408 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %408(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.293, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %409 = getelementptr inbounds i64, i64* %73, i64 3
  %410 = load i64, i64* %409, align 8, !tbaa !3471
  %411 = trunc i64 %410 to i32
  %412 = icmp eq i32 %411, 28
  br i1 %412, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %413 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %413(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.294, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %414 = getelementptr inbounds i64, i64* %73, i64 4
  %415 = load i64, i64* %414, align 8, !tbaa !3473
  %416 = trunc i64 %415 to i32
  %417 = icmp eq i32 %416, 64
  br i1 %417, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %418 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %418(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.295, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %419 = icmp eq i64* %75, null
  br i1 %419, label %if_end140, label %if_then139, !prof !50

if_then139:                                       ; preds = %assert_end138
  %420 = bitcast i64* %75 to <4 x i64>*
  %421 = load <4 x i64>, <4 x i64>* %420, align 8, !tbaa !3477
  %422 = trunc <4 x i64> %421 to <4 x i32>
  %423 = icmp eq <4 x i32> %422, <i32 401408, i32 50176, i32 1792, i32 64>
  %424 = getelementptr inbounds i64, i64* %75, i64 4
  %425 = load i64, i64* %424, align 8, !tbaa !3489
  %426 = trunc i64 %425 to i32
  %427 = icmp eq i32 %426, 1
  %rdx.shuf = shufflevector <4 x i1> %423, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %423, %rdx.shuf
  %rdx.shuf149 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx150 = and <4 x i1> %bin.rdx, %rdx.shuf149
  %428 = extractelement <4 x i1> %bin.rdx150, i32 0
  %429 = and i1 %428, %427
  br i1 %429, label %if_end140, label %assert_fail141, !prof !5

if_end140:                                        ; preds = %assert_end138, %if_then139
  %430 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %431 = load i64, i64* %430, align 8
  %432 = icmp eq i64 %431, 0
  br i1 %432, label %assert_end144, label %assert_fail143, !prof !5

assert_fail141:                                   ; preds = %if_then139
  %433 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %433(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.296, i64 0, i64 0))
  ret i32 -1

assert_fail143:                                   ; preds = %if_end140
  %434 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %434(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end144:                                    ; preds = %if_end140
  %435 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %436 = load i32, i32* %435, align 4
  %437 = icmp eq i32 %436, 1
  br i1 %437, label %assert_end146, label %assert_fail145, !prof !5

assert_fail145:                                   ; preds = %assert_end144
  %438 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %438(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %assert_end144
  %439 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %440 = load i32, i32* %439, align 4
  %441 = icmp eq i32 %45, %440
  br i1 %441, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %442 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %442(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %443 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1_compute_(i8* %37, i8* %47, i8* %71, i8* %53, i8* %59, i8* %65, i32 %45)
  ret i32 %443
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %24, align 8
  %8 = getelementptr inbounds %24, %24* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %24, %24* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %24, %24* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %24, %24* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %24, %24* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %24, %24* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %24, %24* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %24* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.297, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.297(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 223
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 224
  %30 = select i1 %29, i32 %28, i32 224
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 224
  %33 = select i1 %32, i32 %31, i32 224
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end6.6
  %indvars.iv36 = phi i64 [ %37, %for_body.preheader ], [ %indvars.iv.next37, %for_end6.6 ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %40 = tail call i8* %39(i32 1, i32 %22, i64 7168, i32 2, i32 32)
  %41 = trunc i64 %indvars.iv36 to i32
  %42 = srem i32 %41, 28
  %43 = mul nsw i32 %42, 28672
  %44 = sdiv i32 %41, 28
  %45 = shl i32 %44, 14
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  %48 = bitcast i8* %40 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %48, align 64, !tbaa !3493
  %49 = getelementptr inbounds i8, i8* %40, i64 256
  %50 = bitcast i8* %49 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %50, align 64, !tbaa !3493
  %51 = getelementptr inbounds i8, i8* %40, i64 512
  %52 = bitcast i8* %51 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %52, align 64, !tbaa !3493
  %53 = getelementptr inbounds i8, i8* %40, i64 768
  %54 = bitcast i8* %53 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %54, align 64, !tbaa !3493
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %55 = phi <64 x float> [ zeroinitializer, %for_body ], [ %87, %for_body5 ]
  %56 = phi <64 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %57 = phi <64 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %58 = phi <64 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %59 = add nsw i64 %indvars.iv, %47
  %60 = getelementptr inbounds float, float* %4, i64 %59
  %61 = load float, float* %60, align 4, !tbaa !3496
  %62 = insertelement <64 x float> undef, float %61, i32 0
  %63 = shufflevector <64 x float> %62, <64 x float> undef, <64 x i32> zeroinitializer
  %64 = shl i64 %indvars.iv, 6
  %65 = add nuw nsw i64 %64, %46
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <64 x float>*
  %68 = load <64 x float>, <64 x float>* %67, align 64, !tbaa !3499
  %69 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %63, <64 x float> %68, <64 x float> %58)
  %70 = add nsw i64 %59, 512
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !3496
  %73 = insertelement <64 x float> undef, float %72, i32 0
  %74 = shufflevector <64 x float> %73, <64 x float> undef, <64 x i32> zeroinitializer
  %75 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %74, <64 x float> %68, <64 x float> %57)
  %76 = add nsw i64 %59, 1024
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !3496
  %79 = insertelement <64 x float> undef, float %78, i32 0
  %80 = shufflevector <64 x float> %79, <64 x float> undef, <64 x i32> zeroinitializer
  %81 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %80, <64 x float> %68, <64 x float> %56)
  %82 = add nsw i64 %59, 1536
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !3496
  %85 = insertelement <64 x float> undef, float %84, i32 0
  %86 = shufflevector <64 x float> %85, <64 x float> undef, <64 x i32> zeroinitializer
  %87 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %86, <64 x float> %68, <64 x float> %55)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  store <64 x float> %69, <64 x float>* %48, align 64, !tbaa !3493
  store <64 x float> %75, <64 x float>* %50, align 64, !tbaa !3493
  store <64 x float> %81, <64 x float>* %52, align 64, !tbaa !3493
  store <64 x float> %87, <64 x float>* %54, align 64, !tbaa !3493
  %88 = getelementptr inbounds i8, i8* %40, i64 1024
  %89 = bitcast i8* %88 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %89, align 64, !tbaa !3493
  %90 = getelementptr inbounds i8, i8* %40, i64 1280
  %91 = bitcast i8* %90 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %91, align 64, !tbaa !3493
  %92 = getelementptr inbounds i8, i8* %40, i64 1536
  %93 = bitcast i8* %92 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %93, align 64, !tbaa !3493
  %94 = getelementptr inbounds i8, i8* %40, i64 1792
  %95 = bitcast i8* %94 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %95, align 64, !tbaa !3493
  %96 = or i64 %47, 2048
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %97 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %129, %for_body5.1 ]
  %98 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %123, %for_body5.1 ]
  %99 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %117, %for_body5.1 ]
  %100 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %111, %for_body5.1 ]
  %101 = add nsw i64 %96, %indvars.iv.1
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !3496
  %104 = insertelement <64 x float> undef, float %103, i32 0
  %105 = shufflevector <64 x float> %104, <64 x float> undef, <64 x i32> zeroinitializer
  %106 = shl i64 %indvars.iv.1, 6
  %107 = add nuw nsw i64 %106, %46
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to <64 x float>*
  %110 = load <64 x float>, <64 x float>* %109, align 64, !tbaa !3499
  %111 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %105, <64 x float> %110, <64 x float> %100)
  %112 = add nsw i64 %101, 512
  %113 = getelementptr inbounds float, float* %4, i64 %112
  %114 = load float, float* %113, align 4, !tbaa !3496
  %115 = insertelement <64 x float> undef, float %114, i32 0
  %116 = shufflevector <64 x float> %115, <64 x float> undef, <64 x i32> zeroinitializer
  %117 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %116, <64 x float> %110, <64 x float> %99)
  %118 = add nsw i64 %101, 1024
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = load float, float* %119, align 4, !tbaa !3496
  %121 = insertelement <64 x float> undef, float %120, i32 0
  %122 = shufflevector <64 x float> %121, <64 x float> undef, <64 x i32> zeroinitializer
  %123 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %122, <64 x float> %110, <64 x float> %98)
  %124 = add nsw i64 %101, 1536
  %125 = getelementptr inbounds float, float* %4, i64 %124
  %126 = load float, float* %125, align 4, !tbaa !3496
  %127 = insertelement <64 x float> undef, float %126, i32 0
  %128 = shufflevector <64 x float> %127, <64 x float> undef, <64 x i32> zeroinitializer
  %129 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %128, <64 x float> %110, <64 x float> %97)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %111, <64 x float>* %89, align 64, !tbaa !3493
  store <64 x float> %117, <64 x float>* %91, align 64, !tbaa !3493
  store <64 x float> %123, <64 x float>* %93, align 64, !tbaa !3493
  store <64 x float> %129, <64 x float>* %95, align 64, !tbaa !3493
  %130 = getelementptr inbounds i8, i8* %40, i64 2048
  %131 = bitcast i8* %130 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %131, align 64, !tbaa !3493
  %132 = getelementptr inbounds i8, i8* %40, i64 2304
  %133 = bitcast i8* %132 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %133, align 64, !tbaa !3493
  %134 = getelementptr inbounds i8, i8* %40, i64 2560
  %135 = bitcast i8* %134 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %135, align 64, !tbaa !3493
  %136 = getelementptr inbounds i8, i8* %40, i64 2816
  %137 = bitcast i8* %136 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %137, align 64, !tbaa !3493
  %138 = add nsw i64 %47, 4096
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %139 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %171, %for_body5.2 ]
  %140 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %165, %for_body5.2 ]
  %141 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %159, %for_body5.2 ]
  %142 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %153, %for_body5.2 ]
  %143 = add nsw i64 %138, %indvars.iv.2
  %144 = getelementptr inbounds float, float* %4, i64 %143
  %145 = load float, float* %144, align 4, !tbaa !3496
  %146 = insertelement <64 x float> undef, float %145, i32 0
  %147 = shufflevector <64 x float> %146, <64 x float> undef, <64 x i32> zeroinitializer
  %148 = shl i64 %indvars.iv.2, 6
  %149 = add nuw nsw i64 %148, %46
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <64 x float>*
  %152 = load <64 x float>, <64 x float>* %151, align 64, !tbaa !3499
  %153 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %147, <64 x float> %152, <64 x float> %142)
  %154 = add nsw i64 %143, 512
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !3496
  %157 = insertelement <64 x float> undef, float %156, i32 0
  %158 = shufflevector <64 x float> %157, <64 x float> undef, <64 x i32> zeroinitializer
  %159 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %158, <64 x float> %152, <64 x float> %141)
  %160 = add nsw i64 %143, 1024
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !3496
  %163 = insertelement <64 x float> undef, float %162, i32 0
  %164 = shufflevector <64 x float> %163, <64 x float> undef, <64 x i32> zeroinitializer
  %165 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %164, <64 x float> %152, <64 x float> %140)
  %166 = add nsw i64 %143, 1536
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !3496
  %169 = insertelement <64 x float> undef, float %168, i32 0
  %170 = shufflevector <64 x float> %169, <64 x float> undef, <64 x i32> zeroinitializer
  %171 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %170, <64 x float> %152, <64 x float> %139)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %153, <64 x float>* %131, align 64, !tbaa !3493
  store <64 x float> %159, <64 x float>* %133, align 64, !tbaa !3493
  store <64 x float> %165, <64 x float>* %135, align 64, !tbaa !3493
  store <64 x float> %171, <64 x float>* %137, align 64, !tbaa !3493
  %172 = getelementptr inbounds i8, i8* %40, i64 3072
  %173 = bitcast i8* %172 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %173, align 64, !tbaa !3493
  %174 = getelementptr inbounds i8, i8* %40, i64 3328
  %175 = bitcast i8* %174 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %175, align 64, !tbaa !3493
  %176 = getelementptr inbounds i8, i8* %40, i64 3584
  %177 = bitcast i8* %176 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %177, align 64, !tbaa !3493
  %178 = getelementptr inbounds i8, i8* %40, i64 3840
  %179 = bitcast i8* %178 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %179, align 64, !tbaa !3493
  %180 = add nsw i64 %47, 6144
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %181 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %213, %for_body5.3 ]
  %182 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %207, %for_body5.3 ]
  %183 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %201, %for_body5.3 ]
  %184 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %195, %for_body5.3 ]
  %185 = add nsw i64 %180, %indvars.iv.3
  %186 = getelementptr inbounds float, float* %4, i64 %185
  %187 = load float, float* %186, align 4, !tbaa !3496
  %188 = insertelement <64 x float> undef, float %187, i32 0
  %189 = shufflevector <64 x float> %188, <64 x float> undef, <64 x i32> zeroinitializer
  %190 = shl i64 %indvars.iv.3, 6
  %191 = add nuw nsw i64 %190, %46
  %192 = getelementptr inbounds float, float* %7, i64 %191
  %193 = bitcast float* %192 to <64 x float>*
  %194 = load <64 x float>, <64 x float>* %193, align 64, !tbaa !3499
  %195 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %189, <64 x float> %194, <64 x float> %184)
  %196 = add nsw i64 %185, 512
  %197 = getelementptr inbounds float, float* %4, i64 %196
  %198 = load float, float* %197, align 4, !tbaa !3496
  %199 = insertelement <64 x float> undef, float %198, i32 0
  %200 = shufflevector <64 x float> %199, <64 x float> undef, <64 x i32> zeroinitializer
  %201 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %200, <64 x float> %194, <64 x float> %183)
  %202 = add nsw i64 %185, 1024
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !3496
  %205 = insertelement <64 x float> undef, float %204, i32 0
  %206 = shufflevector <64 x float> %205, <64 x float> undef, <64 x i32> zeroinitializer
  %207 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %206, <64 x float> %194, <64 x float> %182)
  %208 = add nsw i64 %185, 1536
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !3496
  %211 = insertelement <64 x float> undef, float %210, i32 0
  %212 = shufflevector <64 x float> %211, <64 x float> undef, <64 x i32> zeroinitializer
  %213 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %212, <64 x float> %194, <64 x float> %181)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %195, <64 x float>* %173, align 64, !tbaa !3493
  store <64 x float> %201, <64 x float>* %175, align 64, !tbaa !3493
  store <64 x float> %207, <64 x float>* %177, align 64, !tbaa !3493
  store <64 x float> %213, <64 x float>* %179, align 64, !tbaa !3493
  %214 = getelementptr inbounds i8, i8* %40, i64 4096
  %215 = bitcast i8* %214 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %215, align 64, !tbaa !3493
  %216 = getelementptr inbounds i8, i8* %40, i64 4352
  %217 = bitcast i8* %216 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %217, align 64, !tbaa !3493
  %218 = getelementptr inbounds i8, i8* %40, i64 4608
  %219 = bitcast i8* %218 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %219, align 64, !tbaa !3493
  %220 = getelementptr inbounds i8, i8* %40, i64 4864
  %221 = bitcast i8* %220 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %221, align 64, !tbaa !3493
  %222 = add nsw i64 %47, 8192
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %223 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %255, %for_body5.4 ]
  %224 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %249, %for_body5.4 ]
  %225 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %243, %for_body5.4 ]
  %226 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %237, %for_body5.4 ]
  %227 = add nsw i64 %222, %indvars.iv.4
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = load float, float* %228, align 4, !tbaa !3496
  %230 = insertelement <64 x float> undef, float %229, i32 0
  %231 = shufflevector <64 x float> %230, <64 x float> undef, <64 x i32> zeroinitializer
  %232 = shl i64 %indvars.iv.4, 6
  %233 = add nuw nsw i64 %232, %46
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <64 x float>*
  %236 = load <64 x float>, <64 x float>* %235, align 64, !tbaa !3499
  %237 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %231, <64 x float> %236, <64 x float> %226)
  %238 = add nsw i64 %227, 512
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !3496
  %241 = insertelement <64 x float> undef, float %240, i32 0
  %242 = shufflevector <64 x float> %241, <64 x float> undef, <64 x i32> zeroinitializer
  %243 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %242, <64 x float> %236, <64 x float> %225)
  %244 = add nsw i64 %227, 1024
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !3496
  %247 = insertelement <64 x float> undef, float %246, i32 0
  %248 = shufflevector <64 x float> %247, <64 x float> undef, <64 x i32> zeroinitializer
  %249 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %248, <64 x float> %236, <64 x float> %224)
  %250 = add nsw i64 %227, 1536
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !3496
  %253 = insertelement <64 x float> undef, float %252, i32 0
  %254 = shufflevector <64 x float> %253, <64 x float> undef, <64 x i32> zeroinitializer
  %255 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %254, <64 x float> %236, <64 x float> %223)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 256
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %237, <64 x float>* %215, align 64, !tbaa !3493
  store <64 x float> %243, <64 x float>* %217, align 64, !tbaa !3493
  store <64 x float> %249, <64 x float>* %219, align 64, !tbaa !3493
  store <64 x float> %255, <64 x float>* %221, align 64, !tbaa !3493
  %256 = getelementptr inbounds i8, i8* %40, i64 5120
  %257 = bitcast i8* %256 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %257, align 64, !tbaa !3493
  %258 = getelementptr inbounds i8, i8* %40, i64 5376
  %259 = bitcast i8* %258 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %259, align 64, !tbaa !3493
  %260 = getelementptr inbounds i8, i8* %40, i64 5632
  %261 = bitcast i8* %260 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %261, align 64, !tbaa !3493
  %262 = getelementptr inbounds i8, i8* %40, i64 5888
  %263 = bitcast i8* %262 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %263, align 64, !tbaa !3493
  %264 = add nsw i64 %47, 10240
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %265 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %297, %for_body5.5 ]
  %266 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %291, %for_body5.5 ]
  %267 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %285, %for_body5.5 ]
  %268 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %279, %for_body5.5 ]
  %269 = add nsw i64 %264, %indvars.iv.5
  %270 = getelementptr inbounds float, float* %4, i64 %269
  %271 = load float, float* %270, align 4, !tbaa !3496
  %272 = insertelement <64 x float> undef, float %271, i32 0
  %273 = shufflevector <64 x float> %272, <64 x float> undef, <64 x i32> zeroinitializer
  %274 = shl i64 %indvars.iv.5, 6
  %275 = add nuw nsw i64 %274, %46
  %276 = getelementptr inbounds float, float* %7, i64 %275
  %277 = bitcast float* %276 to <64 x float>*
  %278 = load <64 x float>, <64 x float>* %277, align 64, !tbaa !3499
  %279 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %273, <64 x float> %278, <64 x float> %268)
  %280 = add nsw i64 %269, 512
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !3496
  %283 = insertelement <64 x float> undef, float %282, i32 0
  %284 = shufflevector <64 x float> %283, <64 x float> undef, <64 x i32> zeroinitializer
  %285 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %284, <64 x float> %278, <64 x float> %267)
  %286 = add nsw i64 %269, 1024
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !3496
  %289 = insertelement <64 x float> undef, float %288, i32 0
  %290 = shufflevector <64 x float> %289, <64 x float> undef, <64 x i32> zeroinitializer
  %291 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %290, <64 x float> %278, <64 x float> %266)
  %292 = add nsw i64 %269, 1536
  %293 = getelementptr inbounds float, float* %4, i64 %292
  %294 = load float, float* %293, align 4, !tbaa !3496
  %295 = insertelement <64 x float> undef, float %294, i32 0
  %296 = shufflevector <64 x float> %295, <64 x float> undef, <64 x i32> zeroinitializer
  %297 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %296, <64 x float> %278, <64 x float> %265)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 256
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %279, <64 x float>* %257, align 64, !tbaa !3493
  store <64 x float> %285, <64 x float>* %259, align 64, !tbaa !3493
  store <64 x float> %291, <64 x float>* %261, align 64, !tbaa !3493
  store <64 x float> %297, <64 x float>* %263, align 64, !tbaa !3493
  %298 = getelementptr inbounds i8, i8* %40, i64 6144
  %299 = bitcast i8* %298 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %299, align 64, !tbaa !3493
  %300 = getelementptr inbounds i8, i8* %40, i64 6400
  %301 = bitcast i8* %300 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %301, align 64, !tbaa !3493
  %302 = getelementptr inbounds i8, i8* %40, i64 6656
  %303 = bitcast i8* %302 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %303, align 64, !tbaa !3493
  %304 = getelementptr inbounds i8, i8* %40, i64 6912
  %305 = bitcast i8* %304 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %305, align 64, !tbaa !3493
  %306 = add nsw i64 %47, 12288
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %307 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %339, %for_body5.6 ]
  %308 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %333, %for_body5.6 ]
  %309 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %327, %for_body5.6 ]
  %310 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %321, %for_body5.6 ]
  %311 = add nsw i64 %306, %indvars.iv.6
  %312 = getelementptr inbounds float, float* %4, i64 %311
  %313 = load float, float* %312, align 4, !tbaa !3496
  %314 = insertelement <64 x float> undef, float %313, i32 0
  %315 = shufflevector <64 x float> %314, <64 x float> undef, <64 x i32> zeroinitializer
  %316 = shl i64 %indvars.iv.6, 6
  %317 = add nuw nsw i64 %316, %46
  %318 = getelementptr inbounds float, float* %7, i64 %317
  %319 = bitcast float* %318 to <64 x float>*
  %320 = load <64 x float>, <64 x float>* %319, align 64, !tbaa !3499
  %321 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %315, <64 x float> %320, <64 x float> %310)
  %322 = add nsw i64 %311, 512
  %323 = getelementptr inbounds float, float* %4, i64 %322
  %324 = load float, float* %323, align 4, !tbaa !3496
  %325 = insertelement <64 x float> undef, float %324, i32 0
  %326 = shufflevector <64 x float> %325, <64 x float> undef, <64 x i32> zeroinitializer
  %327 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %326, <64 x float> %320, <64 x float> %309)
  %328 = add nsw i64 %311, 1024
  %329 = getelementptr inbounds float, float* %4, i64 %328
  %330 = load float, float* %329, align 4, !tbaa !3496
  %331 = insertelement <64 x float> undef, float %330, i32 0
  %332 = shufflevector <64 x float> %331, <64 x float> undef, <64 x i32> zeroinitializer
  %333 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %332, <64 x float> %320, <64 x float> %308)
  %334 = add nsw i64 %311, 1536
  %335 = getelementptr inbounds float, float* %4, i64 %334
  %336 = load float, float* %335, align 4, !tbaa !3496
  %337 = insertelement <64 x float> undef, float %336, i32 0
  %338 = shufflevector <64 x float> %337, <64 x float> undef, <64 x i32> zeroinitializer
  %339 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %338, <64 x float> %320, <64 x float> %307)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 256
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %321, <64 x float>* %299, align 64, !tbaa !3493
  store <64 x float> %327, <64 x float>* %301, align 64, !tbaa !3493
  store <64 x float> %333, <64 x float>* %303, align 64, !tbaa !3493
  store <64 x float> %339, <64 x float>* %305, align 64, !tbaa !3493
  %340 = mul nsw i64 %indvars.iv36, 1792
  %341 = shl nsw i32 %44, 6
  %342 = sext i32 %341 to i64
  %343 = getelementptr inbounds float, float* %13, i64 %342
  %344 = bitcast float* %343 to <64 x float>*
  %345 = load <64 x float>, <64 x float>* %344, align 64, !tbaa !3502
  %346 = getelementptr inbounds float, float* %16, i64 %342
  %347 = bitcast float* %346 to <64 x float>*
  %348 = load <64 x float>, <64 x float>* %347, align 64, !tbaa !3505
  %349 = getelementptr inbounds float, float* %19, i64 %342
  %350 = bitcast float* %349 to <64 x float>*
  %351 = load <64 x float>, <64 x float>* %350, align 64, !tbaa !3508
  %352 = bitcast i8* %40 to <64 x float>*
  %353 = load <64 x float>, <64 x float>* %352, align 64, !tbaa !3493
  %354 = fadd <64 x float> %345, %353
  %355 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %354, <64 x float> %348, <64 x float> %351)
  %356 = getelementptr inbounds float, float* %10, i64 %340
  %357 = bitcast float* %356 to <64 x float>*
  store <64 x float> %355, <64 x float>* %357, align 64, !tbaa !3511
  %358 = getelementptr inbounds i8, i8* %40, i64 256
  %359 = bitcast i8* %358 to <64 x float>*
  %360 = load <64 x float>, <64 x float>* %359, align 64, !tbaa !3493
  %361 = fadd <64 x float> %345, %360
  %362 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %361, <64 x float> %348, <64 x float> %351)
  %363 = mul i64 %indvars.iv36, 7696581394432
  %sext = ashr exact i64 %363, 32
  %364 = or i64 %sext, 64
  %365 = getelementptr inbounds float, float* %10, i64 %364
  %366 = bitcast float* %365 to <64 x float>*
  store <64 x float> %362, <64 x float>* %366, align 64, !tbaa !3511
  %367 = getelementptr inbounds i8, i8* %40, i64 512
  %368 = bitcast i8* %367 to <64 x float>*
  %369 = load <64 x float>, <64 x float>* %368, align 64, !tbaa !3493
  %370 = fadd <64 x float> %345, %369
  %371 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %370, <64 x float> %348, <64 x float> %351)
  %372 = mul i64 %indvars.iv36, 7696581394432
  %sext38 = ashr exact i64 %372, 32
  %373 = or i64 %sext38, 128
  %374 = getelementptr inbounds float, float* %10, i64 %373
  %375 = bitcast float* %374 to <64 x float>*
  store <64 x float> %371, <64 x float>* %375, align 64, !tbaa !3511
  %376 = getelementptr inbounds i8, i8* %40, i64 768
  %377 = bitcast i8* %376 to <64 x float>*
  %378 = load <64 x float>, <64 x float>* %377, align 64, !tbaa !3493
  %379 = fadd <64 x float> %345, %378
  %380 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %379, <64 x float> %348, <64 x float> %351)
  %381 = mul i64 %indvars.iv36, 7696581394432
  %sext39 = ashr exact i64 %381, 32
  %382 = or i64 %sext39, 192
  %383 = getelementptr inbounds float, float* %10, i64 %382
  %384 = bitcast float* %383 to <64 x float>*
  store <64 x float> %380, <64 x float>* %384, align 64, !tbaa !3511
  %385 = getelementptr inbounds i8, i8* %40, i64 1024
  %386 = bitcast i8* %385 to <64 x float>*
  %387 = load <64 x float>, <64 x float>* %386, align 64, !tbaa !3493
  %388 = fadd <64 x float> %345, %387
  %389 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %388, <64 x float> %348, <64 x float> %351)
  %390 = mul i64 %indvars.iv36, 7696581394432
  %sext40 = add i64 %390, 1099511627776
  %391 = ashr exact i64 %sext40, 32
  %392 = getelementptr inbounds float, float* %10, i64 %391
  %393 = bitcast float* %392 to <64 x float>*
  store <64 x float> %389, <64 x float>* %393, align 64, !tbaa !3511
  %394 = getelementptr inbounds i8, i8* %40, i64 1280
  %395 = bitcast i8* %394 to <64 x float>*
  %396 = load <64 x float>, <64 x float>* %395, align 64, !tbaa !3493
  %397 = fadd <64 x float> %345, %396
  %398 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %397, <64 x float> %348, <64 x float> %351)
  %399 = mul i64 %indvars.iv36, 7696581394432
  %sext41 = add i64 %399, 1374389534720
  %400 = ashr exact i64 %sext41, 32
  %401 = getelementptr inbounds float, float* %10, i64 %400
  %402 = bitcast float* %401 to <64 x float>*
  store <64 x float> %398, <64 x float>* %402, align 64, !tbaa !3511
  %403 = getelementptr inbounds i8, i8* %40, i64 1536
  %404 = bitcast i8* %403 to <64 x float>*
  %405 = load <64 x float>, <64 x float>* %404, align 64, !tbaa !3493
  %406 = fadd <64 x float> %345, %405
  %407 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %406, <64 x float> %348, <64 x float> %351)
  %408 = mul i64 %indvars.iv36, 7696581394432
  %sext42 = add i64 %408, 1649267441664
  %409 = ashr exact i64 %sext42, 32
  %410 = getelementptr inbounds float, float* %10, i64 %409
  %411 = bitcast float* %410 to <64 x float>*
  store <64 x float> %407, <64 x float>* %411, align 64, !tbaa !3511
  %412 = getelementptr inbounds i8, i8* %40, i64 1792
  %413 = bitcast i8* %412 to <64 x float>*
  %414 = load <64 x float>, <64 x float>* %413, align 64, !tbaa !3493
  %415 = fadd <64 x float> %345, %414
  %416 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %415, <64 x float> %348, <64 x float> %351)
  %417 = mul i64 %indvars.iv36, 7696581394432
  %sext43 = add i64 %417, 1924145348608
  %418 = ashr exact i64 %sext43, 32
  %419 = getelementptr inbounds float, float* %10, i64 %418
  %420 = bitcast float* %419 to <64 x float>*
  store <64 x float> %416, <64 x float>* %420, align 64, !tbaa !3511
  %421 = getelementptr inbounds i8, i8* %40, i64 2048
  %422 = bitcast i8* %421 to <64 x float>*
  %423 = load <64 x float>, <64 x float>* %422, align 64, !tbaa !3493
  %424 = fadd <64 x float> %345, %423
  %425 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %424, <64 x float> %348, <64 x float> %351)
  %426 = mul i64 %indvars.iv36, 7696581394432
  %sext44 = add i64 %426, 2199023255552
  %427 = ashr exact i64 %sext44, 32
  %428 = getelementptr inbounds float, float* %10, i64 %427
  %429 = bitcast float* %428 to <64 x float>*
  store <64 x float> %425, <64 x float>* %429, align 64, !tbaa !3511
  %430 = getelementptr inbounds i8, i8* %40, i64 2304
  %431 = bitcast i8* %430 to <64 x float>*
  %432 = load <64 x float>, <64 x float>* %431, align 64, !tbaa !3493
  %433 = fadd <64 x float> %345, %432
  %434 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %433, <64 x float> %348, <64 x float> %351)
  %435 = mul i64 %indvars.iv36, 7696581394432
  %sext45 = add i64 %435, 2473901162496
  %436 = ashr exact i64 %sext45, 32
  %437 = getelementptr inbounds float, float* %10, i64 %436
  %438 = bitcast float* %437 to <64 x float>*
  store <64 x float> %434, <64 x float>* %438, align 64, !tbaa !3511
  %439 = getelementptr inbounds i8, i8* %40, i64 2560
  %440 = bitcast i8* %439 to <64 x float>*
  %441 = load <64 x float>, <64 x float>* %440, align 64, !tbaa !3493
  %442 = fadd <64 x float> %345, %441
  %443 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %442, <64 x float> %348, <64 x float> %351)
  %444 = mul i64 %indvars.iv36, 7696581394432
  %sext46 = add i64 %444, 2748779069440
  %445 = ashr exact i64 %sext46, 32
  %446 = getelementptr inbounds float, float* %10, i64 %445
  %447 = bitcast float* %446 to <64 x float>*
  store <64 x float> %443, <64 x float>* %447, align 64, !tbaa !3511
  %448 = getelementptr inbounds i8, i8* %40, i64 2816
  %449 = bitcast i8* %448 to <64 x float>*
  %450 = load <64 x float>, <64 x float>* %449, align 64, !tbaa !3493
  %451 = fadd <64 x float> %345, %450
  %452 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %451, <64 x float> %348, <64 x float> %351)
  %453 = mul i64 %indvars.iv36, 7696581394432
  %sext47 = add i64 %453, 3023656976384
  %454 = ashr exact i64 %sext47, 32
  %455 = getelementptr inbounds float, float* %10, i64 %454
  %456 = bitcast float* %455 to <64 x float>*
  store <64 x float> %452, <64 x float>* %456, align 64, !tbaa !3511
  %457 = getelementptr inbounds i8, i8* %40, i64 3072
  %458 = bitcast i8* %457 to <64 x float>*
  %459 = load <64 x float>, <64 x float>* %458, align 64, !tbaa !3493
  %460 = fadd <64 x float> %345, %459
  %461 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %460, <64 x float> %348, <64 x float> %351)
  %462 = mul i64 %indvars.iv36, 7696581394432
  %sext48 = add i64 %462, 3298534883328
  %463 = ashr exact i64 %sext48, 32
  %464 = getelementptr inbounds float, float* %10, i64 %463
  %465 = bitcast float* %464 to <64 x float>*
  store <64 x float> %461, <64 x float>* %465, align 64, !tbaa !3511
  %466 = getelementptr inbounds i8, i8* %40, i64 3328
  %467 = bitcast i8* %466 to <64 x float>*
  %468 = load <64 x float>, <64 x float>* %467, align 64, !tbaa !3493
  %469 = fadd <64 x float> %345, %468
  %470 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %469, <64 x float> %348, <64 x float> %351)
  %471 = mul i64 %indvars.iv36, 7696581394432
  %sext49 = add i64 %471, 3573412790272
  %472 = ashr exact i64 %sext49, 32
  %473 = getelementptr inbounds float, float* %10, i64 %472
  %474 = bitcast float* %473 to <64 x float>*
  store <64 x float> %470, <64 x float>* %474, align 64, !tbaa !3511
  %475 = getelementptr inbounds i8, i8* %40, i64 3584
  %476 = bitcast i8* %475 to <64 x float>*
  %477 = load <64 x float>, <64 x float>* %476, align 64, !tbaa !3493
  %478 = fadd <64 x float> %345, %477
  %479 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %478, <64 x float> %348, <64 x float> %351)
  %480 = mul i64 %indvars.iv36, 7696581394432
  %sext50 = add i64 %480, 3848290697216
  %481 = ashr exact i64 %sext50, 32
  %482 = getelementptr inbounds float, float* %10, i64 %481
  %483 = bitcast float* %482 to <64 x float>*
  store <64 x float> %479, <64 x float>* %483, align 64, !tbaa !3511
  %484 = getelementptr inbounds i8, i8* %40, i64 3840
  %485 = bitcast i8* %484 to <64 x float>*
  %486 = load <64 x float>, <64 x float>* %485, align 64, !tbaa !3493
  %487 = fadd <64 x float> %345, %486
  %488 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %487, <64 x float> %348, <64 x float> %351)
  %489 = mul i64 %indvars.iv36, 7696581394432
  %sext51 = add i64 %489, 4123168604160
  %490 = ashr exact i64 %sext51, 32
  %491 = getelementptr inbounds float, float* %10, i64 %490
  %492 = bitcast float* %491 to <64 x float>*
  store <64 x float> %488, <64 x float>* %492, align 64, !tbaa !3511
  %493 = getelementptr inbounds i8, i8* %40, i64 4096
  %494 = bitcast i8* %493 to <64 x float>*
  %495 = load <64 x float>, <64 x float>* %494, align 64, !tbaa !3493
  %496 = fadd <64 x float> %345, %495
  %497 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %496, <64 x float> %348, <64 x float> %351)
  %498 = mul i64 %indvars.iv36, 7696581394432
  %sext52 = add i64 %498, 4398046511104
  %499 = ashr exact i64 %sext52, 32
  %500 = getelementptr inbounds float, float* %10, i64 %499
  %501 = bitcast float* %500 to <64 x float>*
  store <64 x float> %497, <64 x float>* %501, align 64, !tbaa !3511
  %502 = getelementptr inbounds i8, i8* %40, i64 4352
  %503 = bitcast i8* %502 to <64 x float>*
  %504 = load <64 x float>, <64 x float>* %503, align 64, !tbaa !3493
  %505 = fadd <64 x float> %345, %504
  %506 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %505, <64 x float> %348, <64 x float> %351)
  %507 = mul i64 %indvars.iv36, 7696581394432
  %sext53 = add i64 %507, 4672924418048
  %508 = ashr exact i64 %sext53, 32
  %509 = getelementptr inbounds float, float* %10, i64 %508
  %510 = bitcast float* %509 to <64 x float>*
  store <64 x float> %506, <64 x float>* %510, align 64, !tbaa !3511
  %511 = getelementptr inbounds i8, i8* %40, i64 4608
  %512 = bitcast i8* %511 to <64 x float>*
  %513 = load <64 x float>, <64 x float>* %512, align 64, !tbaa !3493
  %514 = fadd <64 x float> %345, %513
  %515 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %514, <64 x float> %348, <64 x float> %351)
  %516 = mul i64 %indvars.iv36, 7696581394432
  %sext54 = add i64 %516, 4947802324992
  %517 = ashr exact i64 %sext54, 32
  %518 = getelementptr inbounds float, float* %10, i64 %517
  %519 = bitcast float* %518 to <64 x float>*
  store <64 x float> %515, <64 x float>* %519, align 64, !tbaa !3511
  %520 = getelementptr inbounds i8, i8* %40, i64 4864
  %521 = bitcast i8* %520 to <64 x float>*
  %522 = load <64 x float>, <64 x float>* %521, align 64, !tbaa !3493
  %523 = fadd <64 x float> %345, %522
  %524 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %523, <64 x float> %348, <64 x float> %351)
  %525 = mul i64 %indvars.iv36, 7696581394432
  %sext55 = add i64 %525, 5222680231936
  %526 = ashr exact i64 %sext55, 32
  %527 = getelementptr inbounds float, float* %10, i64 %526
  %528 = bitcast float* %527 to <64 x float>*
  store <64 x float> %524, <64 x float>* %528, align 64, !tbaa !3511
  %529 = getelementptr inbounds i8, i8* %40, i64 5120
  %530 = bitcast i8* %529 to <64 x float>*
  %531 = load <64 x float>, <64 x float>* %530, align 64, !tbaa !3493
  %532 = fadd <64 x float> %345, %531
  %533 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %532, <64 x float> %348, <64 x float> %351)
  %534 = mul i64 %indvars.iv36, 7696581394432
  %sext56 = add i64 %534, 5497558138880
  %535 = ashr exact i64 %sext56, 32
  %536 = getelementptr inbounds float, float* %10, i64 %535
  %537 = bitcast float* %536 to <64 x float>*
  store <64 x float> %533, <64 x float>* %537, align 64, !tbaa !3511
  %538 = getelementptr inbounds i8, i8* %40, i64 5376
  %539 = bitcast i8* %538 to <64 x float>*
  %540 = load <64 x float>, <64 x float>* %539, align 64, !tbaa !3493
  %541 = fadd <64 x float> %345, %540
  %542 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %541, <64 x float> %348, <64 x float> %351)
  %543 = mul i64 %indvars.iv36, 7696581394432
  %sext57 = add i64 %543, 5772436045824
  %544 = ashr exact i64 %sext57, 32
  %545 = getelementptr inbounds float, float* %10, i64 %544
  %546 = bitcast float* %545 to <64 x float>*
  store <64 x float> %542, <64 x float>* %546, align 64, !tbaa !3511
  %547 = getelementptr inbounds i8, i8* %40, i64 5632
  %548 = bitcast i8* %547 to <64 x float>*
  %549 = load <64 x float>, <64 x float>* %548, align 64, !tbaa !3493
  %550 = fadd <64 x float> %345, %549
  %551 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %550, <64 x float> %348, <64 x float> %351)
  %552 = mul i64 %indvars.iv36, 7696581394432
  %sext58 = add i64 %552, 6047313952768
  %553 = ashr exact i64 %sext58, 32
  %554 = getelementptr inbounds float, float* %10, i64 %553
  %555 = bitcast float* %554 to <64 x float>*
  store <64 x float> %551, <64 x float>* %555, align 64, !tbaa !3511
  %556 = getelementptr inbounds i8, i8* %40, i64 5888
  %557 = bitcast i8* %556 to <64 x float>*
  %558 = load <64 x float>, <64 x float>* %557, align 64, !tbaa !3493
  %559 = fadd <64 x float> %345, %558
  %560 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %559, <64 x float> %348, <64 x float> %351)
  %561 = mul i64 %indvars.iv36, 7696581394432
  %sext59 = add i64 %561, 6322191859712
  %562 = ashr exact i64 %sext59, 32
  %563 = getelementptr inbounds float, float* %10, i64 %562
  %564 = bitcast float* %563 to <64 x float>*
  store <64 x float> %560, <64 x float>* %564, align 64, !tbaa !3511
  %565 = getelementptr inbounds i8, i8* %40, i64 6144
  %566 = bitcast i8* %565 to <64 x float>*
  %567 = load <64 x float>, <64 x float>* %566, align 64, !tbaa !3493
  %568 = fadd <64 x float> %345, %567
  %569 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %568, <64 x float> %348, <64 x float> %351)
  %570 = mul i64 %indvars.iv36, 7696581394432
  %sext60 = add i64 %570, 6597069766656
  %571 = ashr exact i64 %sext60, 32
  %572 = getelementptr inbounds float, float* %10, i64 %571
  %573 = bitcast float* %572 to <64 x float>*
  store <64 x float> %569, <64 x float>* %573, align 64, !tbaa !3511
  %574 = getelementptr inbounds i8, i8* %40, i64 6400
  %575 = bitcast i8* %574 to <64 x float>*
  %576 = load <64 x float>, <64 x float>* %575, align 64, !tbaa !3493
  %577 = fadd <64 x float> %345, %576
  %578 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %577, <64 x float> %348, <64 x float> %351)
  %579 = mul i64 %indvars.iv36, 7696581394432
  %sext61 = add i64 %579, 6871947673600
  %580 = ashr exact i64 %sext61, 32
  %581 = getelementptr inbounds float, float* %10, i64 %580
  %582 = bitcast float* %581 to <64 x float>*
  store <64 x float> %578, <64 x float>* %582, align 64, !tbaa !3511
  %583 = getelementptr inbounds i8, i8* %40, i64 6656
  %584 = bitcast i8* %583 to <64 x float>*
  %585 = load <64 x float>, <64 x float>* %584, align 64, !tbaa !3493
  %586 = fadd <64 x float> %345, %585
  %587 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %586, <64 x float> %348, <64 x float> %351)
  %588 = mul i64 %indvars.iv36, 7696581394432
  %sext62 = add i64 %588, 7146825580544
  %589 = ashr exact i64 %sext62, 32
  %590 = getelementptr inbounds float, float* %10, i64 %589
  %591 = bitcast float* %590 to <64 x float>*
  store <64 x float> %587, <64 x float>* %591, align 64, !tbaa !3511
  %592 = getelementptr inbounds i8, i8* %40, i64 6912
  %593 = bitcast i8* %592 to <64 x float>*
  %594 = load <64 x float>, <64 x float>* %593, align 64, !tbaa !3493
  %595 = fadd <64 x float> %345, %594
  %596 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %595, <64 x float> %348, <64 x float> %351)
  %597 = mul i64 %indvars.iv36, 7696581394432
  %sext63 = add i64 %597, 7421703487488
  %598 = ashr exact i64 %sext63, 32
  %599 = getelementptr inbounds float, float* %10, i64 %598
  %600 = bitcast float* %599 to <64 x float>*
  store <64 x float> %596, <64 x float>* %600, align 64, !tbaa !3511
  %601 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %602 = tail call i32 %601(i32 1, i32 %22, i8* nonnull %40)
  %indvars.iv.next37 = add nsw i64 %indvars.iv36, 1
  %603 = icmp slt i64 %indvars.iv.next37, %38
  br i1 %603, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 7
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([111 x i8], [111 x i8]* @.str.298, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !3514
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !3528
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !3531
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !3533
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !3537
  %36 = getelementptr inbounds i8, i8* %0, i64 48
  %37 = bitcast i8* %36 to %1**
  %38 = load %1*, %1** %37, align 8
  %39 = getelementptr inbounds i8, i8* %1, i64 24
  %40 = bitcast i8* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !3539
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %49 = load i32, i32* %48, align 4
  %50 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %51 = load i32, i32* %50, align 4
  %52 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  %76 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %77 = load i8*, i8** %76, align 8
  %78 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %79 = load i64*, i64** %78, align 8
  %80 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %81 = load i64*, i64** %80, align 8
  %82 = getelementptr inbounds %1, %1* %38, i64 0, i32 0
  %83 = load i8*, i8** %82, align 8
  %84 = getelementptr inbounds %1, %1* %38, i64 0, i32 4
  %85 = load i64*, i64** %84, align 8
  %86 = getelementptr inbounds %1, %1* %38, i64 0, i32 5
  %87 = load i64*, i64** %86, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %88 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %88(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.299, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %89 = getelementptr inbounds i8, i8* %1, i64 4
  %90 = bitcast i8* %89 to i32*
  %91 = load i32, i32* %90, align 4, !tbaa !3542
  switch i32 %91, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.300, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.301, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.302, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.303, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.304, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  switch i32 %41, label %assert_fail13 [
    i32 13, label %assert_end14
    i32 7, label %assert_end14
    i32 4, label %assert_end14
    i32 3, label %assert_end14
  ]

assert_fail13:                                    ; preds = %assert_end12
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.305, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12, %assert_end12, %assert_end12, %assert_end12
  %98 = icmp eq i32 %49, 1
  br i1 %98, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %99 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %99(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %100 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %101 = load i32, i32* %100, align 4
  %102 = icmp eq i32 %101, 5
  br i1 %102, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %104 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %105 = load i16, i16* %104, align 2
  %106 = icmp eq i16 %105, 1
  %107 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %108 = load i8, i8* %107, align 1
  %109 = icmp eq i8 %108, 32
  %110 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %111 = load i8, i8* %110, align 1
  %112 = icmp eq i8 %111, 2
  %113 = and i1 %109, %112
  %114 = and i1 %106, %113
  br i1 %114, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %116 = load i64, i64* %45, align 8, !tbaa !3544
  %117 = trunc i64 %116 to i32
  %118 = icmp eq i32 %117, 1
  br i1 %118, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %119 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %119(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %120 = getelementptr inbounds i64, i64* %45, i64 1
  %121 = load i64, i64* %120, align 8, !tbaa !3558
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %122, 128
  br i1 %123, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %124 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %124(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.306, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %125 = getelementptr inbounds i64, i64* %45, i64 2
  %126 = load i64, i64* %125, align 8, !tbaa !3560
  %127 = trunc i64 %126 to i32
  %128 = icmp eq i32 %127, 7
  br i1 %128, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %130 = getelementptr inbounds i64, i64* %45, i64 3
  %131 = load i64, i64* %130, align 8, !tbaa !3563
  %132 = trunc i64 %131 to i32
  %133 = icmp eq i32 %132, 7
  br i1 %133, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %135 = getelementptr inbounds i64, i64* %45, i64 4
  %136 = load i64, i64* %135, align 8, !tbaa !3565
  %137 = trunc i64 %136 to i32
  %138 = icmp eq i32 %137, 4
  br i1 %138, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %139 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %139(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %140 = icmp eq i64* %47, null
  br i1 %140, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end30
  %141 = bitcast i64* %47 to <4 x i64>*
  %142 = load <4 x i64>, <4 x i64>* %141, align 8, !tbaa !3569
  %143 = trunc <4 x i64> %142 to <4 x i32>
  %144 = icmp eq <4 x i32> %143, <i32 25088, i32 196, i32 28, i32 4>
  %145 = getelementptr inbounds i64, i64* %47, i64 4
  %146 = load i64, i64* %145, align 8, !tbaa !3581
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 1
  %rdx.shuf197 = shufflevector <4 x i1> %144, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx198 = and <4 x i1> %144, %rdx.shuf197
  %rdx.shuf199 = shufflevector <4 x i1> %bin.rdx198, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx200 = and <4 x i1> %bin.rdx198, %rdx.shuf199
  %149 = extractelement <4 x i1> %bin.rdx200, i32 0
  %150 = and i1 %149, %148
  br i1 %150, label %if_end, label %assert_fail31, !prof !5

if_end:                                           ; preds = %assert_end30, %if_then
  %151 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %152 = load i64, i64* %151, align 8
  %153 = icmp eq i64 %152, 0
  br i1 %153, label %assert_end34, label %assert_fail33, !prof !5

assert_fail31:                                    ; preds = %if_then
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([234 x i8], [234 x i8]* @.str.307, i64 0, i64 0))
  ret i32 -1

assert_fail33:                                    ; preds = %if_end
  %155 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %155(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %if_end
  %156 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %157 = load i32, i32* %156, align 4
  %158 = icmp eq i32 %157, 6
  br i1 %158, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %160 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %161 = load i16, i16* %160, align 2
  %162 = icmp eq i16 %161, 1
  %163 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %164 = load i8, i8* %163, align 1
  %165 = icmp eq i8 %164, 32
  %166 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %167 = load i8, i8* %166, align 1
  %168 = icmp eq i8 %167, 2
  %169 = and i1 %165, %168
  %170 = and i1 %162, %169
  br i1 %170, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %172 = load i64, i64* %55, align 8, !tbaa !3585
  %173 = trunc i64 %172 to i32
  %174 = icmp eq i32 %173, 64
  br i1 %174, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %175 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %175(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %176 = getelementptr inbounds i64, i64* %55, i64 1
  %177 = load i64, i64* %176, align 8, !tbaa !3599
  %178 = trunc i64 %177 to i32
  %179 = icmp eq i32 %178, 128
  br i1 %179, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %180 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %180(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.308, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %181 = getelementptr inbounds i64, i64* %55, i64 2
  %182 = load i64, i64* %181, align 8, !tbaa !3601
  %183 = trunc i64 %182 to i32
  %184 = icmp eq i32 %183, 1
  br i1 %184, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %185 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %185(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %186 = getelementptr inbounds i64, i64* %55, i64 3
  %187 = load i64, i64* %186, align 8, !tbaa !3604
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  br i1 %189, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %190 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %190(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %191 = getelementptr inbounds i64, i64* %55, i64 4
  %192 = load i64, i64* %191, align 8, !tbaa !3606
  %193 = trunc i64 %192 to i32
  %194 = icmp eq i32 %193, 4
  br i1 %194, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %196 = getelementptr inbounds i64, i64* %55, i64 5
  %197 = load i64, i64* %196, align 8, !tbaa !3610
  %198 = trunc i64 %197 to i32
  %199 = icmp eq i32 %198, 32
  br i1 %199, label %assert_end50, label %assert_fail49, !prof !5

assert_fail49:                                    ; preds = %assert_end48
  %200 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %200(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %assert_end48
  %201 = icmp eq i64* %57, null
  br i1 %201, label %if_end52, label %if_then51, !prof !50

if_then51:                                        ; preds = %assert_end50
  %202 = bitcast i64* %57 to <4 x i64>*
  %203 = load <4 x i64>, <4 x i64>* %202, align 8, !tbaa !3612
  %204 = trunc <4 x i64> %203 to <4 x i32>
  %205 = icmp eq <4 x i32> %204, <i32 16384, i32 128, i32 128, i32 128>
  %206 = getelementptr inbounds i64, i64* %57, i64 4
  %207 = load i64, i64* %206, align 8, !tbaa !3624
  %208 = trunc i64 %207 to i32
  %209 = icmp eq i32 %208, 32
  %210 = getelementptr inbounds i64, i64* %57, i64 5
  %211 = load i64, i64* %210, align 8, !tbaa !3628
  %212 = trunc i64 %211 to i32
  %213 = icmp eq i32 %212, 1
  %rdx.shuf193 = shufflevector <4 x i1> %205, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx194 = and <4 x i1> %205, %rdx.shuf193
  %rdx.shuf195 = shufflevector <4 x i1> %bin.rdx194, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx196 = and <4 x i1> %bin.rdx194, %rdx.shuf195
  %214 = extractelement <4 x i1> %bin.rdx196, i32 0
  %215 = and i1 %214, %209
  %216 = and i1 %215, %213
  br i1 %216, label %if_end52, label %assert_fail53, !prof !5

if_end52:                                         ; preds = %assert_end50, %if_then51
  %217 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %218 = load i64, i64* %217, align 8
  %219 = icmp eq i64 %218, 0
  br i1 %219, label %assert_end56, label %assert_fail55, !prof !5

assert_fail53:                                    ; preds = %if_then51
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([273 x i8], [273 x i8]* @.str.309, i64 0, i64 0))
  ret i32 -1

assert_fail55:                                    ; preds = %if_end52
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %if_end52
  %222 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %223 = load i32, i32* %222, align 4
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %226 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %227 = load i32, i32* %226, align 4
  %228 = icmp eq i32 %51, %227
  br i1 %228, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %229 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %229(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %230 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %231 = load i32, i32* %230, align 4
  %232 = icmp eq i32 %231, 4
  br i1 %232, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %234 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %235 = load i16, i16* %234, align 2
  %236 = icmp eq i16 %235, 1
  %237 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %238 = load i8, i8* %237, align 1
  %239 = icmp eq i8 %238, 32
  %240 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %241 = load i8, i8* %240, align 1
  %242 = icmp eq i8 %241, 2
  %243 = and i1 %239, %242
  %244 = and i1 %236, %243
  br i1 %244, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %246 = load i64, i64* %61, align 8, !tbaa !3630
  %247 = trunc i64 %246 to i32
  %248 = icmp eq i32 %247, 64
  br i1 %248, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.161, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %250 = getelementptr inbounds i64, i64* %61, i64 1
  %251 = load i64, i64* %250, align 8, !tbaa !3644
  %252 = trunc i64 %251 to i32
  %253 = icmp eq i32 %252, 1
  br i1 %253, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %254 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %254(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %255 = getelementptr inbounds i64, i64* %61, i64 2
  %256 = load i64, i64* %255, align 8, !tbaa !3646
  %257 = trunc i64 %256 to i32
  %258 = icmp eq i32 %257, 1
  br i1 %258, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %259 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %259(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %260 = getelementptr inbounds i64, i64* %61, i64 3
  %261 = load i64, i64* %260, align 8, !tbaa !3649
  %262 = trunc i64 %261 to i32
  %263 = icmp eq i32 %262, 32
  br i1 %263, label %assert_end72, label %assert_fail71, !prof !5

assert_fail71:                                    ; preds = %assert_end70
  %264 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %264(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end72:                                     ; preds = %assert_end70
  %265 = icmp eq i64* %63, null
  br i1 %265, label %if_end74, label %if_then73, !prof !50

if_then73:                                        ; preds = %assert_end72
  %266 = bitcast i64* %63 to <4 x i64>*
  %267 = load <4 x i64>, <4 x i64>* %266, align 8, !tbaa !3651
  %268 = trunc <4 x i64> %267 to <4 x i32>
  %269 = icmp eq <4 x i32> %268, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf189 = shufflevector <4 x i1> %269, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx190 = and <4 x i1> %269, %rdx.shuf189
  %rdx.shuf191 = shufflevector <4 x i1> %bin.rdx190, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx192 = and <4 x i1> %bin.rdx190, %rdx.shuf191
  %270 = extractelement <4 x i1> %bin.rdx192, i32 0
  br i1 %270, label %if_end74, label %assert_fail75, !prof !5

if_end74:                                         ; preds = %assert_end72, %if_then73
  %271 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %272 = load i64, i64* %271, align 8
  %273 = icmp eq i64 %272, 0
  br i1 %273, label %assert_end78, label %assert_fail77, !prof !5

assert_fail75:                                    ; preds = %if_then73
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail77:                                    ; preds = %if_end74
  %275 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %275(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %if_end74
  %276 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %277 = load i32, i32* %276, align 4
  %278 = icmp eq i32 %277, 1
  br i1 %278, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %279 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %279(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %280 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %281 = load i32, i32* %280, align 4
  %282 = icmp eq i32 %51, %281
  br i1 %282, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %283 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %283(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %284 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %285 = load i32, i32* %284, align 4
  %286 = icmp eq i32 %285, 4
  br i1 %286, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %288 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %289 = load i16, i16* %288, align 2
  %290 = icmp eq i16 %289, 1
  %291 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %292 = load i8, i8* %291, align 1
  %293 = icmp eq i8 %292, 32
  %294 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %295 = load i8, i8* %294, align 1
  %296 = icmp eq i8 %295, 2
  %297 = and i1 %293, %296
  %298 = and i1 %290, %297
  br i1 %298, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %300 = load i64, i64* %67, align 8, !tbaa !3663
  %301 = trunc i64 %300 to i32
  %302 = icmp eq i32 %301, 64
  br i1 %302, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.162, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %304 = getelementptr inbounds i64, i64* %67, i64 1
  %305 = load i64, i64* %304, align 8, !tbaa !3677
  %306 = trunc i64 %305 to i32
  %307 = icmp eq i32 %306, 1
  br i1 %307, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %308 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %308(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %309 = getelementptr inbounds i64, i64* %67, i64 2
  %310 = load i64, i64* %309, align 8, !tbaa !3679
  %311 = trunc i64 %310 to i32
  %312 = icmp eq i32 %311, 1
  br i1 %312, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %313 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %313(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %314 = getelementptr inbounds i64, i64* %67, i64 3
  %315 = load i64, i64* %314, align 8, !tbaa !3682
  %316 = trunc i64 %315 to i32
  %317 = icmp eq i32 %316, 32
  br i1 %317, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %318 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %318(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %319 = icmp eq i64* %69, null
  br i1 %319, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %320 = bitcast i64* %69 to <4 x i64>*
  %321 = load <4 x i64>, <4 x i64>* %320, align 8, !tbaa !3684
  %322 = trunc <4 x i64> %321 to <4 x i32>
  %323 = icmp eq <4 x i32> %322, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf185 = shufflevector <4 x i1> %323, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx186 = and <4 x i1> %323, %rdx.shuf185
  %rdx.shuf187 = shufflevector <4 x i1> %bin.rdx186, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx188 = and <4 x i1> %bin.rdx186, %rdx.shuf187
  %324 = extractelement <4 x i1> %bin.rdx188, i32 0
  br i1 %324, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %325 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %326 = load i64, i64* %325, align 8
  %327 = icmp eq i64 %326, 0
  br i1 %327, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %330 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %331, 1
  br i1 %332, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %334 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %51, %335
  br i1 %336, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %338 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %339 = load i32, i32* %338, align 4
  %340 = icmp eq i32 %339, 4
  br i1 %340, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %342 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %343 = load i16, i16* %342, align 2
  %344 = icmp eq i16 %343, 1
  %345 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %346 = load i8, i8* %345, align 1
  %347 = icmp eq i8 %346, 32
  %348 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %349 = load i8, i8* %348, align 1
  %350 = icmp eq i8 %349, 2
  %351 = and i1 %347, %350
  %352 = and i1 %344, %351
  br i1 %352, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %354 = load i64, i64* %73, align 8, !tbaa !3696
  %355 = trunc i64 %354 to i32
  %356 = icmp eq i32 %355, 64
  br i1 %356, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %357 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %357(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.164, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %358 = getelementptr inbounds i64, i64* %73, i64 1
  %359 = load i64, i64* %358, align 8, !tbaa !3710
  %360 = trunc i64 %359 to i32
  %361 = icmp eq i32 %360, 1
  br i1 %361, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %362 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %362(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %363 = getelementptr inbounds i64, i64* %73, i64 2
  %364 = load i64, i64* %363, align 8, !tbaa !3712
  %365 = trunc i64 %364 to i32
  %366 = icmp eq i32 %365, 1
  br i1 %366, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %368 = getelementptr inbounds i64, i64* %73, i64 3
  %369 = load i64, i64* %368, align 8, !tbaa !3715
  %370 = trunc i64 %369 to i32
  %371 = icmp eq i32 %370, 32
  br i1 %371, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %372 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %372(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.167, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %373 = icmp eq i64* %75, null
  br i1 %373, label %if_end118, label %if_then117, !prof !50

if_then117:                                       ; preds = %assert_end116
  %374 = bitcast i64* %75 to <4 x i64>*
  %375 = load <4 x i64>, <4 x i64>* %374, align 8, !tbaa !3717
  %376 = trunc <4 x i64> %375 to <4 x i32>
  %377 = icmp eq <4 x i32> %376, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf181 = shufflevector <4 x i1> %377, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx182 = and <4 x i1> %377, %rdx.shuf181
  %rdx.shuf183 = shufflevector <4 x i1> %bin.rdx182, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx184 = and <4 x i1> %bin.rdx182, %rdx.shuf183
  %378 = extractelement <4 x i1> %bin.rdx184, i32 0
  br i1 %378, label %if_end118, label %assert_fail119, !prof !5

if_end118:                                        ; preds = %assert_end116, %if_then117
  %379 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %380 = load i64, i64* %379, align 8
  %381 = icmp eq i64 %380, 0
  br i1 %381, label %assert_end122, label %assert_fail121, !prof !5

assert_fail119:                                   ; preds = %if_then117
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.168, i64 0, i64 0))
  ret i32 -1

assert_fail121:                                   ; preds = %if_end118
  %383 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %383(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %if_end118
  %384 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %385 = load i32, i32* %384, align 4
  %386 = icmp eq i32 %385, 1
  br i1 %386, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %387 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %387(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %388 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %389 = load i32, i32* %388, align 4
  %390 = icmp eq i32 %51, %389
  br i1 %390, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %391 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %391(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %392 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %393 = load i32, i32* %392, align 4
  %394 = icmp eq i32 %393, 5
  br i1 %394, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %395 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %395(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %396 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %397 = load i16, i16* %396, align 2
  %398 = icmp eq i16 %397, 1
  %399 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %400 = load i8, i8* %399, align 1
  %401 = icmp eq i8 %400, 32
  %402 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %403 = load i8, i8* %402, align 1
  %404 = icmp eq i8 %403, 2
  %405 = and i1 %401, %404
  %406 = and i1 %398, %405
  br i1 %406, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %407 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %407(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %408 = load i64, i64* %79, align 8, !tbaa !3729
  %409 = trunc i64 %408 to i32
  %410 = icmp eq i32 %409, 1
  br i1 %410, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %411 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %411(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %412 = getelementptr inbounds i64, i64* %79, i64 1
  %413 = load i64, i64* %412, align 8, !tbaa !3743
  %414 = trunc i64 %413 to i32
  %415 = icmp eq i32 %414, 64
  br i1 %415, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %416 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %416(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.172, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %417 = getelementptr inbounds i64, i64* %79, i64 2
  %418 = load i64, i64* %417, align 8, !tbaa !3745
  %419 = trunc i64 %418 to i32
  %420 = icmp eq i32 %419, 7
  br i1 %420, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %421 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %421(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.173, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %422 = getelementptr inbounds i64, i64* %79, i64 3
  %423 = load i64, i64* %422, align 8, !tbaa !3748
  %424 = trunc i64 %423 to i32
  %425 = icmp eq i32 %424, 7
  br i1 %425, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %426 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %426(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.174, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %427 = getelementptr inbounds i64, i64* %79, i64 4
  %428 = load i64, i64* %427, align 8, !tbaa !3750
  %429 = trunc i64 %428 to i32
  %430 = icmp eq i32 %429, 32
  br i1 %430, label %assert_end140, label %assert_fail139, !prof !5

assert_fail139:                                   ; preds = %assert_end138
  %431 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %431(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.175, i64 0, i64 0))
  ret i32 -1

assert_end140:                                    ; preds = %assert_end138
  %432 = icmp eq i64* %81, null
  br i1 %432, label %if_end142, label %if_then141, !prof !50

if_then141:                                       ; preds = %assert_end140
  %433 = bitcast i64* %81 to <4 x i64>*
  %434 = load <4 x i64>, <4 x i64>* %433, align 8, !tbaa !3754
  %435 = trunc <4 x i64> %434 to <4 x i32>
  %436 = icmp eq <4 x i32> %435, <i32 100352, i32 1568, i32 224, i32 32>
  %437 = getelementptr inbounds i64, i64* %81, i64 4
  %438 = load i64, i64* %437, align 8, !tbaa !3766
  %439 = trunc i64 %438 to i32
  %440 = icmp eq i32 %439, 1
  %rdx.shuf177 = shufflevector <4 x i1> %436, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx178 = and <4 x i1> %436, %rdx.shuf177
  %rdx.shuf179 = shufflevector <4 x i1> %bin.rdx178, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx180 = and <4 x i1> %bin.rdx178, %rdx.shuf179
  %441 = extractelement <4 x i1> %bin.rdx180, i32 0
  %442 = and i1 %441, %440
  br i1 %442, label %if_end142, label %assert_fail143, !prof !5

if_end142:                                        ; preds = %assert_end140, %if_then141
  %443 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %444 = load i64, i64* %443, align 8
  %445 = icmp eq i64 %444, 0
  br i1 %445, label %assert_end146, label %assert_fail145, !prof !5

assert_fail143:                                   ; preds = %if_then141
  %446 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %446(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.176, i64 0, i64 0))
  ret i32 -1

assert_fail145:                                   ; preds = %if_end142
  %447 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %447(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %if_end142
  %448 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %449 = load i32, i32* %448, align 4
  %450 = icmp eq i32 %449, 1
  br i1 %450, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %451 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %451(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %452 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %453 = load i32, i32* %452, align 4
  %454 = icmp eq i32 %51, %453
  br i1 %454, label %assert_end150, label %assert_fail149, !prof !5

assert_fail149:                                   ; preds = %assert_end148
  %455 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %455(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end150:                                    ; preds = %assert_end148
  %456 = getelementptr inbounds %1, %1* %38, i64 0, i32 2
  %457 = load i32, i32* %456, align 4
  %458 = icmp eq i32 %457, 5
  br i1 %458, label %assert_end152, label %assert_fail151, !prof !5

assert_fail151:                                   ; preds = %assert_end150
  %459 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %459(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.310, i64 0, i64 0))
  ret i32 -1

assert_end152:                                    ; preds = %assert_end150
  %460 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 2
  %461 = load i16, i16* %460, align 2
  %462 = icmp eq i16 %461, 1
  %463 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 1
  %464 = load i8, i8* %463, align 1
  %465 = icmp eq i8 %464, 32
  %466 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 0
  %467 = load i8, i8* %466, align 1
  %468 = icmp eq i8 %467, 2
  %469 = and i1 %465, %468
  %470 = and i1 %462, %469
  br i1 %470, label %assert_end154, label %assert_fail153, !prof !5

assert_fail153:                                   ; preds = %assert_end152
  %471 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %471(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.311, i64 0, i64 0))
  ret i32 -1

assert_end154:                                    ; preds = %assert_end152
  %472 = load i64, i64* %85, align 8, !tbaa !3770
  %473 = trunc i64 %472 to i32
  %474 = icmp eq i32 %473, 1
  br i1 %474, label %assert_end156, label %assert_fail155, !prof !5

assert_fail155:                                   ; preds = %assert_end154
  %475 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %475(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.312, i64 0, i64 0))
  ret i32 -1

assert_end156:                                    ; preds = %assert_end154
  %476 = getelementptr inbounds i64, i64* %85, i64 1
  %477 = load i64, i64* %476, align 8, !tbaa !3784
  %478 = trunc i64 %477 to i32
  %479 = icmp eq i32 %478, 64
  br i1 %479, label %assert_end158, label %assert_fail157, !prof !5

assert_fail157:                                   ; preds = %assert_end156
  %480 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %480(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.313, i64 0, i64 0))
  ret i32 -1

assert_end158:                                    ; preds = %assert_end156
  %481 = getelementptr inbounds i64, i64* %85, i64 2
  %482 = load i64, i64* %481, align 8, !tbaa !3786
  %483 = trunc i64 %482 to i32
  %484 = icmp eq i32 %483, 7
  br i1 %484, label %assert_end160, label %assert_fail159, !prof !5

assert_fail159:                                   ; preds = %assert_end158
  %485 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %485(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.314, i64 0, i64 0))
  ret i32 -1

assert_end160:                                    ; preds = %assert_end158
  %486 = getelementptr inbounds i64, i64* %85, i64 3
  %487 = load i64, i64* %486, align 8, !tbaa !3789
  %488 = trunc i64 %487 to i32
  %489 = icmp eq i32 %488, 7
  br i1 %489, label %assert_end162, label %assert_fail161, !prof !5

assert_fail161:                                   ; preds = %assert_end160
  %490 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %490(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.315, i64 0, i64 0))
  ret i32 -1

assert_end162:                                    ; preds = %assert_end160
  %491 = getelementptr inbounds i64, i64* %85, i64 4
  %492 = load i64, i64* %491, align 8, !tbaa !3791
  %493 = trunc i64 %492 to i32
  %494 = icmp eq i32 %493, 32
  br i1 %494, label %assert_end164, label %assert_fail163, !prof !5

assert_fail163:                                   ; preds = %assert_end162
  %495 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %495(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.316, i64 0, i64 0))
  ret i32 -1

assert_end164:                                    ; preds = %assert_end162
  %496 = icmp eq i64* %87, null
  br i1 %496, label %if_end166, label %if_then165, !prof !50

if_then165:                                       ; preds = %assert_end164
  %497 = bitcast i64* %87 to <4 x i64>*
  %498 = load <4 x i64>, <4 x i64>* %497, align 8, !tbaa !3795
  %499 = trunc <4 x i64> %498 to <4 x i32>
  %500 = icmp eq <4 x i32> %499, <i32 100352, i32 1568, i32 224, i32 32>
  %501 = getelementptr inbounds i64, i64* %87, i64 4
  %502 = load i64, i64* %501, align 8, !tbaa !3807
  %503 = trunc i64 %502 to i32
  %504 = icmp eq i32 %503, 1
  %rdx.shuf = shufflevector <4 x i1> %500, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %500, %rdx.shuf
  %rdx.shuf175 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx176 = and <4 x i1> %bin.rdx, %rdx.shuf175
  %505 = extractelement <4 x i1> %bin.rdx176, i32 0
  %506 = and i1 %505, %504
  br i1 %506, label %if_end166, label %assert_fail167, !prof !5

if_end166:                                        ; preds = %assert_end164, %if_then165
  %507 = getelementptr inbounds %1, %1* %38, i64 0, i32 6
  %508 = load i64, i64* %507, align 8
  %509 = icmp eq i64 %508, 0
  br i1 %509, label %assert_end170, label %assert_fail169, !prof !5

assert_fail167:                                   ; preds = %if_then165
  %510 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %510(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.317, i64 0, i64 0))
  ret i32 -1

assert_fail169:                                   ; preds = %if_end166
  %511 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %511(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.318, i64 0, i64 0))
  ret i32 -1

assert_end170:                                    ; preds = %if_end166
  %512 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 0
  %513 = load i32, i32* %512, align 4
  %514 = icmp eq i32 %513, 1
  br i1 %514, label %assert_end172, label %assert_fail171, !prof !5

assert_fail171:                                   ; preds = %assert_end170
  %515 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %515(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.319, i64 0, i64 0))
  ret i32 -1

assert_end172:                                    ; preds = %assert_end170
  %516 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 1
  %517 = load i32, i32* %516, align 4
  %518 = icmp eq i32 %51, %517
  br i1 %518, label %assert_end174, label %assert_fail173, !prof !5

assert_fail173:                                   ; preds = %assert_end172
  %519 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %519(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.320, i64 0, i64 0))
  ret i32 -1

assert_end174:                                    ; preds = %assert_end172
  %520 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_compute_(i8* %43, i8* %53, i8* %83, i8* %59, i8* %65, i8* %71, i8* %77)
  ret i32 %520
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %7 = alloca %25, align 8
  %8 = getelementptr inbounds %25, %25* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %25, %25* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %25, %25* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %25, %25* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %25, %25* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %25, %25* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %25, %25* %7, i64 0, i32 6
  store i8* %6, i8** %14, align 8
  %15 = bitcast %25* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.321, i8* nonnull %15, i32 0)
  ret i32 %17
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.321(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 447
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 448
  %30 = select i1 %29, i32 %28, i32 448
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 448
  %33 = select i1 %32, i32 %31, i32 448
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin7.preheader
  %indvars.iv45 = phi i64 [ %37, %for_body.lr.ph ], [ %indvars.iv.next46, %for_begin7.preheader ]
  %39 = trunc i64 %indvars.iv45 to i32
  %40 = srem i32 %39, 7
  %41 = mul nsw i32 %40, 28
  %42 = sdiv i32 %39, 7
  %43 = shl i32 %42, 14
  %44 = sext i32 %41 to i64
  %45 = sext i32 %43 to i64
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_begin7.preheader, %entry
  ret i32 0

for_begin7.preheader:                             ; preds = %for_begin4.preheader
  %46 = mul nsw i64 %indvars.iv45, 224
  %47 = shl nsw i32 %42, 5
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds float, float* %13, i64 %48
  %50 = bitcast float* %49 to <32 x float>*
  %51 = load <32 x float>, <32 x float>* %50, align 64, !tbaa !3811
  %52 = getelementptr inbounds float, float* %16, i64 %48
  %53 = bitcast float* %52 to <32 x float>*
  %54 = load <32 x float>, <32 x float>* %53, align 64, !tbaa !3814
  %55 = getelementptr inbounds float, float* %19, i64 %48
  %56 = bitcast float* %55 to <32 x float>*
  %57 = load <32 x float>, <32 x float>* %56, align 64, !tbaa !3817
  %58 = getelementptr inbounds float, float* %22, i64 %46
  %59 = bitcast float* %58 to <32 x float>*
  %60 = load <32 x float>, <32 x float>* %59, align 64, !tbaa !3820
  %61 = fadd <32 x float> %51, %284
  %62 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %61, <32 x float> %54, <32 x float> %57)
  %63 = fadd <32 x float> %60, %62
  %64 = fcmp ogt <32 x float> %63, zeroinitializer
  %65 = select <32 x i1> %64, <32 x float> %63, <32 x float> zeroinitializer
  %66 = getelementptr inbounds float, float* %10, i64 %46
  %67 = bitcast float* %66 to <32 x float>*
  store <32 x float> %65, <32 x float>* %67, align 64, !tbaa !3823
  %68 = add nsw i64 %46, 32
  %69 = getelementptr inbounds float, float* %22, i64 %68
  %70 = bitcast float* %69 to <32 x float>*
  %71 = load <32 x float>, <32 x float>* %70, align 64, !tbaa !3820
  %72 = fadd <32 x float> %51, %290
  %73 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %72, <32 x float> %54, <32 x float> %57)
  %74 = fadd <32 x float> %71, %73
  %75 = fcmp ogt <32 x float> %74, zeroinitializer
  %76 = select <32 x i1> %75, <32 x float> %74, <32 x float> zeroinitializer
  %77 = getelementptr inbounds float, float* %10, i64 %68
  %78 = bitcast float* %77 to <32 x float>*
  store <32 x float> %76, <32 x float>* %78, align 64, !tbaa !3823
  %79 = add nsw i64 %46, 64
  %80 = getelementptr inbounds float, float* %22, i64 %79
  %81 = bitcast float* %80 to <32 x float>*
  %82 = load <32 x float>, <32 x float>* %81, align 64, !tbaa !3820
  %83 = fadd <32 x float> %51, %296
  %84 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %54, <32 x float> %57)
  %85 = fadd <32 x float> %82, %84
  %86 = fcmp ogt <32 x float> %85, zeroinitializer
  %87 = select <32 x i1> %86, <32 x float> %85, <32 x float> zeroinitializer
  %88 = getelementptr inbounds float, float* %10, i64 %79
  %89 = bitcast float* %88 to <32 x float>*
  store <32 x float> %87, <32 x float>* %89, align 64, !tbaa !3823
  %90 = add nsw i64 %46, 96
  %91 = getelementptr inbounds float, float* %22, i64 %90
  %92 = bitcast float* %91 to <32 x float>*
  %93 = load <32 x float>, <32 x float>* %92, align 64, !tbaa !3820
  %94 = fadd <32 x float> %51, %302
  %95 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %94, <32 x float> %54, <32 x float> %57)
  %96 = fadd <32 x float> %93, %95
  %97 = fcmp ogt <32 x float> %96, zeroinitializer
  %98 = select <32 x i1> %97, <32 x float> %96, <32 x float> zeroinitializer
  %99 = getelementptr inbounds float, float* %10, i64 %90
  %100 = bitcast float* %99 to <32 x float>*
  store <32 x float> %98, <32 x float>* %100, align 64, !tbaa !3823
  %101 = add nsw i64 %46, 128
  %102 = getelementptr inbounds float, float* %22, i64 %101
  %103 = bitcast float* %102 to <32 x float>*
  %104 = load <32 x float>, <32 x float>* %103, align 64, !tbaa !3820
  %105 = fadd <32 x float> %51, %308
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %54, <32 x float> %57)
  %107 = fadd <32 x float> %104, %106
  %108 = fcmp ogt <32 x float> %107, zeroinitializer
  %109 = select <32 x i1> %108, <32 x float> %107, <32 x float> zeroinitializer
  %110 = getelementptr inbounds float, float* %10, i64 %101
  %111 = bitcast float* %110 to <32 x float>*
  store <32 x float> %109, <32 x float>* %111, align 64, !tbaa !3823
  %112 = add nsw i64 %46, 160
  %113 = getelementptr inbounds float, float* %22, i64 %112
  %114 = bitcast float* %113 to <32 x float>*
  %115 = load <32 x float>, <32 x float>* %114, align 64, !tbaa !3820
  %116 = fadd <32 x float> %51, %314
  %117 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %116, <32 x float> %54, <32 x float> %57)
  %118 = fadd <32 x float> %115, %117
  %119 = fcmp ogt <32 x float> %118, zeroinitializer
  %120 = select <32 x i1> %119, <32 x float> %118, <32 x float> zeroinitializer
  %121 = getelementptr inbounds float, float* %10, i64 %112
  %122 = bitcast float* %121 to <32 x float>*
  store <32 x float> %120, <32 x float>* %122, align 64, !tbaa !3823
  %123 = add nsw i64 %46, 192
  %124 = getelementptr inbounds float, float* %22, i64 %123
  %125 = bitcast float* %124 to <32 x float>*
  %126 = load <32 x float>, <32 x float>* %125, align 64, !tbaa !3820
  %127 = fadd <32 x float> %51, %320
  %128 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %127, <32 x float> %54, <32 x float> %57)
  %129 = fadd <32 x float> %126, %128
  %130 = fcmp ogt <32 x float> %129, zeroinitializer
  %131 = select <32 x i1> %130, <32 x float> %129, <32 x float> zeroinitializer
  %132 = getelementptr inbounds float, float* %10, i64 %123
  %133 = bitcast float* %132 to <32 x float>*
  store <32 x float> %131, <32 x float>* %133, align 64, !tbaa !3823
  %indvars.iv.next46 = add nsw i64 %indvars.iv45, 1
  %134 = icmp slt i64 %indvars.iv.next46, %38
  br i1 %134, label %for_body, label %for_end, !prof !5

for_begin4.preheader:                             ; preds = %for_begin4.preheader, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_begin4.preheader ]
  %.lcssa2235 = phi <32 x float> [ zeroinitializer, %for_body ], [ %320, %for_begin4.preheader ]
  %.lcssa2033 = phi <32 x float> [ zeroinitializer, %for_body ], [ %314, %for_begin4.preheader ]
  %.lcssa1831 = phi <32 x float> [ zeroinitializer, %for_body ], [ %308, %for_begin4.preheader ]
  %.lcssa1629 = phi <32 x float> [ zeroinitializer, %for_body ], [ %302, %for_begin4.preheader ]
  %.lcssa1427 = phi <32 x float> [ zeroinitializer, %for_body ], [ %296, %for_begin4.preheader ]
  %.lcssa1226 = phi <32 x float> [ zeroinitializer, %for_body ], [ %290, %for_begin4.preheader ]
  %.lcssa24 = phi <32 x float> [ zeroinitializer, %for_body ], [ %284, %for_begin4.preheader ]
  %135 = mul nuw nsw i64 %indvars.iv, 196
  %136 = add nsw i64 %135, %44
  %137 = shl i64 %indvars.iv, 7
  %138 = add nuw nsw i64 %137, %45
  %139 = getelementptr inbounds float, float* %4, i64 %136
  %140 = load float, float* %139, align 4, !tbaa !3826
  %141 = insertelement <32 x float> undef, float %140, i32 0
  %142 = shufflevector <32 x float> %141, <32 x float> undef, <32 x i32> zeroinitializer
  %143 = getelementptr inbounds float, float* %7, i64 %138
  %144 = bitcast float* %143 to <32 x float>*
  %145 = load <32 x float>, <32 x float>* %144, align 64, !tbaa !3829
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %142, <32 x float> %145, <32 x float> %.lcssa24)
  %147 = add nsw i64 %136, 4
  %148 = getelementptr inbounds float, float* %4, i64 %147
  %149 = load float, float* %148, align 4, !tbaa !3826
  %150 = insertelement <32 x float> undef, float %149, i32 0
  %151 = shufflevector <32 x float> %150, <32 x float> undef, <32 x i32> zeroinitializer
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %151, <32 x float> %145, <32 x float> %.lcssa1226)
  %153 = add nsw i64 %136, 8
  %154 = getelementptr inbounds float, float* %4, i64 %153
  %155 = load float, float* %154, align 4, !tbaa !3826
  %156 = insertelement <32 x float> undef, float %155, i32 0
  %157 = shufflevector <32 x float> %156, <32 x float> undef, <32 x i32> zeroinitializer
  %158 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %157, <32 x float> %145, <32 x float> %.lcssa1427)
  %159 = add nsw i64 %136, 12
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = load float, float* %160, align 4, !tbaa !3826
  %162 = insertelement <32 x float> undef, float %161, i32 0
  %163 = shufflevector <32 x float> %162, <32 x float> undef, <32 x i32> zeroinitializer
  %164 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %163, <32 x float> %145, <32 x float> %.lcssa1629)
  %165 = add nsw i64 %136, 16
  %166 = getelementptr inbounds float, float* %4, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !3826
  %168 = insertelement <32 x float> undef, float %167, i32 0
  %169 = shufflevector <32 x float> %168, <32 x float> undef, <32 x i32> zeroinitializer
  %170 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %169, <32 x float> %145, <32 x float> %.lcssa1831)
  %171 = add nsw i64 %136, 20
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !3826
  %174 = insertelement <32 x float> undef, float %173, i32 0
  %175 = shufflevector <32 x float> %174, <32 x float> undef, <32 x i32> zeroinitializer
  %176 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %175, <32 x float> %145, <32 x float> %.lcssa2033)
  %177 = add nsw i64 %136, 24
  %178 = getelementptr inbounds float, float* %4, i64 %177
  %179 = load float, float* %178, align 4, !tbaa !3826
  %180 = insertelement <32 x float> undef, float %179, i32 0
  %181 = shufflevector <32 x float> %180, <32 x float> undef, <32 x i32> zeroinitializer
  %182 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %181, <32 x float> %145, <32 x float> %.lcssa2235)
  %183 = or i64 %136, 1
  %184 = getelementptr inbounds float, float* %4, i64 %183
  %185 = load float, float* %184, align 4, !tbaa !3826
  %186 = insertelement <32 x float> undef, float %185, i32 0
  %187 = shufflevector <32 x float> %186, <32 x float> undef, <32 x i32> zeroinitializer
  %188 = or i64 %138, 32
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to <32 x float>*
  %191 = load <32 x float>, <32 x float>* %190, align 64, !tbaa !3829
  %192 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %187, <32 x float> %191, <32 x float> %146)
  %193 = add nsw i64 %183, 4
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = load float, float* %194, align 4, !tbaa !3826
  %196 = insertelement <32 x float> undef, float %195, i32 0
  %197 = shufflevector <32 x float> %196, <32 x float> undef, <32 x i32> zeroinitializer
  %198 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %197, <32 x float> %191, <32 x float> %152)
  %199 = add nsw i64 %183, 8
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !3826
  %202 = insertelement <32 x float> undef, float %201, i32 0
  %203 = shufflevector <32 x float> %202, <32 x float> undef, <32 x i32> zeroinitializer
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %203, <32 x float> %191, <32 x float> %158)
  %205 = add nsw i64 %183, 12
  %206 = getelementptr inbounds float, float* %4, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !3826
  %208 = insertelement <32 x float> undef, float %207, i32 0
  %209 = shufflevector <32 x float> %208, <32 x float> undef, <32 x i32> zeroinitializer
  %210 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %209, <32 x float> %191, <32 x float> %164)
  %211 = add nsw i64 %183, 16
  %212 = getelementptr inbounds float, float* %4, i64 %211
  %213 = load float, float* %212, align 4, !tbaa !3826
  %214 = insertelement <32 x float> undef, float %213, i32 0
  %215 = shufflevector <32 x float> %214, <32 x float> undef, <32 x i32> zeroinitializer
  %216 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %215, <32 x float> %191, <32 x float> %170)
  %217 = add nsw i64 %183, 20
  %218 = getelementptr inbounds float, float* %4, i64 %217
  %219 = load float, float* %218, align 4, !tbaa !3826
  %220 = insertelement <32 x float> undef, float %219, i32 0
  %221 = shufflevector <32 x float> %220, <32 x float> undef, <32 x i32> zeroinitializer
  %222 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %221, <32 x float> %191, <32 x float> %176)
  %223 = add nsw i64 %183, 24
  %224 = getelementptr inbounds float, float* %4, i64 %223
  %225 = load float, float* %224, align 4, !tbaa !3826
  %226 = insertelement <32 x float> undef, float %225, i32 0
  %227 = shufflevector <32 x float> %226, <32 x float> undef, <32 x i32> zeroinitializer
  %228 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %227, <32 x float> %191, <32 x float> %182)
  %229 = or i64 %136, 2
  %230 = getelementptr inbounds float, float* %4, i64 %229
  %231 = load float, float* %230, align 4, !tbaa !3826
  %232 = insertelement <32 x float> undef, float %231, i32 0
  %233 = shufflevector <32 x float> %232, <32 x float> undef, <32 x i32> zeroinitializer
  %234 = or i64 %138, 64
  %235 = getelementptr inbounds float, float* %7, i64 %234
  %236 = bitcast float* %235 to <32 x float>*
  %237 = load <32 x float>, <32 x float>* %236, align 64, !tbaa !3829
  %238 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %233, <32 x float> %237, <32 x float> %192)
  %239 = add nsw i64 %229, 4
  %240 = getelementptr inbounds float, float* %4, i64 %239
  %241 = load float, float* %240, align 4, !tbaa !3826
  %242 = insertelement <32 x float> undef, float %241, i32 0
  %243 = shufflevector <32 x float> %242, <32 x float> undef, <32 x i32> zeroinitializer
  %244 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %243, <32 x float> %237, <32 x float> %198)
  %245 = add nsw i64 %229, 8
  %246 = getelementptr inbounds float, float* %4, i64 %245
  %247 = load float, float* %246, align 4, !tbaa !3826
  %248 = insertelement <32 x float> undef, float %247, i32 0
  %249 = shufflevector <32 x float> %248, <32 x float> undef, <32 x i32> zeroinitializer
  %250 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %249, <32 x float> %237, <32 x float> %204)
  %251 = add nsw i64 %229, 12
  %252 = getelementptr inbounds float, float* %4, i64 %251
  %253 = load float, float* %252, align 4, !tbaa !3826
  %254 = insertelement <32 x float> undef, float %253, i32 0
  %255 = shufflevector <32 x float> %254, <32 x float> undef, <32 x i32> zeroinitializer
  %256 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %255, <32 x float> %237, <32 x float> %210)
  %257 = add nsw i64 %229, 16
  %258 = getelementptr inbounds float, float* %4, i64 %257
  %259 = load float, float* %258, align 4, !tbaa !3826
  %260 = insertelement <32 x float> undef, float %259, i32 0
  %261 = shufflevector <32 x float> %260, <32 x float> undef, <32 x i32> zeroinitializer
  %262 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %261, <32 x float> %237, <32 x float> %216)
  %263 = add nsw i64 %229, 20
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !3826
  %266 = insertelement <32 x float> undef, float %265, i32 0
  %267 = shufflevector <32 x float> %266, <32 x float> undef, <32 x i32> zeroinitializer
  %268 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %267, <32 x float> %237, <32 x float> %222)
  %269 = add nsw i64 %229, 24
  %270 = getelementptr inbounds float, float* %4, i64 %269
  %271 = load float, float* %270, align 4, !tbaa !3826
  %272 = insertelement <32 x float> undef, float %271, i32 0
  %273 = shufflevector <32 x float> %272, <32 x float> undef, <32 x i32> zeroinitializer
  %274 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %273, <32 x float> %237, <32 x float> %228)
  %275 = or i64 %136, 3
  %276 = getelementptr inbounds float, float* %4, i64 %275
  %277 = load float, float* %276, align 4, !tbaa !3826
  %278 = insertelement <32 x float> undef, float %277, i32 0
  %279 = shufflevector <32 x float> %278, <32 x float> undef, <32 x i32> zeroinitializer
  %280 = or i64 %138, 96
  %281 = getelementptr inbounds float, float* %7, i64 %280
  %282 = bitcast float* %281 to <32 x float>*
  %283 = load <32 x float>, <32 x float>* %282, align 64, !tbaa !3829
  %284 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %279, <32 x float> %283, <32 x float> %238)
  %285 = add nsw i64 %275, 4
  %286 = getelementptr inbounds float, float* %4, i64 %285
  %287 = load float, float* %286, align 4, !tbaa !3826
  %288 = insertelement <32 x float> undef, float %287, i32 0
  %289 = shufflevector <32 x float> %288, <32 x float> undef, <32 x i32> zeroinitializer
  %290 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %289, <32 x float> %283, <32 x float> %244)
  %291 = add nsw i64 %275, 8
  %292 = getelementptr inbounds float, float* %4, i64 %291
  %293 = load float, float* %292, align 4, !tbaa !3826
  %294 = insertelement <32 x float> undef, float %293, i32 0
  %295 = shufflevector <32 x float> %294, <32 x float> undef, <32 x i32> zeroinitializer
  %296 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %295, <32 x float> %283, <32 x float> %250)
  %297 = add nsw i64 %275, 12
  %298 = getelementptr inbounds float, float* %4, i64 %297
  %299 = load float, float* %298, align 4, !tbaa !3826
  %300 = insertelement <32 x float> undef, float %299, i32 0
  %301 = shufflevector <32 x float> %300, <32 x float> undef, <32 x i32> zeroinitializer
  %302 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %301, <32 x float> %283, <32 x float> %256)
  %303 = add nsw i64 %275, 16
  %304 = getelementptr inbounds float, float* %4, i64 %303
  %305 = load float, float* %304, align 4, !tbaa !3826
  %306 = insertelement <32 x float> undef, float %305, i32 0
  %307 = shufflevector <32 x float> %306, <32 x float> undef, <32 x i32> zeroinitializer
  %308 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %307, <32 x float> %283, <32 x float> %262)
  %309 = add nsw i64 %275, 20
  %310 = getelementptr inbounds float, float* %4, i64 %309
  %311 = load float, float* %310, align 4, !tbaa !3826
  %312 = insertelement <32 x float> undef, float %311, i32 0
  %313 = shufflevector <32 x float> %312, <32 x float> undef, <32 x i32> zeroinitializer
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %313, <32 x float> %283, <32 x float> %268)
  %315 = add nsw i64 %275, 24
  %316 = getelementptr inbounds float, float* %4, i64 %315
  %317 = load float, float* %316, align 4, !tbaa !3826
  %318 = insertelement <32 x float> undef, float %317, i32 0
  %319 = shufflevector <32 x float> %318, <32 x float> undef, <32 x i32> zeroinitializer
  %320 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %319, <32 x float> %283, <32 x float> %274)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_begin7.preheader, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_32(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.322, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !3832
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.323, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !3846
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.324, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !3848
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !3862
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 16
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !3864
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 7
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !3867
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 7
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !3869
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !3873
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 25088, i32 1568, i32 224, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !3885
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.325, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !3889
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !3903
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 128
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.308, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !3905
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 7
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.326, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !3908
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 7
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.327, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !3910
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 4
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !3914
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 25088, i32 196, i32 28, i32 4>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !3926
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([234 x i8], [234 x i8]* @.str.328, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_32_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_32_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %26, align 8
  %3 = getelementptr inbounds %26, %26* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %26, %26* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %26* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.329, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.329(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 895
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 896
  %15 = select i1 %14, i32 %13, i32 896
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 896
  %18 = select i1 %17, i32 %16, i32 896
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_begin1.preheader ]
  %24 = mul nsw i64 %indvars.iv, 28
  %25 = trunc i64 %indvars.iv to i32
  %26 = sdiv i32 %25, 7
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 7
  %29 = mul nsw i32 %28, 224
  %30 = and i32 %27, 28
  %31 = and i32 %27, 28
  %32 = and i32 %27, 28
  %33 = insertelement <4 x i32> undef, i32 %27, i32 0
  %34 = insertelement <4 x i32> %33, i32 %30, i32 1
  %35 = insertelement <4 x i32> %34, i32 %31, i32 2
  %36 = insertelement <4 x i32> %35, i32 %32, i32 3
  %37 = and <4 x i32> %36, <i32 28, i32 undef, i32 undef, i32 undef>
  %38 = or <4 x i32> %36, <i32 undef, i32 1, i32 2, i32 3>
  %39 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %shuffle8 = shufflevector <4 x i32> %39, <4 x i32> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 0, i32 1, i32 2, i32 3, i32 0, i32 1, i32 2, i32 3, i32 0, i32 1, i32 2, i32 3>
  %40 = insertelement <4 x i32> undef, i32 %26, i32 0
  %41 = ashr <4 x i32> %40, <i32 3, i32 0, i32 0, i32 0>
  %42 = mul nsw <4 x i32> %41, <i32 1568, i32 undef, i32 undef, i32 undef>
  %shuffle7 = shufflevector <4 x i32> %42, <4 x i32> undef, <16 x i32> zeroinitializer
  %43 = add nsw i32 %29, 32
  %44 = add nsw i32 %29, 64
  %45 = add nsw i32 %29, 96
  %46 = insertelement <4 x i32> undef, i32 %29, i32 0
  %47 = insertelement <4 x i32> %46, i32 %43, i32 1
  %48 = insertelement <4 x i32> %47, i32 %44, i32 2
  %49 = insertelement <4 x i32> %48, i32 %45, i32 3
  %shuffle = shufflevector <4 x i32> %49, <4 x i32> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 1, i32 1, i32 1, i32 1, i32 2, i32 2, i32 2, i32 2, i32 3, i32 3, i32 3, i32 3>
  %50 = add <16 x i32> %shuffle, %shuffle7
  %51 = or <16 x i32> %50, %shuffle8
  %52 = sext <16 x i32> %51 to <16 x i64>
  %53 = extractelement <16 x i64> %52, i32 0
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to i32*
  %56 = load i32, i32* %55, align 4, !tbaa !3930
  %57 = getelementptr inbounds float, float* %4, i64 %24
  %58 = bitcast float* %57 to i32*
  store i32 %56, i32* %58, align 4, !tbaa !3933
  %59 = or i64 %24, 1
  %60 = extractelement <16 x i64> %52, i32 1
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = bitcast float* %61 to i32*
  %63 = load i32, i32* %62, align 4, !tbaa !3930
  %64 = getelementptr inbounds float, float* %4, i64 %59
  %65 = bitcast float* %64 to i32*
  store i32 %63, i32* %65, align 4, !tbaa !3933
  %66 = or i64 %24, 2
  %67 = extractelement <16 x i64> %52, i32 2
  %68 = getelementptr inbounds float, float* %7, i64 %67
  %69 = bitcast float* %68 to i32*
  %70 = load i32, i32* %69, align 4, !tbaa !3930
  %71 = getelementptr inbounds float, float* %4, i64 %66
  %72 = bitcast float* %71 to i32*
  store i32 %70, i32* %72, align 4, !tbaa !3933
  %73 = or i64 %24, 3
  %74 = extractelement <16 x i64> %52, i32 3
  %75 = getelementptr inbounds float, float* %7, i64 %74
  %76 = bitcast float* %75 to i32*
  %77 = load i32, i32* %76, align 4, !tbaa !3930
  %78 = getelementptr inbounds float, float* %4, i64 %73
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 4, !tbaa !3933
  %80 = add nsw i64 %24, 4
  %81 = extractelement <16 x i64> %52, i32 4
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to i32*
  %84 = load i32, i32* %83, align 4, !tbaa !3930
  %85 = getelementptr inbounds float, float* %4, i64 %80
  %86 = bitcast float* %85 to i32*
  store i32 %84, i32* %86, align 4, !tbaa !3933
  %87 = add nsw i64 %24, 5
  %88 = extractelement <16 x i64> %52, i32 5
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = bitcast float* %89 to i32*
  %91 = load i32, i32* %90, align 4, !tbaa !3930
  %92 = getelementptr inbounds float, float* %4, i64 %87
  %93 = bitcast float* %92 to i32*
  store i32 %91, i32* %93, align 4, !tbaa !3933
  %94 = add nsw i64 %24, 6
  %95 = extractelement <16 x i64> %52, i32 6
  %96 = getelementptr inbounds float, float* %7, i64 %95
  %97 = bitcast float* %96 to i32*
  %98 = load i32, i32* %97, align 4, !tbaa !3930
  %99 = getelementptr inbounds float, float* %4, i64 %94
  %100 = bitcast float* %99 to i32*
  store i32 %98, i32* %100, align 4, !tbaa !3933
  %101 = add nsw i64 %24, 7
  %102 = extractelement <16 x i64> %52, i32 7
  %103 = getelementptr inbounds float, float* %7, i64 %102
  %104 = bitcast float* %103 to i32*
  %105 = load i32, i32* %104, align 4, !tbaa !3930
  %106 = getelementptr inbounds float, float* %4, i64 %101
  %107 = bitcast float* %106 to i32*
  store i32 %105, i32* %107, align 4, !tbaa !3933
  %108 = add nsw i64 %24, 8
  %109 = extractelement <16 x i64> %52, i32 8
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !3930
  %113 = getelementptr inbounds float, float* %4, i64 %108
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !3933
  %115 = add nsw i64 %24, 9
  %116 = extractelement <16 x i64> %52, i32 9
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = bitcast float* %117 to i32*
  %119 = load i32, i32* %118, align 4, !tbaa !3930
  %120 = getelementptr inbounds float, float* %4, i64 %115
  %121 = bitcast float* %120 to i32*
  store i32 %119, i32* %121, align 4, !tbaa !3933
  %122 = add nsw i64 %24, 10
  %123 = extractelement <16 x i64> %52, i32 10
  %124 = getelementptr inbounds float, float* %7, i64 %123
  %125 = bitcast float* %124 to i32*
  %126 = load i32, i32* %125, align 4, !tbaa !3930
  %127 = getelementptr inbounds float, float* %4, i64 %122
  %128 = bitcast float* %127 to i32*
  store i32 %126, i32* %128, align 4, !tbaa !3933
  %129 = add nsw i64 %24, 11
  %130 = extractelement <16 x i64> %52, i32 11
  %131 = getelementptr inbounds float, float* %7, i64 %130
  %132 = bitcast float* %131 to i32*
  %133 = load i32, i32* %132, align 4, !tbaa !3930
  %134 = getelementptr inbounds float, float* %4, i64 %129
  %135 = bitcast float* %134 to i32*
  store i32 %133, i32* %135, align 4, !tbaa !3933
  %136 = add nsw i64 %24, 12
  %137 = extractelement <16 x i64> %52, i32 12
  %138 = getelementptr inbounds float, float* %7, i64 %137
  %139 = bitcast float* %138 to i32*
  %140 = load i32, i32* %139, align 4, !tbaa !3930
  %141 = getelementptr inbounds float, float* %4, i64 %136
  %142 = bitcast float* %141 to i32*
  store i32 %140, i32* %142, align 4, !tbaa !3933
  %143 = add nsw i64 %24, 13
  %144 = extractelement <16 x i64> %52, i32 13
  %145 = getelementptr inbounds float, float* %7, i64 %144
  %146 = bitcast float* %145 to i32*
  %147 = load i32, i32* %146, align 4, !tbaa !3930
  %148 = getelementptr inbounds float, float* %4, i64 %143
  %149 = bitcast float* %148 to i32*
  store i32 %147, i32* %149, align 4, !tbaa !3933
  %150 = add nsw i64 %24, 14
  %151 = extractelement <16 x i64> %52, i32 14
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = bitcast float* %152 to i32*
  %154 = load i32, i32* %153, align 4, !tbaa !3930
  %155 = getelementptr inbounds float, float* %4, i64 %150
  %156 = bitcast float* %155 to i32*
  store i32 %154, i32* %156, align 4, !tbaa !3933
  %157 = add nsw i64 %24, 15
  %158 = extractelement <16 x i64> %52, i32 15
  %159 = getelementptr inbounds float, float* %7, i64 %158
  %160 = bitcast float* %159 to i32*
  %161 = load i32, i32* %160, align 4, !tbaa !3930
  %162 = getelementptr inbounds float, float* %4, i64 %157
  %163 = bitcast float* %162 to i32*
  store i32 %161, i32* %163, align 4, !tbaa !3933
  %164 = add nsw i64 %24, 16
  %165 = insertelement <2 x i32> undef, i32 %29, i32 0
  %166 = shufflevector <2 x i32> %165, <2 x i32> undef, <2 x i32> zeroinitializer
  %167 = add nsw <2 x i32> %166, <i32 128, i32 160>
  %shuffle9 = shufflevector <2 x i32> %167, <2 x i32> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 1, i32 1, i32 1, i32 1>
  %168 = shufflevector <4 x i32> %42, <4 x i32> undef, <8 x i32> zeroinitializer
  %169 = add <8 x i32> %shuffle9, %168
  %170 = shufflevector <4 x i32> %37, <4 x i32> %38, <8 x i32> <i32 0, i32 5, i32 6, i32 7, i32 0, i32 5, i32 6, i32 7>
  %171 = or <8 x i32> %169, %170
  %172 = extractelement <8 x i32> %171, i32 0
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to i32*
  %176 = load i32, i32* %175, align 4, !tbaa !3930
  %177 = getelementptr inbounds float, float* %4, i64 %164
  %178 = bitcast float* %177 to i32*
  store i32 %176, i32* %178, align 4, !tbaa !3933
  %179 = add nsw i64 %24, 17
  %180 = extractelement <8 x i32> %171, i32 1
  %181 = sext i32 %180 to i64
  %182 = getelementptr inbounds float, float* %7, i64 %181
  %183 = bitcast float* %182 to i32*
  %184 = load i32, i32* %183, align 4, !tbaa !3930
  %185 = getelementptr inbounds float, float* %4, i64 %179
  %186 = bitcast float* %185 to i32*
  store i32 %184, i32* %186, align 4, !tbaa !3933
  %187 = add nsw i64 %24, 18
  %188 = extractelement <8 x i32> %171, i32 2
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to i32*
  %192 = load i32, i32* %191, align 4, !tbaa !3930
  %193 = getelementptr inbounds float, float* %4, i64 %187
  %194 = bitcast float* %193 to i32*
  store i32 %192, i32* %194, align 4, !tbaa !3933
  %195 = add nsw i64 %24, 19
  %196 = extractelement <8 x i32> %171, i32 3
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds float, float* %7, i64 %197
  %199 = bitcast float* %198 to i32*
  %200 = load i32, i32* %199, align 4, !tbaa !3930
  %201 = getelementptr inbounds float, float* %4, i64 %195
  %202 = bitcast float* %201 to i32*
  store i32 %200, i32* %202, align 4, !tbaa !3933
  %203 = add nsw i64 %24, 20
  %204 = extractelement <8 x i32> %171, i32 4
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = bitcast float* %206 to i32*
  %208 = load i32, i32* %207, align 4, !tbaa !3930
  %209 = getelementptr inbounds float, float* %4, i64 %203
  %210 = bitcast float* %209 to i32*
  store i32 %208, i32* %210, align 4, !tbaa !3933
  %211 = add nsw i64 %24, 21
  %212 = extractelement <8 x i32> %171, i32 5
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %7, i64 %213
  %215 = bitcast float* %214 to i32*
  %216 = load i32, i32* %215, align 4, !tbaa !3930
  %217 = getelementptr inbounds float, float* %4, i64 %211
  %218 = bitcast float* %217 to i32*
  store i32 %216, i32* %218, align 4, !tbaa !3933
  %219 = add nsw i64 %24, 22
  %220 = extractelement <8 x i32> %171, i32 6
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds float, float* %7, i64 %221
  %223 = bitcast float* %222 to i32*
  %224 = load i32, i32* %223, align 4, !tbaa !3930
  %225 = getelementptr inbounds float, float* %4, i64 %219
  %226 = bitcast float* %225 to i32*
  store i32 %224, i32* %226, align 4, !tbaa !3933
  %227 = add nsw i64 %24, 23
  %228 = extractelement <8 x i32> %171, i32 7
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to i32*
  %232 = load i32, i32* %231, align 4, !tbaa !3930
  %233 = getelementptr inbounds float, float* %4, i64 %227
  %234 = bitcast float* %233 to i32*
  store i32 %232, i32* %234, align 4, !tbaa !3933
  %235 = add nsw i64 %24, 24
  %narrow = add nsw i32 %29, 192
  %236 = insertelement <4 x i32> undef, i32 %narrow, i32 0
  %237 = add <4 x i32> %236, %42
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %240 = or <4 x i32> %238, %239
  %241 = extractelement <4 x i32> %240, i32 0
  %242 = sext i32 %241 to i64
  %243 = getelementptr inbounds float, float* %7, i64 %242
  %244 = bitcast float* %243 to i32*
  %245 = load i32, i32* %244, align 4, !tbaa !3930
  %246 = getelementptr inbounds float, float* %4, i64 %235
  %247 = bitcast float* %246 to i32*
  store i32 %245, i32* %247, align 4, !tbaa !3933
  %248 = add nsw i64 %24, 25
  %249 = extractelement <4 x i32> %240, i32 1
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds float, float* %7, i64 %250
  %252 = bitcast float* %251 to i32*
  %253 = load i32, i32* %252, align 4, !tbaa !3930
  %254 = getelementptr inbounds float, float* %4, i64 %248
  %255 = bitcast float* %254 to i32*
  store i32 %253, i32* %255, align 4, !tbaa !3933
  %256 = add nsw i64 %24, 26
  %257 = extractelement <4 x i32> %240, i32 2
  %258 = sext i32 %257 to i64
  %259 = getelementptr inbounds float, float* %7, i64 %258
  %260 = bitcast float* %259 to i32*
  %261 = load i32, i32* %260, align 4, !tbaa !3930
  %262 = getelementptr inbounds float, float* %4, i64 %256
  %263 = bitcast float* %262 to i32*
  store i32 %261, i32* %263, align 4, !tbaa !3933
  %264 = add nsw i64 %24, 27
  %265 = extractelement <4 x i32> %240, i32 3
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds float, float* %7, i64 %266
  %268 = bitcast float* %267 to i32*
  %269 = load i32, i32* %268, align 4, !tbaa !3930
  %270 = getelementptr inbounds float, float* %4, i64 %264
  %271 = bitcast float* %270 to i32*
  store i32 %269, i32* %271, align 4, !tbaa !3933
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %272 = icmp slt i64 %indvars.iv.next, %23
  br i1 %272, label %for_begin1.preheader, label %for_end, !prof !5

for_end:                                          ; preds = %for_begin1.preheader, %entry
  ret i32 0
}

define dllexport i32 @fused_layout_transform_41(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.330, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !3936
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.331, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !3950
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.332, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !3952
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !3966
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 16
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !3968
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 28
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !3971
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 28
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !3973
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !3977
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 401408, i32 25088, i32 896, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !3989
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.333, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !3993
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !4007
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !4009
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 28
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !4012
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 28
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !4014
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 512
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !4018
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 401408, i32 401408, i32 14336, i32 512>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !4030
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([243 x i8], [243 x i8]* @.str.334, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_41_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_41_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %27, align 8
  %3 = getelementptr inbounds %27, %27* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %27, %27* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %27* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.335, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.335(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 14336
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 9
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 25088
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !4034
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !4037
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_transpose_nn_batch_flatten(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([102 x i8], [102 x i8]* @.str.336, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !4040
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([177 x i8], [177 x i8]* @.str.337, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !4054
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([177 x i8], [177 x i8]* @.str.338, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !4056
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !4070
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 64
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !4072
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 1
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.339, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !4075
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 1
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.340, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !4077
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !4081
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 2048, i32 32, i32 32, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !4093
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %79, %rdx.shuf
  %rdx.shuf43 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx44 = and <4 x i1> %bin.rdx, %rdx.shuf43
  %84 = extractelement <4 x i1> %bin.rdx44, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([233 x i8], [233 x i8]* @.str.341, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 2
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.342, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !4097
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !4111
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 2048
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.343, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = icmp eq i64* %27, null
  br i1 %116, label %if_end34, label %if_then33, !prof !50

if_then33:                                        ; preds = %assert_end32
  %117 = load i64, i64* %27, align 8, !tbaa !4113
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 2048
  %120 = getelementptr inbounds i64, i64* %27, i64 1
  %121 = load i64, i64* %120, align 8, !tbaa !4127
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %122, 1
  %124 = and i1 %119, %123
  br i1 %124, label %if_end34, label %assert_fail35, !prof !5

if_end34:                                         ; preds = %assert_end32, %if_then33
  %125 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end38, label %assert_fail37, !prof !5

assert_fail35:                                    ; preds = %if_then33
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([125 x i8], [125 x i8]* @.str.344, i64 0, i64 0))
  ret i32 -1

assert_fail37:                                    ; preds = %if_end34
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %if_end34
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 1
  br i1 %132, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %135 = load i32, i32* %134, align 4
  %136 = icmp eq i32 %21, %135
  br i1 %136, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %137 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %137(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  tail call fastcc void @fused_layout_transform_transpose_nn_batch_flatten_compute_(i8* %23, i8* %13)
  ret i32 0
}

; Function Attrs: noinline norecurse nounwind
define private fastcc void @fused_layout_transform_transpose_nn_batch_flatten_compute_(i8* noalias nocapture, i8* noalias nocapture readonly) unnamed_addr #4 {
entry:
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %0, i8* align 4 %1, i64 8192, i1 false)
  ret void
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 6
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.345, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !4129
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !4143
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !4146
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !4148
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !4152
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([182 x i8], [182 x i8]* @.str.346, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %77 = getelementptr inbounds i8, i8* %1, i64 4
  %78 = bitcast i8* %77 to i32*
  %79 = load i32, i32* %78, align 4, !tbaa !4154
  switch i32 %79, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([182 x i8], [182 x i8]* @.str.347, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %81 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %81(i8* getelementptr inbounds ([182 x i8], [182 x i8]* @.str.348, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([182 x i8], [182 x i8]* @.str.349, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %83 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %83(i8* getelementptr inbounds ([182 x i8], [182 x i8]* @.str.350, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([182 x i8], [182 x i8]* @.str.351, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  %85 = icmp eq i32 %43, 1
  br i1 %85, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %86 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %86(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %87 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %88 = load i32, i32* %87, align 4
  %89 = icmp eq i32 %88, 5
  br i1 %89, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %91 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %92 = load i16, i16* %91, align 2
  %93 = icmp eq i16 %92, 1
  %94 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %95 = load i8, i8* %94, align 1
  %96 = icmp eq i8 %95, 32
  %97 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %98 = load i8, i8* %97, align 1
  %99 = icmp eq i8 %98, 2
  %100 = and i1 %96, %99
  %101 = and i1 %93, %100
  br i1 %101, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %103 = load i64, i64* %39, align 8, !tbaa !4156
  %104 = trunc i64 %103 to i32
  %105 = icmp eq i32 %104, 1
  br i1 %105, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %107 = getelementptr inbounds i64, i64* %39, i64 1
  %108 = load i64, i64* %107, align 8, !tbaa !4170
  %109 = trunc i64 %108 to i32
  %110 = icmp eq i32 %109, 1
  br i1 %110, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %111 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %111(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %112 = getelementptr inbounds i64, i64* %39, i64 2
  %113 = load i64, i64* %112, align 8, !tbaa !4172
  %114 = trunc i64 %113 to i32
  %115 = icmp eq i32 %114, 230
  br i1 %115, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %116 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %116(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.352, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %117 = getelementptr inbounds i64, i64* %39, i64 3
  %118 = load i64, i64* %117, align 8, !tbaa !4175
  %119 = trunc i64 %118 to i32
  %120 = icmp eq i32 %119, 230
  br i1 %120, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %121 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %121(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.353, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %122 = getelementptr inbounds i64, i64* %39, i64 4
  %123 = load i64, i64* %122, align 8, !tbaa !4177
  %124 = trunc i64 %123 to i32
  %125 = icmp eq i32 %124, 3
  br i1 %125, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %126 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %126(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.354, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %127 = icmp eq i64* %41, null
  br i1 %127, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end28
  %128 = bitcast i64* %41 to <4 x i64>*
  %129 = load <4 x i64>, <4 x i64>* %128, align 8, !tbaa !4181
  %130 = trunc <4 x i64> %129 to <4 x i32>
  %131 = icmp eq <4 x i32> %130, <i32 158700, i32 158700, i32 690, i32 3>
  %132 = getelementptr inbounds i64, i64* %41, i64 4
  %133 = load i64, i64* %132, align 8, !tbaa !4193
  %134 = trunc i64 %133 to i32
  %135 = icmp eq i32 %134, 1
  %rdx.shuf167 = shufflevector <4 x i1> %131, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx168 = and <4 x i1> %131, %rdx.shuf167
  %rdx.shuf169 = shufflevector <4 x i1> %bin.rdx168, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx170 = and <4 x i1> %bin.rdx168, %rdx.shuf169
  %136 = extractelement <4 x i1> %bin.rdx170, i32 0
  %137 = and i1 %136, %135
  br i1 %137, label %if_end, label %assert_fail29, !prof !5

if_end:                                           ; preds = %assert_end28, %if_then
  %138 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %139 = load i64, i64* %138, align 8
  %140 = icmp eq i64 %139, 0
  br i1 %140, label %assert_end32, label %assert_fail31, !prof !5

assert_fail29:                                    ; preds = %if_then
  %141 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %141(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.355, i64 0, i64 0))
  ret i32 -1

assert_fail31:                                    ; preds = %if_end
  %142 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %142(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %if_end
  %143 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %144 = load i32, i32* %143, align 4
  %145 = icmp eq i32 %144, 6
  br i1 %145, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %148 = load i16, i16* %147, align 2
  %149 = icmp eq i16 %148, 1
  %150 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %151 = load i8, i8* %150, align 1
  %152 = icmp eq i8 %151, 32
  %153 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %154 = load i8, i8* %153, align 1
  %155 = icmp eq i8 %154, 2
  %156 = and i1 %152, %155
  %157 = and i1 %149, %156
  br i1 %157, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %159 = load i64, i64* %49, align 8, !tbaa !4197
  %160 = trunc i64 %159 to i32
  %161 = icmp eq i32 %160, 8
  br i1 %161, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %162 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %162(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.190, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %163 = getelementptr inbounds i64, i64* %49, i64 1
  %164 = load i64, i64* %163, align 8, !tbaa !4211
  %165 = trunc i64 %164 to i32
  %166 = icmp eq i32 %165, 1
  br i1 %166, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %167 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %167(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %168 = getelementptr inbounds i64, i64* %49, i64 2
  %169 = load i64, i64* %168, align 8, !tbaa !4213
  %170 = trunc i64 %169 to i32
  %171 = icmp eq i32 %170, 7
  br i1 %171, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %172 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %172(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.326, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %173 = getelementptr inbounds i64, i64* %49, i64 3
  %174 = load i64, i64* %173, align 8, !tbaa !4216
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 7
  br i1 %176, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %177 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %177(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.327, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %178 = getelementptr inbounds i64, i64* %49, i64 4
  %179 = load i64, i64* %178, align 8, !tbaa !4218
  %180 = trunc i64 %179 to i32
  %181 = icmp eq i32 %180, 3
  br i1 %181, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %182 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %182(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.356, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %183 = getelementptr inbounds i64, i64* %49, i64 5
  %184 = load i64, i64* %183, align 8, !tbaa !4222
  %185 = trunc i64 %184 to i32
  %186 = icmp eq i32 %185, 8
  br i1 %186, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %187 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %187(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.357, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %188 = icmp eq i64* %51, null
  br i1 %188, label %if_end50, label %if_then49, !prof !50

if_then49:                                        ; preds = %assert_end48
  %189 = bitcast i64* %51 to <4 x i64>*
  %190 = load <4 x i64>, <4 x i64>* %189, align 8, !tbaa !4224
  %191 = trunc <4 x i64> %190 to <4 x i32>
  %192 = icmp eq <4 x i32> %191, <i32 1176, i32 1176, i32 168, i32 24>
  %193 = getelementptr inbounds i64, i64* %51, i64 4
  %194 = load i64, i64* %193, align 8, !tbaa !4236
  %195 = trunc i64 %194 to i32
  %196 = icmp eq i32 %195, 8
  %197 = getelementptr inbounds i64, i64* %51, i64 5
  %198 = load i64, i64* %197, align 8, !tbaa !4240
  %199 = trunc i64 %198 to i32
  %200 = icmp eq i32 %199, 1
  %rdx.shuf163 = shufflevector <4 x i1> %192, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx164 = and <4 x i1> %192, %rdx.shuf163
  %rdx.shuf165 = shufflevector <4 x i1> %bin.rdx164, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx166 = and <4 x i1> %bin.rdx164, %rdx.shuf165
  %201 = extractelement <4 x i1> %bin.rdx166, i32 0
  %202 = and i1 %201, %196
  %203 = and i1 %202, %200
  br i1 %203, label %if_end50, label %assert_fail51, !prof !5

if_end50:                                         ; preds = %assert_end48, %if_then49
  %204 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %205 = load i64, i64* %204, align 8
  %206 = icmp eq i64 %205, 0
  br i1 %206, label %assert_end54, label %assert_fail53, !prof !5

assert_fail51:                                    ; preds = %if_then49
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([271 x i8], [271 x i8]* @.str.358, i64 0, i64 0))
  ret i32 -1

assert_fail53:                                    ; preds = %if_end50
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %if_end50
  %209 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %210 = load i32, i32* %209, align 4
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %213 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %214 = load i32, i32* %213, align 4
  %215 = icmp eq i32 %45, %214
  br i1 %215, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %216 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %216(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %217 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %218 = load i32, i32* %217, align 4
  %219 = icmp eq i32 %218, 4
  br i1 %219, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %221 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %222 = load i16, i16* %221, align 2
  %223 = icmp eq i16 %222, 1
  %224 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %225 = load i8, i8* %224, align 1
  %226 = icmp eq i8 %225, 32
  %227 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %228 = load i8, i8* %227, align 1
  %229 = icmp eq i8 %228, 2
  %230 = and i1 %226, %229
  %231 = and i1 %223, %230
  br i1 %231, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %233 = load i64, i64* %55, align 8, !tbaa !4242
  %234 = trunc i64 %233 to i32
  %235 = icmp eq i32 %234, 8
  br i1 %235, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %236 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %236(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.192, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %237 = getelementptr inbounds i64, i64* %55, i64 1
  %238 = load i64, i64* %237, align 8, !tbaa !4256
  %239 = trunc i64 %238 to i32
  %240 = icmp eq i32 %239, 1
  br i1 %240, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %241 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %241(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %242 = getelementptr inbounds i64, i64* %55, i64 2
  %243 = load i64, i64* %242, align 8, !tbaa !4258
  %244 = trunc i64 %243 to i32
  %245 = icmp eq i32 %244, 1
  br i1 %245, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %246 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %246(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %247 = getelementptr inbounds i64, i64* %55, i64 3
  %248 = load i64, i64* %247, align 8, !tbaa !4261
  %249 = trunc i64 %248 to i32
  %250 = icmp eq i32 %249, 8
  br i1 %250, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %251 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %251(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.359, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %252 = icmp eq i64* %57, null
  br i1 %252, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %253 = bitcast i64* %57 to <4 x i64>*
  %254 = load <4 x i64>, <4 x i64>* %253, align 8, !tbaa !4263
  %255 = trunc <4 x i64> %254 to <4 x i32>
  %256 = icmp eq <4 x i32> %255, <i32 8, i32 8, i32 8, i32 1>
  %rdx.shuf159 = shufflevector <4 x i1> %256, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx160 = and <4 x i1> %256, %rdx.shuf159
  %rdx.shuf161 = shufflevector <4 x i1> %bin.rdx160, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx162 = and <4 x i1> %bin.rdx160, %rdx.shuf161
  %257 = extractelement <4 x i1> %bin.rdx162, i32 0
  br i1 %257, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %258 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %259 = load i64, i64* %258, align 8
  %260 = icmp eq i64 %259, 0
  br i1 %260, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([192 x i8], [192 x i8]* @.str.360, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %262 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %262(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %263 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %264 = load i32, i32* %263, align 4
  %265 = icmp eq i32 %264, 1
  br i1 %265, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %266 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %266(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %267 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %268 = load i32, i32* %267, align 4
  %269 = icmp eq i32 %45, %268
  br i1 %269, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %270 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %270(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %271 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %272 = load i32, i32* %271, align 4
  %273 = icmp eq i32 %272, 4
  br i1 %273, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %275 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %276 = load i16, i16* %275, align 2
  %277 = icmp eq i16 %276, 1
  %278 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %279 = load i8, i8* %278, align 1
  %280 = icmp eq i8 %279, 32
  %281 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %282 = load i8, i8* %281, align 1
  %283 = icmp eq i8 %282, 2
  %284 = and i1 %280, %283
  %285 = and i1 %277, %284
  br i1 %285, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %287 = load i64, i64* %61, align 8, !tbaa !4275
  %288 = trunc i64 %287 to i32
  %289 = icmp eq i32 %288, 8
  br i1 %289, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %290 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %290(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.193, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %291 = getelementptr inbounds i64, i64* %61, i64 1
  %292 = load i64, i64* %291, align 8, !tbaa !4289
  %293 = trunc i64 %292 to i32
  %294 = icmp eq i32 %293, 1
  br i1 %294, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %295 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %295(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %296 = getelementptr inbounds i64, i64* %61, i64 2
  %297 = load i64, i64* %296, align 8, !tbaa !4291
  %298 = trunc i64 %297 to i32
  %299 = icmp eq i32 %298, 1
  br i1 %299, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %300 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %300(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %301 = getelementptr inbounds i64, i64* %61, i64 3
  %302 = load i64, i64* %301, align 8, !tbaa !4294
  %303 = trunc i64 %302 to i32
  %304 = icmp eq i32 %303, 8
  br i1 %304, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %305 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %305(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.361, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %306 = icmp eq i64* %63, null
  br i1 %306, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %307 = bitcast i64* %63 to <4 x i64>*
  %308 = load <4 x i64>, <4 x i64>* %307, align 8, !tbaa !4296
  %309 = trunc <4 x i64> %308 to <4 x i32>
  %310 = icmp eq <4 x i32> %309, <i32 8, i32 8, i32 8, i32 1>
  %rdx.shuf155 = shufflevector <4 x i1> %310, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx156 = and <4 x i1> %310, %rdx.shuf155
  %rdx.shuf157 = shufflevector <4 x i1> %bin.rdx156, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx158 = and <4 x i1> %bin.rdx156, %rdx.shuf157
  %311 = extractelement <4 x i1> %bin.rdx158, i32 0
  br i1 %311, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %312 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %313 = load i64, i64* %312, align 8
  %314 = icmp eq i64 %313, 0
  br i1 %314, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([192 x i8], [192 x i8]* @.str.362, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %317 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %318, 1
  br i1 %319, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %321 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %322 = load i32, i32* %321, align 4
  %323 = icmp eq i32 %45, %322
  br i1 %323, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %325 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %326 = load i32, i32* %325, align 4
  %327 = icmp eq i32 %326, 4
  br i1 %327, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %329 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %330 = load i16, i16* %329, align 2
  %331 = icmp eq i16 %330, 1
  %332 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %333 = load i8, i8* %332, align 1
  %334 = icmp eq i8 %333, 32
  %335 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %336 = load i8, i8* %335, align 1
  %337 = icmp eq i8 %336, 2
  %338 = and i1 %334, %337
  %339 = and i1 %331, %338
  br i1 %339, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %340 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %340(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %341 = load i64, i64* %67, align 8, !tbaa !4308
  %342 = trunc i64 %341 to i32
  %343 = icmp eq i32 %342, 8
  br i1 %343, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %344 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %344(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.194, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %345 = getelementptr inbounds i64, i64* %67, i64 1
  %346 = load i64, i64* %345, align 8, !tbaa !4322
  %347 = trunc i64 %346 to i32
  %348 = icmp eq i32 %347, 1
  br i1 %348, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %350 = getelementptr inbounds i64, i64* %67, i64 2
  %351 = load i64, i64* %350, align 8, !tbaa !4324
  %352 = trunc i64 %351 to i32
  %353 = icmp eq i32 %352, 1
  br i1 %353, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %354 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %354(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %355 = getelementptr inbounds i64, i64* %67, i64 3
  %356 = load i64, i64* %355, align 8, !tbaa !4327
  %357 = trunc i64 %356 to i32
  %358 = icmp eq i32 %357, 8
  br i1 %358, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %359 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %359(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.363, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %360 = icmp eq i64* %69, null
  br i1 %360, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %361 = bitcast i64* %69 to <4 x i64>*
  %362 = load <4 x i64>, <4 x i64>* %361, align 8, !tbaa !4329
  %363 = trunc <4 x i64> %362 to <4 x i32>
  %364 = icmp eq <4 x i32> %363, <i32 8, i32 8, i32 8, i32 1>
  %rdx.shuf151 = shufflevector <4 x i1> %364, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx152 = and <4 x i1> %364, %rdx.shuf151
  %rdx.shuf153 = shufflevector <4 x i1> %bin.rdx152, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx154 = and <4 x i1> %bin.rdx152, %rdx.shuf153
  %365 = extractelement <4 x i1> %bin.rdx154, i32 0
  br i1 %365, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %366 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %367 = load i64, i64* %366, align 8
  %368 = icmp eq i64 %367, 0
  br i1 %368, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %369 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %369(i8* getelementptr inbounds ([192 x i8], [192 x i8]* @.str.364, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %370 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %370(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %371 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %372 = load i32, i32* %371, align 4
  %373 = icmp eq i32 %372, 1
  br i1 %373, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %374 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %374(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %375 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %376 = load i32, i32* %375, align 4
  %377 = icmp eq i32 %45, %376
  br i1 %377, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %378 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %378(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %379 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %380 = load i32, i32* %379, align 4
  %381 = icmp eq i32 %380, 5
  br i1 %381, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %383 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %384 = load i16, i16* %383, align 2
  %385 = icmp eq i16 %384, 1
  %386 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %387 = load i8, i8* %386, align 1
  %388 = icmp eq i8 %387, 32
  %389 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %390 = load i8, i8* %389, align 1
  %391 = icmp eq i8 %390, 2
  %392 = and i1 %388, %391
  %393 = and i1 %385, %392
  br i1 %393, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %394 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %394(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %395 = load i64, i64* %73, align 8, !tbaa !4341
  %396 = trunc i64 %395 to i32
  %397 = icmp eq i32 %396, 1
  br i1 %397, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %398 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %398(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %399 = getelementptr inbounds i64, i64* %73, i64 1
  %400 = load i64, i64* %399, align 8, !tbaa !4355
  %401 = trunc i64 %400 to i32
  %402 = icmp eq i32 %401, 8
  br i1 %402, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %403 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %403(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.195, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %404 = getelementptr inbounds i64, i64* %73, i64 2
  %405 = load i64, i64* %404, align 8, !tbaa !4357
  %406 = trunc i64 %405 to i32
  %407 = icmp eq i32 %406, 112
  br i1 %407, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %408 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %408(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.365, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %409 = getelementptr inbounds i64, i64* %73, i64 3
  %410 = load i64, i64* %409, align 8, !tbaa !4360
  %411 = trunc i64 %410 to i32
  %412 = icmp eq i32 %411, 112
  br i1 %412, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %413 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %413(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.366, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %414 = getelementptr inbounds i64, i64* %73, i64 4
  %415 = load i64, i64* %414, align 8, !tbaa !4362
  %416 = trunc i64 %415 to i32
  %417 = icmp eq i32 %416, 8
  br i1 %417, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %418 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %418(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.367, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %419 = icmp eq i64* %75, null
  br i1 %419, label %if_end140, label %if_then139, !prof !50

if_then139:                                       ; preds = %assert_end138
  %420 = bitcast i64* %75 to <4 x i64>*
  %421 = load <4 x i64>, <4 x i64>* %420, align 8, !tbaa !4366
  %422 = trunc <4 x i64> %421 to <4 x i32>
  %423 = icmp eq <4 x i32> %422, <i32 802816, i32 100352, i32 896, i32 8>
  %424 = getelementptr inbounds i64, i64* %75, i64 4
  %425 = load i64, i64* %424, align 8, !tbaa !4378
  %426 = trunc i64 %425 to i32
  %427 = icmp eq i32 %426, 1
  %rdx.shuf = shufflevector <4 x i1> %423, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %423, %rdx.shuf
  %rdx.shuf149 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx150 = and <4 x i1> %bin.rdx, %rdx.shuf149
  %428 = extractelement <4 x i1> %bin.rdx150, i32 0
  %429 = and i1 %428, %427
  br i1 %429, label %if_end140, label %assert_fail141, !prof !5

if_end140:                                        ; preds = %assert_end138, %if_then139
  %430 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %431 = load i64, i64* %430, align 8
  %432 = icmp eq i64 %431, 0
  br i1 %432, label %assert_end144, label %assert_fail143, !prof !5

assert_fail141:                                   ; preds = %if_then139
  %433 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %433(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.368, i64 0, i64 0))
  ret i32 -1

assert_fail143:                                   ; preds = %if_end140
  %434 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %434(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end144:                                    ; preds = %if_end140
  %435 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %436 = load i32, i32* %435, align 4
  %437 = icmp eq i32 %436, 1
  br i1 %437, label %assert_end146, label %assert_fail145, !prof !5

assert_fail145:                                   ; preds = %assert_end144
  %438 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %438(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %assert_end144
  %439 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %440 = load i32, i32* %439, align 4
  %441 = icmp eq i32 %45, %440
  br i1 %441, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %442 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %442(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %443 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_compute_(i8* %37, i8* %47, i8* %71, i8* %53, i8* %59, i8* %65, i32 %45)
  ret i32 %443
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %28, align 8
  %8 = getelementptr inbounds %28, %28* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %28, %28* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %28, %28* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %28, %28* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %28, %28* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %28, %28* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %28, %28* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %28* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.369, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.369(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [28 x <8 x float>], align 16
  %.sub = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0
  %4 = bitcast i8* %2 to float**
  %5 = load float*, float** %4, align 8
  %6 = getelementptr inbounds i8, i8* %2, i64 8
  %7 = bitcast i8* %6 to float**
  %8 = load float*, float** %7, align 8
  %9 = getelementptr inbounds i8, i8* %2, i64 16
  %10 = bitcast i8* %9 to float**
  %11 = load float*, float** %10, align 8
  %12 = getelementptr inbounds i8, i8* %2, i64 24
  %13 = bitcast i8* %12 to float**
  %14 = load float*, float** %13, align 8
  %15 = getelementptr inbounds i8, i8* %2, i64 32
  %16 = bitcast i8* %15 to float**
  %17 = load float*, float** %16, align 8
  %18 = getelementptr inbounds i8, i8* %2, i64 40
  %19 = bitcast i8* %18 to float**
  %20 = load float*, float** %19, align 8
  %21 = getelementptr inbounds i8, i8* %2, i64 48
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %25 = load i32, i32* %24, align 4
  %26 = add nsw i32 %25, 895
  %27 = sdiv i32 %26, %25
  %28 = add nsw i32 %0, 1
  %29 = mul nsw i32 %27, %28
  %30 = icmp slt i32 %29, 896
  %31 = select i1 %30, i32 %29, i32 896
  %32 = mul nsw i32 %27, %0
  %33 = icmp slt i32 %32, 896
  %34 = select i1 %33, i32 %32, i32 896
  %35 = icmp slt i32 %34, %31
  br i1 %35, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %36 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 8
  %37 = bitcast float* %36 to <8 x float>*
  %38 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 16
  %39 = bitcast float* %38 to <8 x float>*
  %40 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 24
  %41 = bitcast float* %40 to <8 x float>*
  %42 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 32
  %43 = bitcast float* %42 to <8 x float>*
  %44 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 40
  %45 = bitcast float* %44 to <8 x float>*
  %46 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 48
  %47 = bitcast float* %46 to <8 x float>*
  %48 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 56
  %49 = bitcast float* %48 to <8 x float>*
  %50 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 64
  %51 = bitcast float* %50 to <8 x float>*
  %52 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 72
  %53 = bitcast float* %52 to <8 x float>*
  %54 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 80
  %55 = bitcast float* %54 to <8 x float>*
  %56 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 88
  %57 = bitcast float* %56 to <8 x float>*
  %58 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 96
  %59 = bitcast float* %58 to <8 x float>*
  %60 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 104
  %61 = bitcast float* %60 to <8 x float>*
  %62 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 112
  %63 = bitcast float* %62 to <8 x float>*
  %64 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 120
  %65 = bitcast float* %64 to <8 x float>*
  %66 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 128
  %67 = bitcast float* %66 to <8 x float>*
  %68 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 136
  %69 = bitcast float* %68 to <8 x float>*
  %70 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 144
  %71 = bitcast float* %70 to <8 x float>*
  %72 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 152
  %73 = bitcast float* %72 to <8 x float>*
  %74 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 160
  %75 = bitcast float* %74 to <8 x float>*
  %76 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 168
  %77 = bitcast float* %76 to <8 x float>*
  %78 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 176
  %79 = bitcast float* %78 to <8 x float>*
  %80 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 184
  %81 = bitcast float* %80 to <8 x float>*
  %82 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 192
  %83 = bitcast float* %82 to <8 x float>*
  %84 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 200
  %85 = bitcast float* %84 to <8 x float>*
  %86 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 208
  %87 = bitcast float* %86 to <8 x float>*
  %88 = getelementptr inbounds [28 x <8 x float>], [28 x <8 x float>]* %3, i64 0, i64 0, i64 216
  %89 = bitcast float* %88 to <8 x float>*
  %90 = bitcast [28 x <8 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end21.3
  %91 = phi i32 [ %34, %for_body.lr.ph ], [ %762, %for_end21.3 ]
  %92 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %93 = tail call i8* %92(i32 1, i32 %23, i64 3584, i32 2, i32 32)
  %94 = srem i32 %91, 112
  %95 = mul nsw i32 %94, 1380
  %96 = sdiv i32 %91, 112
  %97 = mul nsw i32 %96, 1176
  %98 = bitcast i8* %93 to float*
  %99 = sext i32 %97 to i64
  %100 = sext i32 %95 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end21.3, %entry
  ret i32 0

for_begin16.preheader:                            ; preds = %for_begin13.preheader
  %101 = mul nsw i32 %91, 896
  %102 = shl nsw i32 %96, 3
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %14, i64 %103
  %105 = bitcast float* %104 to <8 x float>*
  %106 = load <8 x float>, <8 x float>* %105, align 32, !tbaa !4382
  %107 = getelementptr inbounds float, float* %17, i64 %103
  %108 = bitcast float* %107 to <8 x float>*
  %109 = load <8 x float>, <8 x float>* %108, align 32, !tbaa !4385
  %110 = getelementptr inbounds float, float* %20, i64 %103
  %111 = bitcast float* %110 to <8 x float>*
  %112 = load <8 x float>, <8 x float>* %111, align 32, !tbaa !4388
  %113 = bitcast i8* %93 to <8 x float>*
  %114 = load <8 x float>, <8 x float>* %113, align 32, !tbaa !4391
  %115 = fadd <8 x float> %106, %114
  %116 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %115, <8 x float> %109, <8 x float> %112)
  %117 = fcmp ogt <8 x float> %116, zeroinitializer
  %118 = select <8 x i1> %117, <8 x float> %116, <8 x float> zeroinitializer
  %119 = sext i32 %101 to i64
  %120 = getelementptr inbounds float, float* %11, i64 %119
  %121 = bitcast float* %120 to <8 x float>*
  store <8 x float> %118, <8 x float>* %121, align 32, !tbaa !4394
  %122 = or i32 %101, 8
  %123 = getelementptr inbounds i8, i8* %93, i64 32
  %124 = bitcast i8* %123 to <8 x float>*
  %125 = load <8 x float>, <8 x float>* %124, align 32, !tbaa !4391
  %126 = fadd <8 x float> %106, %125
  %127 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %126, <8 x float> %109, <8 x float> %112)
  %128 = fcmp ogt <8 x float> %127, zeroinitializer
  %129 = select <8 x i1> %128, <8 x float> %127, <8 x float> zeroinitializer
  %130 = sext i32 %122 to i64
  %131 = getelementptr inbounds float, float* %11, i64 %130
  %132 = bitcast float* %131 to <8 x float>*
  store <8 x float> %129, <8 x float>* %132, align 32, !tbaa !4394
  %133 = or i32 %101, 16
  %134 = getelementptr inbounds i8, i8* %93, i64 64
  %135 = bitcast i8* %134 to <8 x float>*
  %136 = load <8 x float>, <8 x float>* %135, align 32, !tbaa !4391
  %137 = fadd <8 x float> %106, %136
  %138 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %137, <8 x float> %109, <8 x float> %112)
  %139 = fcmp ogt <8 x float> %138, zeroinitializer
  %140 = select <8 x i1> %139, <8 x float> %138, <8 x float> zeroinitializer
  %141 = sext i32 %133 to i64
  %142 = getelementptr inbounds float, float* %11, i64 %141
  %143 = bitcast float* %142 to <8 x float>*
  store <8 x float> %140, <8 x float>* %143, align 32, !tbaa !4394
  %144 = or i32 %101, 24
  %145 = getelementptr inbounds i8, i8* %93, i64 96
  %146 = bitcast i8* %145 to <8 x float>*
  %147 = load <8 x float>, <8 x float>* %146, align 32, !tbaa !4391
  %148 = fadd <8 x float> %106, %147
  %149 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %148, <8 x float> %109, <8 x float> %112)
  %150 = fcmp ogt <8 x float> %149, zeroinitializer
  %151 = select <8 x i1> %150, <8 x float> %149, <8 x float> zeroinitializer
  %152 = sext i32 %144 to i64
  %153 = getelementptr inbounds float, float* %11, i64 %152
  %154 = bitcast float* %153 to <8 x float>*
  store <8 x float> %151, <8 x float>* %154, align 32, !tbaa !4394
  %155 = or i32 %101, 32
  %156 = getelementptr inbounds i8, i8* %93, i64 128
  %157 = bitcast i8* %156 to <8 x float>*
  %158 = load <8 x float>, <8 x float>* %157, align 32, !tbaa !4391
  %159 = fadd <8 x float> %106, %158
  %160 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %159, <8 x float> %109, <8 x float> %112)
  %161 = fcmp ogt <8 x float> %160, zeroinitializer
  %162 = select <8 x i1> %161, <8 x float> %160, <8 x float> zeroinitializer
  %163 = sext i32 %155 to i64
  %164 = getelementptr inbounds float, float* %11, i64 %163
  %165 = bitcast float* %164 to <8 x float>*
  store <8 x float> %162, <8 x float>* %165, align 32, !tbaa !4394
  %166 = or i32 %101, 40
  %167 = getelementptr inbounds i8, i8* %93, i64 160
  %168 = bitcast i8* %167 to <8 x float>*
  %169 = load <8 x float>, <8 x float>* %168, align 32, !tbaa !4391
  %170 = fadd <8 x float> %106, %169
  %171 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %170, <8 x float> %109, <8 x float> %112)
  %172 = fcmp ogt <8 x float> %171, zeroinitializer
  %173 = select <8 x i1> %172, <8 x float> %171, <8 x float> zeroinitializer
  %174 = sext i32 %166 to i64
  %175 = getelementptr inbounds float, float* %11, i64 %174
  %176 = bitcast float* %175 to <8 x float>*
  store <8 x float> %173, <8 x float>* %176, align 32, !tbaa !4394
  %177 = or i32 %101, 48
  %178 = getelementptr inbounds i8, i8* %93, i64 192
  %179 = bitcast i8* %178 to <8 x float>*
  %180 = load <8 x float>, <8 x float>* %179, align 32, !tbaa !4391
  %181 = fadd <8 x float> %106, %180
  %182 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %181, <8 x float> %109, <8 x float> %112)
  %183 = fcmp ogt <8 x float> %182, zeroinitializer
  %184 = select <8 x i1> %183, <8 x float> %182, <8 x float> zeroinitializer
  %185 = sext i32 %177 to i64
  %186 = getelementptr inbounds float, float* %11, i64 %185
  %187 = bitcast float* %186 to <8 x float>*
  store <8 x float> %184, <8 x float>* %187, align 32, !tbaa !4394
  %188 = or i32 %101, 56
  %189 = getelementptr inbounds i8, i8* %93, i64 224
  %190 = bitcast i8* %189 to <8 x float>*
  %191 = load <8 x float>, <8 x float>* %190, align 32, !tbaa !4391
  %192 = fadd <8 x float> %106, %191
  %193 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %192, <8 x float> %109, <8 x float> %112)
  %194 = fcmp ogt <8 x float> %193, zeroinitializer
  %195 = select <8 x i1> %194, <8 x float> %193, <8 x float> zeroinitializer
  %196 = sext i32 %188 to i64
  %197 = getelementptr inbounds float, float* %11, i64 %196
  %198 = bitcast float* %197 to <8 x float>*
  store <8 x float> %195, <8 x float>* %198, align 32, !tbaa !4394
  %199 = or i32 %101, 64
  %200 = getelementptr inbounds i8, i8* %93, i64 256
  %201 = bitcast i8* %200 to <8 x float>*
  %202 = load <8 x float>, <8 x float>* %201, align 32, !tbaa !4391
  %203 = fadd <8 x float> %106, %202
  %204 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %203, <8 x float> %109, <8 x float> %112)
  %205 = fcmp ogt <8 x float> %204, zeroinitializer
  %206 = select <8 x i1> %205, <8 x float> %204, <8 x float> zeroinitializer
  %207 = sext i32 %199 to i64
  %208 = getelementptr inbounds float, float* %11, i64 %207
  %209 = bitcast float* %208 to <8 x float>*
  store <8 x float> %206, <8 x float>* %209, align 32, !tbaa !4394
  %210 = or i32 %101, 72
  %211 = getelementptr inbounds i8, i8* %93, i64 288
  %212 = bitcast i8* %211 to <8 x float>*
  %213 = load <8 x float>, <8 x float>* %212, align 32, !tbaa !4391
  %214 = fadd <8 x float> %106, %213
  %215 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %214, <8 x float> %109, <8 x float> %112)
  %216 = fcmp ogt <8 x float> %215, zeroinitializer
  %217 = select <8 x i1> %216, <8 x float> %215, <8 x float> zeroinitializer
  %218 = sext i32 %210 to i64
  %219 = getelementptr inbounds float, float* %11, i64 %218
  %220 = bitcast float* %219 to <8 x float>*
  store <8 x float> %217, <8 x float>* %220, align 32, !tbaa !4394
  %221 = or i32 %101, 80
  %222 = getelementptr inbounds i8, i8* %93, i64 320
  %223 = bitcast i8* %222 to <8 x float>*
  %224 = load <8 x float>, <8 x float>* %223, align 32, !tbaa !4391
  %225 = fadd <8 x float> %106, %224
  %226 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %225, <8 x float> %109, <8 x float> %112)
  %227 = fcmp ogt <8 x float> %226, zeroinitializer
  %228 = select <8 x i1> %227, <8 x float> %226, <8 x float> zeroinitializer
  %229 = sext i32 %221 to i64
  %230 = getelementptr inbounds float, float* %11, i64 %229
  %231 = bitcast float* %230 to <8 x float>*
  store <8 x float> %228, <8 x float>* %231, align 32, !tbaa !4394
  %232 = or i32 %101, 88
  %233 = getelementptr inbounds i8, i8* %93, i64 352
  %234 = bitcast i8* %233 to <8 x float>*
  %235 = load <8 x float>, <8 x float>* %234, align 32, !tbaa !4391
  %236 = fadd <8 x float> %106, %235
  %237 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %236, <8 x float> %109, <8 x float> %112)
  %238 = fcmp ogt <8 x float> %237, zeroinitializer
  %239 = select <8 x i1> %238, <8 x float> %237, <8 x float> zeroinitializer
  %240 = sext i32 %232 to i64
  %241 = getelementptr inbounds float, float* %11, i64 %240
  %242 = bitcast float* %241 to <8 x float>*
  store <8 x float> %239, <8 x float>* %242, align 32, !tbaa !4394
  %243 = or i32 %101, 96
  %244 = getelementptr inbounds i8, i8* %93, i64 384
  %245 = bitcast i8* %244 to <8 x float>*
  %246 = load <8 x float>, <8 x float>* %245, align 32, !tbaa !4391
  %247 = fadd <8 x float> %106, %246
  %248 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %247, <8 x float> %109, <8 x float> %112)
  %249 = fcmp ogt <8 x float> %248, zeroinitializer
  %250 = select <8 x i1> %249, <8 x float> %248, <8 x float> zeroinitializer
  %251 = sext i32 %243 to i64
  %252 = getelementptr inbounds float, float* %11, i64 %251
  %253 = bitcast float* %252 to <8 x float>*
  store <8 x float> %250, <8 x float>* %253, align 32, !tbaa !4394
  %254 = or i32 %101, 104
  %255 = getelementptr inbounds i8, i8* %93, i64 416
  %256 = bitcast i8* %255 to <8 x float>*
  %257 = load <8 x float>, <8 x float>* %256, align 32, !tbaa !4391
  %258 = fadd <8 x float> %106, %257
  %259 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %258, <8 x float> %109, <8 x float> %112)
  %260 = fcmp ogt <8 x float> %259, zeroinitializer
  %261 = select <8 x i1> %260, <8 x float> %259, <8 x float> zeroinitializer
  %262 = sext i32 %254 to i64
  %263 = getelementptr inbounds float, float* %11, i64 %262
  %264 = bitcast float* %263 to <8 x float>*
  store <8 x float> %261, <8 x float>* %264, align 32, !tbaa !4394
  %265 = or i32 %101, 112
  %266 = getelementptr inbounds i8, i8* %93, i64 448
  %267 = bitcast i8* %266 to <8 x float>*
  %268 = load <8 x float>, <8 x float>* %267, align 32, !tbaa !4391
  %269 = fadd <8 x float> %106, %268
  %270 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %269, <8 x float> %109, <8 x float> %112)
  %271 = fcmp ogt <8 x float> %270, zeroinitializer
  %272 = select <8 x i1> %271, <8 x float> %270, <8 x float> zeroinitializer
  %273 = sext i32 %265 to i64
  %274 = getelementptr inbounds float, float* %11, i64 %273
  %275 = bitcast float* %274 to <8 x float>*
  store <8 x float> %272, <8 x float>* %275, align 32, !tbaa !4394
  %276 = or i32 %101, 120
  %277 = getelementptr inbounds i8, i8* %93, i64 480
  %278 = bitcast i8* %277 to <8 x float>*
  %279 = load <8 x float>, <8 x float>* %278, align 32, !tbaa !4391
  %280 = fadd <8 x float> %106, %279
  %281 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %280, <8 x float> %109, <8 x float> %112)
  %282 = fcmp ogt <8 x float> %281, zeroinitializer
  %283 = select <8 x i1> %282, <8 x float> %281, <8 x float> zeroinitializer
  %284 = sext i32 %276 to i64
  %285 = getelementptr inbounds float, float* %11, i64 %284
  %286 = bitcast float* %285 to <8 x float>*
  store <8 x float> %283, <8 x float>* %286, align 32, !tbaa !4394
  %287 = add i32 %101, 128
  %288 = getelementptr inbounds i8, i8* %93, i64 512
  %289 = bitcast i8* %288 to <8 x float>*
  %290 = load <8 x float>, <8 x float>* %289, align 32, !tbaa !4391
  %291 = fadd <8 x float> %106, %290
  %292 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %291, <8 x float> %109, <8 x float> %112)
  %293 = fcmp ogt <8 x float> %292, zeroinitializer
  %294 = select <8 x i1> %293, <8 x float> %292, <8 x float> zeroinitializer
  %295 = sext i32 %287 to i64
  %296 = getelementptr inbounds float, float* %11, i64 %295
  %297 = bitcast float* %296 to <8 x float>*
  store <8 x float> %294, <8 x float>* %297, align 32, !tbaa !4394
  %298 = add i32 %101, 136
  %299 = getelementptr inbounds i8, i8* %93, i64 544
  %300 = bitcast i8* %299 to <8 x float>*
  %301 = load <8 x float>, <8 x float>* %300, align 32, !tbaa !4391
  %302 = fadd <8 x float> %106, %301
  %303 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %302, <8 x float> %109, <8 x float> %112)
  %304 = fcmp ogt <8 x float> %303, zeroinitializer
  %305 = select <8 x i1> %304, <8 x float> %303, <8 x float> zeroinitializer
  %306 = sext i32 %298 to i64
  %307 = getelementptr inbounds float, float* %11, i64 %306
  %308 = bitcast float* %307 to <8 x float>*
  store <8 x float> %305, <8 x float>* %308, align 32, !tbaa !4394
  %309 = add i32 %101, 144
  %310 = getelementptr inbounds i8, i8* %93, i64 576
  %311 = bitcast i8* %310 to <8 x float>*
  %312 = load <8 x float>, <8 x float>* %311, align 32, !tbaa !4391
  %313 = fadd <8 x float> %106, %312
  %314 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %313, <8 x float> %109, <8 x float> %112)
  %315 = fcmp ogt <8 x float> %314, zeroinitializer
  %316 = select <8 x i1> %315, <8 x float> %314, <8 x float> zeroinitializer
  %317 = sext i32 %309 to i64
  %318 = getelementptr inbounds float, float* %11, i64 %317
  %319 = bitcast float* %318 to <8 x float>*
  store <8 x float> %316, <8 x float>* %319, align 32, !tbaa !4394
  %320 = add i32 %101, 152
  %321 = getelementptr inbounds i8, i8* %93, i64 608
  %322 = bitcast i8* %321 to <8 x float>*
  %323 = load <8 x float>, <8 x float>* %322, align 32, !tbaa !4391
  %324 = fadd <8 x float> %106, %323
  %325 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %324, <8 x float> %109, <8 x float> %112)
  %326 = fcmp ogt <8 x float> %325, zeroinitializer
  %327 = select <8 x i1> %326, <8 x float> %325, <8 x float> zeroinitializer
  %328 = sext i32 %320 to i64
  %329 = getelementptr inbounds float, float* %11, i64 %328
  %330 = bitcast float* %329 to <8 x float>*
  store <8 x float> %327, <8 x float>* %330, align 32, !tbaa !4394
  %331 = add i32 %101, 160
  %332 = getelementptr inbounds i8, i8* %93, i64 640
  %333 = bitcast i8* %332 to <8 x float>*
  %334 = load <8 x float>, <8 x float>* %333, align 32, !tbaa !4391
  %335 = fadd <8 x float> %106, %334
  %336 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %335, <8 x float> %109, <8 x float> %112)
  %337 = fcmp ogt <8 x float> %336, zeroinitializer
  %338 = select <8 x i1> %337, <8 x float> %336, <8 x float> zeroinitializer
  %339 = sext i32 %331 to i64
  %340 = getelementptr inbounds float, float* %11, i64 %339
  %341 = bitcast float* %340 to <8 x float>*
  store <8 x float> %338, <8 x float>* %341, align 32, !tbaa !4394
  %342 = add i32 %101, 168
  %343 = getelementptr inbounds i8, i8* %93, i64 672
  %344 = bitcast i8* %343 to <8 x float>*
  %345 = load <8 x float>, <8 x float>* %344, align 32, !tbaa !4391
  %346 = fadd <8 x float> %106, %345
  %347 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %346, <8 x float> %109, <8 x float> %112)
  %348 = fcmp ogt <8 x float> %347, zeroinitializer
  %349 = select <8 x i1> %348, <8 x float> %347, <8 x float> zeroinitializer
  %350 = sext i32 %342 to i64
  %351 = getelementptr inbounds float, float* %11, i64 %350
  %352 = bitcast float* %351 to <8 x float>*
  store <8 x float> %349, <8 x float>* %352, align 32, !tbaa !4394
  %353 = add i32 %101, 176
  %354 = getelementptr inbounds i8, i8* %93, i64 704
  %355 = bitcast i8* %354 to <8 x float>*
  %356 = load <8 x float>, <8 x float>* %355, align 32, !tbaa !4391
  %357 = fadd <8 x float> %106, %356
  %358 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %357, <8 x float> %109, <8 x float> %112)
  %359 = fcmp ogt <8 x float> %358, zeroinitializer
  %360 = select <8 x i1> %359, <8 x float> %358, <8 x float> zeroinitializer
  %361 = sext i32 %353 to i64
  %362 = getelementptr inbounds float, float* %11, i64 %361
  %363 = bitcast float* %362 to <8 x float>*
  store <8 x float> %360, <8 x float>* %363, align 32, !tbaa !4394
  %364 = add i32 %101, 184
  %365 = getelementptr inbounds i8, i8* %93, i64 736
  %366 = bitcast i8* %365 to <8 x float>*
  %367 = load <8 x float>, <8 x float>* %366, align 32, !tbaa !4391
  %368 = fadd <8 x float> %106, %367
  %369 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %368, <8 x float> %109, <8 x float> %112)
  %370 = fcmp ogt <8 x float> %369, zeroinitializer
  %371 = select <8 x i1> %370, <8 x float> %369, <8 x float> zeroinitializer
  %372 = sext i32 %364 to i64
  %373 = getelementptr inbounds float, float* %11, i64 %372
  %374 = bitcast float* %373 to <8 x float>*
  store <8 x float> %371, <8 x float>* %374, align 32, !tbaa !4394
  %375 = add i32 %101, 192
  %376 = getelementptr inbounds i8, i8* %93, i64 768
  %377 = bitcast i8* %376 to <8 x float>*
  %378 = load <8 x float>, <8 x float>* %377, align 32, !tbaa !4391
  %379 = fadd <8 x float> %106, %378
  %380 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %379, <8 x float> %109, <8 x float> %112)
  %381 = fcmp ogt <8 x float> %380, zeroinitializer
  %382 = select <8 x i1> %381, <8 x float> %380, <8 x float> zeroinitializer
  %383 = sext i32 %375 to i64
  %384 = getelementptr inbounds float, float* %11, i64 %383
  %385 = bitcast float* %384 to <8 x float>*
  store <8 x float> %382, <8 x float>* %385, align 32, !tbaa !4394
  %386 = add i32 %101, 200
  %387 = getelementptr inbounds i8, i8* %93, i64 800
  %388 = bitcast i8* %387 to <8 x float>*
  %389 = load <8 x float>, <8 x float>* %388, align 32, !tbaa !4391
  %390 = fadd <8 x float> %106, %389
  %391 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %390, <8 x float> %109, <8 x float> %112)
  %392 = fcmp ogt <8 x float> %391, zeroinitializer
  %393 = select <8 x i1> %392, <8 x float> %391, <8 x float> zeroinitializer
  %394 = sext i32 %386 to i64
  %395 = getelementptr inbounds float, float* %11, i64 %394
  %396 = bitcast float* %395 to <8 x float>*
  store <8 x float> %393, <8 x float>* %396, align 32, !tbaa !4394
  %397 = add i32 %101, 208
  %398 = getelementptr inbounds i8, i8* %93, i64 832
  %399 = bitcast i8* %398 to <8 x float>*
  %400 = load <8 x float>, <8 x float>* %399, align 32, !tbaa !4391
  %401 = fadd <8 x float> %106, %400
  %402 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %401, <8 x float> %109, <8 x float> %112)
  %403 = fcmp ogt <8 x float> %402, zeroinitializer
  %404 = select <8 x i1> %403, <8 x float> %402, <8 x float> zeroinitializer
  %405 = sext i32 %397 to i64
  %406 = getelementptr inbounds float, float* %11, i64 %405
  %407 = bitcast float* %406 to <8 x float>*
  store <8 x float> %404, <8 x float>* %407, align 32, !tbaa !4394
  %408 = add i32 %101, 216
  %409 = getelementptr inbounds i8, i8* %93, i64 864
  %410 = bitcast i8* %409 to <8 x float>*
  %411 = load <8 x float>, <8 x float>* %410, align 32, !tbaa !4391
  %412 = fadd <8 x float> %106, %411
  %413 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %412, <8 x float> %109, <8 x float> %112)
  %414 = fcmp ogt <8 x float> %413, zeroinitializer
  %415 = select <8 x i1> %414, <8 x float> %413, <8 x float> zeroinitializer
  %416 = sext i32 %408 to i64
  %417 = getelementptr inbounds float, float* %11, i64 %416
  %418 = bitcast float* %417 to <8 x float>*
  store <8 x float> %415, <8 x float>* %418, align 32, !tbaa !4394
  br label %for_body20.1

for_body2:                                        ; preds = %for_begin13.preheader, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_begin13.preheader ]
  %419 = mul nuw nsw i64 %indvar, 168
  %420 = add nsw i64 %419, %100
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %90, i8 0, i64 896, i1 false)
  br label %for_begin7.preheader

for_begin13.preheader:                            ; preds = %for_end9
  store <8 x float> %555, <8 x float>* %.sub, align 16, !tbaa !4397
  store <8 x float> %561, <8 x float>* %37, align 16, !tbaa !4397
  store <8 x float> %567, <8 x float>* %39, align 16, !tbaa !4397
  store <8 x float> %573, <8 x float>* %41, align 16, !tbaa !4397
  store <8 x float> %579, <8 x float>* %43, align 16, !tbaa !4397
  store <8 x float> %585, <8 x float>* %45, align 16, !tbaa !4397
  store <8 x float> %591, <8 x float>* %47, align 16, !tbaa !4397
  store <8 x float> %597, <8 x float>* %49, align 16, !tbaa !4397
  store <8 x float> %603, <8 x float>* %51, align 16, !tbaa !4397
  store <8 x float> %609, <8 x float>* %53, align 16, !tbaa !4397
  store <8 x float> %615, <8 x float>* %55, align 16, !tbaa !4397
  store <8 x float> %621, <8 x float>* %57, align 16, !tbaa !4397
  store <8 x float> %627, <8 x float>* %59, align 16, !tbaa !4397
  store <8 x float> %633, <8 x float>* %61, align 16, !tbaa !4397
  store <8 x float> %639, <8 x float>* %63, align 16, !tbaa !4397
  store <8 x float> %645, <8 x float>* %65, align 16, !tbaa !4397
  store <8 x float> %651, <8 x float>* %67, align 16, !tbaa !4397
  store <8 x float> %657, <8 x float>* %69, align 16, !tbaa !4397
  store <8 x float> %663, <8 x float>* %71, align 16, !tbaa !4397
  store <8 x float> %669, <8 x float>* %73, align 16, !tbaa !4397
  store <8 x float> %675, <8 x float>* %75, align 16, !tbaa !4397
  store <8 x float> %681, <8 x float>* %77, align 16, !tbaa !4397
  store <8 x float> %687, <8 x float>* %79, align 16, !tbaa !4397
  store <8 x float> %693, <8 x float>* %81, align 16, !tbaa !4397
  store <8 x float> %699, <8 x float>* %83, align 16, !tbaa !4397
  store <8 x float> %705, <8 x float>* %85, align 16, !tbaa !4397
  store <8 x float> %711, <8 x float>* %87, align 16, !tbaa !4397
  store <8 x float> %717, <8 x float>* %89, align 16, !tbaa !4397
  %421 = mul nuw nsw i64 %indvar, 224
  %422 = getelementptr inbounds float, float* %98, i64 %421
  %423 = bitcast float* %422 to <8 x float>*
  store <8 x float> %555, <8 x float>* %423, align 32, !tbaa !4391
  %424 = or i64 %421, 8
  %425 = getelementptr inbounds float, float* %98, i64 %424
  %426 = bitcast float* %425 to <8 x float>*
  store <8 x float> %561, <8 x float>* %426, align 32, !tbaa !4391
  %427 = or i64 %421, 16
  %428 = getelementptr inbounds float, float* %98, i64 %427
  %429 = bitcast float* %428 to <8 x float>*
  store <8 x float> %567, <8 x float>* %429, align 32, !tbaa !4391
  %430 = or i64 %421, 24
  %431 = getelementptr inbounds float, float* %98, i64 %430
  %432 = bitcast float* %431 to <8 x float>*
  store <8 x float> %573, <8 x float>* %432, align 32, !tbaa !4391
  %433 = add nuw nsw i64 %421, 32
  %434 = getelementptr inbounds float, float* %98, i64 %433
  %435 = bitcast float* %434 to <8 x float>*
  store <8 x float> %579, <8 x float>* %435, align 32, !tbaa !4391
  %436 = add nuw nsw i64 %421, 40
  %437 = getelementptr inbounds float, float* %98, i64 %436
  %438 = bitcast float* %437 to <8 x float>*
  store <8 x float> %585, <8 x float>* %438, align 32, !tbaa !4391
  %439 = add nuw nsw i64 %421, 48
  %440 = getelementptr inbounds float, float* %98, i64 %439
  %441 = bitcast float* %440 to <8 x float>*
  store <8 x float> %591, <8 x float>* %441, align 32, !tbaa !4391
  %442 = add nuw nsw i64 %421, 56
  %443 = getelementptr inbounds float, float* %98, i64 %442
  %444 = bitcast float* %443 to <8 x float>*
  store <8 x float> %597, <8 x float>* %444, align 32, !tbaa !4391
  %445 = add nuw nsw i64 %421, 64
  %446 = getelementptr inbounds float, float* %98, i64 %445
  %447 = bitcast float* %446 to <8 x float>*
  store <8 x float> %603, <8 x float>* %447, align 32, !tbaa !4391
  %448 = add nuw nsw i64 %421, 72
  %449 = getelementptr inbounds float, float* %98, i64 %448
  %450 = bitcast float* %449 to <8 x float>*
  store <8 x float> %609, <8 x float>* %450, align 32, !tbaa !4391
  %451 = add nuw nsw i64 %421, 80
  %452 = getelementptr inbounds float, float* %98, i64 %451
  %453 = bitcast float* %452 to <8 x float>*
  store <8 x float> %615, <8 x float>* %453, align 32, !tbaa !4391
  %454 = add nuw nsw i64 %421, 88
  %455 = getelementptr inbounds float, float* %98, i64 %454
  %456 = bitcast float* %455 to <8 x float>*
  store <8 x float> %621, <8 x float>* %456, align 32, !tbaa !4391
  %457 = add nuw nsw i64 %421, 96
  %458 = getelementptr inbounds float, float* %98, i64 %457
  %459 = bitcast float* %458 to <8 x float>*
  store <8 x float> %627, <8 x float>* %459, align 32, !tbaa !4391
  %460 = add nuw nsw i64 %421, 104
  %461 = getelementptr inbounds float, float* %98, i64 %460
  %462 = bitcast float* %461 to <8 x float>*
  store <8 x float> %633, <8 x float>* %462, align 32, !tbaa !4391
  %463 = add nuw nsw i64 %421, 112
  %464 = getelementptr inbounds float, float* %98, i64 %463
  %465 = bitcast float* %464 to <8 x float>*
  store <8 x float> %639, <8 x float>* %465, align 32, !tbaa !4391
  %466 = add nuw nsw i64 %421, 120
  %467 = getelementptr inbounds float, float* %98, i64 %466
  %468 = bitcast float* %467 to <8 x float>*
  store <8 x float> %645, <8 x float>* %468, align 32, !tbaa !4391
  %469 = add nuw nsw i64 %421, 128
  %470 = getelementptr inbounds float, float* %98, i64 %469
  %471 = bitcast float* %470 to <8 x float>*
  store <8 x float> %651, <8 x float>* %471, align 32, !tbaa !4391
  %472 = add nuw nsw i64 %421, 136
  %473 = getelementptr inbounds float, float* %98, i64 %472
  %474 = bitcast float* %473 to <8 x float>*
  store <8 x float> %657, <8 x float>* %474, align 32, !tbaa !4391
  %475 = add nuw nsw i64 %421, 144
  %476 = getelementptr inbounds float, float* %98, i64 %475
  %477 = bitcast float* %476 to <8 x float>*
  store <8 x float> %663, <8 x float>* %477, align 32, !tbaa !4391
  %478 = add nuw nsw i64 %421, 152
  %479 = getelementptr inbounds float, float* %98, i64 %478
  %480 = bitcast float* %479 to <8 x float>*
  store <8 x float> %669, <8 x float>* %480, align 32, !tbaa !4391
  %481 = add nuw nsw i64 %421, 160
  %482 = getelementptr inbounds float, float* %98, i64 %481
  %483 = bitcast float* %482 to <8 x float>*
  store <8 x float> %675, <8 x float>* %483, align 32, !tbaa !4391
  %484 = add nuw nsw i64 %421, 168
  %485 = getelementptr inbounds float, float* %98, i64 %484
  %486 = bitcast float* %485 to <8 x float>*
  store <8 x float> %681, <8 x float>* %486, align 32, !tbaa !4391
  %487 = add nuw nsw i64 %421, 176
  %488 = getelementptr inbounds float, float* %98, i64 %487
  %489 = bitcast float* %488 to <8 x float>*
  store <8 x float> %687, <8 x float>* %489, align 32, !tbaa !4391
  %490 = add nuw nsw i64 %421, 184
  %491 = getelementptr inbounds float, float* %98, i64 %490
  %492 = bitcast float* %491 to <8 x float>*
  store <8 x float> %693, <8 x float>* %492, align 32, !tbaa !4391
  %493 = add nuw nsw i64 %421, 192
  %494 = load <8 x float>, <8 x float>* %83, align 16, !tbaa !4408
  %495 = getelementptr inbounds float, float* %98, i64 %493
  %496 = bitcast float* %495 to <8 x float>*
  store <8 x float> %494, <8 x float>* %496, align 32, !tbaa !4391
  %497 = add nuw nsw i64 %421, 200
  %498 = load <8 x float>, <8 x float>* %85, align 16, !tbaa !4408
  %499 = getelementptr inbounds float, float* %98, i64 %497
  %500 = bitcast float* %499 to <8 x float>*
  store <8 x float> %498, <8 x float>* %500, align 32, !tbaa !4391
  %501 = add nuw nsw i64 %421, 208
  %502 = load <8 x float>, <8 x float>* %87, align 16, !tbaa !4408
  %503 = getelementptr inbounds float, float* %98, i64 %501
  %504 = bitcast float* %503 to <8 x float>*
  store <8 x float> %502, <8 x float>* %504, align 32, !tbaa !4391
  %505 = add nuw nsw i64 %421, 216
  %506 = load <8 x float>, <8 x float>* %89, align 16, !tbaa !4408
  %507 = getelementptr inbounds float, float* %98, i64 %505
  %508 = bitcast float* %507 to <8 x float>*
  store <8 x float> %506, <8 x float>* %508, align 32, !tbaa !4391
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond226 = icmp eq i64 %indvar.next, 4
  br i1 %exitcond226, label %for_begin16.preheader, label %for_body2, !prof !50

for_begin7.preheader:                             ; preds = %for_end9, %for_body2
  %indvars.iv220 = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next221, %for_end9 ]
  %.lcssa80.lcssa189 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %717, %for_end9 ]
  %.lcssa78.lcssa187 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %711, %for_end9 ]
  %.lcssa76.lcssa185 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %705, %for_end9 ]
  %.lcssa74.lcssa183 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %699, %for_end9 ]
  %.lcssa72.lcssa181 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %693, %for_end9 ]
  %.lcssa70.lcssa179 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %687, %for_end9 ]
  %.lcssa68.lcssa177 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %681, %for_end9 ]
  %.lcssa66.lcssa175 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %675, %for_end9 ]
  %.lcssa64.lcssa173 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %669, %for_end9 ]
  %.lcssa62.lcssa171 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %663, %for_end9 ]
  %.lcssa60.lcssa169 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %657, %for_end9 ]
  %.lcssa58.lcssa167 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %651, %for_end9 ]
  %.lcssa56.lcssa165 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %645, %for_end9 ]
  %.lcssa54.lcssa163 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %639, %for_end9 ]
  %.lcssa52.lcssa161 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %633, %for_end9 ]
  %.lcssa50.lcssa159 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %627, %for_end9 ]
  %.lcssa48.lcssa157 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %621, %for_end9 ]
  %.lcssa46.lcssa155 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %615, %for_end9 ]
  %.lcssa44.lcssa153 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %609, %for_end9 ]
  %.lcssa42.lcssa151 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %603, %for_end9 ]
  %.lcssa40.lcssa149 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %597, %for_end9 ]
  %.lcssa38.lcssa147 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %591, %for_end9 ]
  %.lcssa36.lcssa145 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %585, %for_end9 ]
  %.lcssa34.lcssa143 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %579, %for_end9 ]
  %.lcssa32.lcssa141 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %573, %for_end9 ]
  %.lcssa30.lcssa140 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %567, %for_end9 ]
  %.lcssa28.lcssa138 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %561, %for_end9 ]
  %.lcssa.lcssa136 = phi <8 x float> [ zeroinitializer, %for_body2 ], [ %555, %for_end9 ]
  %509 = mul nuw nsw i64 %indvars.iv220, 690
  %510 = add nsw i64 %420, %509
  %511 = mul nuw nsw i64 %indvars.iv220, 168
  %512 = add nsw i64 %511, %99
  br label %for_begin10.preheader

for_begin10.preheader:                            ; preds = %for_end12, %for_begin7.preheader
  %indvars.iv217 = phi i64 [ 0, %for_begin7.preheader ], [ %indvars.iv.next218, %for_end12 ]
  %.lcssa80135 = phi <8 x float> [ %.lcssa80.lcssa189, %for_begin7.preheader ], [ %717, %for_end12 ]
  %.lcssa78133 = phi <8 x float> [ %.lcssa78.lcssa187, %for_begin7.preheader ], [ %711, %for_end12 ]
  %.lcssa76131 = phi <8 x float> [ %.lcssa76.lcssa185, %for_begin7.preheader ], [ %705, %for_end12 ]
  %.lcssa74129 = phi <8 x float> [ %.lcssa74.lcssa183, %for_begin7.preheader ], [ %699, %for_end12 ]
  %.lcssa72127 = phi <8 x float> [ %.lcssa72.lcssa181, %for_begin7.preheader ], [ %693, %for_end12 ]
  %.lcssa70125 = phi <8 x float> [ %.lcssa70.lcssa179, %for_begin7.preheader ], [ %687, %for_end12 ]
  %.lcssa68123 = phi <8 x float> [ %.lcssa68.lcssa177, %for_begin7.preheader ], [ %681, %for_end12 ]
  %.lcssa66121 = phi <8 x float> [ %.lcssa66.lcssa175, %for_begin7.preheader ], [ %675, %for_end12 ]
  %.lcssa64119 = phi <8 x float> [ %.lcssa64.lcssa173, %for_begin7.preheader ], [ %669, %for_end12 ]
  %.lcssa62117 = phi <8 x float> [ %.lcssa62.lcssa171, %for_begin7.preheader ], [ %663, %for_end12 ]
  %.lcssa60115 = phi <8 x float> [ %.lcssa60.lcssa169, %for_begin7.preheader ], [ %657, %for_end12 ]
  %.lcssa58113 = phi <8 x float> [ %.lcssa58.lcssa167, %for_begin7.preheader ], [ %651, %for_end12 ]
  %.lcssa56111 = phi <8 x float> [ %.lcssa56.lcssa165, %for_begin7.preheader ], [ %645, %for_end12 ]
  %.lcssa54109 = phi <8 x float> [ %.lcssa54.lcssa163, %for_begin7.preheader ], [ %639, %for_end12 ]
  %.lcssa52107 = phi <8 x float> [ %.lcssa52.lcssa161, %for_begin7.preheader ], [ %633, %for_end12 ]
  %.lcssa50105 = phi <8 x float> [ %.lcssa50.lcssa159, %for_begin7.preheader ], [ %627, %for_end12 ]
  %.lcssa48103 = phi <8 x float> [ %.lcssa48.lcssa157, %for_begin7.preheader ], [ %621, %for_end12 ]
  %.lcssa46101 = phi <8 x float> [ %.lcssa46.lcssa155, %for_begin7.preheader ], [ %615, %for_end12 ]
  %.lcssa4499 = phi <8 x float> [ %.lcssa44.lcssa153, %for_begin7.preheader ], [ %609, %for_end12 ]
  %.lcssa4297 = phi <8 x float> [ %.lcssa42.lcssa151, %for_begin7.preheader ], [ %603, %for_end12 ]
  %.lcssa4095 = phi <8 x float> [ %.lcssa40.lcssa149, %for_begin7.preheader ], [ %597, %for_end12 ]
  %.lcssa3893 = phi <8 x float> [ %.lcssa38.lcssa147, %for_begin7.preheader ], [ %591, %for_end12 ]
  %.lcssa3691 = phi <8 x float> [ %.lcssa36.lcssa145, %for_begin7.preheader ], [ %585, %for_end12 ]
  %.lcssa3489 = phi <8 x float> [ %.lcssa34.lcssa143, %for_begin7.preheader ], [ %579, %for_end12 ]
  %.lcssa3287 = phi <8 x float> [ %.lcssa32.lcssa141, %for_begin7.preheader ], [ %573, %for_end12 ]
  %.lcssa3085 = phi <8 x float> [ %.lcssa30.lcssa140, %for_begin7.preheader ], [ %567, %for_end12 ]
  %.lcssa2884 = phi <8 x float> [ %.lcssa28.lcssa138, %for_begin7.preheader ], [ %561, %for_end12 ]
  %.lcssa82 = phi <8 x float> [ %.lcssa.lcssa136, %for_begin7.preheader ], [ %555, %for_end12 ]
  %513 = mul nuw nsw i64 %indvars.iv217, 3
  %514 = add nsw i64 %510, %513
  %515 = mul nuw nsw i64 %indvars.iv217, 24
  %516 = add nsw i64 %512, %515
  br label %for_body11

for_end9:                                         ; preds = %for_end12
  %indvars.iv.next221 = add nuw nsw i64 %indvars.iv220, 1
  %exitcond222 = icmp eq i64 %indvars.iv.next221, 7
  br i1 %exitcond222, label %for_begin13.preheader, label %for_begin7.preheader, !prof !50

for_body11:                                       ; preds = %for_body11, %for_begin10.preheader
  %indvars.iv = phi i64 [ 0, %for_begin10.preheader ], [ %indvars.iv.next, %for_body11 ]
  %517 = phi <8 x float> [ %.lcssa80135, %for_begin10.preheader ], [ %717, %for_body11 ]
  %518 = phi <8 x float> [ %.lcssa78133, %for_begin10.preheader ], [ %711, %for_body11 ]
  %519 = phi <8 x float> [ %.lcssa76131, %for_begin10.preheader ], [ %705, %for_body11 ]
  %520 = phi <8 x float> [ %.lcssa74129, %for_begin10.preheader ], [ %699, %for_body11 ]
  %521 = phi <8 x float> [ %.lcssa72127, %for_begin10.preheader ], [ %693, %for_body11 ]
  %522 = phi <8 x float> [ %.lcssa70125, %for_begin10.preheader ], [ %687, %for_body11 ]
  %523 = phi <8 x float> [ %.lcssa68123, %for_begin10.preheader ], [ %681, %for_body11 ]
  %524 = phi <8 x float> [ %.lcssa66121, %for_begin10.preheader ], [ %675, %for_body11 ]
  %525 = phi <8 x float> [ %.lcssa64119, %for_begin10.preheader ], [ %669, %for_body11 ]
  %526 = phi <8 x float> [ %.lcssa62117, %for_begin10.preheader ], [ %663, %for_body11 ]
  %527 = phi <8 x float> [ %.lcssa60115, %for_begin10.preheader ], [ %657, %for_body11 ]
  %528 = phi <8 x float> [ %.lcssa58113, %for_begin10.preheader ], [ %651, %for_body11 ]
  %529 = phi <8 x float> [ %.lcssa56111, %for_begin10.preheader ], [ %645, %for_body11 ]
  %530 = phi <8 x float> [ %.lcssa54109, %for_begin10.preheader ], [ %639, %for_body11 ]
  %531 = phi <8 x float> [ %.lcssa52107, %for_begin10.preheader ], [ %633, %for_body11 ]
  %532 = phi <8 x float> [ %.lcssa50105, %for_begin10.preheader ], [ %627, %for_body11 ]
  %533 = phi <8 x float> [ %.lcssa48103, %for_begin10.preheader ], [ %621, %for_body11 ]
  %534 = phi <8 x float> [ %.lcssa46101, %for_begin10.preheader ], [ %615, %for_body11 ]
  %535 = phi <8 x float> [ %.lcssa4499, %for_begin10.preheader ], [ %609, %for_body11 ]
  %536 = phi <8 x float> [ %.lcssa4297, %for_begin10.preheader ], [ %603, %for_body11 ]
  %537 = phi <8 x float> [ %.lcssa4095, %for_begin10.preheader ], [ %597, %for_body11 ]
  %538 = phi <8 x float> [ %.lcssa3893, %for_begin10.preheader ], [ %591, %for_body11 ]
  %539 = phi <8 x float> [ %.lcssa3691, %for_begin10.preheader ], [ %585, %for_body11 ]
  %540 = phi <8 x float> [ %.lcssa3489, %for_begin10.preheader ], [ %579, %for_body11 ]
  %541 = phi <8 x float> [ %.lcssa3287, %for_begin10.preheader ], [ %573, %for_body11 ]
  %542 = phi <8 x float> [ %.lcssa3085, %for_begin10.preheader ], [ %567, %for_body11 ]
  %543 = phi <8 x float> [ %.lcssa2884, %for_begin10.preheader ], [ %561, %for_body11 ]
  %544 = phi <8 x float> [ %.lcssa82, %for_begin10.preheader ], [ %555, %for_body11 ]
  %545 = add nsw i64 %514, %indvars.iv
  %546 = getelementptr inbounds float, float* %5, i64 %545
  %547 = load float, float* %546, align 4, !tbaa !4409
  %548 = insertelement <8 x float> undef, float %547, i32 0
  %549 = shufflevector <8 x float> %548, <8 x float> undef, <8 x i32> zeroinitializer
  %550 = shl i64 %indvars.iv, 3
  %551 = add nsw i64 %516, %550
  %552 = getelementptr inbounds float, float* %8, i64 %551
  %553 = bitcast float* %552 to <8 x float>*
  %554 = load <8 x float>, <8 x float>* %553, align 32, !tbaa !4412
  %555 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %549, <8 x float> %554, <8 x float> %544)
  %556 = add nsw i64 %545, 6
  %557 = getelementptr inbounds float, float* %5, i64 %556
  %558 = load float, float* %557, align 4, !tbaa !4409
  %559 = insertelement <8 x float> undef, float %558, i32 0
  %560 = shufflevector <8 x float> %559, <8 x float> undef, <8 x i32> zeroinitializer
  %561 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %560, <8 x float> %554, <8 x float> %543)
  %562 = add nsw i64 %545, 12
  %563 = getelementptr inbounds float, float* %5, i64 %562
  %564 = load float, float* %563, align 4, !tbaa !4409
  %565 = insertelement <8 x float> undef, float %564, i32 0
  %566 = shufflevector <8 x float> %565, <8 x float> undef, <8 x i32> zeroinitializer
  %567 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %566, <8 x float> %554, <8 x float> %542)
  %568 = add nsw i64 %545, 18
  %569 = getelementptr inbounds float, float* %5, i64 %568
  %570 = load float, float* %569, align 4, !tbaa !4409
  %571 = insertelement <8 x float> undef, float %570, i32 0
  %572 = shufflevector <8 x float> %571, <8 x float> undef, <8 x i32> zeroinitializer
  %573 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %572, <8 x float> %554, <8 x float> %541)
  %574 = add nsw i64 %545, 24
  %575 = getelementptr inbounds float, float* %5, i64 %574
  %576 = load float, float* %575, align 4, !tbaa !4409
  %577 = insertelement <8 x float> undef, float %576, i32 0
  %578 = shufflevector <8 x float> %577, <8 x float> undef, <8 x i32> zeroinitializer
  %579 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %578, <8 x float> %554, <8 x float> %540)
  %580 = add nsw i64 %545, 30
  %581 = getelementptr inbounds float, float* %5, i64 %580
  %582 = load float, float* %581, align 4, !tbaa !4409
  %583 = insertelement <8 x float> undef, float %582, i32 0
  %584 = shufflevector <8 x float> %583, <8 x float> undef, <8 x i32> zeroinitializer
  %585 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %584, <8 x float> %554, <8 x float> %539)
  %586 = add nsw i64 %545, 36
  %587 = getelementptr inbounds float, float* %5, i64 %586
  %588 = load float, float* %587, align 4, !tbaa !4409
  %589 = insertelement <8 x float> undef, float %588, i32 0
  %590 = shufflevector <8 x float> %589, <8 x float> undef, <8 x i32> zeroinitializer
  %591 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %590, <8 x float> %554, <8 x float> %538)
  %592 = add nsw i64 %545, 42
  %593 = getelementptr inbounds float, float* %5, i64 %592
  %594 = load float, float* %593, align 4, !tbaa !4409
  %595 = insertelement <8 x float> undef, float %594, i32 0
  %596 = shufflevector <8 x float> %595, <8 x float> undef, <8 x i32> zeroinitializer
  %597 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %596, <8 x float> %554, <8 x float> %537)
  %598 = add nsw i64 %545, 48
  %599 = getelementptr inbounds float, float* %5, i64 %598
  %600 = load float, float* %599, align 4, !tbaa !4409
  %601 = insertelement <8 x float> undef, float %600, i32 0
  %602 = shufflevector <8 x float> %601, <8 x float> undef, <8 x i32> zeroinitializer
  %603 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %602, <8 x float> %554, <8 x float> %536)
  %604 = add nsw i64 %545, 54
  %605 = getelementptr inbounds float, float* %5, i64 %604
  %606 = load float, float* %605, align 4, !tbaa !4409
  %607 = insertelement <8 x float> undef, float %606, i32 0
  %608 = shufflevector <8 x float> %607, <8 x float> undef, <8 x i32> zeroinitializer
  %609 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %608, <8 x float> %554, <8 x float> %535)
  %610 = add nsw i64 %545, 60
  %611 = getelementptr inbounds float, float* %5, i64 %610
  %612 = load float, float* %611, align 4, !tbaa !4409
  %613 = insertelement <8 x float> undef, float %612, i32 0
  %614 = shufflevector <8 x float> %613, <8 x float> undef, <8 x i32> zeroinitializer
  %615 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %614, <8 x float> %554, <8 x float> %534)
  %616 = add nsw i64 %545, 66
  %617 = getelementptr inbounds float, float* %5, i64 %616
  %618 = load float, float* %617, align 4, !tbaa !4409
  %619 = insertelement <8 x float> undef, float %618, i32 0
  %620 = shufflevector <8 x float> %619, <8 x float> undef, <8 x i32> zeroinitializer
  %621 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %620, <8 x float> %554, <8 x float> %533)
  %622 = add nsw i64 %545, 72
  %623 = getelementptr inbounds float, float* %5, i64 %622
  %624 = load float, float* %623, align 4, !tbaa !4409
  %625 = insertelement <8 x float> undef, float %624, i32 0
  %626 = shufflevector <8 x float> %625, <8 x float> undef, <8 x i32> zeroinitializer
  %627 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %626, <8 x float> %554, <8 x float> %532)
  %628 = add nsw i64 %545, 78
  %629 = getelementptr inbounds float, float* %5, i64 %628
  %630 = load float, float* %629, align 4, !tbaa !4409
  %631 = insertelement <8 x float> undef, float %630, i32 0
  %632 = shufflevector <8 x float> %631, <8 x float> undef, <8 x i32> zeroinitializer
  %633 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %632, <8 x float> %554, <8 x float> %531)
  %634 = add nsw i64 %545, 84
  %635 = getelementptr inbounds float, float* %5, i64 %634
  %636 = load float, float* %635, align 4, !tbaa !4409
  %637 = insertelement <8 x float> undef, float %636, i32 0
  %638 = shufflevector <8 x float> %637, <8 x float> undef, <8 x i32> zeroinitializer
  %639 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %638, <8 x float> %554, <8 x float> %530)
  %640 = add nsw i64 %545, 90
  %641 = getelementptr inbounds float, float* %5, i64 %640
  %642 = load float, float* %641, align 4, !tbaa !4409
  %643 = insertelement <8 x float> undef, float %642, i32 0
  %644 = shufflevector <8 x float> %643, <8 x float> undef, <8 x i32> zeroinitializer
  %645 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %644, <8 x float> %554, <8 x float> %529)
  %646 = add nsw i64 %545, 96
  %647 = getelementptr inbounds float, float* %5, i64 %646
  %648 = load float, float* %647, align 4, !tbaa !4409
  %649 = insertelement <8 x float> undef, float %648, i32 0
  %650 = shufflevector <8 x float> %649, <8 x float> undef, <8 x i32> zeroinitializer
  %651 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %650, <8 x float> %554, <8 x float> %528)
  %652 = add nsw i64 %545, 102
  %653 = getelementptr inbounds float, float* %5, i64 %652
  %654 = load float, float* %653, align 4, !tbaa !4409
  %655 = insertelement <8 x float> undef, float %654, i32 0
  %656 = shufflevector <8 x float> %655, <8 x float> undef, <8 x i32> zeroinitializer
  %657 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %656, <8 x float> %554, <8 x float> %527)
  %658 = add nsw i64 %545, 108
  %659 = getelementptr inbounds float, float* %5, i64 %658
  %660 = load float, float* %659, align 4, !tbaa !4409
  %661 = insertelement <8 x float> undef, float %660, i32 0
  %662 = shufflevector <8 x float> %661, <8 x float> undef, <8 x i32> zeroinitializer
  %663 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %662, <8 x float> %554, <8 x float> %526)
  %664 = add nsw i64 %545, 114
  %665 = getelementptr inbounds float, float* %5, i64 %664
  %666 = load float, float* %665, align 4, !tbaa !4409
  %667 = insertelement <8 x float> undef, float %666, i32 0
  %668 = shufflevector <8 x float> %667, <8 x float> undef, <8 x i32> zeroinitializer
  %669 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %668, <8 x float> %554, <8 x float> %525)
  %670 = add nsw i64 %545, 120
  %671 = getelementptr inbounds float, float* %5, i64 %670
  %672 = load float, float* %671, align 4, !tbaa !4409
  %673 = insertelement <8 x float> undef, float %672, i32 0
  %674 = shufflevector <8 x float> %673, <8 x float> undef, <8 x i32> zeroinitializer
  %675 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %674, <8 x float> %554, <8 x float> %524)
  %676 = add nsw i64 %545, 126
  %677 = getelementptr inbounds float, float* %5, i64 %676
  %678 = load float, float* %677, align 4, !tbaa !4409
  %679 = insertelement <8 x float> undef, float %678, i32 0
  %680 = shufflevector <8 x float> %679, <8 x float> undef, <8 x i32> zeroinitializer
  %681 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %680, <8 x float> %554, <8 x float> %523)
  %682 = add nsw i64 %545, 132
  %683 = getelementptr inbounds float, float* %5, i64 %682
  %684 = load float, float* %683, align 4, !tbaa !4409
  %685 = insertelement <8 x float> undef, float %684, i32 0
  %686 = shufflevector <8 x float> %685, <8 x float> undef, <8 x i32> zeroinitializer
  %687 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %686, <8 x float> %554, <8 x float> %522)
  %688 = add nsw i64 %545, 138
  %689 = getelementptr inbounds float, float* %5, i64 %688
  %690 = load float, float* %689, align 4, !tbaa !4409
  %691 = insertelement <8 x float> undef, float %690, i32 0
  %692 = shufflevector <8 x float> %691, <8 x float> undef, <8 x i32> zeroinitializer
  %693 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %692, <8 x float> %554, <8 x float> %521)
  %694 = add nsw i64 %545, 144
  %695 = getelementptr inbounds float, float* %5, i64 %694
  %696 = load float, float* %695, align 4, !tbaa !4409
  %697 = insertelement <8 x float> undef, float %696, i32 0
  %698 = shufflevector <8 x float> %697, <8 x float> undef, <8 x i32> zeroinitializer
  %699 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %698, <8 x float> %554, <8 x float> %520)
  %700 = add nsw i64 %545, 150
  %701 = getelementptr inbounds float, float* %5, i64 %700
  %702 = load float, float* %701, align 4, !tbaa !4409
  %703 = insertelement <8 x float> undef, float %702, i32 0
  %704 = shufflevector <8 x float> %703, <8 x float> undef, <8 x i32> zeroinitializer
  %705 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %704, <8 x float> %554, <8 x float> %519)
  %706 = add nsw i64 %545, 156
  %707 = getelementptr inbounds float, float* %5, i64 %706
  %708 = load float, float* %707, align 4, !tbaa !4409
  %709 = insertelement <8 x float> undef, float %708, i32 0
  %710 = shufflevector <8 x float> %709, <8 x float> undef, <8 x i32> zeroinitializer
  %711 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %710, <8 x float> %554, <8 x float> %518)
  %712 = add nsw i64 %545, 162
  %713 = getelementptr inbounds float, float* %5, i64 %712
  %714 = load float, float* %713, align 4, !tbaa !4409
  %715 = insertelement <8 x float> undef, float %714, i32 0
  %716 = shufflevector <8 x float> %715, <8 x float> undef, <8 x i32> zeroinitializer
  %717 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %716, <8 x float> %554, <8 x float> %517)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 3
  br i1 %exitcond, label %for_end12, label %for_body11, !prof !50

for_end12:                                        ; preds = %for_body11
  %indvars.iv.next218 = add nuw nsw i64 %indvars.iv217, 1
  %exitcond219 = icmp eq i64 %indvars.iv.next218, 7
  br i1 %exitcond219, label %for_end9, label %for_begin10.preheader, !prof !50

for_body20.1:                                     ; preds = %for_begin16.preheader, %for_body20.1
  %indvars.iv227.1 = phi i64 [ %indvars.iv.next228.1, %for_body20.1 ], [ 0, %for_begin16.preheader ]
  %718 = shl nsw i64 %indvars.iv227.1, 3
  %719 = add nuw nsw i64 %718, 224
  %720 = trunc i64 %719 to i32
  %721 = add i32 %101, %720
  %722 = getelementptr inbounds float, float* %98, i64 %719
  %723 = bitcast float* %722 to <8 x float>*
  %724 = load <8 x float>, <8 x float>* %723, align 32, !tbaa !4391
  %725 = fadd <8 x float> %106, %724
  %726 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %725, <8 x float> %109, <8 x float> %112)
  %727 = fcmp ogt <8 x float> %726, zeroinitializer
  %728 = select <8 x i1> %727, <8 x float> %726, <8 x float> zeroinitializer
  %729 = sext i32 %721 to i64
  %730 = getelementptr inbounds float, float* %11, i64 %729
  %731 = bitcast float* %730 to <8 x float>*
  store <8 x float> %728, <8 x float>* %731, align 32, !tbaa !4394
  %indvars.iv.next228.1 = add nuw nsw i64 %indvars.iv227.1, 1
  %exitcond229.1 = icmp eq i64 %indvars.iv.next228.1, 28
  br i1 %exitcond229.1, label %for_body20.2, label %for_body20.1, !prof !50

for_body20.2:                                     ; preds = %for_body20.1, %for_body20.2
  %indvars.iv227.2 = phi i64 [ %indvars.iv.next228.2, %for_body20.2 ], [ 0, %for_body20.1 ]
  %732 = shl nsw i64 %indvars.iv227.2, 3
  %733 = add nuw nsw i64 %732, 448
  %734 = trunc i64 %733 to i32
  %735 = add i32 %101, %734
  %736 = getelementptr inbounds float, float* %98, i64 %733
  %737 = bitcast float* %736 to <8 x float>*
  %738 = load <8 x float>, <8 x float>* %737, align 32, !tbaa !4391
  %739 = fadd <8 x float> %106, %738
  %740 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %739, <8 x float> %109, <8 x float> %112)
  %741 = fcmp ogt <8 x float> %740, zeroinitializer
  %742 = select <8 x i1> %741, <8 x float> %740, <8 x float> zeroinitializer
  %743 = sext i32 %735 to i64
  %744 = getelementptr inbounds float, float* %11, i64 %743
  %745 = bitcast float* %744 to <8 x float>*
  store <8 x float> %742, <8 x float>* %745, align 32, !tbaa !4394
  %indvars.iv.next228.2 = add nuw nsw i64 %indvars.iv227.2, 1
  %exitcond229.2 = icmp eq i64 %indvars.iv.next228.2, 28
  br i1 %exitcond229.2, label %for_body20.3, label %for_body20.2, !prof !50

for_body20.3:                                     ; preds = %for_body20.2, %for_body20.3
  %indvars.iv227.3 = phi i64 [ %indvars.iv.next228.3, %for_body20.3 ], [ 0, %for_body20.2 ]
  %746 = shl nsw i64 %indvars.iv227.3, 3
  %747 = add nuw nsw i64 %746, 672
  %748 = trunc i64 %747 to i32
  %749 = add i32 %101, %748
  %750 = getelementptr inbounds float, float* %98, i64 %747
  %751 = bitcast float* %750 to <8 x float>*
  %752 = load <8 x float>, <8 x float>* %751, align 32, !tbaa !4391
  %753 = fadd <8 x float> %106, %752
  %754 = tail call <8 x float> @llvm.fmuladd.v8f32(<8 x float> %753, <8 x float> %109, <8 x float> %112)
  %755 = fcmp ogt <8 x float> %754, zeroinitializer
  %756 = select <8 x i1> %755, <8 x float> %754, <8 x float> zeroinitializer
  %757 = sext i32 %749 to i64
  %758 = getelementptr inbounds float, float* %11, i64 %757
  %759 = bitcast float* %758 to <8 x float>*
  store <8 x float> %756, <8 x float>* %759, align 32, !tbaa !4394
  %indvars.iv.next228.3 = add nuw nsw i64 %indvars.iv227.3, 1
  %exitcond229.3 = icmp eq i64 %indvars.iv.next228.3, 28
  br i1 %exitcond229.3, label %for_end21.3, label %for_body20.3, !prof !50

for_end21.3:                                      ; preds = %for_body20.3
  %760 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %761 = tail call i32 %760(i32 1, i32 %23, i8* nonnull %93)
  %762 = add nsw i32 %91, 1
  %763 = icmp slt i32 %762, %31
  br i1 %763, label %for_body, label %for_end, !prof !5
}

; Function Attrs: nounwind readnone speculatable
declare <8 x float> @llvm.fmuladd.v8f32(<8 x float>, <8 x float>, <8 x float>) #2

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.370, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !4415
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !4429
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !4432
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !4434
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.371, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !4438
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.372, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.373, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.374, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.375, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !4440
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !4454
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 8
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !4456
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 28
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !4459
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 28
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !4461
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 64
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !4465
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 401408, i32 50176, i32 1792, i32 64>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !4477
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.30, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !4481
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 4
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !4495
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 8
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.376, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !4497
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !4500
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !4502
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 64
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !4506
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 64
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.227, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !4508
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 32768, i32 4096, i32 4096, i32 4096>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !4520
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 64
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !4524
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([276 x i8], [276 x i8]* @.str.377, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !4526
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 4
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !4540
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !4542
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !4545
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 64
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.229, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !4547
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.230, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !4559
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 4
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !4573
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !4575
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !4578
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 64
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.231, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !4580
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.232, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !4592
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !4606
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 4
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.79, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !4608
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 14
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.378, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !4611
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 14
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.379, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !4613
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 64
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.233, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !4617
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 50176, i32 12544, i32 896, i32 64>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !4629
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.380, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_5_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %29, align 8
  %7 = getelementptr inbounds %29, %29* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %29, %29* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %29, %29* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %29, %29* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %29, %29* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %29, %29* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %29* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.381, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.381(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 27
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 28
  %27 = select i1 %26, i32 %25, i32 28
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 28
  %30 = select i1 %29, i32 %28, i32 28
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_begin10.preheader
  %indvars.iv56 = phi i64 [ %34, %for_body.preheader ], [ %indvars.iv.next57, %for_begin10.preheader ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %37 = tail call i8* %36(i32 1, i32 %19, i64 7168, i32 2, i32 32)
  %38 = bitcast i8* %37 to float*
  %39 = trunc i64 %indvars.iv56 to i32
  %40 = srem i32 %39, 7
  %41 = mul nsw i32 %40, 7168
  %42 = sdiv i32 %39, 7
  %43 = shl i32 %42, 15
  %44 = sext i32 %43 to i64
  %45 = sext i32 %41 to i64
  %46 = or i64 %44, 4096
  %47 = or i64 %44, 8192
  %48 = or i64 %44, 12288
  %49 = or i64 %44, 16384
  %50 = or i64 %44, 20480
  %51 = or i64 %44, 24576
  %52 = or i64 %44, 28672
  br label %for_body2

for_end:                                          ; preds = %for_begin10.preheader, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end9.7
  %53 = mul nsw i64 %indvars.iv56, 1792
  %54 = shl nsw i32 %42, 6
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds float, float* %16, i64 %55
  %57 = bitcast float* %56 to <64 x float>*
  %58 = load <64 x float>, <64 x float>* %57, align 64, !tbaa !4633
  %59 = getelementptr inbounds float, float* %13, i64 %55
  %60 = bitcast float* %59 to <64 x float>*
  %61 = load <64 x float>, <64 x float>* %60, align 64, !tbaa !4636
  %62 = bitcast i8* %37 to <64 x float>*
  %63 = load <64 x float>, <64 x float>* %62, align 64, !tbaa !4639
  %64 = fadd <64 x float> %61, %63
  %65 = fadd <64 x float> %58, %64
  %66 = fcmp ogt <64 x float> %65, zeroinitializer
  %67 = select <64 x i1> %66, <64 x float> %65, <64 x float> zeroinitializer
  %68 = getelementptr inbounds float, float* %10, i64 %53
  %69 = bitcast float* %68 to <64 x float>*
  store <64 x float> %67, <64 x float>* %69, align 64, !tbaa !4642
  %70 = getelementptr inbounds i8, i8* %37, i64 256
  %71 = bitcast i8* %70 to <64 x float>*
  %72 = load <64 x float>, <64 x float>* %71, align 64, !tbaa !4639
  %73 = fadd <64 x float> %61, %72
  %74 = fadd <64 x float> %58, %73
  %75 = fcmp ogt <64 x float> %74, zeroinitializer
  %76 = select <64 x i1> %75, <64 x float> %74, <64 x float> zeroinitializer
  %77 = mul i64 %indvars.iv56, 7696581394432
  %sext = ashr exact i64 %77, 32
  %78 = or i64 %sext, 64
  %79 = getelementptr inbounds float, float* %10, i64 %78
  %80 = bitcast float* %79 to <64 x float>*
  store <64 x float> %76, <64 x float>* %80, align 64, !tbaa !4642
  %81 = getelementptr inbounds i8, i8* %37, i64 3584
  %82 = bitcast i8* %81 to <64 x float>*
  %83 = load <64 x float>, <64 x float>* %82, align 64, !tbaa !4639
  %84 = fadd <64 x float> %61, %83
  %85 = fadd <64 x float> %58, %84
  %86 = fcmp ogt <64 x float> %85, zeroinitializer
  %87 = select <64 x i1> %86, <64 x float> %85, <64 x float> zeroinitializer
  %88 = mul i64 %indvars.iv56, 7696581394432
  %sext71 = add i64 %88, 3848290697216
  %89 = ashr exact i64 %sext71, 32
  %90 = getelementptr inbounds float, float* %10, i64 %89
  %91 = bitcast float* %90 to <64 x float>*
  store <64 x float> %87, <64 x float>* %91, align 64, !tbaa !4642
  %92 = getelementptr inbounds i8, i8* %37, i64 3840
  %93 = bitcast i8* %92 to <64 x float>*
  %94 = load <64 x float>, <64 x float>* %93, align 64, !tbaa !4639
  %95 = fadd <64 x float> %61, %94
  %96 = fadd <64 x float> %58, %95
  %97 = fcmp ogt <64 x float> %96, zeroinitializer
  %98 = select <64 x i1> %97, <64 x float> %96, <64 x float> zeroinitializer
  %99 = mul i64 %indvars.iv56, 7696581394432
  %sext58 = add i64 %99, 4123168604160
  %100 = ashr exact i64 %sext58, 32
  %101 = getelementptr inbounds float, float* %10, i64 %100
  %102 = bitcast float* %101 to <64 x float>*
  store <64 x float> %98, <64 x float>* %102, align 64, !tbaa !4642
  %103 = getelementptr inbounds i8, i8* %37, i64 512
  %104 = bitcast i8* %103 to <64 x float>*
  %105 = load <64 x float>, <64 x float>* %104, align 64, !tbaa !4639
  %106 = fadd <64 x float> %61, %105
  %107 = fadd <64 x float> %58, %106
  %108 = fcmp ogt <64 x float> %107, zeroinitializer
  %109 = select <64 x i1> %108, <64 x float> %107, <64 x float> zeroinitializer
  %110 = mul i64 %indvars.iv56, 7696581394432
  %sext72 = ashr exact i64 %110, 32
  %111 = or i64 %sext72, 128
  %112 = getelementptr inbounds float, float* %10, i64 %111
  %113 = bitcast float* %112 to <64 x float>*
  store <64 x float> %109, <64 x float>* %113, align 64, !tbaa !4642
  %114 = getelementptr inbounds i8, i8* %37, i64 768
  %115 = bitcast i8* %114 to <64 x float>*
  %116 = load <64 x float>, <64 x float>* %115, align 64, !tbaa !4639
  %117 = fadd <64 x float> %61, %116
  %118 = fadd <64 x float> %58, %117
  %119 = fcmp ogt <64 x float> %118, zeroinitializer
  %120 = select <64 x i1> %119, <64 x float> %118, <64 x float> zeroinitializer
  %121 = mul i64 %indvars.iv56, 7696581394432
  %sext59 = ashr exact i64 %121, 32
  %122 = or i64 %sext59, 192
  %123 = getelementptr inbounds float, float* %10, i64 %122
  %124 = bitcast float* %123 to <64 x float>*
  store <64 x float> %120, <64 x float>* %124, align 64, !tbaa !4642
  %125 = getelementptr inbounds i8, i8* %37, i64 4096
  %126 = bitcast i8* %125 to <64 x float>*
  %127 = load <64 x float>, <64 x float>* %126, align 64, !tbaa !4639
  %128 = fadd <64 x float> %61, %127
  %129 = fadd <64 x float> %58, %128
  %130 = fcmp ogt <64 x float> %129, zeroinitializer
  %131 = select <64 x i1> %130, <64 x float> %129, <64 x float> zeroinitializer
  %132 = mul i64 %indvars.iv56, 7696581394432
  %sext73 = add i64 %132, 4398046511104
  %133 = ashr exact i64 %sext73, 32
  %134 = getelementptr inbounds float, float* %10, i64 %133
  %135 = bitcast float* %134 to <64 x float>*
  store <64 x float> %131, <64 x float>* %135, align 64, !tbaa !4642
  %136 = getelementptr inbounds i8, i8* %37, i64 4352
  %137 = bitcast i8* %136 to <64 x float>*
  %138 = load <64 x float>, <64 x float>* %137, align 64, !tbaa !4639
  %139 = fadd <64 x float> %61, %138
  %140 = fadd <64 x float> %58, %139
  %141 = fcmp ogt <64 x float> %140, zeroinitializer
  %142 = select <64 x i1> %141, <64 x float> %140, <64 x float> zeroinitializer
  %143 = mul i64 %indvars.iv56, 7696581394432
  %sext60 = add i64 %143, 4672924418048
  %144 = ashr exact i64 %sext60, 32
  %145 = getelementptr inbounds float, float* %10, i64 %144
  %146 = bitcast float* %145 to <64 x float>*
  store <64 x float> %142, <64 x float>* %146, align 64, !tbaa !4642
  %147 = getelementptr inbounds i8, i8* %37, i64 1024
  %148 = bitcast i8* %147 to <64 x float>*
  %149 = load <64 x float>, <64 x float>* %148, align 64, !tbaa !4639
  %150 = fadd <64 x float> %61, %149
  %151 = fadd <64 x float> %58, %150
  %152 = fcmp ogt <64 x float> %151, zeroinitializer
  %153 = select <64 x i1> %152, <64 x float> %151, <64 x float> zeroinitializer
  %154 = mul i64 %indvars.iv56, 7696581394432
  %sext74 = add i64 %154, 1099511627776
  %155 = ashr exact i64 %sext74, 32
  %156 = getelementptr inbounds float, float* %10, i64 %155
  %157 = bitcast float* %156 to <64 x float>*
  store <64 x float> %153, <64 x float>* %157, align 64, !tbaa !4642
  %158 = getelementptr inbounds i8, i8* %37, i64 1280
  %159 = bitcast i8* %158 to <64 x float>*
  %160 = load <64 x float>, <64 x float>* %159, align 64, !tbaa !4639
  %161 = fadd <64 x float> %61, %160
  %162 = fadd <64 x float> %58, %161
  %163 = fcmp ogt <64 x float> %162, zeroinitializer
  %164 = select <64 x i1> %163, <64 x float> %162, <64 x float> zeroinitializer
  %165 = mul i64 %indvars.iv56, 7696581394432
  %sext61 = add i64 %165, 1374389534720
  %166 = ashr exact i64 %sext61, 32
  %167 = getelementptr inbounds float, float* %10, i64 %166
  %168 = bitcast float* %167 to <64 x float>*
  store <64 x float> %164, <64 x float>* %168, align 64, !tbaa !4642
  %169 = getelementptr inbounds i8, i8* %37, i64 4608
  %170 = bitcast i8* %169 to <64 x float>*
  %171 = load <64 x float>, <64 x float>* %170, align 64, !tbaa !4639
  %172 = fadd <64 x float> %61, %171
  %173 = fadd <64 x float> %58, %172
  %174 = fcmp ogt <64 x float> %173, zeroinitializer
  %175 = select <64 x i1> %174, <64 x float> %173, <64 x float> zeroinitializer
  %176 = mul i64 %indvars.iv56, 7696581394432
  %sext75 = add i64 %176, 4947802324992
  %177 = ashr exact i64 %sext75, 32
  %178 = getelementptr inbounds float, float* %10, i64 %177
  %179 = bitcast float* %178 to <64 x float>*
  store <64 x float> %175, <64 x float>* %179, align 64, !tbaa !4642
  %180 = getelementptr inbounds i8, i8* %37, i64 4864
  %181 = bitcast i8* %180 to <64 x float>*
  %182 = load <64 x float>, <64 x float>* %181, align 64, !tbaa !4639
  %183 = fadd <64 x float> %61, %182
  %184 = fadd <64 x float> %58, %183
  %185 = fcmp ogt <64 x float> %184, zeroinitializer
  %186 = select <64 x i1> %185, <64 x float> %184, <64 x float> zeroinitializer
  %187 = mul i64 %indvars.iv56, 7696581394432
  %sext62 = add i64 %187, 5222680231936
  %188 = ashr exact i64 %sext62, 32
  %189 = getelementptr inbounds float, float* %10, i64 %188
  %190 = bitcast float* %189 to <64 x float>*
  store <64 x float> %186, <64 x float>* %190, align 64, !tbaa !4642
  %191 = getelementptr inbounds i8, i8* %37, i64 1536
  %192 = bitcast i8* %191 to <64 x float>*
  %193 = load <64 x float>, <64 x float>* %192, align 64, !tbaa !4639
  %194 = fadd <64 x float> %61, %193
  %195 = fadd <64 x float> %58, %194
  %196 = fcmp ogt <64 x float> %195, zeroinitializer
  %197 = select <64 x i1> %196, <64 x float> %195, <64 x float> zeroinitializer
  %198 = mul i64 %indvars.iv56, 7696581394432
  %sext76 = add i64 %198, 1649267441664
  %199 = ashr exact i64 %sext76, 32
  %200 = getelementptr inbounds float, float* %10, i64 %199
  %201 = bitcast float* %200 to <64 x float>*
  store <64 x float> %197, <64 x float>* %201, align 64, !tbaa !4642
  %202 = getelementptr inbounds i8, i8* %37, i64 1792
  %203 = bitcast i8* %202 to <64 x float>*
  %204 = load <64 x float>, <64 x float>* %203, align 64, !tbaa !4639
  %205 = fadd <64 x float> %61, %204
  %206 = fadd <64 x float> %58, %205
  %207 = fcmp ogt <64 x float> %206, zeroinitializer
  %208 = select <64 x i1> %207, <64 x float> %206, <64 x float> zeroinitializer
  %209 = mul i64 %indvars.iv56, 7696581394432
  %sext63 = add i64 %209, 1924145348608
  %210 = ashr exact i64 %sext63, 32
  %211 = getelementptr inbounds float, float* %10, i64 %210
  %212 = bitcast float* %211 to <64 x float>*
  store <64 x float> %208, <64 x float>* %212, align 64, !tbaa !4642
  %213 = getelementptr inbounds i8, i8* %37, i64 5120
  %214 = bitcast i8* %213 to <64 x float>*
  %215 = load <64 x float>, <64 x float>* %214, align 64, !tbaa !4639
  %216 = fadd <64 x float> %61, %215
  %217 = fadd <64 x float> %58, %216
  %218 = fcmp ogt <64 x float> %217, zeroinitializer
  %219 = select <64 x i1> %218, <64 x float> %217, <64 x float> zeroinitializer
  %220 = mul i64 %indvars.iv56, 7696581394432
  %sext77 = add i64 %220, 5497558138880
  %221 = ashr exact i64 %sext77, 32
  %222 = getelementptr inbounds float, float* %10, i64 %221
  %223 = bitcast float* %222 to <64 x float>*
  store <64 x float> %219, <64 x float>* %223, align 64, !tbaa !4642
  %224 = getelementptr inbounds i8, i8* %37, i64 5376
  %225 = bitcast i8* %224 to <64 x float>*
  %226 = load <64 x float>, <64 x float>* %225, align 64, !tbaa !4639
  %227 = fadd <64 x float> %61, %226
  %228 = fadd <64 x float> %58, %227
  %229 = fcmp ogt <64 x float> %228, zeroinitializer
  %230 = select <64 x i1> %229, <64 x float> %228, <64 x float> zeroinitializer
  %231 = mul i64 %indvars.iv56, 7696581394432
  %sext64 = add i64 %231, 5772436045824
  %232 = ashr exact i64 %sext64, 32
  %233 = getelementptr inbounds float, float* %10, i64 %232
  %234 = bitcast float* %233 to <64 x float>*
  store <64 x float> %230, <64 x float>* %234, align 64, !tbaa !4642
  %235 = getelementptr inbounds i8, i8* %37, i64 2048
  %236 = bitcast i8* %235 to <64 x float>*
  %237 = load <64 x float>, <64 x float>* %236, align 64, !tbaa !4639
  %238 = fadd <64 x float> %61, %237
  %239 = fadd <64 x float> %58, %238
  %240 = fcmp ogt <64 x float> %239, zeroinitializer
  %241 = select <64 x i1> %240, <64 x float> %239, <64 x float> zeroinitializer
  %242 = mul i64 %indvars.iv56, 7696581394432
  %sext78 = add i64 %242, 2199023255552
  %243 = ashr exact i64 %sext78, 32
  %244 = getelementptr inbounds float, float* %10, i64 %243
  %245 = bitcast float* %244 to <64 x float>*
  store <64 x float> %241, <64 x float>* %245, align 64, !tbaa !4642
  %246 = getelementptr inbounds i8, i8* %37, i64 2304
  %247 = bitcast i8* %246 to <64 x float>*
  %248 = load <64 x float>, <64 x float>* %247, align 64, !tbaa !4639
  %249 = fadd <64 x float> %61, %248
  %250 = fadd <64 x float> %58, %249
  %251 = fcmp ogt <64 x float> %250, zeroinitializer
  %252 = select <64 x i1> %251, <64 x float> %250, <64 x float> zeroinitializer
  %253 = mul i64 %indvars.iv56, 7696581394432
  %sext65 = add i64 %253, 2473901162496
  %254 = ashr exact i64 %sext65, 32
  %255 = getelementptr inbounds float, float* %10, i64 %254
  %256 = bitcast float* %255 to <64 x float>*
  store <64 x float> %252, <64 x float>* %256, align 64, !tbaa !4642
  %257 = getelementptr inbounds i8, i8* %37, i64 5632
  %258 = bitcast i8* %257 to <64 x float>*
  %259 = load <64 x float>, <64 x float>* %258, align 64, !tbaa !4639
  %260 = fadd <64 x float> %61, %259
  %261 = fadd <64 x float> %58, %260
  %262 = fcmp ogt <64 x float> %261, zeroinitializer
  %263 = select <64 x i1> %262, <64 x float> %261, <64 x float> zeroinitializer
  %264 = mul i64 %indvars.iv56, 7696581394432
  %sext79 = add i64 %264, 6047313952768
  %265 = ashr exact i64 %sext79, 32
  %266 = getelementptr inbounds float, float* %10, i64 %265
  %267 = bitcast float* %266 to <64 x float>*
  store <64 x float> %263, <64 x float>* %267, align 64, !tbaa !4642
  %268 = getelementptr inbounds i8, i8* %37, i64 5888
  %269 = bitcast i8* %268 to <64 x float>*
  %270 = load <64 x float>, <64 x float>* %269, align 64, !tbaa !4639
  %271 = fadd <64 x float> %61, %270
  %272 = fadd <64 x float> %58, %271
  %273 = fcmp ogt <64 x float> %272, zeroinitializer
  %274 = select <64 x i1> %273, <64 x float> %272, <64 x float> zeroinitializer
  %275 = mul i64 %indvars.iv56, 7696581394432
  %sext66 = add i64 %275, 6322191859712
  %276 = ashr exact i64 %sext66, 32
  %277 = getelementptr inbounds float, float* %10, i64 %276
  %278 = bitcast float* %277 to <64 x float>*
  store <64 x float> %274, <64 x float>* %278, align 64, !tbaa !4642
  %279 = getelementptr inbounds i8, i8* %37, i64 2560
  %280 = bitcast i8* %279 to <64 x float>*
  %281 = load <64 x float>, <64 x float>* %280, align 64, !tbaa !4639
  %282 = fadd <64 x float> %61, %281
  %283 = fadd <64 x float> %58, %282
  %284 = fcmp ogt <64 x float> %283, zeroinitializer
  %285 = select <64 x i1> %284, <64 x float> %283, <64 x float> zeroinitializer
  %286 = mul i64 %indvars.iv56, 7696581394432
  %sext80 = add i64 %286, 2748779069440
  %287 = ashr exact i64 %sext80, 32
  %288 = getelementptr inbounds float, float* %10, i64 %287
  %289 = bitcast float* %288 to <64 x float>*
  store <64 x float> %285, <64 x float>* %289, align 64, !tbaa !4642
  %290 = getelementptr inbounds i8, i8* %37, i64 2816
  %291 = bitcast i8* %290 to <64 x float>*
  %292 = load <64 x float>, <64 x float>* %291, align 64, !tbaa !4639
  %293 = fadd <64 x float> %61, %292
  %294 = fadd <64 x float> %58, %293
  %295 = fcmp ogt <64 x float> %294, zeroinitializer
  %296 = select <64 x i1> %295, <64 x float> %294, <64 x float> zeroinitializer
  %297 = mul i64 %indvars.iv56, 7696581394432
  %sext67 = add i64 %297, 3023656976384
  %298 = ashr exact i64 %sext67, 32
  %299 = getelementptr inbounds float, float* %10, i64 %298
  %300 = bitcast float* %299 to <64 x float>*
  store <64 x float> %296, <64 x float>* %300, align 64, !tbaa !4642
  %301 = getelementptr inbounds i8, i8* %37, i64 6144
  %302 = bitcast i8* %301 to <64 x float>*
  %303 = load <64 x float>, <64 x float>* %302, align 64, !tbaa !4639
  %304 = fadd <64 x float> %61, %303
  %305 = fadd <64 x float> %58, %304
  %306 = fcmp ogt <64 x float> %305, zeroinitializer
  %307 = select <64 x i1> %306, <64 x float> %305, <64 x float> zeroinitializer
  %308 = mul i64 %indvars.iv56, 7696581394432
  %sext81 = add i64 %308, 6597069766656
  %309 = ashr exact i64 %sext81, 32
  %310 = getelementptr inbounds float, float* %10, i64 %309
  %311 = bitcast float* %310 to <64 x float>*
  store <64 x float> %307, <64 x float>* %311, align 64, !tbaa !4642
  %312 = getelementptr inbounds i8, i8* %37, i64 6400
  %313 = bitcast i8* %312 to <64 x float>*
  %314 = load <64 x float>, <64 x float>* %313, align 64, !tbaa !4639
  %315 = fadd <64 x float> %61, %314
  %316 = fadd <64 x float> %58, %315
  %317 = fcmp ogt <64 x float> %316, zeroinitializer
  %318 = select <64 x i1> %317, <64 x float> %316, <64 x float> zeroinitializer
  %319 = mul i64 %indvars.iv56, 7696581394432
  %sext68 = add i64 %319, 6871947673600
  %320 = ashr exact i64 %sext68, 32
  %321 = getelementptr inbounds float, float* %10, i64 %320
  %322 = bitcast float* %321 to <64 x float>*
  store <64 x float> %318, <64 x float>* %322, align 64, !tbaa !4642
  %323 = getelementptr inbounds i8, i8* %37, i64 3072
  %324 = bitcast i8* %323 to <64 x float>*
  %325 = load <64 x float>, <64 x float>* %324, align 64, !tbaa !4639
  %326 = fadd <64 x float> %61, %325
  %327 = fadd <64 x float> %58, %326
  %328 = fcmp ogt <64 x float> %327, zeroinitializer
  %329 = select <64 x i1> %328, <64 x float> %327, <64 x float> zeroinitializer
  %330 = mul i64 %indvars.iv56, 7696581394432
  %sext82 = add i64 %330, 3298534883328
  %331 = ashr exact i64 %sext82, 32
  %332 = getelementptr inbounds float, float* %10, i64 %331
  %333 = bitcast float* %332 to <64 x float>*
  store <64 x float> %329, <64 x float>* %333, align 64, !tbaa !4642
  %334 = getelementptr inbounds i8, i8* %37, i64 3328
  %335 = bitcast i8* %334 to <64 x float>*
  %336 = load <64 x float>, <64 x float>* %335, align 64, !tbaa !4639
  %337 = fadd <64 x float> %61, %336
  %338 = fadd <64 x float> %58, %337
  %339 = fcmp ogt <64 x float> %338, zeroinitializer
  %340 = select <64 x i1> %339, <64 x float> %338, <64 x float> zeroinitializer
  %341 = mul i64 %indvars.iv56, 7696581394432
  %sext69 = add i64 %341, 3573412790272
  %342 = ashr exact i64 %sext69, 32
  %343 = getelementptr inbounds float, float* %10, i64 %342
  %344 = bitcast float* %343 to <64 x float>*
  store <64 x float> %340, <64 x float>* %344, align 64, !tbaa !4642
  %345 = getelementptr inbounds i8, i8* %37, i64 6656
  %346 = bitcast i8* %345 to <64 x float>*
  %347 = load <64 x float>, <64 x float>* %346, align 64, !tbaa !4639
  %348 = fadd <64 x float> %61, %347
  %349 = fadd <64 x float> %58, %348
  %350 = fcmp ogt <64 x float> %349, zeroinitializer
  %351 = select <64 x i1> %350, <64 x float> %349, <64 x float> zeroinitializer
  %352 = mul i64 %indvars.iv56, 7696581394432
  %sext83 = add i64 %352, 7146825580544
  %353 = ashr exact i64 %sext83, 32
  %354 = getelementptr inbounds float, float* %10, i64 %353
  %355 = bitcast float* %354 to <64 x float>*
  store <64 x float> %351, <64 x float>* %355, align 64, !tbaa !4642
  %356 = getelementptr inbounds i8, i8* %37, i64 6912
  %357 = bitcast i8* %356 to <64 x float>*
  %358 = load <64 x float>, <64 x float>* %357, align 64, !tbaa !4639
  %359 = fadd <64 x float> %61, %358
  %360 = fadd <64 x float> %58, %359
  %361 = fcmp ogt <64 x float> %360, zeroinitializer
  %362 = select <64 x i1> %361, <64 x float> %360, <64 x float> zeroinitializer
  %363 = mul i64 %indvars.iv56, 7696581394432
  %sext70 = add i64 %363, 7421703487488
  %364 = ashr exact i64 %sext70, 32
  %365 = getelementptr inbounds float, float* %10, i64 %364
  %366 = bitcast float* %365 to <64 x float>*
  store <64 x float> %362, <64 x float>* %366, align 64, !tbaa !4642
  %367 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %368 = tail call i32 %367(i32 1, i32 %19, i8* nonnull %37)
  %indvars.iv.next57 = add nsw i64 %indvars.iv56, 1
  %369 = icmp slt i64 %indvars.iv.next57, %35
  br i1 %369, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end9.7, %for_body
  %indvars.iv43 = phi i64 [ 0, %for_body ], [ %indvars.iv.next44, %for_end9.7 ]
  %370 = shl nsw i64 %indvars.iv43, 7
  %371 = getelementptr inbounds float, float* %38, i64 %370
  %372 = bitcast float* %371 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %372, align 64, !tbaa !4639
  %373 = or i64 %370, 64
  %374 = getelementptr inbounds float, float* %38, i64 %373
  %375 = bitcast float* %374 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %375, align 64, !tbaa !4639
  %376 = add nuw nsw i64 %370, 896
  %377 = getelementptr inbounds float, float* %38, i64 %376
  %378 = bitcast float* %377 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %378, align 64, !tbaa !4639
  %379 = add nuw nsw i64 %370, 960
  %380 = getelementptr inbounds float, float* %38, i64 %379
  %381 = bitcast float* %380 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %381, align 64, !tbaa !4639
  %382 = shl i64 %indvars.iv43, 8
  %383 = add nsw i64 %382, %45
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %384 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %416, %for_body8 ]
  %385 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %410, %for_body8 ]
  %386 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %404, %for_body8 ]
  %387 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %398, %for_body8 ]
  %388 = add nsw i64 %383, %indvars.iv
  %389 = getelementptr inbounds float, float* %4, i64 %388
  %390 = load float, float* %389, align 4, !tbaa !4645
  %391 = insertelement <64 x float> undef, float %390, i32 0
  %392 = shufflevector <64 x float> %391, <64 x float> undef, <64 x i32> zeroinitializer
  %393 = shl i64 %indvars.iv, 6
  %394 = add nuw nsw i64 %393, %44
  %395 = getelementptr inbounds float, float* %7, i64 %394
  %396 = bitcast float* %395 to <64 x float>*
  %397 = load <64 x float>, <64 x float>* %396, align 64, !tbaa !4648
  %398 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %392, <64 x float> %397, <64 x float> %387)
  %399 = add nsw i64 %388, 128
  %400 = getelementptr inbounds float, float* %4, i64 %399
  %401 = load float, float* %400, align 4, !tbaa !4645
  %402 = insertelement <64 x float> undef, float %401, i32 0
  %403 = shufflevector <64 x float> %402, <64 x float> undef, <64 x i32> zeroinitializer
  %404 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %403, <64 x float> %397, <64 x float> %386)
  %405 = add nsw i64 %388, 3584
  %406 = getelementptr inbounds float, float* %4, i64 %405
  %407 = load float, float* %406, align 4, !tbaa !4645
  %408 = insertelement <64 x float> undef, float %407, i32 0
  %409 = shufflevector <64 x float> %408, <64 x float> undef, <64 x i32> zeroinitializer
  %410 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %409, <64 x float> %397, <64 x float> %385)
  %411 = add nsw i64 %388, 3712
  %412 = getelementptr inbounds float, float* %4, i64 %411
  %413 = load float, float* %412, align 4, !tbaa !4645
  %414 = insertelement <64 x float> undef, float %413, i32 0
  %415 = shufflevector <64 x float> %414, <64 x float> undef, <64 x i32> zeroinitializer
  %416 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %415, <64 x float> %397, <64 x float> %384)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %417 = add nsw i64 %383, 50176
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %418 = phi <64 x float> [ %416, %for_end9 ], [ %450, %for_body8.1 ]
  %419 = phi <64 x float> [ %410, %for_end9 ], [ %444, %for_body8.1 ]
  %420 = phi <64 x float> [ %404, %for_end9 ], [ %438, %for_body8.1 ]
  %421 = phi <64 x float> [ %398, %for_end9 ], [ %432, %for_body8.1 ]
  %422 = add nsw i64 %417, %indvars.iv.1
  %423 = getelementptr inbounds float, float* %4, i64 %422
  %424 = load float, float* %423, align 4, !tbaa !4645
  %425 = insertelement <64 x float> undef, float %424, i32 0
  %426 = shufflevector <64 x float> %425, <64 x float> undef, <64 x i32> zeroinitializer
  %427 = shl i64 %indvars.iv.1, 6
  %428 = add nuw nsw i64 %46, %427
  %429 = getelementptr inbounds float, float* %7, i64 %428
  %430 = bitcast float* %429 to <64 x float>*
  %431 = load <64 x float>, <64 x float>* %430, align 64, !tbaa !4648
  %432 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %426, <64 x float> %431, <64 x float> %421)
  %433 = add nsw i64 %422, 128
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = load float, float* %434, align 4, !tbaa !4645
  %436 = insertelement <64 x float> undef, float %435, i32 0
  %437 = shufflevector <64 x float> %436, <64 x float> undef, <64 x i32> zeroinitializer
  %438 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %437, <64 x float> %431, <64 x float> %420)
  %439 = add nsw i64 %422, 3584
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = load float, float* %440, align 4, !tbaa !4645
  %442 = insertelement <64 x float> undef, float %441, i32 0
  %443 = shufflevector <64 x float> %442, <64 x float> undef, <64 x i32> zeroinitializer
  %444 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %443, <64 x float> %431, <64 x float> %419)
  %445 = add nsw i64 %422, 3712
  %446 = getelementptr inbounds float, float* %4, i64 %445
  %447 = load float, float* %446, align 4, !tbaa !4645
  %448 = insertelement <64 x float> undef, float %447, i32 0
  %449 = shufflevector <64 x float> %448, <64 x float> undef, <64 x i32> zeroinitializer
  %450 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %449, <64 x float> %431, <64 x float> %418)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 64
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %451 = add nsw i64 %383, 100352
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %452 = phi <64 x float> [ %450, %for_end9.1 ], [ %484, %for_body8.2 ]
  %453 = phi <64 x float> [ %444, %for_end9.1 ], [ %478, %for_body8.2 ]
  %454 = phi <64 x float> [ %438, %for_end9.1 ], [ %472, %for_body8.2 ]
  %455 = phi <64 x float> [ %432, %for_end9.1 ], [ %466, %for_body8.2 ]
  %456 = add nuw nsw i64 %451, %indvars.iv.2
  %457 = getelementptr inbounds float, float* %4, i64 %456
  %458 = load float, float* %457, align 4, !tbaa !4645
  %459 = insertelement <64 x float> undef, float %458, i32 0
  %460 = shufflevector <64 x float> %459, <64 x float> undef, <64 x i32> zeroinitializer
  %461 = shl i64 %indvars.iv.2, 6
  %462 = add nuw nsw i64 %47, %461
  %463 = getelementptr inbounds float, float* %7, i64 %462
  %464 = bitcast float* %463 to <64 x float>*
  %465 = load <64 x float>, <64 x float>* %464, align 64, !tbaa !4648
  %466 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %460, <64 x float> %465, <64 x float> %455)
  %467 = add nsw i64 %456, 128
  %468 = getelementptr inbounds float, float* %4, i64 %467
  %469 = load float, float* %468, align 4, !tbaa !4645
  %470 = insertelement <64 x float> undef, float %469, i32 0
  %471 = shufflevector <64 x float> %470, <64 x float> undef, <64 x i32> zeroinitializer
  %472 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %471, <64 x float> %465, <64 x float> %454)
  %473 = add nsw i64 %456, 3584
  %474 = getelementptr inbounds float, float* %4, i64 %473
  %475 = load float, float* %474, align 4, !tbaa !4645
  %476 = insertelement <64 x float> undef, float %475, i32 0
  %477 = shufflevector <64 x float> %476, <64 x float> undef, <64 x i32> zeroinitializer
  %478 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %477, <64 x float> %465, <64 x float> %453)
  %479 = add nsw i64 %456, 3712
  %480 = getelementptr inbounds float, float* %4, i64 %479
  %481 = load float, float* %480, align 4, !tbaa !4645
  %482 = insertelement <64 x float> undef, float %481, i32 0
  %483 = shufflevector <64 x float> %482, <64 x float> undef, <64 x i32> zeroinitializer
  %484 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %483, <64 x float> %465, <64 x float> %452)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 64
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  %485 = add nsw i64 %383, 150528
  br label %for_body8.3

for_body8.3:                                      ; preds = %for_body8.3, %for_end9.2
  %indvars.iv.3 = phi i64 [ 0, %for_end9.2 ], [ %indvars.iv.next.3, %for_body8.3 ]
  %486 = phi <64 x float> [ %484, %for_end9.2 ], [ %518, %for_body8.3 ]
  %487 = phi <64 x float> [ %478, %for_end9.2 ], [ %512, %for_body8.3 ]
  %488 = phi <64 x float> [ %472, %for_end9.2 ], [ %506, %for_body8.3 ]
  %489 = phi <64 x float> [ %466, %for_end9.2 ], [ %500, %for_body8.3 ]
  %490 = add nuw nsw i64 %485, %indvars.iv.3
  %491 = getelementptr inbounds float, float* %4, i64 %490
  %492 = load float, float* %491, align 4, !tbaa !4645
  %493 = insertelement <64 x float> undef, float %492, i32 0
  %494 = shufflevector <64 x float> %493, <64 x float> undef, <64 x i32> zeroinitializer
  %495 = shl i64 %indvars.iv.3, 6
  %496 = add nuw nsw i64 %48, %495
  %497 = getelementptr inbounds float, float* %7, i64 %496
  %498 = bitcast float* %497 to <64 x float>*
  %499 = load <64 x float>, <64 x float>* %498, align 64, !tbaa !4648
  %500 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %494, <64 x float> %499, <64 x float> %489)
  %501 = add nsw i64 %490, 128
  %502 = getelementptr inbounds float, float* %4, i64 %501
  %503 = load float, float* %502, align 4, !tbaa !4645
  %504 = insertelement <64 x float> undef, float %503, i32 0
  %505 = shufflevector <64 x float> %504, <64 x float> undef, <64 x i32> zeroinitializer
  %506 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %505, <64 x float> %499, <64 x float> %488)
  %507 = add nsw i64 %490, 3584
  %508 = getelementptr inbounds float, float* %4, i64 %507
  %509 = load float, float* %508, align 4, !tbaa !4645
  %510 = insertelement <64 x float> undef, float %509, i32 0
  %511 = shufflevector <64 x float> %510, <64 x float> undef, <64 x i32> zeroinitializer
  %512 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %511, <64 x float> %499, <64 x float> %487)
  %513 = add nsw i64 %490, 3712
  %514 = getelementptr inbounds float, float* %4, i64 %513
  %515 = load float, float* %514, align 4, !tbaa !4645
  %516 = insertelement <64 x float> undef, float %515, i32 0
  %517 = shufflevector <64 x float> %516, <64 x float> undef, <64 x i32> zeroinitializer
  %518 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %517, <64 x float> %499, <64 x float> %486)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 64
  br i1 %exitcond.3, label %for_end9.3, label %for_body8.3, !prof !50

for_end9.3:                                       ; preds = %for_body8.3
  %519 = add nsw i64 %383, 200704
  br label %for_body8.4

for_body8.4:                                      ; preds = %for_body8.4, %for_end9.3
  %indvars.iv.4 = phi i64 [ 0, %for_end9.3 ], [ %indvars.iv.next.4, %for_body8.4 ]
  %520 = phi <64 x float> [ %518, %for_end9.3 ], [ %552, %for_body8.4 ]
  %521 = phi <64 x float> [ %512, %for_end9.3 ], [ %546, %for_body8.4 ]
  %522 = phi <64 x float> [ %506, %for_end9.3 ], [ %540, %for_body8.4 ]
  %523 = phi <64 x float> [ %500, %for_end9.3 ], [ %534, %for_body8.4 ]
  %524 = add nuw nsw i64 %519, %indvars.iv.4
  %525 = getelementptr inbounds float, float* %4, i64 %524
  %526 = load float, float* %525, align 4, !tbaa !4645
  %527 = insertelement <64 x float> undef, float %526, i32 0
  %528 = shufflevector <64 x float> %527, <64 x float> undef, <64 x i32> zeroinitializer
  %529 = shl i64 %indvars.iv.4, 6
  %530 = add nuw nsw i64 %49, %529
  %531 = getelementptr inbounds float, float* %7, i64 %530
  %532 = bitcast float* %531 to <64 x float>*
  %533 = load <64 x float>, <64 x float>* %532, align 64, !tbaa !4648
  %534 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %528, <64 x float> %533, <64 x float> %523)
  %535 = add nsw i64 %524, 128
  %536 = getelementptr inbounds float, float* %4, i64 %535
  %537 = load float, float* %536, align 4, !tbaa !4645
  %538 = insertelement <64 x float> undef, float %537, i32 0
  %539 = shufflevector <64 x float> %538, <64 x float> undef, <64 x i32> zeroinitializer
  %540 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %539, <64 x float> %533, <64 x float> %522)
  %541 = add nsw i64 %524, 3584
  %542 = getelementptr inbounds float, float* %4, i64 %541
  %543 = load float, float* %542, align 4, !tbaa !4645
  %544 = insertelement <64 x float> undef, float %543, i32 0
  %545 = shufflevector <64 x float> %544, <64 x float> undef, <64 x i32> zeroinitializer
  %546 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %545, <64 x float> %533, <64 x float> %521)
  %547 = add nsw i64 %524, 3712
  %548 = getelementptr inbounds float, float* %4, i64 %547
  %549 = load float, float* %548, align 4, !tbaa !4645
  %550 = insertelement <64 x float> undef, float %549, i32 0
  %551 = shufflevector <64 x float> %550, <64 x float> undef, <64 x i32> zeroinitializer
  %552 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %551, <64 x float> %533, <64 x float> %520)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 64
  br i1 %exitcond.4, label %for_end9.4, label %for_body8.4, !prof !50

for_end9.4:                                       ; preds = %for_body8.4
  %553 = add nsw i64 %383, 250880
  br label %for_body8.5

for_body8.5:                                      ; preds = %for_body8.5, %for_end9.4
  %indvars.iv.5 = phi i64 [ 0, %for_end9.4 ], [ %indvars.iv.next.5, %for_body8.5 ]
  %554 = phi <64 x float> [ %552, %for_end9.4 ], [ %586, %for_body8.5 ]
  %555 = phi <64 x float> [ %546, %for_end9.4 ], [ %580, %for_body8.5 ]
  %556 = phi <64 x float> [ %540, %for_end9.4 ], [ %574, %for_body8.5 ]
  %557 = phi <64 x float> [ %534, %for_end9.4 ], [ %568, %for_body8.5 ]
  %558 = add nuw nsw i64 %553, %indvars.iv.5
  %559 = getelementptr inbounds float, float* %4, i64 %558
  %560 = load float, float* %559, align 4, !tbaa !4645
  %561 = insertelement <64 x float> undef, float %560, i32 0
  %562 = shufflevector <64 x float> %561, <64 x float> undef, <64 x i32> zeroinitializer
  %563 = shl i64 %indvars.iv.5, 6
  %564 = add nuw nsw i64 %50, %563
  %565 = getelementptr inbounds float, float* %7, i64 %564
  %566 = bitcast float* %565 to <64 x float>*
  %567 = load <64 x float>, <64 x float>* %566, align 64, !tbaa !4648
  %568 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %562, <64 x float> %567, <64 x float> %557)
  %569 = add nsw i64 %558, 128
  %570 = getelementptr inbounds float, float* %4, i64 %569
  %571 = load float, float* %570, align 4, !tbaa !4645
  %572 = insertelement <64 x float> undef, float %571, i32 0
  %573 = shufflevector <64 x float> %572, <64 x float> undef, <64 x i32> zeroinitializer
  %574 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %573, <64 x float> %567, <64 x float> %556)
  %575 = add nsw i64 %558, 3584
  %576 = getelementptr inbounds float, float* %4, i64 %575
  %577 = load float, float* %576, align 4, !tbaa !4645
  %578 = insertelement <64 x float> undef, float %577, i32 0
  %579 = shufflevector <64 x float> %578, <64 x float> undef, <64 x i32> zeroinitializer
  %580 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %579, <64 x float> %567, <64 x float> %555)
  %581 = add nsw i64 %558, 3712
  %582 = getelementptr inbounds float, float* %4, i64 %581
  %583 = load float, float* %582, align 4, !tbaa !4645
  %584 = insertelement <64 x float> undef, float %583, i32 0
  %585 = shufflevector <64 x float> %584, <64 x float> undef, <64 x i32> zeroinitializer
  %586 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %585, <64 x float> %567, <64 x float> %554)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 64
  br i1 %exitcond.5, label %for_end9.5, label %for_body8.5, !prof !50

for_end9.5:                                       ; preds = %for_body8.5
  %587 = add nsw i64 %383, 301056
  br label %for_body8.6

for_body8.6:                                      ; preds = %for_body8.6, %for_end9.5
  %indvars.iv.6 = phi i64 [ 0, %for_end9.5 ], [ %indvars.iv.next.6, %for_body8.6 ]
  %588 = phi <64 x float> [ %586, %for_end9.5 ], [ %620, %for_body8.6 ]
  %589 = phi <64 x float> [ %580, %for_end9.5 ], [ %614, %for_body8.6 ]
  %590 = phi <64 x float> [ %574, %for_end9.5 ], [ %608, %for_body8.6 ]
  %591 = phi <64 x float> [ %568, %for_end9.5 ], [ %602, %for_body8.6 ]
  %592 = add nuw nsw i64 %587, %indvars.iv.6
  %593 = getelementptr inbounds float, float* %4, i64 %592
  %594 = load float, float* %593, align 4, !tbaa !4645
  %595 = insertelement <64 x float> undef, float %594, i32 0
  %596 = shufflevector <64 x float> %595, <64 x float> undef, <64 x i32> zeroinitializer
  %597 = shl i64 %indvars.iv.6, 6
  %598 = add nuw nsw i64 %51, %597
  %599 = getelementptr inbounds float, float* %7, i64 %598
  %600 = bitcast float* %599 to <64 x float>*
  %601 = load <64 x float>, <64 x float>* %600, align 64, !tbaa !4648
  %602 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %596, <64 x float> %601, <64 x float> %591)
  %603 = add nsw i64 %592, 128
  %604 = getelementptr inbounds float, float* %4, i64 %603
  %605 = load float, float* %604, align 4, !tbaa !4645
  %606 = insertelement <64 x float> undef, float %605, i32 0
  %607 = shufflevector <64 x float> %606, <64 x float> undef, <64 x i32> zeroinitializer
  %608 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %607, <64 x float> %601, <64 x float> %590)
  %609 = add nsw i64 %592, 3584
  %610 = getelementptr inbounds float, float* %4, i64 %609
  %611 = load float, float* %610, align 4, !tbaa !4645
  %612 = insertelement <64 x float> undef, float %611, i32 0
  %613 = shufflevector <64 x float> %612, <64 x float> undef, <64 x i32> zeroinitializer
  %614 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %613, <64 x float> %601, <64 x float> %589)
  %615 = add nsw i64 %592, 3712
  %616 = getelementptr inbounds float, float* %4, i64 %615
  %617 = load float, float* %616, align 4, !tbaa !4645
  %618 = insertelement <64 x float> undef, float %617, i32 0
  %619 = shufflevector <64 x float> %618, <64 x float> undef, <64 x i32> zeroinitializer
  %620 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %619, <64 x float> %601, <64 x float> %588)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 64
  br i1 %exitcond.6, label %for_end9.6, label %for_body8.6, !prof !50

for_end9.6:                                       ; preds = %for_body8.6
  %621 = add nsw i64 %383, 351232
  br label %for_body8.7

for_body8.7:                                      ; preds = %for_body8.7, %for_end9.6
  %indvars.iv.7 = phi i64 [ 0, %for_end9.6 ], [ %indvars.iv.next.7, %for_body8.7 ]
  %622 = phi <64 x float> [ %620, %for_end9.6 ], [ %654, %for_body8.7 ]
  %623 = phi <64 x float> [ %614, %for_end9.6 ], [ %648, %for_body8.7 ]
  %624 = phi <64 x float> [ %608, %for_end9.6 ], [ %642, %for_body8.7 ]
  %625 = phi <64 x float> [ %602, %for_end9.6 ], [ %636, %for_body8.7 ]
  %626 = add nuw nsw i64 %621, %indvars.iv.7
  %627 = getelementptr inbounds float, float* %4, i64 %626
  %628 = load float, float* %627, align 4, !tbaa !4645
  %629 = insertelement <64 x float> undef, float %628, i32 0
  %630 = shufflevector <64 x float> %629, <64 x float> undef, <64 x i32> zeroinitializer
  %631 = shl i64 %indvars.iv.7, 6
  %632 = add nuw nsw i64 %52, %631
  %633 = getelementptr inbounds float, float* %7, i64 %632
  %634 = bitcast float* %633 to <64 x float>*
  %635 = load <64 x float>, <64 x float>* %634, align 64, !tbaa !4648
  %636 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %630, <64 x float> %635, <64 x float> %625)
  %637 = add nsw i64 %626, 128
  %638 = getelementptr inbounds float, float* %4, i64 %637
  %639 = load float, float* %638, align 4, !tbaa !4645
  %640 = insertelement <64 x float> undef, float %639, i32 0
  %641 = shufflevector <64 x float> %640, <64 x float> undef, <64 x i32> zeroinitializer
  %642 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %641, <64 x float> %635, <64 x float> %624)
  %643 = add nsw i64 %626, 3584
  %644 = getelementptr inbounds float, float* %4, i64 %643
  %645 = load float, float* %644, align 4, !tbaa !4645
  %646 = insertelement <64 x float> undef, float %645, i32 0
  %647 = shufflevector <64 x float> %646, <64 x float> undef, <64 x i32> zeroinitializer
  %648 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %647, <64 x float> %635, <64 x float> %623)
  %649 = add nsw i64 %626, 3712
  %650 = getelementptr inbounds float, float* %4, i64 %649
  %651 = load float, float* %650, align 4, !tbaa !4645
  %652 = insertelement <64 x float> undef, float %651, i32 0
  %653 = shufflevector <64 x float> %652, <64 x float> undef, <64 x i32> zeroinitializer
  %654 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %653, <64 x float> %635, <64 x float> %622)
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 64
  br i1 %exitcond.7, label %for_end9.7, label %for_body8.7, !prof !50

for_end9.7:                                       ; preds = %for_body8.7
  store <64 x float> %636, <64 x float>* %372, align 64, !tbaa !4639
  store <64 x float> %642, <64 x float>* %375, align 64, !tbaa !4639
  store <64 x float> %648, <64 x float>* %378, align 64, !tbaa !4639
  store <64 x float> %654, <64 x float>* %381, align 64, !tbaa !4639
  %indvars.iv.next44 = add nuw nsw i64 %indvars.iv43, 1
  %exitcond45 = icmp eq i64 %indvars.iv.next44, 7
  br i1 %exitcond45, label %for_begin10.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 7
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([113 x i8], [113 x i8]* @.str.382, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !4651
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !4665
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !4668
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !4670
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !4674
  %36 = getelementptr inbounds i8, i8* %0, i64 48
  %37 = bitcast i8* %36 to %1**
  %38 = load %1*, %1** %37, align 8
  %39 = getelementptr inbounds i8, i8* %1, i64 24
  %40 = bitcast i8* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !4676
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %49 = load i32, i32* %48, align 4
  %50 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %51 = load i32, i32* %50, align 4
  %52 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  %76 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %77 = load i8*, i8** %76, align 8
  %78 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %79 = load i64*, i64** %78, align 8
  %80 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %81 = load i64*, i64** %80, align 8
  %82 = getelementptr inbounds %1, %1* %38, i64 0, i32 0
  %83 = load i8*, i8** %82, align 8
  %84 = getelementptr inbounds %1, %1* %38, i64 0, i32 4
  %85 = load i64*, i64** %84, align 8
  %86 = getelementptr inbounds %1, %1* %38, i64 0, i32 5
  %87 = load i64*, i64** %86, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %88 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %88(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.383, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %89 = getelementptr inbounds i8, i8* %1, i64 4
  %90 = bitcast i8* %89 to i32*
  %91 = load i32, i32* %90, align 4, !tbaa !4679
  switch i32 %91, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.384, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.385, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.386, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.387, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.388, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  switch i32 %41, label %assert_fail13 [
    i32 13, label %assert_end14
    i32 7, label %assert_end14
    i32 4, label %assert_end14
    i32 3, label %assert_end14
  ]

assert_fail13:                                    ; preds = %assert_end12
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.389, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12, %assert_end12, %assert_end12, %assert_end12
  %98 = icmp eq i32 %49, 1
  br i1 %98, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %99 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %99(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %100 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %101 = load i32, i32* %100, align 4
  %102 = icmp eq i32 %101, 5
  br i1 %102, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %104 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %105 = load i16, i16* %104, align 2
  %106 = icmp eq i16 %105, 1
  %107 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %108 = load i8, i8* %107, align 1
  %109 = icmp eq i8 %108, 32
  %110 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %111 = load i8, i8* %110, align 1
  %112 = icmp eq i8 %111, 2
  %113 = and i1 %109, %112
  %114 = and i1 %106, %113
  br i1 %114, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %116 = load i64, i64* %45, align 8, !tbaa !4681
  %117 = trunc i64 %116 to i32
  %118 = icmp eq i32 %117, 1
  br i1 %118, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %119 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %119(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %120 = getelementptr inbounds i64, i64* %45, i64 1
  %121 = load i64, i64* %120, align 8, !tbaa !4695
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %122, 16
  br i1 %123, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %124 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %124(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %125 = getelementptr inbounds i64, i64* %45, i64 2
  %126 = load i64, i64* %125, align 8, !tbaa !4697
  %127 = trunc i64 %126 to i32
  %128 = icmp eq i32 %127, 56
  br i1 %128, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %130 = getelementptr inbounds i64, i64* %45, i64 3
  %131 = load i64, i64* %130, align 8, !tbaa !4700
  %132 = trunc i64 %131 to i32
  %133 = icmp eq i32 %132, 56
  br i1 %133, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %135 = getelementptr inbounds i64, i64* %45, i64 4
  %136 = load i64, i64* %135, align 8, !tbaa !4702
  %137 = trunc i64 %136 to i32
  %138 = icmp eq i32 %137, 4
  br i1 %138, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %139 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %139(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %140 = icmp eq i64* %47, null
  br i1 %140, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end30
  %141 = bitcast i64* %47 to <4 x i64>*
  %142 = load <4 x i64>, <4 x i64>* %141, align 8, !tbaa !4706
  %143 = trunc <4 x i64> %142 to <4 x i32>
  %144 = icmp eq <4 x i32> %143, <i32 200704, i32 12544, i32 224, i32 4>
  %145 = getelementptr inbounds i64, i64* %47, i64 4
  %146 = load i64, i64* %145, align 8, !tbaa !4718
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 1
  %rdx.shuf197 = shufflevector <4 x i1> %144, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx198 = and <4 x i1> %144, %rdx.shuf197
  %rdx.shuf199 = shufflevector <4 x i1> %bin.rdx198, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx200 = and <4 x i1> %bin.rdx198, %rdx.shuf199
  %149 = extractelement <4 x i1> %bin.rdx200, i32 0
  %150 = and i1 %149, %148
  br i1 %150, label %if_end, label %assert_fail31, !prof !5

if_end:                                           ; preds = %assert_end30, %if_then
  %151 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %152 = load i64, i64* %151, align 8
  %153 = icmp eq i64 %152, 0
  br i1 %153, label %assert_end34, label %assert_fail33, !prof !5

assert_fail31:                                    ; preds = %if_then
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_fail33:                                    ; preds = %if_end
  %155 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %155(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %if_end
  %156 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %157 = load i32, i32* %156, align 4
  %158 = icmp eq i32 %157, 6
  br i1 %158, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %160 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %161 = load i16, i16* %160, align 2
  %162 = icmp eq i16 %161, 1
  %163 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %164 = load i8, i8* %163, align 1
  %165 = icmp eq i8 %164, 32
  %166 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %167 = load i8, i8* %166, align 1
  %168 = icmp eq i8 %167, 2
  %169 = and i1 %165, %168
  %170 = and i1 %162, %169
  br i1 %170, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %172 = load i64, i64* %55, align 8, !tbaa !4722
  %173 = trunc i64 %172 to i32
  %174 = icmp eq i32 %173, 8
  br i1 %174, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %175 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %175(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.190, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %176 = getelementptr inbounds i64, i64* %55, i64 1
  %177 = load i64, i64* %176, align 8, !tbaa !4736
  %178 = trunc i64 %177 to i32
  %179 = icmp eq i32 %178, 16
  br i1 %179, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %180 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %180(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.31, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %181 = getelementptr inbounds i64, i64* %55, i64 2
  %182 = load i64, i64* %181, align 8, !tbaa !4738
  %183 = trunc i64 %182 to i32
  %184 = icmp eq i32 %183, 1
  br i1 %184, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %185 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %185(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %186 = getelementptr inbounds i64, i64* %55, i64 3
  %187 = load i64, i64* %186, align 8, !tbaa !4741
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  br i1 %189, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %190 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %190(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %191 = getelementptr inbounds i64, i64* %55, i64 4
  %192 = load i64, i64* %191, align 8, !tbaa !4743
  %193 = trunc i64 %192 to i32
  %194 = icmp eq i32 %193, 4
  br i1 %194, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %196 = getelementptr inbounds i64, i64* %55, i64 5
  %197 = load i64, i64* %196, align 8, !tbaa !4747
  %198 = trunc i64 %197 to i32
  %199 = icmp eq i32 %198, 32
  br i1 %199, label %assert_end50, label %assert_fail49, !prof !5

assert_fail49:                                    ; preds = %assert_end48
  %200 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %200(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %assert_end48
  %201 = icmp eq i64* %57, null
  br i1 %201, label %if_end52, label %if_then51, !prof !50

if_then51:                                        ; preds = %assert_end50
  %202 = bitcast i64* %57 to <4 x i64>*
  %203 = load <4 x i64>, <4 x i64>* %202, align 8, !tbaa !4749
  %204 = trunc <4 x i64> %203 to <4 x i32>
  %205 = icmp eq <4 x i32> %204, <i32 2048, i32 128, i32 128, i32 128>
  %206 = getelementptr inbounds i64, i64* %57, i64 4
  %207 = load i64, i64* %206, align 8, !tbaa !4761
  %208 = trunc i64 %207 to i32
  %209 = icmp eq i32 %208, 32
  %210 = getelementptr inbounds i64, i64* %57, i64 5
  %211 = load i64, i64* %210, align 8, !tbaa !4765
  %212 = trunc i64 %211 to i32
  %213 = icmp eq i32 %212, 1
  %rdx.shuf193 = shufflevector <4 x i1> %205, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx194 = and <4 x i1> %205, %rdx.shuf193
  %rdx.shuf195 = shufflevector <4 x i1> %bin.rdx194, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx196 = and <4 x i1> %bin.rdx194, %rdx.shuf195
  %214 = extractelement <4 x i1> %bin.rdx196, i32 0
  %215 = and i1 %214, %209
  %216 = and i1 %215, %213
  br i1 %216, label %if_end52, label %assert_fail53, !prof !5

if_end52:                                         ; preds = %assert_end50, %if_then51
  %217 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %218 = load i64, i64* %217, align 8
  %219 = icmp eq i64 %218, 0
  br i1 %219, label %assert_end56, label %assert_fail55, !prof !5

assert_fail53:                                    ; preds = %if_then51
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([272 x i8], [272 x i8]* @.str.191, i64 0, i64 0))
  ret i32 -1

assert_fail55:                                    ; preds = %if_end52
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %if_end52
  %222 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %223 = load i32, i32* %222, align 4
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %226 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %227 = load i32, i32* %226, align 4
  %228 = icmp eq i32 %51, %227
  br i1 %228, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %229 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %229(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %230 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %231 = load i32, i32* %230, align 4
  %232 = icmp eq i32 %231, 4
  br i1 %232, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %234 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %235 = load i16, i16* %234, align 2
  %236 = icmp eq i16 %235, 1
  %237 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %238 = load i8, i8* %237, align 1
  %239 = icmp eq i8 %238, 32
  %240 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %241 = load i8, i8* %240, align 1
  %242 = icmp eq i8 %241, 2
  %243 = and i1 %239, %242
  %244 = and i1 %236, %243
  br i1 %244, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %246 = load i64, i64* %61, align 8, !tbaa !4767
  %247 = trunc i64 %246 to i32
  %248 = icmp eq i32 %247, 8
  br i1 %248, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.192, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %250 = getelementptr inbounds i64, i64* %61, i64 1
  %251 = load i64, i64* %250, align 8, !tbaa !4781
  %252 = trunc i64 %251 to i32
  %253 = icmp eq i32 %252, 1
  br i1 %253, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %254 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %254(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %255 = getelementptr inbounds i64, i64* %61, i64 2
  %256 = load i64, i64* %255, align 8, !tbaa !4783
  %257 = trunc i64 %256 to i32
  %258 = icmp eq i32 %257, 1
  br i1 %258, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %259 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %259(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %260 = getelementptr inbounds i64, i64* %61, i64 3
  %261 = load i64, i64* %260, align 8, !tbaa !4786
  %262 = trunc i64 %261 to i32
  %263 = icmp eq i32 %262, 32
  br i1 %263, label %assert_end72, label %assert_fail71, !prof !5

assert_fail71:                                    ; preds = %assert_end70
  %264 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %264(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end72:                                     ; preds = %assert_end70
  %265 = icmp eq i64* %63, null
  br i1 %265, label %if_end74, label %if_then73, !prof !50

if_then73:                                        ; preds = %assert_end72
  %266 = bitcast i64* %63 to <4 x i64>*
  %267 = load <4 x i64>, <4 x i64>* %266, align 8, !tbaa !4788
  %268 = trunc <4 x i64> %267 to <4 x i32>
  %269 = icmp eq <4 x i32> %268, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf189 = shufflevector <4 x i1> %269, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx190 = and <4 x i1> %269, %rdx.shuf189
  %rdx.shuf191 = shufflevector <4 x i1> %bin.rdx190, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx192 = and <4 x i1> %bin.rdx190, %rdx.shuf191
  %270 = extractelement <4 x i1> %bin.rdx192, i32 0
  br i1 %270, label %if_end74, label %assert_fail75, !prof !5

if_end74:                                         ; preds = %assert_end72, %if_then73
  %271 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %272 = load i64, i64* %271, align 8
  %273 = icmp eq i64 %272, 0
  br i1 %273, label %assert_end78, label %assert_fail77, !prof !5

assert_fail75:                                    ; preds = %if_then73
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail77:                                    ; preds = %if_end74
  %275 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %275(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %if_end74
  %276 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %277 = load i32, i32* %276, align 4
  %278 = icmp eq i32 %277, 1
  br i1 %278, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %279 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %279(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %280 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %281 = load i32, i32* %280, align 4
  %282 = icmp eq i32 %51, %281
  br i1 %282, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %283 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %283(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %284 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %285 = load i32, i32* %284, align 4
  %286 = icmp eq i32 %285, 4
  br i1 %286, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %288 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %289 = load i16, i16* %288, align 2
  %290 = icmp eq i16 %289, 1
  %291 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %292 = load i8, i8* %291, align 1
  %293 = icmp eq i8 %292, 32
  %294 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %295 = load i8, i8* %294, align 1
  %296 = icmp eq i8 %295, 2
  %297 = and i1 %293, %296
  %298 = and i1 %290, %297
  br i1 %298, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %300 = load i64, i64* %67, align 8, !tbaa !4800
  %301 = trunc i64 %300 to i32
  %302 = icmp eq i32 %301, 8
  br i1 %302, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.193, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %304 = getelementptr inbounds i64, i64* %67, i64 1
  %305 = load i64, i64* %304, align 8, !tbaa !4814
  %306 = trunc i64 %305 to i32
  %307 = icmp eq i32 %306, 1
  br i1 %307, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %308 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %308(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %309 = getelementptr inbounds i64, i64* %67, i64 2
  %310 = load i64, i64* %309, align 8, !tbaa !4816
  %311 = trunc i64 %310 to i32
  %312 = icmp eq i32 %311, 1
  br i1 %312, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %313 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %313(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %314 = getelementptr inbounds i64, i64* %67, i64 3
  %315 = load i64, i64* %314, align 8, !tbaa !4819
  %316 = trunc i64 %315 to i32
  %317 = icmp eq i32 %316, 32
  br i1 %317, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %318 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %318(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %319 = icmp eq i64* %69, null
  br i1 %319, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %320 = bitcast i64* %69 to <4 x i64>*
  %321 = load <4 x i64>, <4 x i64>* %320, align 8, !tbaa !4821
  %322 = trunc <4 x i64> %321 to <4 x i32>
  %323 = icmp eq <4 x i32> %322, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf185 = shufflevector <4 x i1> %323, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx186 = and <4 x i1> %323, %rdx.shuf185
  %rdx.shuf187 = shufflevector <4 x i1> %bin.rdx186, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx188 = and <4 x i1> %bin.rdx186, %rdx.shuf187
  %324 = extractelement <4 x i1> %bin.rdx188, i32 0
  br i1 %324, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %325 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %326 = load i64, i64* %325, align 8
  %327 = icmp eq i64 %326, 0
  br i1 %327, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %330 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %331, 1
  br i1 %332, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %334 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %51, %335
  br i1 %336, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %338 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %339 = load i32, i32* %338, align 4
  %340 = icmp eq i32 %339, 4
  br i1 %340, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %342 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %343 = load i16, i16* %342, align 2
  %344 = icmp eq i16 %343, 1
  %345 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %346 = load i8, i8* %345, align 1
  %347 = icmp eq i8 %346, 32
  %348 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %349 = load i8, i8* %348, align 1
  %350 = icmp eq i8 %349, 2
  %351 = and i1 %347, %350
  %352 = and i1 %344, %351
  br i1 %352, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %354 = load i64, i64* %73, align 8, !tbaa !4833
  %355 = trunc i64 %354 to i32
  %356 = icmp eq i32 %355, 8
  br i1 %356, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %357 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %357(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.194, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %358 = getelementptr inbounds i64, i64* %73, i64 1
  %359 = load i64, i64* %358, align 8, !tbaa !4847
  %360 = trunc i64 %359 to i32
  %361 = icmp eq i32 %360, 1
  br i1 %361, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %362 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %362(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %363 = getelementptr inbounds i64, i64* %73, i64 2
  %364 = load i64, i64* %363, align 8, !tbaa !4849
  %365 = trunc i64 %364 to i32
  %366 = icmp eq i32 %365, 1
  br i1 %366, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %368 = getelementptr inbounds i64, i64* %73, i64 3
  %369 = load i64, i64* %368, align 8, !tbaa !4852
  %370 = trunc i64 %369 to i32
  %371 = icmp eq i32 %370, 32
  br i1 %371, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %372 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %372(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.167, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %373 = icmp eq i64* %75, null
  br i1 %373, label %if_end118, label %if_then117, !prof !50

if_then117:                                       ; preds = %assert_end116
  %374 = bitcast i64* %75 to <4 x i64>*
  %375 = load <4 x i64>, <4 x i64>* %374, align 8, !tbaa !4854
  %376 = trunc <4 x i64> %375 to <4 x i32>
  %377 = icmp eq <4 x i32> %376, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf181 = shufflevector <4 x i1> %377, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx182 = and <4 x i1> %377, %rdx.shuf181
  %rdx.shuf183 = shufflevector <4 x i1> %bin.rdx182, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx184 = and <4 x i1> %bin.rdx182, %rdx.shuf183
  %378 = extractelement <4 x i1> %bin.rdx184, i32 0
  br i1 %378, label %if_end118, label %assert_fail119, !prof !5

if_end118:                                        ; preds = %assert_end116, %if_then117
  %379 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %380 = load i64, i64* %379, align 8
  %381 = icmp eq i64 %380, 0
  br i1 %381, label %assert_end122, label %assert_fail121, !prof !5

assert_fail119:                                   ; preds = %if_then117
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.168, i64 0, i64 0))
  ret i32 -1

assert_fail121:                                   ; preds = %if_end118
  %383 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %383(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %if_end118
  %384 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %385 = load i32, i32* %384, align 4
  %386 = icmp eq i32 %385, 1
  br i1 %386, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %387 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %387(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %388 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %389 = load i32, i32* %388, align 4
  %390 = icmp eq i32 %51, %389
  br i1 %390, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %391 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %391(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %392 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %393 = load i32, i32* %392, align 4
  %394 = icmp eq i32 %393, 5
  br i1 %394, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %395 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %395(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %396 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %397 = load i16, i16* %396, align 2
  %398 = icmp eq i16 %397, 1
  %399 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %400 = load i8, i8* %399, align 1
  %401 = icmp eq i8 %400, 32
  %402 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %403 = load i8, i8* %402, align 1
  %404 = icmp eq i8 %403, 2
  %405 = and i1 %401, %404
  %406 = and i1 %398, %405
  br i1 %406, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %407 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %407(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %408 = load i64, i64* %79, align 8, !tbaa !4866
  %409 = trunc i64 %408 to i32
  %410 = icmp eq i32 %409, 1
  br i1 %410, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %411 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %411(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %412 = getelementptr inbounds i64, i64* %79, i64 1
  %413 = load i64, i64* %412, align 8, !tbaa !4880
  %414 = trunc i64 %413 to i32
  %415 = icmp eq i32 %414, 8
  br i1 %415, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %416 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %416(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.195, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %417 = getelementptr inbounds i64, i64* %79, i64 2
  %418 = load i64, i64* %417, align 8, !tbaa !4882
  %419 = trunc i64 %418 to i32
  %420 = icmp eq i32 %419, 56
  br i1 %420, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %421 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %421(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.196, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %422 = getelementptr inbounds i64, i64* %79, i64 3
  %423 = load i64, i64* %422, align 8, !tbaa !4885
  %424 = trunc i64 %423 to i32
  %425 = icmp eq i32 %424, 56
  br i1 %425, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %426 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %426(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.197, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %427 = getelementptr inbounds i64, i64* %79, i64 4
  %428 = load i64, i64* %427, align 8, !tbaa !4887
  %429 = trunc i64 %428 to i32
  %430 = icmp eq i32 %429, 32
  br i1 %430, label %assert_end140, label %assert_fail139, !prof !5

assert_fail139:                                   ; preds = %assert_end138
  %431 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %431(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.175, i64 0, i64 0))
  ret i32 -1

assert_end140:                                    ; preds = %assert_end138
  %432 = icmp eq i64* %81, null
  br i1 %432, label %if_end142, label %if_then141, !prof !50

if_then141:                                       ; preds = %assert_end140
  %433 = bitcast i64* %81 to <4 x i64>*
  %434 = load <4 x i64>, <4 x i64>* %433, align 8, !tbaa !4891
  %435 = trunc <4 x i64> %434 to <4 x i32>
  %436 = icmp eq <4 x i32> %435, <i32 802816, i32 100352, i32 1792, i32 32>
  %437 = getelementptr inbounds i64, i64* %81, i64 4
  %438 = load i64, i64* %437, align 8, !tbaa !4903
  %439 = trunc i64 %438 to i32
  %440 = icmp eq i32 %439, 1
  %rdx.shuf177 = shufflevector <4 x i1> %436, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx178 = and <4 x i1> %436, %rdx.shuf177
  %rdx.shuf179 = shufflevector <4 x i1> %bin.rdx178, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx180 = and <4 x i1> %bin.rdx178, %rdx.shuf179
  %441 = extractelement <4 x i1> %bin.rdx180, i32 0
  %442 = and i1 %441, %440
  br i1 %442, label %if_end142, label %assert_fail143, !prof !5

if_end142:                                        ; preds = %assert_end140, %if_then141
  %443 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %444 = load i64, i64* %443, align 8
  %445 = icmp eq i64 %444, 0
  br i1 %445, label %assert_end146, label %assert_fail145, !prof !5

assert_fail143:                                   ; preds = %if_then141
  %446 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %446(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.198, i64 0, i64 0))
  ret i32 -1

assert_fail145:                                   ; preds = %if_end142
  %447 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %447(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %if_end142
  %448 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %449 = load i32, i32* %448, align 4
  %450 = icmp eq i32 %449, 1
  br i1 %450, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %451 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %451(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %452 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %453 = load i32, i32* %452, align 4
  %454 = icmp eq i32 %51, %453
  br i1 %454, label %assert_end150, label %assert_fail149, !prof !5

assert_fail149:                                   ; preds = %assert_end148
  %455 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %455(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end150:                                    ; preds = %assert_end148
  %456 = getelementptr inbounds %1, %1* %38, i64 0, i32 2
  %457 = load i32, i32* %456, align 4
  %458 = icmp eq i32 %457, 5
  br i1 %458, label %assert_end152, label %assert_fail151, !prof !5

assert_fail151:                                   ; preds = %assert_end150
  %459 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %459(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.310, i64 0, i64 0))
  ret i32 -1

assert_end152:                                    ; preds = %assert_end150
  %460 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 2
  %461 = load i16, i16* %460, align 2
  %462 = icmp eq i16 %461, 1
  %463 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 1
  %464 = load i8, i8* %463, align 1
  %465 = icmp eq i8 %464, 32
  %466 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 0
  %467 = load i8, i8* %466, align 1
  %468 = icmp eq i8 %467, 2
  %469 = and i1 %465, %468
  %470 = and i1 %462, %469
  br i1 %470, label %assert_end154, label %assert_fail153, !prof !5

assert_fail153:                                   ; preds = %assert_end152
  %471 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %471(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.311, i64 0, i64 0))
  ret i32 -1

assert_end154:                                    ; preds = %assert_end152
  %472 = load i64, i64* %85, align 8, !tbaa !4907
  %473 = trunc i64 %472 to i32
  %474 = icmp eq i32 %473, 1
  br i1 %474, label %assert_end156, label %assert_fail155, !prof !5

assert_fail155:                                   ; preds = %assert_end154
  %475 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %475(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.312, i64 0, i64 0))
  ret i32 -1

assert_end156:                                    ; preds = %assert_end154
  %476 = getelementptr inbounds i64, i64* %85, i64 1
  %477 = load i64, i64* %476, align 8, !tbaa !4921
  %478 = trunc i64 %477 to i32
  %479 = icmp eq i32 %478, 8
  br i1 %479, label %assert_end158, label %assert_fail157, !prof !5

assert_fail157:                                   ; preds = %assert_end156
  %480 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %480(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.390, i64 0, i64 0))
  ret i32 -1

assert_end158:                                    ; preds = %assert_end156
  %481 = getelementptr inbounds i64, i64* %85, i64 2
  %482 = load i64, i64* %481, align 8, !tbaa !4923
  %483 = trunc i64 %482 to i32
  %484 = icmp eq i32 %483, 56
  br i1 %484, label %assert_end160, label %assert_fail159, !prof !5

assert_fail159:                                   ; preds = %assert_end158
  %485 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %485(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.391, i64 0, i64 0))
  ret i32 -1

assert_end160:                                    ; preds = %assert_end158
  %486 = getelementptr inbounds i64, i64* %85, i64 3
  %487 = load i64, i64* %486, align 8, !tbaa !4926
  %488 = trunc i64 %487 to i32
  %489 = icmp eq i32 %488, 56
  br i1 %489, label %assert_end162, label %assert_fail161, !prof !5

assert_fail161:                                   ; preds = %assert_end160
  %490 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %490(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.392, i64 0, i64 0))
  ret i32 -1

assert_end162:                                    ; preds = %assert_end160
  %491 = getelementptr inbounds i64, i64* %85, i64 4
  %492 = load i64, i64* %491, align 8, !tbaa !4928
  %493 = trunc i64 %492 to i32
  %494 = icmp eq i32 %493, 32
  br i1 %494, label %assert_end164, label %assert_fail163, !prof !5

assert_fail163:                                   ; preds = %assert_end162
  %495 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %495(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.316, i64 0, i64 0))
  ret i32 -1

assert_end164:                                    ; preds = %assert_end162
  %496 = icmp eq i64* %87, null
  br i1 %496, label %if_end166, label %if_then165, !prof !50

if_then165:                                       ; preds = %assert_end164
  %497 = bitcast i64* %87 to <4 x i64>*
  %498 = load <4 x i64>, <4 x i64>* %497, align 8, !tbaa !4932
  %499 = trunc <4 x i64> %498 to <4 x i32>
  %500 = icmp eq <4 x i32> %499, <i32 802816, i32 100352, i32 1792, i32 32>
  %501 = getelementptr inbounds i64, i64* %87, i64 4
  %502 = load i64, i64* %501, align 8, !tbaa !4944
  %503 = trunc i64 %502 to i32
  %504 = icmp eq i32 %503, 1
  %rdx.shuf = shufflevector <4 x i1> %500, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %500, %rdx.shuf
  %rdx.shuf175 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx176 = and <4 x i1> %bin.rdx, %rdx.shuf175
  %505 = extractelement <4 x i1> %bin.rdx176, i32 0
  %506 = and i1 %505, %504
  br i1 %506, label %if_end166, label %assert_fail167, !prof !5

if_end166:                                        ; preds = %assert_end164, %if_then165
  %507 = getelementptr inbounds %1, %1* %38, i64 0, i32 6
  %508 = load i64, i64* %507, align 8
  %509 = icmp eq i64 %508, 0
  br i1 %509, label %assert_end170, label %assert_fail169, !prof !5

assert_fail167:                                   ; preds = %if_then165
  %510 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %510(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.393, i64 0, i64 0))
  ret i32 -1

assert_fail169:                                   ; preds = %if_end166
  %511 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %511(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.318, i64 0, i64 0))
  ret i32 -1

assert_end170:                                    ; preds = %if_end166
  %512 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 0
  %513 = load i32, i32* %512, align 4
  %514 = icmp eq i32 %513, 1
  br i1 %514, label %assert_end172, label %assert_fail171, !prof !5

assert_fail171:                                   ; preds = %assert_end170
  %515 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %515(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.319, i64 0, i64 0))
  ret i32 -1

assert_end172:                                    ; preds = %assert_end170
  %516 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 1
  %517 = load i32, i32* %516, align 4
  %518 = icmp eq i32 %51, %517
  br i1 %518, label %assert_end174, label %assert_fail173, !prof !5

assert_fail173:                                   ; preds = %assert_end172
  %519 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %519(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.320, i64 0, i64 0))
  ret i32 -1

assert_end174:                                    ; preds = %assert_end172
  %520 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3_compute_(i8* %43, i8* %53, i8* %83, i8* %59, i8* %65, i8* %71, i8* %77, i32 %51)
  ret i32 %520
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %8 = alloca %30, align 8
  %9 = getelementptr inbounds %30, %30* %8, i64 0, i32 0
  store i8* %0, i8** %9, align 8
  %10 = getelementptr inbounds %30, %30* %8, i64 0, i32 1
  store i8* %1, i8** %10, align 8
  %11 = getelementptr inbounds %30, %30* %8, i64 0, i32 2
  store i8* %2, i8** %11, align 8
  %12 = getelementptr inbounds %30, %30* %8, i64 0, i32 3
  store i8* %3, i8** %12, align 8
  %13 = getelementptr inbounds %30, %30* %8, i64 0, i32 4
  store i8* %4, i8** %13, align 8
  %14 = getelementptr inbounds %30, %30* %8, i64 0, i32 5
  store i8* %5, i8** %14, align 8
  %15 = getelementptr inbounds %30, %30* %8, i64 0, i32 6
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %30, %30* %8, i64 0, i32 7
  store i32 %7, i32* %16, align 8
  %17 = bitcast %30* %8 to i8*
  %18 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %19 = call i32 %18(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.394, i8* nonnull %17, i32 0)
  ret i32 %19
}

define private i32 @__tvm_parallel_lambda.394(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds i8, i8* %2, i64 56
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %27 = load i32, i32* %26, align 4
  %28 = add nsw i32 %27, 447
  %29 = sdiv i32 %28, %27
  %30 = add nsw i32 %0, 1
  %31 = mul nsw i32 %29, %30
  %32 = icmp slt i32 %31, 448
  %33 = select i1 %32, i32 %31, i32 448
  %34 = mul nsw i32 %29, %0
  %35 = icmp slt i32 %34, 448
  %36 = select i1 %35, i32 %34, i32 448
  %37 = icmp slt i32 %36, %33
  br i1 %37, label %for_body, label %for_end, !prof !5

for_body:                                         ; preds = %entry, %for_end12
  %38 = phi i32 [ %390, %for_end12 ], [ %36, %entry ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %40 = tail call i8* %39(i32 1, i32 %25, i64 7168, i32 2, i32 32)
  %41 = bitcast i8* %40 to float*
  %42 = srem i32 %38, 56
  %43 = mul nsw i32 %42, 224
  %44 = sdiv i32 %38, 56
  %45 = shl i32 %44, 11
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end12, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end6
  %48 = mul nsw i32 %38, 1792
  %49 = shl nsw i32 %44, 5
  %50 = sext i32 %49 to i64
  %51 = getelementptr inbounds float, float* %13, i64 %50
  %52 = bitcast float* %51 to <32 x float>*
  %53 = load <32 x float>, <32 x float>* %52, align 64, !tbaa !4948
  %54 = getelementptr inbounds float, float* %16, i64 %50
  %55 = bitcast float* %54 to <32 x float>*
  %56 = load <32 x float>, <32 x float>* %55, align 64, !tbaa !4951
  %57 = getelementptr inbounds float, float* %19, i64 %50
  %58 = bitcast float* %57 to <32 x float>*
  %59 = load <32 x float>, <32 x float>* %58, align 64, !tbaa !4954
  br label %for_begin13.preheader

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv52 = phi i64 [ 0, %for_body ], [ %indvars.iv.next53, %for_end6 ]
  %60 = mul nuw nsw i64 %indvars.iv52, 224
  %61 = getelementptr inbounds float, float* %41, i64 %60
  %62 = bitcast float* %61 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %62, align 64, !tbaa !4957
  %63 = add nuw nsw i64 %60, 32
  %64 = getelementptr inbounds float, float* %41, i64 %63
  %65 = bitcast float* %64 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %65, align 64, !tbaa !4957
  %66 = add nuw nsw i64 %60, 64
  %67 = getelementptr inbounds float, float* %41, i64 %66
  %68 = bitcast float* %67 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %68, align 64, !tbaa !4957
  %69 = add nuw nsw i64 %60, 96
  %70 = getelementptr inbounds float, float* %41, i64 %69
  %71 = bitcast float* %70 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %71, align 64, !tbaa !4957
  %72 = add nuw nsw i64 %60, 128
  %73 = getelementptr inbounds float, float* %41, i64 %72
  %74 = bitcast float* %73 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %74, align 64, !tbaa !4957
  %75 = add nuw nsw i64 %60, 160
  %76 = getelementptr inbounds float, float* %41, i64 %75
  %77 = bitcast float* %76 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %77, align 64, !tbaa !4957
  %78 = add nuw nsw i64 %60, 192
  %79 = getelementptr inbounds float, float* %41, i64 %78
  %80 = bitcast float* %79 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %80, align 64, !tbaa !4957
  %81 = mul nuw nsw i64 %indvars.iv52, 28
  %82 = add nsw i64 %81, %47
  br label %for_begin7.preheader

for_begin7.preheader:                             ; preds = %for_begin7.preheader, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_begin7.preheader ]
  %.lcssa3245 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %268, %for_begin7.preheader ]
  %.lcssa3043 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %262, %for_begin7.preheader ]
  %.lcssa2841 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %256, %for_begin7.preheader ]
  %.lcssa2639 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %250, %for_begin7.preheader ]
  %.lcssa2437 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %244, %for_begin7.preheader ]
  %.lcssa2235 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %238, %for_begin7.preheader ]
  %.lcssa34 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %232, %for_begin7.preheader ]
  %83 = mul nuw nsw i64 %indvars.iv, 12544
  %84 = add nsw i64 %82, %83
  %85 = shl i64 %indvars.iv, 7
  %86 = add nuw nsw i64 %85, %46
  %87 = getelementptr inbounds float, float* %4, i64 %84
  %88 = load float, float* %87, align 4, !tbaa !4960
  %89 = insertelement <32 x float> undef, float %88, i32 0
  %90 = shufflevector <32 x float> %89, <32 x float> undef, <32 x i32> zeroinitializer
  %91 = getelementptr inbounds float, float* %7, i64 %86
  %92 = bitcast float* %91 to <32 x float>*
  %93 = load <32 x float>, <32 x float>* %92, align 64, !tbaa !4963
  %94 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %90, <32 x float> %93, <32 x float> %.lcssa34)
  %95 = add nsw i64 %84, 4
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !4960
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %93, <32 x float> %.lcssa2235)
  %101 = add nsw i64 %84, 8
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !4960
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %93, <32 x float> %.lcssa2437)
  %107 = add nsw i64 %84, 12
  %108 = getelementptr inbounds float, float* %4, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !4960
  %110 = insertelement <32 x float> undef, float %109, i32 0
  %111 = shufflevector <32 x float> %110, <32 x float> undef, <32 x i32> zeroinitializer
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %93, <32 x float> %.lcssa2639)
  %113 = add nsw i64 %84, 16
  %114 = getelementptr inbounds float, float* %4, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !4960
  %116 = insertelement <32 x float> undef, float %115, i32 0
  %117 = shufflevector <32 x float> %116, <32 x float> undef, <32 x i32> zeroinitializer
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %93, <32 x float> %.lcssa2841)
  %119 = add nsw i64 %84, 20
  %120 = getelementptr inbounds float, float* %4, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !4960
  %122 = insertelement <32 x float> undef, float %121, i32 0
  %123 = shufflevector <32 x float> %122, <32 x float> undef, <32 x i32> zeroinitializer
  %124 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %93, <32 x float> %.lcssa3043)
  %125 = add nsw i64 %84, 24
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !4960
  %128 = insertelement <32 x float> undef, float %127, i32 0
  %129 = shufflevector <32 x float> %128, <32 x float> undef, <32 x i32> zeroinitializer
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %93, <32 x float> %.lcssa3245)
  %131 = or i64 %84, 1
  %132 = getelementptr inbounds float, float* %4, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !4960
  %134 = insertelement <32 x float> undef, float %133, i32 0
  %135 = shufflevector <32 x float> %134, <32 x float> undef, <32 x i32> zeroinitializer
  %136 = or i64 %86, 32
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = bitcast float* %137 to <32 x float>*
  %139 = load <32 x float>, <32 x float>* %138, align 64, !tbaa !4963
  %140 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %135, <32 x float> %139, <32 x float> %94)
  %141 = add nsw i64 %131, 4
  %142 = getelementptr inbounds float, float* %4, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !4960
  %144 = insertelement <32 x float> undef, float %143, i32 0
  %145 = shufflevector <32 x float> %144, <32 x float> undef, <32 x i32> zeroinitializer
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %145, <32 x float> %139, <32 x float> %100)
  %147 = add nsw i64 %131, 8
  %148 = getelementptr inbounds float, float* %4, i64 %147
  %149 = load float, float* %148, align 4, !tbaa !4960
  %150 = insertelement <32 x float> undef, float %149, i32 0
  %151 = shufflevector <32 x float> %150, <32 x float> undef, <32 x i32> zeroinitializer
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %151, <32 x float> %139, <32 x float> %106)
  %153 = add nsw i64 %131, 12
  %154 = getelementptr inbounds float, float* %4, i64 %153
  %155 = load float, float* %154, align 4, !tbaa !4960
  %156 = insertelement <32 x float> undef, float %155, i32 0
  %157 = shufflevector <32 x float> %156, <32 x float> undef, <32 x i32> zeroinitializer
  %158 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %157, <32 x float> %139, <32 x float> %112)
  %159 = add nsw i64 %131, 16
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = load float, float* %160, align 4, !tbaa !4960
  %162 = insertelement <32 x float> undef, float %161, i32 0
  %163 = shufflevector <32 x float> %162, <32 x float> undef, <32 x i32> zeroinitializer
  %164 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %163, <32 x float> %139, <32 x float> %118)
  %165 = add nsw i64 %131, 20
  %166 = getelementptr inbounds float, float* %4, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !4960
  %168 = insertelement <32 x float> undef, float %167, i32 0
  %169 = shufflevector <32 x float> %168, <32 x float> undef, <32 x i32> zeroinitializer
  %170 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %169, <32 x float> %139, <32 x float> %124)
  %171 = add nsw i64 %131, 24
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !4960
  %174 = insertelement <32 x float> undef, float %173, i32 0
  %175 = shufflevector <32 x float> %174, <32 x float> undef, <32 x i32> zeroinitializer
  %176 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %175, <32 x float> %139, <32 x float> %130)
  %177 = or i64 %84, 2
  %178 = getelementptr inbounds float, float* %4, i64 %177
  %179 = load float, float* %178, align 4, !tbaa !4960
  %180 = insertelement <32 x float> undef, float %179, i32 0
  %181 = shufflevector <32 x float> %180, <32 x float> undef, <32 x i32> zeroinitializer
  %182 = or i64 %86, 64
  %183 = getelementptr inbounds float, float* %7, i64 %182
  %184 = bitcast float* %183 to <32 x float>*
  %185 = load <32 x float>, <32 x float>* %184, align 64, !tbaa !4963
  %186 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %181, <32 x float> %185, <32 x float> %140)
  %187 = add nsw i64 %177, 4
  %188 = getelementptr inbounds float, float* %4, i64 %187
  %189 = load float, float* %188, align 4, !tbaa !4960
  %190 = insertelement <32 x float> undef, float %189, i32 0
  %191 = shufflevector <32 x float> %190, <32 x float> undef, <32 x i32> zeroinitializer
  %192 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %191, <32 x float> %185, <32 x float> %146)
  %193 = add nsw i64 %177, 8
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = load float, float* %194, align 4, !tbaa !4960
  %196 = insertelement <32 x float> undef, float %195, i32 0
  %197 = shufflevector <32 x float> %196, <32 x float> undef, <32 x i32> zeroinitializer
  %198 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %197, <32 x float> %185, <32 x float> %152)
  %199 = add nsw i64 %177, 12
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !4960
  %202 = insertelement <32 x float> undef, float %201, i32 0
  %203 = shufflevector <32 x float> %202, <32 x float> undef, <32 x i32> zeroinitializer
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %203, <32 x float> %185, <32 x float> %158)
  %205 = add nsw i64 %177, 16
  %206 = getelementptr inbounds float, float* %4, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !4960
  %208 = insertelement <32 x float> undef, float %207, i32 0
  %209 = shufflevector <32 x float> %208, <32 x float> undef, <32 x i32> zeroinitializer
  %210 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %209, <32 x float> %185, <32 x float> %164)
  %211 = add nsw i64 %177, 20
  %212 = getelementptr inbounds float, float* %4, i64 %211
  %213 = load float, float* %212, align 4, !tbaa !4960
  %214 = insertelement <32 x float> undef, float %213, i32 0
  %215 = shufflevector <32 x float> %214, <32 x float> undef, <32 x i32> zeroinitializer
  %216 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %215, <32 x float> %185, <32 x float> %170)
  %217 = add nsw i64 %177, 24
  %218 = getelementptr inbounds float, float* %4, i64 %217
  %219 = load float, float* %218, align 4, !tbaa !4960
  %220 = insertelement <32 x float> undef, float %219, i32 0
  %221 = shufflevector <32 x float> %220, <32 x float> undef, <32 x i32> zeroinitializer
  %222 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %221, <32 x float> %185, <32 x float> %176)
  %223 = or i64 %84, 3
  %224 = getelementptr inbounds float, float* %4, i64 %223
  %225 = load float, float* %224, align 4, !tbaa !4960
  %226 = insertelement <32 x float> undef, float %225, i32 0
  %227 = shufflevector <32 x float> %226, <32 x float> undef, <32 x i32> zeroinitializer
  %228 = or i64 %86, 96
  %229 = getelementptr inbounds float, float* %7, i64 %228
  %230 = bitcast float* %229 to <32 x float>*
  %231 = load <32 x float>, <32 x float>* %230, align 64, !tbaa !4963
  %232 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %227, <32 x float> %231, <32 x float> %186)
  %233 = add nsw i64 %223, 4
  %234 = getelementptr inbounds float, float* %4, i64 %233
  %235 = load float, float* %234, align 4, !tbaa !4960
  %236 = insertelement <32 x float> undef, float %235, i32 0
  %237 = shufflevector <32 x float> %236, <32 x float> undef, <32 x i32> zeroinitializer
  %238 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %237, <32 x float> %231, <32 x float> %192)
  %239 = add nsw i64 %223, 8
  %240 = getelementptr inbounds float, float* %4, i64 %239
  %241 = load float, float* %240, align 4, !tbaa !4960
  %242 = insertelement <32 x float> undef, float %241, i32 0
  %243 = shufflevector <32 x float> %242, <32 x float> undef, <32 x i32> zeroinitializer
  %244 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %243, <32 x float> %231, <32 x float> %198)
  %245 = add nsw i64 %223, 12
  %246 = getelementptr inbounds float, float* %4, i64 %245
  %247 = load float, float* %246, align 4, !tbaa !4960
  %248 = insertelement <32 x float> undef, float %247, i32 0
  %249 = shufflevector <32 x float> %248, <32 x float> undef, <32 x i32> zeroinitializer
  %250 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %249, <32 x float> %231, <32 x float> %204)
  %251 = add nsw i64 %223, 16
  %252 = getelementptr inbounds float, float* %4, i64 %251
  %253 = load float, float* %252, align 4, !tbaa !4960
  %254 = insertelement <32 x float> undef, float %253, i32 0
  %255 = shufflevector <32 x float> %254, <32 x float> undef, <32 x i32> zeroinitializer
  %256 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %255, <32 x float> %231, <32 x float> %210)
  %257 = add nsw i64 %223, 20
  %258 = getelementptr inbounds float, float* %4, i64 %257
  %259 = load float, float* %258, align 4, !tbaa !4960
  %260 = insertelement <32 x float> undef, float %259, i32 0
  %261 = shufflevector <32 x float> %260, <32 x float> undef, <32 x i32> zeroinitializer
  %262 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %261, <32 x float> %231, <32 x float> %216)
  %263 = add nsw i64 %223, 24
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !4960
  %266 = insertelement <32 x float> undef, float %265, i32 0
  %267 = shufflevector <32 x float> %266, <32 x float> undef, <32 x i32> zeroinitializer
  %268 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %267, <32 x float> %231, <32 x float> %222)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for_end6, label %for_begin7.preheader, !prof !50

for_end6:                                         ; preds = %for_begin7.preheader
  store <32 x float> %232, <32 x float>* %62, align 64, !tbaa !4957
  store <32 x float> %238, <32 x float>* %65, align 64, !tbaa !4957
  store <32 x float> %244, <32 x float>* %68, align 64, !tbaa !4957
  store <32 x float> %250, <32 x float>* %71, align 64, !tbaa !4957
  store <32 x float> %256, <32 x float>* %74, align 64, !tbaa !4957
  store <32 x float> %262, <32 x float>* %77, align 64, !tbaa !4957
  store <32 x float> %268, <32 x float>* %80, align 64, !tbaa !4957
  %indvars.iv.next53 = add nuw nsw i64 %indvars.iv52, 1
  %exitcond54 = icmp eq i64 %indvars.iv.next53, 8
  br i1 %exitcond54, label %for_begin10.preheader, label %for_body2, !prof !50

for_begin13.preheader:                            ; preds = %for_begin13.preheader, %for_begin10.preheader
  %indvars.iv58 = phi i64 [ 0, %for_begin10.preheader ], [ %indvars.iv.next59, %for_begin13.preheader ]
  %269 = mul nuw nsw i64 %indvars.iv58, 224
  %270 = trunc i64 %269 to i32
  %271 = add i32 %48, %270
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds float, float* %22, i64 %272
  %274 = bitcast float* %273 to <32 x float>*
  %275 = load <32 x float>, <32 x float>* %274, align 64, !tbaa !4966
  %276 = getelementptr inbounds float, float* %41, i64 %269
  %277 = bitcast float* %276 to <32 x float>*
  %278 = load <32 x float>, <32 x float>* %277, align 64, !tbaa !4957
  %279 = fadd <32 x float> %53, %278
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %279, <32 x float> %56, <32 x float> %59)
  %281 = fadd <32 x float> %275, %280
  %282 = fcmp ogt <32 x float> %281, zeroinitializer
  %283 = select <32 x i1> %282, <32 x float> %281, <32 x float> zeroinitializer
  %284 = getelementptr inbounds float, float* %10, i64 %272
  %285 = bitcast float* %284 to <32 x float>*
  store <32 x float> %283, <32 x float>* %285, align 64, !tbaa !4969
  %286 = add nuw nsw i64 %269, 32
  %287 = trunc i64 %286 to i32
  %288 = add i32 %48, %287
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds float, float* %22, i64 %289
  %291 = bitcast float* %290 to <32 x float>*
  %292 = load <32 x float>, <32 x float>* %291, align 64, !tbaa !4966
  %293 = getelementptr inbounds float, float* %41, i64 %286
  %294 = bitcast float* %293 to <32 x float>*
  %295 = load <32 x float>, <32 x float>* %294, align 64, !tbaa !4957
  %296 = fadd <32 x float> %53, %295
  %297 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %296, <32 x float> %56, <32 x float> %59)
  %298 = fadd <32 x float> %292, %297
  %299 = fcmp ogt <32 x float> %298, zeroinitializer
  %300 = select <32 x i1> %299, <32 x float> %298, <32 x float> zeroinitializer
  %301 = getelementptr inbounds float, float* %10, i64 %289
  %302 = bitcast float* %301 to <32 x float>*
  store <32 x float> %300, <32 x float>* %302, align 64, !tbaa !4969
  %303 = add nuw nsw i64 %269, 64
  %304 = trunc i64 %303 to i32
  %305 = add i32 %48, %304
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds float, float* %22, i64 %306
  %308 = bitcast float* %307 to <32 x float>*
  %309 = load <32 x float>, <32 x float>* %308, align 64, !tbaa !4966
  %310 = getelementptr inbounds float, float* %41, i64 %303
  %311 = bitcast float* %310 to <32 x float>*
  %312 = load <32 x float>, <32 x float>* %311, align 64, !tbaa !4957
  %313 = fadd <32 x float> %53, %312
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %313, <32 x float> %56, <32 x float> %59)
  %315 = fadd <32 x float> %309, %314
  %316 = fcmp ogt <32 x float> %315, zeroinitializer
  %317 = select <32 x i1> %316, <32 x float> %315, <32 x float> zeroinitializer
  %318 = getelementptr inbounds float, float* %10, i64 %306
  %319 = bitcast float* %318 to <32 x float>*
  store <32 x float> %317, <32 x float>* %319, align 64, !tbaa !4969
  %320 = add nuw nsw i64 %269, 96
  %321 = trunc i64 %320 to i32
  %322 = add i32 %48, %321
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds float, float* %22, i64 %323
  %325 = bitcast float* %324 to <32 x float>*
  %326 = load <32 x float>, <32 x float>* %325, align 64, !tbaa !4966
  %327 = getelementptr inbounds float, float* %41, i64 %320
  %328 = bitcast float* %327 to <32 x float>*
  %329 = load <32 x float>, <32 x float>* %328, align 64, !tbaa !4957
  %330 = fadd <32 x float> %53, %329
  %331 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %330, <32 x float> %56, <32 x float> %59)
  %332 = fadd <32 x float> %326, %331
  %333 = fcmp ogt <32 x float> %332, zeroinitializer
  %334 = select <32 x i1> %333, <32 x float> %332, <32 x float> zeroinitializer
  %335 = getelementptr inbounds float, float* %10, i64 %323
  %336 = bitcast float* %335 to <32 x float>*
  store <32 x float> %334, <32 x float>* %336, align 64, !tbaa !4969
  %337 = add nuw nsw i64 %269, 128
  %338 = trunc i64 %337 to i32
  %339 = add i32 %48, %338
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds float, float* %22, i64 %340
  %342 = bitcast float* %341 to <32 x float>*
  %343 = load <32 x float>, <32 x float>* %342, align 64, !tbaa !4966
  %344 = getelementptr inbounds float, float* %41, i64 %337
  %345 = bitcast float* %344 to <32 x float>*
  %346 = load <32 x float>, <32 x float>* %345, align 64, !tbaa !4957
  %347 = fadd <32 x float> %53, %346
  %348 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %347, <32 x float> %56, <32 x float> %59)
  %349 = fadd <32 x float> %343, %348
  %350 = fcmp ogt <32 x float> %349, zeroinitializer
  %351 = select <32 x i1> %350, <32 x float> %349, <32 x float> zeroinitializer
  %352 = getelementptr inbounds float, float* %10, i64 %340
  %353 = bitcast float* %352 to <32 x float>*
  store <32 x float> %351, <32 x float>* %353, align 64, !tbaa !4969
  %354 = add nuw nsw i64 %269, 160
  %355 = trunc i64 %354 to i32
  %356 = add i32 %48, %355
  %357 = sext i32 %356 to i64
  %358 = getelementptr inbounds float, float* %22, i64 %357
  %359 = bitcast float* %358 to <32 x float>*
  %360 = load <32 x float>, <32 x float>* %359, align 64, !tbaa !4966
  %361 = getelementptr inbounds float, float* %41, i64 %354
  %362 = bitcast float* %361 to <32 x float>*
  %363 = load <32 x float>, <32 x float>* %362, align 64, !tbaa !4957
  %364 = fadd <32 x float> %53, %363
  %365 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %364, <32 x float> %56, <32 x float> %59)
  %366 = fadd <32 x float> %360, %365
  %367 = fcmp ogt <32 x float> %366, zeroinitializer
  %368 = select <32 x i1> %367, <32 x float> %366, <32 x float> zeroinitializer
  %369 = getelementptr inbounds float, float* %10, i64 %357
  %370 = bitcast float* %369 to <32 x float>*
  store <32 x float> %368, <32 x float>* %370, align 64, !tbaa !4969
  %371 = add nuw nsw i64 %269, 192
  %372 = trunc i64 %371 to i32
  %373 = add i32 %48, %372
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds float, float* %22, i64 %374
  %376 = bitcast float* %375 to <32 x float>*
  %377 = load <32 x float>, <32 x float>* %376, align 64, !tbaa !4966
  %378 = getelementptr inbounds float, float* %41, i64 %371
  %379 = bitcast float* %378 to <32 x float>*
  %380 = load <32 x float>, <32 x float>* %379, align 64, !tbaa !4957
  %381 = fadd <32 x float> %53, %380
  %382 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %56, <32 x float> %59)
  %383 = fadd <32 x float> %377, %382
  %384 = fcmp ogt <32 x float> %383, zeroinitializer
  %385 = select <32 x i1> %384, <32 x float> %383, <32 x float> zeroinitializer
  %386 = getelementptr inbounds float, float* %10, i64 %374
  %387 = bitcast float* %386 to <32 x float>*
  store <32 x float> %385, <32 x float>* %387, align 64, !tbaa !4969
  %indvars.iv.next59 = add nuw nsw i64 %indvars.iv58, 1
  %exitcond60 = icmp eq i64 %indvars.iv.next59, 8
  br i1 %exitcond60, label %for_end12, label %for_begin13.preheader, !prof !50

for_end12:                                        ; preds = %for_begin13.preheader
  %388 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %389 = tail call i32 %388(i32 1, i32 %25, i8* nonnull %40)
  %390 = add nsw i32 %38, 1
  %391 = icmp slt i32 %390, %33
  br i1 %391, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.395, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !4972
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !4986
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !4989
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !4991
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.396, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !4995
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.397, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.398, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.399, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.400, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !4997
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !5011
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 1
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !5013
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 7
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !5016
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 7
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !5018
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 512
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !5022
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 25088, i32 25088, i32 3584, i32 512>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !5034
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.401, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !5038
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 16
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !5052
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !5054
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 3
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.133, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !5057
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 3
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.134, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !5059
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 512
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !5063
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 32
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !5065
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 147456, i32 147456, i32 49152, i32 16384>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !5077
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 32
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !5081
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([281 x i8], [281 x i8]* @.str.402, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !5083
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 16
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !5097
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !5099
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !5102
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 32
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !5104
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !5116
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 16
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.250, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !5130
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !5132
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !5135
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 32
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !5137
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !5149
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !5163
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 16
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.251, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !5165
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 7
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.252, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !5168
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 7
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.253, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !5170
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 32
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !5174
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 25088, i32 1568, i32 224, i32 32>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !5186
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.254, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 165888, i32 2, i32 32)
  %8 = alloca %31, align 8
  %9 = getelementptr inbounds %31, %31* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %31, %31* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %31* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.403, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %23, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %32, align 8
  %16 = getelementptr inbounds %32, %32* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %32, %32* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %32, %32* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %32, %32* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %32, %32* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = bitcast %32* %15 to i8*
  %22 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %23 = call i32 %22(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.404, i8* nonnull %21, i32 0)
  %24 = icmp eq i32 %23, 0
  br i1 %24, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %25 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %26 = call i32 %25(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.403(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 8
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 9
  %15 = select i1 %14, i32 %13, i32 9
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 9
  %18 = select i1 %17, i32 %16, i32 9
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader, label %for_end, !prof !5

for_begin1.preheader:                             ; preds = %entry, %for_end3
  %20 = phi i32 [ %57, %for_end3 ], [ %18, %entry ]
  %21 = mul nsw i32 %20, 4608
  %.off = add i32 %20, -1
  %22 = icmp ult i32 %.off, 7
  %23 = mul nsw i32 %20, 3584
  br i1 %22, label %vector.body251, label %vector.body449

vector.body449:                                   ; preds = %for_begin1.preheader, %vector.body449
  %index459 = phi i64 [ %index.next460, %vector.body449 ], [ 0, %for_begin1.preheader ]
  %24 = trunc i64 %index459 to i32
  %25 = add i32 %21, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds float, float* %4, i64 %26
  %28 = bitcast float* %27 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %28, align 4, !tbaa !5190
  %29 = getelementptr inbounds float, float* %27, i64 4
  %30 = bitcast float* %29 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %30, align 4, !tbaa !5190
  %index.next460 = add i64 %index459, 8
  %31 = icmp eq i64 %index.next460, 512
  br i1 %31, label %vector.body427, label %vector.body449, !llvm.loop !5193

vector.body251:                                   ; preds = %for_begin1.preheader, %vector.body251
  %index261 = phi i64 [ %index.next262, %vector.body251 ], [ 0, %for_begin1.preheader ]
  %32 = trunc i64 %index261 to i32
  %33 = add i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %4, i64 %34
  %36 = bitcast float* %35 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %36, align 4, !tbaa !5190
  %37 = getelementptr inbounds float, float* %35, i64 4
  %38 = bitcast float* %37 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %38, align 4, !tbaa !5190
  %index.next262 = add i64 %index261, 8
  %39 = icmp eq i64 %index.next262, 512
  br i1 %39, label %vector.body220, label %vector.body251, !llvm.loop !5194

vector.body220:                                   ; preds = %vector.body251, %vector.body220
  %index233 = phi i64 [ %index.next234, %vector.body220 ], [ 0, %vector.body251 ]
  %40 = trunc i64 %index233 to i32
  %41 = add i32 %40, 512
  %42 = add i32 %21, %41
  %43 = trunc i64 %index233 to i32
  %44 = add i32 %43, -3584
  %45 = add i32 %44, %23
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds float, float* %7, i64 %46
  %48 = bitcast float* %47 to <4 x i32>*
  %wide.load249 = load <4 x i32>, <4 x i32>* %48, align 4, !tbaa !5195
  %49 = getelementptr inbounds float, float* %47, i64 4
  %50 = bitcast float* %49 to <4 x i32>*
  %wide.load250 = load <4 x i32>, <4 x i32>* %50, align 4, !tbaa !5195
  %51 = sext i32 %42 to i64
  %52 = getelementptr inbounds float, float* %4, i64 %51
  %53 = bitcast float* %52 to <4 x i32>*
  store <4 x i32> %wide.load249, <4 x i32>* %53, align 4, !tbaa !5190
  %54 = getelementptr inbounds float, float* %52, i64 4
  %55 = bitcast float* %54 to <4 x i32>*
  store <4 x i32> %wide.load250, <4 x i32>* %55, align 4, !tbaa !5190
  %index.next234 = add i64 %index233, 8
  %56 = icmp eq i64 %index.next234, 512
  br i1 %56, label %vector.body189, label %vector.body220, !llvm.loop !5198

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %vector.body273, %vector.body
  %57 = add nsw i32 %20, 1
  %58 = icmp slt i32 %57, %15
  br i1 %58, label %for_begin1.preheader, label %for_end, !prof !5

vector.body427:                                   ; preds = %vector.body449, %vector.body427
  %index437 = phi i64 [ %index.next438, %vector.body427 ], [ 0, %vector.body449 ]
  %59 = trunc i64 %index437 to i32
  %60 = add i32 %59, 512
  %61 = add i32 %60, %21
  %62 = sext i32 %61 to i64
  %63 = getelementptr inbounds float, float* %4, i64 %62
  %64 = bitcast float* %63 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %64, align 4, !tbaa !5190
  %65 = getelementptr inbounds float, float* %63, i64 4
  %66 = bitcast float* %65 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %66, align 4, !tbaa !5190
  %index.next438 = add i64 %index437, 8
  %67 = icmp eq i64 %index.next438, 512
  br i1 %67, label %vector.body405, label %vector.body427, !llvm.loop !5199

vector.body405:                                   ; preds = %vector.body427, %vector.body405
  %index415 = phi i64 [ %index.next416, %vector.body405 ], [ 0, %vector.body427 ]
  %68 = trunc i64 %index415 to i32
  %69 = add i32 %68, 1024
  %70 = add i32 %69, %21
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds float, float* %4, i64 %71
  %73 = bitcast float* %72 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %73, align 4, !tbaa !5190
  %74 = getelementptr inbounds float, float* %72, i64 4
  %75 = bitcast float* %74 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %75, align 4, !tbaa !5190
  %index.next416 = add i64 %index415, 8
  %76 = icmp eq i64 %index.next416, 512
  br i1 %76, label %vector.body383, label %vector.body405, !llvm.loop !5200

vector.body383:                                   ; preds = %vector.body405, %vector.body383
  %index393 = phi i64 [ %index.next394, %vector.body383 ], [ 0, %vector.body405 ]
  %77 = trunc i64 %index393 to i32
  %78 = add i32 %77, 1536
  %79 = add i32 %78, %21
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds float, float* %4, i64 %80
  %82 = bitcast float* %81 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %82, align 4, !tbaa !5190
  %83 = getelementptr inbounds float, float* %81, i64 4
  %84 = bitcast float* %83 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %84, align 4, !tbaa !5190
  %index.next394 = add i64 %index393, 8
  %85 = icmp eq i64 %index.next394, 512
  br i1 %85, label %vector.body361, label %vector.body383, !llvm.loop !5201

vector.body361:                                   ; preds = %vector.body383, %vector.body361
  %index371 = phi i64 [ %index.next372, %vector.body361 ], [ 0, %vector.body383 ]
  %86 = trunc i64 %index371 to i32
  %87 = add i32 %86, 2048
  %88 = add i32 %87, %21
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds float, float* %4, i64 %89
  %91 = bitcast float* %90 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %91, align 4, !tbaa !5190
  %92 = getelementptr inbounds float, float* %90, i64 4
  %93 = bitcast float* %92 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %93, align 4, !tbaa !5190
  %index.next372 = add i64 %index371, 8
  %94 = icmp eq i64 %index.next372, 512
  br i1 %94, label %vector.body339, label %vector.body361, !llvm.loop !5202

vector.body339:                                   ; preds = %vector.body361, %vector.body339
  %index349 = phi i64 [ %index.next350, %vector.body339 ], [ 0, %vector.body361 ]
  %95 = trunc i64 %index349 to i32
  %96 = add i32 %95, 2560
  %97 = add i32 %96, %21
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = bitcast float* %99 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %100, align 4, !tbaa !5190
  %101 = getelementptr inbounds float, float* %99, i64 4
  %102 = bitcast float* %101 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %102, align 4, !tbaa !5190
  %index.next350 = add i64 %index349, 8
  %103 = icmp eq i64 %index.next350, 512
  br i1 %103, label %vector.body317, label %vector.body339, !llvm.loop !5203

vector.body317:                                   ; preds = %vector.body339, %vector.body317
  %index327 = phi i64 [ %index.next328, %vector.body317 ], [ 0, %vector.body339 ]
  %104 = trunc i64 %index327 to i32
  %105 = add i32 %104, 3072
  %106 = add i32 %105, %21
  %107 = sext i32 %106 to i64
  %108 = getelementptr inbounds float, float* %4, i64 %107
  %109 = bitcast float* %108 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %109, align 4, !tbaa !5190
  %110 = getelementptr inbounds float, float* %108, i64 4
  %111 = bitcast float* %110 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %111, align 4, !tbaa !5190
  %index.next328 = add i64 %index327, 8
  %112 = icmp eq i64 %index.next328, 512
  br i1 %112, label %vector.body295, label %vector.body317, !llvm.loop !5204

vector.body295:                                   ; preds = %vector.body317, %vector.body295
  %index305 = phi i64 [ %index.next306, %vector.body295 ], [ 0, %vector.body317 ]
  %113 = trunc i64 %index305 to i32
  %114 = add i32 %113, 3584
  %115 = add i32 %114, %21
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = bitcast float* %117 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %118, align 4, !tbaa !5190
  %119 = getelementptr inbounds float, float* %117, i64 4
  %120 = bitcast float* %119 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %120, align 4, !tbaa !5190
  %index.next306 = add i64 %index305, 8
  %121 = icmp eq i64 %index.next306, 512
  br i1 %121, label %vector.body273, label %vector.body295, !llvm.loop !5205

vector.body273:                                   ; preds = %vector.body295, %vector.body273
  %index283 = phi i64 [ %index.next284, %vector.body273 ], [ 0, %vector.body295 ]
  %122 = trunc i64 %index283 to i32
  %123 = add i32 %122, 4096
  %124 = add i32 %123, %21
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = bitcast float* %126 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %127, align 4, !tbaa !5190
  %128 = getelementptr inbounds float, float* %126, i64 4
  %129 = bitcast float* %128 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %129, align 4, !tbaa !5190
  %index.next284 = add i64 %index283, 8
  %130 = icmp eq i64 %index.next284, 512
  br i1 %130, label %for_end3, label %vector.body273, !llvm.loop !5206

vector.body189:                                   ; preds = %vector.body220, %vector.body189
  %index202 = phi i64 [ %index.next203, %vector.body189 ], [ 0, %vector.body220 ]
  %131 = trunc i64 %index202 to i32
  %132 = add i32 %131, 1024
  %133 = add i32 %21, %132
  %134 = trunc i64 %index202 to i32
  %135 = add i32 %134, -3072
  %136 = add i32 %135, %23
  %137 = sext i32 %136 to i64
  %138 = getelementptr inbounds float, float* %7, i64 %137
  %139 = bitcast float* %138 to <4 x i32>*
  %wide.load218 = load <4 x i32>, <4 x i32>* %139, align 4, !tbaa !5195
  %140 = getelementptr inbounds float, float* %138, i64 4
  %141 = bitcast float* %140 to <4 x i32>*
  %wide.load219 = load <4 x i32>, <4 x i32>* %141, align 4, !tbaa !5195
  %142 = sext i32 %133 to i64
  %143 = getelementptr inbounds float, float* %4, i64 %142
  %144 = bitcast float* %143 to <4 x i32>*
  store <4 x i32> %wide.load218, <4 x i32>* %144, align 4, !tbaa !5190
  %145 = getelementptr inbounds float, float* %143, i64 4
  %146 = bitcast float* %145 to <4 x i32>*
  store <4 x i32> %wide.load219, <4 x i32>* %146, align 4, !tbaa !5190
  %index.next203 = add i64 %index202, 8
  %147 = icmp eq i64 %index.next203, 512
  br i1 %147, label %vector.body158, label %vector.body189, !llvm.loop !5207

vector.body158:                                   ; preds = %vector.body189, %vector.body158
  %index171 = phi i64 [ %index.next172, %vector.body158 ], [ 0, %vector.body189 ]
  %148 = trunc i64 %index171 to i32
  %149 = add i32 %148, 1536
  %150 = add i32 %21, %149
  %151 = trunc i64 %index171 to i32
  %152 = add i32 %151, -2560
  %153 = add i32 %152, %23
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to <4 x i32>*
  %wide.load187 = load <4 x i32>, <4 x i32>* %156, align 4, !tbaa !5195
  %157 = getelementptr inbounds float, float* %155, i64 4
  %158 = bitcast float* %157 to <4 x i32>*
  %wide.load188 = load <4 x i32>, <4 x i32>* %158, align 4, !tbaa !5195
  %159 = sext i32 %150 to i64
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = bitcast float* %160 to <4 x i32>*
  store <4 x i32> %wide.load187, <4 x i32>* %161, align 4, !tbaa !5190
  %162 = getelementptr inbounds float, float* %160, i64 4
  %163 = bitcast float* %162 to <4 x i32>*
  store <4 x i32> %wide.load188, <4 x i32>* %163, align 4, !tbaa !5190
  %index.next172 = add i64 %index171, 8
  %164 = icmp eq i64 %index.next172, 512
  br i1 %164, label %vector.body127, label %vector.body158, !llvm.loop !5208

vector.body127:                                   ; preds = %vector.body158, %vector.body127
  %index140 = phi i64 [ %index.next141, %vector.body127 ], [ 0, %vector.body158 ]
  %165 = trunc i64 %index140 to i32
  %166 = add i32 %165, 2048
  %167 = add i32 %21, %166
  %168 = trunc i64 %index140 to i32
  %169 = add i32 %168, -2048
  %170 = add i32 %169, %23
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = bitcast float* %172 to <4 x i32>*
  %wide.load156 = load <4 x i32>, <4 x i32>* %173, align 4, !tbaa !5195
  %174 = getelementptr inbounds float, float* %172, i64 4
  %175 = bitcast float* %174 to <4 x i32>*
  %wide.load157 = load <4 x i32>, <4 x i32>* %175, align 4, !tbaa !5195
  %176 = sext i32 %167 to i64
  %177 = getelementptr inbounds float, float* %4, i64 %176
  %178 = bitcast float* %177 to <4 x i32>*
  store <4 x i32> %wide.load156, <4 x i32>* %178, align 4, !tbaa !5190
  %179 = getelementptr inbounds float, float* %177, i64 4
  %180 = bitcast float* %179 to <4 x i32>*
  store <4 x i32> %wide.load157, <4 x i32>* %180, align 4, !tbaa !5190
  %index.next141 = add i64 %index140, 8
  %181 = icmp eq i64 %index.next141, 512
  br i1 %181, label %vector.body96, label %vector.body127, !llvm.loop !5209

vector.body96:                                    ; preds = %vector.body127, %vector.body96
  %index109 = phi i64 [ %index.next110, %vector.body96 ], [ 0, %vector.body127 ]
  %182 = trunc i64 %index109 to i32
  %183 = add i32 %182, 2560
  %184 = add i32 %21, %183
  %185 = trunc i64 %index109 to i32
  %186 = add i32 %185, -1536
  %187 = add i32 %186, %23
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to <4 x i32>*
  %wide.load125 = load <4 x i32>, <4 x i32>* %190, align 4, !tbaa !5195
  %191 = getelementptr inbounds float, float* %189, i64 4
  %192 = bitcast float* %191 to <4 x i32>*
  %wide.load126 = load <4 x i32>, <4 x i32>* %192, align 4, !tbaa !5195
  %193 = sext i32 %184 to i64
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = bitcast float* %194 to <4 x i32>*
  store <4 x i32> %wide.load125, <4 x i32>* %195, align 4, !tbaa !5190
  %196 = getelementptr inbounds float, float* %194, i64 4
  %197 = bitcast float* %196 to <4 x i32>*
  store <4 x i32> %wide.load126, <4 x i32>* %197, align 4, !tbaa !5190
  %index.next110 = add i64 %index109, 8
  %198 = icmp eq i64 %index.next110, 512
  br i1 %198, label %vector.body65, label %vector.body96, !llvm.loop !5210

vector.body65:                                    ; preds = %vector.body96, %vector.body65
  %index78 = phi i64 [ %index.next79, %vector.body65 ], [ 0, %vector.body96 ]
  %199 = trunc i64 %index78 to i32
  %200 = add i32 %199, 3072
  %201 = add i32 %21, %200
  %202 = trunc i64 %index78 to i32
  %203 = add i32 %202, -1024
  %204 = add i32 %203, %23
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = bitcast float* %206 to <4 x i32>*
  %wide.load94 = load <4 x i32>, <4 x i32>* %207, align 4, !tbaa !5195
  %208 = getelementptr inbounds float, float* %206, i64 4
  %209 = bitcast float* %208 to <4 x i32>*
  %wide.load95 = load <4 x i32>, <4 x i32>* %209, align 4, !tbaa !5195
  %210 = sext i32 %201 to i64
  %211 = getelementptr inbounds float, float* %4, i64 %210
  %212 = bitcast float* %211 to <4 x i32>*
  store <4 x i32> %wide.load94, <4 x i32>* %212, align 4, !tbaa !5190
  %213 = getelementptr inbounds float, float* %211, i64 4
  %214 = bitcast float* %213 to <4 x i32>*
  store <4 x i32> %wide.load95, <4 x i32>* %214, align 4, !tbaa !5190
  %index.next79 = add i64 %index78, 8
  %215 = icmp eq i64 %index.next79, 512
  br i1 %215, label %vector.body35, label %vector.body65, !llvm.loop !5211

vector.body35:                                    ; preds = %vector.body65, %vector.body35
  %index48 = phi i64 [ %index.next49, %vector.body35 ], [ 0, %vector.body65 ]
  %216 = trunc i64 %index48 to i32
  %217 = add i32 %216, 3584
  %218 = add i32 %21, %217
  %219 = trunc i64 %index48 to i32
  %220 = add i32 %219, -512
  %221 = add i32 %220, %23
  %222 = sext i32 %221 to i64
  %223 = getelementptr inbounds float, float* %7, i64 %222
  %224 = bitcast float* %223 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %224, align 4, !tbaa !5195
  %225 = getelementptr inbounds float, float* %223, i64 4
  %226 = bitcast float* %225 to <4 x i32>*
  %wide.load64 = load <4 x i32>, <4 x i32>* %226, align 4, !tbaa !5195
  %227 = sext i32 %218 to i64
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = bitcast float* %228 to <4 x i32>*
  store <4 x i32> %wide.load, <4 x i32>* %229, align 4, !tbaa !5190
  %230 = getelementptr inbounds float, float* %228, i64 4
  %231 = bitcast float* %230 to <4 x i32>*
  store <4 x i32> %wide.load64, <4 x i32>* %231, align 4, !tbaa !5190
  %index.next49 = add i64 %index48, 8
  %232 = icmp eq i64 %index.next49, 512
  br i1 %232, label %vector.body, label %vector.body35, !llvm.loop !5212

vector.body:                                      ; preds = %vector.body35, %vector.body
  %index = phi i64 [ %index.next, %vector.body ], [ 0, %vector.body35 ]
  %233 = trunc i64 %index to i32
  %234 = add i32 %233, 4096
  %235 = add i32 %234, %21
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds float, float* %4, i64 %236
  %238 = bitcast float* %237 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %238, align 4, !tbaa !5190
  %239 = getelementptr inbounds float, float* %237, i64 4
  %240 = bitcast float* %239 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %240, align 4, !tbaa !5190
  %index.next = add i64 %index, 8
  %241 = icmp eq i64 %index.next, 512
  br i1 %241, label %for_end3, label %vector.body, !llvm.loop !5213
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.404(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.2
  %indvars.iv48 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next49, %for_end6.2 ]
  %33 = trunc i64 %indvars.iv48 to i32
  %34 = srem i32 %33, 7
  %35 = sdiv i32 %33, 7
  %36 = mul nsw i32 %35, 147456
  %37 = sext i32 %36 to i64
  %38 = mul nsw i32 %34, 4608
  %39 = sext i32 %38 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.2, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %125, %for_body5 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %119, %for_body5 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %118, %for_body5 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %117, %for_body5 ]
  %44 = phi <32 x float> [ zeroinitializer, %for_body ], [ %116, %for_body5 ]
  %45 = phi <32 x float> [ zeroinitializer, %for_body ], [ %115, %for_body5 ]
  %46 = phi <32 x float> [ zeroinitializer, %for_body ], [ %114, %for_body5 ]
  %47 = add nsw i64 %indvars.iv, %39
  %48 = getelementptr inbounds float, float* %4, i64 %47
  %49 = load float, float* %48, align 4, !tbaa !5190
  %50 = insertelement <32 x float> undef, float %49, i32 0
  %51 = shufflevector <32 x float> %50, <32 x float> undef, <32 x i32> zeroinitializer
  %52 = shl nsw i64 %indvars.iv, 5
  %53 = add nsw i64 %52, %37
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <32 x float>*
  %56 = load <32 x float>, <32 x float>* %55, align 64, !tbaa !5214
  %57 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %51, <32 x float> %56, <32 x float> %46)
  %58 = add nsw i64 %47, 512
  %59 = getelementptr inbounds float, float* %4, i64 %58
  %60 = load float, float* %59, align 4, !tbaa !5190
  %61 = insertelement <32 x float> undef, float %60, i32 0
  %62 = shufflevector <32 x float> %61, <32 x float> undef, <32 x i32> zeroinitializer
  %63 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %56, <32 x float> %45)
  %64 = add nsw i64 %47, 1024
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !5190
  %67 = insertelement <32 x float> undef, float %66, i32 0
  %68 = shufflevector <32 x float> %67, <32 x float> undef, <32 x i32> zeroinitializer
  %69 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %56, <32 x float> %44)
  %70 = add nsw i64 %47, 1536
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !5190
  %73 = insertelement <32 x float> undef, float %72, i32 0
  %74 = shufflevector <32 x float> %73, <32 x float> undef, <32 x i32> zeroinitializer
  %75 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %56, <32 x float> %43)
  %76 = add nsw i64 %47, 2048
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !5190
  %79 = insertelement <32 x float> undef, float %78, i32 0
  %80 = shufflevector <32 x float> %79, <32 x float> undef, <32 x i32> zeroinitializer
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %56, <32 x float> %42)
  %82 = add nsw i64 %47, 2560
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !5190
  %85 = insertelement <32 x float> undef, float %84, i32 0
  %86 = shufflevector <32 x float> %85, <32 x float> undef, <32 x i32> zeroinitializer
  %87 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %56, <32 x float> %41)
  %88 = add nsw i64 %47, 3072
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !5190
  %91 = insertelement <32 x float> undef, float %90, i32 0
  %92 = shufflevector <32 x float> %91, <32 x float> undef, <32 x i32> zeroinitializer
  %93 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %56, <32 x float> %40)
  %94 = add nsw i64 %53, 16384
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to <32 x float>*
  %97 = load <32 x float>, <32 x float>* %96, align 64, !tbaa !5214
  %98 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %97, <32 x float> %57)
  %99 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %97, <32 x float> %63)
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %97, <32 x float> %69)
  %101 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %97, <32 x float> %75)
  %102 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %97, <32 x float> %81)
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %97, <32 x float> %87)
  %104 = add nsw i64 %47, 3584
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !5190
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %97, <32 x float> %93)
  %110 = add nsw i64 %53, 32768
  %111 = getelementptr inbounds float, float* %7, i64 %110
  %112 = bitcast float* %111 to <32 x float>*
  %113 = load <32 x float>, <32 x float>* %112, align 64, !tbaa !5214
  %114 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %113, <32 x float> %98)
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %113, <32 x float> %99)
  %116 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %113, <32 x float> %100)
  %117 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %113, <32 x float> %101)
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %113, <32 x float> %102)
  %119 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %113, <32 x float> %103)
  %120 = add nsw i64 %47, 4096
  %121 = getelementptr inbounds float, float* %4, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !5190
  %123 = insertelement <32 x float> undef, float %122, i32 0
  %124 = shufflevector <32 x float> %123, <32 x float> undef, <32 x i32> zeroinitializer
  %125 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %124, <32 x float> %113, <32 x float> %109)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %126 = mul nsw i32 %34, 4608
  %127 = add nsw i32 %126, 4608
  %128 = add nsw i64 %37, 49152
  %129 = sext i32 %127 to i64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %130 = phi <32 x float> [ %125, %for_end6 ], [ %215, %for_body5.1 ]
  %131 = phi <32 x float> [ %119, %for_end6 ], [ %209, %for_body5.1 ]
  %132 = phi <32 x float> [ %118, %for_end6 ], [ %208, %for_body5.1 ]
  %133 = phi <32 x float> [ %117, %for_end6 ], [ %207, %for_body5.1 ]
  %134 = phi <32 x float> [ %116, %for_end6 ], [ %206, %for_body5.1 ]
  %135 = phi <32 x float> [ %115, %for_end6 ], [ %205, %for_body5.1 ]
  %136 = phi <32 x float> [ %114, %for_end6 ], [ %204, %for_body5.1 ]
  %137 = add nsw i64 %indvars.iv.1, %129
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !5190
  %140 = insertelement <32 x float> undef, float %139, i32 0
  %141 = shufflevector <32 x float> %140, <32 x float> undef, <32 x i32> zeroinitializer
  %142 = shl nsw i64 %indvars.iv.1, 5
  %143 = add nsw i64 %128, %142
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <32 x float>*
  %146 = load <32 x float>, <32 x float>* %145, align 64, !tbaa !5214
  %147 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %141, <32 x float> %146, <32 x float> %136)
  %148 = add nsw i64 %137, 512
  %149 = getelementptr inbounds float, float* %4, i64 %148
  %150 = load float, float* %149, align 4, !tbaa !5190
  %151 = insertelement <32 x float> undef, float %150, i32 0
  %152 = shufflevector <32 x float> %151, <32 x float> undef, <32 x i32> zeroinitializer
  %153 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %152, <32 x float> %146, <32 x float> %135)
  %154 = add nsw i64 %137, 1024
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !5190
  %157 = insertelement <32 x float> undef, float %156, i32 0
  %158 = shufflevector <32 x float> %157, <32 x float> undef, <32 x i32> zeroinitializer
  %159 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %146, <32 x float> %134)
  %160 = add nsw i64 %137, 1536
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !5190
  %163 = insertelement <32 x float> undef, float %162, i32 0
  %164 = shufflevector <32 x float> %163, <32 x float> undef, <32 x i32> zeroinitializer
  %165 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %164, <32 x float> %146, <32 x float> %133)
  %166 = add nsw i64 %137, 2048
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !5190
  %169 = insertelement <32 x float> undef, float %168, i32 0
  %170 = shufflevector <32 x float> %169, <32 x float> undef, <32 x i32> zeroinitializer
  %171 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %170, <32 x float> %146, <32 x float> %132)
  %172 = add nsw i64 %137, 2560
  %173 = getelementptr inbounds float, float* %4, i64 %172
  %174 = load float, float* %173, align 4, !tbaa !5190
  %175 = insertelement <32 x float> undef, float %174, i32 0
  %176 = shufflevector <32 x float> %175, <32 x float> undef, <32 x i32> zeroinitializer
  %177 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %176, <32 x float> %146, <32 x float> %131)
  %178 = add nsw i64 %137, 3072
  %179 = getelementptr inbounds float, float* %4, i64 %178
  %180 = load float, float* %179, align 4, !tbaa !5190
  %181 = insertelement <32 x float> undef, float %180, i32 0
  %182 = shufflevector <32 x float> %181, <32 x float> undef, <32 x i32> zeroinitializer
  %183 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %182, <32 x float> %146, <32 x float> %130)
  %184 = add nsw i64 %143, 16384
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to <32 x float>*
  %187 = load <32 x float>, <32 x float>* %186, align 64, !tbaa !5214
  %188 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %152, <32 x float> %187, <32 x float> %147)
  %189 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %187, <32 x float> %153)
  %190 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %164, <32 x float> %187, <32 x float> %159)
  %191 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %170, <32 x float> %187, <32 x float> %165)
  %192 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %176, <32 x float> %187, <32 x float> %171)
  %193 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %182, <32 x float> %187, <32 x float> %177)
  %194 = add nsw i64 %137, 3584
  %195 = getelementptr inbounds float, float* %4, i64 %194
  %196 = load float, float* %195, align 4, !tbaa !5190
  %197 = insertelement <32 x float> undef, float %196, i32 0
  %198 = shufflevector <32 x float> %197, <32 x float> undef, <32 x i32> zeroinitializer
  %199 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %198, <32 x float> %187, <32 x float> %183)
  %200 = add nsw i64 %143, 32768
  %201 = getelementptr inbounds float, float* %7, i64 %200
  %202 = bitcast float* %201 to <32 x float>*
  %203 = load <32 x float>, <32 x float>* %202, align 64, !tbaa !5214
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %203, <32 x float> %188)
  %205 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %164, <32 x float> %203, <32 x float> %189)
  %206 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %170, <32 x float> %203, <32 x float> %190)
  %207 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %176, <32 x float> %203, <32 x float> %191)
  %208 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %182, <32 x float> %203, <32 x float> %192)
  %209 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %198, <32 x float> %203, <32 x float> %193)
  %210 = add nsw i64 %137, 4096
  %211 = getelementptr inbounds float, float* %4, i64 %210
  %212 = load float, float* %211, align 4, !tbaa !5190
  %213 = insertelement <32 x float> undef, float %212, i32 0
  %214 = shufflevector <32 x float> %213, <32 x float> undef, <32 x i32> zeroinitializer
  %215 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %214, <32 x float> %203, <32 x float> %199)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %216 = mul nsw i32 %34, 4608
  %217 = add nsw i32 %216, 9216
  %218 = add nsw i64 %37, 98304
  %219 = sext i32 %217 to i64
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %220 = phi <32 x float> [ %215, %for_end6.1 ], [ %305, %for_body5.2 ]
  %221 = phi <32 x float> [ %209, %for_end6.1 ], [ %299, %for_body5.2 ]
  %222 = phi <32 x float> [ %208, %for_end6.1 ], [ %298, %for_body5.2 ]
  %223 = phi <32 x float> [ %207, %for_end6.1 ], [ %297, %for_body5.2 ]
  %224 = phi <32 x float> [ %206, %for_end6.1 ], [ %296, %for_body5.2 ]
  %225 = phi <32 x float> [ %205, %for_end6.1 ], [ %295, %for_body5.2 ]
  %226 = phi <32 x float> [ %204, %for_end6.1 ], [ %294, %for_body5.2 ]
  %227 = add nsw i64 %indvars.iv.2, %219
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = load float, float* %228, align 4, !tbaa !5190
  %230 = insertelement <32 x float> undef, float %229, i32 0
  %231 = shufflevector <32 x float> %230, <32 x float> undef, <32 x i32> zeroinitializer
  %232 = shl nsw i64 %indvars.iv.2, 5
  %233 = add nsw i64 %218, %232
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <32 x float>*
  %236 = load <32 x float>, <32 x float>* %235, align 64, !tbaa !5214
  %237 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %231, <32 x float> %236, <32 x float> %226)
  %238 = add nsw i64 %227, 512
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !5190
  %241 = insertelement <32 x float> undef, float %240, i32 0
  %242 = shufflevector <32 x float> %241, <32 x float> undef, <32 x i32> zeroinitializer
  %243 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %236, <32 x float> %225)
  %244 = add nsw i64 %227, 1024
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !5190
  %247 = insertelement <32 x float> undef, float %246, i32 0
  %248 = shufflevector <32 x float> %247, <32 x float> undef, <32 x i32> zeroinitializer
  %249 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %236, <32 x float> %224)
  %250 = add nsw i64 %227, 1536
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !5190
  %253 = insertelement <32 x float> undef, float %252, i32 0
  %254 = shufflevector <32 x float> %253, <32 x float> undef, <32 x i32> zeroinitializer
  %255 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %254, <32 x float> %236, <32 x float> %223)
  %256 = add nsw i64 %227, 2048
  %257 = getelementptr inbounds float, float* %4, i64 %256
  %258 = load float, float* %257, align 4, !tbaa !5190
  %259 = insertelement <32 x float> undef, float %258, i32 0
  %260 = shufflevector <32 x float> %259, <32 x float> undef, <32 x i32> zeroinitializer
  %261 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %260, <32 x float> %236, <32 x float> %222)
  %262 = add nsw i64 %227, 2560
  %263 = getelementptr inbounds float, float* %4, i64 %262
  %264 = load float, float* %263, align 4, !tbaa !5190
  %265 = insertelement <32 x float> undef, float %264, i32 0
  %266 = shufflevector <32 x float> %265, <32 x float> undef, <32 x i32> zeroinitializer
  %267 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %266, <32 x float> %236, <32 x float> %221)
  %268 = add nsw i64 %227, 3072
  %269 = getelementptr inbounds float, float* %4, i64 %268
  %270 = load float, float* %269, align 4, !tbaa !5190
  %271 = insertelement <32 x float> undef, float %270, i32 0
  %272 = shufflevector <32 x float> %271, <32 x float> undef, <32 x i32> zeroinitializer
  %273 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %272, <32 x float> %236, <32 x float> %220)
  %274 = add nsw i64 %233, 16384
  %275 = getelementptr inbounds float, float* %7, i64 %274
  %276 = bitcast float* %275 to <32 x float>*
  %277 = load <32 x float>, <32 x float>* %276, align 64, !tbaa !5214
  %278 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %277, <32 x float> %237)
  %279 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %277, <32 x float> %243)
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %254, <32 x float> %277, <32 x float> %249)
  %281 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %260, <32 x float> %277, <32 x float> %255)
  %282 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %266, <32 x float> %277, <32 x float> %261)
  %283 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %272, <32 x float> %277, <32 x float> %267)
  %284 = add nsw i64 %227, 3584
  %285 = getelementptr inbounds float, float* %4, i64 %284
  %286 = load float, float* %285, align 4, !tbaa !5190
  %287 = insertelement <32 x float> undef, float %286, i32 0
  %288 = shufflevector <32 x float> %287, <32 x float> undef, <32 x i32> zeroinitializer
  %289 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %288, <32 x float> %277, <32 x float> %273)
  %290 = add nsw i64 %233, 32768
  %291 = getelementptr inbounds float, float* %7, i64 %290
  %292 = bitcast float* %291 to <32 x float>*
  %293 = load <32 x float>, <32 x float>* %292, align 64, !tbaa !5214
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %293, <32 x float> %278)
  %295 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %254, <32 x float> %293, <32 x float> %279)
  %296 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %260, <32 x float> %293, <32 x float> %280)
  %297 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %266, <32 x float> %293, <32 x float> %281)
  %298 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %272, <32 x float> %293, <32 x float> %282)
  %299 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %288, <32 x float> %293, <32 x float> %283)
  %300 = add nsw i64 %227, 4096
  %301 = getelementptr inbounds float, float* %4, i64 %300
  %302 = load float, float* %301, align 4, !tbaa !5190
  %303 = insertelement <32 x float> undef, float %302, i32 0
  %304 = shufflevector <32 x float> %303, <32 x float> undef, <32 x i32> zeroinitializer
  %305 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %304, <32 x float> %293, <32 x float> %289)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %306 = mul nsw i64 %indvars.iv48, 224
  %307 = shl nsw i32 %35, 5
  %308 = sext i32 %307 to i64
  %309 = getelementptr inbounds float, float* %16, i64 %308
  %310 = bitcast float* %309 to <32 x float>*
  %311 = load <32 x float>, <32 x float>* %310, align 64, !tbaa !5217
  %312 = getelementptr inbounds float, float* %13, i64 %308
  %313 = bitcast float* %312 to <32 x float>*
  %314 = load <32 x float>, <32 x float>* %313, align 64, !tbaa !5220
  %315 = fadd <32 x float> %314, %294
  %316 = fadd <32 x float> %311, %315
  %317 = fcmp ogt <32 x float> %316, zeroinitializer
  %318 = select <32 x i1> %317, <32 x float> %316, <32 x float> zeroinitializer
  %319 = getelementptr inbounds float, float* %10, i64 %306
  %320 = bitcast float* %319 to <32 x float>*
  store <32 x float> %318, <32 x float>* %320, align 64, !tbaa !5223
  %321 = add nsw i64 %306, 32
  %322 = fadd <32 x float> %314, %295
  %323 = fadd <32 x float> %311, %322
  %324 = fcmp ogt <32 x float> %323, zeroinitializer
  %325 = select <32 x i1> %324, <32 x float> %323, <32 x float> zeroinitializer
  %326 = getelementptr inbounds float, float* %10, i64 %321
  %327 = bitcast float* %326 to <32 x float>*
  store <32 x float> %325, <32 x float>* %327, align 64, !tbaa !5223
  %328 = add nsw i64 %306, 64
  %329 = fadd <32 x float> %314, %296
  %330 = fadd <32 x float> %311, %329
  %331 = fcmp ogt <32 x float> %330, zeroinitializer
  %332 = select <32 x i1> %331, <32 x float> %330, <32 x float> zeroinitializer
  %333 = getelementptr inbounds float, float* %10, i64 %328
  %334 = bitcast float* %333 to <32 x float>*
  store <32 x float> %332, <32 x float>* %334, align 64, !tbaa !5223
  %335 = add nsw i64 %306, 96
  %336 = fadd <32 x float> %314, %297
  %337 = fadd <32 x float> %311, %336
  %338 = fcmp ogt <32 x float> %337, zeroinitializer
  %339 = select <32 x i1> %338, <32 x float> %337, <32 x float> zeroinitializer
  %340 = getelementptr inbounds float, float* %10, i64 %335
  %341 = bitcast float* %340 to <32 x float>*
  store <32 x float> %339, <32 x float>* %341, align 64, !tbaa !5223
  %342 = add nsw i64 %306, 128
  %343 = fadd <32 x float> %314, %298
  %344 = fadd <32 x float> %311, %343
  %345 = fcmp ogt <32 x float> %344, zeroinitializer
  %346 = select <32 x i1> %345, <32 x float> %344, <32 x float> zeroinitializer
  %347 = getelementptr inbounds float, float* %10, i64 %342
  %348 = bitcast float* %347 to <32 x float>*
  store <32 x float> %346, <32 x float>* %348, align 64, !tbaa !5223
  %349 = add nsw i64 %306, 160
  %350 = fadd <32 x float> %314, %299
  %351 = fadd <32 x float> %311, %350
  %352 = fcmp ogt <32 x float> %351, zeroinitializer
  %353 = select <32 x i1> %352, <32 x float> %351, <32 x float> zeroinitializer
  %354 = getelementptr inbounds float, float* %10, i64 %349
  %355 = bitcast float* %354 to <32 x float>*
  store <32 x float> %353, <32 x float>* %355, align 64, !tbaa !5223
  %356 = add nsw i64 %306, 192
  %357 = fadd <32 x float> %314, %305
  %358 = fadd <32 x float> %311, %357
  %359 = fcmp ogt <32 x float> %358, zeroinitializer
  %360 = select <32 x i1> %359, <32 x float> %358, <32 x float> zeroinitializer
  %361 = getelementptr inbounds float, float* %10, i64 %356
  %362 = bitcast float* %361 to <32 x float>*
  store <32 x float> %360, <32 x float>* %362, align 64, !tbaa !5223
  %indvars.iv.next49 = add nsw i64 %indvars.iv48, 1
  %363 = icmp slt i64 %indvars.iv.next49, %32
  br i1 %363, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_global_avg_pool2d(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([79 x i8], [79 x i8]* @.str.405, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !5226
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([154 x i8], [154 x i8]* @.str.406, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !5240
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([154 x i8], [154 x i8]* @.str.407, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !5242
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !5256
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 64
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !5258
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 7
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !5261
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 7
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !5263
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !5267
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 100352, i32 1568, i32 224, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !5279
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.408, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !5283
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !5297
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 64
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.409, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !5299
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 1
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !5302
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 1
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !5304
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 32
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.34, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !5308
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 2048, i32 32, i32 32, i32 32>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !5320
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([233 x i8], [233 x i8]* @.str.410, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_nn_global_avg_pool2d_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_global_avg_pool2d_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %33, align 8
  %3 = getelementptr inbounds %33, %33* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %33, %33* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %33* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.411, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.411(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 63
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 64
  %15 = select i1 %14, i32 %13, i32 64
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 64
  %18 = select i1 %17, i32 %16, i32 64
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv14 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next15, %for_end3 ]
  %24 = trunc i64 %indvars.iv14 to i32
  %25 = shl i32 %24, 5
  %26 = mul nsw i64 %indvars.iv14, 1568
  %27 = sext i32 %25 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body2 ]
  %28 = add nuw nsw i64 %indvars.iv, %27
  %29 = getelementptr inbounds float, float* %4, i64 %28
  store float 0.000000e+00, float* %29, align 4, !tbaa !5324
  %30 = add nsw i64 %indvars.iv, %26
  %31 = getelementptr inbounds float, float* %7, i64 %30
  %32 = load float, float* %31, align 4, !tbaa !5327
  %33 = tail call float @llvm.fmuladd.f32(float %32, float 0x3F94E5E0A0000000, float 0.000000e+00)
  %34 = shl i64 %30, 32
  %sext = add i64 %34, 137438953472
  %35 = ashr exact i64 %sext, 32
  %36 = getelementptr inbounds float, float* %7, i64 %35
  %37 = load float, float* %36, align 4, !tbaa !5327
  %38 = tail call float @llvm.fmuladd.f32(float %37, float 0x3F94E5E0A0000000, float %33)
  %39 = shl i64 %30, 32
  %sext16 = add i64 %39, 274877906944
  %40 = ashr exact i64 %sext16, 32
  %41 = getelementptr inbounds float, float* %7, i64 %40
  %42 = load float, float* %41, align 4, !tbaa !5327
  %43 = tail call float @llvm.fmuladd.f32(float %42, float 0x3F94E5E0A0000000, float %38)
  %44 = shl i64 %30, 32
  %sext17 = add i64 %44, 412316860416
  %45 = ashr exact i64 %sext17, 32
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = load float, float* %46, align 4, !tbaa !5327
  %48 = tail call float @llvm.fmuladd.f32(float %47, float 0x3F94E5E0A0000000, float %43)
  %49 = shl i64 %30, 32
  %sext18 = add i64 %49, 549755813888
  %50 = ashr exact i64 %sext18, 32
  %51 = getelementptr inbounds float, float* %7, i64 %50
  %52 = load float, float* %51, align 4, !tbaa !5327
  %53 = tail call float @llvm.fmuladd.f32(float %52, float 0x3F94E5E0A0000000, float %48)
  %54 = shl i64 %30, 32
  %sext19 = add i64 %54, 687194767360
  %55 = ashr exact i64 %sext19, 32
  %56 = getelementptr inbounds float, float* %7, i64 %55
  %57 = load float, float* %56, align 4, !tbaa !5327
  %58 = tail call float @llvm.fmuladd.f32(float %57, float 0x3F94E5E0A0000000, float %53)
  %59 = shl i64 %30, 32
  %sext20 = add i64 %59, 824633720832
  %60 = ashr exact i64 %sext20, 32
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = load float, float* %61, align 4, !tbaa !5327
  %63 = tail call float @llvm.fmuladd.f32(float %62, float 0x3F94E5E0A0000000, float %58)
  %64 = shl i64 %30, 32
  %sext57 = add i64 %64, 962072674304
  %65 = ashr exact i64 %sext57, 32
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = load float, float* %66, align 4, !tbaa !5327
  %68 = tail call float @llvm.fmuladd.f32(float %67, float 0x3F94E5E0A0000000, float %63)
  %69 = shl i64 %30, 32
  %sext21 = add i64 %69, 1099511627776
  %70 = ashr exact i64 %sext21, 32
  %71 = getelementptr inbounds float, float* %7, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !5327
  %73 = tail call float @llvm.fmuladd.f32(float %72, float 0x3F94E5E0A0000000, float %68)
  %74 = shl i64 %30, 32
  %sext22 = add i64 %74, 1236950581248
  %75 = ashr exact i64 %sext22, 32
  %76 = getelementptr inbounds float, float* %7, i64 %75
  %77 = load float, float* %76, align 4, !tbaa !5327
  %78 = tail call float @llvm.fmuladd.f32(float %77, float 0x3F94E5E0A0000000, float %73)
  %79 = shl i64 %30, 32
  %sext23 = add i64 %79, 1374389534720
  %80 = ashr exact i64 %sext23, 32
  %81 = getelementptr inbounds float, float* %7, i64 %80
  %82 = load float, float* %81, align 4, !tbaa !5327
  %83 = tail call float @llvm.fmuladd.f32(float %82, float 0x3F94E5E0A0000000, float %78)
  %84 = shl i64 %30, 32
  %sext24 = add i64 %84, 1511828488192
  %85 = ashr exact i64 %sext24, 32
  %86 = getelementptr inbounds float, float* %7, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !5327
  %88 = tail call float @llvm.fmuladd.f32(float %87, float 0x3F94E5E0A0000000, float %83)
  %89 = shl i64 %30, 32
  %sext25 = add i64 %89, 1649267441664
  %90 = ashr exact i64 %sext25, 32
  %91 = getelementptr inbounds float, float* %7, i64 %90
  %92 = load float, float* %91, align 4, !tbaa !5327
  %93 = tail call float @llvm.fmuladd.f32(float %92, float 0x3F94E5E0A0000000, float %88)
  %94 = shl i64 %30, 32
  %sext26 = add i64 %94, 1786706395136
  %95 = ashr exact i64 %sext26, 32
  %96 = getelementptr inbounds float, float* %7, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !5327
  %98 = tail call float @llvm.fmuladd.f32(float %97, float 0x3F94E5E0A0000000, float %93)
  %99 = shl i64 %30, 32
  %sext58 = add i64 %99, 1924145348608
  %100 = ashr exact i64 %sext58, 32
  %101 = getelementptr inbounds float, float* %7, i64 %100
  %102 = load float, float* %101, align 4, !tbaa !5327
  %103 = tail call float @llvm.fmuladd.f32(float %102, float 0x3F94E5E0A0000000, float %98)
  %104 = shl i64 %30, 32
  %sext27 = add i64 %104, 2061584302080
  %105 = ashr exact i64 %sext27, 32
  %106 = getelementptr inbounds float, float* %7, i64 %105
  %107 = load float, float* %106, align 4, !tbaa !5327
  %108 = tail call float @llvm.fmuladd.f32(float %107, float 0x3F94E5E0A0000000, float %103)
  %109 = shl i64 %30, 32
  %sext28 = add i64 %109, 2199023255552
  %110 = ashr exact i64 %sext28, 32
  %111 = getelementptr inbounds float, float* %7, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !5327
  %113 = tail call float @llvm.fmuladd.f32(float %112, float 0x3F94E5E0A0000000, float %108)
  %114 = shl i64 %30, 32
  %sext29 = add i64 %114, 2336462209024
  %115 = ashr exact i64 %sext29, 32
  %116 = getelementptr inbounds float, float* %7, i64 %115
  %117 = load float, float* %116, align 4, !tbaa !5327
  %118 = tail call float @llvm.fmuladd.f32(float %117, float 0x3F94E5E0A0000000, float %113)
  %119 = shl i64 %30, 32
  %sext30 = add i64 %119, 2473901162496
  %120 = ashr exact i64 %sext30, 32
  %121 = getelementptr inbounds float, float* %7, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !5327
  %123 = tail call float @llvm.fmuladd.f32(float %122, float 0x3F94E5E0A0000000, float %118)
  %124 = shl i64 %30, 32
  %sext31 = add i64 %124, 2611340115968
  %125 = ashr exact i64 %sext31, 32
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !5327
  %128 = tail call float @llvm.fmuladd.f32(float %127, float 0x3F94E5E0A0000000, float %123)
  %129 = shl i64 %30, 32
  %sext32 = add i64 %129, 2748779069440
  %130 = ashr exact i64 %sext32, 32
  %131 = getelementptr inbounds float, float* %7, i64 %130
  %132 = load float, float* %131, align 4, !tbaa !5327
  %133 = tail call float @llvm.fmuladd.f32(float %132, float 0x3F94E5E0A0000000, float %128)
  %134 = shl i64 %30, 32
  %sext59 = add i64 %134, 2886218022912
  %135 = ashr exact i64 %sext59, 32
  %136 = getelementptr inbounds float, float* %7, i64 %135
  %137 = load float, float* %136, align 4, !tbaa !5327
  %138 = tail call float @llvm.fmuladd.f32(float %137, float 0x3F94E5E0A0000000, float %133)
  %139 = shl i64 %30, 32
  %sext33 = add i64 %139, 3023656976384
  %140 = ashr exact i64 %sext33, 32
  %141 = getelementptr inbounds float, float* %7, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !5327
  %143 = tail call float @llvm.fmuladd.f32(float %142, float 0x3F94E5E0A0000000, float %138)
  %144 = shl i64 %30, 32
  %sext34 = add i64 %144, 3161095929856
  %145 = ashr exact i64 %sext34, 32
  %146 = getelementptr inbounds float, float* %7, i64 %145
  %147 = load float, float* %146, align 4, !tbaa !5327
  %148 = tail call float @llvm.fmuladd.f32(float %147, float 0x3F94E5E0A0000000, float %143)
  %149 = shl i64 %30, 32
  %sext35 = add i64 %149, 3298534883328
  %150 = ashr exact i64 %sext35, 32
  %151 = getelementptr inbounds float, float* %7, i64 %150
  %152 = load float, float* %151, align 4, !tbaa !5327
  %153 = tail call float @llvm.fmuladd.f32(float %152, float 0x3F94E5E0A0000000, float %148)
  %154 = shl i64 %30, 32
  %sext36 = add i64 %154, 3435973836800
  %155 = ashr exact i64 %sext36, 32
  %156 = getelementptr inbounds float, float* %7, i64 %155
  %157 = load float, float* %156, align 4, !tbaa !5327
  %158 = tail call float @llvm.fmuladd.f32(float %157, float 0x3F94E5E0A0000000, float %153)
  %159 = shl i64 %30, 32
  %sext37 = add i64 %159, 3573412790272
  %160 = ashr exact i64 %sext37, 32
  %161 = getelementptr inbounds float, float* %7, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !5327
  %163 = tail call float @llvm.fmuladd.f32(float %162, float 0x3F94E5E0A0000000, float %158)
  %164 = shl i64 %30, 32
  %sext38 = add i64 %164, 3710851743744
  %165 = ashr exact i64 %sext38, 32
  %166 = getelementptr inbounds float, float* %7, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !5327
  %168 = tail call float @llvm.fmuladd.f32(float %167, float 0x3F94E5E0A0000000, float %163)
  %169 = shl i64 %30, 32
  %sext60 = add i64 %169, 3848290697216
  %170 = ashr exact i64 %sext60, 32
  %171 = getelementptr inbounds float, float* %7, i64 %170
  %172 = load float, float* %171, align 4, !tbaa !5327
  %173 = tail call float @llvm.fmuladd.f32(float %172, float 0x3F94E5E0A0000000, float %168)
  %174 = shl i64 %30, 32
  %sext39 = add i64 %174, 3985729650688
  %175 = ashr exact i64 %sext39, 32
  %176 = getelementptr inbounds float, float* %7, i64 %175
  %177 = load float, float* %176, align 4, !tbaa !5327
  %178 = tail call float @llvm.fmuladd.f32(float %177, float 0x3F94E5E0A0000000, float %173)
  %179 = shl i64 %30, 32
  %sext40 = add i64 %179, 4123168604160
  %180 = ashr exact i64 %sext40, 32
  %181 = getelementptr inbounds float, float* %7, i64 %180
  %182 = load float, float* %181, align 4, !tbaa !5327
  %183 = tail call float @llvm.fmuladd.f32(float %182, float 0x3F94E5E0A0000000, float %178)
  %184 = shl i64 %30, 32
  %sext41 = add i64 %184, 4260607557632
  %185 = ashr exact i64 %sext41, 32
  %186 = getelementptr inbounds float, float* %7, i64 %185
  %187 = load float, float* %186, align 4, !tbaa !5327
  %188 = tail call float @llvm.fmuladd.f32(float %187, float 0x3F94E5E0A0000000, float %183)
  %189 = shl i64 %30, 32
  %sext42 = add i64 %189, 4398046511104
  %190 = ashr exact i64 %sext42, 32
  %191 = getelementptr inbounds float, float* %7, i64 %190
  %192 = load float, float* %191, align 4, !tbaa !5327
  %193 = tail call float @llvm.fmuladd.f32(float %192, float 0x3F94E5E0A0000000, float %188)
  %194 = shl i64 %30, 32
  %sext43 = add i64 %194, 4535485464576
  %195 = ashr exact i64 %sext43, 32
  %196 = getelementptr inbounds float, float* %7, i64 %195
  %197 = load float, float* %196, align 4, !tbaa !5327
  %198 = tail call float @llvm.fmuladd.f32(float %197, float 0x3F94E5E0A0000000, float %193)
  %199 = shl i64 %30, 32
  %sext44 = add i64 %199, 4672924418048
  %200 = ashr exact i64 %sext44, 32
  %201 = getelementptr inbounds float, float* %7, i64 %200
  %202 = load float, float* %201, align 4, !tbaa !5327
  %203 = tail call float @llvm.fmuladd.f32(float %202, float 0x3F94E5E0A0000000, float %198)
  %204 = shl i64 %30, 32
  %sext61 = add i64 %204, 4810363371520
  %205 = ashr exact i64 %sext61, 32
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !5327
  %208 = tail call float @llvm.fmuladd.f32(float %207, float 0x3F94E5E0A0000000, float %203)
  %209 = shl i64 %30, 32
  %sext45 = add i64 %209, 4947802324992
  %210 = ashr exact i64 %sext45, 32
  %211 = getelementptr inbounds float, float* %7, i64 %210
  %212 = load float, float* %211, align 4, !tbaa !5327
  %213 = tail call float @llvm.fmuladd.f32(float %212, float 0x3F94E5E0A0000000, float %208)
  %214 = shl i64 %30, 32
  %sext46 = add i64 %214, 5085241278464
  %215 = ashr exact i64 %sext46, 32
  %216 = getelementptr inbounds float, float* %7, i64 %215
  %217 = load float, float* %216, align 4, !tbaa !5327
  %218 = tail call float @llvm.fmuladd.f32(float %217, float 0x3F94E5E0A0000000, float %213)
  %219 = shl i64 %30, 32
  %sext47 = add i64 %219, 5222680231936
  %220 = ashr exact i64 %sext47, 32
  %221 = getelementptr inbounds float, float* %7, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !5327
  %223 = tail call float @llvm.fmuladd.f32(float %222, float 0x3F94E5E0A0000000, float %218)
  %224 = shl i64 %30, 32
  %sext48 = add i64 %224, 5360119185408
  %225 = ashr exact i64 %sext48, 32
  %226 = getelementptr inbounds float, float* %7, i64 %225
  %227 = load float, float* %226, align 4, !tbaa !5327
  %228 = tail call float @llvm.fmuladd.f32(float %227, float 0x3F94E5E0A0000000, float %223)
  %229 = shl i64 %30, 32
  %sext49 = add i64 %229, 5497558138880
  %230 = ashr exact i64 %sext49, 32
  %231 = getelementptr inbounds float, float* %7, i64 %230
  %232 = load float, float* %231, align 4, !tbaa !5327
  %233 = tail call float @llvm.fmuladd.f32(float %232, float 0x3F94E5E0A0000000, float %228)
  %234 = shl i64 %30, 32
  %sext50 = add i64 %234, 5634997092352
  %235 = ashr exact i64 %sext50, 32
  %236 = getelementptr inbounds float, float* %7, i64 %235
  %237 = load float, float* %236, align 4, !tbaa !5327
  %238 = tail call float @llvm.fmuladd.f32(float %237, float 0x3F94E5E0A0000000, float %233)
  %239 = shl i64 %30, 32
  %sext62 = add i64 %239, 5772436045824
  %240 = ashr exact i64 %sext62, 32
  %241 = getelementptr inbounds float, float* %7, i64 %240
  %242 = load float, float* %241, align 4, !tbaa !5327
  %243 = tail call float @llvm.fmuladd.f32(float %242, float 0x3F94E5E0A0000000, float %238)
  %244 = shl i64 %30, 32
  %sext51 = add i64 %244, 5909874999296
  %245 = ashr exact i64 %sext51, 32
  %246 = getelementptr inbounds float, float* %7, i64 %245
  %247 = load float, float* %246, align 4, !tbaa !5327
  %248 = tail call float @llvm.fmuladd.f32(float %247, float 0x3F94E5E0A0000000, float %243)
  %249 = shl i64 %30, 32
  %sext52 = add i64 %249, 6047313952768
  %250 = ashr exact i64 %sext52, 32
  %251 = getelementptr inbounds float, float* %7, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !5327
  %253 = tail call float @llvm.fmuladd.f32(float %252, float 0x3F94E5E0A0000000, float %248)
  %254 = shl i64 %30, 32
  %sext53 = add i64 %254, 6184752906240
  %255 = ashr exact i64 %sext53, 32
  %256 = getelementptr inbounds float, float* %7, i64 %255
  %257 = load float, float* %256, align 4, !tbaa !5327
  %258 = tail call float @llvm.fmuladd.f32(float %257, float 0x3F94E5E0A0000000, float %253)
  %259 = shl i64 %30, 32
  %sext54 = add i64 %259, 6322191859712
  %260 = ashr exact i64 %sext54, 32
  %261 = getelementptr inbounds float, float* %7, i64 %260
  %262 = load float, float* %261, align 4, !tbaa !5327
  %263 = tail call float @llvm.fmuladd.f32(float %262, float 0x3F94E5E0A0000000, float %258)
  %264 = shl i64 %30, 32
  %sext55 = add i64 %264, 6459630813184
  %265 = ashr exact i64 %sext55, 32
  %266 = getelementptr inbounds float, float* %7, i64 %265
  %267 = load float, float* %266, align 4, !tbaa !5327
  %268 = tail call float @llvm.fmuladd.f32(float %267, float 0x3F94E5E0A0000000, float %263)
  %269 = shl i64 %30, 32
  %sext56 = add i64 %269, 6597069766656
  %270 = ashr exact i64 %sext56, 32
  %271 = getelementptr inbounds float, float* %7, i64 %270
  %272 = load float, float* %271, align 4, !tbaa !5327
  %273 = tail call float @llvm.fmuladd.f32(float %272, float 0x3F94E5E0A0000000, float %268)
  store float %273, float* %29, align 4, !tbaa !5324
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next15 = add nsw i64 %indvars.iv14, 1
  %274 = icmp slt i64 %indvars.iv.next15, %23
  br i1 %274, label %for_begin1.preheader, label %for_end, !prof !5
}

; Function Attrs: nounwind readnone speculatable
declare float @llvm.fmuladd.f32(float, float, float) #2

define dllexport i32 @fused_layout_transform_34(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.412, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !5330
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.413, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !5344
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.414, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !5346
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !5360
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 64
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !5362
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 7
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !5365
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 7
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !5367
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !5371
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 100352, i32 1568, i32 224, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !5383
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.408, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !5387
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !5401
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 512
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.247, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !5403
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 7
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.326, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !5406
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 7
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.327, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !5408
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 4
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !5412
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 100352, i32 196, i32 28, i32 4>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !5424
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([235 x i8], [235 x i8]* @.str.415, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_34_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_34_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %34, align 8
  %3 = getelementptr inbounds %34, %34* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %34, %34* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %34* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.416, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.416(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 3583
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 3584
  %15 = select i1 %14, i32 %13, i32 3584
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 3584
  %18 = select i1 %17, i32 %16, i32 3584
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_begin1.preheader ]
  %24 = mul nsw i64 %indvars.iv, 28
  %25 = trunc i64 %indvars.iv to i32
  %26 = sdiv i32 %25, 7
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 7
  %29 = mul nsw i32 %28, 224
  %30 = and i32 %27, 28
  %31 = and i32 %27, 28
  %32 = and i32 %27, 28
  %33 = insertelement <4 x i32> undef, i32 %27, i32 0
  %34 = insertelement <4 x i32> %33, i32 %30, i32 1
  %35 = insertelement <4 x i32> %34, i32 %31, i32 2
  %36 = insertelement <4 x i32> %35, i32 %32, i32 3
  %37 = and <4 x i32> %36, <i32 28, i32 undef, i32 undef, i32 undef>
  %38 = or <4 x i32> %36, <i32 undef, i32 1, i32 2, i32 3>
  %39 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %shuffle8 = shufflevector <4 x i32> %39, <4 x i32> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 0, i32 1, i32 2, i32 3, i32 0, i32 1, i32 2, i32 3, i32 0, i32 1, i32 2, i32 3>
  %40 = insertelement <4 x i32> undef, i32 %26, i32 0
  %41 = ashr <4 x i32> %40, <i32 3, i32 0, i32 0, i32 0>
  %42 = mul nsw <4 x i32> %41, <i32 1568, i32 undef, i32 undef, i32 undef>
  %shuffle7 = shufflevector <4 x i32> %42, <4 x i32> undef, <16 x i32> zeroinitializer
  %43 = add nsw i32 %29, 32
  %44 = add nsw i32 %29, 64
  %45 = add nsw i32 %29, 96
  %46 = insertelement <4 x i32> undef, i32 %29, i32 0
  %47 = insertelement <4 x i32> %46, i32 %43, i32 1
  %48 = insertelement <4 x i32> %47, i32 %44, i32 2
  %49 = insertelement <4 x i32> %48, i32 %45, i32 3
  %shuffle = shufflevector <4 x i32> %49, <4 x i32> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 1, i32 1, i32 1, i32 1, i32 2, i32 2, i32 2, i32 2, i32 3, i32 3, i32 3, i32 3>
  %50 = add <16 x i32> %shuffle, %shuffle7
  %51 = or <16 x i32> %50, %shuffle8
  %52 = sext <16 x i32> %51 to <16 x i64>
  %53 = extractelement <16 x i64> %52, i32 0
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to i32*
  %56 = load i32, i32* %55, align 4, !tbaa !5428
  %57 = getelementptr inbounds float, float* %4, i64 %24
  %58 = bitcast float* %57 to i32*
  store i32 %56, i32* %58, align 4, !tbaa !5431
  %59 = or i64 %24, 1
  %60 = extractelement <16 x i64> %52, i32 1
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = bitcast float* %61 to i32*
  %63 = load i32, i32* %62, align 4, !tbaa !5428
  %64 = getelementptr inbounds float, float* %4, i64 %59
  %65 = bitcast float* %64 to i32*
  store i32 %63, i32* %65, align 4, !tbaa !5431
  %66 = or i64 %24, 2
  %67 = extractelement <16 x i64> %52, i32 2
  %68 = getelementptr inbounds float, float* %7, i64 %67
  %69 = bitcast float* %68 to i32*
  %70 = load i32, i32* %69, align 4, !tbaa !5428
  %71 = getelementptr inbounds float, float* %4, i64 %66
  %72 = bitcast float* %71 to i32*
  store i32 %70, i32* %72, align 4, !tbaa !5431
  %73 = or i64 %24, 3
  %74 = extractelement <16 x i64> %52, i32 3
  %75 = getelementptr inbounds float, float* %7, i64 %74
  %76 = bitcast float* %75 to i32*
  %77 = load i32, i32* %76, align 4, !tbaa !5428
  %78 = getelementptr inbounds float, float* %4, i64 %73
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 4, !tbaa !5431
  %80 = add nsw i64 %24, 4
  %81 = extractelement <16 x i64> %52, i32 4
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to i32*
  %84 = load i32, i32* %83, align 4, !tbaa !5428
  %85 = getelementptr inbounds float, float* %4, i64 %80
  %86 = bitcast float* %85 to i32*
  store i32 %84, i32* %86, align 4, !tbaa !5431
  %87 = add nsw i64 %24, 5
  %88 = extractelement <16 x i64> %52, i32 5
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = bitcast float* %89 to i32*
  %91 = load i32, i32* %90, align 4, !tbaa !5428
  %92 = getelementptr inbounds float, float* %4, i64 %87
  %93 = bitcast float* %92 to i32*
  store i32 %91, i32* %93, align 4, !tbaa !5431
  %94 = add nsw i64 %24, 6
  %95 = extractelement <16 x i64> %52, i32 6
  %96 = getelementptr inbounds float, float* %7, i64 %95
  %97 = bitcast float* %96 to i32*
  %98 = load i32, i32* %97, align 4, !tbaa !5428
  %99 = getelementptr inbounds float, float* %4, i64 %94
  %100 = bitcast float* %99 to i32*
  store i32 %98, i32* %100, align 4, !tbaa !5431
  %101 = add nsw i64 %24, 7
  %102 = extractelement <16 x i64> %52, i32 7
  %103 = getelementptr inbounds float, float* %7, i64 %102
  %104 = bitcast float* %103 to i32*
  %105 = load i32, i32* %104, align 4, !tbaa !5428
  %106 = getelementptr inbounds float, float* %4, i64 %101
  %107 = bitcast float* %106 to i32*
  store i32 %105, i32* %107, align 4, !tbaa !5431
  %108 = add nsw i64 %24, 8
  %109 = extractelement <16 x i64> %52, i32 8
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !5428
  %113 = getelementptr inbounds float, float* %4, i64 %108
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !5431
  %115 = add nsw i64 %24, 9
  %116 = extractelement <16 x i64> %52, i32 9
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = bitcast float* %117 to i32*
  %119 = load i32, i32* %118, align 4, !tbaa !5428
  %120 = getelementptr inbounds float, float* %4, i64 %115
  %121 = bitcast float* %120 to i32*
  store i32 %119, i32* %121, align 4, !tbaa !5431
  %122 = add nsw i64 %24, 10
  %123 = extractelement <16 x i64> %52, i32 10
  %124 = getelementptr inbounds float, float* %7, i64 %123
  %125 = bitcast float* %124 to i32*
  %126 = load i32, i32* %125, align 4, !tbaa !5428
  %127 = getelementptr inbounds float, float* %4, i64 %122
  %128 = bitcast float* %127 to i32*
  store i32 %126, i32* %128, align 4, !tbaa !5431
  %129 = add nsw i64 %24, 11
  %130 = extractelement <16 x i64> %52, i32 11
  %131 = getelementptr inbounds float, float* %7, i64 %130
  %132 = bitcast float* %131 to i32*
  %133 = load i32, i32* %132, align 4, !tbaa !5428
  %134 = getelementptr inbounds float, float* %4, i64 %129
  %135 = bitcast float* %134 to i32*
  store i32 %133, i32* %135, align 4, !tbaa !5431
  %136 = add nsw i64 %24, 12
  %137 = extractelement <16 x i64> %52, i32 12
  %138 = getelementptr inbounds float, float* %7, i64 %137
  %139 = bitcast float* %138 to i32*
  %140 = load i32, i32* %139, align 4, !tbaa !5428
  %141 = getelementptr inbounds float, float* %4, i64 %136
  %142 = bitcast float* %141 to i32*
  store i32 %140, i32* %142, align 4, !tbaa !5431
  %143 = add nsw i64 %24, 13
  %144 = extractelement <16 x i64> %52, i32 13
  %145 = getelementptr inbounds float, float* %7, i64 %144
  %146 = bitcast float* %145 to i32*
  %147 = load i32, i32* %146, align 4, !tbaa !5428
  %148 = getelementptr inbounds float, float* %4, i64 %143
  %149 = bitcast float* %148 to i32*
  store i32 %147, i32* %149, align 4, !tbaa !5431
  %150 = add nsw i64 %24, 14
  %151 = extractelement <16 x i64> %52, i32 14
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = bitcast float* %152 to i32*
  %154 = load i32, i32* %153, align 4, !tbaa !5428
  %155 = getelementptr inbounds float, float* %4, i64 %150
  %156 = bitcast float* %155 to i32*
  store i32 %154, i32* %156, align 4, !tbaa !5431
  %157 = add nsw i64 %24, 15
  %158 = extractelement <16 x i64> %52, i32 15
  %159 = getelementptr inbounds float, float* %7, i64 %158
  %160 = bitcast float* %159 to i32*
  %161 = load i32, i32* %160, align 4, !tbaa !5428
  %162 = getelementptr inbounds float, float* %4, i64 %157
  %163 = bitcast float* %162 to i32*
  store i32 %161, i32* %163, align 4, !tbaa !5431
  %164 = add nsw i64 %24, 16
  %165 = insertelement <2 x i32> undef, i32 %29, i32 0
  %166 = shufflevector <2 x i32> %165, <2 x i32> undef, <2 x i32> zeroinitializer
  %167 = add nsw <2 x i32> %166, <i32 128, i32 160>
  %shuffle9 = shufflevector <2 x i32> %167, <2 x i32> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 1, i32 1, i32 1, i32 1>
  %168 = shufflevector <4 x i32> %42, <4 x i32> undef, <8 x i32> zeroinitializer
  %169 = add <8 x i32> %shuffle9, %168
  %170 = shufflevector <4 x i32> %37, <4 x i32> %38, <8 x i32> <i32 0, i32 5, i32 6, i32 7, i32 0, i32 5, i32 6, i32 7>
  %171 = or <8 x i32> %169, %170
  %172 = extractelement <8 x i32> %171, i32 0
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to i32*
  %176 = load i32, i32* %175, align 4, !tbaa !5428
  %177 = getelementptr inbounds float, float* %4, i64 %164
  %178 = bitcast float* %177 to i32*
  store i32 %176, i32* %178, align 4, !tbaa !5431
  %179 = add nsw i64 %24, 17
  %180 = extractelement <8 x i32> %171, i32 1
  %181 = sext i32 %180 to i64
  %182 = getelementptr inbounds float, float* %7, i64 %181
  %183 = bitcast float* %182 to i32*
  %184 = load i32, i32* %183, align 4, !tbaa !5428
  %185 = getelementptr inbounds float, float* %4, i64 %179
  %186 = bitcast float* %185 to i32*
  store i32 %184, i32* %186, align 4, !tbaa !5431
  %187 = add nsw i64 %24, 18
  %188 = extractelement <8 x i32> %171, i32 2
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to i32*
  %192 = load i32, i32* %191, align 4, !tbaa !5428
  %193 = getelementptr inbounds float, float* %4, i64 %187
  %194 = bitcast float* %193 to i32*
  store i32 %192, i32* %194, align 4, !tbaa !5431
  %195 = add nsw i64 %24, 19
  %196 = extractelement <8 x i32> %171, i32 3
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds float, float* %7, i64 %197
  %199 = bitcast float* %198 to i32*
  %200 = load i32, i32* %199, align 4, !tbaa !5428
  %201 = getelementptr inbounds float, float* %4, i64 %195
  %202 = bitcast float* %201 to i32*
  store i32 %200, i32* %202, align 4, !tbaa !5431
  %203 = add nsw i64 %24, 20
  %204 = extractelement <8 x i32> %171, i32 4
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = bitcast float* %206 to i32*
  %208 = load i32, i32* %207, align 4, !tbaa !5428
  %209 = getelementptr inbounds float, float* %4, i64 %203
  %210 = bitcast float* %209 to i32*
  store i32 %208, i32* %210, align 4, !tbaa !5431
  %211 = add nsw i64 %24, 21
  %212 = extractelement <8 x i32> %171, i32 5
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %7, i64 %213
  %215 = bitcast float* %214 to i32*
  %216 = load i32, i32* %215, align 4, !tbaa !5428
  %217 = getelementptr inbounds float, float* %4, i64 %211
  %218 = bitcast float* %217 to i32*
  store i32 %216, i32* %218, align 4, !tbaa !5431
  %219 = add nsw i64 %24, 22
  %220 = extractelement <8 x i32> %171, i32 6
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds float, float* %7, i64 %221
  %223 = bitcast float* %222 to i32*
  %224 = load i32, i32* %223, align 4, !tbaa !5428
  %225 = getelementptr inbounds float, float* %4, i64 %219
  %226 = bitcast float* %225 to i32*
  store i32 %224, i32* %226, align 4, !tbaa !5431
  %227 = add nsw i64 %24, 23
  %228 = extractelement <8 x i32> %171, i32 7
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to i32*
  %232 = load i32, i32* %231, align 4, !tbaa !5428
  %233 = getelementptr inbounds float, float* %4, i64 %227
  %234 = bitcast float* %233 to i32*
  store i32 %232, i32* %234, align 4, !tbaa !5431
  %235 = add nsw i64 %24, 24
  %narrow = add nsw i32 %29, 192
  %236 = insertelement <4 x i32> undef, i32 %narrow, i32 0
  %237 = add <4 x i32> %236, %42
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %240 = or <4 x i32> %238, %239
  %241 = extractelement <4 x i32> %240, i32 0
  %242 = sext i32 %241 to i64
  %243 = getelementptr inbounds float, float* %7, i64 %242
  %244 = bitcast float* %243 to i32*
  %245 = load i32, i32* %244, align 4, !tbaa !5428
  %246 = getelementptr inbounds float, float* %4, i64 %235
  %247 = bitcast float* %246 to i32*
  store i32 %245, i32* %247, align 4, !tbaa !5431
  %248 = add nsw i64 %24, 25
  %249 = extractelement <4 x i32> %240, i32 1
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds float, float* %7, i64 %250
  %252 = bitcast float* %251 to i32*
  %253 = load i32, i32* %252, align 4, !tbaa !5428
  %254 = getelementptr inbounds float, float* %4, i64 %248
  %255 = bitcast float* %254 to i32*
  store i32 %253, i32* %255, align 4, !tbaa !5431
  %256 = add nsw i64 %24, 26
  %257 = extractelement <4 x i32> %240, i32 2
  %258 = sext i32 %257 to i64
  %259 = getelementptr inbounds float, float* %7, i64 %258
  %260 = bitcast float* %259 to i32*
  %261 = load i32, i32* %260, align 4, !tbaa !5428
  %262 = getelementptr inbounds float, float* %4, i64 %256
  %263 = bitcast float* %262 to i32*
  store i32 %261, i32* %263, align 4, !tbaa !5431
  %264 = add nsw i64 %24, 27
  %265 = extractelement <4 x i32> %240, i32 3
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds float, float* %7, i64 %266
  %268 = bitcast float* %267 to i32*
  %269 = load i32, i32* %268, align 4, !tbaa !5428
  %270 = getelementptr inbounds float, float* %4, i64 %264
  %271 = bitcast float* %270 to i32*
  store i32 %269, i32* %271, align 4, !tbaa !5431
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %272 = icmp slt i64 %indvars.iv.next, %23
  br i1 %272, label %for_begin1.preheader, label %for_end, !prof !5

for_end:                                          ; preds = %for_begin1.preheader, %entry
  ret i32 0
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.417, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !5434
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !5448
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !5451
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !5453
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.418, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !5457
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.419, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.420, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.421, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.422, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !5459
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !5473
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 2
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.122, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !5475
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 14
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !5478
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 14
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !5480
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 512
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !5484
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 200704, i32 100352, i32 7168, i32 512>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !5496
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.279, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !5500
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 4
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !5514
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 2
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.280, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !5516
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 1
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !5519
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 1
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !5521
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 512
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !5525
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 64
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.227, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !5527
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 65536, i32 32768, i32 32768, i32 32768>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !5539
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 64
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !5543
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([279 x i8], [279 x i8]* @.str.423, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !5545
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 4
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !5559
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !5561
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !5564
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 64
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.229, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !5566
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.230, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !5578
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 4
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !5592
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !5594
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !5597
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 64
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.231, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !5599
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.232, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !5611
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !5625
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 4
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.79, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !5627
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 14
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.378, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !5630
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 14
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.379, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !5632
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 64
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.233, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !5636
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 50176, i32 12544, i32 896, i32 64>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !5648
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.380, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %35, align 8
  %7 = getelementptr inbounds %35, %35* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %35, %35* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %35, %35* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %35, %35* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %35, %35* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %35, %35* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %35* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.424, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.424(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 27
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 28
  %27 = select i1 %26, i32 %25, i32 28
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 28
  %30 = select i1 %29, i32 %28, i32 28
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_begin10.preheader
  %indvars.iv56 = phi i64 [ %34, %for_body.preheader ], [ %indvars.iv.next57, %for_begin10.preheader ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %37 = tail call i8* %36(i32 1, i32 %19, i64 7168, i32 2, i32 32)
  %38 = bitcast i8* %37 to float*
  %39 = trunc i64 %indvars.iv56 to i32
  %40 = srem i32 %39, 7
  %41 = mul nsw i32 %40, 14336
  %42 = sdiv i32 %39, 7
  %43 = shl i32 %42, 16
  %44 = sext i32 %43 to i64
  %45 = sext i32 %41 to i64
  %46 = or i64 %44, 32768
  br label %for_body2

for_end:                                          ; preds = %for_begin10.preheader, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end9.1
  %47 = mul nsw i64 %indvars.iv56, 1792
  %48 = shl nsw i32 %42, 6
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %16, i64 %49
  %51 = bitcast float* %50 to <64 x float>*
  %52 = load <64 x float>, <64 x float>* %51, align 64, !tbaa !5652
  %53 = getelementptr inbounds float, float* %13, i64 %49
  %54 = bitcast float* %53 to <64 x float>*
  %55 = load <64 x float>, <64 x float>* %54, align 64, !tbaa !5655
  %56 = bitcast i8* %37 to <64 x float>*
  %57 = load <64 x float>, <64 x float>* %56, align 64, !tbaa !5658
  %58 = fadd <64 x float> %55, %57
  %59 = fadd <64 x float> %52, %58
  %60 = fcmp ogt <64 x float> %59, zeroinitializer
  %61 = select <64 x i1> %60, <64 x float> %59, <64 x float> zeroinitializer
  %62 = getelementptr inbounds float, float* %10, i64 %47
  %63 = bitcast float* %62 to <64 x float>*
  store <64 x float> %61, <64 x float>* %63, align 64, !tbaa !5661
  %64 = getelementptr inbounds i8, i8* %37, i64 256
  %65 = bitcast i8* %64 to <64 x float>*
  %66 = load <64 x float>, <64 x float>* %65, align 64, !tbaa !5658
  %67 = fadd <64 x float> %55, %66
  %68 = fadd <64 x float> %52, %67
  %69 = fcmp ogt <64 x float> %68, zeroinitializer
  %70 = select <64 x i1> %69, <64 x float> %68, <64 x float> zeroinitializer
  %71 = mul i64 %indvars.iv56, 7696581394432
  %sext = ashr exact i64 %71, 32
  %72 = or i64 %sext, 64
  %73 = getelementptr inbounds float, float* %10, i64 %72
  %74 = bitcast float* %73 to <64 x float>*
  store <64 x float> %70, <64 x float>* %74, align 64, !tbaa !5661
  %75 = getelementptr inbounds i8, i8* %37, i64 3584
  %76 = bitcast i8* %75 to <64 x float>*
  %77 = load <64 x float>, <64 x float>* %76, align 64, !tbaa !5658
  %78 = fadd <64 x float> %55, %77
  %79 = fadd <64 x float> %52, %78
  %80 = fcmp ogt <64 x float> %79, zeroinitializer
  %81 = select <64 x i1> %80, <64 x float> %79, <64 x float> zeroinitializer
  %82 = mul i64 %indvars.iv56, 7696581394432
  %sext71 = add i64 %82, 3848290697216
  %83 = ashr exact i64 %sext71, 32
  %84 = getelementptr inbounds float, float* %10, i64 %83
  %85 = bitcast float* %84 to <64 x float>*
  store <64 x float> %81, <64 x float>* %85, align 64, !tbaa !5661
  %86 = getelementptr inbounds i8, i8* %37, i64 3840
  %87 = bitcast i8* %86 to <64 x float>*
  %88 = load <64 x float>, <64 x float>* %87, align 64, !tbaa !5658
  %89 = fadd <64 x float> %55, %88
  %90 = fadd <64 x float> %52, %89
  %91 = fcmp ogt <64 x float> %90, zeroinitializer
  %92 = select <64 x i1> %91, <64 x float> %90, <64 x float> zeroinitializer
  %93 = mul i64 %indvars.iv56, 7696581394432
  %sext58 = add i64 %93, 4123168604160
  %94 = ashr exact i64 %sext58, 32
  %95 = getelementptr inbounds float, float* %10, i64 %94
  %96 = bitcast float* %95 to <64 x float>*
  store <64 x float> %92, <64 x float>* %96, align 64, !tbaa !5661
  %97 = getelementptr inbounds i8, i8* %37, i64 512
  %98 = bitcast i8* %97 to <64 x float>*
  %99 = load <64 x float>, <64 x float>* %98, align 64, !tbaa !5658
  %100 = fadd <64 x float> %55, %99
  %101 = fadd <64 x float> %52, %100
  %102 = fcmp ogt <64 x float> %101, zeroinitializer
  %103 = select <64 x i1> %102, <64 x float> %101, <64 x float> zeroinitializer
  %104 = mul i64 %indvars.iv56, 7696581394432
  %sext72 = ashr exact i64 %104, 32
  %105 = or i64 %sext72, 128
  %106 = getelementptr inbounds float, float* %10, i64 %105
  %107 = bitcast float* %106 to <64 x float>*
  store <64 x float> %103, <64 x float>* %107, align 64, !tbaa !5661
  %108 = getelementptr inbounds i8, i8* %37, i64 768
  %109 = bitcast i8* %108 to <64 x float>*
  %110 = load <64 x float>, <64 x float>* %109, align 64, !tbaa !5658
  %111 = fadd <64 x float> %55, %110
  %112 = fadd <64 x float> %52, %111
  %113 = fcmp ogt <64 x float> %112, zeroinitializer
  %114 = select <64 x i1> %113, <64 x float> %112, <64 x float> zeroinitializer
  %115 = mul i64 %indvars.iv56, 7696581394432
  %sext59 = ashr exact i64 %115, 32
  %116 = or i64 %sext59, 192
  %117 = getelementptr inbounds float, float* %10, i64 %116
  %118 = bitcast float* %117 to <64 x float>*
  store <64 x float> %114, <64 x float>* %118, align 64, !tbaa !5661
  %119 = getelementptr inbounds i8, i8* %37, i64 4096
  %120 = bitcast i8* %119 to <64 x float>*
  %121 = load <64 x float>, <64 x float>* %120, align 64, !tbaa !5658
  %122 = fadd <64 x float> %55, %121
  %123 = fadd <64 x float> %52, %122
  %124 = fcmp ogt <64 x float> %123, zeroinitializer
  %125 = select <64 x i1> %124, <64 x float> %123, <64 x float> zeroinitializer
  %126 = mul i64 %indvars.iv56, 7696581394432
  %sext73 = add i64 %126, 4398046511104
  %127 = ashr exact i64 %sext73, 32
  %128 = getelementptr inbounds float, float* %10, i64 %127
  %129 = bitcast float* %128 to <64 x float>*
  store <64 x float> %125, <64 x float>* %129, align 64, !tbaa !5661
  %130 = getelementptr inbounds i8, i8* %37, i64 4352
  %131 = bitcast i8* %130 to <64 x float>*
  %132 = load <64 x float>, <64 x float>* %131, align 64, !tbaa !5658
  %133 = fadd <64 x float> %55, %132
  %134 = fadd <64 x float> %52, %133
  %135 = fcmp ogt <64 x float> %134, zeroinitializer
  %136 = select <64 x i1> %135, <64 x float> %134, <64 x float> zeroinitializer
  %137 = mul i64 %indvars.iv56, 7696581394432
  %sext60 = add i64 %137, 4672924418048
  %138 = ashr exact i64 %sext60, 32
  %139 = getelementptr inbounds float, float* %10, i64 %138
  %140 = bitcast float* %139 to <64 x float>*
  store <64 x float> %136, <64 x float>* %140, align 64, !tbaa !5661
  %141 = getelementptr inbounds i8, i8* %37, i64 1024
  %142 = bitcast i8* %141 to <64 x float>*
  %143 = load <64 x float>, <64 x float>* %142, align 64, !tbaa !5658
  %144 = fadd <64 x float> %55, %143
  %145 = fadd <64 x float> %52, %144
  %146 = fcmp ogt <64 x float> %145, zeroinitializer
  %147 = select <64 x i1> %146, <64 x float> %145, <64 x float> zeroinitializer
  %148 = mul i64 %indvars.iv56, 7696581394432
  %sext74 = add i64 %148, 1099511627776
  %149 = ashr exact i64 %sext74, 32
  %150 = getelementptr inbounds float, float* %10, i64 %149
  %151 = bitcast float* %150 to <64 x float>*
  store <64 x float> %147, <64 x float>* %151, align 64, !tbaa !5661
  %152 = getelementptr inbounds i8, i8* %37, i64 1280
  %153 = bitcast i8* %152 to <64 x float>*
  %154 = load <64 x float>, <64 x float>* %153, align 64, !tbaa !5658
  %155 = fadd <64 x float> %55, %154
  %156 = fadd <64 x float> %52, %155
  %157 = fcmp ogt <64 x float> %156, zeroinitializer
  %158 = select <64 x i1> %157, <64 x float> %156, <64 x float> zeroinitializer
  %159 = mul i64 %indvars.iv56, 7696581394432
  %sext61 = add i64 %159, 1374389534720
  %160 = ashr exact i64 %sext61, 32
  %161 = getelementptr inbounds float, float* %10, i64 %160
  %162 = bitcast float* %161 to <64 x float>*
  store <64 x float> %158, <64 x float>* %162, align 64, !tbaa !5661
  %163 = getelementptr inbounds i8, i8* %37, i64 4608
  %164 = bitcast i8* %163 to <64 x float>*
  %165 = load <64 x float>, <64 x float>* %164, align 64, !tbaa !5658
  %166 = fadd <64 x float> %55, %165
  %167 = fadd <64 x float> %52, %166
  %168 = fcmp ogt <64 x float> %167, zeroinitializer
  %169 = select <64 x i1> %168, <64 x float> %167, <64 x float> zeroinitializer
  %170 = mul i64 %indvars.iv56, 7696581394432
  %sext75 = add i64 %170, 4947802324992
  %171 = ashr exact i64 %sext75, 32
  %172 = getelementptr inbounds float, float* %10, i64 %171
  %173 = bitcast float* %172 to <64 x float>*
  store <64 x float> %169, <64 x float>* %173, align 64, !tbaa !5661
  %174 = getelementptr inbounds i8, i8* %37, i64 4864
  %175 = bitcast i8* %174 to <64 x float>*
  %176 = load <64 x float>, <64 x float>* %175, align 64, !tbaa !5658
  %177 = fadd <64 x float> %55, %176
  %178 = fadd <64 x float> %52, %177
  %179 = fcmp ogt <64 x float> %178, zeroinitializer
  %180 = select <64 x i1> %179, <64 x float> %178, <64 x float> zeroinitializer
  %181 = mul i64 %indvars.iv56, 7696581394432
  %sext62 = add i64 %181, 5222680231936
  %182 = ashr exact i64 %sext62, 32
  %183 = getelementptr inbounds float, float* %10, i64 %182
  %184 = bitcast float* %183 to <64 x float>*
  store <64 x float> %180, <64 x float>* %184, align 64, !tbaa !5661
  %185 = getelementptr inbounds i8, i8* %37, i64 1536
  %186 = bitcast i8* %185 to <64 x float>*
  %187 = load <64 x float>, <64 x float>* %186, align 64, !tbaa !5658
  %188 = fadd <64 x float> %55, %187
  %189 = fadd <64 x float> %52, %188
  %190 = fcmp ogt <64 x float> %189, zeroinitializer
  %191 = select <64 x i1> %190, <64 x float> %189, <64 x float> zeroinitializer
  %192 = mul i64 %indvars.iv56, 7696581394432
  %sext76 = add i64 %192, 1649267441664
  %193 = ashr exact i64 %sext76, 32
  %194 = getelementptr inbounds float, float* %10, i64 %193
  %195 = bitcast float* %194 to <64 x float>*
  store <64 x float> %191, <64 x float>* %195, align 64, !tbaa !5661
  %196 = getelementptr inbounds i8, i8* %37, i64 1792
  %197 = bitcast i8* %196 to <64 x float>*
  %198 = load <64 x float>, <64 x float>* %197, align 64, !tbaa !5658
  %199 = fadd <64 x float> %55, %198
  %200 = fadd <64 x float> %52, %199
  %201 = fcmp ogt <64 x float> %200, zeroinitializer
  %202 = select <64 x i1> %201, <64 x float> %200, <64 x float> zeroinitializer
  %203 = mul i64 %indvars.iv56, 7696581394432
  %sext63 = add i64 %203, 1924145348608
  %204 = ashr exact i64 %sext63, 32
  %205 = getelementptr inbounds float, float* %10, i64 %204
  %206 = bitcast float* %205 to <64 x float>*
  store <64 x float> %202, <64 x float>* %206, align 64, !tbaa !5661
  %207 = getelementptr inbounds i8, i8* %37, i64 5120
  %208 = bitcast i8* %207 to <64 x float>*
  %209 = load <64 x float>, <64 x float>* %208, align 64, !tbaa !5658
  %210 = fadd <64 x float> %55, %209
  %211 = fadd <64 x float> %52, %210
  %212 = fcmp ogt <64 x float> %211, zeroinitializer
  %213 = select <64 x i1> %212, <64 x float> %211, <64 x float> zeroinitializer
  %214 = mul i64 %indvars.iv56, 7696581394432
  %sext77 = add i64 %214, 5497558138880
  %215 = ashr exact i64 %sext77, 32
  %216 = getelementptr inbounds float, float* %10, i64 %215
  %217 = bitcast float* %216 to <64 x float>*
  store <64 x float> %213, <64 x float>* %217, align 64, !tbaa !5661
  %218 = getelementptr inbounds i8, i8* %37, i64 5376
  %219 = bitcast i8* %218 to <64 x float>*
  %220 = load <64 x float>, <64 x float>* %219, align 64, !tbaa !5658
  %221 = fadd <64 x float> %55, %220
  %222 = fadd <64 x float> %52, %221
  %223 = fcmp ogt <64 x float> %222, zeroinitializer
  %224 = select <64 x i1> %223, <64 x float> %222, <64 x float> zeroinitializer
  %225 = mul i64 %indvars.iv56, 7696581394432
  %sext64 = add i64 %225, 5772436045824
  %226 = ashr exact i64 %sext64, 32
  %227 = getelementptr inbounds float, float* %10, i64 %226
  %228 = bitcast float* %227 to <64 x float>*
  store <64 x float> %224, <64 x float>* %228, align 64, !tbaa !5661
  %229 = getelementptr inbounds i8, i8* %37, i64 2048
  %230 = bitcast i8* %229 to <64 x float>*
  %231 = load <64 x float>, <64 x float>* %230, align 64, !tbaa !5658
  %232 = fadd <64 x float> %55, %231
  %233 = fadd <64 x float> %52, %232
  %234 = fcmp ogt <64 x float> %233, zeroinitializer
  %235 = select <64 x i1> %234, <64 x float> %233, <64 x float> zeroinitializer
  %236 = mul i64 %indvars.iv56, 7696581394432
  %sext78 = add i64 %236, 2199023255552
  %237 = ashr exact i64 %sext78, 32
  %238 = getelementptr inbounds float, float* %10, i64 %237
  %239 = bitcast float* %238 to <64 x float>*
  store <64 x float> %235, <64 x float>* %239, align 64, !tbaa !5661
  %240 = getelementptr inbounds i8, i8* %37, i64 2304
  %241 = bitcast i8* %240 to <64 x float>*
  %242 = load <64 x float>, <64 x float>* %241, align 64, !tbaa !5658
  %243 = fadd <64 x float> %55, %242
  %244 = fadd <64 x float> %52, %243
  %245 = fcmp ogt <64 x float> %244, zeroinitializer
  %246 = select <64 x i1> %245, <64 x float> %244, <64 x float> zeroinitializer
  %247 = mul i64 %indvars.iv56, 7696581394432
  %sext65 = add i64 %247, 2473901162496
  %248 = ashr exact i64 %sext65, 32
  %249 = getelementptr inbounds float, float* %10, i64 %248
  %250 = bitcast float* %249 to <64 x float>*
  store <64 x float> %246, <64 x float>* %250, align 64, !tbaa !5661
  %251 = getelementptr inbounds i8, i8* %37, i64 5632
  %252 = bitcast i8* %251 to <64 x float>*
  %253 = load <64 x float>, <64 x float>* %252, align 64, !tbaa !5658
  %254 = fadd <64 x float> %55, %253
  %255 = fadd <64 x float> %52, %254
  %256 = fcmp ogt <64 x float> %255, zeroinitializer
  %257 = select <64 x i1> %256, <64 x float> %255, <64 x float> zeroinitializer
  %258 = mul i64 %indvars.iv56, 7696581394432
  %sext79 = add i64 %258, 6047313952768
  %259 = ashr exact i64 %sext79, 32
  %260 = getelementptr inbounds float, float* %10, i64 %259
  %261 = bitcast float* %260 to <64 x float>*
  store <64 x float> %257, <64 x float>* %261, align 64, !tbaa !5661
  %262 = getelementptr inbounds i8, i8* %37, i64 5888
  %263 = bitcast i8* %262 to <64 x float>*
  %264 = load <64 x float>, <64 x float>* %263, align 64, !tbaa !5658
  %265 = fadd <64 x float> %55, %264
  %266 = fadd <64 x float> %52, %265
  %267 = fcmp ogt <64 x float> %266, zeroinitializer
  %268 = select <64 x i1> %267, <64 x float> %266, <64 x float> zeroinitializer
  %269 = mul i64 %indvars.iv56, 7696581394432
  %sext66 = add i64 %269, 6322191859712
  %270 = ashr exact i64 %sext66, 32
  %271 = getelementptr inbounds float, float* %10, i64 %270
  %272 = bitcast float* %271 to <64 x float>*
  store <64 x float> %268, <64 x float>* %272, align 64, !tbaa !5661
  %273 = getelementptr inbounds i8, i8* %37, i64 2560
  %274 = bitcast i8* %273 to <64 x float>*
  %275 = load <64 x float>, <64 x float>* %274, align 64, !tbaa !5658
  %276 = fadd <64 x float> %55, %275
  %277 = fadd <64 x float> %52, %276
  %278 = fcmp ogt <64 x float> %277, zeroinitializer
  %279 = select <64 x i1> %278, <64 x float> %277, <64 x float> zeroinitializer
  %280 = mul i64 %indvars.iv56, 7696581394432
  %sext80 = add i64 %280, 2748779069440
  %281 = ashr exact i64 %sext80, 32
  %282 = getelementptr inbounds float, float* %10, i64 %281
  %283 = bitcast float* %282 to <64 x float>*
  store <64 x float> %279, <64 x float>* %283, align 64, !tbaa !5661
  %284 = getelementptr inbounds i8, i8* %37, i64 2816
  %285 = bitcast i8* %284 to <64 x float>*
  %286 = load <64 x float>, <64 x float>* %285, align 64, !tbaa !5658
  %287 = fadd <64 x float> %55, %286
  %288 = fadd <64 x float> %52, %287
  %289 = fcmp ogt <64 x float> %288, zeroinitializer
  %290 = select <64 x i1> %289, <64 x float> %288, <64 x float> zeroinitializer
  %291 = mul i64 %indvars.iv56, 7696581394432
  %sext67 = add i64 %291, 3023656976384
  %292 = ashr exact i64 %sext67, 32
  %293 = getelementptr inbounds float, float* %10, i64 %292
  %294 = bitcast float* %293 to <64 x float>*
  store <64 x float> %290, <64 x float>* %294, align 64, !tbaa !5661
  %295 = getelementptr inbounds i8, i8* %37, i64 6144
  %296 = bitcast i8* %295 to <64 x float>*
  %297 = load <64 x float>, <64 x float>* %296, align 64, !tbaa !5658
  %298 = fadd <64 x float> %55, %297
  %299 = fadd <64 x float> %52, %298
  %300 = fcmp ogt <64 x float> %299, zeroinitializer
  %301 = select <64 x i1> %300, <64 x float> %299, <64 x float> zeroinitializer
  %302 = mul i64 %indvars.iv56, 7696581394432
  %sext81 = add i64 %302, 6597069766656
  %303 = ashr exact i64 %sext81, 32
  %304 = getelementptr inbounds float, float* %10, i64 %303
  %305 = bitcast float* %304 to <64 x float>*
  store <64 x float> %301, <64 x float>* %305, align 64, !tbaa !5661
  %306 = getelementptr inbounds i8, i8* %37, i64 6400
  %307 = bitcast i8* %306 to <64 x float>*
  %308 = load <64 x float>, <64 x float>* %307, align 64, !tbaa !5658
  %309 = fadd <64 x float> %55, %308
  %310 = fadd <64 x float> %52, %309
  %311 = fcmp ogt <64 x float> %310, zeroinitializer
  %312 = select <64 x i1> %311, <64 x float> %310, <64 x float> zeroinitializer
  %313 = mul i64 %indvars.iv56, 7696581394432
  %sext68 = add i64 %313, 6871947673600
  %314 = ashr exact i64 %sext68, 32
  %315 = getelementptr inbounds float, float* %10, i64 %314
  %316 = bitcast float* %315 to <64 x float>*
  store <64 x float> %312, <64 x float>* %316, align 64, !tbaa !5661
  %317 = getelementptr inbounds i8, i8* %37, i64 3072
  %318 = bitcast i8* %317 to <64 x float>*
  %319 = load <64 x float>, <64 x float>* %318, align 64, !tbaa !5658
  %320 = fadd <64 x float> %55, %319
  %321 = fadd <64 x float> %52, %320
  %322 = fcmp ogt <64 x float> %321, zeroinitializer
  %323 = select <64 x i1> %322, <64 x float> %321, <64 x float> zeroinitializer
  %324 = mul i64 %indvars.iv56, 7696581394432
  %sext82 = add i64 %324, 3298534883328
  %325 = ashr exact i64 %sext82, 32
  %326 = getelementptr inbounds float, float* %10, i64 %325
  %327 = bitcast float* %326 to <64 x float>*
  store <64 x float> %323, <64 x float>* %327, align 64, !tbaa !5661
  %328 = getelementptr inbounds i8, i8* %37, i64 3328
  %329 = bitcast i8* %328 to <64 x float>*
  %330 = load <64 x float>, <64 x float>* %329, align 64, !tbaa !5658
  %331 = fadd <64 x float> %55, %330
  %332 = fadd <64 x float> %52, %331
  %333 = fcmp ogt <64 x float> %332, zeroinitializer
  %334 = select <64 x i1> %333, <64 x float> %332, <64 x float> zeroinitializer
  %335 = mul i64 %indvars.iv56, 7696581394432
  %sext69 = add i64 %335, 3573412790272
  %336 = ashr exact i64 %sext69, 32
  %337 = getelementptr inbounds float, float* %10, i64 %336
  %338 = bitcast float* %337 to <64 x float>*
  store <64 x float> %334, <64 x float>* %338, align 64, !tbaa !5661
  %339 = getelementptr inbounds i8, i8* %37, i64 6656
  %340 = bitcast i8* %339 to <64 x float>*
  %341 = load <64 x float>, <64 x float>* %340, align 64, !tbaa !5658
  %342 = fadd <64 x float> %55, %341
  %343 = fadd <64 x float> %52, %342
  %344 = fcmp ogt <64 x float> %343, zeroinitializer
  %345 = select <64 x i1> %344, <64 x float> %343, <64 x float> zeroinitializer
  %346 = mul i64 %indvars.iv56, 7696581394432
  %sext83 = add i64 %346, 7146825580544
  %347 = ashr exact i64 %sext83, 32
  %348 = getelementptr inbounds float, float* %10, i64 %347
  %349 = bitcast float* %348 to <64 x float>*
  store <64 x float> %345, <64 x float>* %349, align 64, !tbaa !5661
  %350 = getelementptr inbounds i8, i8* %37, i64 6912
  %351 = bitcast i8* %350 to <64 x float>*
  %352 = load <64 x float>, <64 x float>* %351, align 64, !tbaa !5658
  %353 = fadd <64 x float> %55, %352
  %354 = fadd <64 x float> %52, %353
  %355 = fcmp ogt <64 x float> %354, zeroinitializer
  %356 = select <64 x i1> %355, <64 x float> %354, <64 x float> zeroinitializer
  %357 = mul i64 %indvars.iv56, 7696581394432
  %sext70 = add i64 %357, 7421703487488
  %358 = ashr exact i64 %sext70, 32
  %359 = getelementptr inbounds float, float* %10, i64 %358
  %360 = bitcast float* %359 to <64 x float>*
  store <64 x float> %356, <64 x float>* %360, align 64, !tbaa !5661
  %361 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %362 = tail call i32 %361(i32 1, i32 %19, i8* nonnull %37)
  %indvars.iv.next57 = add nsw i64 %indvars.iv56, 1
  %363 = icmp slt i64 %indvars.iv.next57, %35
  br i1 %363, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end9.1, %for_body
  %indvars.iv43 = phi i64 [ 0, %for_body ], [ %indvars.iv.next44, %for_end9.1 ]
  %364 = shl nsw i64 %indvars.iv43, 7
  %365 = getelementptr inbounds float, float* %38, i64 %364
  %366 = bitcast float* %365 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %366, align 64, !tbaa !5658
  %367 = or i64 %364, 64
  %368 = getelementptr inbounds float, float* %38, i64 %367
  %369 = bitcast float* %368 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %369, align 64, !tbaa !5658
  %370 = add nuw nsw i64 %364, 896
  %371 = getelementptr inbounds float, float* %38, i64 %370
  %372 = bitcast float* %371 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %372, align 64, !tbaa !5658
  %373 = add nuw nsw i64 %364, 960
  %374 = getelementptr inbounds float, float* %38, i64 %373
  %375 = bitcast float* %374 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %375, align 64, !tbaa !5658
  %376 = shl i64 %indvars.iv43, 10
  %377 = add nsw i64 %376, %45
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %378 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %410, %for_body8 ]
  %379 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %404, %for_body8 ]
  %380 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %398, %for_body8 ]
  %381 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %392, %for_body8 ]
  %382 = add nsw i64 %377, %indvars.iv
  %383 = getelementptr inbounds float, float* %4, i64 %382
  %384 = load float, float* %383, align 4, !tbaa !5664
  %385 = insertelement <64 x float> undef, float %384, i32 0
  %386 = shufflevector <64 x float> %385, <64 x float> undef, <64 x i32> zeroinitializer
  %387 = shl i64 %indvars.iv, 6
  %388 = add nuw nsw i64 %387, %44
  %389 = getelementptr inbounds float, float* %7, i64 %388
  %390 = bitcast float* %389 to <64 x float>*
  %391 = load <64 x float>, <64 x float>* %390, align 64, !tbaa !5667
  %392 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %386, <64 x float> %391, <64 x float> %381)
  %393 = add nsw i64 %382, 512
  %394 = getelementptr inbounds float, float* %4, i64 %393
  %395 = load float, float* %394, align 4, !tbaa !5664
  %396 = insertelement <64 x float> undef, float %395, i32 0
  %397 = shufflevector <64 x float> %396, <64 x float> undef, <64 x i32> zeroinitializer
  %398 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %397, <64 x float> %391, <64 x float> %380)
  %399 = add nsw i64 %382, 7168
  %400 = getelementptr inbounds float, float* %4, i64 %399
  %401 = load float, float* %400, align 4, !tbaa !5664
  %402 = insertelement <64 x float> undef, float %401, i32 0
  %403 = shufflevector <64 x float> %402, <64 x float> undef, <64 x i32> zeroinitializer
  %404 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %403, <64 x float> %391, <64 x float> %379)
  %405 = add nsw i64 %382, 7680
  %406 = getelementptr inbounds float, float* %4, i64 %405
  %407 = load float, float* %406, align 4, !tbaa !5664
  %408 = insertelement <64 x float> undef, float %407, i32 0
  %409 = shufflevector <64 x float> %408, <64 x float> undef, <64 x i32> zeroinitializer
  %410 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %409, <64 x float> %391, <64 x float> %378)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %411 = add nsw i64 %377, 100352
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %412 = phi <64 x float> [ %410, %for_end9 ], [ %444, %for_body8.1 ]
  %413 = phi <64 x float> [ %404, %for_end9 ], [ %438, %for_body8.1 ]
  %414 = phi <64 x float> [ %398, %for_end9 ], [ %432, %for_body8.1 ]
  %415 = phi <64 x float> [ %392, %for_end9 ], [ %426, %for_body8.1 ]
  %416 = add nsw i64 %411, %indvars.iv.1
  %417 = getelementptr inbounds float, float* %4, i64 %416
  %418 = load float, float* %417, align 4, !tbaa !5664
  %419 = insertelement <64 x float> undef, float %418, i32 0
  %420 = shufflevector <64 x float> %419, <64 x float> undef, <64 x i32> zeroinitializer
  %421 = shl i64 %indvars.iv.1, 6
  %422 = add nuw nsw i64 %46, %421
  %423 = getelementptr inbounds float, float* %7, i64 %422
  %424 = bitcast float* %423 to <64 x float>*
  %425 = load <64 x float>, <64 x float>* %424, align 64, !tbaa !5667
  %426 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %420, <64 x float> %425, <64 x float> %415)
  %427 = add nsw i64 %416, 512
  %428 = getelementptr inbounds float, float* %4, i64 %427
  %429 = load float, float* %428, align 4, !tbaa !5664
  %430 = insertelement <64 x float> undef, float %429, i32 0
  %431 = shufflevector <64 x float> %430, <64 x float> undef, <64 x i32> zeroinitializer
  %432 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %431, <64 x float> %425, <64 x float> %414)
  %433 = add nsw i64 %416, 7168
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = load float, float* %434, align 4, !tbaa !5664
  %436 = insertelement <64 x float> undef, float %435, i32 0
  %437 = shufflevector <64 x float> %436, <64 x float> undef, <64 x i32> zeroinitializer
  %438 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %437, <64 x float> %425, <64 x float> %413)
  %439 = add nsw i64 %416, 7680
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = load float, float* %440, align 4, !tbaa !5664
  %442 = insertelement <64 x float> undef, float %441, i32 0
  %443 = shufflevector <64 x float> %442, <64 x float> undef, <64 x i32> zeroinitializer
  %444 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %443, <64 x float> %425, <64 x float> %412)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  store <64 x float> %426, <64 x float>* %366, align 64, !tbaa !5658
  store <64 x float> %432, <64 x float>* %369, align 64, !tbaa !5658
  store <64 x float> %438, <64 x float>* %372, align 64, !tbaa !5658
  store <64 x float> %444, <64 x float>* %375, align 64, !tbaa !5658
  %indvars.iv.next44 = add nuw nsw i64 %indvars.iv43, 1
  %exitcond45 = icmp eq i64 %indvars.iv.next44, 7
  br i1 %exitcond45, label %for_begin10.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.425, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !5670
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !5684
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !5687
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !5689
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.426, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !5693
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.427, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.428, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.429, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.430, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !5695
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !5709
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 2
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.122, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !5711
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 14
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !5714
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 14
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !5716
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 128
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.431, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !5720
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 50176, i32 25088, i32 1792, i32 128>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !5732
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.432, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !5736
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 16
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !5750
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 2
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.280, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !5752
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 3
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.133, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !5755
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 3
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.134, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !5757
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 128
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.270, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !5761
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 16
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !5763
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 36864, i32 18432, i32 6144, i32 2048>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !5775
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 16
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !5779
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([277 x i8], [277 x i8]* @.str.433, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !5781
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 16
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !5795
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !5797
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !5800
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 16
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !5802
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 16, i32 16, i32 16, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !5814
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 16
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.250, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !5828
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !5830
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !5833
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 16
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !5835
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 16, i32 16, i32 16, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !5847
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !5861
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 16
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.251, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !5863
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 14
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.378, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !5866
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 14
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.379, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !5868
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 16
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.82, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !5872
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 50176, i32 3136, i32 224, i32 16>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !5884
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.434, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 262144, i32 2, i32 32)
  %8 = alloca %36, align 8
  %9 = getelementptr inbounds %36, %36* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %36, %36* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %36* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.435, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %23, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %37, align 8
  %16 = getelementptr inbounds %37, %37* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %37, %37* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %37, %37* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %37, %37* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %37, %37* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = bitcast %37* %15 to i8*
  %22 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %23 = call i32 %22(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.436, i8* nonnull %21, i32 0)
  %24 = icmp eq i32 %23, 0
  br i1 %24, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %25 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %26 = call i32 %25(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.435(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 31
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 32
  %15 = select i1 %14, i32 %13, i32 32
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 32
  %18 = select i1 %17, i32 %16, i32 32
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = mul i32 %11, %0
  %21 = icmp slt i32 %20, 32
  %22 = select i1 %21, i32 %20, i32 32
  %smax = shl i32 %22, 11
  %23 = xor i32 %smax, -2048
  %24 = sub i32 -2048, %23
  %25 = zext i32 %24 to i64
  %26 = mul i32 %11, %0
  %27 = icmp slt i32 %26, 32
  %28 = select i1 %27, i32 %26, i32 32
  %smax58 = shl i32 %28, 11
  %29 = xor i32 %smax58, -2048
  %30 = sub i32 -2048, %29
  %31 = zext i32 %30 to i64
  %32 = mul i32 %11, %0
  %33 = icmp slt i32 %32, 32
  %34 = select i1 %33, i32 %32, i32 32
  %smax76 = shl i32 %34, 11
  %35 = xor i32 %smax76, -2048
  %36 = sub i32 -2048, %35
  %37 = zext i32 %36 to i64
  %38 = mul i32 %11, %0
  %39 = icmp slt i32 %38, 32
  %40 = select i1 %39, i32 %38, i32 32
  %smax94 = shl i32 %40, 11
  %41 = xor i32 %smax94, -2048
  %42 = sub i32 -2048, %41
  %43 = zext i32 %42 to i64
  %44 = mul i32 %11, %0
  %45 = icmp slt i32 %44, 32
  %46 = select i1 %45, i32 %44, i32 32
  %smax112 = shl i32 %46, 11
  %47 = xor i32 %smax112, -2048
  %48 = sub i32 -2048, %47
  %49 = zext i32 %48 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvar = phi i64 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %50 = phi i32 [ %18, %for_begin1.preheader.preheader ], [ %758, %for_end3 ]
  %51 = shl i64 %indvar, 11
  %52 = add i64 %51, %49
  %53 = shl i64 %indvar, 11
  %54 = add i64 %53, %43
  %55 = shl i64 %indvar, 11
  %56 = add i64 %55, %37
  %57 = shl i64 %indvar, 11
  %58 = add i64 %57, %31
  %59 = shl i64 %indvar, 11
  %60 = add i64 %59, %25
  %61 = shl i32 %50, 11
  %62 = and i32 %50, 15
  %63 = mul nuw nsw i32 %62, 1792
  %64 = ashr i32 %50, 4
  %65 = mul nsw i32 %64, 25088
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv39 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next40, %for_end6 ]
  %66 = shl i64 %indvars.iv39, 7
  %67 = add i64 %52, %66
  %68 = trunc i64 %67 to i32
  %69 = shl i64 %indvars.iv39, 7
  %70 = add i64 %54, %69
  %71 = trunc i64 %70 to i32
  %72 = shl i64 %indvars.iv39, 7
  %73 = add i64 %56, %72
  %74 = trunc i64 %73 to i32
  %75 = shl i64 %indvars.iv39, 7
  %76 = add i64 %58, %75
  %77 = trunc i64 %76 to i32
  %78 = shl i64 %indvars.iv39, 7
  %79 = add i64 %60, %78
  %80 = trunc i64 %79 to i32
  %81 = shl nsw i64 %indvars.iv39, 7
  %82 = trunc i64 %indvars.iv39 to i32
  %83 = add i32 %82, -1
  %84 = icmp ult i32 %83, 14
  br i1 %84, label %for_begin4.preheader.split.us, label %for_begin4.preheader.split

for_begin4.preheader.split.us:                    ; preds = %for_begin4.preheader
  switch i32 %62, label %for_body5.us [
    i32 15, label %vector.scevcheck
    i32 0, label %vector.scevcheck62
  ]

vector.scevcheck62:                               ; preds = %for_begin4.preheader.split.us
  %85 = icmp sgt i32 %77, 2147483520
  br i1 %85, label %for_body5.us.us15, label %vector.body54

vector.body54:                                    ; preds = %vector.scevcheck62
  %86 = trunc i64 %81 to i32
  %87 = add i32 %61, %86
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = bitcast float* %89 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %90, align 4, !tbaa !5888
  %91 = getelementptr inbounds float, float* %89, i64 4
  %92 = bitcast float* %91 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %92, align 4, !tbaa !5888
  %93 = trunc i64 %81 to i32
  %94 = or i32 %93, 8
  %95 = add i32 %61, %94
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %4, i64 %96
  %98 = bitcast float* %97 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %98, align 4, !tbaa !5888
  %99 = getelementptr inbounds float, float* %97, i64 4
  %100 = bitcast float* %99 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %100, align 4, !tbaa !5888
  %101 = trunc i64 %81 to i32
  %102 = or i32 %101, 16
  %103 = add i32 %61, %102
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = bitcast float* %105 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %106, align 4, !tbaa !5888
  %107 = getelementptr inbounds float, float* %105, i64 4
  %108 = bitcast float* %107 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %108, align 4, !tbaa !5888
  %109 = trunc i64 %81 to i32
  %110 = or i32 %109, 24
  %111 = add i32 %61, %110
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds float, float* %4, i64 %112
  %114 = bitcast float* %113 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %114, align 4, !tbaa !5888
  %115 = getelementptr inbounds float, float* %113, i64 4
  %116 = bitcast float* %115 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %116, align 4, !tbaa !5888
  %117 = trunc i64 %81 to i32
  %118 = or i32 %117, 32
  %119 = add i32 %61, %118
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds float, float* %4, i64 %120
  %122 = bitcast float* %121 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %122, align 4, !tbaa !5888
  %123 = getelementptr inbounds float, float* %121, i64 4
  %124 = bitcast float* %123 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %124, align 4, !tbaa !5888
  %125 = trunc i64 %81 to i32
  %126 = or i32 %125, 40
  %127 = add i32 %61, %126
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = bitcast float* %129 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %130, align 4, !tbaa !5888
  %131 = getelementptr inbounds float, float* %129, i64 4
  %132 = bitcast float* %131 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %132, align 4, !tbaa !5888
  %133 = trunc i64 %81 to i32
  %134 = or i32 %133, 48
  %135 = add i32 %61, %134
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %4, i64 %136
  %138 = bitcast float* %137 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %138, align 4, !tbaa !5888
  %139 = getelementptr inbounds float, float* %137, i64 4
  %140 = bitcast float* %139 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %140, align 4, !tbaa !5888
  %141 = trunc i64 %81 to i32
  %142 = or i32 %141, 56
  %143 = add i32 %61, %142
  %144 = sext i32 %143 to i64
  %145 = getelementptr inbounds float, float* %4, i64 %144
  %146 = bitcast float* %145 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %146, align 4, !tbaa !5888
  %147 = getelementptr inbounds float, float* %145, i64 4
  %148 = bitcast float* %147 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %148, align 4, !tbaa !5888
  %149 = trunc i64 %81 to i32
  %150 = or i32 %149, 64
  %151 = add i32 %61, %150
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds float, float* %4, i64 %152
  %154 = bitcast float* %153 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %154, align 4, !tbaa !5888
  %155 = getelementptr inbounds float, float* %153, i64 4
  %156 = bitcast float* %155 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %156, align 4, !tbaa !5888
  %157 = trunc i64 %81 to i32
  %158 = or i32 %157, 72
  %159 = add i32 %61, %158
  %160 = sext i32 %159 to i64
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = bitcast float* %161 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %162, align 4, !tbaa !5888
  %163 = getelementptr inbounds float, float* %161, i64 4
  %164 = bitcast float* %163 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %164, align 4, !tbaa !5888
  %165 = trunc i64 %81 to i32
  %166 = or i32 %165, 80
  %167 = add i32 %61, %166
  %168 = sext i32 %167 to i64
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = bitcast float* %169 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %170, align 4, !tbaa !5888
  %171 = getelementptr inbounds float, float* %169, i64 4
  %172 = bitcast float* %171 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %172, align 4, !tbaa !5888
  %173 = trunc i64 %81 to i32
  %174 = or i32 %173, 88
  %175 = add i32 %61, %174
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds float, float* %4, i64 %176
  %178 = bitcast float* %177 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %178, align 4, !tbaa !5888
  %179 = getelementptr inbounds float, float* %177, i64 4
  %180 = bitcast float* %179 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %180, align 4, !tbaa !5888
  %181 = trunc i64 %81 to i32
  %182 = or i32 %181, 96
  %183 = add i32 %61, %182
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds float, float* %4, i64 %184
  %186 = bitcast float* %185 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %186, align 4, !tbaa !5888
  %187 = getelementptr inbounds float, float* %185, i64 4
  %188 = bitcast float* %187 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %188, align 4, !tbaa !5888
  %189 = trunc i64 %81 to i32
  %190 = or i32 %189, 104
  %191 = add i32 %61, %190
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds float, float* %4, i64 %192
  %194 = bitcast float* %193 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %194, align 4, !tbaa !5888
  %195 = getelementptr inbounds float, float* %193, i64 4
  %196 = bitcast float* %195 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %196, align 4, !tbaa !5888
  %197 = trunc i64 %81 to i32
  %198 = or i32 %197, 112
  %199 = add i32 %61, %198
  %200 = sext i32 %199 to i64
  %201 = getelementptr inbounds float, float* %4, i64 %200
  %202 = bitcast float* %201 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %202, align 4, !tbaa !5888
  %203 = getelementptr inbounds float, float* %201, i64 4
  %204 = bitcast float* %203 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %204, align 4, !tbaa !5888
  %205 = trunc i64 %81 to i32
  %206 = or i32 %205, 120
  %207 = add i32 %61, %206
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = bitcast float* %209 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %210, align 4, !tbaa !5888
  %211 = getelementptr inbounds float, float* %209, i64 4
  %212 = bitcast float* %211 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %212, align 4, !tbaa !5888
  br label %for_end6

vector.scevcheck:                                 ; preds = %for_begin4.preheader.split.us
  %213 = icmp sgt i32 %80, 2147483520
  br i1 %213, label %for_body5.us.us, label %vector.body

vector.body:                                      ; preds = %vector.scevcheck
  %214 = trunc i64 %81 to i32
  %215 = add i32 %61, %214
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds float, float* %4, i64 %216
  %218 = bitcast float* %217 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %218, align 4, !tbaa !5888
  %219 = getelementptr inbounds float, float* %217, i64 4
  %220 = bitcast float* %219 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %220, align 4, !tbaa !5888
  %221 = trunc i64 %81 to i32
  %222 = or i32 %221, 8
  %223 = add i32 %61, %222
  %224 = sext i32 %223 to i64
  %225 = getelementptr inbounds float, float* %4, i64 %224
  %226 = bitcast float* %225 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %226, align 4, !tbaa !5888
  %227 = getelementptr inbounds float, float* %225, i64 4
  %228 = bitcast float* %227 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %228, align 4, !tbaa !5888
  %229 = trunc i64 %81 to i32
  %230 = or i32 %229, 16
  %231 = add i32 %61, %230
  %232 = sext i32 %231 to i64
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = bitcast float* %233 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %234, align 4, !tbaa !5888
  %235 = getelementptr inbounds float, float* %233, i64 4
  %236 = bitcast float* %235 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %236, align 4, !tbaa !5888
  %237 = trunc i64 %81 to i32
  %238 = or i32 %237, 24
  %239 = add i32 %61, %238
  %240 = sext i32 %239 to i64
  %241 = getelementptr inbounds float, float* %4, i64 %240
  %242 = bitcast float* %241 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %242, align 4, !tbaa !5888
  %243 = getelementptr inbounds float, float* %241, i64 4
  %244 = bitcast float* %243 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %244, align 4, !tbaa !5888
  %245 = trunc i64 %81 to i32
  %246 = or i32 %245, 32
  %247 = add i32 %61, %246
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds float, float* %4, i64 %248
  %250 = bitcast float* %249 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %250, align 4, !tbaa !5888
  %251 = getelementptr inbounds float, float* %249, i64 4
  %252 = bitcast float* %251 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %252, align 4, !tbaa !5888
  %253 = trunc i64 %81 to i32
  %254 = or i32 %253, 40
  %255 = add i32 %61, %254
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds float, float* %4, i64 %256
  %258 = bitcast float* %257 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %258, align 4, !tbaa !5888
  %259 = getelementptr inbounds float, float* %257, i64 4
  %260 = bitcast float* %259 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %260, align 4, !tbaa !5888
  %261 = trunc i64 %81 to i32
  %262 = or i32 %261, 48
  %263 = add i32 %61, %262
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds float, float* %4, i64 %264
  %266 = bitcast float* %265 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %266, align 4, !tbaa !5888
  %267 = getelementptr inbounds float, float* %265, i64 4
  %268 = bitcast float* %267 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %268, align 4, !tbaa !5888
  %269 = trunc i64 %81 to i32
  %270 = or i32 %269, 56
  %271 = add i32 %61, %270
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds float, float* %4, i64 %272
  %274 = bitcast float* %273 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %274, align 4, !tbaa !5888
  %275 = getelementptr inbounds float, float* %273, i64 4
  %276 = bitcast float* %275 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %276, align 4, !tbaa !5888
  %277 = trunc i64 %81 to i32
  %278 = or i32 %277, 64
  %279 = add i32 %61, %278
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = bitcast float* %281 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %282, align 4, !tbaa !5888
  %283 = getelementptr inbounds float, float* %281, i64 4
  %284 = bitcast float* %283 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %284, align 4, !tbaa !5888
  %285 = trunc i64 %81 to i32
  %286 = or i32 %285, 72
  %287 = add i32 %61, %286
  %288 = sext i32 %287 to i64
  %289 = getelementptr inbounds float, float* %4, i64 %288
  %290 = bitcast float* %289 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %290, align 4, !tbaa !5888
  %291 = getelementptr inbounds float, float* %289, i64 4
  %292 = bitcast float* %291 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %292, align 4, !tbaa !5888
  %293 = trunc i64 %81 to i32
  %294 = or i32 %293, 80
  %295 = add i32 %61, %294
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds float, float* %4, i64 %296
  %298 = bitcast float* %297 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %298, align 4, !tbaa !5888
  %299 = getelementptr inbounds float, float* %297, i64 4
  %300 = bitcast float* %299 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %300, align 4, !tbaa !5888
  %301 = trunc i64 %81 to i32
  %302 = or i32 %301, 88
  %303 = add i32 %61, %302
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds float, float* %4, i64 %304
  %306 = bitcast float* %305 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %306, align 4, !tbaa !5888
  %307 = getelementptr inbounds float, float* %305, i64 4
  %308 = bitcast float* %307 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %308, align 4, !tbaa !5888
  %309 = trunc i64 %81 to i32
  %310 = or i32 %309, 96
  %311 = add i32 %61, %310
  %312 = sext i32 %311 to i64
  %313 = getelementptr inbounds float, float* %4, i64 %312
  %314 = bitcast float* %313 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %314, align 4, !tbaa !5888
  %315 = getelementptr inbounds float, float* %313, i64 4
  %316 = bitcast float* %315 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %316, align 4, !tbaa !5888
  %317 = trunc i64 %81 to i32
  %318 = or i32 %317, 104
  %319 = add i32 %61, %318
  %320 = sext i32 %319 to i64
  %321 = getelementptr inbounds float, float* %4, i64 %320
  %322 = bitcast float* %321 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %322, align 4, !tbaa !5888
  %323 = getelementptr inbounds float, float* %321, i64 4
  %324 = bitcast float* %323 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %324, align 4, !tbaa !5888
  %325 = trunc i64 %81 to i32
  %326 = or i32 %325, 112
  %327 = add i32 %61, %326
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds float, float* %4, i64 %328
  %330 = bitcast float* %329 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %330, align 4, !tbaa !5888
  %331 = getelementptr inbounds float, float* %329, i64 4
  %332 = bitcast float* %331 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %332, align 4, !tbaa !5888
  %333 = trunc i64 %81 to i32
  %334 = or i32 %333, 120
  %335 = add i32 %61, %334
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds float, float* %4, i64 %336
  %338 = bitcast float* %337 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %338, align 4, !tbaa !5888
  %339 = getelementptr inbounds float, float* %337, i64 4
  %340 = bitcast float* %339 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %340, align 4, !tbaa !5888
  br label %for_end6

for_body5.us.us:                                  ; preds = %vector.scevcheck, %for_body5.us.us
  %indvars.iv33 = phi i64 [ %indvars.iv.next34, %for_body5.us.us ], [ 0, %vector.scevcheck ]
  %341 = add nuw nsw i64 %indvars.iv33, %81
  %342 = trunc i64 %341 to i32
  %343 = add i32 %61, %342
  %344 = sext i32 %343 to i64
  %345 = getelementptr inbounds float, float* %4, i64 %344
  store float 0.000000e+00, float* %345, align 4, !tbaa !5888
  %indvars.iv.next34 = add nuw nsw i64 %indvars.iv33, 1
  %exitcond35 = icmp eq i64 %indvars.iv.next34, 128
  br i1 %exitcond35, label %for_end6, label %for_body5.us.us, !prof !50, !llvm.loop !5891

for_body5.us.us15:                                ; preds = %vector.scevcheck62, %for_body5.us.us15
  %indvars.iv30 = phi i64 [ %indvars.iv.next31, %for_body5.us.us15 ], [ 0, %vector.scevcheck62 ]
  %346 = add nuw nsw i64 %indvars.iv30, %81
  %347 = trunc i64 %346 to i32
  %348 = add i32 %61, %347
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds float, float* %4, i64 %349
  store float 0.000000e+00, float* %350, align 4, !tbaa !5888
  %indvars.iv.next31 = add nuw nsw i64 %indvars.iv30, 1
  %exitcond32 = icmp eq i64 %indvars.iv.next31, 128
  br i1 %exitcond32, label %for_end6, label %for_body5.us.us15, !prof !50, !llvm.loop !5892

for_body5.us:                                     ; preds = %for_begin4.preheader.split.us, %if_end.us
  %indvars.iv36 = phi i64 [ %indvars.iv.next37, %if_end.us ], [ 0, %for_begin4.preheader.split.us ]
  %351 = add nuw nsw i64 %indvars.iv36, %81
  %352 = trunc i64 %351 to i32
  %353 = add i32 %61, %352
  switch i32 %62, label %if_then.us [
    i32 15, label %if_end.us
    i32 0, label %if_end.us
  ]

if_then.us:                                       ; preds = %for_body5.us
  %354 = trunc i64 %351 to i32
  %355 = add i32 %354, -1920
  %356 = add i32 %63, %355
  %357 = add i32 %356, %65
  %358 = sext i32 %357 to i64
  %359 = getelementptr inbounds float, float* %7, i64 %358
  %360 = load float, float* %359, align 4, !tbaa !5893
  br label %if_end.us

if_end.us:                                        ; preds = %if_then.us, %for_body5.us, %for_body5.us
  %361 = phi float [ %360, %if_then.us ], [ 0.000000e+00, %for_body5.us ], [ 0.000000e+00, %for_body5.us ]
  %362 = sext i32 %353 to i64
  %363 = getelementptr inbounds float, float* %4, i64 %362
  store float %361, float* %363, align 4, !tbaa !5888
  %indvars.iv.next37 = add nuw nsw i64 %indvars.iv36, 1
  %exitcond38 = icmp eq i64 %indvars.iv.next37, 128
  br i1 %exitcond38, label %for_end6, label %for_body5.us, !prof !50

for_begin4.preheader.split:                       ; preds = %for_begin4.preheader
  switch i32 %62, label %vector.scevcheck80 [
    i32 15, label %vector.scevcheck98
    i32 0, label %vector.scevcheck116
  ]

vector.scevcheck116:                              ; preds = %for_begin4.preheader.split
  %364 = icmp sgt i32 %68, 2147483520
  br i1 %364, label %for_body5.us11, label %vector.body108

vector.body108:                                   ; preds = %vector.scevcheck116
  %365 = trunc i64 %81 to i32
  %366 = add i32 %61, %365
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds float, float* %4, i64 %367
  %369 = bitcast float* %368 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %369, align 4, !tbaa !5888
  %370 = getelementptr inbounds float, float* %368, i64 4
  %371 = bitcast float* %370 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %371, align 4, !tbaa !5888
  %372 = trunc i64 %81 to i32
  %373 = or i32 %372, 8
  %374 = add i32 %61, %373
  %375 = sext i32 %374 to i64
  %376 = getelementptr inbounds float, float* %4, i64 %375
  %377 = bitcast float* %376 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %377, align 4, !tbaa !5888
  %378 = getelementptr inbounds float, float* %376, i64 4
  %379 = bitcast float* %378 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %379, align 4, !tbaa !5888
  %380 = trunc i64 %81 to i32
  %381 = or i32 %380, 16
  %382 = add i32 %61, %381
  %383 = sext i32 %382 to i64
  %384 = getelementptr inbounds float, float* %4, i64 %383
  %385 = bitcast float* %384 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %385, align 4, !tbaa !5888
  %386 = getelementptr inbounds float, float* %384, i64 4
  %387 = bitcast float* %386 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %387, align 4, !tbaa !5888
  %388 = trunc i64 %81 to i32
  %389 = or i32 %388, 24
  %390 = add i32 %61, %389
  %391 = sext i32 %390 to i64
  %392 = getelementptr inbounds float, float* %4, i64 %391
  %393 = bitcast float* %392 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %393, align 4, !tbaa !5888
  %394 = getelementptr inbounds float, float* %392, i64 4
  %395 = bitcast float* %394 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %395, align 4, !tbaa !5888
  %396 = trunc i64 %81 to i32
  %397 = or i32 %396, 32
  %398 = add i32 %61, %397
  %399 = sext i32 %398 to i64
  %400 = getelementptr inbounds float, float* %4, i64 %399
  %401 = bitcast float* %400 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %401, align 4, !tbaa !5888
  %402 = getelementptr inbounds float, float* %400, i64 4
  %403 = bitcast float* %402 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %403, align 4, !tbaa !5888
  %404 = trunc i64 %81 to i32
  %405 = or i32 %404, 40
  %406 = add i32 %61, %405
  %407 = sext i32 %406 to i64
  %408 = getelementptr inbounds float, float* %4, i64 %407
  %409 = bitcast float* %408 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %409, align 4, !tbaa !5888
  %410 = getelementptr inbounds float, float* %408, i64 4
  %411 = bitcast float* %410 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %411, align 4, !tbaa !5888
  %412 = trunc i64 %81 to i32
  %413 = or i32 %412, 48
  %414 = add i32 %61, %413
  %415 = sext i32 %414 to i64
  %416 = getelementptr inbounds float, float* %4, i64 %415
  %417 = bitcast float* %416 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %417, align 4, !tbaa !5888
  %418 = getelementptr inbounds float, float* %416, i64 4
  %419 = bitcast float* %418 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %419, align 4, !tbaa !5888
  %420 = trunc i64 %81 to i32
  %421 = or i32 %420, 56
  %422 = add i32 %61, %421
  %423 = sext i32 %422 to i64
  %424 = getelementptr inbounds float, float* %4, i64 %423
  %425 = bitcast float* %424 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %425, align 4, !tbaa !5888
  %426 = getelementptr inbounds float, float* %424, i64 4
  %427 = bitcast float* %426 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %427, align 4, !tbaa !5888
  %428 = trunc i64 %81 to i32
  %429 = or i32 %428, 64
  %430 = add i32 %61, %429
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds float, float* %4, i64 %431
  %433 = bitcast float* %432 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %433, align 4, !tbaa !5888
  %434 = getelementptr inbounds float, float* %432, i64 4
  %435 = bitcast float* %434 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %435, align 4, !tbaa !5888
  %436 = trunc i64 %81 to i32
  %437 = or i32 %436, 72
  %438 = add i32 %61, %437
  %439 = sext i32 %438 to i64
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = bitcast float* %440 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %441, align 4, !tbaa !5888
  %442 = getelementptr inbounds float, float* %440, i64 4
  %443 = bitcast float* %442 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %443, align 4, !tbaa !5888
  %444 = trunc i64 %81 to i32
  %445 = or i32 %444, 80
  %446 = add i32 %61, %445
  %447 = sext i32 %446 to i64
  %448 = getelementptr inbounds float, float* %4, i64 %447
  %449 = bitcast float* %448 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %449, align 4, !tbaa !5888
  %450 = getelementptr inbounds float, float* %448, i64 4
  %451 = bitcast float* %450 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %451, align 4, !tbaa !5888
  %452 = trunc i64 %81 to i32
  %453 = or i32 %452, 88
  %454 = add i32 %61, %453
  %455 = sext i32 %454 to i64
  %456 = getelementptr inbounds float, float* %4, i64 %455
  %457 = bitcast float* %456 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %457, align 4, !tbaa !5888
  %458 = getelementptr inbounds float, float* %456, i64 4
  %459 = bitcast float* %458 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %459, align 4, !tbaa !5888
  %460 = trunc i64 %81 to i32
  %461 = or i32 %460, 96
  %462 = add i32 %61, %461
  %463 = sext i32 %462 to i64
  %464 = getelementptr inbounds float, float* %4, i64 %463
  %465 = bitcast float* %464 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %465, align 4, !tbaa !5888
  %466 = getelementptr inbounds float, float* %464, i64 4
  %467 = bitcast float* %466 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %467, align 4, !tbaa !5888
  %468 = trunc i64 %81 to i32
  %469 = or i32 %468, 104
  %470 = add i32 %61, %469
  %471 = sext i32 %470 to i64
  %472 = getelementptr inbounds float, float* %4, i64 %471
  %473 = bitcast float* %472 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %473, align 4, !tbaa !5888
  %474 = getelementptr inbounds float, float* %472, i64 4
  %475 = bitcast float* %474 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %475, align 4, !tbaa !5888
  %476 = trunc i64 %81 to i32
  %477 = or i32 %476, 112
  %478 = add i32 %61, %477
  %479 = sext i32 %478 to i64
  %480 = getelementptr inbounds float, float* %4, i64 %479
  %481 = bitcast float* %480 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %481, align 4, !tbaa !5888
  %482 = getelementptr inbounds float, float* %480, i64 4
  %483 = bitcast float* %482 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %483, align 4, !tbaa !5888
  %484 = trunc i64 %81 to i32
  %485 = or i32 %484, 120
  %486 = add i32 %61, %485
  %487 = sext i32 %486 to i64
  %488 = getelementptr inbounds float, float* %4, i64 %487
  %489 = bitcast float* %488 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %489, align 4, !tbaa !5888
  %490 = getelementptr inbounds float, float* %488, i64 4
  %491 = bitcast float* %490 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %491, align 4, !tbaa !5888
  br label %for_end6

vector.scevcheck98:                               ; preds = %for_begin4.preheader.split
  %492 = icmp sgt i32 %71, 2147483520
  br i1 %492, label %for_body5.us7, label %vector.body90

vector.body90:                                    ; preds = %vector.scevcheck98
  %493 = trunc i64 %81 to i32
  %494 = add i32 %61, %493
  %495 = sext i32 %494 to i64
  %496 = getelementptr inbounds float, float* %4, i64 %495
  %497 = bitcast float* %496 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %497, align 4, !tbaa !5888
  %498 = getelementptr inbounds float, float* %496, i64 4
  %499 = bitcast float* %498 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %499, align 4, !tbaa !5888
  %500 = trunc i64 %81 to i32
  %501 = or i32 %500, 8
  %502 = add i32 %61, %501
  %503 = sext i32 %502 to i64
  %504 = getelementptr inbounds float, float* %4, i64 %503
  %505 = bitcast float* %504 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %505, align 4, !tbaa !5888
  %506 = getelementptr inbounds float, float* %504, i64 4
  %507 = bitcast float* %506 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %507, align 4, !tbaa !5888
  %508 = trunc i64 %81 to i32
  %509 = or i32 %508, 16
  %510 = add i32 %61, %509
  %511 = sext i32 %510 to i64
  %512 = getelementptr inbounds float, float* %4, i64 %511
  %513 = bitcast float* %512 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %513, align 4, !tbaa !5888
  %514 = getelementptr inbounds float, float* %512, i64 4
  %515 = bitcast float* %514 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %515, align 4, !tbaa !5888
  %516 = trunc i64 %81 to i32
  %517 = or i32 %516, 24
  %518 = add i32 %61, %517
  %519 = sext i32 %518 to i64
  %520 = getelementptr inbounds float, float* %4, i64 %519
  %521 = bitcast float* %520 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %521, align 4, !tbaa !5888
  %522 = getelementptr inbounds float, float* %520, i64 4
  %523 = bitcast float* %522 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %523, align 4, !tbaa !5888
  %524 = trunc i64 %81 to i32
  %525 = or i32 %524, 32
  %526 = add i32 %61, %525
  %527 = sext i32 %526 to i64
  %528 = getelementptr inbounds float, float* %4, i64 %527
  %529 = bitcast float* %528 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %529, align 4, !tbaa !5888
  %530 = getelementptr inbounds float, float* %528, i64 4
  %531 = bitcast float* %530 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %531, align 4, !tbaa !5888
  %532 = trunc i64 %81 to i32
  %533 = or i32 %532, 40
  %534 = add i32 %61, %533
  %535 = sext i32 %534 to i64
  %536 = getelementptr inbounds float, float* %4, i64 %535
  %537 = bitcast float* %536 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %537, align 4, !tbaa !5888
  %538 = getelementptr inbounds float, float* %536, i64 4
  %539 = bitcast float* %538 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %539, align 4, !tbaa !5888
  %540 = trunc i64 %81 to i32
  %541 = or i32 %540, 48
  %542 = add i32 %61, %541
  %543 = sext i32 %542 to i64
  %544 = getelementptr inbounds float, float* %4, i64 %543
  %545 = bitcast float* %544 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %545, align 4, !tbaa !5888
  %546 = getelementptr inbounds float, float* %544, i64 4
  %547 = bitcast float* %546 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %547, align 4, !tbaa !5888
  %548 = trunc i64 %81 to i32
  %549 = or i32 %548, 56
  %550 = add i32 %61, %549
  %551 = sext i32 %550 to i64
  %552 = getelementptr inbounds float, float* %4, i64 %551
  %553 = bitcast float* %552 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %553, align 4, !tbaa !5888
  %554 = getelementptr inbounds float, float* %552, i64 4
  %555 = bitcast float* %554 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %555, align 4, !tbaa !5888
  %556 = trunc i64 %81 to i32
  %557 = or i32 %556, 64
  %558 = add i32 %61, %557
  %559 = sext i32 %558 to i64
  %560 = getelementptr inbounds float, float* %4, i64 %559
  %561 = bitcast float* %560 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %561, align 4, !tbaa !5888
  %562 = getelementptr inbounds float, float* %560, i64 4
  %563 = bitcast float* %562 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %563, align 4, !tbaa !5888
  %564 = trunc i64 %81 to i32
  %565 = or i32 %564, 72
  %566 = add i32 %61, %565
  %567 = sext i32 %566 to i64
  %568 = getelementptr inbounds float, float* %4, i64 %567
  %569 = bitcast float* %568 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %569, align 4, !tbaa !5888
  %570 = getelementptr inbounds float, float* %568, i64 4
  %571 = bitcast float* %570 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %571, align 4, !tbaa !5888
  %572 = trunc i64 %81 to i32
  %573 = or i32 %572, 80
  %574 = add i32 %61, %573
  %575 = sext i32 %574 to i64
  %576 = getelementptr inbounds float, float* %4, i64 %575
  %577 = bitcast float* %576 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %577, align 4, !tbaa !5888
  %578 = getelementptr inbounds float, float* %576, i64 4
  %579 = bitcast float* %578 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %579, align 4, !tbaa !5888
  %580 = trunc i64 %81 to i32
  %581 = or i32 %580, 88
  %582 = add i32 %61, %581
  %583 = sext i32 %582 to i64
  %584 = getelementptr inbounds float, float* %4, i64 %583
  %585 = bitcast float* %584 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %585, align 4, !tbaa !5888
  %586 = getelementptr inbounds float, float* %584, i64 4
  %587 = bitcast float* %586 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %587, align 4, !tbaa !5888
  %588 = trunc i64 %81 to i32
  %589 = or i32 %588, 96
  %590 = add i32 %61, %589
  %591 = sext i32 %590 to i64
  %592 = getelementptr inbounds float, float* %4, i64 %591
  %593 = bitcast float* %592 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %593, align 4, !tbaa !5888
  %594 = getelementptr inbounds float, float* %592, i64 4
  %595 = bitcast float* %594 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %595, align 4, !tbaa !5888
  %596 = trunc i64 %81 to i32
  %597 = or i32 %596, 104
  %598 = add i32 %61, %597
  %599 = sext i32 %598 to i64
  %600 = getelementptr inbounds float, float* %4, i64 %599
  %601 = bitcast float* %600 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %601, align 4, !tbaa !5888
  %602 = getelementptr inbounds float, float* %600, i64 4
  %603 = bitcast float* %602 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %603, align 4, !tbaa !5888
  %604 = trunc i64 %81 to i32
  %605 = or i32 %604, 112
  %606 = add i32 %61, %605
  %607 = sext i32 %606 to i64
  %608 = getelementptr inbounds float, float* %4, i64 %607
  %609 = bitcast float* %608 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %609, align 4, !tbaa !5888
  %610 = getelementptr inbounds float, float* %608, i64 4
  %611 = bitcast float* %610 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %611, align 4, !tbaa !5888
  %612 = trunc i64 %81 to i32
  %613 = or i32 %612, 120
  %614 = add i32 %61, %613
  %615 = sext i32 %614 to i64
  %616 = getelementptr inbounds float, float* %4, i64 %615
  %617 = bitcast float* %616 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %617, align 4, !tbaa !5888
  %618 = getelementptr inbounds float, float* %616, i64 4
  %619 = bitcast float* %618 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %619, align 4, !tbaa !5888
  br label %for_end6

vector.scevcheck80:                               ; preds = %for_begin4.preheader.split
  %620 = icmp sgt i32 %74, 2147483520
  br i1 %620, label %for_body5, label %vector.body72

vector.body72:                                    ; preds = %vector.scevcheck80
  %621 = trunc i64 %81 to i32
  %622 = add i32 %61, %621
  %623 = sext i32 %622 to i64
  %624 = getelementptr inbounds float, float* %4, i64 %623
  %625 = bitcast float* %624 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %625, align 4, !tbaa !5888
  %626 = getelementptr inbounds float, float* %624, i64 4
  %627 = bitcast float* %626 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %627, align 4, !tbaa !5888
  %628 = trunc i64 %81 to i32
  %629 = or i32 %628, 8
  %630 = add i32 %61, %629
  %631 = sext i32 %630 to i64
  %632 = getelementptr inbounds float, float* %4, i64 %631
  %633 = bitcast float* %632 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %633, align 4, !tbaa !5888
  %634 = getelementptr inbounds float, float* %632, i64 4
  %635 = bitcast float* %634 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %635, align 4, !tbaa !5888
  %636 = trunc i64 %81 to i32
  %637 = or i32 %636, 16
  %638 = add i32 %61, %637
  %639 = sext i32 %638 to i64
  %640 = getelementptr inbounds float, float* %4, i64 %639
  %641 = bitcast float* %640 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %641, align 4, !tbaa !5888
  %642 = getelementptr inbounds float, float* %640, i64 4
  %643 = bitcast float* %642 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %643, align 4, !tbaa !5888
  %644 = trunc i64 %81 to i32
  %645 = or i32 %644, 24
  %646 = add i32 %61, %645
  %647 = sext i32 %646 to i64
  %648 = getelementptr inbounds float, float* %4, i64 %647
  %649 = bitcast float* %648 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %649, align 4, !tbaa !5888
  %650 = getelementptr inbounds float, float* %648, i64 4
  %651 = bitcast float* %650 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %651, align 4, !tbaa !5888
  %652 = trunc i64 %81 to i32
  %653 = or i32 %652, 32
  %654 = add i32 %61, %653
  %655 = sext i32 %654 to i64
  %656 = getelementptr inbounds float, float* %4, i64 %655
  %657 = bitcast float* %656 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %657, align 4, !tbaa !5888
  %658 = getelementptr inbounds float, float* %656, i64 4
  %659 = bitcast float* %658 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %659, align 4, !tbaa !5888
  %660 = trunc i64 %81 to i32
  %661 = or i32 %660, 40
  %662 = add i32 %61, %661
  %663 = sext i32 %662 to i64
  %664 = getelementptr inbounds float, float* %4, i64 %663
  %665 = bitcast float* %664 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %665, align 4, !tbaa !5888
  %666 = getelementptr inbounds float, float* %664, i64 4
  %667 = bitcast float* %666 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %667, align 4, !tbaa !5888
  %668 = trunc i64 %81 to i32
  %669 = or i32 %668, 48
  %670 = add i32 %61, %669
  %671 = sext i32 %670 to i64
  %672 = getelementptr inbounds float, float* %4, i64 %671
  %673 = bitcast float* %672 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %673, align 4, !tbaa !5888
  %674 = getelementptr inbounds float, float* %672, i64 4
  %675 = bitcast float* %674 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %675, align 4, !tbaa !5888
  %676 = trunc i64 %81 to i32
  %677 = or i32 %676, 56
  %678 = add i32 %61, %677
  %679 = sext i32 %678 to i64
  %680 = getelementptr inbounds float, float* %4, i64 %679
  %681 = bitcast float* %680 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %681, align 4, !tbaa !5888
  %682 = getelementptr inbounds float, float* %680, i64 4
  %683 = bitcast float* %682 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %683, align 4, !tbaa !5888
  %684 = trunc i64 %81 to i32
  %685 = or i32 %684, 64
  %686 = add i32 %61, %685
  %687 = sext i32 %686 to i64
  %688 = getelementptr inbounds float, float* %4, i64 %687
  %689 = bitcast float* %688 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %689, align 4, !tbaa !5888
  %690 = getelementptr inbounds float, float* %688, i64 4
  %691 = bitcast float* %690 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %691, align 4, !tbaa !5888
  %692 = trunc i64 %81 to i32
  %693 = or i32 %692, 72
  %694 = add i32 %61, %693
  %695 = sext i32 %694 to i64
  %696 = getelementptr inbounds float, float* %4, i64 %695
  %697 = bitcast float* %696 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %697, align 4, !tbaa !5888
  %698 = getelementptr inbounds float, float* %696, i64 4
  %699 = bitcast float* %698 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %699, align 4, !tbaa !5888
  %700 = trunc i64 %81 to i32
  %701 = or i32 %700, 80
  %702 = add i32 %61, %701
  %703 = sext i32 %702 to i64
  %704 = getelementptr inbounds float, float* %4, i64 %703
  %705 = bitcast float* %704 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %705, align 4, !tbaa !5888
  %706 = getelementptr inbounds float, float* %704, i64 4
  %707 = bitcast float* %706 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %707, align 4, !tbaa !5888
  %708 = trunc i64 %81 to i32
  %709 = or i32 %708, 88
  %710 = add i32 %61, %709
  %711 = sext i32 %710 to i64
  %712 = getelementptr inbounds float, float* %4, i64 %711
  %713 = bitcast float* %712 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %713, align 4, !tbaa !5888
  %714 = getelementptr inbounds float, float* %712, i64 4
  %715 = bitcast float* %714 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %715, align 4, !tbaa !5888
  %716 = trunc i64 %81 to i32
  %717 = or i32 %716, 96
  %718 = add i32 %61, %717
  %719 = sext i32 %718 to i64
  %720 = getelementptr inbounds float, float* %4, i64 %719
  %721 = bitcast float* %720 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %721, align 4, !tbaa !5888
  %722 = getelementptr inbounds float, float* %720, i64 4
  %723 = bitcast float* %722 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %723, align 4, !tbaa !5888
  %724 = trunc i64 %81 to i32
  %725 = or i32 %724, 104
  %726 = add i32 %61, %725
  %727 = sext i32 %726 to i64
  %728 = getelementptr inbounds float, float* %4, i64 %727
  %729 = bitcast float* %728 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %729, align 4, !tbaa !5888
  %730 = getelementptr inbounds float, float* %728, i64 4
  %731 = bitcast float* %730 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %731, align 4, !tbaa !5888
  %732 = trunc i64 %81 to i32
  %733 = or i32 %732, 112
  %734 = add i32 %61, %733
  %735 = sext i32 %734 to i64
  %736 = getelementptr inbounds float, float* %4, i64 %735
  %737 = bitcast float* %736 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %737, align 4, !tbaa !5888
  %738 = getelementptr inbounds float, float* %736, i64 4
  %739 = bitcast float* %738 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %739, align 4, !tbaa !5888
  %740 = trunc i64 %81 to i32
  %741 = or i32 %740, 120
  %742 = add i32 %61, %741
  %743 = sext i32 %742 to i64
  %744 = getelementptr inbounds float, float* %4, i64 %743
  %745 = bitcast float* %744 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %745, align 4, !tbaa !5888
  %746 = getelementptr inbounds float, float* %744, i64 4
  %747 = bitcast float* %746 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %747, align 4, !tbaa !5888
  br label %for_end6

for_body5.us7:                                    ; preds = %vector.scevcheck98, %for_body5.us7
  %indvars.iv24 = phi i64 [ %indvars.iv.next25, %for_body5.us7 ], [ 0, %vector.scevcheck98 ]
  %748 = add nuw nsw i64 %indvars.iv24, %81
  %749 = trunc i64 %748 to i32
  %750 = add i32 %61, %749
  %751 = sext i32 %750 to i64
  %752 = getelementptr inbounds float, float* %4, i64 %751
  store float 0.000000e+00, float* %752, align 4, !tbaa !5888
  %indvars.iv.next25 = add nuw nsw i64 %indvars.iv24, 1
  %exitcond26 = icmp eq i64 %indvars.iv.next25, 128
  br i1 %exitcond26, label %for_end6, label %for_body5.us7, !prof !50, !llvm.loop !5896

for_body5.us11:                                   ; preds = %vector.scevcheck116, %for_body5.us11
  %indvars.iv = phi i64 [ %indvars.iv.next, %for_body5.us11 ], [ 0, %vector.scevcheck116 ]
  %753 = add nuw nsw i64 %indvars.iv, %81
  %754 = trunc i64 %753 to i32
  %755 = add i32 %61, %754
  %756 = sext i32 %755 to i64
  %757 = getelementptr inbounds float, float* %4, i64 %756
  store float 0.000000e+00, float* %757, align 4, !tbaa !5888
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5.us11, !prof !50, !llvm.loop !5897

for_end3:                                         ; preds = %for_end6
  %758 = add nsw i32 %50, 1
  %759 = icmp slt i32 %758, %15
  %indvar.next = add i64 %indvar, 1
  br i1 %759, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %vector.scevcheck80, %for_body5
  %indvars.iv27 = phi i64 [ %indvars.iv.next28, %for_body5 ], [ 0, %vector.scevcheck80 ]
  %760 = add nuw nsw i64 %indvars.iv27, %81
  %761 = trunc i64 %760 to i32
  %762 = add i32 %61, %761
  %763 = sext i32 %762 to i64
  %764 = getelementptr inbounds float, float* %4, i64 %763
  store float 0.000000e+00, float* %764, align 4, !tbaa !5888
  %indvars.iv.next28 = add nuw nsw i64 %indvars.iv27, 1
  %exitcond29 = icmp eq i64 %indvars.iv.next28, 128
  br i1 %exitcond29, label %for_end6, label %for_body5, !prof !50, !llvm.loop !5898

for_end6:                                         ; preds = %for_body5.us11, %for_body5.us7, %for_body5, %for_body5.us.us15, %for_body5.us.us, %if_end.us, %vector.body108, %vector.body90, %vector.body72, %vector.body54, %vector.body
  %indvars.iv.next40 = add nuw nsw i64 %indvars.iv39, 1
  %exitcond42 = icmp eq i64 %indvars.iv.next40, 16
  br i1 %exitcond42, label %for_end3, label %for_begin4.preheader, !prof !50
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.436(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = alloca [14 x <16 x float>], align 64
  %.sub = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0
  %4 = bitcast i8* %2 to float**
  %5 = load float*, float** %4, align 8
  %6 = getelementptr inbounds i8, i8* %2, i64 8
  %7 = bitcast i8* %6 to float**
  %8 = load float*, float** %7, align 8
  %9 = getelementptr inbounds i8, i8* %2, i64 16
  %10 = bitcast i8* %9 to float**
  %11 = load float*, float** %10, align 8
  %12 = getelementptr inbounds i8, i8* %2, i64 24
  %13 = bitcast i8* %12 to float**
  %14 = load float*, float** %13, align 8
  %15 = getelementptr inbounds i8, i8* %2, i64 32
  %16 = bitcast i8* %15 to float**
  %17 = load float*, float** %16, align 8
  %18 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %19 = load i32, i32* %18, align 4
  %20 = add nsw i32 %19, 223
  %21 = sdiv i32 %20, %19
  %22 = add nsw i32 %0, 1
  %23 = mul nsw i32 %21, %22
  %24 = icmp slt i32 %23, 224
  %25 = select i1 %24, i32 %23, i32 224
  %26 = mul nsw i32 %21, %0
  %27 = icmp slt i32 %26, 224
  %28 = select i1 %27, i32 %26, i32 224
  %29 = icmp slt i32 %28, %25
  br i1 %29, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %30 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 16
  %31 = bitcast float* %30 to <16 x float>*
  %32 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 32
  %33 = bitcast float* %32 to <16 x float>*
  %34 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 48
  %35 = bitcast float* %34 to <16 x float>*
  %36 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 64
  %37 = bitcast float* %36 to <16 x float>*
  %38 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 80
  %39 = bitcast float* %38 to <16 x float>*
  %40 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 96
  %41 = bitcast float* %40 to <16 x float>*
  %42 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 112
  %43 = bitcast float* %42 to <16 x float>*
  %44 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 128
  %45 = bitcast float* %44 to <16 x float>*
  %46 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 144
  %47 = bitcast float* %46 to <16 x float>*
  %48 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 160
  %49 = bitcast float* %48 to <16 x float>*
  %50 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 176
  %51 = bitcast float* %50 to <16 x float>*
  %52 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 192
  %53 = bitcast float* %52 to <16 x float>*
  %54 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 208
  %55 = bitcast float* %54 to <16 x float>*
  %56 = add i32 %28, 1
  %57 = sext i32 %56 to i64
  %58 = add nsw i64 %57, -1
  %59 = sext i32 %25 to i64
  %60 = bitcast [14 x <16 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv117 = phi i64 [ %58, %for_body.lr.ph ], [ %indvars.iv.next118, %for_end6.1 ]
  %61 = trunc i64 %indvars.iv117 to i32
  %62 = srem i32 %61, 14
  %63 = sdiv i32 %61, 14
  %64 = mul nsw i32 %63, 36864
  %65 = sext i32 %64 to i64
  call void @llvm.memset.p0i8.i64(i8* nonnull align 64 %60, i8 0, i64 896, i1 false)
  br label %for_begin7.preheader

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_begin7.preheader:                             ; preds = %for_end9, %for_body
  %indvars.iv106 = phi i64 [ 0, %for_body ], [ %indvars.iv.next107, %for_end9 ]
  %.lcssa3966 = phi <16 x float> [ zeroinitializer, %for_body ], [ %219, %for_end9 ]
  %.lcssa3764 = phi <16 x float> [ zeroinitializer, %for_body ], [ %213, %for_end9 ]
  %.lcssa3562 = phi <16 x float> [ zeroinitializer, %for_body ], [ %212, %for_end9 ]
  %.lcssa3360 = phi <16 x float> [ zeroinitializer, %for_body ], [ %211, %for_end9 ]
  %.lcssa3158 = phi <16 x float> [ zeroinitializer, %for_body ], [ %210, %for_end9 ]
  %.lcssa2956 = phi <16 x float> [ zeroinitializer, %for_body ], [ %209, %for_end9 ]
  %.lcssa2754 = phi <16 x float> [ zeroinitializer, %for_body ], [ %208, %for_end9 ]
  %.lcssa2552 = phi <16 x float> [ zeroinitializer, %for_body ], [ %207, %for_end9 ]
  %.lcssa2350 = phi <16 x float> [ zeroinitializer, %for_body ], [ %206, %for_end9 ]
  %.lcssa2148 = phi <16 x float> [ zeroinitializer, %for_body ], [ %205, %for_end9 ]
  %.lcssa1946 = phi <16 x float> [ zeroinitializer, %for_body ], [ %204, %for_end9 ]
  %.lcssa1744 = phi <16 x float> [ zeroinitializer, %for_body ], [ %203, %for_end9 ]
  %.lcssa1543 = phi <16 x float> [ zeroinitializer, %for_body ], [ %202, %for_end9 ]
  %.lcssa41 = phi <16 x float> [ zeroinitializer, %for_body ], [ %201, %for_end9 ]
  %66 = phi i32 [ 0, %for_body ], [ %220, %for_end9 ]
  %reass.add = add nsw i32 %66, %62
  %reass.mul = shl i32 %reass.add, 11
  %67 = mul nuw nsw i64 %indvars.iv106, 6144
  %68 = add nsw i64 %67, %65
  %69 = sext i32 %reass.mul to i64
  br label %for_body8

for_end6:                                         ; preds = %for_end9
  %70 = add nsw i64 %65, 18432
  br label %for_begin7.preheader.1

for_body8:                                        ; preds = %for_body8, %for_begin7.preheader
  %indvars.iv = phi i64 [ 0, %for_begin7.preheader ], [ %indvars.iv.next, %for_body8 ]
  %71 = phi <16 x float> [ %.lcssa3966, %for_begin7.preheader ], [ %219, %for_body8 ]
  %72 = phi <16 x float> [ %.lcssa3764, %for_begin7.preheader ], [ %213, %for_body8 ]
  %73 = phi <16 x float> [ %.lcssa3562, %for_begin7.preheader ], [ %212, %for_body8 ]
  %74 = phi <16 x float> [ %.lcssa3360, %for_begin7.preheader ], [ %211, %for_body8 ]
  %75 = phi <16 x float> [ %.lcssa3158, %for_begin7.preheader ], [ %210, %for_body8 ]
  %76 = phi <16 x float> [ %.lcssa2956, %for_begin7.preheader ], [ %209, %for_body8 ]
  %77 = phi <16 x float> [ %.lcssa2754, %for_begin7.preheader ], [ %208, %for_body8 ]
  %78 = phi <16 x float> [ %.lcssa2552, %for_begin7.preheader ], [ %207, %for_body8 ]
  %79 = phi <16 x float> [ %.lcssa2350, %for_begin7.preheader ], [ %206, %for_body8 ]
  %80 = phi <16 x float> [ %.lcssa2148, %for_begin7.preheader ], [ %205, %for_body8 ]
  %81 = phi <16 x float> [ %.lcssa1946, %for_begin7.preheader ], [ %204, %for_body8 ]
  %82 = phi <16 x float> [ %.lcssa1744, %for_begin7.preheader ], [ %203, %for_body8 ]
  %83 = phi <16 x float> [ %.lcssa1543, %for_begin7.preheader ], [ %202, %for_body8 ]
  %84 = phi <16 x float> [ %.lcssa41, %for_begin7.preheader ], [ %201, %for_body8 ]
  %85 = add nsw i64 %indvars.iv, %69
  %86 = getelementptr inbounds float, float* %5, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !5888
  %88 = insertelement <16 x float> undef, float %87, i32 0
  %89 = shufflevector <16 x float> %88, <16 x float> undef, <16 x i32> zeroinitializer
  %90 = shl nsw i64 %indvars.iv, 4
  %91 = add nsw i64 %68, %90
  %92 = getelementptr inbounds float, float* %8, i64 %91
  %93 = bitcast float* %92 to <16 x float>*
  %94 = load <16 x float>, <16 x float>* %93, align 64, !tbaa !5899
  %95 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %89, <16 x float> %94, <16 x float> %84)
  %96 = add nsw i64 %85, 128
  %97 = getelementptr inbounds float, float* %5, i64 %96
  %98 = load float, float* %97, align 4, !tbaa !5888
  %99 = insertelement <16 x float> undef, float %98, i32 0
  %100 = shufflevector <16 x float> %99, <16 x float> undef, <16 x i32> zeroinitializer
  %101 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %100, <16 x float> %94, <16 x float> %83)
  %102 = add nsw i64 %85, 256
  %103 = getelementptr inbounds float, float* %5, i64 %102
  %104 = load float, float* %103, align 4, !tbaa !5888
  %105 = insertelement <16 x float> undef, float %104, i32 0
  %106 = shufflevector <16 x float> %105, <16 x float> undef, <16 x i32> zeroinitializer
  %107 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %106, <16 x float> %94, <16 x float> %82)
  %108 = add nsw i64 %85, 384
  %109 = getelementptr inbounds float, float* %5, i64 %108
  %110 = load float, float* %109, align 4, !tbaa !5888
  %111 = insertelement <16 x float> undef, float %110, i32 0
  %112 = shufflevector <16 x float> %111, <16 x float> undef, <16 x i32> zeroinitializer
  %113 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %112, <16 x float> %94, <16 x float> %81)
  %114 = add nsw i64 %85, 512
  %115 = getelementptr inbounds float, float* %5, i64 %114
  %116 = load float, float* %115, align 4, !tbaa !5888
  %117 = insertelement <16 x float> undef, float %116, i32 0
  %118 = shufflevector <16 x float> %117, <16 x float> undef, <16 x i32> zeroinitializer
  %119 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %118, <16 x float> %94, <16 x float> %80)
  %120 = add nsw i64 %85, 640
  %121 = getelementptr inbounds float, float* %5, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !5888
  %123 = insertelement <16 x float> undef, float %122, i32 0
  %124 = shufflevector <16 x float> %123, <16 x float> undef, <16 x i32> zeroinitializer
  %125 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %124, <16 x float> %94, <16 x float> %79)
  %126 = add nsw i64 %85, 768
  %127 = getelementptr inbounds float, float* %5, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !5888
  %129 = insertelement <16 x float> undef, float %128, i32 0
  %130 = shufflevector <16 x float> %129, <16 x float> undef, <16 x i32> zeroinitializer
  %131 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %130, <16 x float> %94, <16 x float> %78)
  %132 = add nsw i64 %85, 896
  %133 = getelementptr inbounds float, float* %5, i64 %132
  %134 = load float, float* %133, align 4, !tbaa !5888
  %135 = insertelement <16 x float> undef, float %134, i32 0
  %136 = shufflevector <16 x float> %135, <16 x float> undef, <16 x i32> zeroinitializer
  %137 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %136, <16 x float> %94, <16 x float> %77)
  %138 = add nsw i64 %85, 1024
  %139 = getelementptr inbounds float, float* %5, i64 %138
  %140 = load float, float* %139, align 4, !tbaa !5888
  %141 = insertelement <16 x float> undef, float %140, i32 0
  %142 = shufflevector <16 x float> %141, <16 x float> undef, <16 x i32> zeroinitializer
  %143 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %142, <16 x float> %94, <16 x float> %76)
  %144 = add nsw i64 %85, 1152
  %145 = getelementptr inbounds float, float* %5, i64 %144
  %146 = load float, float* %145, align 4, !tbaa !5888
  %147 = insertelement <16 x float> undef, float %146, i32 0
  %148 = shufflevector <16 x float> %147, <16 x float> undef, <16 x i32> zeroinitializer
  %149 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %148, <16 x float> %94, <16 x float> %75)
  %150 = add nsw i64 %85, 1280
  %151 = getelementptr inbounds float, float* %5, i64 %150
  %152 = load float, float* %151, align 4, !tbaa !5888
  %153 = insertelement <16 x float> undef, float %152, i32 0
  %154 = shufflevector <16 x float> %153, <16 x float> undef, <16 x i32> zeroinitializer
  %155 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %154, <16 x float> %94, <16 x float> %74)
  %156 = add nsw i64 %85, 1408
  %157 = getelementptr inbounds float, float* %5, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !5888
  %159 = insertelement <16 x float> undef, float %158, i32 0
  %160 = shufflevector <16 x float> %159, <16 x float> undef, <16 x i32> zeroinitializer
  %161 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %160, <16 x float> %94, <16 x float> %73)
  %162 = add nsw i64 %85, 1536
  %163 = getelementptr inbounds float, float* %5, i64 %162
  %164 = load float, float* %163, align 4, !tbaa !5888
  %165 = insertelement <16 x float> undef, float %164, i32 0
  %166 = shufflevector <16 x float> %165, <16 x float> undef, <16 x i32> zeroinitializer
  %167 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %166, <16 x float> %94, <16 x float> %72)
  %168 = add nsw i64 %85, 1664
  %169 = getelementptr inbounds float, float* %5, i64 %168
  %170 = load float, float* %169, align 4, !tbaa !5888
  %171 = insertelement <16 x float> undef, float %170, i32 0
  %172 = shufflevector <16 x float> %171, <16 x float> undef, <16 x i32> zeroinitializer
  %173 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %172, <16 x float> %94, <16 x float> %71)
  %174 = add nsw i64 %91, 2048
  %175 = getelementptr inbounds float, float* %8, i64 %174
  %176 = bitcast float* %175 to <16 x float>*
  %177 = load <16 x float>, <16 x float>* %176, align 64, !tbaa !5899
  %178 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %100, <16 x float> %177, <16 x float> %95)
  %179 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %106, <16 x float> %177, <16 x float> %101)
  %180 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %112, <16 x float> %177, <16 x float> %107)
  %181 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %118, <16 x float> %177, <16 x float> %113)
  %182 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %124, <16 x float> %177, <16 x float> %119)
  %183 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %130, <16 x float> %177, <16 x float> %125)
  %184 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %136, <16 x float> %177, <16 x float> %131)
  %185 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %142, <16 x float> %177, <16 x float> %137)
  %186 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %148, <16 x float> %177, <16 x float> %143)
  %187 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %154, <16 x float> %177, <16 x float> %149)
  %188 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %160, <16 x float> %177, <16 x float> %155)
  %189 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %166, <16 x float> %177, <16 x float> %161)
  %190 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %172, <16 x float> %177, <16 x float> %167)
  %191 = add nsw i64 %85, 1792
  %192 = getelementptr inbounds float, float* %5, i64 %191
  %193 = load float, float* %192, align 4, !tbaa !5888
  %194 = insertelement <16 x float> undef, float %193, i32 0
  %195 = shufflevector <16 x float> %194, <16 x float> undef, <16 x i32> zeroinitializer
  %196 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %195, <16 x float> %177, <16 x float> %173)
  %197 = add nsw i64 %91, 4096
  %198 = getelementptr inbounds float, float* %8, i64 %197
  %199 = bitcast float* %198 to <16 x float>*
  %200 = load <16 x float>, <16 x float>* %199, align 64, !tbaa !5899
  %201 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %106, <16 x float> %200, <16 x float> %178)
  %202 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %112, <16 x float> %200, <16 x float> %179)
  %203 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %118, <16 x float> %200, <16 x float> %180)
  %204 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %124, <16 x float> %200, <16 x float> %181)
  %205 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %130, <16 x float> %200, <16 x float> %182)
  %206 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %136, <16 x float> %200, <16 x float> %183)
  %207 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %142, <16 x float> %200, <16 x float> %184)
  %208 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %148, <16 x float> %200, <16 x float> %185)
  %209 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %154, <16 x float> %200, <16 x float> %186)
  %210 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %160, <16 x float> %200, <16 x float> %187)
  %211 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %166, <16 x float> %200, <16 x float> %188)
  %212 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %172, <16 x float> %200, <16 x float> %189)
  %213 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %195, <16 x float> %200, <16 x float> %190)
  %214 = add nsw i64 %85, 1920
  %215 = getelementptr inbounds float, float* %5, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !5888
  %217 = insertelement <16 x float> undef, float %216, i32 0
  %218 = shufflevector <16 x float> %217, <16 x float> undef, <16 x i32> zeroinitializer
  %219 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %218, <16 x float> %200, <16 x float> %196)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %indvars.iv.next107 = add nuw nsw i64 %indvars.iv106, 1
  %220 = add nuw nsw i32 %66, 1
  %exitcond110 = icmp eq i64 %indvars.iv.next107, 3
  br i1 %exitcond110, label %for_end6, label %for_begin7.preheader, !prof !50

for_begin7.preheader.1:                           ; preds = %for_end9.1, %for_end6
  %indvars.iv106.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next107.1, %for_end9.1 ]
  %.lcssa3966.1 = phi <16 x float> [ %219, %for_end6 ], [ %374, %for_end9.1 ]
  %.lcssa3764.1 = phi <16 x float> [ %213, %for_end6 ], [ %368, %for_end9.1 ]
  %.lcssa3562.1 = phi <16 x float> [ %212, %for_end6 ], [ %367, %for_end9.1 ]
  %.lcssa3360.1 = phi <16 x float> [ %211, %for_end6 ], [ %366, %for_end9.1 ]
  %.lcssa3158.1 = phi <16 x float> [ %210, %for_end6 ], [ %365, %for_end9.1 ]
  %.lcssa2956.1 = phi <16 x float> [ %209, %for_end6 ], [ %364, %for_end9.1 ]
  %.lcssa2754.1 = phi <16 x float> [ %208, %for_end6 ], [ %363, %for_end9.1 ]
  %.lcssa2552.1 = phi <16 x float> [ %207, %for_end6 ], [ %362, %for_end9.1 ]
  %.lcssa2350.1 = phi <16 x float> [ %206, %for_end6 ], [ %361, %for_end9.1 ]
  %.lcssa2148.1 = phi <16 x float> [ %205, %for_end6 ], [ %360, %for_end9.1 ]
  %.lcssa1946.1 = phi <16 x float> [ %204, %for_end6 ], [ %359, %for_end9.1 ]
  %.lcssa1744.1 = phi <16 x float> [ %203, %for_end6 ], [ %358, %for_end9.1 ]
  %.lcssa1543.1 = phi <16 x float> [ %202, %for_end6 ], [ %357, %for_end9.1 ]
  %.lcssa41.1 = phi <16 x float> [ %201, %for_end6 ], [ %356, %for_end9.1 ]
  %221 = phi i32 [ 0, %for_end6 ], [ %375, %for_end9.1 ]
  %reass.add.1 = add nsw i32 %221, %62
  %reass.mul.1 = shl i32 %reass.add.1, 11
  %222 = add nsw i32 %reass.mul.1, 32768
  %223 = mul nuw nsw i64 %indvars.iv106.1, 6144
  %224 = add nsw i64 %70, %223
  %225 = sext i32 %222 to i64
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_begin7.preheader.1
  %indvars.iv.1 = phi i64 [ 0, %for_begin7.preheader.1 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %226 = phi <16 x float> [ %.lcssa3966.1, %for_begin7.preheader.1 ], [ %374, %for_body8.1 ]
  %227 = phi <16 x float> [ %.lcssa3764.1, %for_begin7.preheader.1 ], [ %368, %for_body8.1 ]
  %228 = phi <16 x float> [ %.lcssa3562.1, %for_begin7.preheader.1 ], [ %367, %for_body8.1 ]
  %229 = phi <16 x float> [ %.lcssa3360.1, %for_begin7.preheader.1 ], [ %366, %for_body8.1 ]
  %230 = phi <16 x float> [ %.lcssa3158.1, %for_begin7.preheader.1 ], [ %365, %for_body8.1 ]
  %231 = phi <16 x float> [ %.lcssa2956.1, %for_begin7.preheader.1 ], [ %364, %for_body8.1 ]
  %232 = phi <16 x float> [ %.lcssa2754.1, %for_begin7.preheader.1 ], [ %363, %for_body8.1 ]
  %233 = phi <16 x float> [ %.lcssa2552.1, %for_begin7.preheader.1 ], [ %362, %for_body8.1 ]
  %234 = phi <16 x float> [ %.lcssa2350.1, %for_begin7.preheader.1 ], [ %361, %for_body8.1 ]
  %235 = phi <16 x float> [ %.lcssa2148.1, %for_begin7.preheader.1 ], [ %360, %for_body8.1 ]
  %236 = phi <16 x float> [ %.lcssa1946.1, %for_begin7.preheader.1 ], [ %359, %for_body8.1 ]
  %237 = phi <16 x float> [ %.lcssa1744.1, %for_begin7.preheader.1 ], [ %358, %for_body8.1 ]
  %238 = phi <16 x float> [ %.lcssa1543.1, %for_begin7.preheader.1 ], [ %357, %for_body8.1 ]
  %239 = phi <16 x float> [ %.lcssa41.1, %for_begin7.preheader.1 ], [ %356, %for_body8.1 ]
  %240 = add nsw i64 %indvars.iv.1, %225
  %241 = getelementptr inbounds float, float* %5, i64 %240
  %242 = load float, float* %241, align 4, !tbaa !5888
  %243 = insertelement <16 x float> undef, float %242, i32 0
  %244 = shufflevector <16 x float> %243, <16 x float> undef, <16 x i32> zeroinitializer
  %245 = shl nsw i64 %indvars.iv.1, 4
  %246 = add nsw i64 %224, %245
  %247 = getelementptr inbounds float, float* %8, i64 %246
  %248 = bitcast float* %247 to <16 x float>*
  %249 = load <16 x float>, <16 x float>* %248, align 64, !tbaa !5899
  %250 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %244, <16 x float> %249, <16 x float> %239)
  %251 = add nsw i64 %240, 128
  %252 = getelementptr inbounds float, float* %5, i64 %251
  %253 = load float, float* %252, align 4, !tbaa !5888
  %254 = insertelement <16 x float> undef, float %253, i32 0
  %255 = shufflevector <16 x float> %254, <16 x float> undef, <16 x i32> zeroinitializer
  %256 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %255, <16 x float> %249, <16 x float> %238)
  %257 = add nsw i64 %240, 256
  %258 = getelementptr inbounds float, float* %5, i64 %257
  %259 = load float, float* %258, align 4, !tbaa !5888
  %260 = insertelement <16 x float> undef, float %259, i32 0
  %261 = shufflevector <16 x float> %260, <16 x float> undef, <16 x i32> zeroinitializer
  %262 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %261, <16 x float> %249, <16 x float> %237)
  %263 = add nsw i64 %240, 384
  %264 = getelementptr inbounds float, float* %5, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !5888
  %266 = insertelement <16 x float> undef, float %265, i32 0
  %267 = shufflevector <16 x float> %266, <16 x float> undef, <16 x i32> zeroinitializer
  %268 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %267, <16 x float> %249, <16 x float> %236)
  %269 = add nsw i64 %240, 512
  %270 = getelementptr inbounds float, float* %5, i64 %269
  %271 = load float, float* %270, align 4, !tbaa !5888
  %272 = insertelement <16 x float> undef, float %271, i32 0
  %273 = shufflevector <16 x float> %272, <16 x float> undef, <16 x i32> zeroinitializer
  %274 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %273, <16 x float> %249, <16 x float> %235)
  %275 = add nsw i64 %240, 640
  %276 = getelementptr inbounds float, float* %5, i64 %275
  %277 = load float, float* %276, align 4, !tbaa !5888
  %278 = insertelement <16 x float> undef, float %277, i32 0
  %279 = shufflevector <16 x float> %278, <16 x float> undef, <16 x i32> zeroinitializer
  %280 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %279, <16 x float> %249, <16 x float> %234)
  %281 = add nsw i64 %240, 768
  %282 = getelementptr inbounds float, float* %5, i64 %281
  %283 = load float, float* %282, align 4, !tbaa !5888
  %284 = insertelement <16 x float> undef, float %283, i32 0
  %285 = shufflevector <16 x float> %284, <16 x float> undef, <16 x i32> zeroinitializer
  %286 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %285, <16 x float> %249, <16 x float> %233)
  %287 = add nsw i64 %240, 896
  %288 = getelementptr inbounds float, float* %5, i64 %287
  %289 = load float, float* %288, align 4, !tbaa !5888
  %290 = insertelement <16 x float> undef, float %289, i32 0
  %291 = shufflevector <16 x float> %290, <16 x float> undef, <16 x i32> zeroinitializer
  %292 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %291, <16 x float> %249, <16 x float> %232)
  %293 = add nsw i64 %240, 1024
  %294 = getelementptr inbounds float, float* %5, i64 %293
  %295 = load float, float* %294, align 4, !tbaa !5888
  %296 = insertelement <16 x float> undef, float %295, i32 0
  %297 = shufflevector <16 x float> %296, <16 x float> undef, <16 x i32> zeroinitializer
  %298 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %297, <16 x float> %249, <16 x float> %231)
  %299 = add nsw i64 %240, 1152
  %300 = getelementptr inbounds float, float* %5, i64 %299
  %301 = load float, float* %300, align 4, !tbaa !5888
  %302 = insertelement <16 x float> undef, float %301, i32 0
  %303 = shufflevector <16 x float> %302, <16 x float> undef, <16 x i32> zeroinitializer
  %304 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %303, <16 x float> %249, <16 x float> %230)
  %305 = add nsw i64 %240, 1280
  %306 = getelementptr inbounds float, float* %5, i64 %305
  %307 = load float, float* %306, align 4, !tbaa !5888
  %308 = insertelement <16 x float> undef, float %307, i32 0
  %309 = shufflevector <16 x float> %308, <16 x float> undef, <16 x i32> zeroinitializer
  %310 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %309, <16 x float> %249, <16 x float> %229)
  %311 = add nsw i64 %240, 1408
  %312 = getelementptr inbounds float, float* %5, i64 %311
  %313 = load float, float* %312, align 4, !tbaa !5888
  %314 = insertelement <16 x float> undef, float %313, i32 0
  %315 = shufflevector <16 x float> %314, <16 x float> undef, <16 x i32> zeroinitializer
  %316 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %315, <16 x float> %249, <16 x float> %228)
  %317 = add nsw i64 %240, 1536
  %318 = getelementptr inbounds float, float* %5, i64 %317
  %319 = load float, float* %318, align 4, !tbaa !5888
  %320 = insertelement <16 x float> undef, float %319, i32 0
  %321 = shufflevector <16 x float> %320, <16 x float> undef, <16 x i32> zeroinitializer
  %322 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %321, <16 x float> %249, <16 x float> %227)
  %323 = add nsw i64 %240, 1664
  %324 = getelementptr inbounds float, float* %5, i64 %323
  %325 = load float, float* %324, align 4, !tbaa !5888
  %326 = insertelement <16 x float> undef, float %325, i32 0
  %327 = shufflevector <16 x float> %326, <16 x float> undef, <16 x i32> zeroinitializer
  %328 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %327, <16 x float> %249, <16 x float> %226)
  %329 = add nsw i64 %246, 2048
  %330 = getelementptr inbounds float, float* %8, i64 %329
  %331 = bitcast float* %330 to <16 x float>*
  %332 = load <16 x float>, <16 x float>* %331, align 64, !tbaa !5899
  %333 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %255, <16 x float> %332, <16 x float> %250)
  %334 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %261, <16 x float> %332, <16 x float> %256)
  %335 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %267, <16 x float> %332, <16 x float> %262)
  %336 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %273, <16 x float> %332, <16 x float> %268)
  %337 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %279, <16 x float> %332, <16 x float> %274)
  %338 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %285, <16 x float> %332, <16 x float> %280)
  %339 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %291, <16 x float> %332, <16 x float> %286)
  %340 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %297, <16 x float> %332, <16 x float> %292)
  %341 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %303, <16 x float> %332, <16 x float> %298)
  %342 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %309, <16 x float> %332, <16 x float> %304)
  %343 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %315, <16 x float> %332, <16 x float> %310)
  %344 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %321, <16 x float> %332, <16 x float> %316)
  %345 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %327, <16 x float> %332, <16 x float> %322)
  %346 = add nsw i64 %240, 1792
  %347 = getelementptr inbounds float, float* %5, i64 %346
  %348 = load float, float* %347, align 4, !tbaa !5888
  %349 = insertelement <16 x float> undef, float %348, i32 0
  %350 = shufflevector <16 x float> %349, <16 x float> undef, <16 x i32> zeroinitializer
  %351 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %350, <16 x float> %332, <16 x float> %328)
  %352 = add nsw i64 %246, 4096
  %353 = getelementptr inbounds float, float* %8, i64 %352
  %354 = bitcast float* %353 to <16 x float>*
  %355 = load <16 x float>, <16 x float>* %354, align 64, !tbaa !5899
  %356 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %261, <16 x float> %355, <16 x float> %333)
  %357 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %267, <16 x float> %355, <16 x float> %334)
  %358 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %273, <16 x float> %355, <16 x float> %335)
  %359 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %279, <16 x float> %355, <16 x float> %336)
  %360 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %285, <16 x float> %355, <16 x float> %337)
  %361 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %291, <16 x float> %355, <16 x float> %338)
  %362 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %297, <16 x float> %355, <16 x float> %339)
  %363 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %303, <16 x float> %355, <16 x float> %340)
  %364 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %309, <16 x float> %355, <16 x float> %341)
  %365 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %315, <16 x float> %355, <16 x float> %342)
  %366 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %321, <16 x float> %355, <16 x float> %343)
  %367 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %327, <16 x float> %355, <16 x float> %344)
  %368 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %350, <16 x float> %355, <16 x float> %345)
  %369 = add nsw i64 %240, 1920
  %370 = getelementptr inbounds float, float* %5, i64 %369
  %371 = load float, float* %370, align 4, !tbaa !5888
  %372 = insertelement <16 x float> undef, float %371, i32 0
  %373 = shufflevector <16 x float> %372, <16 x float> undef, <16 x i32> zeroinitializer
  %374 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %373, <16 x float> %355, <16 x float> %351)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %indvars.iv.next107.1 = add nuw nsw i64 %indvars.iv106.1, 1
  %375 = add nuw nsw i32 %221, 1
  %exitcond110.1 = icmp eq i64 %indvars.iv.next107.1, 3
  br i1 %exitcond110.1, label %for_end6.1, label %for_begin7.preheader.1, !prof !50

for_end6.1:                                       ; preds = %for_end9.1
  store <16 x float> %356, <16 x float>* %.sub, align 64, !tbaa !5902
  store <16 x float> %357, <16 x float>* %31, align 64, !tbaa !5902
  store <16 x float> %358, <16 x float>* %33, align 64, !tbaa !5902
  store <16 x float> %359, <16 x float>* %35, align 64, !tbaa !5902
  store <16 x float> %360, <16 x float>* %37, align 64, !tbaa !5902
  store <16 x float> %361, <16 x float>* %39, align 64, !tbaa !5902
  store <16 x float> %362, <16 x float>* %41, align 64, !tbaa !5902
  store <16 x float> %363, <16 x float>* %43, align 64, !tbaa !5902
  store <16 x float> %364, <16 x float>* %45, align 64, !tbaa !5902
  store <16 x float> %365, <16 x float>* %47, align 64, !tbaa !5902
  store <16 x float> %366, <16 x float>* %49, align 64, !tbaa !5902
  store <16 x float> %367, <16 x float>* %51, align 64, !tbaa !5902
  store <16 x float> %368, <16 x float>* %53, align 64, !tbaa !5902
  store <16 x float> %374, <16 x float>* %55, align 64, !tbaa !5902
  %376 = mul nsw i64 %indvars.iv117, 224
  %377 = shl nsw i32 %63, 4
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds float, float* %17, i64 %378
  %380 = bitcast float* %379 to <16 x float>*
  %381 = load <16 x float>, <16 x float>* %380, align 64, !tbaa !5912
  %382 = getelementptr inbounds float, float* %14, i64 %378
  %383 = bitcast float* %382 to <16 x float>*
  %384 = load <16 x float>, <16 x float>* %383, align 64, !tbaa !5915
  %385 = fadd <16 x float> %384, %356
  %386 = fadd <16 x float> %381, %385
  %387 = fcmp ogt <16 x float> %386, zeroinitializer
  %388 = select <16 x i1> %387, <16 x float> %386, <16 x float> zeroinitializer
  %389 = getelementptr inbounds float, float* %11, i64 %376
  %390 = bitcast float* %389 to <16 x float>*
  store <16 x float> %388, <16 x float>* %390, align 64, !tbaa !5918
  %391 = or i64 %376, 16
  %392 = fadd <16 x float> %384, %357
  %393 = fadd <16 x float> %381, %392
  %394 = fcmp ogt <16 x float> %393, zeroinitializer
  %395 = select <16 x i1> %394, <16 x float> %393, <16 x float> zeroinitializer
  %396 = getelementptr inbounds float, float* %11, i64 %391
  %397 = bitcast float* %396 to <16 x float>*
  store <16 x float> %395, <16 x float>* %397, align 64, !tbaa !5918
  %398 = add nsw i64 %376, 32
  %399 = fadd <16 x float> %384, %358
  %400 = fadd <16 x float> %381, %399
  %401 = fcmp ogt <16 x float> %400, zeroinitializer
  %402 = select <16 x i1> %401, <16 x float> %400, <16 x float> zeroinitializer
  %403 = getelementptr inbounds float, float* %11, i64 %398
  %404 = bitcast float* %403 to <16 x float>*
  store <16 x float> %402, <16 x float>* %404, align 64, !tbaa !5918
  %405 = add nsw i64 %376, 48
  %406 = fadd <16 x float> %384, %359
  %407 = fadd <16 x float> %381, %406
  %408 = fcmp ogt <16 x float> %407, zeroinitializer
  %409 = select <16 x i1> %408, <16 x float> %407, <16 x float> zeroinitializer
  %410 = getelementptr inbounds float, float* %11, i64 %405
  %411 = bitcast float* %410 to <16 x float>*
  store <16 x float> %409, <16 x float>* %411, align 64, !tbaa !5918
  %412 = add nsw i64 %376, 64
  %413 = fadd <16 x float> %384, %360
  %414 = fadd <16 x float> %381, %413
  %415 = fcmp ogt <16 x float> %414, zeroinitializer
  %416 = select <16 x i1> %415, <16 x float> %414, <16 x float> zeroinitializer
  %417 = getelementptr inbounds float, float* %11, i64 %412
  %418 = bitcast float* %417 to <16 x float>*
  store <16 x float> %416, <16 x float>* %418, align 64, !tbaa !5918
  %419 = add nsw i64 %376, 80
  %420 = fadd <16 x float> %384, %361
  %421 = fadd <16 x float> %381, %420
  %422 = fcmp ogt <16 x float> %421, zeroinitializer
  %423 = select <16 x i1> %422, <16 x float> %421, <16 x float> zeroinitializer
  %424 = getelementptr inbounds float, float* %11, i64 %419
  %425 = bitcast float* %424 to <16 x float>*
  store <16 x float> %423, <16 x float>* %425, align 64, !tbaa !5918
  %426 = add nsw i64 %376, 96
  %427 = fadd <16 x float> %384, %362
  %428 = fadd <16 x float> %381, %427
  %429 = fcmp ogt <16 x float> %428, zeroinitializer
  %430 = select <16 x i1> %429, <16 x float> %428, <16 x float> zeroinitializer
  %431 = getelementptr inbounds float, float* %11, i64 %426
  %432 = bitcast float* %431 to <16 x float>*
  store <16 x float> %430, <16 x float>* %432, align 64, !tbaa !5918
  %433 = add nsw i64 %376, 112
  %434 = fadd <16 x float> %384, %363
  %435 = fadd <16 x float> %381, %434
  %436 = fcmp ogt <16 x float> %435, zeroinitializer
  %437 = select <16 x i1> %436, <16 x float> %435, <16 x float> zeroinitializer
  %438 = getelementptr inbounds float, float* %11, i64 %433
  %439 = bitcast float* %438 to <16 x float>*
  store <16 x float> %437, <16 x float>* %439, align 64, !tbaa !5918
  %440 = add nsw i64 %376, 128
  %441 = fadd <16 x float> %384, %364
  %442 = fadd <16 x float> %381, %441
  %443 = fcmp ogt <16 x float> %442, zeroinitializer
  %444 = select <16 x i1> %443, <16 x float> %442, <16 x float> zeroinitializer
  %445 = getelementptr inbounds float, float* %11, i64 %440
  %446 = bitcast float* %445 to <16 x float>*
  store <16 x float> %444, <16 x float>* %446, align 64, !tbaa !5918
  %447 = add nsw i64 %376, 144
  %448 = fadd <16 x float> %384, %365
  %449 = fadd <16 x float> %381, %448
  %450 = fcmp ogt <16 x float> %449, zeroinitializer
  %451 = select <16 x i1> %450, <16 x float> %449, <16 x float> zeroinitializer
  %452 = getelementptr inbounds float, float* %11, i64 %447
  %453 = bitcast float* %452 to <16 x float>*
  store <16 x float> %451, <16 x float>* %453, align 64, !tbaa !5918
  %454 = add nsw i64 %376, 160
  %455 = fadd <16 x float> %384, %366
  %456 = fadd <16 x float> %381, %455
  %457 = fcmp ogt <16 x float> %456, zeroinitializer
  %458 = select <16 x i1> %457, <16 x float> %456, <16 x float> zeroinitializer
  %459 = getelementptr inbounds float, float* %11, i64 %454
  %460 = bitcast float* %459 to <16 x float>*
  store <16 x float> %458, <16 x float>* %460, align 64, !tbaa !5918
  %461 = add nsw i64 %376, 176
  %462 = load <16 x float>, <16 x float>* %51, align 64, !tbaa !5921
  %463 = fadd <16 x float> %384, %462
  %464 = fadd <16 x float> %381, %463
  %465 = fcmp ogt <16 x float> %464, zeroinitializer
  %466 = select <16 x i1> %465, <16 x float> %464, <16 x float> zeroinitializer
  %467 = getelementptr inbounds float, float* %11, i64 %461
  %468 = bitcast float* %467 to <16 x float>*
  store <16 x float> %466, <16 x float>* %468, align 64, !tbaa !5918
  %469 = add nsw i64 %376, 192
  %470 = load <16 x float>, <16 x float>* %53, align 64, !tbaa !5921
  %471 = fadd <16 x float> %384, %470
  %472 = fadd <16 x float> %381, %471
  %473 = fcmp ogt <16 x float> %472, zeroinitializer
  %474 = select <16 x i1> %473, <16 x float> %472, <16 x float> zeroinitializer
  %475 = getelementptr inbounds float, float* %11, i64 %469
  %476 = bitcast float* %475 to <16 x float>*
  store <16 x float> %474, <16 x float>* %476, align 64, !tbaa !5918
  %477 = add nsw i64 %376, 208
  %478 = load <16 x float>, <16 x float>* %55, align 64, !tbaa !5921
  %479 = fadd <16 x float> %384, %478
  %480 = fadd <16 x float> %381, %479
  %481 = fcmp ogt <16 x float> %480, zeroinitializer
  %482 = select <16 x i1> %481, <16 x float> %480, <16 x float> zeroinitializer
  %483 = getelementptr inbounds float, float* %11, i64 %477
  %484 = bitcast float* %483 to <16 x float>*
  store <16 x float> %482, <16 x float>* %484, align 64, !tbaa !5918
  %indvars.iv.next118 = add nsw i64 %indvars.iv117, 1
  %485 = icmp slt i64 %indvars.iv.next118, %59
  br i1 %485, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_35(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.437, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !5922
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.438, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !5936
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.439, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !5938
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !5952
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 16
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !5954
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 14
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !5957
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 14
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !5959
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 64
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !5963
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 200704, i32 12544, i32 896, i32 64>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !5975
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.11, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !5979
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !5993
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 2
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.280, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !5995
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 14
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.17, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !5998
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 14
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.18, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !6000
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 512
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !6004
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 200704, i32 100352, i32 7168, i32 512>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !6016
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.440, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_35_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_35_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %38, align 8
  %3 = getelementptr inbounds %38, %38* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %38, %38* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %38* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.441, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.441(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 7168
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 14
  %27 = mul nsw i32 %26, 896
  %28 = sdiv i32 %25, 14
  %29 = mul nsw i32 %28, 100352
  %30 = add i32 %27, %29
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body5 ]
  %31 = add nsw i64 %24, %indvars.iv
  %32 = trunc i64 %indvars.iv to i32
  %33 = and i32 %32, 63
  %34 = lshr i32 %32, 6
  %35 = mul nsw i32 %34, 12544
  %36 = add i32 %30, %35
  %37 = or i32 %36, %33
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds float, float* %7, i64 %38
  %40 = bitcast float* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !6020
  %42 = getelementptr inbounds float, float* %4, i64 %31
  %43 = bitcast float* %42 to i32*
  store i32 %41, i32* %43, align 4, !tbaa !6023
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %44 = or i64 %24, 512
  %45 = or i32 %30, 64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %46 = add nsw i64 %44, %indvars.iv.1
  %47 = trunc i64 %indvars.iv.1 to i32
  %48 = and i32 %47, 63
  %49 = lshr i32 %47, 6
  %50 = mul nsw i32 %49, 12544
  %51 = add i32 %45, %50
  %52 = or i32 %51, %48
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to i32*
  %56 = load i32, i32* %55, align 4, !tbaa !6020
  %57 = getelementptr inbounds float, float* %4, i64 %46
  %58 = bitcast float* %57 to i32*
  store i32 %56, i32* %58, align 4, !tbaa !6023
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %59 = add nsw i64 %24, 1024
  %60 = add i32 %30, 128
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %61 = add nsw i64 %59, %indvars.iv.2
  %62 = trunc i64 %indvars.iv.2 to i32
  %63 = and i32 %62, 63
  %64 = lshr i32 %62, 6
  %65 = mul nsw i32 %64, 12544
  %66 = add i32 %60, %65
  %67 = or i32 %66, %63
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = bitcast float* %69 to i32*
  %71 = load i32, i32* %70, align 4, !tbaa !6020
  %72 = getelementptr inbounds float, float* %4, i64 %61
  %73 = bitcast float* %72 to i32*
  store i32 %71, i32* %73, align 4, !tbaa !6023
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %74 = add nsw i64 %24, 1536
  %75 = add i32 %30, 192
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %76 = add nsw i64 %74, %indvars.iv.3
  %77 = trunc i64 %indvars.iv.3 to i32
  %78 = and i32 %77, 63
  %79 = lshr i32 %77, 6
  %80 = mul nsw i32 %79, 12544
  %81 = add i32 %75, %80
  %82 = or i32 %81, %78
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = bitcast float* %84 to i32*
  %86 = load i32, i32* %85, align 4, !tbaa !6020
  %87 = getelementptr inbounds float, float* %4, i64 %76
  %88 = bitcast float* %87 to i32*
  store i32 %86, i32* %88, align 4, !tbaa !6023
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  %89 = add nsw i64 %24, 2048
  %90 = add i32 %30, 256
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %91 = add nsw i64 %89, %indvars.iv.4
  %92 = trunc i64 %indvars.iv.4 to i32
  %93 = and i32 %92, 63
  %94 = lshr i32 %92, 6
  %95 = mul nsw i32 %94, 12544
  %96 = add i32 %90, %95
  %97 = or i32 %96, %93
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = bitcast float* %99 to i32*
  %101 = load i32, i32* %100, align 4, !tbaa !6020
  %102 = getelementptr inbounds float, float* %4, i64 %91
  %103 = bitcast float* %102 to i32*
  store i32 %101, i32* %103, align 4, !tbaa !6023
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  %104 = add nsw i64 %24, 2560
  %105 = add i32 %30, 320
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %106 = add nsw i64 %104, %indvars.iv.5
  %107 = trunc i64 %indvars.iv.5 to i32
  %108 = and i32 %107, 63
  %109 = lshr i32 %107, 6
  %110 = mul nsw i32 %109, 12544
  %111 = add i32 %105, %110
  %112 = or i32 %111, %108
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to i32*
  %116 = load i32, i32* %115, align 4, !tbaa !6020
  %117 = getelementptr inbounds float, float* %4, i64 %106
  %118 = bitcast float* %117 to i32*
  store i32 %116, i32* %118, align 4, !tbaa !6023
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  %119 = add nsw i64 %24, 3072
  %120 = add i32 %30, 384
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %121 = add nsw i64 %119, %indvars.iv.6
  %122 = trunc i64 %indvars.iv.6 to i32
  %123 = and i32 %122, 63
  %124 = lshr i32 %122, 6
  %125 = mul nsw i32 %124, 12544
  %126 = add i32 %120, %125
  %127 = or i32 %126, %123
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds float, float* %7, i64 %128
  %130 = bitcast float* %129 to i32*
  %131 = load i32, i32* %130, align 4, !tbaa !6020
  %132 = getelementptr inbounds float, float* %4, i64 %121
  %133 = bitcast float* %132 to i32*
  store i32 %131, i32* %133, align 4, !tbaa !6023
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  %134 = add nsw i64 %24, 3584
  %135 = add i32 %30, 448
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %136 = add nsw i64 %134, %indvars.iv.7
  %137 = trunc i64 %indvars.iv.7 to i32
  %138 = and i32 %137, 63
  %139 = lshr i32 %137, 6
  %140 = mul nsw i32 %139, 12544
  %141 = add i32 %135, %140
  %142 = or i32 %141, %138
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to i32*
  %146 = load i32, i32* %145, align 4, !tbaa !6020
  %147 = getelementptr inbounds float, float* %4, i64 %136
  %148 = bitcast float* %147 to i32*
  store i32 %146, i32* %148, align 4, !tbaa !6023
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 512
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !50

for_end6.7:                                       ; preds = %for_body5.7
  %149 = add nsw i64 %24, 4096
  %150 = add i32 %30, 512
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %151 = add nsw i64 %149, %indvars.iv.8
  %152 = trunc i64 %indvars.iv.8 to i32
  %153 = and i32 %152, 63
  %154 = lshr i32 %152, 6
  %155 = mul nsw i32 %154, 12544
  %156 = add i32 %150, %155
  %157 = or i32 %156, %153
  %158 = sext i32 %157 to i64
  %159 = getelementptr inbounds float, float* %7, i64 %158
  %160 = bitcast float* %159 to i32*
  %161 = load i32, i32* %160, align 4, !tbaa !6020
  %162 = getelementptr inbounds float, float* %4, i64 %151
  %163 = bitcast float* %162 to i32*
  store i32 %161, i32* %163, align 4, !tbaa !6023
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 512
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !50

for_end6.8:                                       ; preds = %for_body5.8
  %164 = add nsw i64 %24, 4608
  %165 = add i32 %30, 576
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %166 = add nsw i64 %164, %indvars.iv.9
  %167 = trunc i64 %indvars.iv.9 to i32
  %168 = and i32 %167, 63
  %169 = lshr i32 %167, 6
  %170 = mul nsw i32 %169, 12544
  %171 = add i32 %165, %170
  %172 = or i32 %171, %168
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to i32*
  %176 = load i32, i32* %175, align 4, !tbaa !6020
  %177 = getelementptr inbounds float, float* %4, i64 %166
  %178 = bitcast float* %177 to i32*
  store i32 %176, i32* %178, align 4, !tbaa !6023
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 512
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !50

for_end6.9:                                       ; preds = %for_body5.9
  %179 = add nsw i64 %24, 5120
  %180 = add i32 %30, 640
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %181 = add nsw i64 %179, %indvars.iv.10
  %182 = trunc i64 %indvars.iv.10 to i32
  %183 = and i32 %182, 63
  %184 = lshr i32 %182, 6
  %185 = mul nsw i32 %184, 12544
  %186 = add i32 %180, %185
  %187 = or i32 %186, %183
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4, !tbaa !6020
  %192 = getelementptr inbounds float, float* %4, i64 %181
  %193 = bitcast float* %192 to i32*
  store i32 %191, i32* %193, align 4, !tbaa !6023
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 512
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !50

for_end6.10:                                      ; preds = %for_body5.10
  %194 = add nsw i64 %24, 5632
  %195 = add i32 %30, 704
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %196 = add nsw i64 %194, %indvars.iv.11
  %197 = trunc i64 %indvars.iv.11 to i32
  %198 = and i32 %197, 63
  %199 = lshr i32 %197, 6
  %200 = mul nsw i32 %199, 12544
  %201 = add i32 %195, %200
  %202 = or i32 %201, %198
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds float, float* %7, i64 %203
  %205 = bitcast float* %204 to i32*
  %206 = load i32, i32* %205, align 4, !tbaa !6020
  %207 = getelementptr inbounds float, float* %4, i64 %196
  %208 = bitcast float* %207 to i32*
  store i32 %206, i32* %208, align 4, !tbaa !6023
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 512
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !50

for_end6.11:                                      ; preds = %for_body5.11
  %209 = add nsw i64 %24, 6144
  %210 = add i32 %30, 768
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %211 = add nsw i64 %209, %indvars.iv.12
  %212 = trunc i64 %indvars.iv.12 to i32
  %213 = and i32 %212, 63
  %214 = lshr i32 %212, 6
  %215 = mul nsw i32 %214, 12544
  %216 = add i32 %210, %215
  %217 = or i32 %216, %213
  %218 = sext i32 %217 to i64
  %219 = getelementptr inbounds float, float* %7, i64 %218
  %220 = bitcast float* %219 to i32*
  %221 = load i32, i32* %220, align 4, !tbaa !6020
  %222 = getelementptr inbounds float, float* %4, i64 %211
  %223 = bitcast float* %222 to i32*
  store i32 %221, i32* %223, align 4, !tbaa !6023
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 512
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !50

for_end6.12:                                      ; preds = %for_body5.12
  %224 = add nsw i64 %24, 6656
  %225 = add i32 %30, 832
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %226 = add nsw i64 %224, %indvars.iv.13
  %227 = trunc i64 %indvars.iv.13 to i32
  %228 = and i32 %227, 63
  %229 = lshr i32 %227, 6
  %230 = mul nsw i32 %229, 12544
  %231 = add i32 %225, %230
  %232 = or i32 %231, %228
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to i32*
  %236 = load i32, i32* %235, align 4, !tbaa !6020
  %237 = getelementptr inbounds float, float* %4, i64 %226
  %238 = bitcast float* %237 to i32*
  store i32 %236, i32* %238, align 4, !tbaa !6023
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 512
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !50

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %239 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %239, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 7
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([113 x i8], [113 x i8]* @.str.442, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !6026
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !6040
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !6043
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !6045
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !6049
  %36 = getelementptr inbounds i8, i8* %0, i64 48
  %37 = bitcast i8* %36 to %1**
  %38 = load %1*, %1** %37, align 8
  %39 = getelementptr inbounds i8, i8* %1, i64 24
  %40 = bitcast i8* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !6051
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %49 = load i32, i32* %48, align 4
  %50 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %51 = load i32, i32* %50, align 4
  %52 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  %76 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %77 = load i8*, i8** %76, align 8
  %78 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %79 = load i64*, i64** %78, align 8
  %80 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %81 = load i64*, i64** %80, align 8
  %82 = getelementptr inbounds %1, %1* %38, i64 0, i32 0
  %83 = load i8*, i8** %82, align 8
  %84 = getelementptr inbounds %1, %1* %38, i64 0, i32 4
  %85 = load i64*, i64** %84, align 8
  %86 = getelementptr inbounds %1, %1* %38, i64 0, i32 5
  %87 = load i64*, i64** %86, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %88 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %88(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.443, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %89 = getelementptr inbounds i8, i8* %1, i64 4
  %90 = bitcast i8* %89 to i32*
  %91 = load i32, i32* %90, align 4, !tbaa !6054
  switch i32 %91, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.444, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.445, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.446, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.447, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.448, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  switch i32 %41, label %assert_fail13 [
    i32 13, label %assert_end14
    i32 7, label %assert_end14
    i32 4, label %assert_end14
    i32 3, label %assert_end14
  ]

assert_fail13:                                    ; preds = %assert_end12
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.449, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12, %assert_end12, %assert_end12, %assert_end12
  %98 = icmp eq i32 %49, 1
  br i1 %98, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %99 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %99(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %100 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %101 = load i32, i32* %100, align 4
  %102 = icmp eq i32 %101, 5
  br i1 %102, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %104 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %105 = load i16, i16* %104, align 2
  %106 = icmp eq i16 %105, 1
  %107 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %108 = load i8, i8* %107, align 1
  %109 = icmp eq i8 %108, 32
  %110 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %111 = load i8, i8* %110, align 1
  %112 = icmp eq i8 %111, 2
  %113 = and i1 %109, %112
  %114 = and i1 %106, %113
  br i1 %114, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %116 = load i64, i64* %45, align 8, !tbaa !6056
  %117 = trunc i64 %116 to i32
  %118 = icmp eq i32 %117, 1
  br i1 %118, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %119 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %119(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %120 = getelementptr inbounds i64, i64* %45, i64 1
  %121 = load i64, i64* %120, align 8, !tbaa !6070
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %122, 1
  br i1 %123, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %124 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %124(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %125 = getelementptr inbounds i64, i64* %45, i64 2
  %126 = load i64, i64* %125, align 8, !tbaa !6072
  %127 = trunc i64 %126 to i32
  %128 = icmp eq i32 %127, 14
  br i1 %128, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %130 = getelementptr inbounds i64, i64* %45, i64 3
  %131 = load i64, i64* %130, align 8, !tbaa !6075
  %132 = trunc i64 %131 to i32
  %133 = icmp eq i32 %132, 14
  br i1 %133, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %135 = getelementptr inbounds i64, i64* %45, i64 4
  %136 = load i64, i64* %135, align 8, !tbaa !6077
  %137 = trunc i64 %136 to i32
  %138 = icmp eq i32 %137, 256
  br i1 %138, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %139 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %139(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %140 = icmp eq i64* %47, null
  br i1 %140, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end30
  %141 = bitcast i64* %47 to <4 x i64>*
  %142 = load <4 x i64>, <4 x i64>* %141, align 8, !tbaa !6081
  %143 = trunc <4 x i64> %142 to <4 x i32>
  %144 = icmp eq <4 x i32> %143, <i32 50176, i32 50176, i32 3584, i32 256>
  %145 = getelementptr inbounds i64, i64* %47, i64 4
  %146 = load i64, i64* %145, align 8, !tbaa !6093
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 1
  %rdx.shuf197 = shufflevector <4 x i1> %144, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx198 = and <4 x i1> %144, %rdx.shuf197
  %rdx.shuf199 = shufflevector <4 x i1> %bin.rdx198, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx200 = and <4 x i1> %bin.rdx198, %rdx.shuf199
  %149 = extractelement <4 x i1> %bin.rdx200, i32 0
  %150 = and i1 %149, %148
  br i1 %150, label %if_end, label %assert_fail31, !prof !5

if_end:                                           ; preds = %assert_end30, %if_then
  %151 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %152 = load i64, i64* %151, align 8
  %153 = icmp eq i64 %152, 0
  br i1 %153, label %assert_end34, label %assert_fail33, !prof !5

assert_fail31:                                    ; preds = %if_then
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.450, i64 0, i64 0))
  ret i32 -1

assert_fail33:                                    ; preds = %if_end
  %155 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %155(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %if_end
  %156 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %157 = load i32, i32* %156, align 4
  %158 = icmp eq i32 %157, 6
  br i1 %158, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %160 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %161 = load i16, i16* %160, align 2
  %162 = icmp eq i16 %161, 1
  %163 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %164 = load i8, i8* %163, align 1
  %165 = icmp eq i8 %164, 32
  %166 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %167 = load i8, i8* %166, align 1
  %168 = icmp eq i8 %167, 2
  %169 = and i1 %165, %168
  %170 = and i1 %162, %169
  br i1 %170, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %172 = load i64, i64* %55, align 8, !tbaa !6097
  %173 = trunc i64 %172 to i32
  %174 = icmp eq i32 %173, 16
  br i1 %174, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %175 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %175(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %176 = getelementptr inbounds i64, i64* %55, i64 1
  %177 = load i64, i64* %176, align 8, !tbaa !6111
  %178 = trunc i64 %177 to i32
  %179 = icmp eq i32 %178, 1
  br i1 %179, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %180 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %180(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %181 = getelementptr inbounds i64, i64* %55, i64 2
  %182 = load i64, i64* %181, align 8, !tbaa !6113
  %183 = trunc i64 %182 to i32
  %184 = icmp eq i32 %183, 1
  br i1 %184, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %185 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %185(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %186 = getelementptr inbounds i64, i64* %55, i64 3
  %187 = load i64, i64* %186, align 8, !tbaa !6116
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  br i1 %189, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %190 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %190(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %191 = getelementptr inbounds i64, i64* %55, i64 4
  %192 = load i64, i64* %191, align 8, !tbaa !6118
  %193 = trunc i64 %192 to i32
  %194 = icmp eq i32 %193, 256
  br i1 %194, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %196 = getelementptr inbounds i64, i64* %55, i64 5
  %197 = load i64, i64* %196, align 8, !tbaa !6122
  %198 = trunc i64 %197 to i32
  %199 = icmp eq i32 %198, 64
  br i1 %199, label %assert_end50, label %assert_fail49, !prof !5

assert_fail49:                                    ; preds = %assert_end48
  %200 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %200(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.227, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %assert_end48
  %201 = icmp eq i64* %57, null
  br i1 %201, label %if_end52, label %if_then51, !prof !50

if_then51:                                        ; preds = %assert_end50
  %202 = bitcast i64* %57 to <4 x i64>*
  %203 = load <4 x i64>, <4 x i64>* %202, align 8, !tbaa !6124
  %204 = trunc <4 x i64> %203 to <4 x i32>
  %205 = icmp eq <4 x i32> %204, <i32 16384, i32 16384, i32 16384, i32 16384>
  %206 = getelementptr inbounds i64, i64* %57, i64 4
  %207 = load i64, i64* %206, align 8, !tbaa !6136
  %208 = trunc i64 %207 to i32
  %209 = icmp eq i32 %208, 64
  %210 = getelementptr inbounds i64, i64* %57, i64 5
  %211 = load i64, i64* %210, align 8, !tbaa !6140
  %212 = trunc i64 %211 to i32
  %213 = icmp eq i32 %212, 1
  %rdx.shuf193 = shufflevector <4 x i1> %205, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx194 = and <4 x i1> %205, %rdx.shuf193
  %rdx.shuf195 = shufflevector <4 x i1> %bin.rdx194, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx196 = and <4 x i1> %bin.rdx194, %rdx.shuf195
  %214 = extractelement <4 x i1> %bin.rdx196, i32 0
  %215 = and i1 %214, %209
  %216 = and i1 %215, %213
  br i1 %216, label %if_end52, label %assert_fail53, !prof !5

if_end52:                                         ; preds = %assert_end50, %if_then51
  %217 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %218 = load i64, i64* %217, align 8
  %219 = icmp eq i64 %218, 0
  br i1 %219, label %assert_end56, label %assert_fail55, !prof !5

assert_fail53:                                    ; preds = %if_then51
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([279 x i8], [279 x i8]* @.str.290, i64 0, i64 0))
  ret i32 -1

assert_fail55:                                    ; preds = %if_end52
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %if_end52
  %222 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %223 = load i32, i32* %222, align 4
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %226 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %227 = load i32, i32* %226, align 4
  %228 = icmp eq i32 %51, %227
  br i1 %228, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %229 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %229(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %230 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %231 = load i32, i32* %230, align 4
  %232 = icmp eq i32 %231, 4
  br i1 %232, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %234 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %235 = load i16, i16* %234, align 2
  %236 = icmp eq i16 %235, 1
  %237 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %238 = load i8, i8* %237, align 1
  %239 = icmp eq i8 %238, 32
  %240 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %241 = load i8, i8* %240, align 1
  %242 = icmp eq i8 %241, 2
  %243 = and i1 %239, %242
  %244 = and i1 %236, %243
  br i1 %244, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %246 = load i64, i64* %61, align 8, !tbaa !6142
  %247 = trunc i64 %246 to i32
  %248 = icmp eq i32 %247, 16
  br i1 %248, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %250 = getelementptr inbounds i64, i64* %61, i64 1
  %251 = load i64, i64* %250, align 8, !tbaa !6156
  %252 = trunc i64 %251 to i32
  %253 = icmp eq i32 %252, 1
  br i1 %253, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %254 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %254(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %255 = getelementptr inbounds i64, i64* %61, i64 2
  %256 = load i64, i64* %255, align 8, !tbaa !6158
  %257 = trunc i64 %256 to i32
  %258 = icmp eq i32 %257, 1
  br i1 %258, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %259 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %259(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %260 = getelementptr inbounds i64, i64* %61, i64 3
  %261 = load i64, i64* %260, align 8, !tbaa !6161
  %262 = trunc i64 %261 to i32
  %263 = icmp eq i32 %262, 64
  br i1 %263, label %assert_end72, label %assert_fail71, !prof !5

assert_fail71:                                    ; preds = %assert_end70
  %264 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %264(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.229, i64 0, i64 0))
  ret i32 -1

assert_end72:                                     ; preds = %assert_end70
  %265 = icmp eq i64* %63, null
  br i1 %265, label %if_end74, label %if_then73, !prof !50

if_then73:                                        ; preds = %assert_end72
  %266 = bitcast i64* %63 to <4 x i64>*
  %267 = load <4 x i64>, <4 x i64>* %266, align 8, !tbaa !6163
  %268 = trunc <4 x i64> %267 to <4 x i32>
  %269 = icmp eq <4 x i32> %268, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf189 = shufflevector <4 x i1> %269, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx190 = and <4 x i1> %269, %rdx.shuf189
  %rdx.shuf191 = shufflevector <4 x i1> %bin.rdx190, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx192 = and <4 x i1> %bin.rdx190, %rdx.shuf191
  %270 = extractelement <4 x i1> %bin.rdx192, i32 0
  br i1 %270, label %if_end74, label %assert_fail75, !prof !5

if_end74:                                         ; preds = %assert_end72, %if_then73
  %271 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %272 = load i64, i64* %271, align 8
  %273 = icmp eq i64 %272, 0
  br i1 %273, label %assert_end78, label %assert_fail77, !prof !5

assert_fail75:                                    ; preds = %if_then73
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.230, i64 0, i64 0))
  ret i32 -1

assert_fail77:                                    ; preds = %if_end74
  %275 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %275(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %if_end74
  %276 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %277 = load i32, i32* %276, align 4
  %278 = icmp eq i32 %277, 1
  br i1 %278, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %279 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %279(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %280 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %281 = load i32, i32* %280, align 4
  %282 = icmp eq i32 %51, %281
  br i1 %282, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %283 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %283(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %284 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %285 = load i32, i32* %284, align 4
  %286 = icmp eq i32 %285, 4
  br i1 %286, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %288 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %289 = load i16, i16* %288, align 2
  %290 = icmp eq i16 %289, 1
  %291 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %292 = load i8, i8* %291, align 1
  %293 = icmp eq i8 %292, 32
  %294 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %295 = load i8, i8* %294, align 1
  %296 = icmp eq i8 %295, 2
  %297 = and i1 %293, %296
  %298 = and i1 %290, %297
  br i1 %298, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %300 = load i64, i64* %67, align 8, !tbaa !6175
  %301 = trunc i64 %300 to i32
  %302 = icmp eq i32 %301, 16
  br i1 %302, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.250, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %304 = getelementptr inbounds i64, i64* %67, i64 1
  %305 = load i64, i64* %304, align 8, !tbaa !6189
  %306 = trunc i64 %305 to i32
  %307 = icmp eq i32 %306, 1
  br i1 %307, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %308 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %308(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %309 = getelementptr inbounds i64, i64* %67, i64 2
  %310 = load i64, i64* %309, align 8, !tbaa !6191
  %311 = trunc i64 %310 to i32
  %312 = icmp eq i32 %311, 1
  br i1 %312, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %313 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %313(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %314 = getelementptr inbounds i64, i64* %67, i64 3
  %315 = load i64, i64* %314, align 8, !tbaa !6194
  %316 = trunc i64 %315 to i32
  %317 = icmp eq i32 %316, 64
  br i1 %317, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %318 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %318(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.231, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %319 = icmp eq i64* %69, null
  br i1 %319, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %320 = bitcast i64* %69 to <4 x i64>*
  %321 = load <4 x i64>, <4 x i64>* %320, align 8, !tbaa !6196
  %322 = trunc <4 x i64> %321 to <4 x i32>
  %323 = icmp eq <4 x i32> %322, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf185 = shufflevector <4 x i1> %323, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx186 = and <4 x i1> %323, %rdx.shuf185
  %rdx.shuf187 = shufflevector <4 x i1> %bin.rdx186, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx188 = and <4 x i1> %bin.rdx186, %rdx.shuf187
  %324 = extractelement <4 x i1> %bin.rdx188, i32 0
  br i1 %324, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %325 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %326 = load i64, i64* %325, align 8
  %327 = icmp eq i64 %326, 0
  br i1 %327, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.232, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %330 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %331, 1
  br i1 %332, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %334 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %51, %335
  br i1 %336, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %338 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %339 = load i32, i32* %338, align 4
  %340 = icmp eq i32 %339, 4
  br i1 %340, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %342 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %343 = load i16, i16* %342, align 2
  %344 = icmp eq i16 %343, 1
  %345 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %346 = load i8, i8* %345, align 1
  %347 = icmp eq i8 %346, 32
  %348 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %349 = load i8, i8* %348, align 1
  %350 = icmp eq i8 %349, 2
  %351 = and i1 %347, %350
  %352 = and i1 %344, %351
  br i1 %352, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %354 = load i64, i64* %73, align 8, !tbaa !6208
  %355 = trunc i64 %354 to i32
  %356 = icmp eq i32 %355, 16
  br i1 %356, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %357 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %357(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.451, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %358 = getelementptr inbounds i64, i64* %73, i64 1
  %359 = load i64, i64* %358, align 8, !tbaa !6222
  %360 = trunc i64 %359 to i32
  %361 = icmp eq i32 %360, 1
  br i1 %361, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %362 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %362(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %363 = getelementptr inbounds i64, i64* %73, i64 2
  %364 = load i64, i64* %363, align 8, !tbaa !6224
  %365 = trunc i64 %364 to i32
  %366 = icmp eq i32 %365, 1
  br i1 %366, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %368 = getelementptr inbounds i64, i64* %73, i64 3
  %369 = load i64, i64* %368, align 8, !tbaa !6227
  %370 = trunc i64 %369 to i32
  %371 = icmp eq i32 %370, 64
  br i1 %371, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %372 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %372(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.291, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %373 = icmp eq i64* %75, null
  br i1 %373, label %if_end118, label %if_then117, !prof !50

if_then117:                                       ; preds = %assert_end116
  %374 = bitcast i64* %75 to <4 x i64>*
  %375 = load <4 x i64>, <4 x i64>* %374, align 8, !tbaa !6229
  %376 = trunc <4 x i64> %375 to <4 x i32>
  %377 = icmp eq <4 x i32> %376, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf181 = shufflevector <4 x i1> %377, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx182 = and <4 x i1> %377, %rdx.shuf181
  %rdx.shuf183 = shufflevector <4 x i1> %bin.rdx182, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx184 = and <4 x i1> %bin.rdx182, %rdx.shuf183
  %378 = extractelement <4 x i1> %bin.rdx184, i32 0
  br i1 %378, label %if_end118, label %assert_fail119, !prof !5

if_end118:                                        ; preds = %assert_end116, %if_then117
  %379 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %380 = load i64, i64* %379, align 8
  %381 = icmp eq i64 %380, 0
  br i1 %381, label %assert_end122, label %assert_fail121, !prof !5

assert_fail119:                                   ; preds = %if_then117
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.292, i64 0, i64 0))
  ret i32 -1

assert_fail121:                                   ; preds = %if_end118
  %383 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %383(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %if_end118
  %384 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %385 = load i32, i32* %384, align 4
  %386 = icmp eq i32 %385, 1
  br i1 %386, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %387 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %387(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %388 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %389 = load i32, i32* %388, align 4
  %390 = icmp eq i32 %51, %389
  br i1 %390, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %391 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %391(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %392 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %393 = load i32, i32* %392, align 4
  %394 = icmp eq i32 %393, 5
  br i1 %394, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %395 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %395(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %396 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %397 = load i16, i16* %396, align 2
  %398 = icmp eq i16 %397, 1
  %399 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %400 = load i8, i8* %399, align 1
  %401 = icmp eq i8 %400, 32
  %402 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %403 = load i8, i8* %402, align 1
  %404 = icmp eq i8 %403, 2
  %405 = and i1 %401, %404
  %406 = and i1 %398, %405
  br i1 %406, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %407 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %407(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %408 = load i64, i64* %79, align 8, !tbaa !6241
  %409 = trunc i64 %408 to i32
  %410 = icmp eq i32 %409, 1
  br i1 %410, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %411 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %411(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %412 = getelementptr inbounds i64, i64* %79, i64 1
  %413 = load i64, i64* %412, align 8, !tbaa !6255
  %414 = trunc i64 %413 to i32
  %415 = icmp eq i32 %414, 16
  br i1 %415, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %416 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %416(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.452, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %417 = getelementptr inbounds i64, i64* %79, i64 2
  %418 = load i64, i64* %417, align 8, !tbaa !6257
  %419 = trunc i64 %418 to i32
  %420 = icmp eq i32 %419, 14
  br i1 %420, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %421 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %421(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.453, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %422 = getelementptr inbounds i64, i64* %79, i64 3
  %423 = load i64, i64* %422, align 8, !tbaa !6260
  %424 = trunc i64 %423 to i32
  %425 = icmp eq i32 %424, 14
  br i1 %425, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %426 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %426(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.454, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %427 = getelementptr inbounds i64, i64* %79, i64 4
  %428 = load i64, i64* %427, align 8, !tbaa !6262
  %429 = trunc i64 %428 to i32
  %430 = icmp eq i32 %429, 64
  br i1 %430, label %assert_end140, label %assert_fail139, !prof !5

assert_fail139:                                   ; preds = %assert_end138
  %431 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %431(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.295, i64 0, i64 0))
  ret i32 -1

assert_end140:                                    ; preds = %assert_end138
  %432 = icmp eq i64* %81, null
  br i1 %432, label %if_end142, label %if_then141, !prof !50

if_then141:                                       ; preds = %assert_end140
  %433 = bitcast i64* %81 to <4 x i64>*
  %434 = load <4 x i64>, <4 x i64>* %433, align 8, !tbaa !6266
  %435 = trunc <4 x i64> %434 to <4 x i32>
  %436 = icmp eq <4 x i32> %435, <i32 200704, i32 12544, i32 896, i32 64>
  %437 = getelementptr inbounds i64, i64* %81, i64 4
  %438 = load i64, i64* %437, align 8, !tbaa !6278
  %439 = trunc i64 %438 to i32
  %440 = icmp eq i32 %439, 1
  %rdx.shuf177 = shufflevector <4 x i1> %436, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx178 = and <4 x i1> %436, %rdx.shuf177
  %rdx.shuf179 = shufflevector <4 x i1> %bin.rdx178, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx180 = and <4 x i1> %bin.rdx178, %rdx.shuf179
  %441 = extractelement <4 x i1> %bin.rdx180, i32 0
  %442 = and i1 %441, %440
  br i1 %442, label %if_end142, label %assert_fail143, !prof !5

if_end142:                                        ; preds = %assert_end140, %if_then141
  %443 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %444 = load i64, i64* %443, align 8
  %445 = icmp eq i64 %444, 0
  br i1 %445, label %assert_end146, label %assert_fail145, !prof !5

assert_fail143:                                   ; preds = %if_then141
  %446 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %446(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.455, i64 0, i64 0))
  ret i32 -1

assert_fail145:                                   ; preds = %if_end142
  %447 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %447(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %if_end142
  %448 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %449 = load i32, i32* %448, align 4
  %450 = icmp eq i32 %449, 1
  br i1 %450, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %451 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %451(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %452 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %453 = load i32, i32* %452, align 4
  %454 = icmp eq i32 %51, %453
  br i1 %454, label %assert_end150, label %assert_fail149, !prof !5

assert_fail149:                                   ; preds = %assert_end148
  %455 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %455(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end150:                                    ; preds = %assert_end148
  %456 = getelementptr inbounds %1, %1* %38, i64 0, i32 2
  %457 = load i32, i32* %456, align 4
  %458 = icmp eq i32 %457, 5
  br i1 %458, label %assert_end152, label %assert_fail151, !prof !5

assert_fail151:                                   ; preds = %assert_end150
  %459 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %459(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.310, i64 0, i64 0))
  ret i32 -1

assert_end152:                                    ; preds = %assert_end150
  %460 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 2
  %461 = load i16, i16* %460, align 2
  %462 = icmp eq i16 %461, 1
  %463 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 1
  %464 = load i8, i8* %463, align 1
  %465 = icmp eq i8 %464, 32
  %466 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 0
  %467 = load i8, i8* %466, align 1
  %468 = icmp eq i8 %467, 2
  %469 = and i1 %465, %468
  %470 = and i1 %462, %469
  br i1 %470, label %assert_end154, label %assert_fail153, !prof !5

assert_fail153:                                   ; preds = %assert_end152
  %471 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %471(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.311, i64 0, i64 0))
  ret i32 -1

assert_end154:                                    ; preds = %assert_end152
  %472 = load i64, i64* %85, align 8, !tbaa !6282
  %473 = trunc i64 %472 to i32
  %474 = icmp eq i32 %473, 1
  br i1 %474, label %assert_end156, label %assert_fail155, !prof !5

assert_fail155:                                   ; preds = %assert_end154
  %475 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %475(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.312, i64 0, i64 0))
  ret i32 -1

assert_end156:                                    ; preds = %assert_end154
  %476 = getelementptr inbounds i64, i64* %85, i64 1
  %477 = load i64, i64* %476, align 8, !tbaa !6296
  %478 = trunc i64 %477 to i32
  %479 = icmp eq i32 %478, 16
  br i1 %479, label %assert_end158, label %assert_fail157, !prof !5

assert_fail157:                                   ; preds = %assert_end156
  %480 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %480(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.456, i64 0, i64 0))
  ret i32 -1

assert_end158:                                    ; preds = %assert_end156
  %481 = getelementptr inbounds i64, i64* %85, i64 2
  %482 = load i64, i64* %481, align 8, !tbaa !6298
  %483 = trunc i64 %482 to i32
  %484 = icmp eq i32 %483, 14
  br i1 %484, label %assert_end160, label %assert_fail159, !prof !5

assert_fail159:                                   ; preds = %assert_end158
  %485 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %485(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.457, i64 0, i64 0))
  ret i32 -1

assert_end160:                                    ; preds = %assert_end158
  %486 = getelementptr inbounds i64, i64* %85, i64 3
  %487 = load i64, i64* %486, align 8, !tbaa !6301
  %488 = trunc i64 %487 to i32
  %489 = icmp eq i32 %488, 14
  br i1 %489, label %assert_end162, label %assert_fail161, !prof !5

assert_fail161:                                   ; preds = %assert_end160
  %490 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %490(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.458, i64 0, i64 0))
  ret i32 -1

assert_end162:                                    ; preds = %assert_end160
  %491 = getelementptr inbounds i64, i64* %85, i64 4
  %492 = load i64, i64* %491, align 8, !tbaa !6303
  %493 = trunc i64 %492 to i32
  %494 = icmp eq i32 %493, 64
  br i1 %494, label %assert_end164, label %assert_fail163, !prof !5

assert_fail163:                                   ; preds = %assert_end162
  %495 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %495(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.459, i64 0, i64 0))
  ret i32 -1

assert_end164:                                    ; preds = %assert_end162
  %496 = icmp eq i64* %87, null
  br i1 %496, label %if_end166, label %if_then165, !prof !50

if_then165:                                       ; preds = %assert_end164
  %497 = bitcast i64* %87 to <4 x i64>*
  %498 = load <4 x i64>, <4 x i64>* %497, align 8, !tbaa !6307
  %499 = trunc <4 x i64> %498 to <4 x i32>
  %500 = icmp eq <4 x i32> %499, <i32 200704, i32 12544, i32 896, i32 64>
  %501 = getelementptr inbounds i64, i64* %87, i64 4
  %502 = load i64, i64* %501, align 8, !tbaa !6319
  %503 = trunc i64 %502 to i32
  %504 = icmp eq i32 %503, 1
  %rdx.shuf = shufflevector <4 x i1> %500, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %500, %rdx.shuf
  %rdx.shuf175 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx176 = and <4 x i1> %bin.rdx, %rdx.shuf175
  %505 = extractelement <4 x i1> %bin.rdx176, i32 0
  %506 = and i1 %505, %504
  br i1 %506, label %if_end166, label %assert_fail167, !prof !5

if_end166:                                        ; preds = %assert_end164, %if_then165
  %507 = getelementptr inbounds %1, %1* %38, i64 0, i32 6
  %508 = load i64, i64* %507, align 8
  %509 = icmp eq i64 %508, 0
  br i1 %509, label %assert_end170, label %assert_fail169, !prof !5

assert_fail167:                                   ; preds = %if_then165
  %510 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %510(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.460, i64 0, i64 0))
  ret i32 -1

assert_fail169:                                   ; preds = %if_end166
  %511 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %511(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.318, i64 0, i64 0))
  ret i32 -1

assert_end170:                                    ; preds = %if_end166
  %512 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 0
  %513 = load i32, i32* %512, align 4
  %514 = icmp eq i32 %513, 1
  br i1 %514, label %assert_end172, label %assert_fail171, !prof !5

assert_fail171:                                   ; preds = %assert_end170
  %515 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %515(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.319, i64 0, i64 0))
  ret i32 -1

assert_end172:                                    ; preds = %assert_end170
  %516 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 1
  %517 = load i32, i32* %516, align 4
  %518 = icmp eq i32 %51, %517
  br i1 %518, label %assert_end174, label %assert_fail173, !prof !5

assert_fail173:                                   ; preds = %assert_end172
  %519 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %519(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.320, i64 0, i64 0))
  ret i32 -1

assert_end174:                                    ; preds = %assert_end172
  %520 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1_compute_(i8* %43, i8* %53, i8* %83, i8* %59, i8* %65, i8* %71, i8* %77, i32 %51)
  ret i32 %520
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %8 = alloca %39, align 8
  %9 = getelementptr inbounds %39, %39* %8, i64 0, i32 0
  store i8* %0, i8** %9, align 8
  %10 = getelementptr inbounds %39, %39* %8, i64 0, i32 1
  store i8* %1, i8** %10, align 8
  %11 = getelementptr inbounds %39, %39* %8, i64 0, i32 2
  store i8* %2, i8** %11, align 8
  %12 = getelementptr inbounds %39, %39* %8, i64 0, i32 3
  store i8* %3, i8** %12, align 8
  %13 = getelementptr inbounds %39, %39* %8, i64 0, i32 4
  store i8* %4, i8** %13, align 8
  %14 = getelementptr inbounds %39, %39* %8, i64 0, i32 5
  store i8* %5, i8** %14, align 8
  %15 = getelementptr inbounds %39, %39* %8, i64 0, i32 6
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %39, %39* %8, i64 0, i32 7
  store i32 %7, i32* %16, align 8
  %17 = bitcast %39* %8 to i8*
  %18 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %19 = call i32 %18(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.461, i8* nonnull %17, i32 0)
  ret i32 %19
}

define private i32 @__tvm_parallel_lambda.461(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds i8, i8* %2, i64 56
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %27 = load i32, i32* %26, align 4
  %28 = add nsw i32 %27, 111
  %29 = sdiv i32 %28, %27
  %30 = add nsw i32 %0, 1
  %31 = mul nsw i32 %29, %30
  %32 = icmp slt i32 %31, 112
  %33 = select i1 %32, i32 %31, i32 112
  %34 = mul nsw i32 %29, %0
  %35 = icmp slt i32 %34, 112
  %36 = select i1 %35, i32 %34, i32 112
  %37 = icmp slt i32 %36, %33
  br i1 %37, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %38 = add i32 %36, 1
  %39 = sext i32 %38 to i64
  %40 = add nsw i64 %39, -1
  %41 = sext i32 %33 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end6.6
  %indvars.iv43 = phi i64 [ %40, %for_body.preheader ], [ %indvars.iv.next44, %for_end6.6 ]
  %42 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %43 = tail call i8* %42(i32 1, i32 %25, i64 7168, i32 2, i32 32)
  %44 = trunc i64 %indvars.iv43 to i32
  %45 = srem i32 %44, 7
  %46 = mul nsw i32 %45, 7168
  %47 = sdiv i32 %44, 7
  %48 = shl i32 %47, 14
  %49 = sext i32 %48 to i64
  %50 = sext i32 %46 to i64
  %51 = bitcast i8* %43 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %51, align 64, !tbaa !6323
  %52 = getelementptr inbounds i8, i8* %43, i64 256
  %53 = bitcast i8* %52 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %53, align 64, !tbaa !6323
  %54 = getelementptr inbounds i8, i8* %43, i64 3584
  %55 = bitcast i8* %54 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %55, align 64, !tbaa !6323
  %56 = getelementptr inbounds i8, i8* %43, i64 3840
  %57 = bitcast i8* %56 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %57, align 64, !tbaa !6323
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %58 = phi <64 x float> [ zeroinitializer, %for_body ], [ %90, %for_body5 ]
  %59 = phi <64 x float> [ zeroinitializer, %for_body ], [ %84, %for_body5 ]
  %60 = phi <64 x float> [ zeroinitializer, %for_body ], [ %78, %for_body5 ]
  %61 = phi <64 x float> [ zeroinitializer, %for_body ], [ %72, %for_body5 ]
  %62 = add nsw i64 %indvars.iv, %50
  %63 = getelementptr inbounds float, float* %4, i64 %62
  %64 = load float, float* %63, align 4, !tbaa !6326
  %65 = insertelement <64 x float> undef, float %64, i32 0
  %66 = shufflevector <64 x float> %65, <64 x float> undef, <64 x i32> zeroinitializer
  %67 = shl i64 %indvars.iv, 6
  %68 = add nuw nsw i64 %67, %49
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = bitcast float* %69 to <64 x float>*
  %71 = load <64 x float>, <64 x float>* %70, align 64, !tbaa !6329
  %72 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %66, <64 x float> %71, <64 x float> %61)
  %73 = add nsw i64 %62, 256
  %74 = getelementptr inbounds float, float* %4, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !6326
  %76 = insertelement <64 x float> undef, float %75, i32 0
  %77 = shufflevector <64 x float> %76, <64 x float> undef, <64 x i32> zeroinitializer
  %78 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %77, <64 x float> %71, <64 x float> %60)
  %79 = add nsw i64 %62, 3584
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !6326
  %82 = insertelement <64 x float> undef, float %81, i32 0
  %83 = shufflevector <64 x float> %82, <64 x float> undef, <64 x i32> zeroinitializer
  %84 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %83, <64 x float> %71, <64 x float> %59)
  %85 = add nsw i64 %62, 3840
  %86 = getelementptr inbounds float, float* %4, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !6326
  %88 = insertelement <64 x float> undef, float %87, i32 0
  %89 = shufflevector <64 x float> %88, <64 x float> undef, <64 x i32> zeroinitializer
  %90 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %89, <64 x float> %71, <64 x float> %58)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  store <64 x float> %72, <64 x float>* %51, align 64, !tbaa !6323
  store <64 x float> %78, <64 x float>* %53, align 64, !tbaa !6323
  store <64 x float> %84, <64 x float>* %55, align 64, !tbaa !6323
  store <64 x float> %90, <64 x float>* %57, align 64, !tbaa !6323
  %91 = getelementptr inbounds i8, i8* %43, i64 512
  %92 = bitcast i8* %91 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %92, align 64, !tbaa !6323
  %93 = getelementptr inbounds i8, i8* %43, i64 768
  %94 = bitcast i8* %93 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %94, align 64, !tbaa !6323
  %95 = getelementptr inbounds i8, i8* %43, i64 4096
  %96 = bitcast i8* %95 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %96, align 64, !tbaa !6323
  %97 = getelementptr inbounds i8, i8* %43, i64 4352
  %98 = bitcast i8* %97 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %98, align 64, !tbaa !6323
  %99 = or i64 %50, 512
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %100 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %132, %for_body5.1 ]
  %101 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %126, %for_body5.1 ]
  %102 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %120, %for_body5.1 ]
  %103 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %114, %for_body5.1 ]
  %104 = add nsw i64 %99, %indvars.iv.1
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !6326
  %107 = insertelement <64 x float> undef, float %106, i32 0
  %108 = shufflevector <64 x float> %107, <64 x float> undef, <64 x i32> zeroinitializer
  %109 = shl i64 %indvars.iv.1, 6
  %110 = add nuw nsw i64 %109, %49
  %111 = getelementptr inbounds float, float* %7, i64 %110
  %112 = bitcast float* %111 to <64 x float>*
  %113 = load <64 x float>, <64 x float>* %112, align 64, !tbaa !6329
  %114 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %108, <64 x float> %113, <64 x float> %103)
  %115 = add nsw i64 %104, 256
  %116 = getelementptr inbounds float, float* %4, i64 %115
  %117 = load float, float* %116, align 4, !tbaa !6326
  %118 = insertelement <64 x float> undef, float %117, i32 0
  %119 = shufflevector <64 x float> %118, <64 x float> undef, <64 x i32> zeroinitializer
  %120 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %119, <64 x float> %113, <64 x float> %102)
  %121 = add nsw i64 %104, 3584
  %122 = getelementptr inbounds float, float* %4, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !6326
  %124 = insertelement <64 x float> undef, float %123, i32 0
  %125 = shufflevector <64 x float> %124, <64 x float> undef, <64 x i32> zeroinitializer
  %126 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %125, <64 x float> %113, <64 x float> %101)
  %127 = add nsw i64 %104, 3840
  %128 = getelementptr inbounds float, float* %4, i64 %127
  %129 = load float, float* %128, align 4, !tbaa !6326
  %130 = insertelement <64 x float> undef, float %129, i32 0
  %131 = shufflevector <64 x float> %130, <64 x float> undef, <64 x i32> zeroinitializer
  %132 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %131, <64 x float> %113, <64 x float> %100)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %114, <64 x float>* %92, align 64, !tbaa !6323
  store <64 x float> %120, <64 x float>* %94, align 64, !tbaa !6323
  store <64 x float> %126, <64 x float>* %96, align 64, !tbaa !6323
  store <64 x float> %132, <64 x float>* %98, align 64, !tbaa !6323
  %133 = getelementptr inbounds i8, i8* %43, i64 1024
  %134 = bitcast i8* %133 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %134, align 64, !tbaa !6323
  %135 = getelementptr inbounds i8, i8* %43, i64 1280
  %136 = bitcast i8* %135 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %136, align 64, !tbaa !6323
  %137 = getelementptr inbounds i8, i8* %43, i64 4608
  %138 = bitcast i8* %137 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %138, align 64, !tbaa !6323
  %139 = getelementptr inbounds i8, i8* %43, i64 4864
  %140 = bitcast i8* %139 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %140, align 64, !tbaa !6323
  %141 = add nsw i64 %50, 1024
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %142 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %174, %for_body5.2 ]
  %143 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %168, %for_body5.2 ]
  %144 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %162, %for_body5.2 ]
  %145 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %156, %for_body5.2 ]
  %146 = add nsw i64 %141, %indvars.iv.2
  %147 = getelementptr inbounds float, float* %4, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !6326
  %149 = insertelement <64 x float> undef, float %148, i32 0
  %150 = shufflevector <64 x float> %149, <64 x float> undef, <64 x i32> zeroinitializer
  %151 = shl i64 %indvars.iv.2, 6
  %152 = add nuw nsw i64 %151, %49
  %153 = getelementptr inbounds float, float* %7, i64 %152
  %154 = bitcast float* %153 to <64 x float>*
  %155 = load <64 x float>, <64 x float>* %154, align 64, !tbaa !6329
  %156 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %150, <64 x float> %155, <64 x float> %145)
  %157 = add nsw i64 %146, 256
  %158 = getelementptr inbounds float, float* %4, i64 %157
  %159 = load float, float* %158, align 4, !tbaa !6326
  %160 = insertelement <64 x float> undef, float %159, i32 0
  %161 = shufflevector <64 x float> %160, <64 x float> undef, <64 x i32> zeroinitializer
  %162 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %161, <64 x float> %155, <64 x float> %144)
  %163 = add nsw i64 %146, 3584
  %164 = getelementptr inbounds float, float* %4, i64 %163
  %165 = load float, float* %164, align 4, !tbaa !6326
  %166 = insertelement <64 x float> undef, float %165, i32 0
  %167 = shufflevector <64 x float> %166, <64 x float> undef, <64 x i32> zeroinitializer
  %168 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %167, <64 x float> %155, <64 x float> %143)
  %169 = add nsw i64 %146, 3840
  %170 = getelementptr inbounds float, float* %4, i64 %169
  %171 = load float, float* %170, align 4, !tbaa !6326
  %172 = insertelement <64 x float> undef, float %171, i32 0
  %173 = shufflevector <64 x float> %172, <64 x float> undef, <64 x i32> zeroinitializer
  %174 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %173, <64 x float> %155, <64 x float> %142)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %156, <64 x float>* %134, align 64, !tbaa !6323
  store <64 x float> %162, <64 x float>* %136, align 64, !tbaa !6323
  store <64 x float> %168, <64 x float>* %138, align 64, !tbaa !6323
  store <64 x float> %174, <64 x float>* %140, align 64, !tbaa !6323
  %175 = getelementptr inbounds i8, i8* %43, i64 1536
  %176 = bitcast i8* %175 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %176, align 64, !tbaa !6323
  %177 = getelementptr inbounds i8, i8* %43, i64 1792
  %178 = bitcast i8* %177 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %178, align 64, !tbaa !6323
  %179 = getelementptr inbounds i8, i8* %43, i64 5120
  %180 = bitcast i8* %179 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %180, align 64, !tbaa !6323
  %181 = getelementptr inbounds i8, i8* %43, i64 5376
  %182 = bitcast i8* %181 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %182, align 64, !tbaa !6323
  %183 = add nsw i64 %50, 1536
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %184 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %216, %for_body5.3 ]
  %185 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %210, %for_body5.3 ]
  %186 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %204, %for_body5.3 ]
  %187 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %198, %for_body5.3 ]
  %188 = add nsw i64 %183, %indvars.iv.3
  %189 = getelementptr inbounds float, float* %4, i64 %188
  %190 = load float, float* %189, align 4, !tbaa !6326
  %191 = insertelement <64 x float> undef, float %190, i32 0
  %192 = shufflevector <64 x float> %191, <64 x float> undef, <64 x i32> zeroinitializer
  %193 = shl i64 %indvars.iv.3, 6
  %194 = add nuw nsw i64 %193, %49
  %195 = getelementptr inbounds float, float* %7, i64 %194
  %196 = bitcast float* %195 to <64 x float>*
  %197 = load <64 x float>, <64 x float>* %196, align 64, !tbaa !6329
  %198 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %192, <64 x float> %197, <64 x float> %187)
  %199 = add nsw i64 %188, 256
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !6326
  %202 = insertelement <64 x float> undef, float %201, i32 0
  %203 = shufflevector <64 x float> %202, <64 x float> undef, <64 x i32> zeroinitializer
  %204 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %203, <64 x float> %197, <64 x float> %186)
  %205 = add nsw i64 %188, 3584
  %206 = getelementptr inbounds float, float* %4, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !6326
  %208 = insertelement <64 x float> undef, float %207, i32 0
  %209 = shufflevector <64 x float> %208, <64 x float> undef, <64 x i32> zeroinitializer
  %210 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %209, <64 x float> %197, <64 x float> %185)
  %211 = add nsw i64 %188, 3840
  %212 = getelementptr inbounds float, float* %4, i64 %211
  %213 = load float, float* %212, align 4, !tbaa !6326
  %214 = insertelement <64 x float> undef, float %213, i32 0
  %215 = shufflevector <64 x float> %214, <64 x float> undef, <64 x i32> zeroinitializer
  %216 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %215, <64 x float> %197, <64 x float> %184)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %198, <64 x float>* %176, align 64, !tbaa !6323
  store <64 x float> %204, <64 x float>* %178, align 64, !tbaa !6323
  store <64 x float> %210, <64 x float>* %180, align 64, !tbaa !6323
  store <64 x float> %216, <64 x float>* %182, align 64, !tbaa !6323
  %217 = getelementptr inbounds i8, i8* %43, i64 2048
  %218 = bitcast i8* %217 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %218, align 64, !tbaa !6323
  %219 = getelementptr inbounds i8, i8* %43, i64 2304
  %220 = bitcast i8* %219 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %220, align 64, !tbaa !6323
  %221 = getelementptr inbounds i8, i8* %43, i64 5632
  %222 = bitcast i8* %221 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %222, align 64, !tbaa !6323
  %223 = getelementptr inbounds i8, i8* %43, i64 5888
  %224 = bitcast i8* %223 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %224, align 64, !tbaa !6323
  %225 = add nsw i64 %50, 2048
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %226 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %258, %for_body5.4 ]
  %227 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %252, %for_body5.4 ]
  %228 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %246, %for_body5.4 ]
  %229 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %240, %for_body5.4 ]
  %230 = add nsw i64 %225, %indvars.iv.4
  %231 = getelementptr inbounds float, float* %4, i64 %230
  %232 = load float, float* %231, align 4, !tbaa !6326
  %233 = insertelement <64 x float> undef, float %232, i32 0
  %234 = shufflevector <64 x float> %233, <64 x float> undef, <64 x i32> zeroinitializer
  %235 = shl i64 %indvars.iv.4, 6
  %236 = add nuw nsw i64 %235, %49
  %237 = getelementptr inbounds float, float* %7, i64 %236
  %238 = bitcast float* %237 to <64 x float>*
  %239 = load <64 x float>, <64 x float>* %238, align 64, !tbaa !6329
  %240 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %234, <64 x float> %239, <64 x float> %229)
  %241 = add nsw i64 %230, 256
  %242 = getelementptr inbounds float, float* %4, i64 %241
  %243 = load float, float* %242, align 4, !tbaa !6326
  %244 = insertelement <64 x float> undef, float %243, i32 0
  %245 = shufflevector <64 x float> %244, <64 x float> undef, <64 x i32> zeroinitializer
  %246 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %245, <64 x float> %239, <64 x float> %228)
  %247 = add nsw i64 %230, 3584
  %248 = getelementptr inbounds float, float* %4, i64 %247
  %249 = load float, float* %248, align 4, !tbaa !6326
  %250 = insertelement <64 x float> undef, float %249, i32 0
  %251 = shufflevector <64 x float> %250, <64 x float> undef, <64 x i32> zeroinitializer
  %252 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %251, <64 x float> %239, <64 x float> %227)
  %253 = add nsw i64 %230, 3840
  %254 = getelementptr inbounds float, float* %4, i64 %253
  %255 = load float, float* %254, align 4, !tbaa !6326
  %256 = insertelement <64 x float> undef, float %255, i32 0
  %257 = shufflevector <64 x float> %256, <64 x float> undef, <64 x i32> zeroinitializer
  %258 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %257, <64 x float> %239, <64 x float> %226)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 256
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %240, <64 x float>* %218, align 64, !tbaa !6323
  store <64 x float> %246, <64 x float>* %220, align 64, !tbaa !6323
  store <64 x float> %252, <64 x float>* %222, align 64, !tbaa !6323
  store <64 x float> %258, <64 x float>* %224, align 64, !tbaa !6323
  %259 = getelementptr inbounds i8, i8* %43, i64 2560
  %260 = bitcast i8* %259 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %260, align 64, !tbaa !6323
  %261 = getelementptr inbounds i8, i8* %43, i64 2816
  %262 = bitcast i8* %261 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %262, align 64, !tbaa !6323
  %263 = getelementptr inbounds i8, i8* %43, i64 6144
  %264 = bitcast i8* %263 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %264, align 64, !tbaa !6323
  %265 = getelementptr inbounds i8, i8* %43, i64 6400
  %266 = bitcast i8* %265 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %266, align 64, !tbaa !6323
  %267 = add nsw i64 %50, 2560
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %268 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %300, %for_body5.5 ]
  %269 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %294, %for_body5.5 ]
  %270 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %288, %for_body5.5 ]
  %271 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %282, %for_body5.5 ]
  %272 = add nsw i64 %267, %indvars.iv.5
  %273 = getelementptr inbounds float, float* %4, i64 %272
  %274 = load float, float* %273, align 4, !tbaa !6326
  %275 = insertelement <64 x float> undef, float %274, i32 0
  %276 = shufflevector <64 x float> %275, <64 x float> undef, <64 x i32> zeroinitializer
  %277 = shl i64 %indvars.iv.5, 6
  %278 = add nuw nsw i64 %277, %49
  %279 = getelementptr inbounds float, float* %7, i64 %278
  %280 = bitcast float* %279 to <64 x float>*
  %281 = load <64 x float>, <64 x float>* %280, align 64, !tbaa !6329
  %282 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %276, <64 x float> %281, <64 x float> %271)
  %283 = add nsw i64 %272, 256
  %284 = getelementptr inbounds float, float* %4, i64 %283
  %285 = load float, float* %284, align 4, !tbaa !6326
  %286 = insertelement <64 x float> undef, float %285, i32 0
  %287 = shufflevector <64 x float> %286, <64 x float> undef, <64 x i32> zeroinitializer
  %288 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %287, <64 x float> %281, <64 x float> %270)
  %289 = add nsw i64 %272, 3584
  %290 = getelementptr inbounds float, float* %4, i64 %289
  %291 = load float, float* %290, align 4, !tbaa !6326
  %292 = insertelement <64 x float> undef, float %291, i32 0
  %293 = shufflevector <64 x float> %292, <64 x float> undef, <64 x i32> zeroinitializer
  %294 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %293, <64 x float> %281, <64 x float> %269)
  %295 = add nsw i64 %272, 3840
  %296 = getelementptr inbounds float, float* %4, i64 %295
  %297 = load float, float* %296, align 4, !tbaa !6326
  %298 = insertelement <64 x float> undef, float %297, i32 0
  %299 = shufflevector <64 x float> %298, <64 x float> undef, <64 x i32> zeroinitializer
  %300 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %299, <64 x float> %281, <64 x float> %268)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 256
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %282, <64 x float>* %260, align 64, !tbaa !6323
  store <64 x float> %288, <64 x float>* %262, align 64, !tbaa !6323
  store <64 x float> %294, <64 x float>* %264, align 64, !tbaa !6323
  store <64 x float> %300, <64 x float>* %266, align 64, !tbaa !6323
  %301 = getelementptr inbounds i8, i8* %43, i64 3072
  %302 = bitcast i8* %301 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %302, align 64, !tbaa !6323
  %303 = getelementptr inbounds i8, i8* %43, i64 3328
  %304 = bitcast i8* %303 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %304, align 64, !tbaa !6323
  %305 = getelementptr inbounds i8, i8* %43, i64 6656
  %306 = bitcast i8* %305 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %306, align 64, !tbaa !6323
  %307 = getelementptr inbounds i8, i8* %43, i64 6912
  %308 = bitcast i8* %307 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %308, align 64, !tbaa !6323
  %309 = add nsw i64 %50, 3072
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %310 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %342, %for_body5.6 ]
  %311 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %336, %for_body5.6 ]
  %312 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %330, %for_body5.6 ]
  %313 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %324, %for_body5.6 ]
  %314 = add nsw i64 %309, %indvars.iv.6
  %315 = getelementptr inbounds float, float* %4, i64 %314
  %316 = load float, float* %315, align 4, !tbaa !6326
  %317 = insertelement <64 x float> undef, float %316, i32 0
  %318 = shufflevector <64 x float> %317, <64 x float> undef, <64 x i32> zeroinitializer
  %319 = shl i64 %indvars.iv.6, 6
  %320 = add nuw nsw i64 %319, %49
  %321 = getelementptr inbounds float, float* %7, i64 %320
  %322 = bitcast float* %321 to <64 x float>*
  %323 = load <64 x float>, <64 x float>* %322, align 64, !tbaa !6329
  %324 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %318, <64 x float> %323, <64 x float> %313)
  %325 = add nsw i64 %314, 256
  %326 = getelementptr inbounds float, float* %4, i64 %325
  %327 = load float, float* %326, align 4, !tbaa !6326
  %328 = insertelement <64 x float> undef, float %327, i32 0
  %329 = shufflevector <64 x float> %328, <64 x float> undef, <64 x i32> zeroinitializer
  %330 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %329, <64 x float> %323, <64 x float> %312)
  %331 = add nsw i64 %314, 3584
  %332 = getelementptr inbounds float, float* %4, i64 %331
  %333 = load float, float* %332, align 4, !tbaa !6326
  %334 = insertelement <64 x float> undef, float %333, i32 0
  %335 = shufflevector <64 x float> %334, <64 x float> undef, <64 x i32> zeroinitializer
  %336 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %335, <64 x float> %323, <64 x float> %311)
  %337 = add nsw i64 %314, 3840
  %338 = getelementptr inbounds float, float* %4, i64 %337
  %339 = load float, float* %338, align 4, !tbaa !6326
  %340 = insertelement <64 x float> undef, float %339, i32 0
  %341 = shufflevector <64 x float> %340, <64 x float> undef, <64 x i32> zeroinitializer
  %342 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %341, <64 x float> %323, <64 x float> %310)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 256
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %324, <64 x float>* %302, align 64, !tbaa !6323
  store <64 x float> %330, <64 x float>* %304, align 64, !tbaa !6323
  store <64 x float> %336, <64 x float>* %306, align 64, !tbaa !6323
  store <64 x float> %342, <64 x float>* %308, align 64, !tbaa !6323
  %343 = mul nsw i64 %indvars.iv43, 1792
  %344 = shl nsw i32 %47, 6
  %345 = sext i32 %344 to i64
  %346 = getelementptr inbounds float, float* %13, i64 %345
  %347 = bitcast float* %346 to <64 x float>*
  %348 = load <64 x float>, <64 x float>* %347, align 64, !tbaa !6332
  %349 = getelementptr inbounds float, float* %16, i64 %345
  %350 = bitcast float* %349 to <64 x float>*
  %351 = load <64 x float>, <64 x float>* %350, align 64, !tbaa !6335
  %352 = getelementptr inbounds float, float* %19, i64 %345
  %353 = bitcast float* %352 to <64 x float>*
  %354 = load <64 x float>, <64 x float>* %353, align 64, !tbaa !6338
  %355 = getelementptr inbounds float, float* %22, i64 %343
  %356 = bitcast float* %355 to <64 x float>*
  %357 = load <64 x float>, <64 x float>* %356, align 64, !tbaa !6341
  %358 = bitcast i8* %43 to <64 x float>*
  %359 = load <64 x float>, <64 x float>* %358, align 64, !tbaa !6323
  %360 = fadd <64 x float> %348, %359
  %361 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %360, <64 x float> %351, <64 x float> %354)
  %362 = fadd <64 x float> %357, %361
  %363 = fcmp ogt <64 x float> %362, zeroinitializer
  %364 = select <64 x i1> %363, <64 x float> %362, <64 x float> zeroinitializer
  %365 = getelementptr inbounds float, float* %10, i64 %343
  %366 = bitcast float* %365 to <64 x float>*
  store <64 x float> %364, <64 x float>* %366, align 64, !tbaa !6344
  %367 = mul i64 %indvars.iv43, 7696581394432
  %sext = ashr exact i64 %367, 32
  %368 = or i64 %sext, 64
  %369 = getelementptr inbounds float, float* %22, i64 %368
  %370 = bitcast float* %369 to <64 x float>*
  %371 = load <64 x float>, <64 x float>* %370, align 64, !tbaa !6341
  %372 = getelementptr inbounds i8, i8* %43, i64 256
  %373 = bitcast i8* %372 to <64 x float>*
  %374 = load <64 x float>, <64 x float>* %373, align 64, !tbaa !6323
  %375 = fadd <64 x float> %348, %374
  %376 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %375, <64 x float> %351, <64 x float> %354)
  %377 = fadd <64 x float> %371, %376
  %378 = fcmp ogt <64 x float> %377, zeroinitializer
  %379 = select <64 x i1> %378, <64 x float> %377, <64 x float> zeroinitializer
  %380 = getelementptr inbounds float, float* %10, i64 %368
  %381 = bitcast float* %380 to <64 x float>*
  store <64 x float> %379, <64 x float>* %381, align 64, !tbaa !6344
  %382 = mul i64 %indvars.iv43, 7696581394432
  %sext58 = add i64 %382, 3848290697216
  %383 = ashr exact i64 %sext58, 32
  %384 = getelementptr inbounds float, float* %22, i64 %383
  %385 = bitcast float* %384 to <64 x float>*
  %386 = load <64 x float>, <64 x float>* %385, align 64, !tbaa !6341
  %387 = getelementptr inbounds i8, i8* %43, i64 3584
  %388 = bitcast i8* %387 to <64 x float>*
  %389 = load <64 x float>, <64 x float>* %388, align 64, !tbaa !6323
  %390 = fadd <64 x float> %348, %389
  %391 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %390, <64 x float> %351, <64 x float> %354)
  %392 = fadd <64 x float> %386, %391
  %393 = fcmp ogt <64 x float> %392, zeroinitializer
  %394 = select <64 x i1> %393, <64 x float> %392, <64 x float> zeroinitializer
  %395 = getelementptr inbounds float, float* %10, i64 %383
  %396 = bitcast float* %395 to <64 x float>*
  store <64 x float> %394, <64 x float>* %396, align 64, !tbaa !6344
  %397 = mul i64 %indvars.iv43, 7696581394432
  %sext45 = add i64 %397, 4123168604160
  %398 = ashr exact i64 %sext45, 32
  %399 = getelementptr inbounds float, float* %22, i64 %398
  %400 = bitcast float* %399 to <64 x float>*
  %401 = load <64 x float>, <64 x float>* %400, align 64, !tbaa !6341
  %402 = getelementptr inbounds i8, i8* %43, i64 3840
  %403 = bitcast i8* %402 to <64 x float>*
  %404 = load <64 x float>, <64 x float>* %403, align 64, !tbaa !6323
  %405 = fadd <64 x float> %348, %404
  %406 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %405, <64 x float> %351, <64 x float> %354)
  %407 = fadd <64 x float> %401, %406
  %408 = fcmp ogt <64 x float> %407, zeroinitializer
  %409 = select <64 x i1> %408, <64 x float> %407, <64 x float> zeroinitializer
  %410 = getelementptr inbounds float, float* %10, i64 %398
  %411 = bitcast float* %410 to <64 x float>*
  store <64 x float> %409, <64 x float>* %411, align 64, !tbaa !6344
  %412 = mul i64 %indvars.iv43, 7696581394432
  %sext59 = ashr exact i64 %412, 32
  %413 = or i64 %sext59, 128
  %414 = getelementptr inbounds float, float* %22, i64 %413
  %415 = bitcast float* %414 to <64 x float>*
  %416 = load <64 x float>, <64 x float>* %415, align 64, !tbaa !6341
  %417 = getelementptr inbounds i8, i8* %43, i64 512
  %418 = bitcast i8* %417 to <64 x float>*
  %419 = load <64 x float>, <64 x float>* %418, align 64, !tbaa !6323
  %420 = fadd <64 x float> %348, %419
  %421 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %420, <64 x float> %351, <64 x float> %354)
  %422 = fadd <64 x float> %416, %421
  %423 = fcmp ogt <64 x float> %422, zeroinitializer
  %424 = select <64 x i1> %423, <64 x float> %422, <64 x float> zeroinitializer
  %425 = getelementptr inbounds float, float* %10, i64 %413
  %426 = bitcast float* %425 to <64 x float>*
  store <64 x float> %424, <64 x float>* %426, align 64, !tbaa !6344
  %427 = mul i64 %indvars.iv43, 7696581394432
  %sext46 = ashr exact i64 %427, 32
  %428 = or i64 %sext46, 192
  %429 = getelementptr inbounds float, float* %22, i64 %428
  %430 = bitcast float* %429 to <64 x float>*
  %431 = load <64 x float>, <64 x float>* %430, align 64, !tbaa !6341
  %432 = getelementptr inbounds i8, i8* %43, i64 768
  %433 = bitcast i8* %432 to <64 x float>*
  %434 = load <64 x float>, <64 x float>* %433, align 64, !tbaa !6323
  %435 = fadd <64 x float> %348, %434
  %436 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %435, <64 x float> %351, <64 x float> %354)
  %437 = fadd <64 x float> %431, %436
  %438 = fcmp ogt <64 x float> %437, zeroinitializer
  %439 = select <64 x i1> %438, <64 x float> %437, <64 x float> zeroinitializer
  %440 = getelementptr inbounds float, float* %10, i64 %428
  %441 = bitcast float* %440 to <64 x float>*
  store <64 x float> %439, <64 x float>* %441, align 64, !tbaa !6344
  %442 = mul i64 %indvars.iv43, 7696581394432
  %sext60 = add i64 %442, 4398046511104
  %443 = ashr exact i64 %sext60, 32
  %444 = getelementptr inbounds float, float* %22, i64 %443
  %445 = bitcast float* %444 to <64 x float>*
  %446 = load <64 x float>, <64 x float>* %445, align 64, !tbaa !6341
  %447 = getelementptr inbounds i8, i8* %43, i64 4096
  %448 = bitcast i8* %447 to <64 x float>*
  %449 = load <64 x float>, <64 x float>* %448, align 64, !tbaa !6323
  %450 = fadd <64 x float> %348, %449
  %451 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %450, <64 x float> %351, <64 x float> %354)
  %452 = fadd <64 x float> %446, %451
  %453 = fcmp ogt <64 x float> %452, zeroinitializer
  %454 = select <64 x i1> %453, <64 x float> %452, <64 x float> zeroinitializer
  %455 = getelementptr inbounds float, float* %10, i64 %443
  %456 = bitcast float* %455 to <64 x float>*
  store <64 x float> %454, <64 x float>* %456, align 64, !tbaa !6344
  %457 = mul i64 %indvars.iv43, 7696581394432
  %sext47 = add i64 %457, 4672924418048
  %458 = ashr exact i64 %sext47, 32
  %459 = getelementptr inbounds float, float* %22, i64 %458
  %460 = bitcast float* %459 to <64 x float>*
  %461 = load <64 x float>, <64 x float>* %460, align 64, !tbaa !6341
  %462 = getelementptr inbounds i8, i8* %43, i64 4352
  %463 = bitcast i8* %462 to <64 x float>*
  %464 = load <64 x float>, <64 x float>* %463, align 64, !tbaa !6323
  %465 = fadd <64 x float> %348, %464
  %466 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %465, <64 x float> %351, <64 x float> %354)
  %467 = fadd <64 x float> %461, %466
  %468 = fcmp ogt <64 x float> %467, zeroinitializer
  %469 = select <64 x i1> %468, <64 x float> %467, <64 x float> zeroinitializer
  %470 = getelementptr inbounds float, float* %10, i64 %458
  %471 = bitcast float* %470 to <64 x float>*
  store <64 x float> %469, <64 x float>* %471, align 64, !tbaa !6344
  %472 = mul i64 %indvars.iv43, 7696581394432
  %sext61 = add i64 %472, 1099511627776
  %473 = ashr exact i64 %sext61, 32
  %474 = getelementptr inbounds float, float* %22, i64 %473
  %475 = bitcast float* %474 to <64 x float>*
  %476 = load <64 x float>, <64 x float>* %475, align 64, !tbaa !6341
  %477 = getelementptr inbounds i8, i8* %43, i64 1024
  %478 = bitcast i8* %477 to <64 x float>*
  %479 = load <64 x float>, <64 x float>* %478, align 64, !tbaa !6323
  %480 = fadd <64 x float> %348, %479
  %481 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %480, <64 x float> %351, <64 x float> %354)
  %482 = fadd <64 x float> %476, %481
  %483 = fcmp ogt <64 x float> %482, zeroinitializer
  %484 = select <64 x i1> %483, <64 x float> %482, <64 x float> zeroinitializer
  %485 = getelementptr inbounds float, float* %10, i64 %473
  %486 = bitcast float* %485 to <64 x float>*
  store <64 x float> %484, <64 x float>* %486, align 64, !tbaa !6344
  %487 = mul i64 %indvars.iv43, 7696581394432
  %sext48 = add i64 %487, 1374389534720
  %488 = ashr exact i64 %sext48, 32
  %489 = getelementptr inbounds float, float* %22, i64 %488
  %490 = bitcast float* %489 to <64 x float>*
  %491 = load <64 x float>, <64 x float>* %490, align 64, !tbaa !6341
  %492 = getelementptr inbounds i8, i8* %43, i64 1280
  %493 = bitcast i8* %492 to <64 x float>*
  %494 = load <64 x float>, <64 x float>* %493, align 64, !tbaa !6323
  %495 = fadd <64 x float> %348, %494
  %496 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %495, <64 x float> %351, <64 x float> %354)
  %497 = fadd <64 x float> %491, %496
  %498 = fcmp ogt <64 x float> %497, zeroinitializer
  %499 = select <64 x i1> %498, <64 x float> %497, <64 x float> zeroinitializer
  %500 = getelementptr inbounds float, float* %10, i64 %488
  %501 = bitcast float* %500 to <64 x float>*
  store <64 x float> %499, <64 x float>* %501, align 64, !tbaa !6344
  %502 = mul i64 %indvars.iv43, 7696581394432
  %sext62 = add i64 %502, 4947802324992
  %503 = ashr exact i64 %sext62, 32
  %504 = getelementptr inbounds float, float* %22, i64 %503
  %505 = bitcast float* %504 to <64 x float>*
  %506 = load <64 x float>, <64 x float>* %505, align 64, !tbaa !6341
  %507 = getelementptr inbounds i8, i8* %43, i64 4608
  %508 = bitcast i8* %507 to <64 x float>*
  %509 = load <64 x float>, <64 x float>* %508, align 64, !tbaa !6323
  %510 = fadd <64 x float> %348, %509
  %511 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %510, <64 x float> %351, <64 x float> %354)
  %512 = fadd <64 x float> %506, %511
  %513 = fcmp ogt <64 x float> %512, zeroinitializer
  %514 = select <64 x i1> %513, <64 x float> %512, <64 x float> zeroinitializer
  %515 = getelementptr inbounds float, float* %10, i64 %503
  %516 = bitcast float* %515 to <64 x float>*
  store <64 x float> %514, <64 x float>* %516, align 64, !tbaa !6344
  %517 = mul i64 %indvars.iv43, 7696581394432
  %sext49 = add i64 %517, 5222680231936
  %518 = ashr exact i64 %sext49, 32
  %519 = getelementptr inbounds float, float* %22, i64 %518
  %520 = bitcast float* %519 to <64 x float>*
  %521 = load <64 x float>, <64 x float>* %520, align 64, !tbaa !6341
  %522 = getelementptr inbounds i8, i8* %43, i64 4864
  %523 = bitcast i8* %522 to <64 x float>*
  %524 = load <64 x float>, <64 x float>* %523, align 64, !tbaa !6323
  %525 = fadd <64 x float> %348, %524
  %526 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %525, <64 x float> %351, <64 x float> %354)
  %527 = fadd <64 x float> %521, %526
  %528 = fcmp ogt <64 x float> %527, zeroinitializer
  %529 = select <64 x i1> %528, <64 x float> %527, <64 x float> zeroinitializer
  %530 = getelementptr inbounds float, float* %10, i64 %518
  %531 = bitcast float* %530 to <64 x float>*
  store <64 x float> %529, <64 x float>* %531, align 64, !tbaa !6344
  %532 = mul i64 %indvars.iv43, 7696581394432
  %sext63 = add i64 %532, 1649267441664
  %533 = ashr exact i64 %sext63, 32
  %534 = getelementptr inbounds float, float* %22, i64 %533
  %535 = bitcast float* %534 to <64 x float>*
  %536 = load <64 x float>, <64 x float>* %535, align 64, !tbaa !6341
  %537 = getelementptr inbounds i8, i8* %43, i64 1536
  %538 = bitcast i8* %537 to <64 x float>*
  %539 = load <64 x float>, <64 x float>* %538, align 64, !tbaa !6323
  %540 = fadd <64 x float> %348, %539
  %541 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %540, <64 x float> %351, <64 x float> %354)
  %542 = fadd <64 x float> %536, %541
  %543 = fcmp ogt <64 x float> %542, zeroinitializer
  %544 = select <64 x i1> %543, <64 x float> %542, <64 x float> zeroinitializer
  %545 = getelementptr inbounds float, float* %10, i64 %533
  %546 = bitcast float* %545 to <64 x float>*
  store <64 x float> %544, <64 x float>* %546, align 64, !tbaa !6344
  %547 = mul i64 %indvars.iv43, 7696581394432
  %sext50 = add i64 %547, 1924145348608
  %548 = ashr exact i64 %sext50, 32
  %549 = getelementptr inbounds float, float* %22, i64 %548
  %550 = bitcast float* %549 to <64 x float>*
  %551 = load <64 x float>, <64 x float>* %550, align 64, !tbaa !6341
  %552 = getelementptr inbounds i8, i8* %43, i64 1792
  %553 = bitcast i8* %552 to <64 x float>*
  %554 = load <64 x float>, <64 x float>* %553, align 64, !tbaa !6323
  %555 = fadd <64 x float> %348, %554
  %556 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %555, <64 x float> %351, <64 x float> %354)
  %557 = fadd <64 x float> %551, %556
  %558 = fcmp ogt <64 x float> %557, zeroinitializer
  %559 = select <64 x i1> %558, <64 x float> %557, <64 x float> zeroinitializer
  %560 = getelementptr inbounds float, float* %10, i64 %548
  %561 = bitcast float* %560 to <64 x float>*
  store <64 x float> %559, <64 x float>* %561, align 64, !tbaa !6344
  %562 = mul i64 %indvars.iv43, 7696581394432
  %sext64 = add i64 %562, 5497558138880
  %563 = ashr exact i64 %sext64, 32
  %564 = getelementptr inbounds float, float* %22, i64 %563
  %565 = bitcast float* %564 to <64 x float>*
  %566 = load <64 x float>, <64 x float>* %565, align 64, !tbaa !6341
  %567 = getelementptr inbounds i8, i8* %43, i64 5120
  %568 = bitcast i8* %567 to <64 x float>*
  %569 = load <64 x float>, <64 x float>* %568, align 64, !tbaa !6323
  %570 = fadd <64 x float> %348, %569
  %571 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %570, <64 x float> %351, <64 x float> %354)
  %572 = fadd <64 x float> %566, %571
  %573 = fcmp ogt <64 x float> %572, zeroinitializer
  %574 = select <64 x i1> %573, <64 x float> %572, <64 x float> zeroinitializer
  %575 = getelementptr inbounds float, float* %10, i64 %563
  %576 = bitcast float* %575 to <64 x float>*
  store <64 x float> %574, <64 x float>* %576, align 64, !tbaa !6344
  %577 = mul i64 %indvars.iv43, 7696581394432
  %sext51 = add i64 %577, 5772436045824
  %578 = ashr exact i64 %sext51, 32
  %579 = getelementptr inbounds float, float* %22, i64 %578
  %580 = bitcast float* %579 to <64 x float>*
  %581 = load <64 x float>, <64 x float>* %580, align 64, !tbaa !6341
  %582 = getelementptr inbounds i8, i8* %43, i64 5376
  %583 = bitcast i8* %582 to <64 x float>*
  %584 = load <64 x float>, <64 x float>* %583, align 64, !tbaa !6323
  %585 = fadd <64 x float> %348, %584
  %586 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %585, <64 x float> %351, <64 x float> %354)
  %587 = fadd <64 x float> %581, %586
  %588 = fcmp ogt <64 x float> %587, zeroinitializer
  %589 = select <64 x i1> %588, <64 x float> %587, <64 x float> zeroinitializer
  %590 = getelementptr inbounds float, float* %10, i64 %578
  %591 = bitcast float* %590 to <64 x float>*
  store <64 x float> %589, <64 x float>* %591, align 64, !tbaa !6344
  %592 = mul i64 %indvars.iv43, 7696581394432
  %sext65 = add i64 %592, 2199023255552
  %593 = ashr exact i64 %sext65, 32
  %594 = getelementptr inbounds float, float* %22, i64 %593
  %595 = bitcast float* %594 to <64 x float>*
  %596 = load <64 x float>, <64 x float>* %595, align 64, !tbaa !6341
  %597 = getelementptr inbounds i8, i8* %43, i64 2048
  %598 = bitcast i8* %597 to <64 x float>*
  %599 = load <64 x float>, <64 x float>* %598, align 64, !tbaa !6323
  %600 = fadd <64 x float> %348, %599
  %601 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %600, <64 x float> %351, <64 x float> %354)
  %602 = fadd <64 x float> %596, %601
  %603 = fcmp ogt <64 x float> %602, zeroinitializer
  %604 = select <64 x i1> %603, <64 x float> %602, <64 x float> zeroinitializer
  %605 = getelementptr inbounds float, float* %10, i64 %593
  %606 = bitcast float* %605 to <64 x float>*
  store <64 x float> %604, <64 x float>* %606, align 64, !tbaa !6344
  %607 = mul i64 %indvars.iv43, 7696581394432
  %sext52 = add i64 %607, 2473901162496
  %608 = ashr exact i64 %sext52, 32
  %609 = getelementptr inbounds float, float* %22, i64 %608
  %610 = bitcast float* %609 to <64 x float>*
  %611 = load <64 x float>, <64 x float>* %610, align 64, !tbaa !6341
  %612 = getelementptr inbounds i8, i8* %43, i64 2304
  %613 = bitcast i8* %612 to <64 x float>*
  %614 = load <64 x float>, <64 x float>* %613, align 64, !tbaa !6323
  %615 = fadd <64 x float> %348, %614
  %616 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %615, <64 x float> %351, <64 x float> %354)
  %617 = fadd <64 x float> %611, %616
  %618 = fcmp ogt <64 x float> %617, zeroinitializer
  %619 = select <64 x i1> %618, <64 x float> %617, <64 x float> zeroinitializer
  %620 = getelementptr inbounds float, float* %10, i64 %608
  %621 = bitcast float* %620 to <64 x float>*
  store <64 x float> %619, <64 x float>* %621, align 64, !tbaa !6344
  %622 = mul i64 %indvars.iv43, 7696581394432
  %sext66 = add i64 %622, 6047313952768
  %623 = ashr exact i64 %sext66, 32
  %624 = getelementptr inbounds float, float* %22, i64 %623
  %625 = bitcast float* %624 to <64 x float>*
  %626 = load <64 x float>, <64 x float>* %625, align 64, !tbaa !6341
  %627 = getelementptr inbounds i8, i8* %43, i64 5632
  %628 = bitcast i8* %627 to <64 x float>*
  %629 = load <64 x float>, <64 x float>* %628, align 64, !tbaa !6323
  %630 = fadd <64 x float> %348, %629
  %631 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %630, <64 x float> %351, <64 x float> %354)
  %632 = fadd <64 x float> %626, %631
  %633 = fcmp ogt <64 x float> %632, zeroinitializer
  %634 = select <64 x i1> %633, <64 x float> %632, <64 x float> zeroinitializer
  %635 = getelementptr inbounds float, float* %10, i64 %623
  %636 = bitcast float* %635 to <64 x float>*
  store <64 x float> %634, <64 x float>* %636, align 64, !tbaa !6344
  %637 = mul i64 %indvars.iv43, 7696581394432
  %sext53 = add i64 %637, 6322191859712
  %638 = ashr exact i64 %sext53, 32
  %639 = getelementptr inbounds float, float* %22, i64 %638
  %640 = bitcast float* %639 to <64 x float>*
  %641 = load <64 x float>, <64 x float>* %640, align 64, !tbaa !6341
  %642 = getelementptr inbounds i8, i8* %43, i64 5888
  %643 = bitcast i8* %642 to <64 x float>*
  %644 = load <64 x float>, <64 x float>* %643, align 64, !tbaa !6323
  %645 = fadd <64 x float> %348, %644
  %646 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %645, <64 x float> %351, <64 x float> %354)
  %647 = fadd <64 x float> %641, %646
  %648 = fcmp ogt <64 x float> %647, zeroinitializer
  %649 = select <64 x i1> %648, <64 x float> %647, <64 x float> zeroinitializer
  %650 = getelementptr inbounds float, float* %10, i64 %638
  %651 = bitcast float* %650 to <64 x float>*
  store <64 x float> %649, <64 x float>* %651, align 64, !tbaa !6344
  %652 = mul i64 %indvars.iv43, 7696581394432
  %sext67 = add i64 %652, 2748779069440
  %653 = ashr exact i64 %sext67, 32
  %654 = getelementptr inbounds float, float* %22, i64 %653
  %655 = bitcast float* %654 to <64 x float>*
  %656 = load <64 x float>, <64 x float>* %655, align 64, !tbaa !6341
  %657 = getelementptr inbounds i8, i8* %43, i64 2560
  %658 = bitcast i8* %657 to <64 x float>*
  %659 = load <64 x float>, <64 x float>* %658, align 64, !tbaa !6323
  %660 = fadd <64 x float> %348, %659
  %661 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %660, <64 x float> %351, <64 x float> %354)
  %662 = fadd <64 x float> %656, %661
  %663 = fcmp ogt <64 x float> %662, zeroinitializer
  %664 = select <64 x i1> %663, <64 x float> %662, <64 x float> zeroinitializer
  %665 = getelementptr inbounds float, float* %10, i64 %653
  %666 = bitcast float* %665 to <64 x float>*
  store <64 x float> %664, <64 x float>* %666, align 64, !tbaa !6344
  %667 = mul i64 %indvars.iv43, 7696581394432
  %sext54 = add i64 %667, 3023656976384
  %668 = ashr exact i64 %sext54, 32
  %669 = getelementptr inbounds float, float* %22, i64 %668
  %670 = bitcast float* %669 to <64 x float>*
  %671 = load <64 x float>, <64 x float>* %670, align 64, !tbaa !6341
  %672 = getelementptr inbounds i8, i8* %43, i64 2816
  %673 = bitcast i8* %672 to <64 x float>*
  %674 = load <64 x float>, <64 x float>* %673, align 64, !tbaa !6323
  %675 = fadd <64 x float> %348, %674
  %676 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %675, <64 x float> %351, <64 x float> %354)
  %677 = fadd <64 x float> %671, %676
  %678 = fcmp ogt <64 x float> %677, zeroinitializer
  %679 = select <64 x i1> %678, <64 x float> %677, <64 x float> zeroinitializer
  %680 = getelementptr inbounds float, float* %10, i64 %668
  %681 = bitcast float* %680 to <64 x float>*
  store <64 x float> %679, <64 x float>* %681, align 64, !tbaa !6344
  %682 = mul i64 %indvars.iv43, 7696581394432
  %sext68 = add i64 %682, 6597069766656
  %683 = ashr exact i64 %sext68, 32
  %684 = getelementptr inbounds float, float* %22, i64 %683
  %685 = bitcast float* %684 to <64 x float>*
  %686 = load <64 x float>, <64 x float>* %685, align 64, !tbaa !6341
  %687 = getelementptr inbounds i8, i8* %43, i64 6144
  %688 = bitcast i8* %687 to <64 x float>*
  %689 = load <64 x float>, <64 x float>* %688, align 64, !tbaa !6323
  %690 = fadd <64 x float> %348, %689
  %691 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %690, <64 x float> %351, <64 x float> %354)
  %692 = fadd <64 x float> %686, %691
  %693 = fcmp ogt <64 x float> %692, zeroinitializer
  %694 = select <64 x i1> %693, <64 x float> %692, <64 x float> zeroinitializer
  %695 = getelementptr inbounds float, float* %10, i64 %683
  %696 = bitcast float* %695 to <64 x float>*
  store <64 x float> %694, <64 x float>* %696, align 64, !tbaa !6344
  %697 = mul i64 %indvars.iv43, 7696581394432
  %sext55 = add i64 %697, 6871947673600
  %698 = ashr exact i64 %sext55, 32
  %699 = getelementptr inbounds float, float* %22, i64 %698
  %700 = bitcast float* %699 to <64 x float>*
  %701 = load <64 x float>, <64 x float>* %700, align 64, !tbaa !6341
  %702 = getelementptr inbounds i8, i8* %43, i64 6400
  %703 = bitcast i8* %702 to <64 x float>*
  %704 = load <64 x float>, <64 x float>* %703, align 64, !tbaa !6323
  %705 = fadd <64 x float> %348, %704
  %706 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %705, <64 x float> %351, <64 x float> %354)
  %707 = fadd <64 x float> %701, %706
  %708 = fcmp ogt <64 x float> %707, zeroinitializer
  %709 = select <64 x i1> %708, <64 x float> %707, <64 x float> zeroinitializer
  %710 = getelementptr inbounds float, float* %10, i64 %698
  %711 = bitcast float* %710 to <64 x float>*
  store <64 x float> %709, <64 x float>* %711, align 64, !tbaa !6344
  %712 = mul i64 %indvars.iv43, 7696581394432
  %sext69 = add i64 %712, 3298534883328
  %713 = ashr exact i64 %sext69, 32
  %714 = getelementptr inbounds float, float* %22, i64 %713
  %715 = bitcast float* %714 to <64 x float>*
  %716 = load <64 x float>, <64 x float>* %715, align 64, !tbaa !6341
  %717 = getelementptr inbounds i8, i8* %43, i64 3072
  %718 = bitcast i8* %717 to <64 x float>*
  %719 = load <64 x float>, <64 x float>* %718, align 64, !tbaa !6323
  %720 = fadd <64 x float> %348, %719
  %721 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %720, <64 x float> %351, <64 x float> %354)
  %722 = fadd <64 x float> %716, %721
  %723 = fcmp ogt <64 x float> %722, zeroinitializer
  %724 = select <64 x i1> %723, <64 x float> %722, <64 x float> zeroinitializer
  %725 = getelementptr inbounds float, float* %10, i64 %713
  %726 = bitcast float* %725 to <64 x float>*
  store <64 x float> %724, <64 x float>* %726, align 64, !tbaa !6344
  %727 = mul i64 %indvars.iv43, 7696581394432
  %sext56 = add i64 %727, 3573412790272
  %728 = ashr exact i64 %sext56, 32
  %729 = getelementptr inbounds float, float* %22, i64 %728
  %730 = bitcast float* %729 to <64 x float>*
  %731 = load <64 x float>, <64 x float>* %730, align 64, !tbaa !6341
  %732 = getelementptr inbounds i8, i8* %43, i64 3328
  %733 = bitcast i8* %732 to <64 x float>*
  %734 = load <64 x float>, <64 x float>* %733, align 64, !tbaa !6323
  %735 = fadd <64 x float> %348, %734
  %736 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %735, <64 x float> %351, <64 x float> %354)
  %737 = fadd <64 x float> %731, %736
  %738 = fcmp ogt <64 x float> %737, zeroinitializer
  %739 = select <64 x i1> %738, <64 x float> %737, <64 x float> zeroinitializer
  %740 = getelementptr inbounds float, float* %10, i64 %728
  %741 = bitcast float* %740 to <64 x float>*
  store <64 x float> %739, <64 x float>* %741, align 64, !tbaa !6344
  %742 = mul i64 %indvars.iv43, 7696581394432
  %sext70 = add i64 %742, 7146825580544
  %743 = ashr exact i64 %sext70, 32
  %744 = getelementptr inbounds float, float* %22, i64 %743
  %745 = bitcast float* %744 to <64 x float>*
  %746 = load <64 x float>, <64 x float>* %745, align 64, !tbaa !6341
  %747 = getelementptr inbounds i8, i8* %43, i64 6656
  %748 = bitcast i8* %747 to <64 x float>*
  %749 = load <64 x float>, <64 x float>* %748, align 64, !tbaa !6323
  %750 = fadd <64 x float> %348, %749
  %751 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %750, <64 x float> %351, <64 x float> %354)
  %752 = fadd <64 x float> %746, %751
  %753 = fcmp ogt <64 x float> %752, zeroinitializer
  %754 = select <64 x i1> %753, <64 x float> %752, <64 x float> zeroinitializer
  %755 = getelementptr inbounds float, float* %10, i64 %743
  %756 = bitcast float* %755 to <64 x float>*
  store <64 x float> %754, <64 x float>* %756, align 64, !tbaa !6344
  %757 = mul i64 %indvars.iv43, 7696581394432
  %sext57 = add i64 %757, 7421703487488
  %758 = ashr exact i64 %sext57, 32
  %759 = getelementptr inbounds float, float* %22, i64 %758
  %760 = bitcast float* %759 to <64 x float>*
  %761 = load <64 x float>, <64 x float>* %760, align 64, !tbaa !6341
  %762 = getelementptr inbounds i8, i8* %43, i64 6912
  %763 = bitcast i8* %762 to <64 x float>*
  %764 = load <64 x float>, <64 x float>* %763, align 64, !tbaa !6323
  %765 = fadd <64 x float> %348, %764
  %766 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %765, <64 x float> %351, <64 x float> %354)
  %767 = fadd <64 x float> %761, %766
  %768 = fcmp ogt <64 x float> %767, zeroinitializer
  %769 = select <64 x i1> %768, <64 x float> %767, <64 x float> zeroinitializer
  %770 = getelementptr inbounds float, float* %10, i64 %758
  %771 = bitcast float* %770 to <64 x float>*
  store <64 x float> %769, <64 x float>* %771, align 64, !tbaa !6344
  %772 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %773 = tail call i32 %772(i32 1, i32 %25, i8* nonnull %43)
  %indvars.iv.next44 = add nsw i64 %indvars.iv43, 1
  %774 = icmp slt i64 %indvars.iv.next44, %41
  br i1 %774, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 6
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([101 x i8], [101 x i8]* @.str.462, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !6347
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !6361
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !6364
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !6366
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !6370
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.463, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %77 = getelementptr inbounds i8, i8* %1, i64 4
  %78 = bitcast i8* %77 to i32*
  %79 = load i32, i32* %78, align 4, !tbaa !6372
  switch i32 %79, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.464, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %81 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %81(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.465, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.466, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %83 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %83(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.467, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.468, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  %85 = icmp eq i32 %43, 1
  br i1 %85, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %86 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %86(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %87 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %88 = load i32, i32* %87, align 4
  %89 = icmp eq i32 %88, 5
  br i1 %89, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %91 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %92 = load i16, i16* %91, align 2
  %93 = icmp eq i16 %92, 1
  %94 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %95 = load i8, i8* %94, align 1
  %96 = icmp eq i8 %95, 32
  %97 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %98 = load i8, i8* %97, align 1
  %99 = icmp eq i8 %98, 2
  %100 = and i1 %96, %99
  %101 = and i1 %93, %100
  br i1 %101, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %103 = load i64, i64* %39, align 8, !tbaa !6374
  %104 = trunc i64 %103 to i32
  %105 = icmp eq i32 %104, 1
  br i1 %105, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %107 = getelementptr inbounds i64, i64* %39, i64 1
  %108 = load i64, i64* %107, align 8, !tbaa !6388
  %109 = trunc i64 %108 to i32
  %110 = icmp eq i32 %109, 1
  br i1 %110, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %111 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %111(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %112 = getelementptr inbounds i64, i64* %39, i64 2
  %113 = load i64, i64* %112, align 8, !tbaa !6390
  %114 = trunc i64 %113 to i32
  %115 = icmp eq i32 %114, 28
  br i1 %115, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %116 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %116(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %117 = getelementptr inbounds i64, i64* %39, i64 3
  %118 = load i64, i64* %117, align 8, !tbaa !6393
  %119 = trunc i64 %118 to i32
  %120 = icmp eq i32 %119, 28
  br i1 %120, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %121 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %121(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %122 = getelementptr inbounds i64, i64* %39, i64 4
  %123 = load i64, i64* %122, align 8, !tbaa !6395
  %124 = trunc i64 %123 to i32
  %125 = icmp eq i32 %124, 512
  br i1 %125, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %126 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %126(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %127 = icmp eq i64* %41, null
  br i1 %127, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end28
  %128 = bitcast i64* %41 to <4 x i64>*
  %129 = load <4 x i64>, <4 x i64>* %128, align 8, !tbaa !6399
  %130 = trunc <4 x i64> %129 to <4 x i32>
  %131 = icmp eq <4 x i32> %130, <i32 401408, i32 401408, i32 14336, i32 512>
  %132 = getelementptr inbounds i64, i64* %41, i64 4
  %133 = load i64, i64* %132, align 8, !tbaa !6411
  %134 = trunc i64 %133 to i32
  %135 = icmp eq i32 %134, 1
  %rdx.shuf167 = shufflevector <4 x i1> %131, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx168 = and <4 x i1> %131, %rdx.shuf167
  %rdx.shuf169 = shufflevector <4 x i1> %bin.rdx168, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx170 = and <4 x i1> %bin.rdx168, %rdx.shuf169
  %136 = extractelement <4 x i1> %bin.rdx170, i32 0
  %137 = and i1 %136, %135
  br i1 %137, label %if_end, label %assert_fail29, !prof !5

if_end:                                           ; preds = %assert_end28, %if_then
  %138 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %139 = load i64, i64* %138, align 8
  %140 = icmp eq i64 %139, 0
  br i1 %140, label %assert_end32, label %assert_fail31, !prof !5

assert_fail29:                                    ; preds = %if_then
  %141 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %141(i8* getelementptr inbounds ([243 x i8], [243 x i8]* @.str.225, i64 0, i64 0))
  ret i32 -1

assert_fail31:                                    ; preds = %if_end
  %142 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %142(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %if_end
  %143 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %144 = load i32, i32* %143, align 4
  %145 = icmp eq i32 %144, 6
  br i1 %145, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %148 = load i16, i16* %147, align 2
  %149 = icmp eq i16 %148, 1
  %150 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %151 = load i8, i8* %150, align 1
  %152 = icmp eq i8 %151, 32
  %153 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %154 = load i8, i8* %153, align 1
  %155 = icmp eq i8 %154, 2
  %156 = and i1 %152, %155
  %157 = and i1 %149, %156
  br i1 %157, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %159 = load i64, i64* %49, align 8, !tbaa !6415
  %160 = trunc i64 %159 to i32
  %161 = icmp eq i32 %160, 16
  br i1 %161, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %162 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %162(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %163 = getelementptr inbounds i64, i64* %49, i64 1
  %164 = load i64, i64* %163, align 8, !tbaa !6429
  %165 = trunc i64 %164 to i32
  %166 = icmp eq i32 %165, 1
  br i1 %166, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %167 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %167(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %168 = getelementptr inbounds i64, i64* %49, i64 2
  %169 = load i64, i64* %168, align 8, !tbaa !6431
  %170 = trunc i64 %169 to i32
  %171 = icmp eq i32 %170, 1
  br i1 %171, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %172 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %172(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %173 = getelementptr inbounds i64, i64* %49, i64 3
  %174 = load i64, i64* %173, align 8, !tbaa !6434
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  br i1 %176, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %177 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %177(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %178 = getelementptr inbounds i64, i64* %49, i64 4
  %179 = load i64, i64* %178, align 8, !tbaa !6436
  %180 = trunc i64 %179 to i32
  %181 = icmp eq i32 %180, 512
  br i1 %181, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %182 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %182(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %183 = getelementptr inbounds i64, i64* %49, i64 5
  %184 = load i64, i64* %183, align 8, !tbaa !6440
  %185 = trunc i64 %184 to i32
  %186 = icmp eq i32 %185, 64
  br i1 %186, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %187 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %187(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.227, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %188 = icmp eq i64* %51, null
  br i1 %188, label %if_end50, label %if_then49, !prof !50

if_then49:                                        ; preds = %assert_end48
  %189 = bitcast i64* %51 to <4 x i64>*
  %190 = load <4 x i64>, <4 x i64>* %189, align 8, !tbaa !6442
  %191 = trunc <4 x i64> %190 to <4 x i32>
  %192 = icmp eq <4 x i32> %191, <i32 32768, i32 32768, i32 32768, i32 32768>
  %193 = getelementptr inbounds i64, i64* %51, i64 4
  %194 = load i64, i64* %193, align 8, !tbaa !6454
  %195 = trunc i64 %194 to i32
  %196 = icmp eq i32 %195, 64
  %197 = getelementptr inbounds i64, i64* %51, i64 5
  %198 = load i64, i64* %197, align 8, !tbaa !6458
  %199 = trunc i64 %198 to i32
  %200 = icmp eq i32 %199, 1
  %rdx.shuf163 = shufflevector <4 x i1> %192, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx164 = and <4 x i1> %192, %rdx.shuf163
  %rdx.shuf165 = shufflevector <4 x i1> %bin.rdx164, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx166 = and <4 x i1> %bin.rdx164, %rdx.shuf165
  %201 = extractelement <4 x i1> %bin.rdx166, i32 0
  %202 = and i1 %201, %196
  %203 = and i1 %202, %200
  br i1 %203, label %if_end50, label %assert_fail51, !prof !5

if_end50:                                         ; preds = %assert_end48, %if_then49
  %204 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %205 = load i64, i64* %204, align 8
  %206 = icmp eq i64 %205, 0
  br i1 %206, label %assert_end54, label %assert_fail53, !prof !5

assert_fail51:                                    ; preds = %if_then49
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([279 x i8], [279 x i8]* @.str.228, i64 0, i64 0))
  ret i32 -1

assert_fail53:                                    ; preds = %if_end50
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %if_end50
  %209 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %210 = load i32, i32* %209, align 4
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %213 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %214 = load i32, i32* %213, align 4
  %215 = icmp eq i32 %45, %214
  br i1 %215, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %216 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %216(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %217 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %218 = load i32, i32* %217, align 4
  %219 = icmp eq i32 %218, 4
  br i1 %219, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %221 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %222 = load i16, i16* %221, align 2
  %223 = icmp eq i16 %222, 1
  %224 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %225 = load i8, i8* %224, align 1
  %226 = icmp eq i8 %225, 32
  %227 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %228 = load i8, i8* %227, align 1
  %229 = icmp eq i8 %228, 2
  %230 = and i1 %226, %229
  %231 = and i1 %223, %230
  br i1 %231, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %233 = load i64, i64* %55, align 8, !tbaa !6460
  %234 = trunc i64 %233 to i32
  %235 = icmp eq i32 %234, 16
  br i1 %235, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %236 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %236(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %237 = getelementptr inbounds i64, i64* %55, i64 1
  %238 = load i64, i64* %237, align 8, !tbaa !6474
  %239 = trunc i64 %238 to i32
  %240 = icmp eq i32 %239, 1
  br i1 %240, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %241 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %241(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %242 = getelementptr inbounds i64, i64* %55, i64 2
  %243 = load i64, i64* %242, align 8, !tbaa !6476
  %244 = trunc i64 %243 to i32
  %245 = icmp eq i32 %244, 1
  br i1 %245, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %246 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %246(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %247 = getelementptr inbounds i64, i64* %55, i64 3
  %248 = load i64, i64* %247, align 8, !tbaa !6479
  %249 = trunc i64 %248 to i32
  %250 = icmp eq i32 %249, 64
  br i1 %250, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %251 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %251(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.229, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %252 = icmp eq i64* %57, null
  br i1 %252, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %253 = bitcast i64* %57 to <4 x i64>*
  %254 = load <4 x i64>, <4 x i64>* %253, align 8, !tbaa !6481
  %255 = trunc <4 x i64> %254 to <4 x i32>
  %256 = icmp eq <4 x i32> %255, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf159 = shufflevector <4 x i1> %256, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx160 = and <4 x i1> %256, %rdx.shuf159
  %rdx.shuf161 = shufflevector <4 x i1> %bin.rdx160, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx162 = and <4 x i1> %bin.rdx160, %rdx.shuf161
  %257 = extractelement <4 x i1> %bin.rdx162, i32 0
  br i1 %257, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %258 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %259 = load i64, i64* %258, align 8
  %260 = icmp eq i64 %259, 0
  br i1 %260, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.230, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %262 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %262(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %263 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %264 = load i32, i32* %263, align 4
  %265 = icmp eq i32 %264, 1
  br i1 %265, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %266 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %266(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %267 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %268 = load i32, i32* %267, align 4
  %269 = icmp eq i32 %45, %268
  br i1 %269, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %270 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %270(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %271 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %272 = load i32, i32* %271, align 4
  %273 = icmp eq i32 %272, 4
  br i1 %273, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %275 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %276 = load i16, i16* %275, align 2
  %277 = icmp eq i16 %276, 1
  %278 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %279 = load i8, i8* %278, align 1
  %280 = icmp eq i8 %279, 32
  %281 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %282 = load i8, i8* %281, align 1
  %283 = icmp eq i8 %282, 2
  %284 = and i1 %280, %283
  %285 = and i1 %277, %284
  br i1 %285, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %287 = load i64, i64* %61, align 8, !tbaa !6493
  %288 = trunc i64 %287 to i32
  %289 = icmp eq i32 %288, 16
  br i1 %289, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %290 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %290(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.250, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %291 = getelementptr inbounds i64, i64* %61, i64 1
  %292 = load i64, i64* %291, align 8, !tbaa !6507
  %293 = trunc i64 %292 to i32
  %294 = icmp eq i32 %293, 1
  br i1 %294, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %295 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %295(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %296 = getelementptr inbounds i64, i64* %61, i64 2
  %297 = load i64, i64* %296, align 8, !tbaa !6509
  %298 = trunc i64 %297 to i32
  %299 = icmp eq i32 %298, 1
  br i1 %299, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %300 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %300(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %301 = getelementptr inbounds i64, i64* %61, i64 3
  %302 = load i64, i64* %301, align 8, !tbaa !6512
  %303 = trunc i64 %302 to i32
  %304 = icmp eq i32 %303, 64
  br i1 %304, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %305 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %305(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.231, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %306 = icmp eq i64* %63, null
  br i1 %306, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %307 = bitcast i64* %63 to <4 x i64>*
  %308 = load <4 x i64>, <4 x i64>* %307, align 8, !tbaa !6514
  %309 = trunc <4 x i64> %308 to <4 x i32>
  %310 = icmp eq <4 x i32> %309, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf155 = shufflevector <4 x i1> %310, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx156 = and <4 x i1> %310, %rdx.shuf155
  %rdx.shuf157 = shufflevector <4 x i1> %bin.rdx156, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx158 = and <4 x i1> %bin.rdx156, %rdx.shuf157
  %311 = extractelement <4 x i1> %bin.rdx158, i32 0
  br i1 %311, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %312 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %313 = load i64, i64* %312, align 8
  %314 = icmp eq i64 %313, 0
  br i1 %314, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.232, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %317 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %318, 1
  br i1 %319, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %321 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %322 = load i32, i32* %321, align 4
  %323 = icmp eq i32 %45, %322
  br i1 %323, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %325 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %326 = load i32, i32* %325, align 4
  %327 = icmp eq i32 %326, 4
  br i1 %327, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %329 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %330 = load i16, i16* %329, align 2
  %331 = icmp eq i16 %330, 1
  %332 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %333 = load i8, i8* %332, align 1
  %334 = icmp eq i8 %333, 32
  %335 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %336 = load i8, i8* %335, align 1
  %337 = icmp eq i8 %336, 2
  %338 = and i1 %334, %337
  %339 = and i1 %331, %338
  br i1 %339, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %340 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %340(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %341 = load i64, i64* %67, align 8, !tbaa !6526
  %342 = trunc i64 %341 to i32
  %343 = icmp eq i32 %342, 16
  br i1 %343, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %344 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %344(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.451, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %345 = getelementptr inbounds i64, i64* %67, i64 1
  %346 = load i64, i64* %345, align 8, !tbaa !6540
  %347 = trunc i64 %346 to i32
  %348 = icmp eq i32 %347, 1
  br i1 %348, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %350 = getelementptr inbounds i64, i64* %67, i64 2
  %351 = load i64, i64* %350, align 8, !tbaa !6542
  %352 = trunc i64 %351 to i32
  %353 = icmp eq i32 %352, 1
  br i1 %353, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %354 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %354(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %355 = getelementptr inbounds i64, i64* %67, i64 3
  %356 = load i64, i64* %355, align 8, !tbaa !6545
  %357 = trunc i64 %356 to i32
  %358 = icmp eq i32 %357, 64
  br i1 %358, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %359 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %359(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.291, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %360 = icmp eq i64* %69, null
  br i1 %360, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %361 = bitcast i64* %69 to <4 x i64>*
  %362 = load <4 x i64>, <4 x i64>* %361, align 8, !tbaa !6547
  %363 = trunc <4 x i64> %362 to <4 x i32>
  %364 = icmp eq <4 x i32> %363, <i32 64, i32 64, i32 64, i32 1>
  %rdx.shuf151 = shufflevector <4 x i1> %364, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx152 = and <4 x i1> %364, %rdx.shuf151
  %rdx.shuf153 = shufflevector <4 x i1> %bin.rdx152, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx154 = and <4 x i1> %bin.rdx152, %rdx.shuf153
  %365 = extractelement <4 x i1> %bin.rdx154, i32 0
  br i1 %365, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %366 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %367 = load i64, i64* %366, align 8
  %368 = icmp eq i64 %367, 0
  br i1 %368, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %369 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %369(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.292, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %370 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %370(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %371 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %372 = load i32, i32* %371, align 4
  %373 = icmp eq i32 %372, 1
  br i1 %373, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %374 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %374(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %375 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %376 = load i32, i32* %375, align 4
  %377 = icmp eq i32 %45, %376
  br i1 %377, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %378 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %378(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %379 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %380 = load i32, i32* %379, align 4
  %381 = icmp eq i32 %380, 5
  br i1 %381, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %383 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %384 = load i16, i16* %383, align 2
  %385 = icmp eq i16 %384, 1
  %386 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %387 = load i8, i8* %386, align 1
  %388 = icmp eq i8 %387, 32
  %389 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %390 = load i8, i8* %389, align 1
  %391 = icmp eq i8 %390, 2
  %392 = and i1 %388, %391
  %393 = and i1 %385, %392
  br i1 %393, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %394 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %394(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %395 = load i64, i64* %73, align 8, !tbaa !6559
  %396 = trunc i64 %395 to i32
  %397 = icmp eq i32 %396, 1
  br i1 %397, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %398 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %398(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %399 = getelementptr inbounds i64, i64* %73, i64 1
  %400 = load i64, i64* %399, align 8, !tbaa !6573
  %401 = trunc i64 %400 to i32
  %402 = icmp eq i32 %401, 16
  br i1 %402, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %403 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %403(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.452, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %404 = getelementptr inbounds i64, i64* %73, i64 2
  %405 = load i64, i64* %404, align 8, !tbaa !6575
  %406 = trunc i64 %405 to i32
  %407 = icmp eq i32 %406, 14
  br i1 %407, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %408 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %408(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.453, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %409 = getelementptr inbounds i64, i64* %73, i64 3
  %410 = load i64, i64* %409, align 8, !tbaa !6578
  %411 = trunc i64 %410 to i32
  %412 = icmp eq i32 %411, 14
  br i1 %412, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %413 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %413(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.454, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %414 = getelementptr inbounds i64, i64* %73, i64 4
  %415 = load i64, i64* %414, align 8, !tbaa !6580
  %416 = trunc i64 %415 to i32
  %417 = icmp eq i32 %416, 64
  br i1 %417, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %418 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %418(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.295, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %419 = icmp eq i64* %75, null
  br i1 %419, label %if_end140, label %if_then139, !prof !50

if_then139:                                       ; preds = %assert_end138
  %420 = bitcast i64* %75 to <4 x i64>*
  %421 = load <4 x i64>, <4 x i64>* %420, align 8, !tbaa !6584
  %422 = trunc <4 x i64> %421 to <4 x i32>
  %423 = icmp eq <4 x i32> %422, <i32 200704, i32 12544, i32 896, i32 64>
  %424 = getelementptr inbounds i64, i64* %75, i64 4
  %425 = load i64, i64* %424, align 8, !tbaa !6596
  %426 = trunc i64 %425 to i32
  %427 = icmp eq i32 %426, 1
  %rdx.shuf = shufflevector <4 x i1> %423, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %423, %rdx.shuf
  %rdx.shuf149 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx150 = and <4 x i1> %bin.rdx, %rdx.shuf149
  %428 = extractelement <4 x i1> %bin.rdx150, i32 0
  %429 = and i1 %428, %427
  br i1 %429, label %if_end140, label %assert_fail141, !prof !5

if_end140:                                        ; preds = %assert_end138, %if_then139
  %430 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %431 = load i64, i64* %430, align 8
  %432 = icmp eq i64 %431, 0
  br i1 %432, label %assert_end144, label %assert_fail143, !prof !5

assert_fail141:                                   ; preds = %if_then139
  %433 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %433(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.455, i64 0, i64 0))
  ret i32 -1

assert_fail143:                                   ; preds = %if_end140
  %434 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %434(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end144:                                    ; preds = %if_end140
  %435 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %436 = load i32, i32* %435, align 4
  %437 = icmp eq i32 %436, 1
  br i1 %437, label %assert_end146, label %assert_fail145, !prof !5

assert_fail145:                                   ; preds = %assert_end144
  %438 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %438(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %assert_end144
  %439 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %440 = load i32, i32* %439, align 4
  %441 = icmp eq i32 %45, %440
  br i1 %441, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %442 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %442(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %443 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2_compute_(i8* %37, i8* %47, i8* %71, i8* %53, i8* %59, i8* %65, i32 %45)
  ret i32 %443
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %40, align 8
  %8 = getelementptr inbounds %40, %40* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %40, %40* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %40, %40* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %40, %40* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %40, %40* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %40, %40* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %40, %40* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %40* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.469, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.469(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 111
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 112
  %30 = select i1 %29, i32 %28, i32 112
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 112
  %33 = select i1 %32, i32 %31, i32 112
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end6.6
  %indvars.iv43 = phi i64 [ %37, %for_body.preheader ], [ %indvars.iv.next44, %for_end6.6 ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %40 = tail call i8* %39(i32 1, i32 %22, i64 7168, i32 2, i32 32)
  %41 = trunc i64 %indvars.iv43 to i32
  %42 = srem i32 %41, 7
  %43 = mul nsw i32 %42, 57344
  %44 = sdiv i32 %41, 7
  %45 = shl i32 %44, 15
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  %48 = bitcast i8* %40 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %48, align 64, !tbaa !6600
  %49 = getelementptr inbounds i8, i8* %40, i64 256
  %50 = bitcast i8* %49 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %50, align 64, !tbaa !6600
  %51 = getelementptr inbounds i8, i8* %40, i64 3584
  %52 = bitcast i8* %51 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %52, align 64, !tbaa !6600
  %53 = getelementptr inbounds i8, i8* %40, i64 3840
  %54 = bitcast i8* %53 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %54, align 64, !tbaa !6600
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %55 = phi <64 x float> [ zeroinitializer, %for_body ], [ %87, %for_body5 ]
  %56 = phi <64 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %57 = phi <64 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %58 = phi <64 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %59 = add nsw i64 %indvars.iv, %47
  %60 = getelementptr inbounds float, float* %4, i64 %59
  %61 = load float, float* %60, align 4, !tbaa !6603
  %62 = insertelement <64 x float> undef, float %61, i32 0
  %63 = shufflevector <64 x float> %62, <64 x float> undef, <64 x i32> zeroinitializer
  %64 = shl i64 %indvars.iv, 6
  %65 = add nuw nsw i64 %64, %46
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <64 x float>*
  %68 = load <64 x float>, <64 x float>* %67, align 64, !tbaa !6606
  %69 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %63, <64 x float> %68, <64 x float> %58)
  %70 = add nsw i64 %59, 1024
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !6603
  %73 = insertelement <64 x float> undef, float %72, i32 0
  %74 = shufflevector <64 x float> %73, <64 x float> undef, <64 x i32> zeroinitializer
  %75 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %74, <64 x float> %68, <64 x float> %57)
  %76 = add nsw i64 %59, 28672
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !6603
  %79 = insertelement <64 x float> undef, float %78, i32 0
  %80 = shufflevector <64 x float> %79, <64 x float> undef, <64 x i32> zeroinitializer
  %81 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %80, <64 x float> %68, <64 x float> %56)
  %82 = add nsw i64 %59, 29696
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !6603
  %85 = insertelement <64 x float> undef, float %84, i32 0
  %86 = shufflevector <64 x float> %85, <64 x float> undef, <64 x i32> zeroinitializer
  %87 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %86, <64 x float> %68, <64 x float> %55)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  store <64 x float> %69, <64 x float>* %48, align 64, !tbaa !6600
  store <64 x float> %75, <64 x float>* %50, align 64, !tbaa !6600
  store <64 x float> %81, <64 x float>* %52, align 64, !tbaa !6600
  store <64 x float> %87, <64 x float>* %54, align 64, !tbaa !6600
  %88 = getelementptr inbounds i8, i8* %40, i64 512
  %89 = bitcast i8* %88 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %89, align 64, !tbaa !6600
  %90 = getelementptr inbounds i8, i8* %40, i64 768
  %91 = bitcast i8* %90 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %91, align 64, !tbaa !6600
  %92 = getelementptr inbounds i8, i8* %40, i64 4096
  %93 = bitcast i8* %92 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %93, align 64, !tbaa !6600
  %94 = getelementptr inbounds i8, i8* %40, i64 4352
  %95 = bitcast i8* %94 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %95, align 64, !tbaa !6600
  %96 = or i64 %47, 2048
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %97 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %129, %for_body5.1 ]
  %98 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %123, %for_body5.1 ]
  %99 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %117, %for_body5.1 ]
  %100 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %111, %for_body5.1 ]
  %101 = add nsw i64 %96, %indvars.iv.1
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !6603
  %104 = insertelement <64 x float> undef, float %103, i32 0
  %105 = shufflevector <64 x float> %104, <64 x float> undef, <64 x i32> zeroinitializer
  %106 = shl i64 %indvars.iv.1, 6
  %107 = add nuw nsw i64 %106, %46
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to <64 x float>*
  %110 = load <64 x float>, <64 x float>* %109, align 64, !tbaa !6606
  %111 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %105, <64 x float> %110, <64 x float> %100)
  %112 = add nsw i64 %101, 1024
  %113 = getelementptr inbounds float, float* %4, i64 %112
  %114 = load float, float* %113, align 4, !tbaa !6603
  %115 = insertelement <64 x float> undef, float %114, i32 0
  %116 = shufflevector <64 x float> %115, <64 x float> undef, <64 x i32> zeroinitializer
  %117 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %116, <64 x float> %110, <64 x float> %99)
  %118 = add nsw i64 %101, 28672
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = load float, float* %119, align 4, !tbaa !6603
  %121 = insertelement <64 x float> undef, float %120, i32 0
  %122 = shufflevector <64 x float> %121, <64 x float> undef, <64 x i32> zeroinitializer
  %123 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %122, <64 x float> %110, <64 x float> %98)
  %124 = add nsw i64 %101, 29696
  %125 = getelementptr inbounds float, float* %4, i64 %124
  %126 = load float, float* %125, align 4, !tbaa !6603
  %127 = insertelement <64 x float> undef, float %126, i32 0
  %128 = shufflevector <64 x float> %127, <64 x float> undef, <64 x i32> zeroinitializer
  %129 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %128, <64 x float> %110, <64 x float> %97)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %111, <64 x float>* %89, align 64, !tbaa !6600
  store <64 x float> %117, <64 x float>* %91, align 64, !tbaa !6600
  store <64 x float> %123, <64 x float>* %93, align 64, !tbaa !6600
  store <64 x float> %129, <64 x float>* %95, align 64, !tbaa !6600
  %130 = getelementptr inbounds i8, i8* %40, i64 1024
  %131 = bitcast i8* %130 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %131, align 64, !tbaa !6600
  %132 = getelementptr inbounds i8, i8* %40, i64 1280
  %133 = bitcast i8* %132 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %133, align 64, !tbaa !6600
  %134 = getelementptr inbounds i8, i8* %40, i64 4608
  %135 = bitcast i8* %134 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %135, align 64, !tbaa !6600
  %136 = getelementptr inbounds i8, i8* %40, i64 4864
  %137 = bitcast i8* %136 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %137, align 64, !tbaa !6600
  %138 = or i64 %47, 4096
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %139 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %171, %for_body5.2 ]
  %140 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %165, %for_body5.2 ]
  %141 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %159, %for_body5.2 ]
  %142 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %153, %for_body5.2 ]
  %143 = add nsw i64 %138, %indvars.iv.2
  %144 = getelementptr inbounds float, float* %4, i64 %143
  %145 = load float, float* %144, align 4, !tbaa !6603
  %146 = insertelement <64 x float> undef, float %145, i32 0
  %147 = shufflevector <64 x float> %146, <64 x float> undef, <64 x i32> zeroinitializer
  %148 = shl i64 %indvars.iv.2, 6
  %149 = add nuw nsw i64 %148, %46
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <64 x float>*
  %152 = load <64 x float>, <64 x float>* %151, align 64, !tbaa !6606
  %153 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %147, <64 x float> %152, <64 x float> %142)
  %154 = add nsw i64 %143, 1024
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !6603
  %157 = insertelement <64 x float> undef, float %156, i32 0
  %158 = shufflevector <64 x float> %157, <64 x float> undef, <64 x i32> zeroinitializer
  %159 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %158, <64 x float> %152, <64 x float> %141)
  %160 = add nsw i64 %143, 28672
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !6603
  %163 = insertelement <64 x float> undef, float %162, i32 0
  %164 = shufflevector <64 x float> %163, <64 x float> undef, <64 x i32> zeroinitializer
  %165 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %164, <64 x float> %152, <64 x float> %140)
  %166 = add nsw i64 %143, 29696
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !6603
  %169 = insertelement <64 x float> undef, float %168, i32 0
  %170 = shufflevector <64 x float> %169, <64 x float> undef, <64 x i32> zeroinitializer
  %171 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %170, <64 x float> %152, <64 x float> %139)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %153, <64 x float>* %131, align 64, !tbaa !6600
  store <64 x float> %159, <64 x float>* %133, align 64, !tbaa !6600
  store <64 x float> %165, <64 x float>* %135, align 64, !tbaa !6600
  store <64 x float> %171, <64 x float>* %137, align 64, !tbaa !6600
  %172 = getelementptr inbounds i8, i8* %40, i64 1536
  %173 = bitcast i8* %172 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %173, align 64, !tbaa !6600
  %174 = getelementptr inbounds i8, i8* %40, i64 1792
  %175 = bitcast i8* %174 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %175, align 64, !tbaa !6600
  %176 = getelementptr inbounds i8, i8* %40, i64 5120
  %177 = bitcast i8* %176 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %177, align 64, !tbaa !6600
  %178 = getelementptr inbounds i8, i8* %40, i64 5376
  %179 = bitcast i8* %178 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %179, align 64, !tbaa !6600
  %180 = or i64 %47, 6144
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %181 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %213, %for_body5.3 ]
  %182 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %207, %for_body5.3 ]
  %183 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %201, %for_body5.3 ]
  %184 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %195, %for_body5.3 ]
  %185 = add nsw i64 %180, %indvars.iv.3
  %186 = getelementptr inbounds float, float* %4, i64 %185
  %187 = load float, float* %186, align 4, !tbaa !6603
  %188 = insertelement <64 x float> undef, float %187, i32 0
  %189 = shufflevector <64 x float> %188, <64 x float> undef, <64 x i32> zeroinitializer
  %190 = shl i64 %indvars.iv.3, 6
  %191 = add nuw nsw i64 %190, %46
  %192 = getelementptr inbounds float, float* %7, i64 %191
  %193 = bitcast float* %192 to <64 x float>*
  %194 = load <64 x float>, <64 x float>* %193, align 64, !tbaa !6606
  %195 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %189, <64 x float> %194, <64 x float> %184)
  %196 = add nsw i64 %185, 1024
  %197 = getelementptr inbounds float, float* %4, i64 %196
  %198 = load float, float* %197, align 4, !tbaa !6603
  %199 = insertelement <64 x float> undef, float %198, i32 0
  %200 = shufflevector <64 x float> %199, <64 x float> undef, <64 x i32> zeroinitializer
  %201 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %200, <64 x float> %194, <64 x float> %183)
  %202 = add nsw i64 %185, 28672
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !6603
  %205 = insertelement <64 x float> undef, float %204, i32 0
  %206 = shufflevector <64 x float> %205, <64 x float> undef, <64 x i32> zeroinitializer
  %207 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %206, <64 x float> %194, <64 x float> %182)
  %208 = add nsw i64 %185, 29696
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !6603
  %211 = insertelement <64 x float> undef, float %210, i32 0
  %212 = shufflevector <64 x float> %211, <64 x float> undef, <64 x i32> zeroinitializer
  %213 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %212, <64 x float> %194, <64 x float> %181)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %195, <64 x float>* %173, align 64, !tbaa !6600
  store <64 x float> %201, <64 x float>* %175, align 64, !tbaa !6600
  store <64 x float> %207, <64 x float>* %177, align 64, !tbaa !6600
  store <64 x float> %213, <64 x float>* %179, align 64, !tbaa !6600
  %214 = getelementptr inbounds i8, i8* %40, i64 2048
  %215 = bitcast i8* %214 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %215, align 64, !tbaa !6600
  %216 = getelementptr inbounds i8, i8* %40, i64 2304
  %217 = bitcast i8* %216 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %217, align 64, !tbaa !6600
  %218 = getelementptr inbounds i8, i8* %40, i64 5632
  %219 = bitcast i8* %218 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %219, align 64, !tbaa !6600
  %220 = getelementptr inbounds i8, i8* %40, i64 5888
  %221 = bitcast i8* %220 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %221, align 64, !tbaa !6600
  %222 = add nsw i64 %47, 8192
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %223 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %255, %for_body5.4 ]
  %224 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %249, %for_body5.4 ]
  %225 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %243, %for_body5.4 ]
  %226 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %237, %for_body5.4 ]
  %227 = add nsw i64 %222, %indvars.iv.4
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = load float, float* %228, align 4, !tbaa !6603
  %230 = insertelement <64 x float> undef, float %229, i32 0
  %231 = shufflevector <64 x float> %230, <64 x float> undef, <64 x i32> zeroinitializer
  %232 = shl i64 %indvars.iv.4, 6
  %233 = add nuw nsw i64 %232, %46
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <64 x float>*
  %236 = load <64 x float>, <64 x float>* %235, align 64, !tbaa !6606
  %237 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %231, <64 x float> %236, <64 x float> %226)
  %238 = add nsw i64 %227, 1024
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !6603
  %241 = insertelement <64 x float> undef, float %240, i32 0
  %242 = shufflevector <64 x float> %241, <64 x float> undef, <64 x i32> zeroinitializer
  %243 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %242, <64 x float> %236, <64 x float> %225)
  %244 = add nsw i64 %227, 28672
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !6603
  %247 = insertelement <64 x float> undef, float %246, i32 0
  %248 = shufflevector <64 x float> %247, <64 x float> undef, <64 x i32> zeroinitializer
  %249 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %248, <64 x float> %236, <64 x float> %224)
  %250 = add nsw i64 %227, 29696
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !6603
  %253 = insertelement <64 x float> undef, float %252, i32 0
  %254 = shufflevector <64 x float> %253, <64 x float> undef, <64 x i32> zeroinitializer
  %255 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %254, <64 x float> %236, <64 x float> %223)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %237, <64 x float>* %215, align 64, !tbaa !6600
  store <64 x float> %243, <64 x float>* %217, align 64, !tbaa !6600
  store <64 x float> %249, <64 x float>* %219, align 64, !tbaa !6600
  store <64 x float> %255, <64 x float>* %221, align 64, !tbaa !6600
  %256 = getelementptr inbounds i8, i8* %40, i64 2560
  %257 = bitcast i8* %256 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %257, align 64, !tbaa !6600
  %258 = getelementptr inbounds i8, i8* %40, i64 2816
  %259 = bitcast i8* %258 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %259, align 64, !tbaa !6600
  %260 = getelementptr inbounds i8, i8* %40, i64 6144
  %261 = bitcast i8* %260 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %261, align 64, !tbaa !6600
  %262 = getelementptr inbounds i8, i8* %40, i64 6400
  %263 = bitcast i8* %262 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %263, align 64, !tbaa !6600
  %264 = add nsw i64 %47, 10240
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %265 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %297, %for_body5.5 ]
  %266 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %291, %for_body5.5 ]
  %267 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %285, %for_body5.5 ]
  %268 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %279, %for_body5.5 ]
  %269 = add nsw i64 %264, %indvars.iv.5
  %270 = getelementptr inbounds float, float* %4, i64 %269
  %271 = load float, float* %270, align 4, !tbaa !6603
  %272 = insertelement <64 x float> undef, float %271, i32 0
  %273 = shufflevector <64 x float> %272, <64 x float> undef, <64 x i32> zeroinitializer
  %274 = shl i64 %indvars.iv.5, 6
  %275 = add nuw nsw i64 %274, %46
  %276 = getelementptr inbounds float, float* %7, i64 %275
  %277 = bitcast float* %276 to <64 x float>*
  %278 = load <64 x float>, <64 x float>* %277, align 64, !tbaa !6606
  %279 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %273, <64 x float> %278, <64 x float> %268)
  %280 = add nsw i64 %269, 1024
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !6603
  %283 = insertelement <64 x float> undef, float %282, i32 0
  %284 = shufflevector <64 x float> %283, <64 x float> undef, <64 x i32> zeroinitializer
  %285 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %284, <64 x float> %278, <64 x float> %267)
  %286 = add nsw i64 %269, 28672
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !6603
  %289 = insertelement <64 x float> undef, float %288, i32 0
  %290 = shufflevector <64 x float> %289, <64 x float> undef, <64 x i32> zeroinitializer
  %291 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %290, <64 x float> %278, <64 x float> %266)
  %292 = add nsw i64 %269, 29696
  %293 = getelementptr inbounds float, float* %4, i64 %292
  %294 = load float, float* %293, align 4, !tbaa !6603
  %295 = insertelement <64 x float> undef, float %294, i32 0
  %296 = shufflevector <64 x float> %295, <64 x float> undef, <64 x i32> zeroinitializer
  %297 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %296, <64 x float> %278, <64 x float> %265)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %279, <64 x float>* %257, align 64, !tbaa !6600
  store <64 x float> %285, <64 x float>* %259, align 64, !tbaa !6600
  store <64 x float> %291, <64 x float>* %261, align 64, !tbaa !6600
  store <64 x float> %297, <64 x float>* %263, align 64, !tbaa !6600
  %298 = getelementptr inbounds i8, i8* %40, i64 3072
  %299 = bitcast i8* %298 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %299, align 64, !tbaa !6600
  %300 = getelementptr inbounds i8, i8* %40, i64 3328
  %301 = bitcast i8* %300 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %301, align 64, !tbaa !6600
  %302 = getelementptr inbounds i8, i8* %40, i64 6656
  %303 = bitcast i8* %302 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %303, align 64, !tbaa !6600
  %304 = getelementptr inbounds i8, i8* %40, i64 6912
  %305 = bitcast i8* %304 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %305, align 64, !tbaa !6600
  %306 = add nsw i64 %47, 12288
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %307 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %339, %for_body5.6 ]
  %308 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %333, %for_body5.6 ]
  %309 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %327, %for_body5.6 ]
  %310 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %321, %for_body5.6 ]
  %311 = add nsw i64 %306, %indvars.iv.6
  %312 = getelementptr inbounds float, float* %4, i64 %311
  %313 = load float, float* %312, align 4, !tbaa !6603
  %314 = insertelement <64 x float> undef, float %313, i32 0
  %315 = shufflevector <64 x float> %314, <64 x float> undef, <64 x i32> zeroinitializer
  %316 = shl i64 %indvars.iv.6, 6
  %317 = add nuw nsw i64 %316, %46
  %318 = getelementptr inbounds float, float* %7, i64 %317
  %319 = bitcast float* %318 to <64 x float>*
  %320 = load <64 x float>, <64 x float>* %319, align 64, !tbaa !6606
  %321 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %315, <64 x float> %320, <64 x float> %310)
  %322 = add nsw i64 %311, 1024
  %323 = getelementptr inbounds float, float* %4, i64 %322
  %324 = load float, float* %323, align 4, !tbaa !6603
  %325 = insertelement <64 x float> undef, float %324, i32 0
  %326 = shufflevector <64 x float> %325, <64 x float> undef, <64 x i32> zeroinitializer
  %327 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %326, <64 x float> %320, <64 x float> %309)
  %328 = add nsw i64 %311, 28672
  %329 = getelementptr inbounds float, float* %4, i64 %328
  %330 = load float, float* %329, align 4, !tbaa !6603
  %331 = insertelement <64 x float> undef, float %330, i32 0
  %332 = shufflevector <64 x float> %331, <64 x float> undef, <64 x i32> zeroinitializer
  %333 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %332, <64 x float> %320, <64 x float> %308)
  %334 = add nsw i64 %311, 29696
  %335 = getelementptr inbounds float, float* %4, i64 %334
  %336 = load float, float* %335, align 4, !tbaa !6603
  %337 = insertelement <64 x float> undef, float %336, i32 0
  %338 = shufflevector <64 x float> %337, <64 x float> undef, <64 x i32> zeroinitializer
  %339 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %338, <64 x float> %320, <64 x float> %307)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %321, <64 x float>* %299, align 64, !tbaa !6600
  store <64 x float> %327, <64 x float>* %301, align 64, !tbaa !6600
  store <64 x float> %333, <64 x float>* %303, align 64, !tbaa !6600
  store <64 x float> %339, <64 x float>* %305, align 64, !tbaa !6600
  %340 = mul nsw i64 %indvars.iv43, 1792
  %341 = shl nsw i32 %44, 6
  %342 = sext i32 %341 to i64
  %343 = getelementptr inbounds float, float* %13, i64 %342
  %344 = bitcast float* %343 to <64 x float>*
  %345 = load <64 x float>, <64 x float>* %344, align 64, !tbaa !6609
  %346 = getelementptr inbounds float, float* %16, i64 %342
  %347 = bitcast float* %346 to <64 x float>*
  %348 = load <64 x float>, <64 x float>* %347, align 64, !tbaa !6612
  %349 = getelementptr inbounds float, float* %19, i64 %342
  %350 = bitcast float* %349 to <64 x float>*
  %351 = load <64 x float>, <64 x float>* %350, align 64, !tbaa !6615
  %352 = bitcast i8* %40 to <64 x float>*
  %353 = load <64 x float>, <64 x float>* %352, align 64, !tbaa !6600
  %354 = fadd <64 x float> %345, %353
  %355 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %354, <64 x float> %348, <64 x float> %351)
  %356 = getelementptr inbounds float, float* %10, i64 %340
  %357 = bitcast float* %356 to <64 x float>*
  store <64 x float> %355, <64 x float>* %357, align 64, !tbaa !6618
  %358 = getelementptr inbounds i8, i8* %40, i64 256
  %359 = bitcast i8* %358 to <64 x float>*
  %360 = load <64 x float>, <64 x float>* %359, align 64, !tbaa !6600
  %361 = fadd <64 x float> %345, %360
  %362 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %361, <64 x float> %348, <64 x float> %351)
  %363 = mul i64 %indvars.iv43, 7696581394432
  %sext = ashr exact i64 %363, 32
  %364 = or i64 %sext, 64
  %365 = getelementptr inbounds float, float* %10, i64 %364
  %366 = bitcast float* %365 to <64 x float>*
  store <64 x float> %362, <64 x float>* %366, align 64, !tbaa !6618
  %367 = getelementptr inbounds i8, i8* %40, i64 3584
  %368 = bitcast i8* %367 to <64 x float>*
  %369 = load <64 x float>, <64 x float>* %368, align 64, !tbaa !6600
  %370 = fadd <64 x float> %345, %369
  %371 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %370, <64 x float> %348, <64 x float> %351)
  %372 = mul i64 %indvars.iv43, 7696581394432
  %sext58 = add i64 %372, 3848290697216
  %373 = ashr exact i64 %sext58, 32
  %374 = getelementptr inbounds float, float* %10, i64 %373
  %375 = bitcast float* %374 to <64 x float>*
  store <64 x float> %371, <64 x float>* %375, align 64, !tbaa !6618
  %376 = getelementptr inbounds i8, i8* %40, i64 3840
  %377 = bitcast i8* %376 to <64 x float>*
  %378 = load <64 x float>, <64 x float>* %377, align 64, !tbaa !6600
  %379 = fadd <64 x float> %345, %378
  %380 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %379, <64 x float> %348, <64 x float> %351)
  %381 = mul i64 %indvars.iv43, 7696581394432
  %sext45 = add i64 %381, 4123168604160
  %382 = ashr exact i64 %sext45, 32
  %383 = getelementptr inbounds float, float* %10, i64 %382
  %384 = bitcast float* %383 to <64 x float>*
  store <64 x float> %380, <64 x float>* %384, align 64, !tbaa !6618
  %385 = getelementptr inbounds i8, i8* %40, i64 512
  %386 = bitcast i8* %385 to <64 x float>*
  %387 = load <64 x float>, <64 x float>* %386, align 64, !tbaa !6600
  %388 = fadd <64 x float> %345, %387
  %389 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %388, <64 x float> %348, <64 x float> %351)
  %390 = mul i64 %indvars.iv43, 7696581394432
  %sext59 = ashr exact i64 %390, 32
  %391 = or i64 %sext59, 128
  %392 = getelementptr inbounds float, float* %10, i64 %391
  %393 = bitcast float* %392 to <64 x float>*
  store <64 x float> %389, <64 x float>* %393, align 64, !tbaa !6618
  %394 = getelementptr inbounds i8, i8* %40, i64 768
  %395 = bitcast i8* %394 to <64 x float>*
  %396 = load <64 x float>, <64 x float>* %395, align 64, !tbaa !6600
  %397 = fadd <64 x float> %345, %396
  %398 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %397, <64 x float> %348, <64 x float> %351)
  %399 = mul i64 %indvars.iv43, 7696581394432
  %sext46 = ashr exact i64 %399, 32
  %400 = or i64 %sext46, 192
  %401 = getelementptr inbounds float, float* %10, i64 %400
  %402 = bitcast float* %401 to <64 x float>*
  store <64 x float> %398, <64 x float>* %402, align 64, !tbaa !6618
  %403 = getelementptr inbounds i8, i8* %40, i64 4096
  %404 = bitcast i8* %403 to <64 x float>*
  %405 = load <64 x float>, <64 x float>* %404, align 64, !tbaa !6600
  %406 = fadd <64 x float> %345, %405
  %407 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %406, <64 x float> %348, <64 x float> %351)
  %408 = mul i64 %indvars.iv43, 7696581394432
  %sext60 = add i64 %408, 4398046511104
  %409 = ashr exact i64 %sext60, 32
  %410 = getelementptr inbounds float, float* %10, i64 %409
  %411 = bitcast float* %410 to <64 x float>*
  store <64 x float> %407, <64 x float>* %411, align 64, !tbaa !6618
  %412 = getelementptr inbounds i8, i8* %40, i64 4352
  %413 = bitcast i8* %412 to <64 x float>*
  %414 = load <64 x float>, <64 x float>* %413, align 64, !tbaa !6600
  %415 = fadd <64 x float> %345, %414
  %416 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %415, <64 x float> %348, <64 x float> %351)
  %417 = mul i64 %indvars.iv43, 7696581394432
  %sext47 = add i64 %417, 4672924418048
  %418 = ashr exact i64 %sext47, 32
  %419 = getelementptr inbounds float, float* %10, i64 %418
  %420 = bitcast float* %419 to <64 x float>*
  store <64 x float> %416, <64 x float>* %420, align 64, !tbaa !6618
  %421 = getelementptr inbounds i8, i8* %40, i64 1024
  %422 = bitcast i8* %421 to <64 x float>*
  %423 = load <64 x float>, <64 x float>* %422, align 64, !tbaa !6600
  %424 = fadd <64 x float> %345, %423
  %425 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %424, <64 x float> %348, <64 x float> %351)
  %426 = mul i64 %indvars.iv43, 7696581394432
  %sext61 = add i64 %426, 1099511627776
  %427 = ashr exact i64 %sext61, 32
  %428 = getelementptr inbounds float, float* %10, i64 %427
  %429 = bitcast float* %428 to <64 x float>*
  store <64 x float> %425, <64 x float>* %429, align 64, !tbaa !6618
  %430 = getelementptr inbounds i8, i8* %40, i64 1280
  %431 = bitcast i8* %430 to <64 x float>*
  %432 = load <64 x float>, <64 x float>* %431, align 64, !tbaa !6600
  %433 = fadd <64 x float> %345, %432
  %434 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %433, <64 x float> %348, <64 x float> %351)
  %435 = mul i64 %indvars.iv43, 7696581394432
  %sext48 = add i64 %435, 1374389534720
  %436 = ashr exact i64 %sext48, 32
  %437 = getelementptr inbounds float, float* %10, i64 %436
  %438 = bitcast float* %437 to <64 x float>*
  store <64 x float> %434, <64 x float>* %438, align 64, !tbaa !6618
  %439 = getelementptr inbounds i8, i8* %40, i64 4608
  %440 = bitcast i8* %439 to <64 x float>*
  %441 = load <64 x float>, <64 x float>* %440, align 64, !tbaa !6600
  %442 = fadd <64 x float> %345, %441
  %443 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %442, <64 x float> %348, <64 x float> %351)
  %444 = mul i64 %indvars.iv43, 7696581394432
  %sext62 = add i64 %444, 4947802324992
  %445 = ashr exact i64 %sext62, 32
  %446 = getelementptr inbounds float, float* %10, i64 %445
  %447 = bitcast float* %446 to <64 x float>*
  store <64 x float> %443, <64 x float>* %447, align 64, !tbaa !6618
  %448 = getelementptr inbounds i8, i8* %40, i64 4864
  %449 = bitcast i8* %448 to <64 x float>*
  %450 = load <64 x float>, <64 x float>* %449, align 64, !tbaa !6600
  %451 = fadd <64 x float> %345, %450
  %452 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %451, <64 x float> %348, <64 x float> %351)
  %453 = mul i64 %indvars.iv43, 7696581394432
  %sext49 = add i64 %453, 5222680231936
  %454 = ashr exact i64 %sext49, 32
  %455 = getelementptr inbounds float, float* %10, i64 %454
  %456 = bitcast float* %455 to <64 x float>*
  store <64 x float> %452, <64 x float>* %456, align 64, !tbaa !6618
  %457 = getelementptr inbounds i8, i8* %40, i64 1536
  %458 = bitcast i8* %457 to <64 x float>*
  %459 = load <64 x float>, <64 x float>* %458, align 64, !tbaa !6600
  %460 = fadd <64 x float> %345, %459
  %461 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %460, <64 x float> %348, <64 x float> %351)
  %462 = mul i64 %indvars.iv43, 7696581394432
  %sext63 = add i64 %462, 1649267441664
  %463 = ashr exact i64 %sext63, 32
  %464 = getelementptr inbounds float, float* %10, i64 %463
  %465 = bitcast float* %464 to <64 x float>*
  store <64 x float> %461, <64 x float>* %465, align 64, !tbaa !6618
  %466 = getelementptr inbounds i8, i8* %40, i64 1792
  %467 = bitcast i8* %466 to <64 x float>*
  %468 = load <64 x float>, <64 x float>* %467, align 64, !tbaa !6600
  %469 = fadd <64 x float> %345, %468
  %470 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %469, <64 x float> %348, <64 x float> %351)
  %471 = mul i64 %indvars.iv43, 7696581394432
  %sext50 = add i64 %471, 1924145348608
  %472 = ashr exact i64 %sext50, 32
  %473 = getelementptr inbounds float, float* %10, i64 %472
  %474 = bitcast float* %473 to <64 x float>*
  store <64 x float> %470, <64 x float>* %474, align 64, !tbaa !6618
  %475 = getelementptr inbounds i8, i8* %40, i64 5120
  %476 = bitcast i8* %475 to <64 x float>*
  %477 = load <64 x float>, <64 x float>* %476, align 64, !tbaa !6600
  %478 = fadd <64 x float> %345, %477
  %479 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %478, <64 x float> %348, <64 x float> %351)
  %480 = mul i64 %indvars.iv43, 7696581394432
  %sext64 = add i64 %480, 5497558138880
  %481 = ashr exact i64 %sext64, 32
  %482 = getelementptr inbounds float, float* %10, i64 %481
  %483 = bitcast float* %482 to <64 x float>*
  store <64 x float> %479, <64 x float>* %483, align 64, !tbaa !6618
  %484 = getelementptr inbounds i8, i8* %40, i64 5376
  %485 = bitcast i8* %484 to <64 x float>*
  %486 = load <64 x float>, <64 x float>* %485, align 64, !tbaa !6600
  %487 = fadd <64 x float> %345, %486
  %488 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %487, <64 x float> %348, <64 x float> %351)
  %489 = mul i64 %indvars.iv43, 7696581394432
  %sext51 = add i64 %489, 5772436045824
  %490 = ashr exact i64 %sext51, 32
  %491 = getelementptr inbounds float, float* %10, i64 %490
  %492 = bitcast float* %491 to <64 x float>*
  store <64 x float> %488, <64 x float>* %492, align 64, !tbaa !6618
  %493 = getelementptr inbounds i8, i8* %40, i64 2048
  %494 = bitcast i8* %493 to <64 x float>*
  %495 = load <64 x float>, <64 x float>* %494, align 64, !tbaa !6600
  %496 = fadd <64 x float> %345, %495
  %497 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %496, <64 x float> %348, <64 x float> %351)
  %498 = mul i64 %indvars.iv43, 7696581394432
  %sext65 = add i64 %498, 2199023255552
  %499 = ashr exact i64 %sext65, 32
  %500 = getelementptr inbounds float, float* %10, i64 %499
  %501 = bitcast float* %500 to <64 x float>*
  store <64 x float> %497, <64 x float>* %501, align 64, !tbaa !6618
  %502 = getelementptr inbounds i8, i8* %40, i64 2304
  %503 = bitcast i8* %502 to <64 x float>*
  %504 = load <64 x float>, <64 x float>* %503, align 64, !tbaa !6600
  %505 = fadd <64 x float> %345, %504
  %506 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %505, <64 x float> %348, <64 x float> %351)
  %507 = mul i64 %indvars.iv43, 7696581394432
  %sext52 = add i64 %507, 2473901162496
  %508 = ashr exact i64 %sext52, 32
  %509 = getelementptr inbounds float, float* %10, i64 %508
  %510 = bitcast float* %509 to <64 x float>*
  store <64 x float> %506, <64 x float>* %510, align 64, !tbaa !6618
  %511 = getelementptr inbounds i8, i8* %40, i64 5632
  %512 = bitcast i8* %511 to <64 x float>*
  %513 = load <64 x float>, <64 x float>* %512, align 64, !tbaa !6600
  %514 = fadd <64 x float> %345, %513
  %515 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %514, <64 x float> %348, <64 x float> %351)
  %516 = mul i64 %indvars.iv43, 7696581394432
  %sext66 = add i64 %516, 6047313952768
  %517 = ashr exact i64 %sext66, 32
  %518 = getelementptr inbounds float, float* %10, i64 %517
  %519 = bitcast float* %518 to <64 x float>*
  store <64 x float> %515, <64 x float>* %519, align 64, !tbaa !6618
  %520 = getelementptr inbounds i8, i8* %40, i64 5888
  %521 = bitcast i8* %520 to <64 x float>*
  %522 = load <64 x float>, <64 x float>* %521, align 64, !tbaa !6600
  %523 = fadd <64 x float> %345, %522
  %524 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %523, <64 x float> %348, <64 x float> %351)
  %525 = mul i64 %indvars.iv43, 7696581394432
  %sext53 = add i64 %525, 6322191859712
  %526 = ashr exact i64 %sext53, 32
  %527 = getelementptr inbounds float, float* %10, i64 %526
  %528 = bitcast float* %527 to <64 x float>*
  store <64 x float> %524, <64 x float>* %528, align 64, !tbaa !6618
  %529 = getelementptr inbounds i8, i8* %40, i64 2560
  %530 = bitcast i8* %529 to <64 x float>*
  %531 = load <64 x float>, <64 x float>* %530, align 64, !tbaa !6600
  %532 = fadd <64 x float> %345, %531
  %533 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %532, <64 x float> %348, <64 x float> %351)
  %534 = mul i64 %indvars.iv43, 7696581394432
  %sext67 = add i64 %534, 2748779069440
  %535 = ashr exact i64 %sext67, 32
  %536 = getelementptr inbounds float, float* %10, i64 %535
  %537 = bitcast float* %536 to <64 x float>*
  store <64 x float> %533, <64 x float>* %537, align 64, !tbaa !6618
  %538 = getelementptr inbounds i8, i8* %40, i64 2816
  %539 = bitcast i8* %538 to <64 x float>*
  %540 = load <64 x float>, <64 x float>* %539, align 64, !tbaa !6600
  %541 = fadd <64 x float> %345, %540
  %542 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %541, <64 x float> %348, <64 x float> %351)
  %543 = mul i64 %indvars.iv43, 7696581394432
  %sext54 = add i64 %543, 3023656976384
  %544 = ashr exact i64 %sext54, 32
  %545 = getelementptr inbounds float, float* %10, i64 %544
  %546 = bitcast float* %545 to <64 x float>*
  store <64 x float> %542, <64 x float>* %546, align 64, !tbaa !6618
  %547 = getelementptr inbounds i8, i8* %40, i64 6144
  %548 = bitcast i8* %547 to <64 x float>*
  %549 = load <64 x float>, <64 x float>* %548, align 64, !tbaa !6600
  %550 = fadd <64 x float> %345, %549
  %551 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %550, <64 x float> %348, <64 x float> %351)
  %552 = mul i64 %indvars.iv43, 7696581394432
  %sext68 = add i64 %552, 6597069766656
  %553 = ashr exact i64 %sext68, 32
  %554 = getelementptr inbounds float, float* %10, i64 %553
  %555 = bitcast float* %554 to <64 x float>*
  store <64 x float> %551, <64 x float>* %555, align 64, !tbaa !6618
  %556 = getelementptr inbounds i8, i8* %40, i64 6400
  %557 = bitcast i8* %556 to <64 x float>*
  %558 = load <64 x float>, <64 x float>* %557, align 64, !tbaa !6600
  %559 = fadd <64 x float> %345, %558
  %560 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %559, <64 x float> %348, <64 x float> %351)
  %561 = mul i64 %indvars.iv43, 7696581394432
  %sext55 = add i64 %561, 6871947673600
  %562 = ashr exact i64 %sext55, 32
  %563 = getelementptr inbounds float, float* %10, i64 %562
  %564 = bitcast float* %563 to <64 x float>*
  store <64 x float> %560, <64 x float>* %564, align 64, !tbaa !6618
  %565 = getelementptr inbounds i8, i8* %40, i64 3072
  %566 = bitcast i8* %565 to <64 x float>*
  %567 = load <64 x float>, <64 x float>* %566, align 64, !tbaa !6600
  %568 = fadd <64 x float> %345, %567
  %569 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %568, <64 x float> %348, <64 x float> %351)
  %570 = mul i64 %indvars.iv43, 7696581394432
  %sext69 = add i64 %570, 3298534883328
  %571 = ashr exact i64 %sext69, 32
  %572 = getelementptr inbounds float, float* %10, i64 %571
  %573 = bitcast float* %572 to <64 x float>*
  store <64 x float> %569, <64 x float>* %573, align 64, !tbaa !6618
  %574 = getelementptr inbounds i8, i8* %40, i64 3328
  %575 = bitcast i8* %574 to <64 x float>*
  %576 = load <64 x float>, <64 x float>* %575, align 64, !tbaa !6600
  %577 = fadd <64 x float> %345, %576
  %578 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %577, <64 x float> %348, <64 x float> %351)
  %579 = mul i64 %indvars.iv43, 7696581394432
  %sext56 = add i64 %579, 3573412790272
  %580 = ashr exact i64 %sext56, 32
  %581 = getelementptr inbounds float, float* %10, i64 %580
  %582 = bitcast float* %581 to <64 x float>*
  store <64 x float> %578, <64 x float>* %582, align 64, !tbaa !6618
  %583 = getelementptr inbounds i8, i8* %40, i64 6656
  %584 = bitcast i8* %583 to <64 x float>*
  %585 = load <64 x float>, <64 x float>* %584, align 64, !tbaa !6600
  %586 = fadd <64 x float> %345, %585
  %587 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %586, <64 x float> %348, <64 x float> %351)
  %588 = mul i64 %indvars.iv43, 7696581394432
  %sext70 = add i64 %588, 7146825580544
  %589 = ashr exact i64 %sext70, 32
  %590 = getelementptr inbounds float, float* %10, i64 %589
  %591 = bitcast float* %590 to <64 x float>*
  store <64 x float> %587, <64 x float>* %591, align 64, !tbaa !6618
  %592 = getelementptr inbounds i8, i8* %40, i64 6912
  %593 = bitcast i8* %592 to <64 x float>*
  %594 = load <64 x float>, <64 x float>* %593, align 64, !tbaa !6600
  %595 = fadd <64 x float> %345, %594
  %596 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %595, <64 x float> %348, <64 x float> %351)
  %597 = mul i64 %indvars.iv43, 7696581394432
  %sext57 = add i64 %597, 7421703487488
  %598 = ashr exact i64 %sext57, 32
  %599 = getelementptr inbounds float, float* %10, i64 %598
  %600 = bitcast float* %599 to <64 x float>*
  store <64 x float> %596, <64 x float>* %600, align 64, !tbaa !6618
  %601 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %602 = tail call i32 %601(i32 1, i32 %22, i8* nonnull %40)
  %indvars.iv.next44 = add nsw i64 %indvars.iv43, 1
  %603 = icmp slt i64 %indvars.iv.next44, %38
  br i1 %603, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_pad_layout_transform(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([82 x i8], [82 x i8]* @.str.470, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !6621
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([157 x i8], [157 x i8]* @.str.471, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !6635
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([157 x i8], [157 x i8]* @.str.472, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 4
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.203, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !6637
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !6651
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 3
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.473, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !6653
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 224
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.474, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !6656
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 224
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.475, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = icmp eq i64* %17, null
  br i1 %70, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end18
  %71 = bitcast i64* %17 to <4 x i64>*
  %72 = load <4 x i64>, <4 x i64>* %71, align 8, !tbaa !6658
  %73 = trunc <4 x i64> %72 to <4 x i32>
  %74 = icmp eq <4 x i32> %73, <i32 150528, i32 50176, i32 224, i32 1>
  %rdx.shuf49 = shufflevector <4 x i1> %74, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %74, %rdx.shuf49
  %rdx.shuf51 = shufflevector <4 x i1> %bin.rdx50, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %bin.rdx50, %rdx.shuf51
  %75 = extractelement <4 x i1> %bin.rdx52, i32 0
  br i1 %75, label %if_end, label %assert_fail19, !prof !5

if_end:                                           ; preds = %assert_end18, %if_then
  %76 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %77 = load i64, i64* %76, align 8
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %assert_end22, label %assert_fail21, !prof !5

assert_fail19:                                    ; preds = %if_then
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([203 x i8], [203 x i8]* @.str.476, i64 0, i64 0))
  ret i32 -1

assert_fail21:                                    ; preds = %if_end
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %if_end
  %81 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %82 = load i32, i32* %81, align 4
  %83 = icmp eq i32 %82, 5
  br i1 %83, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %85 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %86 = load i16, i16* %85, align 2
  %87 = icmp eq i16 %86, 1
  %88 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %89 = load i8, i8* %88, align 1
  %90 = icmp eq i8 %89, 32
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %92 = load i8, i8* %91, align 1
  %93 = icmp eq i8 %92, 2
  %94 = and i1 %90, %93
  %95 = and i1 %87, %94
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = load i64, i64* %25, align 8, !tbaa !6670
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 1
  br i1 %99, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %101 = getelementptr inbounds i64, i64* %25, i64 1
  %102 = load i64, i64* %101, align 8, !tbaa !6684
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 1
  br i1 %104, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %106 = getelementptr inbounds i64, i64* %25, i64 2
  %107 = load i64, i64* %106, align 8, !tbaa !6686
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 230
  br i1 %109, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.477, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %111 = getelementptr inbounds i64, i64* %25, i64 3
  %112 = load i64, i64* %111, align 8, !tbaa !6689
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 230
  br i1 %114, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.478, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %116 = getelementptr inbounds i64, i64* %25, i64 4
  %117 = load i64, i64* %116, align 8, !tbaa !6691
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 3
  br i1 %119, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.356, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %121 = icmp eq i64* %27, null
  br i1 %121, label %if_end38, label %if_then37, !prof !50

if_then37:                                        ; preds = %assert_end36
  %122 = bitcast i64* %27 to <4 x i64>*
  %123 = load <4 x i64>, <4 x i64>* %122, align 8, !tbaa !6695
  %124 = trunc <4 x i64> %123 to <4 x i32>
  %125 = icmp eq <4 x i32> %124, <i32 158700, i32 158700, i32 690, i32 3>
  %126 = getelementptr inbounds i64, i64* %27, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !6707
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 1
  %rdx.shuf = shufflevector <4 x i1> %125, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %125, %rdx.shuf
  %rdx.shuf47 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx48 = and <4 x i1> %bin.rdx, %rdx.shuf47
  %130 = extractelement <4 x i1> %bin.rdx48, i32 0
  %131 = and i1 %130, %129
  br i1 %131, label %if_end38, label %assert_fail39, !prof !5

if_end38:                                         ; preds = %assert_end36, %if_then37
  %132 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %133 = load i64, i64* %132, align 8
  %134 = icmp eq i64 %133, 0
  br i1 %134, label %assert_end42, label %assert_fail41, !prof !5

assert_fail39:                                    ; preds = %if_then37
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.479, i64 0, i64 0))
  ret i32 -1

assert_fail41:                                    ; preds = %if_end38
  %136 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %136(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %if_end38
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %138 = load i32, i32* %137, align 4
  %139 = icmp eq i32 %138, 1
  br i1 %139, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %140 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %140(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %141 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %142 = load i32, i32* %141, align 4
  %143 = icmp eq i32 %21, %142
  br i1 %143, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %144 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %144(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %145 = tail call fastcc i32 @fused_nn_pad_layout_transform_compute_(i8* %23, i8* %13)
  ret i32 %145
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_pad_layout_transform_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %41, align 8
  %3 = getelementptr inbounds %41, %41* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %41, %41* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %41* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.480, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.480(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 229
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 230
  %15 = select i1 %14, i32 %13, i32 230
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 230
  %18 = select i1 %17, i32 %16, i32 230
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 230
  %21 = select i1 %20, i32 %16, i32 230
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -690
  %23 = add i32 %22, -690
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv22 = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next23, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul i32 %indvar, 690
  %29 = add i32 %23, %28
  %30 = mul nsw i64 %indvars.iv22, 690
  %31 = trunc i64 %indvars.iv22 to i32
  %.off = add i32 %31, -3
  %32 = icmp ult i32 %.off, 224
  %33 = trunc i64 %indvars.iv22 to i32
  %34 = mul i32 %33, 224
  %35 = add i32 %34, -675
  br i1 %32, label %for_begin4.preheader.us, label %for_begin4.preheader.preheader

for_begin4.preheader.preheader:                   ; preds = %for_begin1.preheader
  %36 = sext i32 %29 to i64
  %scevgep18 = getelementptr float, float* %4, i64 %36
  %scevgep1819 = bitcast float* %scevgep18 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %scevgep1819, i8 0, i64 2760, i1 false)
  br label %for_end3

for_begin4.preheader.us:                          ; preds = %for_begin1.preheader, %for_end6.us
  %indvars.iv = phi i64 [ %indvars.iv.next, %for_end6.us ], [ 0, %for_begin1.preheader ]
  %37 = mul nuw nsw i64 %indvars.iv, 3
  %38 = add nsw i64 %37, %30
  %39 = trunc i64 %indvars.iv to i32
  %40 = add i32 %39, -3
  %41 = icmp ult i32 %40, 224
  %42 = trunc i64 %indvars.iv to i32
  %43 = add i32 %35, %42
  br i1 %41, label %for_body5.us.us.preheader, label %for_body5.us8.preheader

for_body5.us8.preheader:                          ; preds = %for_begin4.preheader.us
  %44 = trunc i64 %37 to i32
  %45 = add i32 %29, %44
  %46 = sext i32 %45 to i64
  %scevgep = getelementptr float, float* %4, i64 %46
  %scevgep20 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %scevgep20, i8 0, i64 12, i1 false)
  br label %for_end6.us

for_body5.us.us.preheader:                        ; preds = %for_begin4.preheader.us
  %47 = sext i32 %43 to i64
  %48 = getelementptr inbounds float, float* %7, i64 %47
  %49 = bitcast float* %48 to i32*
  %50 = load i32, i32* %49, align 4, !tbaa !6711
  %51 = getelementptr inbounds float, float* %4, i64 %38
  %52 = bitcast float* %51 to i32*
  store i32 %50, i32* %52, align 4, !tbaa !6714
  %53 = add nsw i64 %38, 1
  %54 = add i32 %43, 50176
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds float, float* %7, i64 %55
  %57 = bitcast float* %56 to i32*
  %58 = load i32, i32* %57, align 4, !tbaa !6711
  %59 = getelementptr inbounds float, float* %4, i64 %53
  %60 = bitcast float* %59 to i32*
  store i32 %58, i32* %60, align 4, !tbaa !6714
  %61 = add nsw i64 %38, 2
  %62 = add i32 %43, 100352
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %7, i64 %63
  %65 = bitcast float* %64 to i32*
  %66 = load i32, i32* %65, align 4, !tbaa !6711
  %67 = getelementptr inbounds float, float* %4, i64 %61
  %68 = bitcast float* %67 to i32*
  store i32 %66, i32* %68, align 4, !tbaa !6714
  br label %for_end6.us

for_end6.us:                                      ; preds = %for_body5.us8.preheader, %for_body5.us.us.preheader
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 230
  br i1 %exitcond, label %for_end3, label %for_begin4.preheader.us, !prof !50

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_end6.us, %for_begin4.preheader.preheader
  %indvars.iv.next23 = add nsw i64 %indvars.iv22, 1
  %69 = icmp slt i64 %indvars.iv.next23, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %69, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_max_pool2d(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.481, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !6717
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([147 x i8], [147 x i8]* @.str.482, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !6731
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([147 x i8], [147 x i8]* @.str.483, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 4
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.203, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !6733
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !6747
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 64
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !6749
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 114
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.484, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !6752
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 114
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.485, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = icmp eq i64* %17, null
  br i1 %70, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end18
  %71 = bitcast i64* %17 to <4 x i64>*
  %72 = load <4 x i64>, <4 x i64>* %71, align 8, !tbaa !6754
  %73 = trunc <4 x i64> %72 to <4 x i32>
  %74 = icmp eq <4 x i32> %73, <i32 831744, i32 12996, i32 114, i32 1>
  %rdx.shuf47 = shufflevector <4 x i1> %74, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx48 = and <4 x i1> %74, %rdx.shuf47
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx48, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx48, %rdx.shuf49
  %75 = extractelement <4 x i1> %bin.rdx50, i32 0
  br i1 %75, label %if_end, label %assert_fail19, !prof !5

if_end:                                           ; preds = %assert_end18, %if_then
  %76 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %77 = load i64, i64* %76, align 8
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %assert_end22, label %assert_fail21, !prof !5

assert_fail19:                                    ; preds = %if_then
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([203 x i8], [203 x i8]* @.str.486, i64 0, i64 0))
  ret i32 -1

assert_fail21:                                    ; preds = %if_end
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %if_end
  %81 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %82 = load i32, i32* %81, align 4
  %83 = icmp eq i32 %82, 4
  br i1 %83, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %84 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %84(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.487, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %85 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %86 = load i16, i16* %85, align 2
  %87 = icmp eq i16 %86, 1
  %88 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %89 = load i8, i8* %88, align 1
  %90 = icmp eq i8 %89, 32
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %92 = load i8, i8* %91, align 1
  %93 = icmp eq i8 %92, 2
  %94 = and i1 %90, %93
  %95 = and i1 %87, %94
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = load i64, i64* %25, align 8, !tbaa !6766
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 1
  br i1 %99, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %101 = getelementptr inbounds i64, i64* %25, i64 1
  %102 = load i64, i64* %101, align 8, !tbaa !6780
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 64
  br i1 %104, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.409, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %106 = getelementptr inbounds i64, i64* %25, i64 2
  %107 = load i64, i64* %106, align 8, !tbaa !6782
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 56
  br i1 %109, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %111 = getelementptr inbounds i64, i64* %25, i64 3
  %112 = load i64, i64* %111, align 8, !tbaa !6785
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 56
  br i1 %114, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %116 = icmp eq i64* %27, null
  br i1 %116, label %if_end36, label %if_then35, !prof !50

if_then35:                                        ; preds = %assert_end34
  %117 = bitcast i64* %27 to <4 x i64>*
  %118 = load <4 x i64>, <4 x i64>* %117, align 8, !tbaa !6787
  %119 = trunc <4 x i64> %118 to <4 x i32>
  %120 = icmp eq <4 x i32> %119, <i32 200704, i32 3136, i32 56, i32 1>
  %rdx.shuf = shufflevector <4 x i1> %120, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %120, %rdx.shuf
  %rdx.shuf45 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx46 = and <4 x i1> %bin.rdx, %rdx.shuf45
  %121 = extractelement <4 x i1> %bin.rdx46, i32 0
  br i1 %121, label %if_end36, label %assert_fail37, !prof !5

if_end36:                                         ; preds = %assert_end34, %if_then35
  %122 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %123 = load i64, i64* %122, align 8
  %124 = icmp eq i64 %123, 0
  br i1 %124, label %assert_end40, label %assert_fail39, !prof !5

assert_fail37:                                    ; preds = %if_then35
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([201 x i8], [201 x i8]* @.str.488, i64 0, i64 0))
  ret i32 -1

assert_fail39:                                    ; preds = %if_end36
  %126 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %126(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %if_end36
  %127 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %128 = load i32, i32* %127, align 4
  %129 = icmp eq i32 %128, 1
  br i1 %129, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %131 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %132 = load i32, i32* %131, align 4
  %133 = icmp eq i32 %21, %132
  br i1 %133, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %135 = tail call fastcc i32 @fused_nn_max_pool2d_compute_(i8* %23, i8* %13)
  ret i32 %135
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_max_pool2d_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %42, align 8
  %3 = getelementptr inbounds %42, %42* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %42, %42* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %42* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.489, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.489(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 63
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 64
  %15 = select i1 %14, i32 %13, i32 64
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 64
  %18 = select i1 %17, i32 %16, i32 64
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv19 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next20, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv19, 3136
  %25 = mul nsw i64 %indvars.iv19, 12996
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv16 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next17, %for_end6 ]
  %26 = mul nuw nsw i64 %indvars.iv16, 56
  %27 = add nsw i64 %26, %24
  %28 = mul nuw nsw i64 %indvars.iv16, 228
  %29 = add nsw i64 %28, %25
  %30 = trunc i64 %29 to i32
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next20 = add nsw i64 %indvars.iv19, 1
  %31 = icmp slt i64 %indvars.iv.next20, %23
  br i1 %31, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %27, %indvars.iv
  %33 = getelementptr inbounds float, float* %4, i64 %32
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %34 = shl i32 %indvars.iv.tr, 1
  %35 = add i32 %34, %30
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds float, float* %7, i64 %36
  %38 = load float, float* %37, align 4, !tbaa !6799
  %39 = fcmp olt float %38, 0xC7EFFFFFE0000000
  %40 = select i1 %39, float 0xC7EFFFFFE0000000, float %38
  %41 = or i32 %35, 1
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds float, float* %7, i64 %42
  %44 = load float, float* %43, align 4, !tbaa !6799
  %45 = fcmp ogt float %40, %44
  %46 = select i1 %45, float %40, float %44
  %47 = add i32 %35, 2
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds float, float* %7, i64 %48
  %50 = load float, float* %49, align 4, !tbaa !6799
  %51 = fcmp ogt float %46, %50
  %52 = select i1 %51, float %46, float %50
  %53 = add i32 %35, 114
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds float, float* %7, i64 %54
  %56 = load float, float* %55, align 4, !tbaa !6799
  %57 = fcmp ogt float %52, %56
  %58 = select i1 %57, float %52, float %56
  %59 = add i32 %35, 115
  %60 = sext i32 %59 to i64
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = load float, float* %61, align 4, !tbaa !6799
  %63 = fcmp ogt float %58, %62
  %64 = select i1 %63, float %58, float %62
  %65 = add i32 %35, 116
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds float, float* %7, i64 %66
  %68 = load float, float* %67, align 4, !tbaa !6799
  %69 = fcmp ogt float %64, %68
  %70 = select i1 %69, float %64, float %68
  %71 = add i32 %35, 228
  %72 = sext i32 %71 to i64
  %73 = getelementptr inbounds float, float* %7, i64 %72
  %74 = load float, float* %73, align 4, !tbaa !6799
  %75 = fcmp ogt float %70, %74
  %76 = select i1 %75, float %70, float %74
  %77 = add i32 %35, 229
  %78 = sext i32 %77 to i64
  %79 = getelementptr inbounds float, float* %7, i64 %78
  %80 = load float, float* %79, align 4, !tbaa !6799
  %81 = fcmp ogt float %76, %80
  %82 = select i1 %81, float %76, float %80
  %83 = add i32 %35, 230
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds float, float* %7, i64 %84
  %86 = load float, float* %85, align 4, !tbaa !6799
  %87 = fcmp ogt float %82, %86
  %88 = select i1 %87, float %82, float %86
  store float %88, float* %33, align 4, !tbaa !6802
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next17 = add nuw nsw i64 %indvars.iv16, 1
  %exitcond18 = icmp eq i64 %indvars.iv.next17, 56
  br i1 %exitcond18, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_33(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.490, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !6805
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.491, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !6819
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.492, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !6821
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !6835
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 16
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !6837
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 7
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !6840
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 7
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !6842
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !6846
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 25088, i32 1568, i32 224, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !6858
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.325, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !6862
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !6876
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !6878
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 7
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.326, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !6881
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 7
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.327, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !6883
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 512
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !6887
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 25088, i32 25088, i32 3584, i32 512>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !6899
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.493, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_33_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_33_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %43, align 8
  %3 = getelementptr inbounds %43, %43* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %43, %43* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %43* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.494, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.494(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 6
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 7
  %15 = select i1 %14, i32 %13, i32 7
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 7
  %18 = select i1 %17, i32 %16, i32 7
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end6.6
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end6.6 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 224
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body5 ]
  %27 = add nsw i64 %24, %indvars.iv
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 31
  %30 = lshr i32 %28, 5
  %31 = mul nsw i32 %30, 1568
  %32 = add i32 %26, %31
  %33 = or i32 %32, %29
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to i32*
  %37 = load i32, i32* %36, align 4, !tbaa !6903
  %38 = getelementptr inbounds float, float* %4, i64 %27
  %39 = bitcast float* %38 to i32*
  store i32 %37, i32* %39, align 4, !tbaa !6906
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %40 = add nsw i64 %24, 512
  %41 = add i32 %26, 32
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %42 = add nsw i64 %40, %indvars.iv.1
  %43 = trunc i64 %indvars.iv.1 to i32
  %44 = and i32 %43, 31
  %45 = lshr i32 %43, 5
  %46 = mul nsw i32 %45, 1568
  %47 = add i32 %41, %46
  %48 = or i32 %47, %44
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to i32*
  %52 = load i32, i32* %51, align 4, !tbaa !6903
  %53 = getelementptr inbounds float, float* %4, i64 %42
  %54 = bitcast float* %53 to i32*
  store i32 %52, i32* %54, align 4, !tbaa !6906
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %55 = add nsw i64 %24, 1024
  %56 = add i32 %26, 64
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %57 = add nsw i64 %55, %indvars.iv.2
  %58 = trunc i64 %indvars.iv.2 to i32
  %59 = and i32 %58, 31
  %60 = lshr i32 %58, 5
  %61 = mul nsw i32 %60, 1568
  %62 = add i32 %56, %61
  %63 = or i32 %62, %59
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float* %7, i64 %64
  %66 = bitcast float* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !6903
  %68 = getelementptr inbounds float, float* %4, i64 %57
  %69 = bitcast float* %68 to i32*
  store i32 %67, i32* %69, align 4, !tbaa !6906
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %70 = add nsw i64 %24, 1536
  %71 = add i32 %26, 96
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %72 = add nsw i64 %70, %indvars.iv.3
  %73 = trunc i64 %indvars.iv.3 to i32
  %74 = and i32 %73, 31
  %75 = lshr i32 %73, 5
  %76 = mul nsw i32 %75, 1568
  %77 = add i32 %71, %76
  %78 = or i32 %77, %74
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %7, i64 %79
  %81 = bitcast float* %80 to i32*
  %82 = load i32, i32* %81, align 4, !tbaa !6903
  %83 = getelementptr inbounds float, float* %4, i64 %72
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4, !tbaa !6906
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  %85 = add nsw i64 %24, 2048
  %86 = add i32 %26, 128
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %87 = add nsw i64 %85, %indvars.iv.4
  %88 = trunc i64 %indvars.iv.4 to i32
  %89 = and i32 %88, 31
  %90 = lshr i32 %88, 5
  %91 = mul nsw i32 %90, 1568
  %92 = add i32 %86, %91
  %93 = or i32 %92, %89
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !6903
  %98 = getelementptr inbounds float, float* %4, i64 %87
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !6906
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  %100 = add nsw i64 %24, 2560
  %101 = add i32 %26, 160
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %102 = add nsw i64 %100, %indvars.iv.5
  %103 = trunc i64 %indvars.iv.5 to i32
  %104 = and i32 %103, 31
  %105 = lshr i32 %103, 5
  %106 = mul nsw i32 %105, 1568
  %107 = add i32 %101, %106
  %108 = or i32 %107, %104
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !6903
  %113 = getelementptr inbounds float, float* %4, i64 %102
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !6906
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  %115 = add nsw i64 %24, 3072
  %116 = add i32 %26, 192
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %117 = add nsw i64 %115, %indvars.iv.6
  %118 = trunc i64 %indvars.iv.6 to i32
  %119 = and i32 %118, 31
  %120 = lshr i32 %118, 5
  %121 = mul nsw i32 %120, 1568
  %122 = add i32 %116, %121
  %123 = or i32 %122, %119
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to i32*
  %127 = load i32, i32* %126, align 4, !tbaa !6903
  %128 = getelementptr inbounds float, float* %4, i64 %117
  %129 = bitcast float* %128 to i32*
  store i32 %127, i32* %129, align 4, !tbaa !6906
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %130 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %130, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_38(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.495, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !6909
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.496, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !6923
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.497, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !6925
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !6939
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 16
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !6941
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 28
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !6944
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 28
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !6946
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !6950
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 401408, i32 25088, i32 896, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !6962
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.333, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !6966
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !6980
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 8
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.376, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !6982
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 28
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !6985
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 28
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !6987
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 64
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !6991
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 401408, i32 50176, i32 1792, i32 64>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !7003
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.498, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_38_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_38_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %44, align 8
  %3 = getelementptr inbounds %44, %44* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %44, %44* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %44* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.499, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.499(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 223
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 224
  %15 = select i1 %14, i32 %13, i32 224
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 224
  %18 = select i1 %17, i32 %16, i32 224
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 1792
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 28
  %27 = mul nsw i32 %26, 896
  %28 = sdiv i32 %25, 28
  %29 = mul nsw i32 %28, 50176
  %30 = add i32 %27, %29
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %31 = shl i64 %indvars.iv7, 6
  %32 = add nsw i64 %31, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %33 = shl i32 %indvars.iv7.tr, 5
  %34 = add i32 %30, %33
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %35 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %35, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %36 = add nsw i64 %32, %indvars.iv
  %37 = trunc i64 %indvars.iv to i32
  %38 = and i32 %37, 31
  %39 = lshr i32 %37, 5
  %40 = mul nsw i32 %39, 25088
  %41 = add i32 %34, %40
  %42 = or i32 %41, %38
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds float, float* %7, i64 %43
  %45 = bitcast float* %44 to i32*
  %46 = load i32, i32* %45, align 4, !tbaa !7007
  %47 = getelementptr inbounds float, float* %4, i64 %36
  %48 = bitcast float* %47 to i32*
  store i32 %46, i32* %48, align 4, !tbaa !7010
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_37(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.500, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !7013
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.501, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !7027
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.502, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !7029
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !7043
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 4
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !7045
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 14
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !7048
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 14
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !7050
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 64
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !7054
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 50176, i32 12544, i32 896, i32 64>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !7066
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.503, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !7070
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !7084
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 2
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.280, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !7086
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 14
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.17, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !7089
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 14
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.18, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !7091
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 128
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.270, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !7095
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 50176, i32 25088, i32 1792, i32 128>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !7107
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.504, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_37_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_37_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %45, align 8
  %3 = getelementptr inbounds %45, %45* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %45, %45* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %45* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.505, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.505(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 1792
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 14
  %27 = mul nsw i32 %26, 896
  %28 = sdiv i32 %25, 14
  %29 = mul nsw i32 %28, 25088
  %30 = add i32 %27, %29
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body5 ]
  %31 = add nsw i64 %24, %indvars.iv
  %32 = trunc i64 %indvars.iv to i32
  %33 = and i32 %32, 63
  %34 = lshr i32 %32, 6
  %35 = mul nsw i32 %34, 12544
  %36 = add i32 %30, %35
  %37 = or i32 %36, %33
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds float, float* %7, i64 %38
  %40 = bitcast float* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !7111
  %42 = getelementptr inbounds float, float* %4, i64 %31
  %43 = bitcast float* %42 to i32*
  store i32 %41, i32* %43, align 4, !tbaa !7114
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %44 = or i64 %24, 128
  %45 = or i32 %30, 64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %46 = add nsw i64 %44, %indvars.iv.1
  %47 = trunc i64 %indvars.iv.1 to i32
  %48 = and i32 %47, 63
  %49 = lshr i32 %47, 6
  %50 = mul nsw i32 %49, 12544
  %51 = add i32 %45, %50
  %52 = or i32 %51, %48
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to i32*
  %56 = load i32, i32* %55, align 4, !tbaa !7111
  %57 = getelementptr inbounds float, float* %4, i64 %46
  %58 = bitcast float* %57 to i32*
  store i32 %56, i32* %58, align 4, !tbaa !7114
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %59 = add nsw i64 %24, 256
  %60 = add i32 %30, 128
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %61 = add nsw i64 %59, %indvars.iv.2
  %62 = trunc i64 %indvars.iv.2 to i32
  %63 = and i32 %62, 63
  %64 = lshr i32 %62, 6
  %65 = mul nsw i32 %64, 12544
  %66 = add i32 %60, %65
  %67 = or i32 %66, %63
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = bitcast float* %69 to i32*
  %71 = load i32, i32* %70, align 4, !tbaa !7111
  %72 = getelementptr inbounds float, float* %4, i64 %61
  %73 = bitcast float* %72 to i32*
  store i32 %71, i32* %73, align 4, !tbaa !7114
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 128
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %74 = add nsw i64 %24, 384
  %75 = add i32 %30, 192
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %76 = add nsw i64 %74, %indvars.iv.3
  %77 = trunc i64 %indvars.iv.3 to i32
  %78 = and i32 %77, 63
  %79 = lshr i32 %77, 6
  %80 = mul nsw i32 %79, 12544
  %81 = add i32 %75, %80
  %82 = or i32 %81, %78
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = bitcast float* %84 to i32*
  %86 = load i32, i32* %85, align 4, !tbaa !7111
  %87 = getelementptr inbounds float, float* %4, i64 %76
  %88 = bitcast float* %87 to i32*
  store i32 %86, i32* %88, align 4, !tbaa !7114
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 128
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !50

for_end6.3:                                       ; preds = %for_body5.3
  %89 = add nsw i64 %24, 512
  %90 = add i32 %30, 256
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %91 = add nsw i64 %89, %indvars.iv.4
  %92 = trunc i64 %indvars.iv.4 to i32
  %93 = and i32 %92, 63
  %94 = lshr i32 %92, 6
  %95 = mul nsw i32 %94, 12544
  %96 = add i32 %90, %95
  %97 = or i32 %96, %93
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = bitcast float* %99 to i32*
  %101 = load i32, i32* %100, align 4, !tbaa !7111
  %102 = getelementptr inbounds float, float* %4, i64 %91
  %103 = bitcast float* %102 to i32*
  store i32 %101, i32* %103, align 4, !tbaa !7114
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 128
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !50

for_end6.4:                                       ; preds = %for_body5.4
  %104 = add nsw i64 %24, 640
  %105 = add i32 %30, 320
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %106 = add nsw i64 %104, %indvars.iv.5
  %107 = trunc i64 %indvars.iv.5 to i32
  %108 = and i32 %107, 63
  %109 = lshr i32 %107, 6
  %110 = mul nsw i32 %109, 12544
  %111 = add i32 %105, %110
  %112 = or i32 %111, %108
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to i32*
  %116 = load i32, i32* %115, align 4, !tbaa !7111
  %117 = getelementptr inbounds float, float* %4, i64 %106
  %118 = bitcast float* %117 to i32*
  store i32 %116, i32* %118, align 4, !tbaa !7114
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 128
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !50

for_end6.5:                                       ; preds = %for_body5.5
  %119 = add nsw i64 %24, 768
  %120 = add i32 %30, 384
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %121 = add nsw i64 %119, %indvars.iv.6
  %122 = trunc i64 %indvars.iv.6 to i32
  %123 = and i32 %122, 63
  %124 = lshr i32 %122, 6
  %125 = mul nsw i32 %124, 12544
  %126 = add i32 %120, %125
  %127 = or i32 %126, %123
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds float, float* %7, i64 %128
  %130 = bitcast float* %129 to i32*
  %131 = load i32, i32* %130, align 4, !tbaa !7111
  %132 = getelementptr inbounds float, float* %4, i64 %121
  %133 = bitcast float* %132 to i32*
  store i32 %131, i32* %133, align 4, !tbaa !7114
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 128
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !50

for_end6.6:                                       ; preds = %for_body5.6
  %134 = add nsw i64 %24, 896
  %135 = add i32 %30, 448
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %136 = add nsw i64 %134, %indvars.iv.7
  %137 = trunc i64 %indvars.iv.7 to i32
  %138 = and i32 %137, 63
  %139 = lshr i32 %137, 6
  %140 = mul nsw i32 %139, 12544
  %141 = add i32 %135, %140
  %142 = or i32 %141, %138
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to i32*
  %146 = load i32, i32* %145, align 4, !tbaa !7111
  %147 = getelementptr inbounds float, float* %4, i64 %136
  %148 = bitcast float* %147 to i32*
  store i32 %146, i32* %148, align 4, !tbaa !7114
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 128
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !50

for_end6.7:                                       ; preds = %for_body5.7
  %149 = add nsw i64 %24, 1024
  %150 = add i32 %30, 512
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %151 = add nsw i64 %149, %indvars.iv.8
  %152 = trunc i64 %indvars.iv.8 to i32
  %153 = and i32 %152, 63
  %154 = lshr i32 %152, 6
  %155 = mul nsw i32 %154, 12544
  %156 = add i32 %150, %155
  %157 = or i32 %156, %153
  %158 = sext i32 %157 to i64
  %159 = getelementptr inbounds float, float* %7, i64 %158
  %160 = bitcast float* %159 to i32*
  %161 = load i32, i32* %160, align 4, !tbaa !7111
  %162 = getelementptr inbounds float, float* %4, i64 %151
  %163 = bitcast float* %162 to i32*
  store i32 %161, i32* %163, align 4, !tbaa !7114
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 128
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !50

for_end6.8:                                       ; preds = %for_body5.8
  %164 = add nsw i64 %24, 1152
  %165 = add i32 %30, 576
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %166 = add nsw i64 %164, %indvars.iv.9
  %167 = trunc i64 %indvars.iv.9 to i32
  %168 = and i32 %167, 63
  %169 = lshr i32 %167, 6
  %170 = mul nsw i32 %169, 12544
  %171 = add i32 %165, %170
  %172 = or i32 %171, %168
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to i32*
  %176 = load i32, i32* %175, align 4, !tbaa !7111
  %177 = getelementptr inbounds float, float* %4, i64 %166
  %178 = bitcast float* %177 to i32*
  store i32 %176, i32* %178, align 4, !tbaa !7114
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 128
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !50

for_end6.9:                                       ; preds = %for_body5.9
  %179 = add nsw i64 %24, 1280
  %180 = add i32 %30, 640
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %181 = add nsw i64 %179, %indvars.iv.10
  %182 = trunc i64 %indvars.iv.10 to i32
  %183 = and i32 %182, 63
  %184 = lshr i32 %182, 6
  %185 = mul nsw i32 %184, 12544
  %186 = add i32 %180, %185
  %187 = or i32 %186, %183
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4, !tbaa !7111
  %192 = getelementptr inbounds float, float* %4, i64 %181
  %193 = bitcast float* %192 to i32*
  store i32 %191, i32* %193, align 4, !tbaa !7114
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 128
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !50

for_end6.10:                                      ; preds = %for_body5.10
  %194 = add nsw i64 %24, 1408
  %195 = add i32 %30, 704
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %196 = add nsw i64 %194, %indvars.iv.11
  %197 = trunc i64 %indvars.iv.11 to i32
  %198 = and i32 %197, 63
  %199 = lshr i32 %197, 6
  %200 = mul nsw i32 %199, 12544
  %201 = add i32 %195, %200
  %202 = or i32 %201, %198
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds float, float* %7, i64 %203
  %205 = bitcast float* %204 to i32*
  %206 = load i32, i32* %205, align 4, !tbaa !7111
  %207 = getelementptr inbounds float, float* %4, i64 %196
  %208 = bitcast float* %207 to i32*
  store i32 %206, i32* %208, align 4, !tbaa !7114
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 128
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !50

for_end6.11:                                      ; preds = %for_body5.11
  %209 = add nsw i64 %24, 1536
  %210 = add i32 %30, 768
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %211 = add nsw i64 %209, %indvars.iv.12
  %212 = trunc i64 %indvars.iv.12 to i32
  %213 = and i32 %212, 63
  %214 = lshr i32 %212, 6
  %215 = mul nsw i32 %214, 12544
  %216 = add i32 %210, %215
  %217 = or i32 %216, %213
  %218 = sext i32 %217 to i64
  %219 = getelementptr inbounds float, float* %7, i64 %218
  %220 = bitcast float* %219 to i32*
  %221 = load i32, i32* %220, align 4, !tbaa !7111
  %222 = getelementptr inbounds float, float* %4, i64 %211
  %223 = bitcast float* %222 to i32*
  store i32 %221, i32* %223, align 4, !tbaa !7114
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 128
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !50

for_end6.12:                                      ; preds = %for_body5.12
  %224 = add nsw i64 %24, 1664
  %225 = add i32 %30, 832
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %226 = add nsw i64 %224, %indvars.iv.13
  %227 = trunc i64 %indvars.iv.13 to i32
  %228 = and i32 %227, 63
  %229 = lshr i32 %227, 6
  %230 = mul nsw i32 %229, 12544
  %231 = add i32 %225, %230
  %232 = or i32 %231, %228
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to i32*
  %236 = load i32, i32* %235, align 4, !tbaa !7111
  %237 = getelementptr inbounds float, float* %4, i64 %226
  %238 = bitcast float* %237 to i32*
  store i32 %236, i32* %238, align 4, !tbaa !7114
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 128
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !50

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %239 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %239, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_nn_pad(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([82 x i8], [82 x i8]* @.str.506, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !7117
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([157 x i8], [157 x i8]* @.str.507, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !7131
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([157 x i8], [157 x i8]* @.str.508, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !7133
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !7147
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 8
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !7149
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 112
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.509, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !7152
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 112
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.510, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !7154
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 8
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.511, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !7158
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 802816, i32 100352, i32 896, i32 8>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !7170
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf49 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %79, %rdx.shuf49
  %rdx.shuf51 = shufflevector <4 x i1> %bin.rdx50, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %bin.rdx50, %rdx.shuf51
  %84 = extractelement <4 x i1> %bin.rdx52, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.512, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 4
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.487, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !7174
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !7188
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 64
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.409, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !7190
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 114
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.513, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !7193
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 114
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.514, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = icmp eq i64* %27, null
  br i1 %126, label %if_end38, label %if_then37, !prof !50

if_then37:                                        ; preds = %assert_end36
  %127 = bitcast i64* %27 to <4 x i64>*
  %128 = load <4 x i64>, <4 x i64>* %127, align 8, !tbaa !7195
  %129 = trunc <4 x i64> %128 to <4 x i32>
  %130 = icmp eq <4 x i32> %129, <i32 831744, i32 12996, i32 114, i32 1>
  %rdx.shuf = shufflevector <4 x i1> %130, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %130, %rdx.shuf
  %rdx.shuf47 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx48 = and <4 x i1> %bin.rdx, %rdx.shuf47
  %131 = extractelement <4 x i1> %bin.rdx48, i32 0
  br i1 %131, label %if_end38, label %assert_fail39, !prof !5

if_end38:                                         ; preds = %assert_end36, %if_then37
  %132 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %133 = load i64, i64* %132, align 8
  %134 = icmp eq i64 %133, 0
  br i1 %134, label %assert_end42, label %assert_fail41, !prof !5

assert_fail39:                                    ; preds = %if_then37
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([203 x i8], [203 x i8]* @.str.515, i64 0, i64 0))
  ret i32 -1

assert_fail41:                                    ; preds = %if_end38
  %136 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %136(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %if_end38
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %138 = load i32, i32* %137, align 4
  %139 = icmp eq i32 %138, 1
  br i1 %139, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %140 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %140(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %141 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %142 = load i32, i32* %141, align 4
  %143 = icmp eq i32 %21, %142
  br i1 %143, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %144 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %144(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %145 = tail call fastcc i32 @fused_layout_transform_nn_pad_compute_(i8* %23, i8* %13)
  ret i32 %145
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_nn_pad_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %46, align 8
  %3 = getelementptr inbounds %46, %46* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %46, %46* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %46* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.516, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.516(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 63
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 64
  %15 = select i1 %14, i32 %13, i32 64
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 64
  %18 = select i1 %17, i32 %16, i32 64
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 64
  %21 = select i1 %20, i32 %16, i32 64
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -12996
  %23 = add i32 %22, -12996
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv13 = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next14, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul i32 %indvar, 12996
  %29 = add i32 %23, %28
  %30 = mul nsw i64 %indvars.iv13, 12996
  %31 = trunc i64 %indvars.iv13 to i32
  %32 = and i64 %indvars.iv13, 7
  %33 = ashr i32 %31, 3
  %34 = mul nsw i32 %33, 100352
  %35 = zext i32 %34 to i64
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv9 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next10, %for_end6 ]
  %36 = mul nuw nsw i64 %indvars.iv9, 114
  %37 = add nsw i64 %36, %30
  %38 = trunc i64 %indvars.iv9 to i32
  %39 = add i32 %38, -1
  %40 = icmp ult i32 %39, 112
  %41 = mul nuw nsw i64 %indvars.iv9, 896
  %42 = add nuw i64 %41, %35
  br i1 %40, label %for_body5.us, label %for_body5.preheader

for_body5.preheader:                              ; preds = %for_begin4.preheader
  %43 = trunc i64 %36 to i32
  %44 = add i32 %29, %43
  %45 = sext i32 %44 to i64
  %scevgep = getelementptr float, float* %4, i64 %45
  %scevgep8 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %scevgep8, i8 0, i64 456, i1 false)
  br label %for_end6

for_body5.us:                                     ; preds = %for_begin4.preheader, %if_end.us
  %indvars.iv = phi i64 [ %indvars.iv.next, %if_end.us ], [ 0, %for_begin4.preheader ]
  %46 = add nsw i64 %37, %indvars.iv
  %47 = trunc i64 %indvars.iv to i32
  switch i32 %47, label %if_then.us [
    i32 113, label %if_end.us
    i32 0, label %if_end.us
  ]

if_then.us:                                       ; preds = %for_body5.us
  %48 = shl i64 %indvars.iv, 3
  %49 = add i64 %42, %48
  %50 = or i64 %32, %49
  %51 = shl i64 %50, 32
  %sext = add i64 %51, -3882650435584
  %52 = ashr exact i64 %sext, 32
  %53 = getelementptr inbounds float, float* %7, i64 %52
  %54 = load float, float* %53, align 4, !tbaa !7207
  br label %if_end.us

if_end.us:                                        ; preds = %if_then.us, %for_body5.us, %for_body5.us
  %55 = phi float [ %54, %if_then.us ], [ 0.000000e+00, %for_body5.us ], [ 0.000000e+00, %for_body5.us ]
  %56 = getelementptr inbounds float, float* %4, i64 %46
  store float %55, float* %56, align 4, !tbaa !7210
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 114
  br i1 %exitcond, label %for_end6, label %for_body5.us, !prof !50

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next14 = add nsw i64 %indvars.iv13, 1
  %57 = icmp slt i64 %indvars.iv.next14, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %57, label %for_begin1.preheader, label %for_end, !prof !5

for_end6:                                         ; preds = %if_end.us, %for_body5.preheader
  %indvars.iv.next10 = add nuw nsw i64 %indvars.iv9, 1
  %exitcond12 = icmp eq i64 %indvars.iv.next10, 114
  br i1 %exitcond12, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_39(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.517, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !7213
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.518, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !7227
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.519, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !7229
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !7243
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 4
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !7245
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 28
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !7248
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 28
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !7250
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 32
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !7254
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 100352, i32 25088, i32 896, i32 32>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !7266
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.269, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !7270
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !7284
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 32
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.520, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !7286
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 28
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !7289
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 28
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !7291
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 4
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !7295
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 100352, i32 3136, i32 112, i32 4>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !7307
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.521, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_39_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_39_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %47, align 8
  %3 = getelementptr inbounds %47, %47* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %47, %47* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %47* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.522, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.522(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 895
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 896
  %15 = select i1 %14, i32 %13, i32 896
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 896
  %18 = select i1 %17, i32 %16, i32 896
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 112
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = sdiv i32 %25, 28
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 28
  %29 = mul nsw i32 %28, 896
  %30 = and i32 %27, 28
  %31 = ashr i32 %26, 3
  %32 = mul nsw i32 %31, 25088
  %33 = and i32 %27, 28
  %34 = or i32 %33, 1
  %35 = ashr i32 %26, 3
  %36 = mul nsw i32 %35, 25088
  %37 = and i32 %27, 28
  %38 = or i32 %37, 2
  %39 = ashr i32 %26, 3
  %40 = mul nsw i32 %39, 25088
  %41 = and i32 %27, 28
  %42 = or i32 %41, 3
  %43 = ashr i32 %26, 3
  %44 = mul nsw i32 %43, 25088
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_begin4.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_begin4.preheader ]
  %45 = shl i64 %indvars.iv, 2
  %46 = add nsw i64 %45, %24
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %47 = shl i32 %indvars.iv.tr, 5
  %48 = add i32 %29, %47
  %49 = add i32 %48, %32
  %50 = or i32 %49, %30
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds float, float* %7, i64 %51
  %53 = bitcast float* %52 to i32*
  %54 = load i32, i32* %53, align 4, !tbaa !7311
  %55 = getelementptr inbounds float, float* %4, i64 %46
  %56 = bitcast float* %55 to i32*
  store i32 %54, i32* %56, align 4, !tbaa !7314
  %57 = or i64 %46, 1
  %58 = add i32 %48, %36
  %59 = or i32 %58, %34
  %60 = sext i32 %59 to i64
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = bitcast float* %61 to i32*
  %63 = load i32, i32* %62, align 4, !tbaa !7311
  %64 = getelementptr inbounds float, float* %4, i64 %57
  %65 = bitcast float* %64 to i32*
  store i32 %63, i32* %65, align 4, !tbaa !7314
  %66 = or i64 %46, 2
  %67 = add i32 %48, %40
  %68 = or i32 %67, %38
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to i32*
  %72 = load i32, i32* %71, align 4, !tbaa !7311
  %73 = getelementptr inbounds float, float* %4, i64 %66
  %74 = bitcast float* %73 to i32*
  store i32 %72, i32* %74, align 4, !tbaa !7314
  %75 = or i64 %46, 3
  %76 = add i32 %48, %44
  %77 = or i32 %76, %42
  %78 = sext i32 %77 to i64
  %79 = getelementptr inbounds float, float* %7, i64 %78
  %80 = bitcast float* %79 to i32*
  %81 = load i32, i32* %80, align 4, !tbaa !7311
  %82 = getelementptr inbounds float, float* %4, i64 %75
  %83 = bitcast float* %82 to i32*
  store i32 %81, i32* %83, align 4, !tbaa !7314
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 28
  br i1 %exitcond, label %for_end3, label %for_begin4.preheader, !prof !50

for_end3:                                         ; preds = %for_begin4.preheader
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %84 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %84, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_softmax(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([69 x i8], [69 x i8]* @.str.523, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !7317
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([144 x i8], [144 x i8]* @.str.524, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !7331
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([144 x i8], [144 x i8]* @.str.525, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 2
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.526, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !7333
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !7347
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 1000
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.527, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = icmp eq i64* %17, null
  br i1 %60, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end14
  %61 = load i64, i64* %17, align 8, !tbaa !7349
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 1000
  %64 = getelementptr inbounds i64, i64* %17, i64 1
  %65 = load i64, i64* %64, align 8, !tbaa !7363
  %66 = trunc i64 %65 to i32
  %67 = icmp eq i32 %66, 1
  %68 = and i1 %63, %67
  br i1 %68, label %if_end, label %assert_fail15, !prof !5

if_end:                                           ; preds = %assert_end14, %if_then
  %69 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %70 = load i64, i64* %69, align 8
  %71 = icmp eq i64 %70, 0
  br i1 %71, label %assert_end18, label %assert_fail17, !prof !5

assert_fail15:                                    ; preds = %if_then
  %72 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %72(i8* getelementptr inbounds ([125 x i8], [125 x i8]* @.str.528, i64 0, i64 0))
  ret i32 -1

assert_fail17:                                    ; preds = %if_end
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %if_end
  %74 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 2
  br i1 %76, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.342, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %78 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %90 = load i64, i64* %25, align 8, !tbaa !7365
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %94 = getelementptr inbounds i64, i64* %25, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !7379
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 1000
  br i1 %97, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.529, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %99 = icmp eq i64* %27, null
  br i1 %99, label %if_end28, label %if_then27, !prof !50

if_then27:                                        ; preds = %assert_end26
  %100 = load i64, i64* %27, align 8, !tbaa !7381
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 1000
  %103 = getelementptr inbounds i64, i64* %27, i64 1
  %104 = load i64, i64* %103, align 8, !tbaa !7395
  %105 = trunc i64 %104 to i32
  %106 = icmp eq i32 %105, 1
  %107 = and i1 %102, %106
  br i1 %107, label %if_end28, label %assert_fail29, !prof !5

if_end28:                                         ; preds = %assert_end26, %if_then27
  %108 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %109 = load i64, i64* %108, align 8
  %110 = icmp eq i64 %109, 0
  br i1 %110, label %assert_end32, label %assert_fail31, !prof !5

assert_fail29:                                    ; preds = %if_then27
  %111 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %111(i8* getelementptr inbounds ([125 x i8], [125 x i8]* @.str.530, i64 0, i64 0))
  ret i32 -1

assert_fail31:                                    ; preds = %if_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %if_end28
  %113 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %114 = load i32, i32* %113, align 4
  %115 = icmp eq i32 %114, 1
  br i1 %115, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %116 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %116(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %117 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %118 = load i32, i32* %117, align 4
  %119 = icmp eq i32 %21, %118
  br i1 %119, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  tail call fastcc void @fused_nn_softmax_compute_(i8* %13, i8* %23, i32 %21)
  ret i32 0
}

; Function Attrs: noinline
define private fastcc void @fused_nn_softmax_compute_(i8* noalias nocapture readonly, i8* noalias nocapture, i32) unnamed_addr #0 {
entry:
  %3 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %4 = tail call i8* %3(i32 1, i32 %2, i64 4000, i32 2, i32 32)
  %5 = bitcast i8* %0 to float*
  br label %for_body

for_begin1.preheader:                             ; preds = %for_body
  %6 = bitcast i8* %4 to float*
  %broadcast.splatinsert15 = insertelement <4 x float> undef, float %17, i32 0
  %broadcast.splat16 = shufflevector <4 x float> %broadcast.splatinsert15, <4 x float> undef, <4 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %for_begin1.preheader
  %index = phi i64 [ 0, %for_begin1.preheader ], [ %index.next, %vector.body ]
  %7 = getelementptr inbounds float, float* %5, i64 %index
  %8 = bitcast float* %7 to <4 x float>*
  %wide.load = load <4 x float>, <4 x float>* %8, align 4, !tbaa !7397
  %9 = fsub <4 x float> %wide.load, %broadcast.splat16
  %10 = call <4 x float> @llvm.exp.v4f32(<4 x float> %9)
  %11 = getelementptr inbounds float, float* %6, i64 %index
  %12 = bitcast float* %11 to <4 x float>*
  store <4 x float> %10, <4 x float>* %12, align 4, !tbaa !7400
  %index.next = add i64 %index, 4
  %13 = icmp eq i64 %index.next, 1000
  br i1 %13, label %for_body5, label %vector.body, !llvm.loop !7403

for_body:                                         ; preds = %for_body, %entry
  %indvars.iv10 = phi i64 [ 0, %entry ], [ %indvars.iv.next11, %for_body ]
  %.02 = phi float [ 0xC7EFFFFFE0000000, %entry ], [ %17, %for_body ]
  %14 = getelementptr inbounds float, float* %5, i64 %indvars.iv10
  %15 = load float, float* %14, align 4, !tbaa !7397
  %16 = fcmp ogt float %.02, %15
  %17 = select i1 %16, float %.02, float %15
  %indvars.iv.next11 = add nuw nsw i64 %indvars.iv10, 1
  %exitcond12 = icmp eq i64 %indvars.iv.next11, 1000
  br i1 %exitcond12, label %for_begin1.preheader, label %for_body, !prof !50

for_begin7.preheader:                             ; preds = %for_body5
  %18 = bitcast i8* %1 to float*
  %broadcast.splatinsert29 = insertelement <4 x float> undef, float %27, i32 0
  %broadcast.splat30 = shufflevector <4 x float> %broadcast.splatinsert29, <4 x float> undef, <4 x i32> zeroinitializer
  br label %vector.body17

vector.body17:                                    ; preds = %vector.body17, %for_begin7.preheader
  %index21 = phi i64 [ 0, %for_begin7.preheader ], [ %index.next22, %vector.body17 ]
  %19 = getelementptr inbounds float, float* %6, i64 %index21
  %20 = bitcast float* %19 to <4 x float>*
  %wide.load28 = load <4 x float>, <4 x float>* %20, align 4, !tbaa !7400
  %21 = fdiv <4 x float> %wide.load28, %broadcast.splat30
  %22 = getelementptr inbounds float, float* %18, i64 %index21
  %23 = bitcast float* %22 to <4 x float>*
  store <4 x float> %21, <4 x float>* %23, align 4, !tbaa !7404
  %index.next22 = add i64 %index21, 4
  %24 = icmp eq i64 %index.next22, 1000
  br i1 %24, label %for_end9, label %vector.body17, !llvm.loop !7407

for_body5:                                        ; preds = %vector.body, %for_body5
  %indvars.iv4 = phi i64 [ %indvars.iv.next5, %for_body5 ], [ 0, %vector.body ]
  %.0151 = phi float [ %27, %for_body5 ], [ 0.000000e+00, %vector.body ]
  %25 = getelementptr inbounds float, float* %6, i64 %indvars.iv4
  %26 = load float, float* %25, align 4, !tbaa !7400
  %27 = fadd float %.0151, %26
  %indvars.iv.next5 = add nuw nsw i64 %indvars.iv4, 1
  %exitcond6 = icmp eq i64 %indvars.iv.next5, 1000
  br i1 %exitcond6, label %for_begin7.preheader, label %for_body5, !prof !50

for_end9:                                         ; preds = %vector.body17
  %28 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %29 = tail call i32 %28(i32 1, i32 %2, i8* nonnull %4)
  ret void
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 7
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([113 x i8], [113 x i8]* @.str.531, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !7408
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !7422
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !7425
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !7427
  %30 = getelementptr inbounds i8, i8* %0, i64 40
  %31 = bitcast i8* %30 to %1**
  %32 = load %1*, %1** %31, align 8
  %33 = getelementptr inbounds i8, i8* %1, i64 20
  %34 = bitcast i8* %33 to i32*
  %35 = load i32, i32* %34, align 4, !tbaa !7431
  %36 = getelementptr inbounds i8, i8* %0, i64 48
  %37 = bitcast i8* %36 to %1**
  %38 = load %1*, %1** %37, align 8
  %39 = getelementptr inbounds i8, i8* %1, i64 24
  %40 = bitcast i8* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !7433
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %49 = load i32, i32* %48, align 4
  %50 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %51 = load i32, i32* %50, align 4
  %52 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %65 = load i8*, i8** %64, align 8
  %66 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %67 = load i64*, i64** %66, align 8
  %68 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %69 = load i64*, i64** %68, align 8
  %70 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %71 = load i8*, i8** %70, align 8
  %72 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %73 = load i64*, i64** %72, align 8
  %74 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %75 = load i64*, i64** %74, align 8
  %76 = getelementptr inbounds %1, %1* %32, i64 0, i32 0
  %77 = load i8*, i8** %76, align 8
  %78 = getelementptr inbounds %1, %1* %32, i64 0, i32 4
  %79 = load i64*, i64** %78, align 8
  %80 = getelementptr inbounds %1, %1* %32, i64 0, i32 5
  %81 = load i64*, i64** %80, align 8
  %82 = getelementptr inbounds %1, %1* %38, i64 0, i32 0
  %83 = load i8*, i8** %82, align 8
  %84 = getelementptr inbounds %1, %1* %38, i64 0, i32 4
  %85 = load i64*, i64** %84, align 8
  %86 = getelementptr inbounds %1, %1* %38, i64 0, i32 5
  %87 = load i64*, i64** %86, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %88 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %88(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.532, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %89 = getelementptr inbounds i8, i8* %1, i64 4
  %90 = bitcast i8* %89 to i32*
  %91 = load i32, i32* %90, align 4, !tbaa !7436
  switch i32 %91, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.533, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.534, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.535, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.536, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  switch i32 %35, label %assert_fail11 [
    i32 13, label %assert_end12
    i32 7, label %assert_end12
    i32 4, label %assert_end12
    i32 3, label %assert_end12
  ]

assert_fail11:                                    ; preds = %assert_end10
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.537, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10, %assert_end10, %assert_end10, %assert_end10
  switch i32 %41, label %assert_fail13 [
    i32 13, label %assert_end14
    i32 7, label %assert_end14
    i32 4, label %assert_end14
    i32 3, label %assert_end14
  ]

assert_fail13:                                    ; preds = %assert_end12
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([188 x i8], [188 x i8]* @.str.538, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12, %assert_end12, %assert_end12, %assert_end12
  %98 = icmp eq i32 %49, 1
  br i1 %98, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %99 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %99(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %100 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %101 = load i32, i32* %100, align 4
  %102 = icmp eq i32 %101, 5
  br i1 %102, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %104 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %105 = load i16, i16* %104, align 2
  %106 = icmp eq i16 %105, 1
  %107 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %108 = load i8, i8* %107, align 1
  %109 = icmp eq i8 %108, 32
  %110 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %111 = load i8, i8* %110, align 1
  %112 = icmp eq i8 %111, 2
  %113 = and i1 %109, %112
  %114 = and i1 %106, %113
  br i1 %114, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %116 = load i64, i64* %45, align 8, !tbaa !7438
  %117 = trunc i64 %116 to i32
  %118 = icmp eq i32 %117, 1
  br i1 %118, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %119 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %119(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %120 = getelementptr inbounds i64, i64* %45, i64 1
  %121 = load i64, i64* %120, align 8, !tbaa !7452
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %122, 32
  br i1 %123, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %124 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %124(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.539, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %125 = getelementptr inbounds i64, i64* %45, i64 2
  %126 = load i64, i64* %125, align 8, !tbaa !7454
  %127 = trunc i64 %126 to i32
  %128 = icmp eq i32 %127, 28
  br i1 %128, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %130 = getelementptr inbounds i64, i64* %45, i64 3
  %131 = load i64, i64* %130, align 8, !tbaa !7457
  %132 = trunc i64 %131 to i32
  %133 = icmp eq i32 %132, 28
  br i1 %133, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %135 = getelementptr inbounds i64, i64* %45, i64 4
  %136 = load i64, i64* %135, align 8, !tbaa !7459
  %137 = trunc i64 %136 to i32
  %138 = icmp eq i32 %137, 4
  br i1 %138, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %139 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %139(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %140 = icmp eq i64* %47, null
  br i1 %140, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end30
  %141 = bitcast i64* %47 to <4 x i64>*
  %142 = load <4 x i64>, <4 x i64>* %141, align 8, !tbaa !7463
  %143 = trunc <4 x i64> %142 to <4 x i32>
  %144 = icmp eq <4 x i32> %143, <i32 100352, i32 3136, i32 112, i32 4>
  %145 = getelementptr inbounds i64, i64* %47, i64 4
  %146 = load i64, i64* %145, align 8, !tbaa !7475
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 1
  %rdx.shuf197 = shufflevector <4 x i1> %144, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx198 = and <4 x i1> %144, %rdx.shuf197
  %rdx.shuf199 = shufflevector <4 x i1> %bin.rdx198, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx200 = and <4 x i1> %bin.rdx198, %rdx.shuf199
  %149 = extractelement <4 x i1> %bin.rdx200, i32 0
  %150 = and i1 %149, %148
  br i1 %150, label %if_end, label %assert_fail31, !prof !5

if_end:                                           ; preds = %assert_end30, %if_then
  %151 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %152 = load i64, i64* %151, align 8
  %153 = icmp eq i64 %152, 0
  br i1 %153, label %assert_end34, label %assert_fail33, !prof !5

assert_fail31:                                    ; preds = %if_then
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.540, i64 0, i64 0))
  ret i32 -1

assert_fail33:                                    ; preds = %if_end
  %155 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %155(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %if_end
  %156 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %157 = load i32, i32* %156, align 4
  %158 = icmp eq i32 %157, 6
  br i1 %158, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %160 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %161 = load i16, i16* %160, align 2
  %162 = icmp eq i16 %161, 1
  %163 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %164 = load i8, i8* %163, align 1
  %165 = icmp eq i8 %164, 32
  %166 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %167 = load i8, i8* %166, align 1
  %168 = icmp eq i8 %167, 2
  %169 = and i1 %165, %168
  %170 = and i1 %162, %169
  br i1 %170, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %172 = load i64, i64* %55, align 8, !tbaa !7479
  %173 = trunc i64 %172 to i32
  %174 = icmp eq i32 %173, 16
  br i1 %174, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %175 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %175(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %176 = getelementptr inbounds i64, i64* %55, i64 1
  %177 = load i64, i64* %176, align 8, !tbaa !7493
  %178 = trunc i64 %177 to i32
  %179 = icmp eq i32 %178, 32
  br i1 %179, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %180 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %180(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.520, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %181 = getelementptr inbounds i64, i64* %55, i64 2
  %182 = load i64, i64* %181, align 8, !tbaa !7495
  %183 = trunc i64 %182 to i32
  %184 = icmp eq i32 %183, 1
  br i1 %184, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %185 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %185(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %186 = getelementptr inbounds i64, i64* %55, i64 3
  %187 = load i64, i64* %186, align 8, !tbaa !7498
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  br i1 %189, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %190 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %190(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %191 = getelementptr inbounds i64, i64* %55, i64 4
  %192 = load i64, i64* %191, align 8, !tbaa !7500
  %193 = trunc i64 %192 to i32
  %194 = icmp eq i32 %193, 4
  br i1 %194, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %196 = getelementptr inbounds i64, i64* %55, i64 5
  %197 = load i64, i64* %196, align 8, !tbaa !7504
  %198 = trunc i64 %197 to i32
  %199 = icmp eq i32 %198, 32
  br i1 %199, label %assert_end50, label %assert_fail49, !prof !5

assert_fail49:                                    ; preds = %assert_end48
  %200 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %200(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %assert_end48
  %201 = icmp eq i64* %57, null
  br i1 %201, label %if_end52, label %if_then51, !prof !50

if_then51:                                        ; preds = %assert_end50
  %202 = bitcast i64* %57 to <4 x i64>*
  %203 = load <4 x i64>, <4 x i64>* %202, align 8, !tbaa !7506
  %204 = trunc <4 x i64> %203 to <4 x i32>
  %205 = icmp eq <4 x i32> %204, <i32 4096, i32 128, i32 128, i32 128>
  %206 = getelementptr inbounds i64, i64* %57, i64 4
  %207 = load i64, i64* %206, align 8, !tbaa !7518
  %208 = trunc i64 %207 to i32
  %209 = icmp eq i32 %208, 32
  %210 = getelementptr inbounds i64, i64* %57, i64 5
  %211 = load i64, i64* %210, align 8, !tbaa !7522
  %212 = trunc i64 %211 to i32
  %213 = icmp eq i32 %212, 1
  %rdx.shuf193 = shufflevector <4 x i1> %205, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx194 = and <4 x i1> %205, %rdx.shuf193
  %rdx.shuf195 = shufflevector <4 x i1> %bin.rdx194, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx196 = and <4 x i1> %bin.rdx194, %rdx.shuf195
  %214 = extractelement <4 x i1> %bin.rdx196, i32 0
  %215 = and i1 %214, %209
  %216 = and i1 %215, %213
  br i1 %216, label %if_end52, label %assert_fail53, !prof !5

if_end52:                                         ; preds = %assert_end50, %if_then51
  %217 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %218 = load i64, i64* %217, align 8
  %219 = icmp eq i64 %218, 0
  br i1 %219, label %assert_end56, label %assert_fail55, !prof !5

assert_fail53:                                    ; preds = %if_then51
  %220 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %220(i8* getelementptr inbounds ([272 x i8], [272 x i8]* @.str.541, i64 0, i64 0))
  ret i32 -1

assert_fail55:                                    ; preds = %if_end52
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %if_end52
  %222 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %223 = load i32, i32* %222, align 4
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %226 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %227 = load i32, i32* %226, align 4
  %228 = icmp eq i32 %51, %227
  br i1 %228, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %229 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %229(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %230 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %231 = load i32, i32* %230, align 4
  %232 = icmp eq i32 %231, 4
  br i1 %232, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %234 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %235 = load i16, i16* %234, align 2
  %236 = icmp eq i16 %235, 1
  %237 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %238 = load i8, i8* %237, align 1
  %239 = icmp eq i8 %238, 32
  %240 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %241 = load i8, i8* %240, align 1
  %242 = icmp eq i8 %241, 2
  %243 = and i1 %239, %242
  %244 = and i1 %236, %243
  br i1 %244, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %246 = load i64, i64* %61, align 8, !tbaa !7524
  %247 = trunc i64 %246 to i32
  %248 = icmp eq i32 %247, 16
  br i1 %248, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %250 = getelementptr inbounds i64, i64* %61, i64 1
  %251 = load i64, i64* %250, align 8, !tbaa !7538
  %252 = trunc i64 %251 to i32
  %253 = icmp eq i32 %252, 1
  br i1 %253, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %254 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %254(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %255 = getelementptr inbounds i64, i64* %61, i64 2
  %256 = load i64, i64* %255, align 8, !tbaa !7540
  %257 = trunc i64 %256 to i32
  %258 = icmp eq i32 %257, 1
  br i1 %258, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %259 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %259(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %260 = getelementptr inbounds i64, i64* %61, i64 3
  %261 = load i64, i64* %260, align 8, !tbaa !7543
  %262 = trunc i64 %261 to i32
  %263 = icmp eq i32 %262, 32
  br i1 %263, label %assert_end72, label %assert_fail71, !prof !5

assert_fail71:                                    ; preds = %assert_end70
  %264 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %264(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end72:                                     ; preds = %assert_end70
  %265 = icmp eq i64* %63, null
  br i1 %265, label %if_end74, label %if_then73, !prof !50

if_then73:                                        ; preds = %assert_end72
  %266 = bitcast i64* %63 to <4 x i64>*
  %267 = load <4 x i64>, <4 x i64>* %266, align 8, !tbaa !7545
  %268 = trunc <4 x i64> %267 to <4 x i32>
  %269 = icmp eq <4 x i32> %268, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf189 = shufflevector <4 x i1> %269, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx190 = and <4 x i1> %269, %rdx.shuf189
  %rdx.shuf191 = shufflevector <4 x i1> %bin.rdx190, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx192 = and <4 x i1> %bin.rdx190, %rdx.shuf191
  %270 = extractelement <4 x i1> %bin.rdx192, i32 0
  br i1 %270, label %if_end74, label %assert_fail75, !prof !5

if_end74:                                         ; preds = %assert_end72, %if_then73
  %271 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %272 = load i64, i64* %271, align 8
  %273 = icmp eq i64 %272, 0
  br i1 %273, label %assert_end78, label %assert_fail77, !prof !5

assert_fail75:                                    ; preds = %if_then73
  %274 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %274(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail77:                                    ; preds = %if_end74
  %275 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %275(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %if_end74
  %276 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %277 = load i32, i32* %276, align 4
  %278 = icmp eq i32 %277, 1
  br i1 %278, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %279 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %279(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %280 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %281 = load i32, i32* %280, align 4
  %282 = icmp eq i32 %51, %281
  br i1 %282, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %283 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %283(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %284 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %285 = load i32, i32* %284, align 4
  %286 = icmp eq i32 %285, 4
  br i1 %286, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %288 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %289 = load i16, i16* %288, align 2
  %290 = icmp eq i16 %289, 1
  %291 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %292 = load i8, i8* %291, align 1
  %293 = icmp eq i8 %292, 32
  %294 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %295 = load i8, i8* %294, align 1
  %296 = icmp eq i8 %295, 2
  %297 = and i1 %293, %296
  %298 = and i1 %290, %297
  br i1 %298, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %300 = load i64, i64* %67, align 8, !tbaa !7557
  %301 = trunc i64 %300 to i32
  %302 = icmp eq i32 %301, 16
  br i1 %302, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.250, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %304 = getelementptr inbounds i64, i64* %67, i64 1
  %305 = load i64, i64* %304, align 8, !tbaa !7571
  %306 = trunc i64 %305 to i32
  %307 = icmp eq i32 %306, 1
  br i1 %307, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %308 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %308(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %309 = getelementptr inbounds i64, i64* %67, i64 2
  %310 = load i64, i64* %309, align 8, !tbaa !7573
  %311 = trunc i64 %310 to i32
  %312 = icmp eq i32 %311, 1
  br i1 %312, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %313 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %313(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %314 = getelementptr inbounds i64, i64* %67, i64 3
  %315 = load i64, i64* %314, align 8, !tbaa !7576
  %316 = trunc i64 %315 to i32
  %317 = icmp eq i32 %316, 32
  br i1 %317, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %318 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %318(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %319 = icmp eq i64* %69, null
  br i1 %319, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %320 = bitcast i64* %69 to <4 x i64>*
  %321 = load <4 x i64>, <4 x i64>* %320, align 8, !tbaa !7578
  %322 = trunc <4 x i64> %321 to <4 x i32>
  %323 = icmp eq <4 x i32> %322, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf185 = shufflevector <4 x i1> %323, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx186 = and <4 x i1> %323, %rdx.shuf185
  %rdx.shuf187 = shufflevector <4 x i1> %bin.rdx186, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx188 = and <4 x i1> %bin.rdx186, %rdx.shuf187
  %324 = extractelement <4 x i1> %bin.rdx188, i32 0
  br i1 %324, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %325 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %326 = load i64, i64* %325, align 8
  %327 = icmp eq i64 %326, 0
  br i1 %327, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %328 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %328(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %330 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %331, 1
  br i1 %332, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %334 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %51, %335
  br i1 %336, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %338 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %339 = load i32, i32* %338, align 4
  %340 = icmp eq i32 %339, 4
  br i1 %340, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %342 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %343 = load i16, i16* %342, align 2
  %344 = icmp eq i16 %343, 1
  %345 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %346 = load i8, i8* %345, align 1
  %347 = icmp eq i8 %346, 32
  %348 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %349 = load i8, i8* %348, align 1
  %350 = icmp eq i8 %349, 2
  %351 = and i1 %347, %350
  %352 = and i1 %344, %351
  br i1 %352, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %354 = load i64, i64* %73, align 8, !tbaa !7590
  %355 = trunc i64 %354 to i32
  %356 = icmp eq i32 %355, 16
  br i1 %356, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %357 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %357(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.451, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %358 = getelementptr inbounds i64, i64* %73, i64 1
  %359 = load i64, i64* %358, align 8, !tbaa !7604
  %360 = trunc i64 %359 to i32
  %361 = icmp eq i32 %360, 1
  br i1 %361, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %362 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %362(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %363 = getelementptr inbounds i64, i64* %73, i64 2
  %364 = load i64, i64* %363, align 8, !tbaa !7606
  %365 = trunc i64 %364 to i32
  %366 = icmp eq i32 %365, 1
  br i1 %366, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %368 = getelementptr inbounds i64, i64* %73, i64 3
  %369 = load i64, i64* %368, align 8, !tbaa !7609
  %370 = trunc i64 %369 to i32
  %371 = icmp eq i32 %370, 32
  br i1 %371, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %372 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %372(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.167, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %373 = icmp eq i64* %75, null
  br i1 %373, label %if_end118, label %if_then117, !prof !50

if_then117:                                       ; preds = %assert_end116
  %374 = bitcast i64* %75 to <4 x i64>*
  %375 = load <4 x i64>, <4 x i64>* %374, align 8, !tbaa !7611
  %376 = trunc <4 x i64> %375 to <4 x i32>
  %377 = icmp eq <4 x i32> %376, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf181 = shufflevector <4 x i1> %377, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx182 = and <4 x i1> %377, %rdx.shuf181
  %rdx.shuf183 = shufflevector <4 x i1> %bin.rdx182, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx184 = and <4 x i1> %bin.rdx182, %rdx.shuf183
  %378 = extractelement <4 x i1> %bin.rdx184, i32 0
  br i1 %378, label %if_end118, label %assert_fail119, !prof !5

if_end118:                                        ; preds = %assert_end116, %if_then117
  %379 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %380 = load i64, i64* %379, align 8
  %381 = icmp eq i64 %380, 0
  br i1 %381, label %assert_end122, label %assert_fail121, !prof !5

assert_fail119:                                   ; preds = %if_then117
  %382 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %382(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.168, i64 0, i64 0))
  ret i32 -1

assert_fail121:                                   ; preds = %if_end118
  %383 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %383(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %if_end118
  %384 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %385 = load i32, i32* %384, align 4
  %386 = icmp eq i32 %385, 1
  br i1 %386, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %387 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %387(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %388 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %389 = load i32, i32* %388, align 4
  %390 = icmp eq i32 %51, %389
  br i1 %390, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %391 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %391(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %392 = getelementptr inbounds %1, %1* %32, i64 0, i32 2
  %393 = load i32, i32* %392, align 4
  %394 = icmp eq i32 %393, 5
  br i1 %394, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %395 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %395(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %396 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 2
  %397 = load i16, i16* %396, align 2
  %398 = icmp eq i16 %397, 1
  %399 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 1
  %400 = load i8, i8* %399, align 1
  %401 = icmp eq i8 %400, 32
  %402 = getelementptr inbounds %1, %1* %32, i64 0, i32 3, i32 0
  %403 = load i8, i8* %402, align 1
  %404 = icmp eq i8 %403, 2
  %405 = and i1 %401, %404
  %406 = and i1 %398, %405
  br i1 %406, label %assert_end130, label %assert_fail129, !prof !5

assert_fail129:                                   ; preds = %assert_end128
  %407 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %407(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end130:                                    ; preds = %assert_end128
  %408 = load i64, i64* %79, align 8, !tbaa !7623
  %409 = trunc i64 %408 to i32
  %410 = icmp eq i32 %409, 1
  br i1 %410, label %assert_end132, label %assert_fail131, !prof !5

assert_fail131:                                   ; preds = %assert_end130
  %411 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %411(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end132:                                    ; preds = %assert_end130
  %412 = getelementptr inbounds i64, i64* %79, i64 1
  %413 = load i64, i64* %412, align 8, !tbaa !7637
  %414 = trunc i64 %413 to i32
  %415 = icmp eq i32 %414, 16
  br i1 %415, label %assert_end134, label %assert_fail133, !prof !5

assert_fail133:                                   ; preds = %assert_end132
  %416 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %416(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.452, i64 0, i64 0))
  ret i32 -1

assert_end134:                                    ; preds = %assert_end132
  %417 = getelementptr inbounds i64, i64* %79, i64 2
  %418 = load i64, i64* %417, align 8, !tbaa !7639
  %419 = trunc i64 %418 to i32
  %420 = icmp eq i32 %419, 28
  br i1 %420, label %assert_end136, label %assert_fail135, !prof !5

assert_fail135:                                   ; preds = %assert_end134
  %421 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %421(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.293, i64 0, i64 0))
  ret i32 -1

assert_end136:                                    ; preds = %assert_end134
  %422 = getelementptr inbounds i64, i64* %79, i64 3
  %423 = load i64, i64* %422, align 8, !tbaa !7642
  %424 = trunc i64 %423 to i32
  %425 = icmp eq i32 %424, 28
  br i1 %425, label %assert_end138, label %assert_fail137, !prof !5

assert_fail137:                                   ; preds = %assert_end136
  %426 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %426(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.294, i64 0, i64 0))
  ret i32 -1

assert_end138:                                    ; preds = %assert_end136
  %427 = getelementptr inbounds i64, i64* %79, i64 4
  %428 = load i64, i64* %427, align 8, !tbaa !7644
  %429 = trunc i64 %428 to i32
  %430 = icmp eq i32 %429, 32
  br i1 %430, label %assert_end140, label %assert_fail139, !prof !5

assert_fail139:                                   ; preds = %assert_end138
  %431 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %431(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.175, i64 0, i64 0))
  ret i32 -1

assert_end140:                                    ; preds = %assert_end138
  %432 = icmp eq i64* %81, null
  br i1 %432, label %if_end142, label %if_then141, !prof !50

if_then141:                                       ; preds = %assert_end140
  %433 = bitcast i64* %81 to <4 x i64>*
  %434 = load <4 x i64>, <4 x i64>* %433, align 8, !tbaa !7648
  %435 = trunc <4 x i64> %434 to <4 x i32>
  %436 = icmp eq <4 x i32> %435, <i32 401408, i32 25088, i32 896, i32 32>
  %437 = getelementptr inbounds i64, i64* %81, i64 4
  %438 = load i64, i64* %437, align 8, !tbaa !7660
  %439 = trunc i64 %438 to i32
  %440 = icmp eq i32 %439, 1
  %rdx.shuf177 = shufflevector <4 x i1> %436, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx178 = and <4 x i1> %436, %rdx.shuf177
  %rdx.shuf179 = shufflevector <4 x i1> %bin.rdx178, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx180 = and <4 x i1> %bin.rdx178, %rdx.shuf179
  %441 = extractelement <4 x i1> %bin.rdx180, i32 0
  %442 = and i1 %441, %440
  br i1 %442, label %if_end142, label %assert_fail143, !prof !5

if_end142:                                        ; preds = %assert_end140, %if_then141
  %443 = getelementptr inbounds %1, %1* %32, i64 0, i32 6
  %444 = load i64, i64* %443, align 8
  %445 = icmp eq i64 %444, 0
  br i1 %445, label %assert_end146, label %assert_fail145, !prof !5

assert_fail143:                                   ; preds = %if_then141
  %446 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %446(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.542, i64 0, i64 0))
  ret i32 -1

assert_fail145:                                   ; preds = %if_end142
  %447 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %447(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end146:                                    ; preds = %if_end142
  %448 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 0
  %449 = load i32, i32* %448, align 4
  %450 = icmp eq i32 %449, 1
  br i1 %450, label %assert_end148, label %assert_fail147, !prof !5

assert_fail147:                                   ; preds = %assert_end146
  %451 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %451(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end148:                                    ; preds = %assert_end146
  %452 = getelementptr inbounds %1, %1* %32, i64 0, i32 1, i32 1
  %453 = load i32, i32* %452, align 4
  %454 = icmp eq i32 %51, %453
  br i1 %454, label %assert_end150, label %assert_fail149, !prof !5

assert_fail149:                                   ; preds = %assert_end148
  %455 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %455(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_end150:                                    ; preds = %assert_end148
  %456 = getelementptr inbounds %1, %1* %38, i64 0, i32 2
  %457 = load i32, i32* %456, align 4
  %458 = icmp eq i32 %457, 5
  br i1 %458, label %assert_end152, label %assert_fail151, !prof !5

assert_fail151:                                   ; preds = %assert_end150
  %459 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %459(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.310, i64 0, i64 0))
  ret i32 -1

assert_end152:                                    ; preds = %assert_end150
  %460 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 2
  %461 = load i16, i16* %460, align 2
  %462 = icmp eq i16 %461, 1
  %463 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 1
  %464 = load i8, i8* %463, align 1
  %465 = icmp eq i8 %464, 32
  %466 = getelementptr inbounds %1, %1* %38, i64 0, i32 3, i32 0
  %467 = load i8, i8* %466, align 1
  %468 = icmp eq i8 %467, 2
  %469 = and i1 %465, %468
  %470 = and i1 %462, %469
  br i1 %470, label %assert_end154, label %assert_fail153, !prof !5

assert_fail153:                                   ; preds = %assert_end152
  %471 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %471(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.311, i64 0, i64 0))
  ret i32 -1

assert_end154:                                    ; preds = %assert_end152
  %472 = load i64, i64* %85, align 8, !tbaa !7664
  %473 = trunc i64 %472 to i32
  %474 = icmp eq i32 %473, 1
  br i1 %474, label %assert_end156, label %assert_fail155, !prof !5

assert_fail155:                                   ; preds = %assert_end154
  %475 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %475(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.312, i64 0, i64 0))
  ret i32 -1

assert_end156:                                    ; preds = %assert_end154
  %476 = getelementptr inbounds i64, i64* %85, i64 1
  %477 = load i64, i64* %476, align 8, !tbaa !7678
  %478 = trunc i64 %477 to i32
  %479 = icmp eq i32 %478, 16
  br i1 %479, label %assert_end158, label %assert_fail157, !prof !5

assert_fail157:                                   ; preds = %assert_end156
  %480 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %480(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.456, i64 0, i64 0))
  ret i32 -1

assert_end158:                                    ; preds = %assert_end156
  %481 = getelementptr inbounds i64, i64* %85, i64 2
  %482 = load i64, i64* %481, align 8, !tbaa !7680
  %483 = trunc i64 %482 to i32
  %484 = icmp eq i32 %483, 28
  br i1 %484, label %assert_end160, label %assert_fail159, !prof !5

assert_fail159:                                   ; preds = %assert_end158
  %485 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %485(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.543, i64 0, i64 0))
  ret i32 -1

assert_end160:                                    ; preds = %assert_end158
  %486 = getelementptr inbounds i64, i64* %85, i64 3
  %487 = load i64, i64* %486, align 8, !tbaa !7683
  %488 = trunc i64 %487 to i32
  %489 = icmp eq i32 %488, 28
  br i1 %489, label %assert_end162, label %assert_fail161, !prof !5

assert_fail161:                                   ; preds = %assert_end160
  %490 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %490(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.544, i64 0, i64 0))
  ret i32 -1

assert_end162:                                    ; preds = %assert_end160
  %491 = getelementptr inbounds i64, i64* %85, i64 4
  %492 = load i64, i64* %491, align 8, !tbaa !7685
  %493 = trunc i64 %492 to i32
  %494 = icmp eq i32 %493, 32
  br i1 %494, label %assert_end164, label %assert_fail163, !prof !5

assert_fail163:                                   ; preds = %assert_end162
  %495 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %495(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.316, i64 0, i64 0))
  ret i32 -1

assert_end164:                                    ; preds = %assert_end162
  %496 = icmp eq i64* %87, null
  br i1 %496, label %if_end166, label %if_then165, !prof !50

if_then165:                                       ; preds = %assert_end164
  %497 = bitcast i64* %87 to <4 x i64>*
  %498 = load <4 x i64>, <4 x i64>* %497, align 8, !tbaa !7689
  %499 = trunc <4 x i64> %498 to <4 x i32>
  %500 = icmp eq <4 x i32> %499, <i32 401408, i32 25088, i32 896, i32 32>
  %501 = getelementptr inbounds i64, i64* %87, i64 4
  %502 = load i64, i64* %501, align 8, !tbaa !7701
  %503 = trunc i64 %502 to i32
  %504 = icmp eq i32 %503, 1
  %rdx.shuf = shufflevector <4 x i1> %500, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %500, %rdx.shuf
  %rdx.shuf175 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx176 = and <4 x i1> %bin.rdx, %rdx.shuf175
  %505 = extractelement <4 x i1> %bin.rdx176, i32 0
  %506 = and i1 %505, %504
  br i1 %506, label %if_end166, label %assert_fail167, !prof !5

if_end166:                                        ; preds = %assert_end164, %if_then165
  %507 = getelementptr inbounds %1, %1* %38, i64 0, i32 6
  %508 = load i64, i64* %507, align 8
  %509 = icmp eq i64 %508, 0
  br i1 %509, label %assert_end170, label %assert_fail169, !prof !5

assert_fail167:                                   ; preds = %if_then165
  %510 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %510(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.545, i64 0, i64 0))
  ret i32 -1

assert_fail169:                                   ; preds = %if_end166
  %511 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %511(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.318, i64 0, i64 0))
  ret i32 -1

assert_end170:                                    ; preds = %if_end166
  %512 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 0
  %513 = load i32, i32* %512, align 4
  %514 = icmp eq i32 %513, 1
  br i1 %514, label %assert_end172, label %assert_fail171, !prof !5

assert_fail171:                                   ; preds = %assert_end170
  %515 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %515(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.319, i64 0, i64 0))
  ret i32 -1

assert_end172:                                    ; preds = %assert_end170
  %516 = getelementptr inbounds %1, %1* %38, i64 0, i32 1, i32 1
  %517 = load i32, i32* %516, align 4
  %518 = icmp eq i32 %51, %517
  br i1 %518, label %assert_end174, label %assert_fail173, !prof !5

assert_fail173:                                   ; preds = %assert_end172
  %519 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %519(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.320, i64 0, i64 0))
  ret i32 -1

assert_end174:                                    ; preds = %assert_end172
  %520 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2_compute_(i8* %43, i8* %53, i8* %83, i8* %59, i8* %65, i8* %71, i8* %77, i32 %51)
  ret i32 %520
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %8 = alloca %48, align 8
  %9 = getelementptr inbounds %48, %48* %8, i64 0, i32 0
  store i8* %0, i8** %9, align 8
  %10 = getelementptr inbounds %48, %48* %8, i64 0, i32 1
  store i8* %1, i8** %10, align 8
  %11 = getelementptr inbounds %48, %48* %8, i64 0, i32 2
  store i8* %2, i8** %11, align 8
  %12 = getelementptr inbounds %48, %48* %8, i64 0, i32 3
  store i8* %3, i8** %12, align 8
  %13 = getelementptr inbounds %48, %48* %8, i64 0, i32 4
  store i8* %4, i8** %13, align 8
  %14 = getelementptr inbounds %48, %48* %8, i64 0, i32 5
  store i8* %5, i8** %14, align 8
  %15 = getelementptr inbounds %48, %48* %8, i64 0, i32 6
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %48, %48* %8, i64 0, i32 7
  store i32 %7, i32* %16, align 8
  %17 = bitcast %48* %8 to i8*
  %18 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %19 = call i32 %18(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.546, i8* nonnull %17, i32 0)
  ret i32 %19
}

define private i32 @__tvm_parallel_lambda.546(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds i8, i8* %2, i64 56
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %27 = load i32, i32* %26, align 4
  %28 = add nsw i32 %27, 447
  %29 = sdiv i32 %28, %27
  %30 = add nsw i32 %0, 1
  %31 = mul nsw i32 %29, %30
  %32 = icmp slt i32 %31, 448
  %33 = select i1 %32, i32 %31, i32 448
  %34 = mul nsw i32 %29, %0
  %35 = icmp slt i32 %34, 448
  %36 = select i1 %35, i32 %34, i32 448
  %37 = icmp slt i32 %36, %33
  br i1 %37, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %38 = add i32 %36, 1
  %39 = sext i32 %38 to i64
  %40 = add nsw i64 %39, -1
  %41 = sext i32 %33 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_begin10.preheader
  %indvars.iv61 = phi i64 [ %40, %for_body.preheader ], [ %indvars.iv.next62, %for_begin10.preheader ]
  %42 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %43 = tail call i8* %42(i32 1, i32 %25, i64 3584, i32 2, i32 32)
  %44 = bitcast i8* %43 to float*
  %45 = trunc i64 %indvars.iv61 to i32
  %46 = srem i32 %45, 28
  %47 = mul nsw i32 %46, 112
  %48 = sdiv i32 %45, 28
  %49 = shl i32 %48, 12
  %50 = sext i32 %49 to i64
  %51 = sext i32 %47 to i64
  br label %for_body2

for_end:                                          ; preds = %for_begin10.preheader, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end6
  %52 = mul nsw i64 %indvars.iv61, 896
  %53 = shl nsw i32 %48, 5
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds float, float* %13, i64 %54
  %56 = bitcast float* %55 to <32 x float>*
  %57 = load <32 x float>, <32 x float>* %56, align 64, !tbaa !7705
  %58 = getelementptr inbounds float, float* %16, i64 %54
  %59 = bitcast float* %58 to <32 x float>*
  %60 = load <32 x float>, <32 x float>* %59, align 64, !tbaa !7708
  %61 = getelementptr inbounds float, float* %19, i64 %54
  %62 = bitcast float* %61 to <32 x float>*
  %63 = load <32 x float>, <32 x float>* %62, align 64, !tbaa !7711
  %64 = getelementptr inbounds float, float* %22, i64 %52
  %65 = bitcast float* %64 to <32 x float>*
  %66 = load <32 x float>, <32 x float>* %65, align 64, !tbaa !7714
  %67 = bitcast i8* %43 to <32 x float>*
  %68 = load <32 x float>, <32 x float>* %67, align 64, !tbaa !7717
  %69 = fadd <32 x float> %57, %68
  %70 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %69, <32 x float> %60, <32 x float> %63)
  %71 = fadd <32 x float> %66, %70
  %72 = fcmp ogt <32 x float> %71, zeroinitializer
  %73 = select <32 x i1> %72, <32 x float> %71, <32 x float> zeroinitializer
  %74 = getelementptr inbounds float, float* %10, i64 %52
  %75 = bitcast float* %74 to <32 x float>*
  store <32 x float> %73, <32 x float>* %75, align 64, !tbaa !7720
  %76 = mul i64 %indvars.iv61, 3848290697216
  %sext = ashr exact i64 %76, 32
  %77 = or i64 %sext, 32
  %78 = getelementptr inbounds float, float* %22, i64 %77
  %79 = bitcast float* %78 to <32 x float>*
  %80 = load <32 x float>, <32 x float>* %79, align 64, !tbaa !7714
  %81 = getelementptr inbounds i8, i8* %43, i64 128
  %82 = bitcast i8* %81 to <32 x float>*
  %83 = load <32 x float>, <32 x float>* %82, align 64, !tbaa !7717
  %84 = fadd <32 x float> %57, %83
  %85 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %84, <32 x float> %60, <32 x float> %63)
  %86 = fadd <32 x float> %80, %85
  %87 = fcmp ogt <32 x float> %86, zeroinitializer
  %88 = select <32 x i1> %87, <32 x float> %86, <32 x float> zeroinitializer
  %89 = getelementptr inbounds float, float* %10, i64 %77
  %90 = bitcast float* %89 to <32 x float>*
  store <32 x float> %88, <32 x float>* %90, align 64, !tbaa !7720
  %91 = mul i64 %indvars.iv61, 3848290697216
  %sext63 = ashr exact i64 %91, 32
  %92 = or i64 %sext63, 64
  %93 = getelementptr inbounds float, float* %22, i64 %92
  %94 = bitcast float* %93 to <32 x float>*
  %95 = load <32 x float>, <32 x float>* %94, align 64, !tbaa !7714
  %96 = getelementptr inbounds i8, i8* %43, i64 256
  %97 = bitcast i8* %96 to <32 x float>*
  %98 = load <32 x float>, <32 x float>* %97, align 64, !tbaa !7717
  %99 = fadd <32 x float> %57, %98
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %60, <32 x float> %63)
  %101 = fadd <32 x float> %95, %100
  %102 = fcmp ogt <32 x float> %101, zeroinitializer
  %103 = select <32 x i1> %102, <32 x float> %101, <32 x float> zeroinitializer
  %104 = getelementptr inbounds float, float* %10, i64 %92
  %105 = bitcast float* %104 to <32 x float>*
  store <32 x float> %103, <32 x float>* %105, align 64, !tbaa !7720
  %106 = mul i64 %indvars.iv61, 3848290697216
  %sext64 = ashr exact i64 %106, 32
  %107 = or i64 %sext64, 96
  %108 = getelementptr inbounds float, float* %22, i64 %107
  %109 = bitcast float* %108 to <32 x float>*
  %110 = load <32 x float>, <32 x float>* %109, align 64, !tbaa !7714
  %111 = getelementptr inbounds i8, i8* %43, i64 384
  %112 = bitcast i8* %111 to <32 x float>*
  %113 = load <32 x float>, <32 x float>* %112, align 64, !tbaa !7717
  %114 = fadd <32 x float> %57, %113
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %60, <32 x float> %63)
  %116 = fadd <32 x float> %110, %115
  %117 = fcmp ogt <32 x float> %116, zeroinitializer
  %118 = select <32 x i1> %117, <32 x float> %116, <32 x float> zeroinitializer
  %119 = getelementptr inbounds float, float* %10, i64 %107
  %120 = bitcast float* %119 to <32 x float>*
  store <32 x float> %118, <32 x float>* %120, align 64, !tbaa !7720
  %121 = mul i64 %indvars.iv61, 3848290697216
  %sext65 = add i64 %121, 549755813888
  %122 = ashr exact i64 %sext65, 32
  %123 = getelementptr inbounds float, float* %22, i64 %122
  %124 = bitcast float* %123 to <32 x float>*
  %125 = load <32 x float>, <32 x float>* %124, align 64, !tbaa !7714
  %126 = getelementptr inbounds i8, i8* %43, i64 512
  %127 = bitcast i8* %126 to <32 x float>*
  %128 = load <32 x float>, <32 x float>* %127, align 64, !tbaa !7717
  %129 = fadd <32 x float> %57, %128
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %60, <32 x float> %63)
  %131 = fadd <32 x float> %125, %130
  %132 = fcmp ogt <32 x float> %131, zeroinitializer
  %133 = select <32 x i1> %132, <32 x float> %131, <32 x float> zeroinitializer
  %134 = getelementptr inbounds float, float* %10, i64 %122
  %135 = bitcast float* %134 to <32 x float>*
  store <32 x float> %133, <32 x float>* %135, align 64, !tbaa !7720
  %136 = mul i64 %indvars.iv61, 3848290697216
  %sext66 = add i64 %136, 687194767360
  %137 = ashr exact i64 %sext66, 32
  %138 = getelementptr inbounds float, float* %22, i64 %137
  %139 = bitcast float* %138 to <32 x float>*
  %140 = load <32 x float>, <32 x float>* %139, align 64, !tbaa !7714
  %141 = getelementptr inbounds i8, i8* %43, i64 640
  %142 = bitcast i8* %141 to <32 x float>*
  %143 = load <32 x float>, <32 x float>* %142, align 64, !tbaa !7717
  %144 = fadd <32 x float> %57, %143
  %145 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %144, <32 x float> %60, <32 x float> %63)
  %146 = fadd <32 x float> %140, %145
  %147 = fcmp ogt <32 x float> %146, zeroinitializer
  %148 = select <32 x i1> %147, <32 x float> %146, <32 x float> zeroinitializer
  %149 = getelementptr inbounds float, float* %10, i64 %137
  %150 = bitcast float* %149 to <32 x float>*
  store <32 x float> %148, <32 x float>* %150, align 64, !tbaa !7720
  %151 = mul i64 %indvars.iv61, 3848290697216
  %sext67 = add i64 %151, 824633720832
  %152 = ashr exact i64 %sext67, 32
  %153 = getelementptr inbounds float, float* %22, i64 %152
  %154 = bitcast float* %153 to <32 x float>*
  %155 = load <32 x float>, <32 x float>* %154, align 64, !tbaa !7714
  %156 = getelementptr inbounds i8, i8* %43, i64 768
  %157 = bitcast i8* %156 to <32 x float>*
  %158 = load <32 x float>, <32 x float>* %157, align 64, !tbaa !7717
  %159 = fadd <32 x float> %57, %158
  %160 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %159, <32 x float> %60, <32 x float> %63)
  %161 = fadd <32 x float> %155, %160
  %162 = fcmp ogt <32 x float> %161, zeroinitializer
  %163 = select <32 x i1> %162, <32 x float> %161, <32 x float> zeroinitializer
  %164 = getelementptr inbounds float, float* %10, i64 %152
  %165 = bitcast float* %164 to <32 x float>*
  store <32 x float> %163, <32 x float>* %165, align 64, !tbaa !7720
  %166 = mul i64 %indvars.iv61, 3848290697216
  %sext68 = add i64 %166, 962072674304
  %167 = ashr exact i64 %sext68, 32
  %168 = getelementptr inbounds float, float* %22, i64 %167
  %169 = bitcast float* %168 to <32 x float>*
  %170 = load <32 x float>, <32 x float>* %169, align 64, !tbaa !7714
  %171 = getelementptr inbounds i8, i8* %43, i64 896
  %172 = bitcast i8* %171 to <32 x float>*
  %173 = load <32 x float>, <32 x float>* %172, align 64, !tbaa !7717
  %174 = fadd <32 x float> %57, %173
  %175 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %174, <32 x float> %60, <32 x float> %63)
  %176 = fadd <32 x float> %170, %175
  %177 = fcmp ogt <32 x float> %176, zeroinitializer
  %178 = select <32 x i1> %177, <32 x float> %176, <32 x float> zeroinitializer
  %179 = getelementptr inbounds float, float* %10, i64 %167
  %180 = bitcast float* %179 to <32 x float>*
  store <32 x float> %178, <32 x float>* %180, align 64, !tbaa !7720
  %181 = mul i64 %indvars.iv61, 3848290697216
  %sext69 = add i64 %181, 1099511627776
  %182 = ashr exact i64 %sext69, 32
  %183 = getelementptr inbounds float, float* %22, i64 %182
  %184 = bitcast float* %183 to <32 x float>*
  %185 = load <32 x float>, <32 x float>* %184, align 64, !tbaa !7714
  %186 = getelementptr inbounds i8, i8* %43, i64 1024
  %187 = bitcast i8* %186 to <32 x float>*
  %188 = load <32 x float>, <32 x float>* %187, align 64, !tbaa !7717
  %189 = fadd <32 x float> %57, %188
  %190 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %189, <32 x float> %60, <32 x float> %63)
  %191 = fadd <32 x float> %185, %190
  %192 = fcmp ogt <32 x float> %191, zeroinitializer
  %193 = select <32 x i1> %192, <32 x float> %191, <32 x float> zeroinitializer
  %194 = getelementptr inbounds float, float* %10, i64 %182
  %195 = bitcast float* %194 to <32 x float>*
  store <32 x float> %193, <32 x float>* %195, align 64, !tbaa !7720
  %196 = mul i64 %indvars.iv61, 3848290697216
  %sext70 = add i64 %196, 1236950581248
  %197 = ashr exact i64 %sext70, 32
  %198 = getelementptr inbounds float, float* %22, i64 %197
  %199 = bitcast float* %198 to <32 x float>*
  %200 = load <32 x float>, <32 x float>* %199, align 64, !tbaa !7714
  %201 = getelementptr inbounds i8, i8* %43, i64 1152
  %202 = bitcast i8* %201 to <32 x float>*
  %203 = load <32 x float>, <32 x float>* %202, align 64, !tbaa !7717
  %204 = fadd <32 x float> %57, %203
  %205 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %204, <32 x float> %60, <32 x float> %63)
  %206 = fadd <32 x float> %200, %205
  %207 = fcmp ogt <32 x float> %206, zeroinitializer
  %208 = select <32 x i1> %207, <32 x float> %206, <32 x float> zeroinitializer
  %209 = getelementptr inbounds float, float* %10, i64 %197
  %210 = bitcast float* %209 to <32 x float>*
  store <32 x float> %208, <32 x float>* %210, align 64, !tbaa !7720
  %211 = mul i64 %indvars.iv61, 3848290697216
  %sext71 = add i64 %211, 1374389534720
  %212 = ashr exact i64 %sext71, 32
  %213 = getelementptr inbounds float, float* %22, i64 %212
  %214 = bitcast float* %213 to <32 x float>*
  %215 = load <32 x float>, <32 x float>* %214, align 64, !tbaa !7714
  %216 = getelementptr inbounds i8, i8* %43, i64 1280
  %217 = bitcast i8* %216 to <32 x float>*
  %218 = load <32 x float>, <32 x float>* %217, align 64, !tbaa !7717
  %219 = fadd <32 x float> %57, %218
  %220 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %219, <32 x float> %60, <32 x float> %63)
  %221 = fadd <32 x float> %215, %220
  %222 = fcmp ogt <32 x float> %221, zeroinitializer
  %223 = select <32 x i1> %222, <32 x float> %221, <32 x float> zeroinitializer
  %224 = getelementptr inbounds float, float* %10, i64 %212
  %225 = bitcast float* %224 to <32 x float>*
  store <32 x float> %223, <32 x float>* %225, align 64, !tbaa !7720
  %226 = mul i64 %indvars.iv61, 3848290697216
  %sext72 = add i64 %226, 1511828488192
  %227 = ashr exact i64 %sext72, 32
  %228 = getelementptr inbounds float, float* %22, i64 %227
  %229 = bitcast float* %228 to <32 x float>*
  %230 = load <32 x float>, <32 x float>* %229, align 64, !tbaa !7714
  %231 = getelementptr inbounds i8, i8* %43, i64 1408
  %232 = bitcast i8* %231 to <32 x float>*
  %233 = load <32 x float>, <32 x float>* %232, align 64, !tbaa !7717
  %234 = fadd <32 x float> %57, %233
  %235 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %234, <32 x float> %60, <32 x float> %63)
  %236 = fadd <32 x float> %230, %235
  %237 = fcmp ogt <32 x float> %236, zeroinitializer
  %238 = select <32 x i1> %237, <32 x float> %236, <32 x float> zeroinitializer
  %239 = getelementptr inbounds float, float* %10, i64 %227
  %240 = bitcast float* %239 to <32 x float>*
  store <32 x float> %238, <32 x float>* %240, align 64, !tbaa !7720
  %241 = mul i64 %indvars.iv61, 3848290697216
  %sext73 = add i64 %241, 1649267441664
  %242 = ashr exact i64 %sext73, 32
  %243 = getelementptr inbounds float, float* %22, i64 %242
  %244 = bitcast float* %243 to <32 x float>*
  %245 = load <32 x float>, <32 x float>* %244, align 64, !tbaa !7714
  %246 = getelementptr inbounds i8, i8* %43, i64 1536
  %247 = bitcast i8* %246 to <32 x float>*
  %248 = load <32 x float>, <32 x float>* %247, align 64, !tbaa !7717
  %249 = fadd <32 x float> %57, %248
  %250 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %249, <32 x float> %60, <32 x float> %63)
  %251 = fadd <32 x float> %245, %250
  %252 = fcmp ogt <32 x float> %251, zeroinitializer
  %253 = select <32 x i1> %252, <32 x float> %251, <32 x float> zeroinitializer
  %254 = getelementptr inbounds float, float* %10, i64 %242
  %255 = bitcast float* %254 to <32 x float>*
  store <32 x float> %253, <32 x float>* %255, align 64, !tbaa !7720
  %256 = mul i64 %indvars.iv61, 3848290697216
  %sext74 = add i64 %256, 1786706395136
  %257 = ashr exact i64 %sext74, 32
  %258 = getelementptr inbounds float, float* %22, i64 %257
  %259 = bitcast float* %258 to <32 x float>*
  %260 = load <32 x float>, <32 x float>* %259, align 64, !tbaa !7714
  %261 = getelementptr inbounds i8, i8* %43, i64 1664
  %262 = bitcast i8* %261 to <32 x float>*
  %263 = load <32 x float>, <32 x float>* %262, align 64, !tbaa !7717
  %264 = fadd <32 x float> %57, %263
  %265 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %264, <32 x float> %60, <32 x float> %63)
  %266 = fadd <32 x float> %260, %265
  %267 = fcmp ogt <32 x float> %266, zeroinitializer
  %268 = select <32 x i1> %267, <32 x float> %266, <32 x float> zeroinitializer
  %269 = getelementptr inbounds float, float* %10, i64 %257
  %270 = bitcast float* %269 to <32 x float>*
  store <32 x float> %268, <32 x float>* %270, align 64, !tbaa !7720
  %271 = mul i64 %indvars.iv61, 3848290697216
  %sext75 = add i64 %271, 1924145348608
  %272 = ashr exact i64 %sext75, 32
  %273 = getelementptr inbounds float, float* %22, i64 %272
  %274 = bitcast float* %273 to <32 x float>*
  %275 = load <32 x float>, <32 x float>* %274, align 64, !tbaa !7714
  %276 = getelementptr inbounds i8, i8* %43, i64 1792
  %277 = bitcast i8* %276 to <32 x float>*
  %278 = load <32 x float>, <32 x float>* %277, align 64, !tbaa !7717
  %279 = fadd <32 x float> %57, %278
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %279, <32 x float> %60, <32 x float> %63)
  %281 = fadd <32 x float> %275, %280
  %282 = fcmp ogt <32 x float> %281, zeroinitializer
  %283 = select <32 x i1> %282, <32 x float> %281, <32 x float> zeroinitializer
  %284 = getelementptr inbounds float, float* %10, i64 %272
  %285 = bitcast float* %284 to <32 x float>*
  store <32 x float> %283, <32 x float>* %285, align 64, !tbaa !7720
  %286 = mul i64 %indvars.iv61, 3848290697216
  %sext76 = add i64 %286, 2061584302080
  %287 = ashr exact i64 %sext76, 32
  %288 = getelementptr inbounds float, float* %22, i64 %287
  %289 = bitcast float* %288 to <32 x float>*
  %290 = load <32 x float>, <32 x float>* %289, align 64, !tbaa !7714
  %291 = getelementptr inbounds i8, i8* %43, i64 1920
  %292 = bitcast i8* %291 to <32 x float>*
  %293 = load <32 x float>, <32 x float>* %292, align 64, !tbaa !7717
  %294 = fadd <32 x float> %57, %293
  %295 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %294, <32 x float> %60, <32 x float> %63)
  %296 = fadd <32 x float> %290, %295
  %297 = fcmp ogt <32 x float> %296, zeroinitializer
  %298 = select <32 x i1> %297, <32 x float> %296, <32 x float> zeroinitializer
  %299 = getelementptr inbounds float, float* %10, i64 %287
  %300 = bitcast float* %299 to <32 x float>*
  store <32 x float> %298, <32 x float>* %300, align 64, !tbaa !7720
  %301 = mul i64 %indvars.iv61, 3848290697216
  %sext77 = add i64 %301, 2199023255552
  %302 = ashr exact i64 %sext77, 32
  %303 = getelementptr inbounds float, float* %22, i64 %302
  %304 = bitcast float* %303 to <32 x float>*
  %305 = load <32 x float>, <32 x float>* %304, align 64, !tbaa !7714
  %306 = getelementptr inbounds i8, i8* %43, i64 2048
  %307 = bitcast i8* %306 to <32 x float>*
  %308 = load <32 x float>, <32 x float>* %307, align 64, !tbaa !7717
  %309 = fadd <32 x float> %57, %308
  %310 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %309, <32 x float> %60, <32 x float> %63)
  %311 = fadd <32 x float> %305, %310
  %312 = fcmp ogt <32 x float> %311, zeroinitializer
  %313 = select <32 x i1> %312, <32 x float> %311, <32 x float> zeroinitializer
  %314 = getelementptr inbounds float, float* %10, i64 %302
  %315 = bitcast float* %314 to <32 x float>*
  store <32 x float> %313, <32 x float>* %315, align 64, !tbaa !7720
  %316 = mul i64 %indvars.iv61, 3848290697216
  %sext78 = add i64 %316, 2336462209024
  %317 = ashr exact i64 %sext78, 32
  %318 = getelementptr inbounds float, float* %22, i64 %317
  %319 = bitcast float* %318 to <32 x float>*
  %320 = load <32 x float>, <32 x float>* %319, align 64, !tbaa !7714
  %321 = getelementptr inbounds i8, i8* %43, i64 2176
  %322 = bitcast i8* %321 to <32 x float>*
  %323 = load <32 x float>, <32 x float>* %322, align 64, !tbaa !7717
  %324 = fadd <32 x float> %57, %323
  %325 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %324, <32 x float> %60, <32 x float> %63)
  %326 = fadd <32 x float> %320, %325
  %327 = fcmp ogt <32 x float> %326, zeroinitializer
  %328 = select <32 x i1> %327, <32 x float> %326, <32 x float> zeroinitializer
  %329 = getelementptr inbounds float, float* %10, i64 %317
  %330 = bitcast float* %329 to <32 x float>*
  store <32 x float> %328, <32 x float>* %330, align 64, !tbaa !7720
  %331 = mul i64 %indvars.iv61, 3848290697216
  %sext79 = add i64 %331, 2473901162496
  %332 = ashr exact i64 %sext79, 32
  %333 = getelementptr inbounds float, float* %22, i64 %332
  %334 = bitcast float* %333 to <32 x float>*
  %335 = load <32 x float>, <32 x float>* %334, align 64, !tbaa !7714
  %336 = getelementptr inbounds i8, i8* %43, i64 2304
  %337 = bitcast i8* %336 to <32 x float>*
  %338 = load <32 x float>, <32 x float>* %337, align 64, !tbaa !7717
  %339 = fadd <32 x float> %57, %338
  %340 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %339, <32 x float> %60, <32 x float> %63)
  %341 = fadd <32 x float> %335, %340
  %342 = fcmp ogt <32 x float> %341, zeroinitializer
  %343 = select <32 x i1> %342, <32 x float> %341, <32 x float> zeroinitializer
  %344 = getelementptr inbounds float, float* %10, i64 %332
  %345 = bitcast float* %344 to <32 x float>*
  store <32 x float> %343, <32 x float>* %345, align 64, !tbaa !7720
  %346 = mul i64 %indvars.iv61, 3848290697216
  %sext80 = add i64 %346, 2611340115968
  %347 = ashr exact i64 %sext80, 32
  %348 = getelementptr inbounds float, float* %22, i64 %347
  %349 = bitcast float* %348 to <32 x float>*
  %350 = load <32 x float>, <32 x float>* %349, align 64, !tbaa !7714
  %351 = getelementptr inbounds i8, i8* %43, i64 2432
  %352 = bitcast i8* %351 to <32 x float>*
  %353 = load <32 x float>, <32 x float>* %352, align 64, !tbaa !7717
  %354 = fadd <32 x float> %57, %353
  %355 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %354, <32 x float> %60, <32 x float> %63)
  %356 = fadd <32 x float> %350, %355
  %357 = fcmp ogt <32 x float> %356, zeroinitializer
  %358 = select <32 x i1> %357, <32 x float> %356, <32 x float> zeroinitializer
  %359 = getelementptr inbounds float, float* %10, i64 %347
  %360 = bitcast float* %359 to <32 x float>*
  store <32 x float> %358, <32 x float>* %360, align 64, !tbaa !7720
  %361 = mul i64 %indvars.iv61, 3848290697216
  %sext81 = add i64 %361, 2748779069440
  %362 = ashr exact i64 %sext81, 32
  %363 = getelementptr inbounds float, float* %22, i64 %362
  %364 = bitcast float* %363 to <32 x float>*
  %365 = load <32 x float>, <32 x float>* %364, align 64, !tbaa !7714
  %366 = getelementptr inbounds i8, i8* %43, i64 2560
  %367 = bitcast i8* %366 to <32 x float>*
  %368 = load <32 x float>, <32 x float>* %367, align 64, !tbaa !7717
  %369 = fadd <32 x float> %57, %368
  %370 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %369, <32 x float> %60, <32 x float> %63)
  %371 = fadd <32 x float> %365, %370
  %372 = fcmp ogt <32 x float> %371, zeroinitializer
  %373 = select <32 x i1> %372, <32 x float> %371, <32 x float> zeroinitializer
  %374 = getelementptr inbounds float, float* %10, i64 %362
  %375 = bitcast float* %374 to <32 x float>*
  store <32 x float> %373, <32 x float>* %375, align 64, !tbaa !7720
  %376 = mul i64 %indvars.iv61, 3848290697216
  %sext82 = add i64 %376, 2886218022912
  %377 = ashr exact i64 %sext82, 32
  %378 = getelementptr inbounds float, float* %22, i64 %377
  %379 = bitcast float* %378 to <32 x float>*
  %380 = load <32 x float>, <32 x float>* %379, align 64, !tbaa !7714
  %381 = getelementptr inbounds i8, i8* %43, i64 2688
  %382 = bitcast i8* %381 to <32 x float>*
  %383 = load <32 x float>, <32 x float>* %382, align 64, !tbaa !7717
  %384 = fadd <32 x float> %57, %383
  %385 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %384, <32 x float> %60, <32 x float> %63)
  %386 = fadd <32 x float> %380, %385
  %387 = fcmp ogt <32 x float> %386, zeroinitializer
  %388 = select <32 x i1> %387, <32 x float> %386, <32 x float> zeroinitializer
  %389 = getelementptr inbounds float, float* %10, i64 %377
  %390 = bitcast float* %389 to <32 x float>*
  store <32 x float> %388, <32 x float>* %390, align 64, !tbaa !7720
  %391 = mul i64 %indvars.iv61, 3848290697216
  %sext83 = add i64 %391, 3023656976384
  %392 = ashr exact i64 %sext83, 32
  %393 = getelementptr inbounds float, float* %22, i64 %392
  %394 = bitcast float* %393 to <32 x float>*
  %395 = load <32 x float>, <32 x float>* %394, align 64, !tbaa !7714
  %396 = getelementptr inbounds i8, i8* %43, i64 2816
  %397 = bitcast i8* %396 to <32 x float>*
  %398 = load <32 x float>, <32 x float>* %397, align 64, !tbaa !7717
  %399 = fadd <32 x float> %57, %398
  %400 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %60, <32 x float> %63)
  %401 = fadd <32 x float> %395, %400
  %402 = fcmp ogt <32 x float> %401, zeroinitializer
  %403 = select <32 x i1> %402, <32 x float> %401, <32 x float> zeroinitializer
  %404 = getelementptr inbounds float, float* %10, i64 %392
  %405 = bitcast float* %404 to <32 x float>*
  store <32 x float> %403, <32 x float>* %405, align 64, !tbaa !7720
  %406 = mul i64 %indvars.iv61, 3848290697216
  %sext84 = add i64 %406, 3161095929856
  %407 = ashr exact i64 %sext84, 32
  %408 = getelementptr inbounds float, float* %22, i64 %407
  %409 = bitcast float* %408 to <32 x float>*
  %410 = load <32 x float>, <32 x float>* %409, align 64, !tbaa !7714
  %411 = getelementptr inbounds i8, i8* %43, i64 2944
  %412 = bitcast i8* %411 to <32 x float>*
  %413 = load <32 x float>, <32 x float>* %412, align 64, !tbaa !7717
  %414 = fadd <32 x float> %57, %413
  %415 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %414, <32 x float> %60, <32 x float> %63)
  %416 = fadd <32 x float> %410, %415
  %417 = fcmp ogt <32 x float> %416, zeroinitializer
  %418 = select <32 x i1> %417, <32 x float> %416, <32 x float> zeroinitializer
  %419 = getelementptr inbounds float, float* %10, i64 %407
  %420 = bitcast float* %419 to <32 x float>*
  store <32 x float> %418, <32 x float>* %420, align 64, !tbaa !7720
  %421 = mul i64 %indvars.iv61, 3848290697216
  %sext85 = add i64 %421, 3298534883328
  %422 = ashr exact i64 %sext85, 32
  %423 = getelementptr inbounds float, float* %22, i64 %422
  %424 = bitcast float* %423 to <32 x float>*
  %425 = load <32 x float>, <32 x float>* %424, align 64, !tbaa !7714
  %426 = getelementptr inbounds i8, i8* %43, i64 3072
  %427 = bitcast i8* %426 to <32 x float>*
  %428 = load <32 x float>, <32 x float>* %427, align 64, !tbaa !7717
  %429 = fadd <32 x float> %57, %428
  %430 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %429, <32 x float> %60, <32 x float> %63)
  %431 = fadd <32 x float> %425, %430
  %432 = fcmp ogt <32 x float> %431, zeroinitializer
  %433 = select <32 x i1> %432, <32 x float> %431, <32 x float> zeroinitializer
  %434 = getelementptr inbounds float, float* %10, i64 %422
  %435 = bitcast float* %434 to <32 x float>*
  store <32 x float> %433, <32 x float>* %435, align 64, !tbaa !7720
  %436 = mul i64 %indvars.iv61, 3848290697216
  %sext86 = add i64 %436, 3435973836800
  %437 = ashr exact i64 %sext86, 32
  %438 = getelementptr inbounds float, float* %22, i64 %437
  %439 = bitcast float* %438 to <32 x float>*
  %440 = load <32 x float>, <32 x float>* %439, align 64, !tbaa !7714
  %441 = getelementptr inbounds i8, i8* %43, i64 3200
  %442 = bitcast i8* %441 to <32 x float>*
  %443 = load <32 x float>, <32 x float>* %442, align 64, !tbaa !7717
  %444 = fadd <32 x float> %57, %443
  %445 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %444, <32 x float> %60, <32 x float> %63)
  %446 = fadd <32 x float> %440, %445
  %447 = fcmp ogt <32 x float> %446, zeroinitializer
  %448 = select <32 x i1> %447, <32 x float> %446, <32 x float> zeroinitializer
  %449 = getelementptr inbounds float, float* %10, i64 %437
  %450 = bitcast float* %449 to <32 x float>*
  store <32 x float> %448, <32 x float>* %450, align 64, !tbaa !7720
  %451 = mul i64 %indvars.iv61, 3848290697216
  %sext87 = add i64 %451, 3573412790272
  %452 = ashr exact i64 %sext87, 32
  %453 = getelementptr inbounds float, float* %22, i64 %452
  %454 = bitcast float* %453 to <32 x float>*
  %455 = load <32 x float>, <32 x float>* %454, align 64, !tbaa !7714
  %456 = getelementptr inbounds i8, i8* %43, i64 3328
  %457 = bitcast i8* %456 to <32 x float>*
  %458 = load <32 x float>, <32 x float>* %457, align 64, !tbaa !7717
  %459 = fadd <32 x float> %57, %458
  %460 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %459, <32 x float> %60, <32 x float> %63)
  %461 = fadd <32 x float> %455, %460
  %462 = fcmp ogt <32 x float> %461, zeroinitializer
  %463 = select <32 x i1> %462, <32 x float> %461, <32 x float> zeroinitializer
  %464 = getelementptr inbounds float, float* %10, i64 %452
  %465 = bitcast float* %464 to <32 x float>*
  store <32 x float> %463, <32 x float>* %465, align 64, !tbaa !7720
  %466 = mul i64 %indvars.iv61, 3848290697216
  %sext88 = add i64 %466, 3710851743744
  %467 = ashr exact i64 %sext88, 32
  %468 = getelementptr inbounds float, float* %22, i64 %467
  %469 = bitcast float* %468 to <32 x float>*
  %470 = load <32 x float>, <32 x float>* %469, align 64, !tbaa !7714
  %471 = getelementptr inbounds i8, i8* %43, i64 3456
  %472 = bitcast i8* %471 to <32 x float>*
  %473 = load <32 x float>, <32 x float>* %472, align 64, !tbaa !7717
  %474 = fadd <32 x float> %57, %473
  %475 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %60, <32 x float> %63)
  %476 = fadd <32 x float> %470, %475
  %477 = fcmp ogt <32 x float> %476, zeroinitializer
  %478 = select <32 x i1> %477, <32 x float> %476, <32 x float> zeroinitializer
  %479 = getelementptr inbounds float, float* %10, i64 %467
  %480 = bitcast float* %479 to <32 x float>*
  store <32 x float> %478, <32 x float>* %480, align 64, !tbaa !7720
  %481 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %482 = tail call i32 %481(i32 1, i32 %25, i8* nonnull %43)
  %indvars.iv.next62 = add nsw i64 %indvars.iv61, 1
  %483 = icmp slt i64 %indvars.iv.next62, %41
  br i1 %483, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv52 = phi i64 [ 0, %for_body ], [ %indvars.iv.next53, %for_end6 ]
  %484 = mul nuw nsw i64 %indvars.iv52, 224
  %485 = getelementptr inbounds float, float* %44, i64 %484
  %486 = bitcast float* %485 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %486, align 64, !tbaa !7717
  %487 = add nuw nsw i64 %484, 32
  %488 = getelementptr inbounds float, float* %44, i64 %487
  %489 = bitcast float* %488 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %489, align 64, !tbaa !7717
  %490 = add nuw nsw i64 %484, 64
  %491 = getelementptr inbounds float, float* %44, i64 %490
  %492 = bitcast float* %491 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %492, align 64, !tbaa !7717
  %493 = add nuw nsw i64 %484, 96
  %494 = getelementptr inbounds float, float* %44, i64 %493
  %495 = bitcast float* %494 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %495, align 64, !tbaa !7717
  %496 = add nuw nsw i64 %484, 128
  %497 = getelementptr inbounds float, float* %44, i64 %496
  %498 = bitcast float* %497 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %498, align 64, !tbaa !7717
  %499 = add nuw nsw i64 %484, 160
  %500 = getelementptr inbounds float, float* %44, i64 %499
  %501 = bitcast float* %500 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %501, align 64, !tbaa !7717
  %502 = add nuw nsw i64 %484, 192
  %503 = getelementptr inbounds float, float* %44, i64 %502
  %504 = bitcast float* %503 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %504, align 64, !tbaa !7717
  %505 = mul nuw nsw i64 %indvars.iv52, 28
  %506 = add nsw i64 %505, %51
  br label %for_begin7.preheader

for_begin7.preheader:                             ; preds = %for_begin7.preheader, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_begin7.preheader ]
  %.lcssa3245 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %692, %for_begin7.preheader ]
  %.lcssa3043 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %686, %for_begin7.preheader ]
  %.lcssa2841 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %680, %for_begin7.preheader ]
  %.lcssa2639 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %674, %for_begin7.preheader ]
  %.lcssa2437 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %668, %for_begin7.preheader ]
  %.lcssa2235 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %662, %for_begin7.preheader ]
  %.lcssa34 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %656, %for_begin7.preheader ]
  %507 = mul nuw nsw i64 %indvars.iv, 3136
  %508 = add nsw i64 %506, %507
  %509 = shl i64 %indvars.iv, 7
  %510 = add nuw nsw i64 %509, %50
  %511 = getelementptr inbounds float, float* %4, i64 %508
  %512 = load float, float* %511, align 4, !tbaa !7723
  %513 = insertelement <32 x float> undef, float %512, i32 0
  %514 = shufflevector <32 x float> %513, <32 x float> undef, <32 x i32> zeroinitializer
  %515 = getelementptr inbounds float, float* %7, i64 %510
  %516 = bitcast float* %515 to <32 x float>*
  %517 = load <32 x float>, <32 x float>* %516, align 64, !tbaa !7726
  %518 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %517, <32 x float> %.lcssa34)
  %519 = add nsw i64 %508, 4
  %520 = getelementptr inbounds float, float* %4, i64 %519
  %521 = load float, float* %520, align 4, !tbaa !7723
  %522 = insertelement <32 x float> undef, float %521, i32 0
  %523 = shufflevector <32 x float> %522, <32 x float> undef, <32 x i32> zeroinitializer
  %524 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %523, <32 x float> %517, <32 x float> %.lcssa2235)
  %525 = add nsw i64 %508, 8
  %526 = getelementptr inbounds float, float* %4, i64 %525
  %527 = load float, float* %526, align 4, !tbaa !7723
  %528 = insertelement <32 x float> undef, float %527, i32 0
  %529 = shufflevector <32 x float> %528, <32 x float> undef, <32 x i32> zeroinitializer
  %530 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %529, <32 x float> %517, <32 x float> %.lcssa2437)
  %531 = add nsw i64 %508, 12
  %532 = getelementptr inbounds float, float* %4, i64 %531
  %533 = load float, float* %532, align 4, !tbaa !7723
  %534 = insertelement <32 x float> undef, float %533, i32 0
  %535 = shufflevector <32 x float> %534, <32 x float> undef, <32 x i32> zeroinitializer
  %536 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %535, <32 x float> %517, <32 x float> %.lcssa2639)
  %537 = add nsw i64 %508, 16
  %538 = getelementptr inbounds float, float* %4, i64 %537
  %539 = load float, float* %538, align 4, !tbaa !7723
  %540 = insertelement <32 x float> undef, float %539, i32 0
  %541 = shufflevector <32 x float> %540, <32 x float> undef, <32 x i32> zeroinitializer
  %542 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %541, <32 x float> %517, <32 x float> %.lcssa2841)
  %543 = add nsw i64 %508, 20
  %544 = getelementptr inbounds float, float* %4, i64 %543
  %545 = load float, float* %544, align 4, !tbaa !7723
  %546 = insertelement <32 x float> undef, float %545, i32 0
  %547 = shufflevector <32 x float> %546, <32 x float> undef, <32 x i32> zeroinitializer
  %548 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %547, <32 x float> %517, <32 x float> %.lcssa3043)
  %549 = add nsw i64 %508, 24
  %550 = getelementptr inbounds float, float* %4, i64 %549
  %551 = load float, float* %550, align 4, !tbaa !7723
  %552 = insertelement <32 x float> undef, float %551, i32 0
  %553 = shufflevector <32 x float> %552, <32 x float> undef, <32 x i32> zeroinitializer
  %554 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %553, <32 x float> %517, <32 x float> %.lcssa3245)
  %555 = or i64 %508, 1
  %556 = getelementptr inbounds float, float* %4, i64 %555
  %557 = load float, float* %556, align 4, !tbaa !7723
  %558 = insertelement <32 x float> undef, float %557, i32 0
  %559 = shufflevector <32 x float> %558, <32 x float> undef, <32 x i32> zeroinitializer
  %560 = or i64 %510, 32
  %561 = getelementptr inbounds float, float* %7, i64 %560
  %562 = bitcast float* %561 to <32 x float>*
  %563 = load <32 x float>, <32 x float>* %562, align 64, !tbaa !7726
  %564 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %559, <32 x float> %563, <32 x float> %518)
  %565 = add nsw i64 %555, 4
  %566 = getelementptr inbounds float, float* %4, i64 %565
  %567 = load float, float* %566, align 4, !tbaa !7723
  %568 = insertelement <32 x float> undef, float %567, i32 0
  %569 = shufflevector <32 x float> %568, <32 x float> undef, <32 x i32> zeroinitializer
  %570 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %569, <32 x float> %563, <32 x float> %524)
  %571 = add nsw i64 %555, 8
  %572 = getelementptr inbounds float, float* %4, i64 %571
  %573 = load float, float* %572, align 4, !tbaa !7723
  %574 = insertelement <32 x float> undef, float %573, i32 0
  %575 = shufflevector <32 x float> %574, <32 x float> undef, <32 x i32> zeroinitializer
  %576 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %575, <32 x float> %563, <32 x float> %530)
  %577 = add nsw i64 %555, 12
  %578 = getelementptr inbounds float, float* %4, i64 %577
  %579 = load float, float* %578, align 4, !tbaa !7723
  %580 = insertelement <32 x float> undef, float %579, i32 0
  %581 = shufflevector <32 x float> %580, <32 x float> undef, <32 x i32> zeroinitializer
  %582 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %581, <32 x float> %563, <32 x float> %536)
  %583 = add nsw i64 %555, 16
  %584 = getelementptr inbounds float, float* %4, i64 %583
  %585 = load float, float* %584, align 4, !tbaa !7723
  %586 = insertelement <32 x float> undef, float %585, i32 0
  %587 = shufflevector <32 x float> %586, <32 x float> undef, <32 x i32> zeroinitializer
  %588 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %587, <32 x float> %563, <32 x float> %542)
  %589 = add nsw i64 %555, 20
  %590 = getelementptr inbounds float, float* %4, i64 %589
  %591 = load float, float* %590, align 4, !tbaa !7723
  %592 = insertelement <32 x float> undef, float %591, i32 0
  %593 = shufflevector <32 x float> %592, <32 x float> undef, <32 x i32> zeroinitializer
  %594 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %593, <32 x float> %563, <32 x float> %548)
  %595 = add nsw i64 %555, 24
  %596 = getelementptr inbounds float, float* %4, i64 %595
  %597 = load float, float* %596, align 4, !tbaa !7723
  %598 = insertelement <32 x float> undef, float %597, i32 0
  %599 = shufflevector <32 x float> %598, <32 x float> undef, <32 x i32> zeroinitializer
  %600 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %599, <32 x float> %563, <32 x float> %554)
  %601 = or i64 %508, 2
  %602 = getelementptr inbounds float, float* %4, i64 %601
  %603 = load float, float* %602, align 4, !tbaa !7723
  %604 = insertelement <32 x float> undef, float %603, i32 0
  %605 = shufflevector <32 x float> %604, <32 x float> undef, <32 x i32> zeroinitializer
  %606 = or i64 %510, 64
  %607 = getelementptr inbounds float, float* %7, i64 %606
  %608 = bitcast float* %607 to <32 x float>*
  %609 = load <32 x float>, <32 x float>* %608, align 64, !tbaa !7726
  %610 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %605, <32 x float> %609, <32 x float> %564)
  %611 = add nsw i64 %601, 4
  %612 = getelementptr inbounds float, float* %4, i64 %611
  %613 = load float, float* %612, align 4, !tbaa !7723
  %614 = insertelement <32 x float> undef, float %613, i32 0
  %615 = shufflevector <32 x float> %614, <32 x float> undef, <32 x i32> zeroinitializer
  %616 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %615, <32 x float> %609, <32 x float> %570)
  %617 = add nsw i64 %601, 8
  %618 = getelementptr inbounds float, float* %4, i64 %617
  %619 = load float, float* %618, align 4, !tbaa !7723
  %620 = insertelement <32 x float> undef, float %619, i32 0
  %621 = shufflevector <32 x float> %620, <32 x float> undef, <32 x i32> zeroinitializer
  %622 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %621, <32 x float> %609, <32 x float> %576)
  %623 = add nsw i64 %601, 12
  %624 = getelementptr inbounds float, float* %4, i64 %623
  %625 = load float, float* %624, align 4, !tbaa !7723
  %626 = insertelement <32 x float> undef, float %625, i32 0
  %627 = shufflevector <32 x float> %626, <32 x float> undef, <32 x i32> zeroinitializer
  %628 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %627, <32 x float> %609, <32 x float> %582)
  %629 = add nsw i64 %601, 16
  %630 = getelementptr inbounds float, float* %4, i64 %629
  %631 = load float, float* %630, align 4, !tbaa !7723
  %632 = insertelement <32 x float> undef, float %631, i32 0
  %633 = shufflevector <32 x float> %632, <32 x float> undef, <32 x i32> zeroinitializer
  %634 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %633, <32 x float> %609, <32 x float> %588)
  %635 = add nsw i64 %601, 20
  %636 = getelementptr inbounds float, float* %4, i64 %635
  %637 = load float, float* %636, align 4, !tbaa !7723
  %638 = insertelement <32 x float> undef, float %637, i32 0
  %639 = shufflevector <32 x float> %638, <32 x float> undef, <32 x i32> zeroinitializer
  %640 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %639, <32 x float> %609, <32 x float> %594)
  %641 = add nsw i64 %601, 24
  %642 = getelementptr inbounds float, float* %4, i64 %641
  %643 = load float, float* %642, align 4, !tbaa !7723
  %644 = insertelement <32 x float> undef, float %643, i32 0
  %645 = shufflevector <32 x float> %644, <32 x float> undef, <32 x i32> zeroinitializer
  %646 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %645, <32 x float> %609, <32 x float> %600)
  %647 = or i64 %508, 3
  %648 = getelementptr inbounds float, float* %4, i64 %647
  %649 = load float, float* %648, align 4, !tbaa !7723
  %650 = insertelement <32 x float> undef, float %649, i32 0
  %651 = shufflevector <32 x float> %650, <32 x float> undef, <32 x i32> zeroinitializer
  %652 = or i64 %510, 96
  %653 = getelementptr inbounds float, float* %7, i64 %652
  %654 = bitcast float* %653 to <32 x float>*
  %655 = load <32 x float>, <32 x float>* %654, align 64, !tbaa !7726
  %656 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %651, <32 x float> %655, <32 x float> %610)
  %657 = add nsw i64 %647, 4
  %658 = getelementptr inbounds float, float* %4, i64 %657
  %659 = load float, float* %658, align 4, !tbaa !7723
  %660 = insertelement <32 x float> undef, float %659, i32 0
  %661 = shufflevector <32 x float> %660, <32 x float> undef, <32 x i32> zeroinitializer
  %662 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %661, <32 x float> %655, <32 x float> %616)
  %663 = add nsw i64 %647, 8
  %664 = getelementptr inbounds float, float* %4, i64 %663
  %665 = load float, float* %664, align 4, !tbaa !7723
  %666 = insertelement <32 x float> undef, float %665, i32 0
  %667 = shufflevector <32 x float> %666, <32 x float> undef, <32 x i32> zeroinitializer
  %668 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %667, <32 x float> %655, <32 x float> %622)
  %669 = add nsw i64 %647, 12
  %670 = getelementptr inbounds float, float* %4, i64 %669
  %671 = load float, float* %670, align 4, !tbaa !7723
  %672 = insertelement <32 x float> undef, float %671, i32 0
  %673 = shufflevector <32 x float> %672, <32 x float> undef, <32 x i32> zeroinitializer
  %674 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %673, <32 x float> %655, <32 x float> %628)
  %675 = add nsw i64 %647, 16
  %676 = getelementptr inbounds float, float* %4, i64 %675
  %677 = load float, float* %676, align 4, !tbaa !7723
  %678 = insertelement <32 x float> undef, float %677, i32 0
  %679 = shufflevector <32 x float> %678, <32 x float> undef, <32 x i32> zeroinitializer
  %680 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %679, <32 x float> %655, <32 x float> %634)
  %681 = add nsw i64 %647, 20
  %682 = getelementptr inbounds float, float* %4, i64 %681
  %683 = load float, float* %682, align 4, !tbaa !7723
  %684 = insertelement <32 x float> undef, float %683, i32 0
  %685 = shufflevector <32 x float> %684, <32 x float> undef, <32 x i32> zeroinitializer
  %686 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %685, <32 x float> %655, <32 x float> %640)
  %687 = add nsw i64 %647, 24
  %688 = getelementptr inbounds float, float* %4, i64 %687
  %689 = load float, float* %688, align 4, !tbaa !7723
  %690 = insertelement <32 x float> undef, float %689, i32 0
  %691 = shufflevector <32 x float> %690, <32 x float> undef, <32 x i32> zeroinitializer
  %692 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %691, <32 x float> %655, <32 x float> %646)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end6, label %for_begin7.preheader, !prof !50

for_end6:                                         ; preds = %for_begin7.preheader
  store <32 x float> %656, <32 x float>* %486, align 64, !tbaa !7717
  store <32 x float> %662, <32 x float>* %489, align 64, !tbaa !7717
  store <32 x float> %668, <32 x float>* %492, align 64, !tbaa !7717
  store <32 x float> %674, <32 x float>* %495, align 64, !tbaa !7717
  store <32 x float> %680, <32 x float>* %498, align 64, !tbaa !7717
  store <32 x float> %686, <32 x float>* %501, align 64, !tbaa !7717
  store <32 x float> %692, <32 x float>* %504, align 64, !tbaa !7717
  %indvars.iv.next53 = add nuw nsw i64 %indvars.iv52, 1
  %exitcond54 = icmp eq i64 %indvars.iv.next53, 4
  br i1 %exitcond54, label %for_begin10.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_nn_dense_add(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 4
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([71 x i8], [71 x i8]* @.str.547, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !7729
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !7743
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !7746
  %24 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %31 = load i32, i32* %30, align 4
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %35 = load i8*, i8** %34, align 8
  %36 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %37 = load i64*, i64** %36, align 8
  %38 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.548, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %53 = getelementptr inbounds i8, i8* %1, i64 4
  %54 = bitcast i8* %53 to i32*
  %55 = load i32, i32* %54, align 4, !tbaa !7748
  switch i32 %55, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.549, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %57 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %57(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.550, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.551, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %59 = icmp eq i32 %31, 1
  br i1 %59, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %61 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %62 = load i32, i32* %61, align 4
  %63 = icmp eq i32 %62, 2
  br i1 %63, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.526, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %65 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %66 = load i16, i16* %65, align 2
  %67 = icmp eq i16 %66, 1
  %68 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %69 = load i8, i8* %68, align 1
  %70 = icmp eq i8 %69, 32
  %71 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %72 = load i8, i8* %71, align 1
  %73 = icmp eq i8 %72, 2
  %74 = and i1 %70, %73
  %75 = and i1 %67, %74
  br i1 %75, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %77 = load i64, i64* %27, align 8, !tbaa !7750
  %78 = trunc i64 %77 to i32
  %79 = icmp eq i32 %78, 1
  br i1 %79, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %80 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %80(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %81 = getelementptr inbounds i64, i64* %27, i64 1
  %82 = load i64, i64* %81, align 8, !tbaa !7764
  %83 = trunc i64 %82 to i32
  %84 = icmp eq i32 %83, 2048
  br i1 %84, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %85 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %85(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.552, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %86 = icmp eq i64* %29, null
  br i1 %86, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end18
  %87 = load i64, i64* %29, align 8, !tbaa !7766
  %88 = trunc i64 %87 to i32
  %89 = icmp eq i32 %88, 2048
  %90 = getelementptr inbounds i64, i64* %29, i64 1
  %91 = load i64, i64* %90, align 8, !tbaa !7780
  %92 = trunc i64 %91 to i32
  %93 = icmp eq i32 %92, 1
  %94 = and i1 %89, %93
  br i1 %94, label %if_end, label %assert_fail19, !prof !5

if_end:                                           ; preds = %assert_end18, %if_then
  %95 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %96 = load i64, i64* %95, align 8
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %assert_end22, label %assert_fail21, !prof !5

assert_fail19:                                    ; preds = %if_then
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([125 x i8], [125 x i8]* @.str.553, i64 0, i64 0))
  ret i32 -1

assert_fail21:                                    ; preds = %if_end
  %99 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %99(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %if_end
  %100 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %101 = load i32, i32* %100, align 4
  %102 = icmp eq i32 %101, 2
  br i1 %102, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.342, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %104 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %105 = load i16, i16* %104, align 2
  %106 = icmp eq i16 %105, 1
  %107 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %108 = load i8, i8* %107, align 1
  %109 = icmp eq i8 %108, 32
  %110 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %111 = load i8, i8* %110, align 1
  %112 = icmp eq i8 %111, 2
  %113 = and i1 %109, %112
  %114 = and i1 %106, %113
  br i1 %114, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %116 = load i64, i64* %37, align 8, !tbaa !7782
  %117 = trunc i64 %116 to i32
  %118 = icmp eq i32 %117, 1000
  br i1 %118, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %119 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %119(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.554, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %120 = getelementptr inbounds i64, i64* %37, i64 1
  %121 = load i64, i64* %120, align 8, !tbaa !7796
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %122, 2048
  br i1 %123, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %124 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %124(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.343, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %125 = icmp eq i64* %39, null
  br i1 %125, label %if_end32, label %if_then31, !prof !50

if_then31:                                        ; preds = %assert_end30
  %126 = load i64, i64* %39, align 8, !tbaa !7798
  %127 = trunc i64 %126 to i32
  %128 = icmp eq i32 %127, 2048
  %129 = getelementptr inbounds i64, i64* %39, i64 1
  %130 = load i64, i64* %129, align 8, !tbaa !7812
  %131 = trunc i64 %130 to i32
  %132 = icmp eq i32 %131, 1
  %133 = and i1 %128, %132
  br i1 %133, label %if_end32, label %assert_fail33, !prof !5

if_end32:                                         ; preds = %assert_end30, %if_then31
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %135 = load i64, i64* %134, align 8
  %136 = icmp eq i64 %135, 0
  br i1 %136, label %assert_end36, label %assert_fail35, !prof !5

assert_fail33:                                    ; preds = %if_then31
  %137 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %137(i8* getelementptr inbounds ([125 x i8], [125 x i8]* @.str.344, i64 0, i64 0))
  ret i32 -1

assert_fail35:                                    ; preds = %if_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %if_end32
  %139 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %140 = load i32, i32* %139, align 4
  %141 = icmp eq i32 %140, 1
  br i1 %141, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %142 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %142(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %143 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %144 = load i32, i32* %143, align 4
  %145 = icmp eq i32 %33, %144
  br i1 %145, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %147 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.555, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %151 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %152 = load i16, i16* %151, align 2
  %153 = icmp eq i16 %152, 1
  %154 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %155 = load i8, i8* %154, align 1
  %156 = icmp eq i8 %155, 32
  %157 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %158 = load i8, i8* %157, align 1
  %159 = icmp eq i8 %158, 2
  %160 = and i1 %156, %159
  %161 = and i1 %153, %160
  br i1 %161, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %162 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %162(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %163 = load i64, i64* %43, align 8, !tbaa !7814
  %164 = trunc i64 %163 to i32
  %165 = icmp eq i32 %164, 1000
  br i1 %165, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %166 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %166(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.556, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %167 = icmp eq i64* %45, null
  br i1 %167, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %168 = load i64, i64* %45, align 8, !tbaa !7828
  %169 = trunc i64 %168 to i32
  %170 = icmp eq i32 %169, 1
  br i1 %170, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %171 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %172 = load i64, i64* %171, align 8
  %173 = icmp eq i64 %172, 0
  br i1 %173, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @.str.557, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %175 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %175(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %176 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %177 = load i32, i32* %176, align 4
  %178 = icmp eq i32 %177, 1
  br i1 %178, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %179 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %179(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %180 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %181 = load i32, i32* %180, align 4
  %182 = icmp eq i32 %33, %181
  br i1 %182, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %184 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %185 = load i32, i32* %184, align 4
  %186 = icmp eq i32 %185, 2
  br i1 %186, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %187 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %187(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.558, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %188 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %189 = load i16, i16* %188, align 2
  %190 = icmp eq i16 %189, 1
  %191 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %192 = load i8, i8* %191, align 1
  %193 = icmp eq i8 %192, 32
  %194 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %195 = load i8, i8* %194, align 1
  %196 = icmp eq i8 %195, 2
  %197 = and i1 %193, %196
  %198 = and i1 %190, %197
  br i1 %198, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %200 = load i64, i64* %49, align 8, !tbaa !7842
  %201 = trunc i64 %200 to i32
  %202 = icmp eq i32 %201, 1
  br i1 %202, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.559, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %204 = getelementptr inbounds i64, i64* %49, i64 1
  %205 = load i64, i64* %204, align 8, !tbaa !7856
  %206 = trunc i64 %205 to i32
  %207 = icmp eq i32 %206, 1000
  br i1 %207, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.560, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %209 = icmp eq i64* %51, null
  br i1 %209, label %if_end66, label %if_then65, !prof !50

if_then65:                                        ; preds = %assert_end64
  %210 = load i64, i64* %51, align 8, !tbaa !7858
  %211 = trunc i64 %210 to i32
  %212 = icmp eq i32 %211, 1000
  %213 = getelementptr inbounds i64, i64* %51, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !7872
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 1
  %217 = and i1 %212, %216
  br i1 %217, label %if_end66, label %assert_fail67, !prof !5

if_end66:                                         ; preds = %assert_end64, %if_then65
  %218 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %219 = load i64, i64* %218, align 8
  %220 = icmp eq i64 %219, 0
  br i1 %220, label %assert_end70, label %assert_fail69, !prof !5

assert_fail67:                                    ; preds = %if_then65
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([125 x i8], [125 x i8]* @.str.561, i64 0, i64 0))
  ret i32 -1

assert_fail69:                                    ; preds = %if_end66
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %if_end66
  %223 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %224 = load i32, i32* %223, align 4
  %225 = icmp eq i32 %224, 1
  br i1 %225, label %assert_end72, label %assert_fail71, !prof !5

assert_fail71:                                    ; preds = %assert_end70
  %226 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %226(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end72:                                     ; preds = %assert_end70
  %227 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %228 = load i32, i32* %227, align 4
  %229 = icmp eq i32 %33, %228
  br i1 %229, label %assert_end74, label %assert_fail73, !prof !5

assert_fail73:                                    ; preds = %assert_end72
  %230 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %230(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %assert_end72
  %231 = tail call fastcc i32 @fused_nn_dense_add_compute_(i8* %25, i8* %35, i8* %47, i8* %41, i32 %33)
  ret i32 %231
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_dense_add_compute_(i8* noalias, i8* noalias, i8* noalias nocapture, i8* noalias nocapture readonly, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 4000, i32 2, i32 32)
  %7 = alloca %49, align 8
  %8 = getelementptr inbounds %49, %49* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %49, %49* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %49, %49* %7, i64 0, i32 2
  store i8* %6, i8** %10, align 8
  %11 = bitcast %49* %7 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.562, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %for_begin.preheader, label %call_fail, !prof !5

for_begin.preheader:                              ; preds = %entry
  %15 = bitcast i8* %3 to float*
  %16 = bitcast i8* %6 to float*
  %17 = bitcast i8* %2 to float*
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %for_begin.preheader
  %index = phi i64 [ 0, %for_begin.preheader ], [ %index.next, %vector.body ]
  %18 = getelementptr inbounds float, float* %15, i64 %index
  %19 = bitcast float* %18 to <4 x float>*
  %wide.load = load <4 x float>, <4 x float>* %19, align 4, !tbaa !7874
  %20 = getelementptr inbounds float, float* %18, i64 4
  %21 = bitcast float* %20 to <4 x float>*
  %wide.load5 = load <4 x float>, <4 x float>* %21, align 4, !tbaa !7874
  %22 = getelementptr inbounds float, float* %16, i64 %index
  %23 = bitcast float* %22 to <4 x float>*
  %wide.load6 = load <4 x float>, <4 x float>* %23, align 4, !tbaa !7877
  %24 = getelementptr inbounds float, float* %22, i64 4
  %25 = bitcast float* %24 to <4 x float>*
  %wide.load7 = load <4 x float>, <4 x float>* %25, align 4, !tbaa !7877
  %26 = fadd <4 x float> %wide.load, %wide.load6
  %27 = fadd <4 x float> %wide.load5, %wide.load7
  %28 = getelementptr inbounds float, float* %17, i64 %index
  %29 = bitcast float* %28 to <4 x float>*
  store <4 x float> %26, <4 x float>* %29, align 4, !tbaa !7880
  %30 = getelementptr inbounds float, float* %28, i64 4
  %31 = bitcast float* %30 to <4 x float>*
  store <4 x float> %27, <4 x float>* %31, align 4, !tbaa !7880
  %index.next = add i64 %index, 8
  %32 = icmp eq i64 %index.next, 1000
  br i1 %32, label %for_end, label %vector.body, !llvm.loop !7883

call_fail:                                        ; preds = %for_end, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %for_end ]
  ret i32 %merge

for_end:                                          ; preds = %vector.body
  %33 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %34 = call i32 %33(i32 1, i32 %4, i8* nonnull %6)
  br label %call_fail
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.562(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = add nsw i32 %12, 999
  %14 = sdiv i32 %13, %12
  %15 = add nsw i32 %0, 1
  %16 = mul nsw i32 %14, %15
  %17 = icmp slt i32 %16, 1000
  %18 = select i1 %17, i32 %16, i32 1000
  %19 = mul nsw i32 %14, %0
  %20 = icmp slt i32 %19, 1000
  %21 = select i1 %20, i32 %19, i32 1000
  %22 = icmp slt i32 %21, %18
  br i1 %22, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %23 = add i32 %21, 1
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = sext i32 %18 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv7 = phi i64 [ %25, %for_begin1.preheader.preheader ], [ %indvars.iv.next8, %for_end3 ]
  %27 = trunc i64 %indvars.iv7 to i32
  %28 = shl i32 %27, 11
  %29 = sext i32 %28 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body2 ]
  %.06 = phi <16 x float> [ zeroinitializer, %for_begin1.preheader ], [ %38, %for_body2 ]
  %30 = shl nsw i64 %indvars.iv, 4
  %31 = getelementptr inbounds float, float* %4, i64 %30
  %32 = bitcast float* %31 to <16 x float>*
  %33 = load <16 x float>, <16 x float>* %32, align 64, !tbaa !7884
  %34 = add nuw nsw i64 %30, %29
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to <16 x float>*
  %37 = load <16 x float>, <16 x float>* %36, align 64, !tbaa !7887
  %38 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %33, <16 x float> %37, <16 x float> %.06)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50

for_end3:                                         ; preds = %for_body2
  %39 = getelementptr inbounds float, float* %10, i64 %indvars.iv7
  %.0.vec.extract = extractelement <16 x float> %38, i32 0
  %40 = fadd float %.0.vec.extract, 0.000000e+00
  %.4.vec.extract = extractelement <16 x float> %38, i32 1
  %41 = fadd float %.4.vec.extract, %40
  %.8.vec.extract = extractelement <16 x float> %38, i32 2
  %42 = fadd float %.8.vec.extract, %41
  %.12.vec.extract = extractelement <16 x float> %38, i32 3
  %43 = fadd float %.12.vec.extract, %42
  %.16.vec.extract = extractelement <16 x float> %38, i32 4
  %44 = fadd float %.16.vec.extract, %43
  %.20.vec.extract = extractelement <16 x float> %38, i32 5
  %45 = fadd float %.20.vec.extract, %44
  %.24.vec.extract = extractelement <16 x float> %38, i32 6
  %46 = fadd float %.24.vec.extract, %45
  %.28.vec.extract = extractelement <16 x float> %38, i32 7
  %47 = fadd float %.28.vec.extract, %46
  %.32.vec.extract = extractelement <16 x float> %38, i32 8
  %48 = fadd float %.32.vec.extract, %47
  %.36.vec.extract = extractelement <16 x float> %38, i32 9
  %49 = fadd float %.36.vec.extract, %48
  %.40.vec.extract = extractelement <16 x float> %38, i32 10
  %50 = fadd float %.40.vec.extract, %49
  %.44.vec.extract = extractelement <16 x float> %38, i32 11
  %51 = fadd float %.44.vec.extract, %50
  %.48.vec.extract = extractelement <16 x float> %38, i32 12
  %52 = fadd float %.48.vec.extract, %51
  %.52.vec.extract = extractelement <16 x float> %38, i32 13
  %53 = fadd float %.52.vec.extract, %52
  %.56.vec.extract = extractelement <16 x float> %38, i32 14
  %54 = fadd float %.56.vec.extract, %53
  %.60.vec.extract = extractelement <16 x float> %38, i32 15
  %55 = fadd float %.60.vec.extract, %54
  store float %55, float* %39, align 4, !tbaa !7877
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %56 = icmp slt i64 %indvars.iv.next8, %26
  br i1 %56, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 5
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.563, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !7890
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds i8, i8* %0, i64 16
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 8
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !7904
  %18 = getelementptr inbounds i8, i8* %0, i64 24
  %19 = bitcast i8* %18 to %1**
  %20 = load %1*, %1** %19, align 8
  %21 = getelementptr inbounds i8, i8* %1, i64 12
  %22 = bitcast i8* %21 to i32*
  %23 = load i32, i32* %22, align 4, !tbaa !7907
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  %25 = bitcast i8* %24 to %1**
  %26 = load %1*, %1** %25, align 8
  %27 = getelementptr inbounds i8, i8* %1, i64 16
  %28 = bitcast i8* %27 to i32*
  %29 = load i32, i32* %28, align 4, !tbaa !7909
  %30 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %31 = load i8*, i8** %30, align 8
  %32 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %33 = load i64*, i64** %32, align 8
  %34 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %41 = load i8*, i8** %40, align 8
  %42 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %43 = load i64*, i64** %42, align 8
  %44 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %14, i64 0, i32 0
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %1, %1* %14, i64 0, i32 4
  %49 = load i64*, i64** %48, align 8
  %50 = getelementptr inbounds %1, %1* %14, i64 0, i32 5
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %20, i64 0, i32 0
  %53 = load i8*, i8** %52, align 8
  %54 = getelementptr inbounds %1, %1* %20, i64 0, i32 4
  %55 = load i64*, i64** %54, align 8
  %56 = getelementptr inbounds %1, %1* %20, i64 0, i32 5
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %26, i64 0, i32 0
  %59 = load i8*, i8** %58, align 8
  %60 = getelementptr inbounds %1, %1* %26, i64 0, i32 4
  %61 = load i64*, i64** %60, align 8
  %62 = getelementptr inbounds %1, %1* %26, i64 0, i32 5
  %63 = load i64*, i64** %62, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.564, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %65 = getelementptr inbounds i8, i8* %1, i64 4
  %66 = bitcast i8* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !7913
  switch i32 %67, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %68 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %68(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.565, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %17, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.566, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %23, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.567, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %29, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.568, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %72 = icmp eq i32 %37, 1
  br i1 %72, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %74 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = icmp eq i32 %75, 5
  br i1 %76, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %77 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %77(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %78 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %79 = load i16, i16* %78, align 2
  %80 = icmp eq i16 %79, 1
  %81 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %82 = load i8, i8* %81, align 1
  %83 = icmp eq i8 %82, 32
  %84 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %85 = load i8, i8* %84, align 1
  %86 = icmp eq i8 %85, 2
  %87 = and i1 %83, %86
  %88 = and i1 %80, %87
  br i1 %88, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %90 = load i64, i64* %33, align 8, !tbaa !7915
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %91, 1
  br i1 %92, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %93 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %93(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %94 = getelementptr inbounds i64, i64* %33, i64 1
  %95 = load i64, i64* %94, align 8, !tbaa !7929
  %96 = trunc i64 %95 to i32
  %97 = icmp eq i32 %96, 1
  br i1 %97, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %99 = getelementptr inbounds i64, i64* %33, i64 2
  %100 = load i64, i64* %99, align 8, !tbaa !7931
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %101, 28
  br i1 %102, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %103 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %103(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %104 = getelementptr inbounds i64, i64* %33, i64 3
  %105 = load i64, i64* %104, align 8, !tbaa !7934
  %106 = trunc i64 %105 to i32
  %107 = icmp eq i32 %106, 28
  br i1 %107, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %109 = getelementptr inbounds i64, i64* %33, i64 4
  %110 = load i64, i64* %109, align 8, !tbaa !7936
  %111 = trunc i64 %110 to i32
  %112 = icmp eq i32 %111, 128
  br i1 %112, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %113 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %113(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.431, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %114 = icmp eq i64* %35, null
  br i1 %114, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %115 = bitcast i64* %35 to <4 x i64>*
  %116 = load <4 x i64>, <4 x i64>* %115, align 8, !tbaa !7940
  %117 = trunc <4 x i64> %116 to <4 x i32>
  %118 = icmp eq <4 x i32> %117, <i32 100352, i32 100352, i32 3584, i32 128>
  %119 = getelementptr inbounds i64, i64* %35, i64 4
  %120 = load i64, i64* %119, align 8, !tbaa !7952
  %121 = trunc i64 %120 to i32
  %122 = icmp eq i32 %121, 1
  %rdx.shuf139 = shufflevector <4 x i1> %118, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %118, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %123 = extractelement <4 x i1> %bin.rdx142, i32 0
  %124 = and i1 %123, %122
  br i1 %124, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %125 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %126 = load i64, i64* %125, align 8
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %128 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %128(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.569, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %129 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %129(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %130 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %131 = load i32, i32* %130, align 4
  %132 = icmp eq i32 %131, 6
  br i1 %132, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %133 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %133(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %134 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %135 = load i16, i16* %134, align 2
  %136 = icmp eq i16 %135, 1
  %137 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %138 = load i8, i8* %137, align 1
  %139 = icmp eq i8 %138, 32
  %140 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 2
  %143 = and i1 %139, %142
  %144 = and i1 %136, %143
  br i1 %144, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %146 = load i64, i64* %43, align 8, !tbaa !7956
  %147 = trunc i64 %146 to i32
  %148 = icmp eq i32 %147, 4
  br i1 %148, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %149 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %149(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %150 = getelementptr inbounds i64, i64* %43, i64 1
  %151 = load i64, i64* %150, align 8, !tbaa !7970
  %152 = trunc i64 %151 to i32
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %155 = getelementptr inbounds i64, i64* %43, i64 2
  %156 = load i64, i64* %155, align 8, !tbaa !7972
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %157, 3
  br i1 %158, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %159 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %159(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.133, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %160 = getelementptr inbounds i64, i64* %43, i64 3
  %161 = load i64, i64* %160, align 8, !tbaa !7975
  %162 = trunc i64 %161 to i32
  %163 = icmp eq i32 %162, 3
  br i1 %163, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.134, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %165 = getelementptr inbounds i64, i64* %43, i64 4
  %166 = load i64, i64* %165, align 8, !tbaa !7977
  %167 = trunc i64 %166 to i32
  %168 = icmp eq i32 %167, 128
  br i1 %168, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %169 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %169(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.270, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %170 = getelementptr inbounds i64, i64* %43, i64 5
  %171 = load i64, i64* %170, align 8, !tbaa !7981
  %172 = trunc i64 %171 to i32
  %173 = icmp eq i32 %172, 32
  br i1 %173, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %174 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %174(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %175 = icmp eq i64* %45, null
  br i1 %175, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %176 = bitcast i64* %45 to <4 x i64>*
  %177 = load <4 x i64>, <4 x i64>* %176, align 8, !tbaa !7983
  %178 = trunc <4 x i64> %177 to <4 x i32>
  %179 = icmp eq <4 x i32> %178, <i32 36864, i32 36864, i32 12288, i32 4096>
  %180 = getelementptr inbounds i64, i64* %45, i64 4
  %181 = load i64, i64* %180, align 8, !tbaa !7995
  %182 = trunc i64 %181 to i32
  %183 = icmp eq i32 %182, 32
  %184 = getelementptr inbounds i64, i64* %45, i64 5
  %185 = load i64, i64* %184, align 8, !tbaa !7999
  %186 = trunc i64 %185 to i32
  %187 = icmp eq i32 %186, 1
  %rdx.shuf135 = shufflevector <4 x i1> %179, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %179, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %188 = extractelement <4 x i1> %bin.rdx138, i32 0
  %189 = and i1 %188, %183
  %190 = and i1 %189, %187
  br i1 %190, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %191 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %192 = load i64, i64* %191, align 8
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %194 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %194(i8* getelementptr inbounds ([278 x i8], [278 x i8]* @.str.570, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %195 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %195(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %196 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %197 = load i32, i32* %196, align 4
  %198 = icmp eq i32 %197, 1
  br i1 %198, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %199 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %199(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %200 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq i32 %39, %201
  br i1 %202, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %203 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %203(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %204 = getelementptr inbounds %1, %1* %14, i64 0, i32 2
  %205 = load i32, i32* %204, align 4
  %206 = icmp eq i32 %205, 4
  br i1 %206, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %207 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %207(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %208 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 2
  %209 = load i16, i16* %208, align 2
  %210 = icmp eq i16 %209, 1
  %211 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 1
  %212 = load i8, i8* %211, align 1
  %213 = icmp eq i8 %212, 32
  %214 = getelementptr inbounds %1, %1* %14, i64 0, i32 3, i32 0
  %215 = load i8, i8* %214, align 1
  %216 = icmp eq i8 %215, 2
  %217 = and i1 %213, %216
  %218 = and i1 %210, %217
  br i1 %218, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %219 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %219(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %220 = load i64, i64* %49, align 8, !tbaa !8001
  %221 = trunc i64 %220 to i32
  %222 = icmp eq i32 %221, 4
  br i1 %222, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %224 = getelementptr inbounds i64, i64* %49, i64 1
  %225 = load i64, i64* %224, align 8, !tbaa !8015
  %226 = trunc i64 %225 to i32
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %229 = getelementptr inbounds i64, i64* %49, i64 2
  %230 = load i64, i64* %229, align 8, !tbaa !8017
  %231 = trunc i64 %230 to i32
  %232 = icmp eq i32 %231, 1
  br i1 %232, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %233 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %233(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %234 = getelementptr inbounds i64, i64* %49, i64 3
  %235 = load i64, i64* %234, align 8, !tbaa !8020
  %236 = trunc i64 %235 to i32
  %237 = icmp eq i32 %236, 32
  br i1 %237, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %238 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %238(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.110, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %239 = icmp eq i64* %51, null
  br i1 %239, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %240 = bitcast i64* %51 to <4 x i64>*
  %241 = load <4 x i64>, <4 x i64>* %240, align 8, !tbaa !8022
  %242 = trunc <4 x i64> %241 to <4 x i32>
  %243 = icmp eq <4 x i32> %242, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf131 = shufflevector <4 x i1> %243, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %243, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %244 = extractelement <4 x i1> %bin.rdx134, i32 0
  br i1 %244, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %245 = getelementptr inbounds %1, %1* %14, i64 0, i32 6
  %246 = load i64, i64* %245, align 8
  %247 = icmp eq i64 %246, 0
  br i1 %247, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.111, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %249 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %249(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %250 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 0
  %251 = load i32, i32* %250, align 4
  %252 = icmp eq i32 %251, 1
  br i1 %252, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %253 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %253(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %254 = getelementptr inbounds %1, %1* %14, i64 0, i32 1, i32 1
  %255 = load i32, i32* %254, align 4
  %256 = icmp eq i32 %39, %255
  br i1 %256, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %257 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %257(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %258 = getelementptr inbounds %1, %1* %20, i64 0, i32 2
  %259 = load i32, i32* %258, align 4
  %260 = icmp eq i32 %259, 4
  br i1 %260, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %262 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 2
  %263 = load i16, i16* %262, align 2
  %264 = icmp eq i16 %263, 1
  %265 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 1
  %266 = load i8, i8* %265, align 1
  %267 = icmp eq i8 %266, 32
  %268 = getelementptr inbounds %1, %1* %20, i64 0, i32 3, i32 0
  %269 = load i8, i8* %268, align 1
  %270 = icmp eq i8 %269, 2
  %271 = and i1 %267, %270
  %272 = and i1 %264, %271
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = load i64, i64* %55, align 8, !tbaa !8034
  %275 = trunc i64 %274 to i32
  %276 = icmp eq i32 %275, 4
  br i1 %276, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %277 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %277(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %278 = getelementptr inbounds i64, i64* %55, i64 1
  %279 = load i64, i64* %278, align 8, !tbaa !8048
  %280 = trunc i64 %279 to i32
  %281 = icmp eq i32 %280, 1
  br i1 %281, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %282 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %282(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %283 = getelementptr inbounds i64, i64* %55, i64 2
  %284 = load i64, i64* %283, align 8, !tbaa !8050
  %285 = trunc i64 %284 to i32
  %286 = icmp eq i32 %285, 1
  br i1 %286, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %287 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %287(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %288 = getelementptr inbounds i64, i64* %55, i64 3
  %289 = load i64, i64* %288, align 8, !tbaa !8053
  %290 = trunc i64 %289 to i32
  %291 = icmp eq i32 %290, 32
  br i1 %291, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %292 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %292(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %293 = icmp eq i64* %57, null
  br i1 %293, label %if_end92, label %if_then91, !prof !50

if_then91:                                        ; preds = %assert_end90
  %294 = bitcast i64* %57 to <4 x i64>*
  %295 = load <4 x i64>, <4 x i64>* %294, align 8, !tbaa !8055
  %296 = trunc <4 x i64> %295 to <4 x i32>
  %297 = icmp eq <4 x i32> %296, <i32 32, i32 32, i32 32, i32 1>
  %rdx.shuf127 = shufflevector <4 x i1> %297, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx128 = and <4 x i1> %297, %rdx.shuf127
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx128, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx128, %rdx.shuf129
  %298 = extractelement <4 x i1> %bin.rdx130, i32 0
  br i1 %298, label %if_end92, label %assert_fail93, !prof !5

if_end92:                                         ; preds = %assert_end90, %if_then91
  %299 = getelementptr inbounds %1, %1* %20, i64 0, i32 6
  %300 = load i64, i64* %299, align 8
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %assert_end96, label %assert_fail95, !prof !5

assert_fail93:                                    ; preds = %if_then91
  %302 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %302(i8* getelementptr inbounds ([195 x i8], [195 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_fail95:                                    ; preds = %if_end92
  %303 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %303(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end96:                                     ; preds = %if_end92
  %304 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 0
  %305 = load i32, i32* %304, align 4
  %306 = icmp eq i32 %305, 1
  br i1 %306, label %assert_end98, label %assert_fail97, !prof !5

assert_fail97:                                    ; preds = %assert_end96
  %307 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %307(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %assert_end96
  %308 = getelementptr inbounds %1, %1* %20, i64 0, i32 1, i32 1
  %309 = load i32, i32* %308, align 4
  %310 = icmp eq i32 %39, %309
  br i1 %310, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %312 = getelementptr inbounds %1, %1* %26, i64 0, i32 2
  %313 = load i32, i32* %312, align 4
  %314 = icmp eq i32 %313, 5
  br i1 %314, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %315 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %315(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %316 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 2
  %317 = load i16, i16* %316, align 2
  %318 = icmp eq i16 %317, 1
  %319 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 1
  %320 = load i8, i8* %319, align 1
  %321 = icmp eq i8 %320, 32
  %322 = getelementptr inbounds %1, %1* %26, i64 0, i32 3, i32 0
  %323 = load i8, i8* %322, align 1
  %324 = icmp eq i8 %323, 2
  %325 = and i1 %321, %324
  %326 = and i1 %318, %325
  br i1 %326, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %327 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %327(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %328 = load i64, i64* %61, align 8, !tbaa !8067
  %329 = trunc i64 %328 to i32
  %330 = icmp eq i32 %329, 1
  br i1 %330, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %331 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %331(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %332 = getelementptr inbounds i64, i64* %61, i64 1
  %333 = load i64, i64* %332, align 8, !tbaa !8081
  %334 = trunc i64 %333 to i32
  %335 = icmp eq i32 %334, 4
  br i1 %335, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %336 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %336(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.79, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %337 = getelementptr inbounds i64, i64* %61, i64 2
  %338 = load i64, i64* %337, align 8, !tbaa !8083
  %339 = trunc i64 %338 to i32
  %340 = icmp eq i32 %339, 28
  br i1 %340, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %341 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %341(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.214, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %342 = getelementptr inbounds i64, i64* %61, i64 3
  %343 = load i64, i64* %342, align 8, !tbaa !8086
  %344 = trunc i64 %343 to i32
  %345 = icmp eq i32 %344, 28
  br i1 %345, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %346 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %346(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.215, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %347 = getelementptr inbounds i64, i64* %61, i64 4
  %348 = load i64, i64* %347, align 8, !tbaa !8088
  %349 = trunc i64 %348 to i32
  %350 = icmp eq i32 %349, 32
  br i1 %350, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %351 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %351(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %352 = icmp eq i64* %63, null
  br i1 %352, label %if_end116, label %if_then115, !prof !50

if_then115:                                       ; preds = %assert_end114
  %353 = bitcast i64* %63 to <4 x i64>*
  %354 = load <4 x i64>, <4 x i64>* %353, align 8, !tbaa !8092
  %355 = trunc <4 x i64> %354 to <4 x i32>
  %356 = icmp eq <4 x i32> %355, <i32 100352, i32 25088, i32 896, i32 32>
  %357 = getelementptr inbounds i64, i64* %63, i64 4
  %358 = load i64, i64* %357, align 8, !tbaa !8104
  %359 = trunc i64 %358 to i32
  %360 = icmp eq i32 %359, 1
  %rdx.shuf = shufflevector <4 x i1> %356, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %356, %rdx.shuf
  %rdx.shuf125 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx126 = and <4 x i1> %bin.rdx, %rdx.shuf125
  %361 = extractelement <4 x i1> %bin.rdx126, i32 0
  %362 = and i1 %361, %360
  br i1 %362, label %if_end116, label %assert_fail117, !prof !5

if_end116:                                        ; preds = %assert_end114, %if_then115
  %363 = getelementptr inbounds %1, %1* %26, i64 0, i32 6
  %364 = load i64, i64* %363, align 8
  %365 = icmp eq i64 %364, 0
  br i1 %365, label %assert_end120, label %assert_fail119, !prof !5

assert_fail117:                                   ; preds = %if_then115
  %366 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %366(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.216, i64 0, i64 0))
  ret i32 -1

assert_fail119:                                   ; preds = %if_end116
  %367 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %367(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end120:                                    ; preds = %if_end116
  %368 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 0
  %369 = load i32, i32* %368, align 4
  %370 = icmp eq i32 %369, 1
  br i1 %370, label %assert_end122, label %assert_fail121, !prof !5

assert_fail121:                                   ; preds = %assert_end120
  %371 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %371(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.85, i64 0, i64 0))
  ret i32 -1

assert_end122:                                    ; preds = %assert_end120
  %372 = getelementptr inbounds %1, %1* %26, i64 0, i32 1, i32 1
  %373 = load i32, i32* %372, align 4
  %374 = icmp eq i32 %39, %373
  br i1 %374, label %assert_end124, label %assert_fail123, !prof !5

assert_fail123:                                   ; preds = %assert_end122
  %375 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %375(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.86, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %assert_end122
  %376 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6_compute_(i8* %31, i8* %41, i8* %59, i8* %47, i8* %53, i32 %39)
  ret i32 %376
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_6_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 460800, i32 2, i32 32)
  %8 = alloca %50, align 8
  %9 = getelementptr inbounds %50, %50* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %50, %50* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %50* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.571, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %24, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %51, align 8
  %16 = getelementptr inbounds %51, %51* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %51, %51* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %51, %51* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %51, %51* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %51, %51* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = getelementptr inbounds %51, %51* %15, i64 0, i32 5
  store i32 %5, i32* %21, align 8
  %22 = bitcast %51* %15 to i8*
  %23 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %24 = call i32 %23(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.572, i8* nonnull %22, i32 0)
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %26 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %27 = call i32 %26(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.571(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 29
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 30
  %15 = select i1 %14, i32 %13, i32 30
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 30
  %18 = select i1 %17, i32 %16, i32 30
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = mul i32 %11, %0
  %21 = icmp slt i32 %20, 30
  %22 = select i1 %21, i32 %20, i32 30
  %smax = xor i32 %22, -1
  %23 = mul i32 %smax, -3584
  %24 = add i32 %23, -7680
  %25 = or i32 %24, 384
  %26 = zext i32 %25 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvar = phi i64 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %27 = phi i32 [ %18, %for_begin1.preheader.preheader ], [ %564, %for_end3 ]
  %28 = mul i64 %indvar, 3584
  %29 = add i64 %28, %26
  %30 = mul nsw i32 %27, 3840
  %.off = add i32 %27, -1
  %31 = icmp ult i32 %.off, 28
  %32 = mul nsw i32 %27, 3584
  br i1 %31, label %for_begin4.preheader.us, label %for_begin4.preheader

for_begin4.preheader.us:                          ; preds = %for_begin1.preheader, %for_end6.us
  %indvars.iv24 = phi i64 [ %indvars.iv.next25, %for_end6.us ], [ 0, %for_begin1.preheader ]
  %33 = shl nsw i64 %indvars.iv24, 7
  %34 = trunc i64 %indvars.iv24 to i32
  %35 = add i32 %34, -1
  %36 = icmp ult i32 %35, 28
  br i1 %36, label %vector.scevcheck, label %vector.body37

vector.body37:                                    ; preds = %for_begin4.preheader.us
  %37 = trunc i64 %33 to i32
  %38 = add i32 %30, %37
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %4, i64 %39
  %41 = bitcast float* %40 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %41, align 4, !tbaa !8108
  %42 = getelementptr inbounds float, float* %40, i64 4
  %43 = bitcast float* %42 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %43, align 4, !tbaa !8108
  %44 = trunc i64 %33 to i32
  %45 = or i32 %44, 8
  %46 = add i32 %30, %45
  %47 = sext i32 %46 to i64
  %48 = getelementptr inbounds float, float* %4, i64 %47
  %49 = bitcast float* %48 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %49, align 4, !tbaa !8108
  %50 = getelementptr inbounds float, float* %48, i64 4
  %51 = bitcast float* %50 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %51, align 4, !tbaa !8108
  %52 = trunc i64 %33 to i32
  %53 = or i32 %52, 16
  %54 = add i32 %30, %53
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds float, float* %4, i64 %55
  %57 = bitcast float* %56 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %57, align 4, !tbaa !8108
  %58 = getelementptr inbounds float, float* %56, i64 4
  %59 = bitcast float* %58 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %59, align 4, !tbaa !8108
  %60 = trunc i64 %33 to i32
  %61 = or i32 %60, 24
  %62 = add i32 %30, %61
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %4, i64 %63
  %65 = bitcast float* %64 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %65, align 4, !tbaa !8108
  %66 = getelementptr inbounds float, float* %64, i64 4
  %67 = bitcast float* %66 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %67, align 4, !tbaa !8108
  %68 = trunc i64 %33 to i32
  %69 = or i32 %68, 32
  %70 = add i32 %30, %69
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds float, float* %4, i64 %71
  %73 = bitcast float* %72 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %73, align 4, !tbaa !8108
  %74 = getelementptr inbounds float, float* %72, i64 4
  %75 = bitcast float* %74 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %75, align 4, !tbaa !8108
  %76 = trunc i64 %33 to i32
  %77 = or i32 %76, 40
  %78 = add i32 %30, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = bitcast float* %80 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %81, align 4, !tbaa !8108
  %82 = getelementptr inbounds float, float* %80, i64 4
  %83 = bitcast float* %82 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %83, align 4, !tbaa !8108
  %84 = trunc i64 %33 to i32
  %85 = or i32 %84, 48
  %86 = add i32 %30, %85
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds float, float* %4, i64 %87
  %89 = bitcast float* %88 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %89, align 4, !tbaa !8108
  %90 = getelementptr inbounds float, float* %88, i64 4
  %91 = bitcast float* %90 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %91, align 4, !tbaa !8108
  %92 = trunc i64 %33 to i32
  %93 = or i32 %92, 56
  %94 = add i32 %30, %93
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = bitcast float* %96 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %97, align 4, !tbaa !8108
  %98 = getelementptr inbounds float, float* %96, i64 4
  %99 = bitcast float* %98 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %99, align 4, !tbaa !8108
  %100 = trunc i64 %33 to i32
  %101 = or i32 %100, 64
  %102 = add i32 %30, %101
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %4, i64 %103
  %105 = bitcast float* %104 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %105, align 4, !tbaa !8108
  %106 = getelementptr inbounds float, float* %104, i64 4
  %107 = bitcast float* %106 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %107, align 4, !tbaa !8108
  %108 = trunc i64 %33 to i32
  %109 = or i32 %108, 72
  %110 = add i32 %30, %109
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %4, i64 %111
  %113 = bitcast float* %112 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %113, align 4, !tbaa !8108
  %114 = getelementptr inbounds float, float* %112, i64 4
  %115 = bitcast float* %114 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %115, align 4, !tbaa !8108
  %116 = trunc i64 %33 to i32
  %117 = or i32 %116, 80
  %118 = add i32 %30, %117
  %119 = sext i32 %118 to i64
  %120 = getelementptr inbounds float, float* %4, i64 %119
  %121 = bitcast float* %120 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %121, align 4, !tbaa !8108
  %122 = getelementptr inbounds float, float* %120, i64 4
  %123 = bitcast float* %122 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %123, align 4, !tbaa !8108
  %124 = trunc i64 %33 to i32
  %125 = or i32 %124, 88
  %126 = add i32 %30, %125
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds float, float* %4, i64 %127
  %129 = bitcast float* %128 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %129, align 4, !tbaa !8108
  %130 = getelementptr inbounds float, float* %128, i64 4
  %131 = bitcast float* %130 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %131, align 4, !tbaa !8108
  %132 = trunc i64 %33 to i32
  %133 = or i32 %132, 96
  %134 = add i32 %30, %133
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds float, float* %4, i64 %135
  %137 = bitcast float* %136 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %137, align 4, !tbaa !8108
  %138 = getelementptr inbounds float, float* %136, i64 4
  %139 = bitcast float* %138 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %139, align 4, !tbaa !8108
  %140 = trunc i64 %33 to i32
  %141 = or i32 %140, 104
  %142 = add i32 %30, %141
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds float, float* %4, i64 %143
  %145 = bitcast float* %144 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %145, align 4, !tbaa !8108
  %146 = getelementptr inbounds float, float* %144, i64 4
  %147 = bitcast float* %146 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %147, align 4, !tbaa !8108
  %148 = trunc i64 %33 to i32
  %149 = or i32 %148, 112
  %150 = add i32 %30, %149
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %4, i64 %151
  %153 = bitcast float* %152 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %153, align 4, !tbaa !8108
  %154 = getelementptr inbounds float, float* %152, i64 4
  %155 = bitcast float* %154 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %155, align 4, !tbaa !8108
  %156 = trunc i64 %33 to i32
  %157 = or i32 %156, 120
  %158 = add i32 %30, %157
  %159 = sext i32 %158 to i64
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = bitcast float* %160 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %161, align 4, !tbaa !8108
  %162 = getelementptr inbounds float, float* %160, i64 4
  %163 = bitcast float* %162 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %163, align 4, !tbaa !8108
  br label %for_end6.us

vector.scevcheck:                                 ; preds = %for_begin4.preheader.us
  %164 = shl i64 %indvars.iv24, 7
  %165 = add i64 %29, %164
  %166 = trunc i64 %165 to i32
  %167 = icmp sgt i32 %166, 2147483520
  br i1 %167, label %for_body5.us.us, label %vector.body

vector.body:                                      ; preds = %vector.scevcheck
  %168 = trunc i64 %33 to i32
  %169 = add i32 %30, %168
  %170 = trunc i64 %33 to i32
  %171 = add i32 %170, -3712
  %172 = add i32 %171, %32
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %175, align 4, !tbaa !8111
  %176 = getelementptr inbounds float, float* %174, i64 4
  %177 = bitcast float* %176 to <4 x i32>*
  %wide.load36 = load <4 x i32>, <4 x i32>* %177, align 4, !tbaa !8111
  %178 = sext i32 %169 to i64
  %179 = getelementptr inbounds float, float* %4, i64 %178
  %180 = bitcast float* %179 to <4 x i32>*
  store <4 x i32> %wide.load, <4 x i32>* %180, align 4, !tbaa !8108
  %181 = getelementptr inbounds float, float* %179, i64 4
  %182 = bitcast float* %181 to <4 x i32>*
  store <4 x i32> %wide.load36, <4 x i32>* %182, align 4, !tbaa !8108
  %183 = or i64 %33, 8
  %184 = trunc i64 %183 to i32
  %185 = add i32 %30, %184
  %186 = trunc i64 %183 to i32
  %187 = add i32 %186, -3712
  %188 = add i32 %187, %32
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to <4 x i32>*
  %wide.load.1 = load <4 x i32>, <4 x i32>* %191, align 4, !tbaa !8111
  %192 = getelementptr inbounds float, float* %190, i64 4
  %193 = bitcast float* %192 to <4 x i32>*
  %wide.load36.1 = load <4 x i32>, <4 x i32>* %193, align 4, !tbaa !8111
  %194 = sext i32 %185 to i64
  %195 = getelementptr inbounds float, float* %4, i64 %194
  %196 = bitcast float* %195 to <4 x i32>*
  store <4 x i32> %wide.load.1, <4 x i32>* %196, align 4, !tbaa !8108
  %197 = getelementptr inbounds float, float* %195, i64 4
  %198 = bitcast float* %197 to <4 x i32>*
  store <4 x i32> %wide.load36.1, <4 x i32>* %198, align 4, !tbaa !8108
  %199 = or i64 %33, 16
  %200 = trunc i64 %199 to i32
  %201 = add i32 %30, %200
  %202 = trunc i64 %199 to i32
  %203 = add i32 %202, -3712
  %204 = add i32 %203, %32
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = bitcast float* %206 to <4 x i32>*
  %wide.load.2 = load <4 x i32>, <4 x i32>* %207, align 4, !tbaa !8111
  %208 = getelementptr inbounds float, float* %206, i64 4
  %209 = bitcast float* %208 to <4 x i32>*
  %wide.load36.2 = load <4 x i32>, <4 x i32>* %209, align 4, !tbaa !8111
  %210 = sext i32 %201 to i64
  %211 = getelementptr inbounds float, float* %4, i64 %210
  %212 = bitcast float* %211 to <4 x i32>*
  store <4 x i32> %wide.load.2, <4 x i32>* %212, align 4, !tbaa !8108
  %213 = getelementptr inbounds float, float* %211, i64 4
  %214 = bitcast float* %213 to <4 x i32>*
  store <4 x i32> %wide.load36.2, <4 x i32>* %214, align 4, !tbaa !8108
  %215 = or i64 %33, 24
  %216 = trunc i64 %215 to i32
  %217 = add i32 %30, %216
  %218 = trunc i64 %215 to i32
  %219 = add i32 %218, -3712
  %220 = add i32 %219, %32
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds float, float* %7, i64 %221
  %223 = bitcast float* %222 to <4 x i32>*
  %wide.load.3 = load <4 x i32>, <4 x i32>* %223, align 4, !tbaa !8111
  %224 = getelementptr inbounds float, float* %222, i64 4
  %225 = bitcast float* %224 to <4 x i32>*
  %wide.load36.3 = load <4 x i32>, <4 x i32>* %225, align 4, !tbaa !8111
  %226 = sext i32 %217 to i64
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = bitcast float* %227 to <4 x i32>*
  store <4 x i32> %wide.load.3, <4 x i32>* %228, align 4, !tbaa !8108
  %229 = getelementptr inbounds float, float* %227, i64 4
  %230 = bitcast float* %229 to <4 x i32>*
  store <4 x i32> %wide.load36.3, <4 x i32>* %230, align 4, !tbaa !8108
  %231 = or i64 %33, 32
  %232 = trunc i64 %231 to i32
  %233 = add i32 %30, %232
  %234 = trunc i64 %231 to i32
  %235 = add i32 %234, -3712
  %236 = add i32 %235, %32
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds float, float* %7, i64 %237
  %239 = bitcast float* %238 to <4 x i32>*
  %wide.load.4 = load <4 x i32>, <4 x i32>* %239, align 4, !tbaa !8111
  %240 = getelementptr inbounds float, float* %238, i64 4
  %241 = bitcast float* %240 to <4 x i32>*
  %wide.load36.4 = load <4 x i32>, <4 x i32>* %241, align 4, !tbaa !8111
  %242 = sext i32 %233 to i64
  %243 = getelementptr inbounds float, float* %4, i64 %242
  %244 = bitcast float* %243 to <4 x i32>*
  store <4 x i32> %wide.load.4, <4 x i32>* %244, align 4, !tbaa !8108
  %245 = getelementptr inbounds float, float* %243, i64 4
  %246 = bitcast float* %245 to <4 x i32>*
  store <4 x i32> %wide.load36.4, <4 x i32>* %246, align 4, !tbaa !8108
  %247 = or i64 %33, 40
  %248 = trunc i64 %247 to i32
  %249 = add i32 %30, %248
  %250 = trunc i64 %247 to i32
  %251 = add i32 %250, -3712
  %252 = add i32 %251, %32
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds float, float* %7, i64 %253
  %255 = bitcast float* %254 to <4 x i32>*
  %wide.load.5 = load <4 x i32>, <4 x i32>* %255, align 4, !tbaa !8111
  %256 = getelementptr inbounds float, float* %254, i64 4
  %257 = bitcast float* %256 to <4 x i32>*
  %wide.load36.5 = load <4 x i32>, <4 x i32>* %257, align 4, !tbaa !8111
  %258 = sext i32 %249 to i64
  %259 = getelementptr inbounds float, float* %4, i64 %258
  %260 = bitcast float* %259 to <4 x i32>*
  store <4 x i32> %wide.load.5, <4 x i32>* %260, align 4, !tbaa !8108
  %261 = getelementptr inbounds float, float* %259, i64 4
  %262 = bitcast float* %261 to <4 x i32>*
  store <4 x i32> %wide.load36.5, <4 x i32>* %262, align 4, !tbaa !8108
  %263 = or i64 %33, 48
  %264 = trunc i64 %263 to i32
  %265 = add i32 %30, %264
  %266 = trunc i64 %263 to i32
  %267 = add i32 %266, -3712
  %268 = add i32 %267, %32
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds float, float* %7, i64 %269
  %271 = bitcast float* %270 to <4 x i32>*
  %wide.load.6 = load <4 x i32>, <4 x i32>* %271, align 4, !tbaa !8111
  %272 = getelementptr inbounds float, float* %270, i64 4
  %273 = bitcast float* %272 to <4 x i32>*
  %wide.load36.6 = load <4 x i32>, <4 x i32>* %273, align 4, !tbaa !8111
  %274 = sext i32 %265 to i64
  %275 = getelementptr inbounds float, float* %4, i64 %274
  %276 = bitcast float* %275 to <4 x i32>*
  store <4 x i32> %wide.load.6, <4 x i32>* %276, align 4, !tbaa !8108
  %277 = getelementptr inbounds float, float* %275, i64 4
  %278 = bitcast float* %277 to <4 x i32>*
  store <4 x i32> %wide.load36.6, <4 x i32>* %278, align 4, !tbaa !8108
  %279 = or i64 %33, 56
  %280 = trunc i64 %279 to i32
  %281 = add i32 %30, %280
  %282 = trunc i64 %279 to i32
  %283 = add i32 %282, -3712
  %284 = add i32 %283, %32
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds float, float* %7, i64 %285
  %287 = bitcast float* %286 to <4 x i32>*
  %wide.load.7 = load <4 x i32>, <4 x i32>* %287, align 4, !tbaa !8111
  %288 = getelementptr inbounds float, float* %286, i64 4
  %289 = bitcast float* %288 to <4 x i32>*
  %wide.load36.7 = load <4 x i32>, <4 x i32>* %289, align 4, !tbaa !8111
  %290 = sext i32 %281 to i64
  %291 = getelementptr inbounds float, float* %4, i64 %290
  %292 = bitcast float* %291 to <4 x i32>*
  store <4 x i32> %wide.load.7, <4 x i32>* %292, align 4, !tbaa !8108
  %293 = getelementptr inbounds float, float* %291, i64 4
  %294 = bitcast float* %293 to <4 x i32>*
  store <4 x i32> %wide.load36.7, <4 x i32>* %294, align 4, !tbaa !8108
  %295 = or i64 %33, 64
  %296 = trunc i64 %295 to i32
  %297 = add i32 %30, %296
  %298 = trunc i64 %295 to i32
  %299 = add i32 %298, -3712
  %300 = add i32 %299, %32
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds float, float* %7, i64 %301
  %303 = bitcast float* %302 to <4 x i32>*
  %wide.load.8 = load <4 x i32>, <4 x i32>* %303, align 4, !tbaa !8111
  %304 = getelementptr inbounds float, float* %302, i64 4
  %305 = bitcast float* %304 to <4 x i32>*
  %wide.load36.8 = load <4 x i32>, <4 x i32>* %305, align 4, !tbaa !8111
  %306 = sext i32 %297 to i64
  %307 = getelementptr inbounds float, float* %4, i64 %306
  %308 = bitcast float* %307 to <4 x i32>*
  store <4 x i32> %wide.load.8, <4 x i32>* %308, align 4, !tbaa !8108
  %309 = getelementptr inbounds float, float* %307, i64 4
  %310 = bitcast float* %309 to <4 x i32>*
  store <4 x i32> %wide.load36.8, <4 x i32>* %310, align 4, !tbaa !8108
  %311 = or i64 %33, 72
  %312 = trunc i64 %311 to i32
  %313 = add i32 %30, %312
  %314 = trunc i64 %311 to i32
  %315 = add i32 %314, -3712
  %316 = add i32 %315, %32
  %317 = sext i32 %316 to i64
  %318 = getelementptr inbounds float, float* %7, i64 %317
  %319 = bitcast float* %318 to <4 x i32>*
  %wide.load.9 = load <4 x i32>, <4 x i32>* %319, align 4, !tbaa !8111
  %320 = getelementptr inbounds float, float* %318, i64 4
  %321 = bitcast float* %320 to <4 x i32>*
  %wide.load36.9 = load <4 x i32>, <4 x i32>* %321, align 4, !tbaa !8111
  %322 = sext i32 %313 to i64
  %323 = getelementptr inbounds float, float* %4, i64 %322
  %324 = bitcast float* %323 to <4 x i32>*
  store <4 x i32> %wide.load.9, <4 x i32>* %324, align 4, !tbaa !8108
  %325 = getelementptr inbounds float, float* %323, i64 4
  %326 = bitcast float* %325 to <4 x i32>*
  store <4 x i32> %wide.load36.9, <4 x i32>* %326, align 4, !tbaa !8108
  %327 = or i64 %33, 80
  %328 = trunc i64 %327 to i32
  %329 = add i32 %30, %328
  %330 = trunc i64 %327 to i32
  %331 = add i32 %330, -3712
  %332 = add i32 %331, %32
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds float, float* %7, i64 %333
  %335 = bitcast float* %334 to <4 x i32>*
  %wide.load.10 = load <4 x i32>, <4 x i32>* %335, align 4, !tbaa !8111
  %336 = getelementptr inbounds float, float* %334, i64 4
  %337 = bitcast float* %336 to <4 x i32>*
  %wide.load36.10 = load <4 x i32>, <4 x i32>* %337, align 4, !tbaa !8111
  %338 = sext i32 %329 to i64
  %339 = getelementptr inbounds float, float* %4, i64 %338
  %340 = bitcast float* %339 to <4 x i32>*
  store <4 x i32> %wide.load.10, <4 x i32>* %340, align 4, !tbaa !8108
  %341 = getelementptr inbounds float, float* %339, i64 4
  %342 = bitcast float* %341 to <4 x i32>*
  store <4 x i32> %wide.load36.10, <4 x i32>* %342, align 4, !tbaa !8108
  %343 = or i64 %33, 88
  %344 = trunc i64 %343 to i32
  %345 = add i32 %30, %344
  %346 = trunc i64 %343 to i32
  %347 = add i32 %346, -3712
  %348 = add i32 %347, %32
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds float, float* %7, i64 %349
  %351 = bitcast float* %350 to <4 x i32>*
  %wide.load.11 = load <4 x i32>, <4 x i32>* %351, align 4, !tbaa !8111
  %352 = getelementptr inbounds float, float* %350, i64 4
  %353 = bitcast float* %352 to <4 x i32>*
  %wide.load36.11 = load <4 x i32>, <4 x i32>* %353, align 4, !tbaa !8111
  %354 = sext i32 %345 to i64
  %355 = getelementptr inbounds float, float* %4, i64 %354
  %356 = bitcast float* %355 to <4 x i32>*
  store <4 x i32> %wide.load.11, <4 x i32>* %356, align 4, !tbaa !8108
  %357 = getelementptr inbounds float, float* %355, i64 4
  %358 = bitcast float* %357 to <4 x i32>*
  store <4 x i32> %wide.load36.11, <4 x i32>* %358, align 4, !tbaa !8108
  %359 = or i64 %33, 96
  %360 = trunc i64 %359 to i32
  %361 = add i32 %30, %360
  %362 = trunc i64 %359 to i32
  %363 = add i32 %362, -3712
  %364 = add i32 %363, %32
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds float, float* %7, i64 %365
  %367 = bitcast float* %366 to <4 x i32>*
  %wide.load.12 = load <4 x i32>, <4 x i32>* %367, align 4, !tbaa !8111
  %368 = getelementptr inbounds float, float* %366, i64 4
  %369 = bitcast float* %368 to <4 x i32>*
  %wide.load36.12 = load <4 x i32>, <4 x i32>* %369, align 4, !tbaa !8111
  %370 = sext i32 %361 to i64
  %371 = getelementptr inbounds float, float* %4, i64 %370
  %372 = bitcast float* %371 to <4 x i32>*
  store <4 x i32> %wide.load.12, <4 x i32>* %372, align 4, !tbaa !8108
  %373 = getelementptr inbounds float, float* %371, i64 4
  %374 = bitcast float* %373 to <4 x i32>*
  store <4 x i32> %wide.load36.12, <4 x i32>* %374, align 4, !tbaa !8108
  %375 = or i64 %33, 104
  %376 = trunc i64 %375 to i32
  %377 = add i32 %30, %376
  %378 = trunc i64 %375 to i32
  %379 = add i32 %378, -3712
  %380 = add i32 %379, %32
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds float, float* %7, i64 %381
  %383 = bitcast float* %382 to <4 x i32>*
  %wide.load.13 = load <4 x i32>, <4 x i32>* %383, align 4, !tbaa !8111
  %384 = getelementptr inbounds float, float* %382, i64 4
  %385 = bitcast float* %384 to <4 x i32>*
  %wide.load36.13 = load <4 x i32>, <4 x i32>* %385, align 4, !tbaa !8111
  %386 = sext i32 %377 to i64
  %387 = getelementptr inbounds float, float* %4, i64 %386
  %388 = bitcast float* %387 to <4 x i32>*
  store <4 x i32> %wide.load.13, <4 x i32>* %388, align 4, !tbaa !8108
  %389 = getelementptr inbounds float, float* %387, i64 4
  %390 = bitcast float* %389 to <4 x i32>*
  store <4 x i32> %wide.load36.13, <4 x i32>* %390, align 4, !tbaa !8108
  %391 = or i64 %33, 112
  %392 = trunc i64 %391 to i32
  %393 = add i32 %30, %392
  %394 = trunc i64 %391 to i32
  %395 = add i32 %394, -3712
  %396 = add i32 %395, %32
  %397 = sext i32 %396 to i64
  %398 = getelementptr inbounds float, float* %7, i64 %397
  %399 = bitcast float* %398 to <4 x i32>*
  %wide.load.14 = load <4 x i32>, <4 x i32>* %399, align 4, !tbaa !8111
  %400 = getelementptr inbounds float, float* %398, i64 4
  %401 = bitcast float* %400 to <4 x i32>*
  %wide.load36.14 = load <4 x i32>, <4 x i32>* %401, align 4, !tbaa !8111
  %402 = sext i32 %393 to i64
  %403 = getelementptr inbounds float, float* %4, i64 %402
  %404 = bitcast float* %403 to <4 x i32>*
  store <4 x i32> %wide.load.14, <4 x i32>* %404, align 4, !tbaa !8108
  %405 = getelementptr inbounds float, float* %403, i64 4
  %406 = bitcast float* %405 to <4 x i32>*
  store <4 x i32> %wide.load36.14, <4 x i32>* %406, align 4, !tbaa !8108
  %407 = or i64 %33, 120
  %408 = trunc i64 %407 to i32
  %409 = add i32 %30, %408
  %410 = trunc i64 %407 to i32
  %411 = add i32 %410, -3712
  %412 = add i32 %411, %32
  %413 = sext i32 %412 to i64
  %414 = getelementptr inbounds float, float* %7, i64 %413
  %415 = bitcast float* %414 to <4 x i32>*
  %wide.load.15 = load <4 x i32>, <4 x i32>* %415, align 4, !tbaa !8111
  %416 = getelementptr inbounds float, float* %414, i64 4
  %417 = bitcast float* %416 to <4 x i32>*
  %wide.load36.15 = load <4 x i32>, <4 x i32>* %417, align 4, !tbaa !8111
  %418 = sext i32 %409 to i64
  %419 = getelementptr inbounds float, float* %4, i64 %418
  %420 = bitcast float* %419 to <4 x i32>*
  store <4 x i32> %wide.load.15, <4 x i32>* %420, align 4, !tbaa !8108
  %421 = getelementptr inbounds float, float* %419, i64 4
  %422 = bitcast float* %421 to <4 x i32>*
  store <4 x i32> %wide.load36.15, <4 x i32>* %422, align 4, !tbaa !8108
  br label %for_end6.us

for_end6.us:                                      ; preds = %for_body5.us.us, %vector.body37, %vector.body
  %indvars.iv.next25 = add nuw nsw i64 %indvars.iv24, 1
  %exitcond27 = icmp eq i64 %indvars.iv.next25, 30
  br i1 %exitcond27, label %for_end3, label %for_begin4.preheader.us, !prof !50

for_body5.us.us:                                  ; preds = %vector.scevcheck, %for_body5.us.us
  %indvars.iv21 = phi i64 [ %indvars.iv.next22, %for_body5.us.us ], [ 0, %vector.scevcheck ]
  %423 = add nuw nsw i64 %indvars.iv21, %33
  %424 = trunc i64 %423 to i32
  %425 = add i32 %30, %424
  %426 = trunc i64 %423 to i32
  %427 = add i32 %426, -3712
  %428 = add i32 %427, %32
  %429 = sext i32 %428 to i64
  %430 = getelementptr inbounds float, float* %7, i64 %429
  %431 = bitcast float* %430 to i32*
  %432 = load i32, i32* %431, align 4, !tbaa !8111
  %433 = sext i32 %425 to i64
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = bitcast float* %434 to i32*
  store i32 %432, i32* %435, align 4, !tbaa !8108
  %indvars.iv.next22 = add nuw nsw i64 %indvars.iv21, 1
  %exitcond23 = icmp eq i64 %indvars.iv.next22, 128
  br i1 %exitcond23, label %for_end6.us, label %for_body5.us.us, !prof !50, !llvm.loop !8114

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_begin1.preheader, %for_begin4.preheader
  %indvars.iv15 = phi i64 [ %indvars.iv.next16, %for_begin4.preheader ], [ 0, %for_begin1.preheader ]
  %436 = shl nsw i64 %indvars.iv15, 7
  %437 = trunc i64 %436 to i32
  %438 = add i32 %30, %437
  %439 = sext i32 %438 to i64
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = bitcast float* %440 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %441, align 4, !tbaa !8108
  %442 = getelementptr inbounds float, float* %440, i64 4
  %443 = bitcast float* %442 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %443, align 4, !tbaa !8108
  %444 = trunc i64 %436 to i32
  %445 = or i32 %444, 8
  %446 = add i32 %30, %445
  %447 = sext i32 %446 to i64
  %448 = getelementptr inbounds float, float* %4, i64 %447
  %449 = bitcast float* %448 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %449, align 4, !tbaa !8108
  %450 = getelementptr inbounds float, float* %448, i64 4
  %451 = bitcast float* %450 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %451, align 4, !tbaa !8108
  %452 = trunc i64 %436 to i32
  %453 = or i32 %452, 16
  %454 = add i32 %30, %453
  %455 = sext i32 %454 to i64
  %456 = getelementptr inbounds float, float* %4, i64 %455
  %457 = bitcast float* %456 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %457, align 4, !tbaa !8108
  %458 = getelementptr inbounds float, float* %456, i64 4
  %459 = bitcast float* %458 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %459, align 4, !tbaa !8108
  %460 = trunc i64 %436 to i32
  %461 = or i32 %460, 24
  %462 = add i32 %30, %461
  %463 = sext i32 %462 to i64
  %464 = getelementptr inbounds float, float* %4, i64 %463
  %465 = bitcast float* %464 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %465, align 4, !tbaa !8108
  %466 = getelementptr inbounds float, float* %464, i64 4
  %467 = bitcast float* %466 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %467, align 4, !tbaa !8108
  %468 = trunc i64 %436 to i32
  %469 = or i32 %468, 32
  %470 = add i32 %30, %469
  %471 = sext i32 %470 to i64
  %472 = getelementptr inbounds float, float* %4, i64 %471
  %473 = bitcast float* %472 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %473, align 4, !tbaa !8108
  %474 = getelementptr inbounds float, float* %472, i64 4
  %475 = bitcast float* %474 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %475, align 4, !tbaa !8108
  %476 = trunc i64 %436 to i32
  %477 = or i32 %476, 40
  %478 = add i32 %30, %477
  %479 = sext i32 %478 to i64
  %480 = getelementptr inbounds float, float* %4, i64 %479
  %481 = bitcast float* %480 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %481, align 4, !tbaa !8108
  %482 = getelementptr inbounds float, float* %480, i64 4
  %483 = bitcast float* %482 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %483, align 4, !tbaa !8108
  %484 = trunc i64 %436 to i32
  %485 = or i32 %484, 48
  %486 = add i32 %30, %485
  %487 = sext i32 %486 to i64
  %488 = getelementptr inbounds float, float* %4, i64 %487
  %489 = bitcast float* %488 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %489, align 4, !tbaa !8108
  %490 = getelementptr inbounds float, float* %488, i64 4
  %491 = bitcast float* %490 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %491, align 4, !tbaa !8108
  %492 = trunc i64 %436 to i32
  %493 = or i32 %492, 56
  %494 = add i32 %30, %493
  %495 = sext i32 %494 to i64
  %496 = getelementptr inbounds float, float* %4, i64 %495
  %497 = bitcast float* %496 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %497, align 4, !tbaa !8108
  %498 = getelementptr inbounds float, float* %496, i64 4
  %499 = bitcast float* %498 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %499, align 4, !tbaa !8108
  %500 = trunc i64 %436 to i32
  %501 = or i32 %500, 64
  %502 = add i32 %30, %501
  %503 = sext i32 %502 to i64
  %504 = getelementptr inbounds float, float* %4, i64 %503
  %505 = bitcast float* %504 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %505, align 4, !tbaa !8108
  %506 = getelementptr inbounds float, float* %504, i64 4
  %507 = bitcast float* %506 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %507, align 4, !tbaa !8108
  %508 = trunc i64 %436 to i32
  %509 = or i32 %508, 72
  %510 = add i32 %30, %509
  %511 = sext i32 %510 to i64
  %512 = getelementptr inbounds float, float* %4, i64 %511
  %513 = bitcast float* %512 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %513, align 4, !tbaa !8108
  %514 = getelementptr inbounds float, float* %512, i64 4
  %515 = bitcast float* %514 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %515, align 4, !tbaa !8108
  %516 = trunc i64 %436 to i32
  %517 = or i32 %516, 80
  %518 = add i32 %30, %517
  %519 = sext i32 %518 to i64
  %520 = getelementptr inbounds float, float* %4, i64 %519
  %521 = bitcast float* %520 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %521, align 4, !tbaa !8108
  %522 = getelementptr inbounds float, float* %520, i64 4
  %523 = bitcast float* %522 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %523, align 4, !tbaa !8108
  %524 = trunc i64 %436 to i32
  %525 = or i32 %524, 88
  %526 = add i32 %30, %525
  %527 = sext i32 %526 to i64
  %528 = getelementptr inbounds float, float* %4, i64 %527
  %529 = bitcast float* %528 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %529, align 4, !tbaa !8108
  %530 = getelementptr inbounds float, float* %528, i64 4
  %531 = bitcast float* %530 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %531, align 4, !tbaa !8108
  %532 = trunc i64 %436 to i32
  %533 = or i32 %532, 96
  %534 = add i32 %30, %533
  %535 = sext i32 %534 to i64
  %536 = getelementptr inbounds float, float* %4, i64 %535
  %537 = bitcast float* %536 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %537, align 4, !tbaa !8108
  %538 = getelementptr inbounds float, float* %536, i64 4
  %539 = bitcast float* %538 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %539, align 4, !tbaa !8108
  %540 = trunc i64 %436 to i32
  %541 = or i32 %540, 104
  %542 = add i32 %30, %541
  %543 = sext i32 %542 to i64
  %544 = getelementptr inbounds float, float* %4, i64 %543
  %545 = bitcast float* %544 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %545, align 4, !tbaa !8108
  %546 = getelementptr inbounds float, float* %544, i64 4
  %547 = bitcast float* %546 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %547, align 4, !tbaa !8108
  %548 = trunc i64 %436 to i32
  %549 = or i32 %548, 112
  %550 = add i32 %30, %549
  %551 = sext i32 %550 to i64
  %552 = getelementptr inbounds float, float* %4, i64 %551
  %553 = bitcast float* %552 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %553, align 4, !tbaa !8108
  %554 = getelementptr inbounds float, float* %552, i64 4
  %555 = bitcast float* %554 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %555, align 4, !tbaa !8108
  %556 = trunc i64 %436 to i32
  %557 = or i32 %556, 120
  %558 = add i32 %30, %557
  %559 = sext i32 %558 to i64
  %560 = getelementptr inbounds float, float* %4, i64 %559
  %561 = bitcast float* %560 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %561, align 4, !tbaa !8108
  %562 = getelementptr inbounds float, float* %560, i64 4
  %563 = bitcast float* %562 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %563, align 4, !tbaa !8108
  %indvars.iv.next16 = add nuw nsw i64 %indvars.iv15, 1
  %exitcond17 = icmp eq i64 %indvars.iv.next16, 30
  br i1 %exitcond17, label %for_end3, label %for_begin4.preheader, !prof !50

for_end3:                                         ; preds = %for_begin4.preheader, %for_end6.us
  %564 = add nsw i32 %27, 1
  %565 = icmp slt i32 %564, %15
  %indvar.next = add i64 %indvar, 1
  br i1 %565, label %for_begin1.preheader, label %for_end, !prof !5
}

define private i32 @__tvm_parallel_lambda.572(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to float**
  %18 = load float*, float** %17, align 8
  %19 = getelementptr inbounds i8, i8* %2, i64 40
  %20 = bitcast i8* %19 to i32*
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, 111
  %25 = sdiv i32 %24, %23
  %26 = add nsw i32 %0, 1
  %27 = mul nsw i32 %25, %26
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = mul nsw i32 %25, %0
  %31 = icmp slt i32 %30, 112
  %32 = select i1 %31, i32 %30, i32 112
  %33 = icmp slt i32 %32, %29
  br i1 %33, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %34 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %35 = bitcast float* %34 to <32 x float>*
  %36 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %37 = bitcast float* %36 to <32 x float>*
  %38 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %39 = bitcast float* %38 to <32 x float>*
  %40 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %41 = bitcast float* %40 to <32 x float>*
  %42 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %43 = bitcast float* %42 to <32 x float>*
  %44 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %45 = bitcast float* %44 to <32 x float>*
  %46 = add i32 %32, 1
  %47 = sext i32 %46 to i64
  %48 = add nsw i64 %47, -1
  %49 = sext i32 %29 to i64
  %50 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin13.preheader
  %indvars.iv68 = phi i64 [ %48, %for_body.lr.ph ], [ %indvars.iv.next69, %for_begin13.preheader ]
  %51 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %52 = tail call i8* %51(i32 1, i32 %21, i64 3584, i32 2, i32 32)
  %53 = trunc i64 %indvars.iv68 to i32
  %54 = srem i32 %53, 28
  %55 = sdiv i32 %53, 28
  %56 = mul nsw i32 %55, 36864
  %57 = sext i32 %56 to i64
  %58 = mul nsw i32 %54, 3840
  %59 = sext i32 %58 to i64
  %60 = mul nsw i32 %54, 3840
  %61 = add nsw i32 %60, 3840
  %62 = sext i32 %61 to i64
  %63 = add nsw i64 %57, 12288
  %64 = mul nsw i32 %54, 3840
  %65 = add nsw i32 %64, 7680
  %66 = sext i32 %65 to i64
  %67 = add nsw i64 %57, 24576
  br label %for_body2

for_end:                                          ; preds = %for_begin13.preheader, %entry
  ret i32 0

for_begin13.preheader:                            ; preds = %for_end9.2
  %68 = mul nsw i64 %indvars.iv68, 896
  %69 = shl nsw i32 %55, 5
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds float, float* %18, i64 %70
  %72 = bitcast float* %71 to <32 x float>*
  %73 = load <32 x float>, <32 x float>* %72, align 64, !tbaa !8115
  %74 = getelementptr inbounds float, float* %15, i64 %70
  %75 = bitcast float* %74 to <32 x float>*
  %76 = load <32 x float>, <32 x float>* %75, align 64, !tbaa !8118
  %77 = bitcast i8* %52 to <32 x float>*
  %78 = load <32 x float>, <32 x float>* %77, align 64, !tbaa !8121
  %79 = fadd <32 x float> %76, %78
  %80 = fadd <32 x float> %73, %79
  %81 = fcmp ogt <32 x float> %80, zeroinitializer
  %82 = select <32 x i1> %81, <32 x float> %80, <32 x float> zeroinitializer
  %83 = getelementptr inbounds float, float* %12, i64 %68
  %84 = bitcast float* %83 to <32 x float>*
  store <32 x float> %82, <32 x float>* %84, align 64, !tbaa !8124
  %85 = getelementptr inbounds i8, i8* %52, i64 128
  %86 = bitcast i8* %85 to <32 x float>*
  %87 = load <32 x float>, <32 x float>* %86, align 64, !tbaa !8121
  %88 = fadd <32 x float> %76, %87
  %89 = fadd <32 x float> %73, %88
  %90 = fcmp ogt <32 x float> %89, zeroinitializer
  %91 = select <32 x i1> %90, <32 x float> %89, <32 x float> zeroinitializer
  %92 = mul i64 %indvars.iv68, 3848290697216
  %sext = ashr exact i64 %92, 32
  %93 = or i64 %sext, 32
  %94 = getelementptr inbounds float, float* %12, i64 %93
  %95 = bitcast float* %94 to <32 x float>*
  store <32 x float> %91, <32 x float>* %95, align 64, !tbaa !8124
  %96 = getelementptr inbounds i8, i8* %52, i64 256
  %97 = bitcast i8* %96 to <32 x float>*
  %98 = load <32 x float>, <32 x float>* %97, align 64, !tbaa !8121
  %99 = fadd <32 x float> %76, %98
  %100 = fadd <32 x float> %73, %99
  %101 = fcmp ogt <32 x float> %100, zeroinitializer
  %102 = select <32 x i1> %101, <32 x float> %100, <32 x float> zeroinitializer
  %103 = mul i64 %indvars.iv68, 3848290697216
  %sext70 = ashr exact i64 %103, 32
  %104 = or i64 %sext70, 64
  %105 = getelementptr inbounds float, float* %12, i64 %104
  %106 = bitcast float* %105 to <32 x float>*
  store <32 x float> %102, <32 x float>* %106, align 64, !tbaa !8124
  %107 = getelementptr inbounds i8, i8* %52, i64 384
  %108 = bitcast i8* %107 to <32 x float>*
  %109 = load <32 x float>, <32 x float>* %108, align 64, !tbaa !8121
  %110 = fadd <32 x float> %76, %109
  %111 = fadd <32 x float> %73, %110
  %112 = fcmp ogt <32 x float> %111, zeroinitializer
  %113 = select <32 x i1> %112, <32 x float> %111, <32 x float> zeroinitializer
  %114 = mul i64 %indvars.iv68, 3848290697216
  %sext71 = ashr exact i64 %114, 32
  %115 = or i64 %sext71, 96
  %116 = getelementptr inbounds float, float* %12, i64 %115
  %117 = bitcast float* %116 to <32 x float>*
  store <32 x float> %113, <32 x float>* %117, align 64, !tbaa !8124
  %118 = getelementptr inbounds i8, i8* %52, i64 512
  %119 = bitcast i8* %118 to <32 x float>*
  %120 = load <32 x float>, <32 x float>* %119, align 64, !tbaa !8121
  %121 = fadd <32 x float> %76, %120
  %122 = fadd <32 x float> %73, %121
  %123 = fcmp ogt <32 x float> %122, zeroinitializer
  %124 = select <32 x i1> %123, <32 x float> %122, <32 x float> zeroinitializer
  %125 = mul i64 %indvars.iv68, 3848290697216
  %sext72 = add i64 %125, 549755813888
  %126 = ashr exact i64 %sext72, 32
  %127 = getelementptr inbounds float, float* %12, i64 %126
  %128 = bitcast float* %127 to <32 x float>*
  store <32 x float> %124, <32 x float>* %128, align 64, !tbaa !8124
  %129 = getelementptr inbounds i8, i8* %52, i64 640
  %130 = bitcast i8* %129 to <32 x float>*
  %131 = load <32 x float>, <32 x float>* %130, align 64, !tbaa !8121
  %132 = fadd <32 x float> %76, %131
  %133 = fadd <32 x float> %73, %132
  %134 = fcmp ogt <32 x float> %133, zeroinitializer
  %135 = select <32 x i1> %134, <32 x float> %133, <32 x float> zeroinitializer
  %136 = mul i64 %indvars.iv68, 3848290697216
  %sext73 = add i64 %136, 687194767360
  %137 = ashr exact i64 %sext73, 32
  %138 = getelementptr inbounds float, float* %12, i64 %137
  %139 = bitcast float* %138 to <32 x float>*
  store <32 x float> %135, <32 x float>* %139, align 64, !tbaa !8124
  %140 = getelementptr inbounds i8, i8* %52, i64 768
  %141 = bitcast i8* %140 to <32 x float>*
  %142 = load <32 x float>, <32 x float>* %141, align 64, !tbaa !8121
  %143 = fadd <32 x float> %76, %142
  %144 = fadd <32 x float> %73, %143
  %145 = fcmp ogt <32 x float> %144, zeroinitializer
  %146 = select <32 x i1> %145, <32 x float> %144, <32 x float> zeroinitializer
  %147 = mul i64 %indvars.iv68, 3848290697216
  %sext74 = add i64 %147, 824633720832
  %148 = ashr exact i64 %sext74, 32
  %149 = getelementptr inbounds float, float* %12, i64 %148
  %150 = bitcast float* %149 to <32 x float>*
  store <32 x float> %146, <32 x float>* %150, align 64, !tbaa !8124
  %151 = getelementptr inbounds i8, i8* %52, i64 896
  %152 = bitcast i8* %151 to <32 x float>*
  %153 = load <32 x float>, <32 x float>* %152, align 64, !tbaa !8121
  %154 = fadd <32 x float> %76, %153
  %155 = fadd <32 x float> %73, %154
  %156 = fcmp ogt <32 x float> %155, zeroinitializer
  %157 = select <32 x i1> %156, <32 x float> %155, <32 x float> zeroinitializer
  %158 = mul i64 %indvars.iv68, 3848290697216
  %sext75 = add i64 %158, 962072674304
  %159 = ashr exact i64 %sext75, 32
  %160 = getelementptr inbounds float, float* %12, i64 %159
  %161 = bitcast float* %160 to <32 x float>*
  store <32 x float> %157, <32 x float>* %161, align 64, !tbaa !8124
  %162 = getelementptr inbounds i8, i8* %52, i64 1024
  %163 = bitcast i8* %162 to <32 x float>*
  %164 = load <32 x float>, <32 x float>* %163, align 64, !tbaa !8121
  %165 = fadd <32 x float> %76, %164
  %166 = fadd <32 x float> %73, %165
  %167 = fcmp ogt <32 x float> %166, zeroinitializer
  %168 = select <32 x i1> %167, <32 x float> %166, <32 x float> zeroinitializer
  %169 = mul i64 %indvars.iv68, 3848290697216
  %sext76 = add i64 %169, 1099511627776
  %170 = ashr exact i64 %sext76, 32
  %171 = getelementptr inbounds float, float* %12, i64 %170
  %172 = bitcast float* %171 to <32 x float>*
  store <32 x float> %168, <32 x float>* %172, align 64, !tbaa !8124
  %173 = getelementptr inbounds i8, i8* %52, i64 1152
  %174 = bitcast i8* %173 to <32 x float>*
  %175 = load <32 x float>, <32 x float>* %174, align 64, !tbaa !8121
  %176 = fadd <32 x float> %76, %175
  %177 = fadd <32 x float> %73, %176
  %178 = fcmp ogt <32 x float> %177, zeroinitializer
  %179 = select <32 x i1> %178, <32 x float> %177, <32 x float> zeroinitializer
  %180 = mul i64 %indvars.iv68, 3848290697216
  %sext77 = add i64 %180, 1236950581248
  %181 = ashr exact i64 %sext77, 32
  %182 = getelementptr inbounds float, float* %12, i64 %181
  %183 = bitcast float* %182 to <32 x float>*
  store <32 x float> %179, <32 x float>* %183, align 64, !tbaa !8124
  %184 = getelementptr inbounds i8, i8* %52, i64 1280
  %185 = bitcast i8* %184 to <32 x float>*
  %186 = load <32 x float>, <32 x float>* %185, align 64, !tbaa !8121
  %187 = fadd <32 x float> %76, %186
  %188 = fadd <32 x float> %73, %187
  %189 = fcmp ogt <32 x float> %188, zeroinitializer
  %190 = select <32 x i1> %189, <32 x float> %188, <32 x float> zeroinitializer
  %191 = mul i64 %indvars.iv68, 3848290697216
  %sext78 = add i64 %191, 1374389534720
  %192 = ashr exact i64 %sext78, 32
  %193 = getelementptr inbounds float, float* %12, i64 %192
  %194 = bitcast float* %193 to <32 x float>*
  store <32 x float> %190, <32 x float>* %194, align 64, !tbaa !8124
  %195 = getelementptr inbounds i8, i8* %52, i64 1408
  %196 = bitcast i8* %195 to <32 x float>*
  %197 = load <32 x float>, <32 x float>* %196, align 64, !tbaa !8121
  %198 = fadd <32 x float> %76, %197
  %199 = fadd <32 x float> %73, %198
  %200 = fcmp ogt <32 x float> %199, zeroinitializer
  %201 = select <32 x i1> %200, <32 x float> %199, <32 x float> zeroinitializer
  %202 = mul i64 %indvars.iv68, 3848290697216
  %sext79 = add i64 %202, 1511828488192
  %203 = ashr exact i64 %sext79, 32
  %204 = getelementptr inbounds float, float* %12, i64 %203
  %205 = bitcast float* %204 to <32 x float>*
  store <32 x float> %201, <32 x float>* %205, align 64, !tbaa !8124
  %206 = getelementptr inbounds i8, i8* %52, i64 1536
  %207 = bitcast i8* %206 to <32 x float>*
  %208 = load <32 x float>, <32 x float>* %207, align 64, !tbaa !8121
  %209 = fadd <32 x float> %76, %208
  %210 = fadd <32 x float> %73, %209
  %211 = fcmp ogt <32 x float> %210, zeroinitializer
  %212 = select <32 x i1> %211, <32 x float> %210, <32 x float> zeroinitializer
  %213 = mul i64 %indvars.iv68, 3848290697216
  %sext80 = add i64 %213, 1649267441664
  %214 = ashr exact i64 %sext80, 32
  %215 = getelementptr inbounds float, float* %12, i64 %214
  %216 = bitcast float* %215 to <32 x float>*
  store <32 x float> %212, <32 x float>* %216, align 64, !tbaa !8124
  %217 = getelementptr inbounds i8, i8* %52, i64 1664
  %218 = bitcast i8* %217 to <32 x float>*
  %219 = load <32 x float>, <32 x float>* %218, align 64, !tbaa !8121
  %220 = fadd <32 x float> %76, %219
  %221 = fadd <32 x float> %73, %220
  %222 = fcmp ogt <32 x float> %221, zeroinitializer
  %223 = select <32 x i1> %222, <32 x float> %221, <32 x float> zeroinitializer
  %224 = mul i64 %indvars.iv68, 3848290697216
  %sext81 = add i64 %224, 1786706395136
  %225 = ashr exact i64 %sext81, 32
  %226 = getelementptr inbounds float, float* %12, i64 %225
  %227 = bitcast float* %226 to <32 x float>*
  store <32 x float> %223, <32 x float>* %227, align 64, !tbaa !8124
  %228 = getelementptr inbounds i8, i8* %52, i64 1792
  %229 = bitcast i8* %228 to <32 x float>*
  %230 = load <32 x float>, <32 x float>* %229, align 64, !tbaa !8121
  %231 = fadd <32 x float> %76, %230
  %232 = fadd <32 x float> %73, %231
  %233 = fcmp ogt <32 x float> %232, zeroinitializer
  %234 = select <32 x i1> %233, <32 x float> %232, <32 x float> zeroinitializer
  %235 = mul i64 %indvars.iv68, 3848290697216
  %sext82 = add i64 %235, 1924145348608
  %236 = ashr exact i64 %sext82, 32
  %237 = getelementptr inbounds float, float* %12, i64 %236
  %238 = bitcast float* %237 to <32 x float>*
  store <32 x float> %234, <32 x float>* %238, align 64, !tbaa !8124
  %239 = getelementptr inbounds i8, i8* %52, i64 1920
  %240 = bitcast i8* %239 to <32 x float>*
  %241 = load <32 x float>, <32 x float>* %240, align 64, !tbaa !8121
  %242 = fadd <32 x float> %76, %241
  %243 = fadd <32 x float> %73, %242
  %244 = fcmp ogt <32 x float> %243, zeroinitializer
  %245 = select <32 x i1> %244, <32 x float> %243, <32 x float> zeroinitializer
  %246 = mul i64 %indvars.iv68, 3848290697216
  %sext83 = add i64 %246, 2061584302080
  %247 = ashr exact i64 %sext83, 32
  %248 = getelementptr inbounds float, float* %12, i64 %247
  %249 = bitcast float* %248 to <32 x float>*
  store <32 x float> %245, <32 x float>* %249, align 64, !tbaa !8124
  %250 = getelementptr inbounds i8, i8* %52, i64 2048
  %251 = bitcast i8* %250 to <32 x float>*
  %252 = load <32 x float>, <32 x float>* %251, align 64, !tbaa !8121
  %253 = fadd <32 x float> %76, %252
  %254 = fadd <32 x float> %73, %253
  %255 = fcmp ogt <32 x float> %254, zeroinitializer
  %256 = select <32 x i1> %255, <32 x float> %254, <32 x float> zeroinitializer
  %257 = mul i64 %indvars.iv68, 3848290697216
  %sext84 = add i64 %257, 2199023255552
  %258 = ashr exact i64 %sext84, 32
  %259 = getelementptr inbounds float, float* %12, i64 %258
  %260 = bitcast float* %259 to <32 x float>*
  store <32 x float> %256, <32 x float>* %260, align 64, !tbaa !8124
  %261 = getelementptr inbounds i8, i8* %52, i64 2176
  %262 = bitcast i8* %261 to <32 x float>*
  %263 = load <32 x float>, <32 x float>* %262, align 64, !tbaa !8121
  %264 = fadd <32 x float> %76, %263
  %265 = fadd <32 x float> %73, %264
  %266 = fcmp ogt <32 x float> %265, zeroinitializer
  %267 = select <32 x i1> %266, <32 x float> %265, <32 x float> zeroinitializer
  %268 = mul i64 %indvars.iv68, 3848290697216
  %sext85 = add i64 %268, 2336462209024
  %269 = ashr exact i64 %sext85, 32
  %270 = getelementptr inbounds float, float* %12, i64 %269
  %271 = bitcast float* %270 to <32 x float>*
  store <32 x float> %267, <32 x float>* %271, align 64, !tbaa !8124
  %272 = getelementptr inbounds i8, i8* %52, i64 2304
  %273 = bitcast i8* %272 to <32 x float>*
  %274 = load <32 x float>, <32 x float>* %273, align 64, !tbaa !8121
  %275 = fadd <32 x float> %76, %274
  %276 = fadd <32 x float> %73, %275
  %277 = fcmp ogt <32 x float> %276, zeroinitializer
  %278 = select <32 x i1> %277, <32 x float> %276, <32 x float> zeroinitializer
  %279 = mul i64 %indvars.iv68, 3848290697216
  %sext86 = add i64 %279, 2473901162496
  %280 = ashr exact i64 %sext86, 32
  %281 = getelementptr inbounds float, float* %12, i64 %280
  %282 = bitcast float* %281 to <32 x float>*
  store <32 x float> %278, <32 x float>* %282, align 64, !tbaa !8124
  %283 = getelementptr inbounds i8, i8* %52, i64 2432
  %284 = bitcast i8* %283 to <32 x float>*
  %285 = load <32 x float>, <32 x float>* %284, align 64, !tbaa !8121
  %286 = fadd <32 x float> %76, %285
  %287 = fadd <32 x float> %73, %286
  %288 = fcmp ogt <32 x float> %287, zeroinitializer
  %289 = select <32 x i1> %288, <32 x float> %287, <32 x float> zeroinitializer
  %290 = mul i64 %indvars.iv68, 3848290697216
  %sext87 = add i64 %290, 2611340115968
  %291 = ashr exact i64 %sext87, 32
  %292 = getelementptr inbounds float, float* %12, i64 %291
  %293 = bitcast float* %292 to <32 x float>*
  store <32 x float> %289, <32 x float>* %293, align 64, !tbaa !8124
  %294 = getelementptr inbounds i8, i8* %52, i64 2560
  %295 = bitcast i8* %294 to <32 x float>*
  %296 = load <32 x float>, <32 x float>* %295, align 64, !tbaa !8121
  %297 = fadd <32 x float> %76, %296
  %298 = fadd <32 x float> %73, %297
  %299 = fcmp ogt <32 x float> %298, zeroinitializer
  %300 = select <32 x i1> %299, <32 x float> %298, <32 x float> zeroinitializer
  %301 = mul i64 %indvars.iv68, 3848290697216
  %sext88 = add i64 %301, 2748779069440
  %302 = ashr exact i64 %sext88, 32
  %303 = getelementptr inbounds float, float* %12, i64 %302
  %304 = bitcast float* %303 to <32 x float>*
  store <32 x float> %300, <32 x float>* %304, align 64, !tbaa !8124
  %305 = getelementptr inbounds i8, i8* %52, i64 2688
  %306 = bitcast i8* %305 to <32 x float>*
  %307 = load <32 x float>, <32 x float>* %306, align 64, !tbaa !8121
  %308 = fadd <32 x float> %76, %307
  %309 = fadd <32 x float> %73, %308
  %310 = fcmp ogt <32 x float> %309, zeroinitializer
  %311 = select <32 x i1> %310, <32 x float> %309, <32 x float> zeroinitializer
  %312 = mul i64 %indvars.iv68, 3848290697216
  %sext89 = add i64 %312, 2886218022912
  %313 = ashr exact i64 %sext89, 32
  %314 = getelementptr inbounds float, float* %12, i64 %313
  %315 = bitcast float* %314 to <32 x float>*
  store <32 x float> %311, <32 x float>* %315, align 64, !tbaa !8124
  %316 = getelementptr inbounds i8, i8* %52, i64 2816
  %317 = bitcast i8* %316 to <32 x float>*
  %318 = load <32 x float>, <32 x float>* %317, align 64, !tbaa !8121
  %319 = fadd <32 x float> %76, %318
  %320 = fadd <32 x float> %73, %319
  %321 = fcmp ogt <32 x float> %320, zeroinitializer
  %322 = select <32 x i1> %321, <32 x float> %320, <32 x float> zeroinitializer
  %323 = mul i64 %indvars.iv68, 3848290697216
  %sext90 = add i64 %323, 3023656976384
  %324 = ashr exact i64 %sext90, 32
  %325 = getelementptr inbounds float, float* %12, i64 %324
  %326 = bitcast float* %325 to <32 x float>*
  store <32 x float> %322, <32 x float>* %326, align 64, !tbaa !8124
  %327 = getelementptr inbounds i8, i8* %52, i64 2944
  %328 = bitcast i8* %327 to <32 x float>*
  %329 = load <32 x float>, <32 x float>* %328, align 64, !tbaa !8121
  %330 = fadd <32 x float> %76, %329
  %331 = fadd <32 x float> %73, %330
  %332 = fcmp ogt <32 x float> %331, zeroinitializer
  %333 = select <32 x i1> %332, <32 x float> %331, <32 x float> zeroinitializer
  %334 = mul i64 %indvars.iv68, 3848290697216
  %sext91 = add i64 %334, 3161095929856
  %335 = ashr exact i64 %sext91, 32
  %336 = getelementptr inbounds float, float* %12, i64 %335
  %337 = bitcast float* %336 to <32 x float>*
  store <32 x float> %333, <32 x float>* %337, align 64, !tbaa !8124
  %338 = getelementptr inbounds i8, i8* %52, i64 3072
  %339 = bitcast i8* %338 to <32 x float>*
  %340 = load <32 x float>, <32 x float>* %339, align 64, !tbaa !8121
  %341 = fadd <32 x float> %76, %340
  %342 = fadd <32 x float> %73, %341
  %343 = fcmp ogt <32 x float> %342, zeroinitializer
  %344 = select <32 x i1> %343, <32 x float> %342, <32 x float> zeroinitializer
  %345 = mul i64 %indvars.iv68, 3848290697216
  %sext92 = add i64 %345, 3298534883328
  %346 = ashr exact i64 %sext92, 32
  %347 = getelementptr inbounds float, float* %12, i64 %346
  %348 = bitcast float* %347 to <32 x float>*
  store <32 x float> %344, <32 x float>* %348, align 64, !tbaa !8124
  %349 = getelementptr inbounds i8, i8* %52, i64 3200
  %350 = bitcast i8* %349 to <32 x float>*
  %351 = load <32 x float>, <32 x float>* %350, align 64, !tbaa !8121
  %352 = fadd <32 x float> %76, %351
  %353 = fadd <32 x float> %73, %352
  %354 = fcmp ogt <32 x float> %353, zeroinitializer
  %355 = select <32 x i1> %354, <32 x float> %353, <32 x float> zeroinitializer
  %356 = mul i64 %indvars.iv68, 3848290697216
  %sext93 = add i64 %356, 3435973836800
  %357 = ashr exact i64 %sext93, 32
  %358 = getelementptr inbounds float, float* %12, i64 %357
  %359 = bitcast float* %358 to <32 x float>*
  store <32 x float> %355, <32 x float>* %359, align 64, !tbaa !8124
  %360 = getelementptr inbounds i8, i8* %52, i64 3328
  %361 = bitcast i8* %360 to <32 x float>*
  %362 = load <32 x float>, <32 x float>* %361, align 64, !tbaa !8121
  %363 = fadd <32 x float> %76, %362
  %364 = fadd <32 x float> %73, %363
  %365 = fcmp ogt <32 x float> %364, zeroinitializer
  %366 = select <32 x i1> %365, <32 x float> %364, <32 x float> zeroinitializer
  %367 = mul i64 %indvars.iv68, 3848290697216
  %sext94 = add i64 %367, 3573412790272
  %368 = ashr exact i64 %sext94, 32
  %369 = getelementptr inbounds float, float* %12, i64 %368
  %370 = bitcast float* %369 to <32 x float>*
  store <32 x float> %366, <32 x float>* %370, align 64, !tbaa !8124
  %371 = getelementptr inbounds i8, i8* %52, i64 3456
  %372 = bitcast i8* %371 to <32 x float>*
  %373 = load <32 x float>, <32 x float>* %372, align 64, !tbaa !8121
  %374 = fadd <32 x float> %76, %373
  %375 = fadd <32 x float> %73, %374
  %376 = fcmp ogt <32 x float> %375, zeroinitializer
  %377 = select <32 x i1> %376, <32 x float> %375, <32 x float> zeroinitializer
  %378 = mul i64 %indvars.iv68, 3848290697216
  %sext95 = add i64 %378, 3710851743744
  %379 = ashr exact i64 %sext95, 32
  %380 = getelementptr inbounds float, float* %12, i64 %379
  %381 = bitcast float* %380 to <32 x float>*
  store <32 x float> %377, <32 x float>* %381, align 64, !tbaa !8124
  %382 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %383 = tail call i32 %382(i32 1, i32 %21, i8* nonnull %52)
  %indvars.iv.next69 = add nsw i64 %indvars.iv68, 1
  %384 = icmp slt i64 %indvars.iv.next69, %49
  br i1 %384, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %385 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %52, i64 %385
  %386 = add nsw i64 %385, %59
  call void @llvm.memset.p0i8.i64(i8* nonnull align 128 %50, i8 0, i64 896, i1 false)
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %387 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %472, %for_body8 ]
  %388 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %466, %for_body8 ]
  %389 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %465, %for_body8 ]
  %390 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %464, %for_body8 ]
  %391 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %463, %for_body8 ]
  %392 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %462, %for_body8 ]
  %393 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %461, %for_body8 ]
  %394 = add nsw i64 %386, %indvars.iv
  %395 = getelementptr inbounds float, float* %6, i64 %394
  %396 = load float, float* %395, align 4, !tbaa !8108
  %397 = insertelement <32 x float> undef, float %396, i32 0
  %398 = shufflevector <32 x float> %397, <32 x float> undef, <32 x i32> zeroinitializer
  %399 = shl nsw i64 %indvars.iv, 5
  %400 = add nsw i64 %399, %57
  %401 = getelementptr inbounds float, float* %9, i64 %400
  %402 = bitcast float* %401 to <32 x float>*
  %403 = load <32 x float>, <32 x float>* %402, align 64, !tbaa !8127
  %404 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %398, <32 x float> %403, <32 x float> %393)
  %405 = add nsw i64 %394, 128
  %406 = getelementptr inbounds float, float* %6, i64 %405
  %407 = load float, float* %406, align 4, !tbaa !8108
  %408 = insertelement <32 x float> undef, float %407, i32 0
  %409 = shufflevector <32 x float> %408, <32 x float> undef, <32 x i32> zeroinitializer
  %410 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %409, <32 x float> %403, <32 x float> %392)
  %411 = add nsw i64 %394, 256
  %412 = getelementptr inbounds float, float* %6, i64 %411
  %413 = load float, float* %412, align 4, !tbaa !8108
  %414 = insertelement <32 x float> undef, float %413, i32 0
  %415 = shufflevector <32 x float> %414, <32 x float> undef, <32 x i32> zeroinitializer
  %416 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %415, <32 x float> %403, <32 x float> %391)
  %417 = add nsw i64 %394, 384
  %418 = getelementptr inbounds float, float* %6, i64 %417
  %419 = load float, float* %418, align 4, !tbaa !8108
  %420 = insertelement <32 x float> undef, float %419, i32 0
  %421 = shufflevector <32 x float> %420, <32 x float> undef, <32 x i32> zeroinitializer
  %422 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %403, <32 x float> %390)
  %423 = add nsw i64 %394, 512
  %424 = getelementptr inbounds float, float* %6, i64 %423
  %425 = load float, float* %424, align 4, !tbaa !8108
  %426 = insertelement <32 x float> undef, float %425, i32 0
  %427 = shufflevector <32 x float> %426, <32 x float> undef, <32 x i32> zeroinitializer
  %428 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %427, <32 x float> %403, <32 x float> %389)
  %429 = add nsw i64 %394, 640
  %430 = getelementptr inbounds float, float* %6, i64 %429
  %431 = load float, float* %430, align 4, !tbaa !8108
  %432 = insertelement <32 x float> undef, float %431, i32 0
  %433 = shufflevector <32 x float> %432, <32 x float> undef, <32 x i32> zeroinitializer
  %434 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %433, <32 x float> %403, <32 x float> %388)
  %435 = add nsw i64 %394, 768
  %436 = getelementptr inbounds float, float* %6, i64 %435
  %437 = load float, float* %436, align 4, !tbaa !8108
  %438 = insertelement <32 x float> undef, float %437, i32 0
  %439 = shufflevector <32 x float> %438, <32 x float> undef, <32 x i32> zeroinitializer
  %440 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %439, <32 x float> %403, <32 x float> %387)
  %441 = add nsw i64 %400, 4096
  %442 = getelementptr inbounds float, float* %9, i64 %441
  %443 = bitcast float* %442 to <32 x float>*
  %444 = load <32 x float>, <32 x float>* %443, align 64, !tbaa !8127
  %445 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %409, <32 x float> %444, <32 x float> %404)
  %446 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %415, <32 x float> %444, <32 x float> %410)
  %447 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %444, <32 x float> %416)
  %448 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %427, <32 x float> %444, <32 x float> %422)
  %449 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %433, <32 x float> %444, <32 x float> %428)
  %450 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %439, <32 x float> %444, <32 x float> %434)
  %451 = add nsw i64 %394, 896
  %452 = getelementptr inbounds float, float* %6, i64 %451
  %453 = load float, float* %452, align 4, !tbaa !8108
  %454 = insertelement <32 x float> undef, float %453, i32 0
  %455 = shufflevector <32 x float> %454, <32 x float> undef, <32 x i32> zeroinitializer
  %456 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %455, <32 x float> %444, <32 x float> %440)
  %457 = add nsw i64 %400, 8192
  %458 = getelementptr inbounds float, float* %9, i64 %457
  %459 = bitcast float* %458 to <32 x float>*
  %460 = load <32 x float>, <32 x float>* %459, align 64, !tbaa !8127
  %461 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %415, <32 x float> %460, <32 x float> %445)
  %462 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %460, <32 x float> %446)
  %463 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %427, <32 x float> %460, <32 x float> %447)
  %464 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %433, <32 x float> %460, <32 x float> %448)
  %465 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %439, <32 x float> %460, <32 x float> %449)
  %466 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %455, <32 x float> %460, <32 x float> %450)
  %467 = add nsw i64 %394, 1024
  %468 = getelementptr inbounds float, float* %6, i64 %467
  %469 = load float, float* %468, align 4, !tbaa !8108
  %470 = insertelement <32 x float> undef, float %469, i32 0
  %471 = shufflevector <32 x float> %470, <32 x float> undef, <32 x i32> zeroinitializer
  %472 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %471, <32 x float> %460, <32 x float> %456)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %473 = add nsw i64 %385, %62
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %474 = phi <32 x float> [ %472, %for_end9 ], [ %559, %for_body8.1 ]
  %475 = phi <32 x float> [ %466, %for_end9 ], [ %553, %for_body8.1 ]
  %476 = phi <32 x float> [ %465, %for_end9 ], [ %552, %for_body8.1 ]
  %477 = phi <32 x float> [ %464, %for_end9 ], [ %551, %for_body8.1 ]
  %478 = phi <32 x float> [ %463, %for_end9 ], [ %550, %for_body8.1 ]
  %479 = phi <32 x float> [ %462, %for_end9 ], [ %549, %for_body8.1 ]
  %480 = phi <32 x float> [ %461, %for_end9 ], [ %548, %for_body8.1 ]
  %481 = add nsw i64 %473, %indvars.iv.1
  %482 = getelementptr inbounds float, float* %6, i64 %481
  %483 = load float, float* %482, align 4, !tbaa !8108
  %484 = insertelement <32 x float> undef, float %483, i32 0
  %485 = shufflevector <32 x float> %484, <32 x float> undef, <32 x i32> zeroinitializer
  %486 = shl nsw i64 %indvars.iv.1, 5
  %487 = add nsw i64 %63, %486
  %488 = getelementptr inbounds float, float* %9, i64 %487
  %489 = bitcast float* %488 to <32 x float>*
  %490 = load <32 x float>, <32 x float>* %489, align 64, !tbaa !8127
  %491 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %485, <32 x float> %490, <32 x float> %480)
  %492 = add nsw i64 %481, 128
  %493 = getelementptr inbounds float, float* %6, i64 %492
  %494 = load float, float* %493, align 4, !tbaa !8108
  %495 = insertelement <32 x float> undef, float %494, i32 0
  %496 = shufflevector <32 x float> %495, <32 x float> undef, <32 x i32> zeroinitializer
  %497 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %496, <32 x float> %490, <32 x float> %479)
  %498 = add nsw i64 %481, 256
  %499 = getelementptr inbounds float, float* %6, i64 %498
  %500 = load float, float* %499, align 4, !tbaa !8108
  %501 = insertelement <32 x float> undef, float %500, i32 0
  %502 = shufflevector <32 x float> %501, <32 x float> undef, <32 x i32> zeroinitializer
  %503 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %502, <32 x float> %490, <32 x float> %478)
  %504 = add nsw i64 %481, 384
  %505 = getelementptr inbounds float, float* %6, i64 %504
  %506 = load float, float* %505, align 4, !tbaa !8108
  %507 = insertelement <32 x float> undef, float %506, i32 0
  %508 = shufflevector <32 x float> %507, <32 x float> undef, <32 x i32> zeroinitializer
  %509 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %490, <32 x float> %477)
  %510 = add nsw i64 %481, 512
  %511 = getelementptr inbounds float, float* %6, i64 %510
  %512 = load float, float* %511, align 4, !tbaa !8108
  %513 = insertelement <32 x float> undef, float %512, i32 0
  %514 = shufflevector <32 x float> %513, <32 x float> undef, <32 x i32> zeroinitializer
  %515 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %490, <32 x float> %476)
  %516 = add nsw i64 %481, 640
  %517 = getelementptr inbounds float, float* %6, i64 %516
  %518 = load float, float* %517, align 4, !tbaa !8108
  %519 = insertelement <32 x float> undef, float %518, i32 0
  %520 = shufflevector <32 x float> %519, <32 x float> undef, <32 x i32> zeroinitializer
  %521 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %490, <32 x float> %475)
  %522 = add nsw i64 %481, 768
  %523 = getelementptr inbounds float, float* %6, i64 %522
  %524 = load float, float* %523, align 4, !tbaa !8108
  %525 = insertelement <32 x float> undef, float %524, i32 0
  %526 = shufflevector <32 x float> %525, <32 x float> undef, <32 x i32> zeroinitializer
  %527 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %526, <32 x float> %490, <32 x float> %474)
  %528 = add nsw i64 %487, 4096
  %529 = getelementptr inbounds float, float* %9, i64 %528
  %530 = bitcast float* %529 to <32 x float>*
  %531 = load <32 x float>, <32 x float>* %530, align 64, !tbaa !8127
  %532 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %496, <32 x float> %531, <32 x float> %491)
  %533 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %502, <32 x float> %531, <32 x float> %497)
  %534 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %531, <32 x float> %503)
  %535 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %531, <32 x float> %509)
  %536 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %531, <32 x float> %515)
  %537 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %526, <32 x float> %531, <32 x float> %521)
  %538 = add nsw i64 %481, 896
  %539 = getelementptr inbounds float, float* %6, i64 %538
  %540 = load float, float* %539, align 4, !tbaa !8108
  %541 = insertelement <32 x float> undef, float %540, i32 0
  %542 = shufflevector <32 x float> %541, <32 x float> undef, <32 x i32> zeroinitializer
  %543 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %542, <32 x float> %531, <32 x float> %527)
  %544 = add nsw i64 %487, 8192
  %545 = getelementptr inbounds float, float* %9, i64 %544
  %546 = bitcast float* %545 to <32 x float>*
  %547 = load <32 x float>, <32 x float>* %546, align 64, !tbaa !8127
  %548 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %502, <32 x float> %547, <32 x float> %532)
  %549 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %547, <32 x float> %533)
  %550 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %547, <32 x float> %534)
  %551 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %547, <32 x float> %535)
  %552 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %526, <32 x float> %547, <32 x float> %536)
  %553 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %542, <32 x float> %547, <32 x float> %537)
  %554 = add nsw i64 %481, 1024
  %555 = getelementptr inbounds float, float* %6, i64 %554
  %556 = load float, float* %555, align 4, !tbaa !8108
  %557 = insertelement <32 x float> undef, float %556, i32 0
  %558 = shufflevector <32 x float> %557, <32 x float> undef, <32 x i32> zeroinitializer
  %559 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %558, <32 x float> %547, <32 x float> %543)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %560 = add nsw i64 %385, %66
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %561 = phi <32 x float> [ %559, %for_end9.1 ], [ %646, %for_body8.2 ]
  %562 = phi <32 x float> [ %553, %for_end9.1 ], [ %640, %for_body8.2 ]
  %563 = phi <32 x float> [ %552, %for_end9.1 ], [ %639, %for_body8.2 ]
  %564 = phi <32 x float> [ %551, %for_end9.1 ], [ %638, %for_body8.2 ]
  %565 = phi <32 x float> [ %550, %for_end9.1 ], [ %637, %for_body8.2 ]
  %566 = phi <32 x float> [ %549, %for_end9.1 ], [ %636, %for_body8.2 ]
  %567 = phi <32 x float> [ %548, %for_end9.1 ], [ %635, %for_body8.2 ]
  %568 = add nsw i64 %560, %indvars.iv.2
  %569 = getelementptr inbounds float, float* %6, i64 %568
  %570 = load float, float* %569, align 4, !tbaa !8108
  %571 = insertelement <32 x float> undef, float %570, i32 0
  %572 = shufflevector <32 x float> %571, <32 x float> undef, <32 x i32> zeroinitializer
  %573 = shl nsw i64 %indvars.iv.2, 5
  %574 = add nsw i64 %67, %573
  %575 = getelementptr inbounds float, float* %9, i64 %574
  %576 = bitcast float* %575 to <32 x float>*
  %577 = load <32 x float>, <32 x float>* %576, align 64, !tbaa !8127
  %578 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %572, <32 x float> %577, <32 x float> %567)
  %579 = add nsw i64 %568, 128
  %580 = getelementptr inbounds float, float* %6, i64 %579
  %581 = load float, float* %580, align 4, !tbaa !8108
  %582 = insertelement <32 x float> undef, float %581, i32 0
  %583 = shufflevector <32 x float> %582, <32 x float> undef, <32 x i32> zeroinitializer
  %584 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %583, <32 x float> %577, <32 x float> %566)
  %585 = add nsw i64 %568, 256
  %586 = getelementptr inbounds float, float* %6, i64 %585
  %587 = load float, float* %586, align 4, !tbaa !8108
  %588 = insertelement <32 x float> undef, float %587, i32 0
  %589 = shufflevector <32 x float> %588, <32 x float> undef, <32 x i32> zeroinitializer
  %590 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %589, <32 x float> %577, <32 x float> %565)
  %591 = add nsw i64 %568, 384
  %592 = getelementptr inbounds float, float* %6, i64 %591
  %593 = load float, float* %592, align 4, !tbaa !8108
  %594 = insertelement <32 x float> undef, float %593, i32 0
  %595 = shufflevector <32 x float> %594, <32 x float> undef, <32 x i32> zeroinitializer
  %596 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %577, <32 x float> %564)
  %597 = add nsw i64 %568, 512
  %598 = getelementptr inbounds float, float* %6, i64 %597
  %599 = load float, float* %598, align 4, !tbaa !8108
  %600 = insertelement <32 x float> undef, float %599, i32 0
  %601 = shufflevector <32 x float> %600, <32 x float> undef, <32 x i32> zeroinitializer
  %602 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %601, <32 x float> %577, <32 x float> %563)
  %603 = add nsw i64 %568, 640
  %604 = getelementptr inbounds float, float* %6, i64 %603
  %605 = load float, float* %604, align 4, !tbaa !8108
  %606 = insertelement <32 x float> undef, float %605, i32 0
  %607 = shufflevector <32 x float> %606, <32 x float> undef, <32 x i32> zeroinitializer
  %608 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %607, <32 x float> %577, <32 x float> %562)
  %609 = add nsw i64 %568, 768
  %610 = getelementptr inbounds float, float* %6, i64 %609
  %611 = load float, float* %610, align 4, !tbaa !8108
  %612 = insertelement <32 x float> undef, float %611, i32 0
  %613 = shufflevector <32 x float> %612, <32 x float> undef, <32 x i32> zeroinitializer
  %614 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %613, <32 x float> %577, <32 x float> %561)
  %615 = add nsw i64 %574, 4096
  %616 = getelementptr inbounds float, float* %9, i64 %615
  %617 = bitcast float* %616 to <32 x float>*
  %618 = load <32 x float>, <32 x float>* %617, align 64, !tbaa !8127
  %619 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %583, <32 x float> %618, <32 x float> %578)
  %620 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %589, <32 x float> %618, <32 x float> %584)
  %621 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %618, <32 x float> %590)
  %622 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %601, <32 x float> %618, <32 x float> %596)
  %623 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %607, <32 x float> %618, <32 x float> %602)
  %624 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %613, <32 x float> %618, <32 x float> %608)
  %625 = add nsw i64 %568, 896
  %626 = getelementptr inbounds float, float* %6, i64 %625
  %627 = load float, float* %626, align 4, !tbaa !8108
  %628 = insertelement <32 x float> undef, float %627, i32 0
  %629 = shufflevector <32 x float> %628, <32 x float> undef, <32 x i32> zeroinitializer
  %630 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %629, <32 x float> %618, <32 x float> %614)
  %631 = add nsw i64 %574, 8192
  %632 = getelementptr inbounds float, float* %9, i64 %631
  %633 = bitcast float* %632 to <32 x float>*
  %634 = load <32 x float>, <32 x float>* %633, align 64, !tbaa !8127
  %635 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %589, <32 x float> %634, <32 x float> %619)
  %636 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %634, <32 x float> %620)
  %637 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %601, <32 x float> %634, <32 x float> %621)
  %638 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %607, <32 x float> %634, <32 x float> %622)
  %639 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %613, <32 x float> %634, <32 x float> %623)
  %640 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %629, <32 x float> %634, <32 x float> %624)
  %641 = add nsw i64 %568, 1024
  %642 = getelementptr inbounds float, float* %6, i64 %641
  %643 = load float, float* %642, align 4, !tbaa !8108
  %644 = insertelement <32 x float> undef, float %643, i32 0
  %645 = shufflevector <32 x float> %644, <32 x float> undef, <32 x i32> zeroinitializer
  %646 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %645, <32 x float> %634, <32 x float> %630)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 128
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %635, <32 x float>* %.sub, align 128, !tbaa !8130
  store <32 x float> %636, <32 x float>* %35, align 128, !tbaa !8130
  store <32 x float> %637, <32 x float>* %37, align 128, !tbaa !8130
  store <32 x float> %638, <32 x float>* %39, align 128, !tbaa !8130
  store <32 x float> %639, <32 x float>* %41, align 128, !tbaa !8130
  store <32 x float> %640, <32 x float>* %43, align 128, !tbaa !8130
  store <32 x float> %646, <32 x float>* %45, align 128, !tbaa !8130
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %scevgep, i8* nonnull align 128 %4, i64 896, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond61 = icmp eq i64 %indvar.next, 4
  br i1 %exitcond61, label %for_begin13.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_layout_transform_40(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32) local_unnamed_addr {
entry:
  %3 = icmp eq i32 %2, 2
  br i1 %3, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %4 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %4(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.573, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %5 = bitcast i8* %0 to %1**
  %6 = load %1*, %1** %5, align 8
  %7 = bitcast i8* %1 to i32*
  %8 = load i32, i32* %7, align 4, !tbaa !8139
  %9 = getelementptr inbounds i8, i8* %0, i64 8
  %10 = bitcast i8* %9 to %1**
  %11 = load %1*, %1** %10, align 8
  %12 = getelementptr inbounds %1, %1* %6, i64 0, i32 0
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds %1, %1* %6, i64 0, i32 4
  %15 = load i64*, i64** %14, align 8
  %16 = getelementptr inbounds %1, %1* %6, i64 0, i32 5
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %1, %1* %6, i64 0, i32 1, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %11, i64 0, i32 0
  %23 = load i8*, i8** %22, align 8
  %24 = getelementptr inbounds %1, %1* %11, i64 0, i32 4
  %25 = load i64*, i64** %24, align 8
  %26 = getelementptr inbounds %1, %1* %11, i64 0, i32 5
  %27 = load i64*, i64** %26, align 8
  switch i32 %8, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %28 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %28(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.574, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %29 = getelementptr inbounds i8, i8* %1, i64 4
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !8153
  switch i32 %31, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %32 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %32(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.575, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %33 = icmp eq i32 %19, 1
  br i1 %33, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %35 = getelementptr inbounds %1, %1* %6, i64 0, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 5
  br i1 %37, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %38 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %38(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %39 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 2
  %40 = load i16, i16* %39, align 2
  %41 = icmp eq i16 %40, 1
  %42 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 1
  %43 = load i8, i8* %42, align 1
  %44 = icmp eq i8 %43, 32
  %45 = getelementptr inbounds %1, %1* %6, i64 0, i32 3, i32 0
  %46 = load i8, i8* %45, align 1
  %47 = icmp eq i8 %46, 2
  %48 = and i1 %44, %47
  %49 = and i1 %41, %48
  br i1 %49, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %50 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %50(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %51 = load i64, i64* %15, align 8, !tbaa !8155
  %52 = trunc i64 %51 to i32
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %55 = getelementptr inbounds i64, i64* %15, i64 1
  %56 = load i64, i64* %55, align 8, !tbaa !8169
  %57 = trunc i64 %56 to i32
  %58 = icmp eq i32 %57, 2
  br i1 %58, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.122, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %60 = getelementptr inbounds i64, i64* %15, i64 2
  %61 = load i64, i64* %60, align 8, !tbaa !8171
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %62, 28
  br i1 %63, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %64 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %64(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %65 = getelementptr inbounds i64, i64* %15, i64 3
  %66 = load i64, i64* %65, align 8, !tbaa !8174
  %67 = trunc i64 %66 to i32
  %68 = icmp eq i32 %67, 28
  br i1 %68, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %69 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %69(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %70 = getelementptr inbounds i64, i64* %15, i64 4
  %71 = load i64, i64* %70, align 8, !tbaa !8176
  %72 = trunc i64 %71 to i32
  %73 = icmp eq i32 %72, 64
  br i1 %73, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %74 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %74(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %75 = icmp eq i64* %17, null
  br i1 %75, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %76 = bitcast i64* %17 to <4 x i64>*
  %77 = load <4 x i64>, <4 x i64>* %76, align 8, !tbaa !8180
  %78 = trunc <4 x i64> %77 to <4 x i32>
  %79 = icmp eq <4 x i32> %78, <i32 100352, i32 50176, i32 1792, i32 64>
  %80 = getelementptr inbounds i64, i64* %17, i64 4
  %81 = load i64, i64* %80, align 8, !tbaa !8192
  %82 = trunc i64 %81 to i32
  %83 = icmp eq i32 %82, 1
  %rdx.shuf51 = shufflevector <4 x i1> %79, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %79, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %84 = extractelement <4 x i1> %bin.rdx54, i32 0
  %85 = and i1 %84, %83
  br i1 %85, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %86 = getelementptr inbounds %1, %1* %6, i64 0, i32 6
  %87 = load i64, i64* %86, align 8
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %89 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %89(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.576, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %90 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %90(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %91 = getelementptr inbounds %1, %1* %11, i64 0, i32 2
  %92 = load i32, i32* %91, align 4
  %93 = icmp eq i32 %92, 5
  br i1 %93, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %94 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %94(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %95 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 2
  %96 = load i16, i16* %95, align 2
  %97 = icmp eq i16 %96, 1
  %98 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 1
  %99 = load i8, i8* %98, align 1
  %100 = icmp eq i8 %99, 32
  %101 = getelementptr inbounds %1, %1* %11, i64 0, i32 3, i32 0
  %102 = load i8, i8* %101, align 1
  %103 = icmp eq i8 %102, 2
  %104 = and i1 %100, %103
  %105 = and i1 %97, %104
  br i1 %105, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %106 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %106(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %107 = load i64, i64* %25, align 8, !tbaa !8196
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 1
  br i1 %109, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %111 = getelementptr inbounds i64, i64* %25, i64 1
  %112 = load i64, i64* %111, align 8, !tbaa !8210
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %116 = getelementptr inbounds i64, i64* %25, i64 2
  %117 = load i64, i64* %116, align 8, !tbaa !8212
  %118 = trunc i64 %117 to i32
  %119 = icmp eq i32 %118, 28
  br i1 %119, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %120 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %120(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %121 = getelementptr inbounds i64, i64* %25, i64 3
  %122 = load i64, i64* %121, align 8, !tbaa !8215
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 28
  br i1 %124, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %125 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %125(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %126 = getelementptr inbounds i64, i64* %25, i64 4
  %127 = load i64, i64* %126, align 8, !tbaa !8217
  %128 = trunc i64 %127 to i32
  %129 = icmp eq i32 %128, 128
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.270, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %131 = icmp eq i64* %27, null
  br i1 %131, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %132 = bitcast i64* %27 to <4 x i64>*
  %133 = load <4 x i64>, <4 x i64>* %132, align 8, !tbaa !8221
  %134 = trunc <4 x i64> %133 to <4 x i32>
  %135 = icmp eq <4 x i32> %134, <i32 100352, i32 100352, i32 3584, i32 128>
  %136 = getelementptr inbounds i64, i64* %27, i64 4
  %137 = load i64, i64* %136, align 8, !tbaa !8233
  %138 = trunc i64 %137 to i32
  %139 = icmp eq i32 %138, 1
  %rdx.shuf = shufflevector <4 x i1> %135, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %135, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %140 = extractelement <4 x i1> %bin.rdx50, i32 0
  %141 = and i1 %140, %139
  br i1 %141, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %142 = getelementptr inbounds %1, %1* %11, i64 0, i32 6
  %143 = load i64, i64* %142, align 8
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %145 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %145(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.271, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %147 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 0
  %148 = load i32, i32* %147, align 4
  %149 = icmp eq i32 %148, 1
  br i1 %149, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %150 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %150(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %151 = getelementptr inbounds %1, %1* %11, i64 0, i32 1, i32 1
  %152 = load i32, i32* %151, align 4
  %153 = icmp eq i32 %21, %152
  br i1 %153, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %154 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %154(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %155 = tail call fastcc i32 @fused_layout_transform_40_compute_(i8* %23, i8* %13)
  ret i32 %155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_40_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %52, align 8
  %3 = getelementptr inbounds %52, %52* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %52, %52* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %52* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.577, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.577(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 7
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 6
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 63
  %35 = lshr i32 %33, 6
  %36 = mul nsw i32 %35, 50176
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !8237
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !8240
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1) #5

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1) #5

; Function Attrs: nounwind readnone speculatable
declare <4 x float> @llvm.exp.v4f32(<4 x float>) #2

attributes #0 = { noinline }
attributes #1 = { norecurse nounwind }
attributes #2 = { nounwind readnone speculatable }
attributes #3 = { nounwind }
attributes #4 = { noinline norecurse nounwind }
attributes #5 = { argmemonly nounwind }

!llvm.dbg.cu = !{!0}
!llvm.module.flags = !{!3, !4}

!0 = distinct !DICompileUnit(language: DW_LANG_C, file: !1, producer: "TVM", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !2, dwoId: 1)
!1 = !DIFile(filename: "model.tvm", directory: "/tmp/")
!2 = !{}
!3 = !{i32 2, !"tvm_target", !"llvm"}
!4 = !{i32 4, !"Debug Info Version", i32 3}
!5 = !{!"branch_weights", i32 1048576, i32 1}
!6 = !{!7, !7, i64 0}
!7 = !{!"ctx_ptr", !8, i64 0}
!8 = !{!"tvm-tbaa"}
!9 = !{!10, !10, i64 0}
!10 = !{!"0x9140830.w1.b0", !11, i64 0}
!11 = !{!"0x9140830.w2.b0", !12, i64 0}
!12 = !{!"0x9140830.w4.b0", !13, i64 0}
!13 = !{!"0x9140830.w8.b0", !14, i64 0}
!14 = !{!"0x9140830.w16.b0", !15, i64 0}
!15 = !{!"0x9140830.w32.b0", !16, i64 0}
!16 = !{!"0x9140830.w64.b0", !17, i64 0}
!17 = !{!"0x9140830.w128.b0", !18, i64 0}
!18 = !{!"0x9140830.w256.b0", !19, i64 0}
!19 = !{!"0x9140830.w512.b0", !20, i64 0}
!20 = !{!"0x9140830.w1024.b0", !21, i64 0}
!21 = !{!"int32", !22, i64 0}
!22 = !{!"0x9140830", !8, i64 0}
!23 = !{!24, !24, i64 0}
!24 = !{!"0x9140830.w1.b1", !11, i64 0}
!25 = !{!26, !26, i64 0}
!26 = !{!"0x9158370.w1.b0", !27, i64 0}
!27 = !{!"0x9158370.w2.b0", !28, i64 0}
!28 = !{!"0x9158370.w4.b0", !29, i64 0}
!29 = !{!"0x9158370.w8.b0", !30, i64 0}
!30 = !{!"0x9158370.w16.b0", !31, i64 0}
!31 = !{!"0x9158370.w32.b0", !32, i64 0}
!32 = !{!"0x9158370.w64.b0", !33, i64 0}
!33 = !{!"0x9158370.w128.b0", !34, i64 0}
!34 = !{!"0x9158370.w256.b0", !35, i64 0}
!35 = !{!"0x9158370.w512.b0", !36, i64 0}
!36 = !{!"0x9158370.w1024.b0", !37, i64 0}
!37 = !{!"int64", !38, i64 0}
!38 = !{!"0x9158370", !8, i64 0}
!39 = !{!40, !40, i64 0}
!40 = !{!"0x9158370.w1.b1", !27, i64 0}
!41 = !{!42, !42, i64 0}
!42 = !{!"0x9158370.w1.b2", !43, i64 0}
!43 = !{!"0x9158370.w2.b2", !28, i64 0}
!44 = !{!45, !45, i64 0}
!45 = !{!"0x9158370.w1.b3", !43, i64 0}
!46 = !{!47, !47, i64 0}
!47 = !{!"0x9158370.w1.b4", !48, i64 0}
!48 = !{!"0x9158370.w2.b4", !49, i64 0}
!49 = !{!"0x9158370.w4.b4", !29, i64 0}
!50 = !{!"branch_weights", i32 1, i32 1048576}
!51 = !{!52, !52, i64 0}
!52 = !{!"0x91553d0.w4.b0", !53, i64 0}
!53 = !{!"0x91553d0.w8.b0", !54, i64 0}
!54 = !{!"0x91553d0.w16.b0", !55, i64 0}
!55 = !{!"0x91553d0.w32.b0", !56, i64 0}
!56 = !{!"0x91553d0.w64.b0", !57, i64 0}
!57 = !{!"0x91553d0.w128.b0", !58, i64 0}
!58 = !{!"0x91553d0.w256.b0", !59, i64 0}
!59 = !{!"0x91553d0.w512.b0", !60, i64 0}
!60 = !{!"0x91553d0.w1024.b0", !61, i64 0}
!61 = !{!"int64", !62, i64 0}
!62 = !{!"0x91553d0", !8, i64 0}
!63 = !{!64, !64, i64 0}
!64 = !{!"0x91553d0.w1.b4", !65, i64 0}
!65 = !{!"0x91553d0.w2.b4", !66, i64 0}
!66 = !{!"0x91553d0.w4.b4", !53, i64 0}
!67 = !{!68, !68, i64 0}
!68 = !{!"0x9159f20.w1.b0", !69, i64 0}
!69 = !{!"0x9159f20.w2.b0", !70, i64 0}
!70 = !{!"0x9159f20.w4.b0", !71, i64 0}
!71 = !{!"0x9159f20.w8.b0", !72, i64 0}
!72 = !{!"0x9159f20.w16.b0", !73, i64 0}
!73 = !{!"0x9159f20.w32.b0", !74, i64 0}
!74 = !{!"0x9159f20.w64.b0", !75, i64 0}
!75 = !{!"0x9159f20.w128.b0", !76, i64 0}
!76 = !{!"0x9159f20.w256.b0", !77, i64 0}
!77 = !{!"0x9159f20.w512.b0", !78, i64 0}
!78 = !{!"0x9159f20.w1024.b0", !79, i64 0}
!79 = !{!"int64", !80, i64 0}
!80 = !{!"0x9159f20", !8, i64 0}
!81 = !{!82, !82, i64 0}
!82 = !{!"0x9159f20.w1.b1", !69, i64 0}
!83 = !{!84, !84, i64 0}
!84 = !{!"0x9159f20.w1.b2", !85, i64 0}
!85 = !{!"0x9159f20.w2.b2", !70, i64 0}
!86 = !{!87, !87, i64 0}
!87 = !{!"0x9159f20.w1.b3", !85, i64 0}
!88 = !{!89, !89, i64 0}
!89 = !{!"0x9159f20.w1.b4", !90, i64 0}
!90 = !{!"0x9159f20.w2.b4", !91, i64 0}
!91 = !{!"0x9159f20.w4.b4", !71, i64 0}
!92 = !{!93, !93, i64 0}
!93 = !{!"0x915af30.w4.b0", !94, i64 0}
!94 = !{!"0x915af30.w8.b0", !95, i64 0}
!95 = !{!"0x915af30.w16.b0", !96, i64 0}
!96 = !{!"0x915af30.w32.b0", !97, i64 0}
!97 = !{!"0x915af30.w64.b0", !98, i64 0}
!98 = !{!"0x915af30.w128.b0", !99, i64 0}
!99 = !{!"0x915af30.w256.b0", !100, i64 0}
!100 = !{!"0x915af30.w512.b0", !101, i64 0}
!101 = !{!"0x915af30.w1024.b0", !102, i64 0}
!102 = !{!"int64", !103, i64 0}
!103 = !{!"0x915af30", !8, i64 0}
!104 = !{!105, !105, i64 0}
!105 = !{!"0x915af30.w1.b4", !106, i64 0}
!106 = !{!"0x915af30.w2.b4", !107, i64 0}
!107 = !{!"0x915af30.w4.b4", !94, i64 0}
!108 = !{!109, !109, i64 0}
!109 = !{!"float32", !110, i64 0}
!110 = !{!"0x9144270", !8, i64 0}
!111 = !{!112, !112, i64 0}
!112 = !{!"float32", !113, i64 0}
!113 = !{!"0x914f540", !8, i64 0}
!114 = !{!115, !115, i64 0}
!115 = !{!"0xca20580.w1.b0", !116, i64 0}
!116 = !{!"0xca20580.w2.b0", !117, i64 0}
!117 = !{!"0xca20580.w4.b0", !118, i64 0}
!118 = !{!"0xca20580.w8.b0", !119, i64 0}
!119 = !{!"0xca20580.w16.b0", !120, i64 0}
!120 = !{!"0xca20580.w32.b0", !121, i64 0}
!121 = !{!"0xca20580.w64.b0", !122, i64 0}
!122 = !{!"0xca20580.w128.b0", !123, i64 0}
!123 = !{!"0xca20580.w256.b0", !124, i64 0}
!124 = !{!"0xca20580.w512.b0", !125, i64 0}
!125 = !{!"0xca20580.w1024.b0", !126, i64 0}
!126 = !{!"int32", !127, i64 0}
!127 = !{!"0xca20580", !8, i64 0}
!128 = !{!129, !129, i64 0}
!129 = !{!"0xca20580.w1.b1", !116, i64 0}
!130 = !{!131, !131, i64 0}
!131 = !{!"0xca20e40.w1.b0", !132, i64 0}
!132 = !{!"0xca20e40.w2.b0", !133, i64 0}
!133 = !{!"0xca20e40.w4.b0", !134, i64 0}
!134 = !{!"0xca20e40.w8.b0", !135, i64 0}
!135 = !{!"0xca20e40.w16.b0", !136, i64 0}
!136 = !{!"0xca20e40.w32.b0", !137, i64 0}
!137 = !{!"0xca20e40.w64.b0", !138, i64 0}
!138 = !{!"0xca20e40.w128.b0", !139, i64 0}
!139 = !{!"0xca20e40.w256.b0", !140, i64 0}
!140 = !{!"0xca20e40.w512.b0", !141, i64 0}
!141 = !{!"0xca20e40.w1024.b0", !142, i64 0}
!142 = !{!"int64", !143, i64 0}
!143 = !{!"0xca20e40", !8, i64 0}
!144 = !{!145, !145, i64 0}
!145 = !{!"0xca20e40.w1.b1", !132, i64 0}
!146 = !{!147, !147, i64 0}
!147 = !{!"0xca20e40.w1.b2", !148, i64 0}
!148 = !{!"0xca20e40.w2.b2", !133, i64 0}
!149 = !{!150, !150, i64 0}
!150 = !{!"0xca20e40.w1.b3", !148, i64 0}
!151 = !{!152, !152, i64 0}
!152 = !{!"0xca20e40.w1.b4", !153, i64 0}
!153 = !{!"0xca20e40.w2.b4", !154, i64 0}
!154 = !{!"0xca20e40.w4.b4", !134, i64 0}
!155 = !{!156, !156, i64 0}
!156 = !{!"0xca223f0.w4.b0", !157, i64 0}
!157 = !{!"0xca223f0.w8.b0", !158, i64 0}
!158 = !{!"0xca223f0.w16.b0", !159, i64 0}
!159 = !{!"0xca223f0.w32.b0", !160, i64 0}
!160 = !{!"0xca223f0.w64.b0", !161, i64 0}
!161 = !{!"0xca223f0.w128.b0", !162, i64 0}
!162 = !{!"0xca223f0.w256.b0", !163, i64 0}
!163 = !{!"0xca223f0.w512.b0", !164, i64 0}
!164 = !{!"0xca223f0.w1024.b0", !165, i64 0}
!165 = !{!"int64", !166, i64 0}
!166 = !{!"0xca223f0", !8, i64 0}
!167 = !{!168, !168, i64 0}
!168 = !{!"0xca223f0.w1.b4", !169, i64 0}
!169 = !{!"0xca223f0.w2.b4", !170, i64 0}
!170 = !{!"0xca223f0.w4.b4", !157, i64 0}
!171 = !{!172, !172, i64 0}
!172 = !{!"0xca24330.w1.b0", !173, i64 0}
!173 = !{!"0xca24330.w2.b0", !174, i64 0}
!174 = !{!"0xca24330.w4.b0", !175, i64 0}
!175 = !{!"0xca24330.w8.b0", !176, i64 0}
!176 = !{!"0xca24330.w16.b0", !177, i64 0}
!177 = !{!"0xca24330.w32.b0", !178, i64 0}
!178 = !{!"0xca24330.w64.b0", !179, i64 0}
!179 = !{!"0xca24330.w128.b0", !180, i64 0}
!180 = !{!"0xca24330.w256.b0", !181, i64 0}
!181 = !{!"0xca24330.w512.b0", !182, i64 0}
!182 = !{!"0xca24330.w1024.b0", !183, i64 0}
!183 = !{!"int64", !184, i64 0}
!184 = !{!"0xca24330", !8, i64 0}
!185 = !{!186, !186, i64 0}
!186 = !{!"0xca24330.w1.b1", !173, i64 0}
!187 = !{!188, !188, i64 0}
!188 = !{!"0xca24330.w1.b2", !189, i64 0}
!189 = !{!"0xca24330.w2.b2", !174, i64 0}
!190 = !{!191, !191, i64 0}
!191 = !{!"0xca24330.w1.b3", !189, i64 0}
!192 = !{!193, !193, i64 0}
!193 = !{!"0xca24330.w1.b4", !194, i64 0}
!194 = !{!"0xca24330.w2.b4", !195, i64 0}
!195 = !{!"0xca24330.w4.b4", !175, i64 0}
!196 = !{!197, !197, i64 0}
!197 = !{!"0xca25310.w4.b0", !198, i64 0}
!198 = !{!"0xca25310.w8.b0", !199, i64 0}
!199 = !{!"0xca25310.w16.b0", !200, i64 0}
!200 = !{!"0xca25310.w32.b0", !201, i64 0}
!201 = !{!"0xca25310.w64.b0", !202, i64 0}
!202 = !{!"0xca25310.w128.b0", !203, i64 0}
!203 = !{!"0xca25310.w256.b0", !204, i64 0}
!204 = !{!"0xca25310.w512.b0", !205, i64 0}
!205 = !{!"0xca25310.w1024.b0", !206, i64 0}
!206 = !{!"int64", !207, i64 0}
!207 = !{!"0xca25310", !8, i64 0}
!208 = !{!209, !209, i64 0}
!209 = !{!"0xca25310.w1.b4", !210, i64 0}
!210 = !{!"0xca25310.w2.b4", !211, i64 0}
!211 = !{!"0xca25310.w4.b4", !198, i64 0}
!212 = !{!213, !213, i64 0}
!213 = !{!"float32", !214, i64 0}
!214 = !{!"0xca1ea10", !8, i64 0}
!215 = !{!216, !216, i64 0}
!216 = !{!"float32", !217, i64 0}
!217 = !{!"0xca1e1b0", !8, i64 0}
!218 = !{!219, !219, i64 0}
!219 = !{!"0xa70bf30.w1.b0", !220, i64 0}
!220 = !{!"0xa70bf30.w2.b0", !221, i64 0}
!221 = !{!"0xa70bf30.w4.b0", !222, i64 0}
!222 = !{!"0xa70bf30.w8.b0", !223, i64 0}
!223 = !{!"0xa70bf30.w16.b0", !224, i64 0}
!224 = !{!"0xa70bf30.w32.b0", !225, i64 0}
!225 = !{!"0xa70bf30.w64.b0", !226, i64 0}
!226 = !{!"0xa70bf30.w128.b0", !227, i64 0}
!227 = !{!"0xa70bf30.w256.b0", !228, i64 0}
!228 = !{!"0xa70bf30.w512.b0", !229, i64 0}
!229 = !{!"0xa70bf30.w1024.b0", !230, i64 0}
!230 = !{!"int32", !231, i64 0}
!231 = !{!"0xa70bf30", !8, i64 0}
!232 = !{!233, !233, i64 0}
!233 = !{!"0xa70bf30.w1.b2", !234, i64 0}
!234 = !{!"0xa70bf30.w2.b2", !221, i64 0}
!235 = !{!236, !236, i64 0}
!236 = !{!"0xa70bf30.w1.b3", !234, i64 0}
!237 = !{!238, !238, i64 0}
!238 = !{!"0xa70bf30.w1.b4", !239, i64 0}
!239 = !{!"0xa70bf30.w2.b4", !240, i64 0}
!240 = !{!"0xa70bf30.w4.b4", !222, i64 0}
!241 = !{!242, !242, i64 0}
!242 = !{!"0xa70bf30.w1.b1", !220, i64 0}
!243 = !{!244, !244, i64 0}
!244 = !{!"0xcab3a80.w1.b0", !245, i64 0}
!245 = !{!"0xcab3a80.w2.b0", !246, i64 0}
!246 = !{!"0xcab3a80.w4.b0", !247, i64 0}
!247 = !{!"0xcab3a80.w8.b0", !248, i64 0}
!248 = !{!"0xcab3a80.w16.b0", !249, i64 0}
!249 = !{!"0xcab3a80.w32.b0", !250, i64 0}
!250 = !{!"0xcab3a80.w64.b0", !251, i64 0}
!251 = !{!"0xcab3a80.w128.b0", !252, i64 0}
!252 = !{!"0xcab3a80.w256.b0", !253, i64 0}
!253 = !{!"0xcab3a80.w512.b0", !254, i64 0}
!254 = !{!"0xcab3a80.w1024.b0", !255, i64 0}
!255 = !{!"int64", !256, i64 0}
!256 = !{!"0xcab3a80", !8, i64 0}
!257 = !{!258, !258, i64 0}
!258 = !{!"0xcab3a80.w1.b1", !245, i64 0}
!259 = !{!260, !260, i64 0}
!260 = !{!"0xcab3a80.w1.b2", !261, i64 0}
!261 = !{!"0xcab3a80.w2.b2", !246, i64 0}
!262 = !{!263, !263, i64 0}
!263 = !{!"0xcab3a80.w1.b3", !261, i64 0}
!264 = !{!265, !265, i64 0}
!265 = !{!"0xcab3a80.w1.b4", !266, i64 0}
!266 = !{!"0xcab3a80.w2.b4", !267, i64 0}
!267 = !{!"0xcab3a80.w4.b4", !247, i64 0}
!268 = !{!269, !269, i64 0}
!269 = !{!"0xcab2470.w4.b0", !270, i64 0}
!270 = !{!"0xcab2470.w8.b0", !271, i64 0}
!271 = !{!"0xcab2470.w16.b0", !272, i64 0}
!272 = !{!"0xcab2470.w32.b0", !273, i64 0}
!273 = !{!"0xcab2470.w64.b0", !274, i64 0}
!274 = !{!"0xcab2470.w128.b0", !275, i64 0}
!275 = !{!"0xcab2470.w256.b0", !276, i64 0}
!276 = !{!"0xcab2470.w512.b0", !277, i64 0}
!277 = !{!"0xcab2470.w1024.b0", !278, i64 0}
!278 = !{!"int64", !279, i64 0}
!279 = !{!"0xcab2470", !8, i64 0}
!280 = !{!281, !281, i64 0}
!281 = !{!"0xcab2470.w1.b4", !282, i64 0}
!282 = !{!"0xcab2470.w2.b4", !283, i64 0}
!283 = !{!"0xcab2470.w4.b4", !270, i64 0}
!284 = !{!285, !285, i64 0}
!285 = !{!"0xcab4bd0.w1.b0", !286, i64 0}
!286 = !{!"0xcab4bd0.w2.b0", !287, i64 0}
!287 = !{!"0xcab4bd0.w4.b0", !288, i64 0}
!288 = !{!"0xcab4bd0.w8.b0", !289, i64 0}
!289 = !{!"0xcab4bd0.w16.b0", !290, i64 0}
!290 = !{!"0xcab4bd0.w32.b0", !291, i64 0}
!291 = !{!"0xcab4bd0.w64.b0", !292, i64 0}
!292 = !{!"0xcab4bd0.w128.b0", !293, i64 0}
!293 = !{!"0xcab4bd0.w256.b0", !294, i64 0}
!294 = !{!"0xcab4bd0.w512.b0", !295, i64 0}
!295 = !{!"0xcab4bd0.w1024.b0", !296, i64 0}
!296 = !{!"int64", !297, i64 0}
!297 = !{!"0xcab4bd0", !8, i64 0}
!298 = !{!299, !299, i64 0}
!299 = !{!"0xcab4bd0.w1.b1", !286, i64 0}
!300 = !{!301, !301, i64 0}
!301 = !{!"0xcab4bd0.w1.b2", !302, i64 0}
!302 = !{!"0xcab4bd0.w2.b2", !287, i64 0}
!303 = !{!304, !304, i64 0}
!304 = !{!"0xcab4bd0.w1.b3", !302, i64 0}
!305 = !{!306, !306, i64 0}
!306 = !{!"0xcab4bd0.w1.b4", !307, i64 0}
!307 = !{!"0xcab4bd0.w2.b4", !308, i64 0}
!308 = !{!"0xcab4bd0.w4.b4", !288, i64 0}
!309 = !{!310, !310, i64 0}
!310 = !{!"0xcab4bd0.w1.b5", !307, i64 0}
!311 = !{!312, !312, i64 0}
!312 = !{!"0xcac0d10.w4.b0", !313, i64 0}
!313 = !{!"0xcac0d10.w8.b0", !314, i64 0}
!314 = !{!"0xcac0d10.w16.b0", !315, i64 0}
!315 = !{!"0xcac0d10.w32.b0", !316, i64 0}
!316 = !{!"0xcac0d10.w64.b0", !317, i64 0}
!317 = !{!"0xcac0d10.w128.b0", !318, i64 0}
!318 = !{!"0xcac0d10.w256.b0", !319, i64 0}
!319 = !{!"0xcac0d10.w512.b0", !320, i64 0}
!320 = !{!"0xcac0d10.w1024.b0", !321, i64 0}
!321 = !{!"int64", !322, i64 0}
!322 = !{!"0xcac0d10", !8, i64 0}
!323 = !{!324, !324, i64 0}
!324 = !{!"0xcac0d10.w1.b4", !325, i64 0}
!325 = !{!"0xcac0d10.w2.b4", !326, i64 0}
!326 = !{!"0xcac0d10.w4.b4", !313, i64 0}
!327 = !{!328, !328, i64 0}
!328 = !{!"0xcac0d10.w1.b5", !325, i64 0}
!329 = !{!330, !330, i64 0}
!330 = !{!"0xcac3010.w1.b0", !331, i64 0}
!331 = !{!"0xcac3010.w2.b0", !332, i64 0}
!332 = !{!"0xcac3010.w4.b0", !333, i64 0}
!333 = !{!"0xcac3010.w8.b0", !334, i64 0}
!334 = !{!"0xcac3010.w16.b0", !335, i64 0}
!335 = !{!"0xcac3010.w32.b0", !336, i64 0}
!336 = !{!"0xcac3010.w64.b0", !337, i64 0}
!337 = !{!"0xcac3010.w128.b0", !338, i64 0}
!338 = !{!"0xcac3010.w256.b0", !339, i64 0}
!339 = !{!"0xcac3010.w512.b0", !340, i64 0}
!340 = !{!"0xcac3010.w1024.b0", !341, i64 0}
!341 = !{!"int64", !342, i64 0}
!342 = !{!"0xcac3010", !8, i64 0}
!343 = !{!344, !344, i64 0}
!344 = !{!"0xcac3010.w1.b1", !331, i64 0}
!345 = !{!346, !346, i64 0}
!346 = !{!"0xcac3010.w1.b2", !347, i64 0}
!347 = !{!"0xcac3010.w2.b2", !332, i64 0}
!348 = !{!349, !349, i64 0}
!349 = !{!"0xcac3010.w1.b3", !347, i64 0}
!350 = !{!351, !351, i64 0}
!351 = !{!"0xcac3bb0.w4.b0", !352, i64 0}
!352 = !{!"0xcac3bb0.w8.b0", !353, i64 0}
!353 = !{!"0xcac3bb0.w16.b0", !354, i64 0}
!354 = !{!"0xcac3bb0.w32.b0", !355, i64 0}
!355 = !{!"0xcac3bb0.w64.b0", !356, i64 0}
!356 = !{!"0xcac3bb0.w128.b0", !357, i64 0}
!357 = !{!"0xcac3bb0.w256.b0", !358, i64 0}
!358 = !{!"0xcac3bb0.w512.b0", !359, i64 0}
!359 = !{!"0xcac3bb0.w1024.b0", !360, i64 0}
!360 = !{!"int64", !361, i64 0}
!361 = !{!"0xcac3bb0", !8, i64 0}
!362 = !{!363, !363, i64 0}
!363 = !{!"0xcab6de0.w1.b0", !364, i64 0}
!364 = !{!"0xcab6de0.w2.b0", !365, i64 0}
!365 = !{!"0xcab6de0.w4.b0", !366, i64 0}
!366 = !{!"0xcab6de0.w8.b0", !367, i64 0}
!367 = !{!"0xcab6de0.w16.b0", !368, i64 0}
!368 = !{!"0xcab6de0.w32.b0", !369, i64 0}
!369 = !{!"0xcab6de0.w64.b0", !370, i64 0}
!370 = !{!"0xcab6de0.w128.b0", !371, i64 0}
!371 = !{!"0xcab6de0.w256.b0", !372, i64 0}
!372 = !{!"0xcab6de0.w512.b0", !373, i64 0}
!373 = !{!"0xcab6de0.w1024.b0", !374, i64 0}
!374 = !{!"int64", !375, i64 0}
!375 = !{!"0xcab6de0", !8, i64 0}
!376 = !{!377, !377, i64 0}
!377 = !{!"0xcab6de0.w1.b1", !364, i64 0}
!378 = !{!379, !379, i64 0}
!379 = !{!"0xcab6de0.w1.b2", !380, i64 0}
!380 = !{!"0xcab6de0.w2.b2", !365, i64 0}
!381 = !{!382, !382, i64 0}
!382 = !{!"0xcab6de0.w1.b3", !380, i64 0}
!383 = !{!384, !384, i64 0}
!384 = !{!"0xcac6940.w4.b0", !385, i64 0}
!385 = !{!"0xcac6940.w8.b0", !386, i64 0}
!386 = !{!"0xcac6940.w16.b0", !387, i64 0}
!387 = !{!"0xcac6940.w32.b0", !388, i64 0}
!388 = !{!"0xcac6940.w64.b0", !389, i64 0}
!389 = !{!"0xcac6940.w128.b0", !390, i64 0}
!390 = !{!"0xcac6940.w256.b0", !391, i64 0}
!391 = !{!"0xcac6940.w512.b0", !392, i64 0}
!392 = !{!"0xcac6940.w1024.b0", !393, i64 0}
!393 = !{!"int64", !394, i64 0}
!394 = !{!"0xcac6940", !8, i64 0}
!395 = !{!396, !396, i64 0}
!396 = !{!"0xcac8a20.w1.b0", !397, i64 0}
!397 = !{!"0xcac8a20.w2.b0", !398, i64 0}
!398 = !{!"0xcac8a20.w4.b0", !399, i64 0}
!399 = !{!"0xcac8a20.w8.b0", !400, i64 0}
!400 = !{!"0xcac8a20.w16.b0", !401, i64 0}
!401 = !{!"0xcac8a20.w32.b0", !402, i64 0}
!402 = !{!"0xcac8a20.w64.b0", !403, i64 0}
!403 = !{!"0xcac8a20.w128.b0", !404, i64 0}
!404 = !{!"0xcac8a20.w256.b0", !405, i64 0}
!405 = !{!"0xcac8a20.w512.b0", !406, i64 0}
!406 = !{!"0xcac8a20.w1024.b0", !407, i64 0}
!407 = !{!"int64", !408, i64 0}
!408 = !{!"0xcac8a20", !8, i64 0}
!409 = !{!410, !410, i64 0}
!410 = !{!"0xcac8a20.w1.b1", !397, i64 0}
!411 = !{!412, !412, i64 0}
!412 = !{!"0xcac8a20.w1.b2", !413, i64 0}
!413 = !{!"0xcac8a20.w2.b2", !398, i64 0}
!414 = !{!415, !415, i64 0}
!415 = !{!"0xcac8a20.w1.b3", !413, i64 0}
!416 = !{!417, !417, i64 0}
!417 = !{!"0xcac8a20.w1.b4", !418, i64 0}
!418 = !{!"0xcac8a20.w2.b4", !419, i64 0}
!419 = !{!"0xcac8a20.w4.b4", !399, i64 0}
!420 = !{!421, !421, i64 0}
!421 = !{!"0xcac9200.w4.b0", !422, i64 0}
!422 = !{!"0xcac9200.w8.b0", !423, i64 0}
!423 = !{!"0xcac9200.w16.b0", !424, i64 0}
!424 = !{!"0xcac9200.w32.b0", !425, i64 0}
!425 = !{!"0xcac9200.w64.b0", !426, i64 0}
!426 = !{!"0xcac9200.w128.b0", !427, i64 0}
!427 = !{!"0xcac9200.w256.b0", !428, i64 0}
!428 = !{!"0xcac9200.w512.b0", !429, i64 0}
!429 = !{!"0xcac9200.w1024.b0", !430, i64 0}
!430 = !{!"int64", !431, i64 0}
!431 = !{!"0xcac9200", !8, i64 0}
!432 = !{!433, !433, i64 0}
!433 = !{!"0xcac9200.w1.b4", !434, i64 0}
!434 = !{!"0xcac9200.w2.b4", !435, i64 0}
!435 = !{!"0xcac9200.w4.b4", !422, i64 0}
!436 = !{!437, !437, i64 0}
!437 = !{!"float32", !438, i64 0}
!438 = !{!"0xa705b60", !8, i64 0}
!439 = !{!440, !440, i64 0}
!440 = !{!"float32", !441, i64 0}
!441 = !{!"0xa6ef610", !8, i64 0}
!442 = !{!443, !443, i64 0}
!443 = !{!"float32", !444, i64 0}
!444 = !{!"0xa70c6a0", !8, i64 0}
!445 = !{!446, !446, i64 0}
!446 = !{!"float32", !447, i64 0}
!447 = !{!"0xa706be0", !8, i64 0}
!448 = !{!449, !449, i64 0}
!449 = !{!"float32", !450, i64 0}
!450 = !{!"0xa707140", !8, i64 0}
!451 = !{!452, !452, i64 0}
!452 = !{!"float32", !453, i64 0}
!453 = !{!"0xa705b10", !8, i64 0}
!454 = !{!455, !455, i64 0}
!455 = !{!"0xa6fd480.w1.b0", !456, i64 0}
!456 = !{!"0xa6fd480.w2.b0", !457, i64 0}
!457 = !{!"0xa6fd480.w4.b0", !458, i64 0}
!458 = !{!"0xa6fd480.w8.b0", !459, i64 0}
!459 = !{!"0xa6fd480.w16.b0", !460, i64 0}
!460 = !{!"0xa6fd480.w32.b0", !461, i64 0}
!461 = !{!"0xa6fd480.w64.b0", !462, i64 0}
!462 = !{!"0xa6fd480.w128.b0", !463, i64 0}
!463 = !{!"0xa6fd480.w256.b0", !464, i64 0}
!464 = !{!"0xa6fd480.w512.b0", !465, i64 0}
!465 = !{!"0xa6fd480.w1024.b0", !466, i64 0}
!466 = !{!"int32", !467, i64 0}
!467 = !{!"0xa6fd480", !8, i64 0}
!468 = !{!469, !469, i64 0}
!469 = !{!"0xa6fd480.w1.b1", !456, i64 0}
!470 = !{!471, !471, i64 0}
!471 = !{!"0xa6fe320.w1.b0", !472, i64 0}
!472 = !{!"0xa6fe320.w2.b0", !473, i64 0}
!473 = !{!"0xa6fe320.w4.b0", !474, i64 0}
!474 = !{!"0xa6fe320.w8.b0", !475, i64 0}
!475 = !{!"0xa6fe320.w16.b0", !476, i64 0}
!476 = !{!"0xa6fe320.w32.b0", !477, i64 0}
!477 = !{!"0xa6fe320.w64.b0", !478, i64 0}
!478 = !{!"0xa6fe320.w128.b0", !479, i64 0}
!479 = !{!"0xa6fe320.w256.b0", !480, i64 0}
!480 = !{!"0xa6fe320.w512.b0", !481, i64 0}
!481 = !{!"0xa6fe320.w1024.b0", !482, i64 0}
!482 = !{!"int64", !483, i64 0}
!483 = !{!"0xa6fe320", !8, i64 0}
!484 = !{!485, !485, i64 0}
!485 = !{!"0xa6fe320.w1.b1", !472, i64 0}
!486 = !{!487, !487, i64 0}
!487 = !{!"0xa6fe320.w1.b2", !488, i64 0}
!488 = !{!"0xa6fe320.w2.b2", !473, i64 0}
!489 = !{!490, !490, i64 0}
!490 = !{!"0xa6fe320.w1.b3", !488, i64 0}
!491 = !{!492, !492, i64 0}
!492 = !{!"0xa6fe320.w1.b4", !493, i64 0}
!493 = !{!"0xa6fe320.w2.b4", !494, i64 0}
!494 = !{!"0xa6fe320.w4.b4", !474, i64 0}
!495 = !{!496, !496, i64 0}
!496 = !{!"0xa6feba0.w4.b0", !497, i64 0}
!497 = !{!"0xa6feba0.w8.b0", !498, i64 0}
!498 = !{!"0xa6feba0.w16.b0", !499, i64 0}
!499 = !{!"0xa6feba0.w32.b0", !500, i64 0}
!500 = !{!"0xa6feba0.w64.b0", !501, i64 0}
!501 = !{!"0xa6feba0.w128.b0", !502, i64 0}
!502 = !{!"0xa6feba0.w256.b0", !503, i64 0}
!503 = !{!"0xa6feba0.w512.b0", !504, i64 0}
!504 = !{!"0xa6feba0.w1024.b0", !505, i64 0}
!505 = !{!"int64", !506, i64 0}
!506 = !{!"0xa6feba0", !8, i64 0}
!507 = !{!508, !508, i64 0}
!508 = !{!"0xa6feba0.w1.b4", !509, i64 0}
!509 = !{!"0xa6feba0.w2.b4", !510, i64 0}
!510 = !{!"0xa6feba0.w4.b4", !497, i64 0}
!511 = !{!512, !512, i64 0}
!512 = !{!"0xa700c10.w1.b0", !513, i64 0}
!513 = !{!"0xa700c10.w2.b0", !514, i64 0}
!514 = !{!"0xa700c10.w4.b0", !515, i64 0}
!515 = !{!"0xa700c10.w8.b0", !516, i64 0}
!516 = !{!"0xa700c10.w16.b0", !517, i64 0}
!517 = !{!"0xa700c10.w32.b0", !518, i64 0}
!518 = !{!"0xa700c10.w64.b0", !519, i64 0}
!519 = !{!"0xa700c10.w128.b0", !520, i64 0}
!520 = !{!"0xa700c10.w256.b0", !521, i64 0}
!521 = !{!"0xa700c10.w512.b0", !522, i64 0}
!522 = !{!"0xa700c10.w1024.b0", !523, i64 0}
!523 = !{!"int64", !524, i64 0}
!524 = !{!"0xa700c10", !8, i64 0}
!525 = !{!526, !526, i64 0}
!526 = !{!"0xa700c10.w1.b1", !513, i64 0}
!527 = !{!528, !528, i64 0}
!528 = !{!"0xa700c10.w1.b2", !529, i64 0}
!529 = !{!"0xa700c10.w2.b2", !514, i64 0}
!530 = !{!531, !531, i64 0}
!531 = !{!"0xa700c10.w1.b3", !529, i64 0}
!532 = !{!533, !533, i64 0}
!533 = !{!"0xa700c10.w1.b4", !534, i64 0}
!534 = !{!"0xa700c10.w2.b4", !535, i64 0}
!535 = !{!"0xa700c10.w4.b4", !515, i64 0}
!536 = !{!537, !537, i64 0}
!537 = !{!"0xa7019f0.w4.b0", !538, i64 0}
!538 = !{!"0xa7019f0.w8.b0", !539, i64 0}
!539 = !{!"0xa7019f0.w16.b0", !540, i64 0}
!540 = !{!"0xa7019f0.w32.b0", !541, i64 0}
!541 = !{!"0xa7019f0.w64.b0", !542, i64 0}
!542 = !{!"0xa7019f0.w128.b0", !543, i64 0}
!543 = !{!"0xa7019f0.w256.b0", !544, i64 0}
!544 = !{!"0xa7019f0.w512.b0", !545, i64 0}
!545 = !{!"0xa7019f0.w1024.b0", !546, i64 0}
!546 = !{!"int64", !547, i64 0}
!547 = !{!"0xa7019f0", !8, i64 0}
!548 = !{!549, !549, i64 0}
!549 = !{!"0xa7019f0.w1.b4", !550, i64 0}
!550 = !{!"0xa7019f0.w2.b4", !551, i64 0}
!551 = !{!"0xa7019f0.w4.b4", !538, i64 0}
!552 = !{!553, !553, i64 0}
!553 = !{!"float32", !554, i64 0}
!554 = !{!"0xa6ed3e0", !8, i64 0}
!555 = !{!556, !556, i64 0}
!556 = !{!"float32", !557, i64 0}
!557 = !{!"0xa6f2700", !8, i64 0}
!558 = !{!559, !559, i64 0}
!559 = !{!"0xa6e6080.w1.b0", !560, i64 0}
!560 = !{!"0xa6e6080.w2.b0", !561, i64 0}
!561 = !{!"0xa6e6080.w4.b0", !562, i64 0}
!562 = !{!"0xa6e6080.w8.b0", !563, i64 0}
!563 = !{!"0xa6e6080.w16.b0", !564, i64 0}
!564 = !{!"0xa6e6080.w32.b0", !565, i64 0}
!565 = !{!"0xa6e6080.w64.b0", !566, i64 0}
!566 = !{!"0xa6e6080.w128.b0", !567, i64 0}
!567 = !{!"0xa6e6080.w256.b0", !568, i64 0}
!568 = !{!"0xa6e6080.w512.b0", !569, i64 0}
!569 = !{!"0xa6e6080.w1024.b0", !570, i64 0}
!570 = !{!"int32", !571, i64 0}
!571 = !{!"0xa6e6080", !8, i64 0}
!572 = !{!573, !573, i64 0}
!573 = !{!"0xa6e6080.w1.b2", !574, i64 0}
!574 = !{!"0xa6e6080.w2.b2", !561, i64 0}
!575 = !{!576, !576, i64 0}
!576 = !{!"0xa6e6080.w1.b3", !574, i64 0}
!577 = !{!578, !578, i64 0}
!578 = !{!"0xa6e6080.w1.b4", !579, i64 0}
!579 = !{!"0xa6e6080.w2.b4", !580, i64 0}
!580 = !{!"0xa6e6080.w4.b4", !562, i64 0}
!581 = !{!582, !582, i64 0}
!582 = !{!"0xa6e6080.w1.b1", !560, i64 0}
!583 = !{!584, !584, i64 0}
!584 = !{!"0xa6ecd90.w1.b0", !585, i64 0}
!585 = !{!"0xa6ecd90.w2.b0", !586, i64 0}
!586 = !{!"0xa6ecd90.w4.b0", !587, i64 0}
!587 = !{!"0xa6ecd90.w8.b0", !588, i64 0}
!588 = !{!"0xa6ecd90.w16.b0", !589, i64 0}
!589 = !{!"0xa6ecd90.w32.b0", !590, i64 0}
!590 = !{!"0xa6ecd90.w64.b0", !591, i64 0}
!591 = !{!"0xa6ecd90.w128.b0", !592, i64 0}
!592 = !{!"0xa6ecd90.w256.b0", !593, i64 0}
!593 = !{!"0xa6ecd90.w512.b0", !594, i64 0}
!594 = !{!"0xa6ecd90.w1024.b0", !595, i64 0}
!595 = !{!"int64", !596, i64 0}
!596 = !{!"0xa6ecd90", !8, i64 0}
!597 = !{!598, !598, i64 0}
!598 = !{!"0xa6ecd90.w1.b1", !585, i64 0}
!599 = !{!600, !600, i64 0}
!600 = !{!"0xa6ecd90.w1.b2", !601, i64 0}
!601 = !{!"0xa6ecd90.w2.b2", !586, i64 0}
!602 = !{!603, !603, i64 0}
!603 = !{!"0xa6ecd90.w1.b3", !601, i64 0}
!604 = !{!605, !605, i64 0}
!605 = !{!"0xa6ecd90.w1.b4", !606, i64 0}
!606 = !{!"0xa6ecd90.w2.b4", !607, i64 0}
!607 = !{!"0xa6ecd90.w4.b4", !587, i64 0}
!608 = !{!609, !609, i64 0}
!609 = !{!"0xa6e5060.w4.b0", !610, i64 0}
!610 = !{!"0xa6e5060.w8.b0", !611, i64 0}
!611 = !{!"0xa6e5060.w16.b0", !612, i64 0}
!612 = !{!"0xa6e5060.w32.b0", !613, i64 0}
!613 = !{!"0xa6e5060.w64.b0", !614, i64 0}
!614 = !{!"0xa6e5060.w128.b0", !615, i64 0}
!615 = !{!"0xa6e5060.w256.b0", !616, i64 0}
!616 = !{!"0xa6e5060.w512.b0", !617, i64 0}
!617 = !{!"0xa6e5060.w1024.b0", !618, i64 0}
!618 = !{!"int64", !619, i64 0}
!619 = !{!"0xa6e5060", !8, i64 0}
!620 = !{!621, !621, i64 0}
!621 = !{!"0xa6e5060.w1.b4", !622, i64 0}
!622 = !{!"0xa6e5060.w2.b4", !623, i64 0}
!623 = !{!"0xa6e5060.w4.b4", !610, i64 0}
!624 = !{!625, !625, i64 0}
!625 = !{!"0xa6efff0.w1.b0", !626, i64 0}
!626 = !{!"0xa6efff0.w2.b0", !627, i64 0}
!627 = !{!"0xa6efff0.w4.b0", !628, i64 0}
!628 = !{!"0xa6efff0.w8.b0", !629, i64 0}
!629 = !{!"0xa6efff0.w16.b0", !630, i64 0}
!630 = !{!"0xa6efff0.w32.b0", !631, i64 0}
!631 = !{!"0xa6efff0.w64.b0", !632, i64 0}
!632 = !{!"0xa6efff0.w128.b0", !633, i64 0}
!633 = !{!"0xa6efff0.w256.b0", !634, i64 0}
!634 = !{!"0xa6efff0.w512.b0", !635, i64 0}
!635 = !{!"0xa6efff0.w1024.b0", !636, i64 0}
!636 = !{!"int64", !637, i64 0}
!637 = !{!"0xa6efff0", !8, i64 0}
!638 = !{!639, !639, i64 0}
!639 = !{!"0xa6efff0.w1.b1", !626, i64 0}
!640 = !{!641, !641, i64 0}
!641 = !{!"0xa6efff0.w1.b2", !642, i64 0}
!642 = !{!"0xa6efff0.w2.b2", !627, i64 0}
!643 = !{!644, !644, i64 0}
!644 = !{!"0xa6efff0.w1.b3", !642, i64 0}
!645 = !{!646, !646, i64 0}
!646 = !{!"0xa6efff0.w1.b4", !647, i64 0}
!647 = !{!"0xa6efff0.w2.b4", !648, i64 0}
!648 = !{!"0xa6efff0.w4.b4", !628, i64 0}
!649 = !{!650, !650, i64 0}
!650 = !{!"0xa6efff0.w1.b5", !647, i64 0}
!651 = !{!652, !652, i64 0}
!652 = !{!"0xa6f10e0.w4.b0", !653, i64 0}
!653 = !{!"0xa6f10e0.w8.b0", !654, i64 0}
!654 = !{!"0xa6f10e0.w16.b0", !655, i64 0}
!655 = !{!"0xa6f10e0.w32.b0", !656, i64 0}
!656 = !{!"0xa6f10e0.w64.b0", !657, i64 0}
!657 = !{!"0xa6f10e0.w128.b0", !658, i64 0}
!658 = !{!"0xa6f10e0.w256.b0", !659, i64 0}
!659 = !{!"0xa6f10e0.w512.b0", !660, i64 0}
!660 = !{!"0xa6f10e0.w1024.b0", !661, i64 0}
!661 = !{!"int64", !662, i64 0}
!662 = !{!"0xa6f10e0", !8, i64 0}
!663 = !{!664, !664, i64 0}
!664 = !{!"0xa6f10e0.w1.b4", !665, i64 0}
!665 = !{!"0xa6f10e0.w2.b4", !666, i64 0}
!666 = !{!"0xa6f10e0.w4.b4", !653, i64 0}
!667 = !{!668, !668, i64 0}
!668 = !{!"0xa6f10e0.w1.b5", !665, i64 0}
!669 = !{!670, !670, i64 0}
!670 = !{!"0xa6f3460.w1.b0", !671, i64 0}
!671 = !{!"0xa6f3460.w2.b0", !672, i64 0}
!672 = !{!"0xa6f3460.w4.b0", !673, i64 0}
!673 = !{!"0xa6f3460.w8.b0", !674, i64 0}
!674 = !{!"0xa6f3460.w16.b0", !675, i64 0}
!675 = !{!"0xa6f3460.w32.b0", !676, i64 0}
!676 = !{!"0xa6f3460.w64.b0", !677, i64 0}
!677 = !{!"0xa6f3460.w128.b0", !678, i64 0}
!678 = !{!"0xa6f3460.w256.b0", !679, i64 0}
!679 = !{!"0xa6f3460.w512.b0", !680, i64 0}
!680 = !{!"0xa6f3460.w1024.b0", !681, i64 0}
!681 = !{!"int64", !682, i64 0}
!682 = !{!"0xa6f3460", !8, i64 0}
!683 = !{!684, !684, i64 0}
!684 = !{!"0xa6f3460.w1.b1", !671, i64 0}
!685 = !{!686, !686, i64 0}
!686 = !{!"0xa6f3460.w1.b2", !687, i64 0}
!687 = !{!"0xa6f3460.w2.b2", !672, i64 0}
!688 = !{!689, !689, i64 0}
!689 = !{!"0xa6f3460.w1.b3", !687, i64 0}
!690 = !{!691, !691, i64 0}
!691 = !{!"0xa6f4000.w4.b0", !692, i64 0}
!692 = !{!"0xa6f4000.w8.b0", !693, i64 0}
!693 = !{!"0xa6f4000.w16.b0", !694, i64 0}
!694 = !{!"0xa6f4000.w32.b0", !695, i64 0}
!695 = !{!"0xa6f4000.w64.b0", !696, i64 0}
!696 = !{!"0xa6f4000.w128.b0", !697, i64 0}
!697 = !{!"0xa6f4000.w256.b0", !698, i64 0}
!698 = !{!"0xa6f4000.w512.b0", !699, i64 0}
!699 = !{!"0xa6f4000.w1024.b0", !700, i64 0}
!700 = !{!"int64", !701, i64 0}
!701 = !{!"0xa6f4000", !8, i64 0}
!702 = !{!703, !703, i64 0}
!703 = !{!"0xa6ef6c0.w1.b0", !704, i64 0}
!704 = !{!"0xa6ef6c0.w2.b0", !705, i64 0}
!705 = !{!"0xa6ef6c0.w4.b0", !706, i64 0}
!706 = !{!"0xa6ef6c0.w8.b0", !707, i64 0}
!707 = !{!"0xa6ef6c0.w16.b0", !708, i64 0}
!708 = !{!"0xa6ef6c0.w32.b0", !709, i64 0}
!709 = !{!"0xa6ef6c0.w64.b0", !710, i64 0}
!710 = !{!"0xa6ef6c0.w128.b0", !711, i64 0}
!711 = !{!"0xa6ef6c0.w256.b0", !712, i64 0}
!712 = !{!"0xa6ef6c0.w512.b0", !713, i64 0}
!713 = !{!"0xa6ef6c0.w1024.b0", !714, i64 0}
!714 = !{!"int64", !715, i64 0}
!715 = !{!"0xa6ef6c0", !8, i64 0}
!716 = !{!717, !717, i64 0}
!717 = !{!"0xa6ef6c0.w1.b1", !704, i64 0}
!718 = !{!719, !719, i64 0}
!719 = !{!"0xa6ef6c0.w1.b2", !720, i64 0}
!720 = !{!"0xa6ef6c0.w2.b2", !705, i64 0}
!721 = !{!722, !722, i64 0}
!722 = !{!"0xa6ef6c0.w1.b3", !720, i64 0}
!723 = !{!724, !724, i64 0}
!724 = !{!"0xa6f6d90.w4.b0", !725, i64 0}
!725 = !{!"0xa6f6d90.w8.b0", !726, i64 0}
!726 = !{!"0xa6f6d90.w16.b0", !727, i64 0}
!727 = !{!"0xa6f6d90.w32.b0", !728, i64 0}
!728 = !{!"0xa6f6d90.w64.b0", !729, i64 0}
!729 = !{!"0xa6f6d90.w128.b0", !730, i64 0}
!730 = !{!"0xa6f6d90.w256.b0", !731, i64 0}
!731 = !{!"0xa6f6d90.w512.b0", !732, i64 0}
!732 = !{!"0xa6f6d90.w1024.b0", !733, i64 0}
!733 = !{!"int64", !734, i64 0}
!734 = !{!"0xa6f6d90", !8, i64 0}
!735 = !{!736, !736, i64 0}
!736 = !{!"0xa6f8e70.w1.b0", !737, i64 0}
!737 = !{!"0xa6f8e70.w2.b0", !738, i64 0}
!738 = !{!"0xa6f8e70.w4.b0", !739, i64 0}
!739 = !{!"0xa6f8e70.w8.b0", !740, i64 0}
!740 = !{!"0xa6f8e70.w16.b0", !741, i64 0}
!741 = !{!"0xa6f8e70.w32.b0", !742, i64 0}
!742 = !{!"0xa6f8e70.w64.b0", !743, i64 0}
!743 = !{!"0xa6f8e70.w128.b0", !744, i64 0}
!744 = !{!"0xa6f8e70.w256.b0", !745, i64 0}
!745 = !{!"0xa6f8e70.w512.b0", !746, i64 0}
!746 = !{!"0xa6f8e70.w1024.b0", !747, i64 0}
!747 = !{!"int64", !748, i64 0}
!748 = !{!"0xa6f8e70", !8, i64 0}
!749 = !{!750, !750, i64 0}
!750 = !{!"0xa6f8e70.w1.b1", !737, i64 0}
!751 = !{!752, !752, i64 0}
!752 = !{!"0xa6f8e70.w1.b2", !753, i64 0}
!753 = !{!"0xa6f8e70.w2.b2", !738, i64 0}
!754 = !{!755, !755, i64 0}
!755 = !{!"0xa6f8e70.w1.b3", !753, i64 0}
!756 = !{!757, !757, i64 0}
!757 = !{!"0xa6f8e70.w1.b4", !758, i64 0}
!758 = !{!"0xa6f8e70.w2.b4", !759, i64 0}
!759 = !{!"0xa6f8e70.w4.b4", !739, i64 0}
!760 = !{!761, !761, i64 0}
!761 = !{!"0xa6f9650.w4.b0", !762, i64 0}
!762 = !{!"0xa6f9650.w8.b0", !763, i64 0}
!763 = !{!"0xa6f9650.w16.b0", !764, i64 0}
!764 = !{!"0xa6f9650.w32.b0", !765, i64 0}
!765 = !{!"0xa6f9650.w64.b0", !766, i64 0}
!766 = !{!"0xa6f9650.w128.b0", !767, i64 0}
!767 = !{!"0xa6f9650.w256.b0", !768, i64 0}
!768 = !{!"0xa6f9650.w512.b0", !769, i64 0}
!769 = !{!"0xa6f9650.w1024.b0", !770, i64 0}
!770 = !{!"int64", !771, i64 0}
!771 = !{!"0xa6f9650", !8, i64 0}
!772 = !{!773, !773, i64 0}
!773 = !{!"0xa6f9650.w1.b4", !774, i64 0}
!774 = !{!"0xa6f9650.w2.b4", !775, i64 0}
!775 = !{!"0xa6f9650.w4.b4", !762, i64 0}
!776 = !{!777, !777, i64 0}
!777 = !{!"float32", !778, i64 0}
!778 = !{!"0xa6defe0", !8, i64 0}
!779 = !{!780, !780, i64 0}
!780 = !{!"float32", !781, i64 0}
!781 = !{!"0xa6d2fc0", !8, i64 0}
!782 = !{!783, !783, i64 0}
!783 = !{!"float32", !784, i64 0}
!784 = !{!"0xa6e5b30", !8, i64 0}
!785 = !{!786, !786, i64 0}
!786 = !{!"float32", !787, i64 0}
!787 = !{!"0xa6e0020", !8, i64 0}
!788 = !{!789, !789, i64 0}
!789 = !{!"float32", !790, i64 0}
!790 = !{!"0xa6e05c0", !8, i64 0}
!791 = !{!792, !792, i64 0}
!792 = !{!"float32", !793, i64 0}
!793 = !{!"0xa6def90", !8, i64 0}
!794 = !{!795, !795, i64 0}
!795 = !{!"0xa6d6ab0.w1.b0", !796, i64 0}
!796 = !{!"0xa6d6ab0.w2.b0", !797, i64 0}
!797 = !{!"0xa6d6ab0.w4.b0", !798, i64 0}
!798 = !{!"0xa6d6ab0.w8.b0", !799, i64 0}
!799 = !{!"0xa6d6ab0.w16.b0", !800, i64 0}
!800 = !{!"0xa6d6ab0.w32.b0", !801, i64 0}
!801 = !{!"0xa6d6ab0.w64.b0", !802, i64 0}
!802 = !{!"0xa6d6ab0.w128.b0", !803, i64 0}
!803 = !{!"0xa6d6ab0.w256.b0", !804, i64 0}
!804 = !{!"0xa6d6ab0.w512.b0", !805, i64 0}
!805 = !{!"0xa6d6ab0.w1024.b0", !806, i64 0}
!806 = !{!"int32", !807, i64 0}
!807 = !{!"0xa6d6ab0", !8, i64 0}
!808 = !{!809, !809, i64 0}
!809 = !{!"0xa6d6ab0.w1.b1", !796, i64 0}
!810 = !{!811, !811, i64 0}
!811 = !{!"0xa6d77c0.w1.b0", !812, i64 0}
!812 = !{!"0xa6d77c0.w2.b0", !813, i64 0}
!813 = !{!"0xa6d77c0.w4.b0", !814, i64 0}
!814 = !{!"0xa6d77c0.w8.b0", !815, i64 0}
!815 = !{!"0xa6d77c0.w16.b0", !816, i64 0}
!816 = !{!"0xa6d77c0.w32.b0", !817, i64 0}
!817 = !{!"0xa6d77c0.w64.b0", !818, i64 0}
!818 = !{!"0xa6d77c0.w128.b0", !819, i64 0}
!819 = !{!"0xa6d77c0.w256.b0", !820, i64 0}
!820 = !{!"0xa6d77c0.w512.b0", !821, i64 0}
!821 = !{!"0xa6d77c0.w1024.b0", !822, i64 0}
!822 = !{!"int64", !823, i64 0}
!823 = !{!"0xa6d77c0", !8, i64 0}
!824 = !{!825, !825, i64 0}
!825 = !{!"0xa6d77c0.w1.b1", !812, i64 0}
!826 = !{!827, !827, i64 0}
!827 = !{!"0xa6d77c0.w1.b2", !828, i64 0}
!828 = !{!"0xa6d77c0.w2.b2", !813, i64 0}
!829 = !{!830, !830, i64 0}
!830 = !{!"0xa6d77c0.w1.b3", !828, i64 0}
!831 = !{!832, !832, i64 0}
!832 = !{!"0xa6d77c0.w1.b4", !833, i64 0}
!833 = !{!"0xa6d77c0.w2.b4", !834, i64 0}
!834 = !{!"0xa6d77c0.w4.b4", !814, i64 0}
!835 = !{!836, !836, i64 0}
!836 = !{!"0xa6d4740.w4.b0", !837, i64 0}
!837 = !{!"0xa6d4740.w8.b0", !838, i64 0}
!838 = !{!"0xa6d4740.w16.b0", !839, i64 0}
!839 = !{!"0xa6d4740.w32.b0", !840, i64 0}
!840 = !{!"0xa6d4740.w64.b0", !841, i64 0}
!841 = !{!"0xa6d4740.w128.b0", !842, i64 0}
!842 = !{!"0xa6d4740.w256.b0", !843, i64 0}
!843 = !{!"0xa6d4740.w512.b0", !844, i64 0}
!844 = !{!"0xa6d4740.w1024.b0", !845, i64 0}
!845 = !{!"int64", !846, i64 0}
!846 = !{!"0xa6d4740", !8, i64 0}
!847 = !{!848, !848, i64 0}
!848 = !{!"0xa6d4740.w1.b4", !849, i64 0}
!849 = !{!"0xa6d4740.w2.b4", !850, i64 0}
!850 = !{!"0xa6d4740.w4.b4", !837, i64 0}
!851 = !{!852, !852, i64 0}
!852 = !{!"0xa6d9cf0.w1.b0", !853, i64 0}
!853 = !{!"0xa6d9cf0.w2.b0", !854, i64 0}
!854 = !{!"0xa6d9cf0.w4.b0", !855, i64 0}
!855 = !{!"0xa6d9cf0.w8.b0", !856, i64 0}
!856 = !{!"0xa6d9cf0.w16.b0", !857, i64 0}
!857 = !{!"0xa6d9cf0.w32.b0", !858, i64 0}
!858 = !{!"0xa6d9cf0.w64.b0", !859, i64 0}
!859 = !{!"0xa6d9cf0.w128.b0", !860, i64 0}
!860 = !{!"0xa6d9cf0.w256.b0", !861, i64 0}
!861 = !{!"0xa6d9cf0.w512.b0", !862, i64 0}
!862 = !{!"0xa6d9cf0.w1024.b0", !863, i64 0}
!863 = !{!"int64", !864, i64 0}
!864 = !{!"0xa6d9cf0", !8, i64 0}
!865 = !{!866, !866, i64 0}
!866 = !{!"0xa6d9cf0.w1.b1", !853, i64 0}
!867 = !{!868, !868, i64 0}
!868 = !{!"0xa6d9cf0.w1.b2", !869, i64 0}
!869 = !{!"0xa6d9cf0.w2.b2", !854, i64 0}
!870 = !{!871, !871, i64 0}
!871 = !{!"0xa6d9cf0.w1.b3", !869, i64 0}
!872 = !{!873, !873, i64 0}
!873 = !{!"0xa6d9cf0.w1.b4", !874, i64 0}
!874 = !{!"0xa6d9cf0.w2.b4", !875, i64 0}
!875 = !{!"0xa6d9cf0.w4.b4", !855, i64 0}
!876 = !{!877, !877, i64 0}
!877 = !{!"0xa6dacd0.w4.b0", !878, i64 0}
!878 = !{!"0xa6dacd0.w8.b0", !879, i64 0}
!879 = !{!"0xa6dacd0.w16.b0", !880, i64 0}
!880 = !{!"0xa6dacd0.w32.b0", !881, i64 0}
!881 = !{!"0xa6dacd0.w64.b0", !882, i64 0}
!882 = !{!"0xa6dacd0.w128.b0", !883, i64 0}
!883 = !{!"0xa6dacd0.w256.b0", !884, i64 0}
!884 = !{!"0xa6dacd0.w512.b0", !885, i64 0}
!885 = !{!"0xa6dacd0.w1024.b0", !886, i64 0}
!886 = !{!"int64", !887, i64 0}
!887 = !{!"0xa6dacd0", !8, i64 0}
!888 = !{!889, !889, i64 0}
!889 = !{!"0xa6dacd0.w1.b4", !890, i64 0}
!890 = !{!"0xa6dacd0.w2.b4", !891, i64 0}
!891 = !{!"0xa6dacd0.w4.b4", !878, i64 0}
!892 = !{!893, !893, i64 0}
!893 = !{!"float32", !894, i64 0}
!894 = !{!"0xc9c2450", !8, i64 0}
!895 = !{!896, !896, i64 0}
!896 = !{!"float32", !897, i64 0}
!897 = !{!"0xc9b2480", !8, i64 0}
!898 = !{!899, !899, i64 0}
!899 = !{!"0xc9b1710.w1.b0", !900, i64 0}
!900 = !{!"0xc9b1710.w2.b0", !901, i64 0}
!901 = !{!"0xc9b1710.w4.b0", !902, i64 0}
!902 = !{!"0xc9b1710.w8.b0", !903, i64 0}
!903 = !{!"0xc9b1710.w16.b0", !904, i64 0}
!904 = !{!"0xc9b1710.w32.b0", !905, i64 0}
!905 = !{!"0xc9b1710.w64.b0", !906, i64 0}
!906 = !{!"0xc9b1710.w128.b0", !907, i64 0}
!907 = !{!"0xc9b1710.w256.b0", !908, i64 0}
!908 = !{!"0xc9b1710.w512.b0", !909, i64 0}
!909 = !{!"0xc9b1710.w1024.b0", !910, i64 0}
!910 = !{!"int32", !911, i64 0}
!911 = !{!"0xc9b1710", !8, i64 0}
!912 = !{!913, !913, i64 0}
!913 = !{!"0xc9b1710.w1.b2", !914, i64 0}
!914 = !{!"0xc9b1710.w2.b2", !901, i64 0}
!915 = !{!916, !916, i64 0}
!916 = !{!"0xc9b1710.w1.b3", !914, i64 0}
!917 = !{!918, !918, i64 0}
!918 = !{!"0xc9b1710.w1.b4", !919, i64 0}
!919 = !{!"0xc9b1710.w2.b4", !920, i64 0}
!920 = !{!"0xc9b1710.w4.b4", !902, i64 0}
!921 = !{!922, !922, i64 0}
!922 = !{!"0xc9b1710.w1.b1", !900, i64 0}
!923 = !{!924, !924, i64 0}
!924 = !{!"0xc9c4bb0.w1.b0", !925, i64 0}
!925 = !{!"0xc9c4bb0.w2.b0", !926, i64 0}
!926 = !{!"0xc9c4bb0.w4.b0", !927, i64 0}
!927 = !{!"0xc9c4bb0.w8.b0", !928, i64 0}
!928 = !{!"0xc9c4bb0.w16.b0", !929, i64 0}
!929 = !{!"0xc9c4bb0.w32.b0", !930, i64 0}
!930 = !{!"0xc9c4bb0.w64.b0", !931, i64 0}
!931 = !{!"0xc9c4bb0.w128.b0", !932, i64 0}
!932 = !{!"0xc9c4bb0.w256.b0", !933, i64 0}
!933 = !{!"0xc9c4bb0.w512.b0", !934, i64 0}
!934 = !{!"0xc9c4bb0.w1024.b0", !935, i64 0}
!935 = !{!"int64", !936, i64 0}
!936 = !{!"0xc9c4bb0", !8, i64 0}
!937 = !{!938, !938, i64 0}
!938 = !{!"0xc9c4bb0.w1.b1", !925, i64 0}
!939 = !{!940, !940, i64 0}
!940 = !{!"0xc9c4bb0.w1.b2", !941, i64 0}
!941 = !{!"0xc9c4bb0.w2.b2", !926, i64 0}
!942 = !{!943, !943, i64 0}
!943 = !{!"0xc9c4bb0.w1.b3", !941, i64 0}
!944 = !{!945, !945, i64 0}
!945 = !{!"0xc9c4bb0.w1.b4", !946, i64 0}
!946 = !{!"0xc9c4bb0.w2.b4", !947, i64 0}
!947 = !{!"0xc9c4bb0.w4.b4", !927, i64 0}
!948 = !{!949, !949, i64 0}
!949 = !{!"0xc9c3300.w4.b0", !950, i64 0}
!950 = !{!"0xc9c3300.w8.b0", !951, i64 0}
!951 = !{!"0xc9c3300.w16.b0", !952, i64 0}
!952 = !{!"0xc9c3300.w32.b0", !953, i64 0}
!953 = !{!"0xc9c3300.w64.b0", !954, i64 0}
!954 = !{!"0xc9c3300.w128.b0", !955, i64 0}
!955 = !{!"0xc9c3300.w256.b0", !956, i64 0}
!956 = !{!"0xc9c3300.w512.b0", !957, i64 0}
!957 = !{!"0xc9c3300.w1024.b0", !958, i64 0}
!958 = !{!"int64", !959, i64 0}
!959 = !{!"0xc9c3300", !8, i64 0}
!960 = !{!961, !961, i64 0}
!961 = !{!"0xc9c3300.w1.b4", !962, i64 0}
!962 = !{!"0xc9c3300.w2.b4", !963, i64 0}
!963 = !{!"0xc9c3300.w4.b4", !950, i64 0}
!964 = !{!965, !965, i64 0}
!965 = !{!"0xc9c0b90.w1.b0", !966, i64 0}
!966 = !{!"0xc9c0b90.w2.b0", !967, i64 0}
!967 = !{!"0xc9c0b90.w4.b0", !968, i64 0}
!968 = !{!"0xc9c0b90.w8.b0", !969, i64 0}
!969 = !{!"0xc9c0b90.w16.b0", !970, i64 0}
!970 = !{!"0xc9c0b90.w32.b0", !971, i64 0}
!971 = !{!"0xc9c0b90.w64.b0", !972, i64 0}
!972 = !{!"0xc9c0b90.w128.b0", !973, i64 0}
!973 = !{!"0xc9c0b90.w256.b0", !974, i64 0}
!974 = !{!"0xc9c0b90.w512.b0", !975, i64 0}
!975 = !{!"0xc9c0b90.w1024.b0", !976, i64 0}
!976 = !{!"int64", !977, i64 0}
!977 = !{!"0xc9c0b90", !8, i64 0}
!978 = !{!979, !979, i64 0}
!979 = !{!"0xc9c0b90.w1.b1", !966, i64 0}
!980 = !{!981, !981, i64 0}
!981 = !{!"0xc9c0b90.w1.b2", !982, i64 0}
!982 = !{!"0xc9c0b90.w2.b2", !967, i64 0}
!983 = !{!984, !984, i64 0}
!984 = !{!"0xc9c0b90.w1.b3", !982, i64 0}
!985 = !{!986, !986, i64 0}
!986 = !{!"0xc9c0b90.w1.b4", !987, i64 0}
!987 = !{!"0xc9c0b90.w2.b4", !988, i64 0}
!988 = !{!"0xc9c0b90.w4.b4", !968, i64 0}
!989 = !{!990, !990, i64 0}
!990 = !{!"0xc9c0b90.w1.b5", !987, i64 0}
!991 = !{!992, !992, i64 0}
!992 = !{!"0xc9bf880.w4.b0", !993, i64 0}
!993 = !{!"0xc9bf880.w8.b0", !994, i64 0}
!994 = !{!"0xc9bf880.w16.b0", !995, i64 0}
!995 = !{!"0xc9bf880.w32.b0", !996, i64 0}
!996 = !{!"0xc9bf880.w64.b0", !997, i64 0}
!997 = !{!"0xc9bf880.w128.b0", !998, i64 0}
!998 = !{!"0xc9bf880.w256.b0", !999, i64 0}
!999 = !{!"0xc9bf880.w512.b0", !1000, i64 0}
!1000 = !{!"0xc9bf880.w1024.b0", !1001, i64 0}
!1001 = !{!"int64", !1002, i64 0}
!1002 = !{!"0xc9bf880", !8, i64 0}
!1003 = !{!1004, !1004, i64 0}
!1004 = !{!"0xc9bf880.w1.b4", !1005, i64 0}
!1005 = !{!"0xc9bf880.w2.b4", !1006, i64 0}
!1006 = !{!"0xc9bf880.w4.b4", !993, i64 0}
!1007 = !{!1008, !1008, i64 0}
!1008 = !{!"0xc9bf880.w1.b5", !1005, i64 0}
!1009 = !{!1010, !1010, i64 0}
!1010 = !{!"0xc9c0ff0.w1.b0", !1011, i64 0}
!1011 = !{!"0xc9c0ff0.w2.b0", !1012, i64 0}
!1012 = !{!"0xc9c0ff0.w4.b0", !1013, i64 0}
!1013 = !{!"0xc9c0ff0.w8.b0", !1014, i64 0}
!1014 = !{!"0xc9c0ff0.w16.b0", !1015, i64 0}
!1015 = !{!"0xc9c0ff0.w32.b0", !1016, i64 0}
!1016 = !{!"0xc9c0ff0.w64.b0", !1017, i64 0}
!1017 = !{!"0xc9c0ff0.w128.b0", !1018, i64 0}
!1018 = !{!"0xc9c0ff0.w256.b0", !1019, i64 0}
!1019 = !{!"0xc9c0ff0.w512.b0", !1020, i64 0}
!1020 = !{!"0xc9c0ff0.w1024.b0", !1021, i64 0}
!1021 = !{!"int64", !1022, i64 0}
!1022 = !{!"0xc9c0ff0", !8, i64 0}
!1023 = !{!1024, !1024, i64 0}
!1024 = !{!"0xc9c0ff0.w1.b1", !1011, i64 0}
!1025 = !{!1026, !1026, i64 0}
!1026 = !{!"0xc9c0ff0.w1.b2", !1027, i64 0}
!1027 = !{!"0xc9c0ff0.w2.b2", !1012, i64 0}
!1028 = !{!1029, !1029, i64 0}
!1029 = !{!"0xc9c0ff0.w1.b3", !1027, i64 0}
!1030 = !{!1031, !1031, i64 0}
!1031 = !{!"0xc9bd9c0.w4.b0", !1032, i64 0}
!1032 = !{!"0xc9bd9c0.w8.b0", !1033, i64 0}
!1033 = !{!"0xc9bd9c0.w16.b0", !1034, i64 0}
!1034 = !{!"0xc9bd9c0.w32.b0", !1035, i64 0}
!1035 = !{!"0xc9bd9c0.w64.b0", !1036, i64 0}
!1036 = !{!"0xc9bd9c0.w128.b0", !1037, i64 0}
!1037 = !{!"0xc9bd9c0.w256.b0", !1038, i64 0}
!1038 = !{!"0xc9bd9c0.w512.b0", !1039, i64 0}
!1039 = !{!"0xc9bd9c0.w1024.b0", !1040, i64 0}
!1040 = !{!"int64", !1041, i64 0}
!1041 = !{!"0xc9bd9c0", !8, i64 0}
!1042 = !{!1043, !1043, i64 0}
!1043 = !{!"0xc9bd750.w1.b0", !1044, i64 0}
!1044 = !{!"0xc9bd750.w2.b0", !1045, i64 0}
!1045 = !{!"0xc9bd750.w4.b0", !1046, i64 0}
!1046 = !{!"0xc9bd750.w8.b0", !1047, i64 0}
!1047 = !{!"0xc9bd750.w16.b0", !1048, i64 0}
!1048 = !{!"0xc9bd750.w32.b0", !1049, i64 0}
!1049 = !{!"0xc9bd750.w64.b0", !1050, i64 0}
!1050 = !{!"0xc9bd750.w128.b0", !1051, i64 0}
!1051 = !{!"0xc9bd750.w256.b0", !1052, i64 0}
!1052 = !{!"0xc9bd750.w512.b0", !1053, i64 0}
!1053 = !{!"0xc9bd750.w1024.b0", !1054, i64 0}
!1054 = !{!"int64", !1055, i64 0}
!1055 = !{!"0xc9bd750", !8, i64 0}
!1056 = !{!1057, !1057, i64 0}
!1057 = !{!"0xc9bd750.w1.b1", !1044, i64 0}
!1058 = !{!1059, !1059, i64 0}
!1059 = !{!"0xc9bd750.w1.b2", !1060, i64 0}
!1060 = !{!"0xc9bd750.w2.b2", !1045, i64 0}
!1061 = !{!1062, !1062, i64 0}
!1062 = !{!"0xc9bd750.w1.b3", !1060, i64 0}
!1063 = !{!1064, !1064, i64 0}
!1064 = !{!"0xa6d0310.w4.b0", !1065, i64 0}
!1065 = !{!"0xa6d0310.w8.b0", !1066, i64 0}
!1066 = !{!"0xa6d0310.w16.b0", !1067, i64 0}
!1067 = !{!"0xa6d0310.w32.b0", !1068, i64 0}
!1068 = !{!"0xa6d0310.w64.b0", !1069, i64 0}
!1069 = !{!"0xa6d0310.w128.b0", !1070, i64 0}
!1070 = !{!"0xa6d0310.w256.b0", !1071, i64 0}
!1071 = !{!"0xa6d0310.w512.b0", !1072, i64 0}
!1072 = !{!"0xa6d0310.w1024.b0", !1073, i64 0}
!1073 = !{!"int64", !1074, i64 0}
!1074 = !{!"0xa6d0310", !8, i64 0}
!1075 = !{!1076, !1076, i64 0}
!1076 = !{!"0xa6d23f0.w1.b0", !1077, i64 0}
!1077 = !{!"0xa6d23f0.w2.b0", !1078, i64 0}
!1078 = !{!"0xa6d23f0.w4.b0", !1079, i64 0}
!1079 = !{!"0xa6d23f0.w8.b0", !1080, i64 0}
!1080 = !{!"0xa6d23f0.w16.b0", !1081, i64 0}
!1081 = !{!"0xa6d23f0.w32.b0", !1082, i64 0}
!1082 = !{!"0xa6d23f0.w64.b0", !1083, i64 0}
!1083 = !{!"0xa6d23f0.w128.b0", !1084, i64 0}
!1084 = !{!"0xa6d23f0.w256.b0", !1085, i64 0}
!1085 = !{!"0xa6d23f0.w512.b0", !1086, i64 0}
!1086 = !{!"0xa6d23f0.w1024.b0", !1087, i64 0}
!1087 = !{!"int64", !1088, i64 0}
!1088 = !{!"0xa6d23f0", !8, i64 0}
!1089 = !{!1090, !1090, i64 0}
!1090 = !{!"0xa6d23f0.w1.b1", !1077, i64 0}
!1091 = !{!1092, !1092, i64 0}
!1092 = !{!"0xa6d23f0.w1.b2", !1093, i64 0}
!1093 = !{!"0xa6d23f0.w2.b2", !1078, i64 0}
!1094 = !{!1095, !1095, i64 0}
!1095 = !{!"0xa6d23f0.w1.b3", !1093, i64 0}
!1096 = !{!1097, !1097, i64 0}
!1097 = !{!"0xa6d23f0.w1.b4", !1098, i64 0}
!1098 = !{!"0xa6d23f0.w2.b4", !1099, i64 0}
!1099 = !{!"0xa6d23f0.w4.b4", !1079, i64 0}
!1100 = !{!1101, !1101, i64 0}
!1101 = !{!"0xa6d31f0.w4.b0", !1102, i64 0}
!1102 = !{!"0xa6d31f0.w8.b0", !1103, i64 0}
!1103 = !{!"0xa6d31f0.w16.b0", !1104, i64 0}
!1104 = !{!"0xa6d31f0.w32.b0", !1105, i64 0}
!1105 = !{!"0xa6d31f0.w64.b0", !1106, i64 0}
!1106 = !{!"0xa6d31f0.w128.b0", !1107, i64 0}
!1107 = !{!"0xa6d31f0.w256.b0", !1108, i64 0}
!1108 = !{!"0xa6d31f0.w512.b0", !1109, i64 0}
!1109 = !{!"0xa6d31f0.w1024.b0", !1110, i64 0}
!1110 = !{!"int64", !1111, i64 0}
!1111 = !{!"0xa6d31f0", !8, i64 0}
!1112 = !{!1113, !1113, i64 0}
!1113 = !{!"0xa6d31f0.w1.b4", !1114, i64 0}
!1114 = !{!"0xa6d31f0.w2.b4", !1115, i64 0}
!1115 = !{!"0xa6d31f0.w4.b4", !1102, i64 0}
!1116 = !{!1117, !1117, i64 0}
!1117 = !{!"float32", !1118, i64 0}
!1118 = !{!"0xc9b9a10", !8, i64 0}
!1119 = !{!1120, !1120, i64 0}
!1120 = !{!"float32", !1121, i64 0}
!1121 = !{!"0xc9b4400", !8, i64 0}
!1122 = distinct !{!1122, !1123}
!1123 = !{!"llvm.loop.isvectorized", i32 1}
!1124 = !{!1125, !1125, i64 0}
!1125 = !{!"float32", !1126, i64 0}
!1126 = !{!"0xc9b2ab0", !8, i64 0}
!1127 = !{!1128, !1128, i64 0}
!1128 = !{!"float32", !1129, i64 0}
!1129 = !{!"0xc9b2d10", !8, i64 0}
!1130 = !{!1131, !1131, i64 0}
!1131 = !{!"float32", !1132, i64 0}
!1132 = !{!"0xc9b4980", !8, i64 0}
!1133 = !{!1134, !1134, i64 0}
!1134 = !{!"float32", !1135, i64 0}
!1135 = !{!"0xc9c0e90", !8, i64 0}
!1136 = !{!1137, !1137, i64 0}
!1137 = !{!"float32", !1138, i64 0}
!1138 = !{!"0xc9b2f70", !8, i64 0}
!1139 = !{!1140, !1140, i64 0}
!1140 = !{!"0xc9c07f0.w32.b0", !1141, i64 0}
!1141 = !{!"0xc9c07f0.w64.b0", !1142, i64 0}
!1142 = !{!"0xc9c07f0.w128.b0", !1143, i64 0}
!1143 = !{!"0xc9c07f0.w256.b0", !1144, i64 0}
!1144 = !{!"0xc9c07f0.w512.b0", !1145, i64 0}
!1145 = !{!"0xc9c07f0.w1024.b0", !1146, i64 0}
!1146 = !{!"float32", !1147, i64 0}
!1147 = !{!"0xc9c07f0", !8, i64 0}
!1148 = !{!1149, !1149, i64 0}
!1149 = !{!"0xc996430.w1.b0", !1150, i64 0}
!1150 = !{!"0xc996430.w2.b0", !1151, i64 0}
!1151 = !{!"0xc996430.w4.b0", !1152, i64 0}
!1152 = !{!"0xc996430.w8.b0", !1153, i64 0}
!1153 = !{!"0xc996430.w16.b0", !1154, i64 0}
!1154 = !{!"0xc996430.w32.b0", !1155, i64 0}
!1155 = !{!"0xc996430.w64.b0", !1156, i64 0}
!1156 = !{!"0xc996430.w128.b0", !1157, i64 0}
!1157 = !{!"0xc996430.w256.b0", !1158, i64 0}
!1158 = !{!"0xc996430.w512.b0", !1159, i64 0}
!1159 = !{!"0xc996430.w1024.b0", !1160, i64 0}
!1160 = !{!"int32", !1161, i64 0}
!1161 = !{!"0xc996430", !8, i64 0}
!1162 = !{!1163, !1163, i64 0}
!1163 = !{!"0xc996430.w1.b1", !1150, i64 0}
!1164 = !{!1165, !1165, i64 0}
!1165 = !{!"0xc998360.w1.b0", !1166, i64 0}
!1166 = !{!"0xc998360.w2.b0", !1167, i64 0}
!1167 = !{!"0xc998360.w4.b0", !1168, i64 0}
!1168 = !{!"0xc998360.w8.b0", !1169, i64 0}
!1169 = !{!"0xc998360.w16.b0", !1170, i64 0}
!1170 = !{!"0xc998360.w32.b0", !1171, i64 0}
!1171 = !{!"0xc998360.w64.b0", !1172, i64 0}
!1172 = !{!"0xc998360.w128.b0", !1173, i64 0}
!1173 = !{!"0xc998360.w256.b0", !1174, i64 0}
!1174 = !{!"0xc998360.w512.b0", !1175, i64 0}
!1175 = !{!"0xc998360.w1024.b0", !1176, i64 0}
!1176 = !{!"int64", !1177, i64 0}
!1177 = !{!"0xc998360", !8, i64 0}
!1178 = !{!1179, !1179, i64 0}
!1179 = !{!"0xc998360.w1.b1", !1166, i64 0}
!1180 = !{!1181, !1181, i64 0}
!1181 = !{!"0xc998360.w1.b2", !1182, i64 0}
!1182 = !{!"0xc998360.w2.b2", !1167, i64 0}
!1183 = !{!1184, !1184, i64 0}
!1184 = !{!"0xc998360.w1.b3", !1182, i64 0}
!1185 = !{!1186, !1186, i64 0}
!1186 = !{!"0xc998360.w1.b4", !1187, i64 0}
!1187 = !{!"0xc998360.w2.b4", !1188, i64 0}
!1188 = !{!"0xc998360.w4.b4", !1168, i64 0}
!1189 = !{!1190, !1190, i64 0}
!1190 = !{!"0xc9ab480.w4.b0", !1191, i64 0}
!1191 = !{!"0xc9ab480.w8.b0", !1192, i64 0}
!1192 = !{!"0xc9ab480.w16.b0", !1193, i64 0}
!1193 = !{!"0xc9ab480.w32.b0", !1194, i64 0}
!1194 = !{!"0xc9ab480.w64.b0", !1195, i64 0}
!1195 = !{!"0xc9ab480.w128.b0", !1196, i64 0}
!1196 = !{!"0xc9ab480.w256.b0", !1197, i64 0}
!1197 = !{!"0xc9ab480.w512.b0", !1198, i64 0}
!1198 = !{!"0xc9ab480.w1024.b0", !1199, i64 0}
!1199 = !{!"int64", !1200, i64 0}
!1200 = !{!"0xc9ab480", !8, i64 0}
!1201 = !{!1202, !1202, i64 0}
!1202 = !{!"0xc9ab480.w1.b4", !1203, i64 0}
!1203 = !{!"0xc9ab480.w2.b4", !1204, i64 0}
!1204 = !{!"0xc9ab480.w4.b4", !1191, i64 0}
!1205 = !{!1206, !1206, i64 0}
!1206 = !{!"0xc9ad260.w1.b0", !1207, i64 0}
!1207 = !{!"0xc9ad260.w2.b0", !1208, i64 0}
!1208 = !{!"0xc9ad260.w4.b0", !1209, i64 0}
!1209 = !{!"0xc9ad260.w8.b0", !1210, i64 0}
!1210 = !{!"0xc9ad260.w16.b0", !1211, i64 0}
!1211 = !{!"0xc9ad260.w32.b0", !1212, i64 0}
!1212 = !{!"0xc9ad260.w64.b0", !1213, i64 0}
!1213 = !{!"0xc9ad260.w128.b0", !1214, i64 0}
!1214 = !{!"0xc9ad260.w256.b0", !1215, i64 0}
!1215 = !{!"0xc9ad260.w512.b0", !1216, i64 0}
!1216 = !{!"0xc9ad260.w1024.b0", !1217, i64 0}
!1217 = !{!"int64", !1218, i64 0}
!1218 = !{!"0xc9ad260", !8, i64 0}
!1219 = !{!1220, !1220, i64 0}
!1220 = !{!"0xc9ad260.w1.b1", !1207, i64 0}
!1221 = !{!1222, !1222, i64 0}
!1222 = !{!"0xc9ad260.w1.b2", !1223, i64 0}
!1223 = !{!"0xc9ad260.w2.b2", !1208, i64 0}
!1224 = !{!1225, !1225, i64 0}
!1225 = !{!"0xc9ad260.w1.b3", !1223, i64 0}
!1226 = !{!1227, !1227, i64 0}
!1227 = !{!"0xc9ad260.w1.b4", !1228, i64 0}
!1228 = !{!"0xc9ad260.w2.b4", !1229, i64 0}
!1229 = !{!"0xc9ad260.w4.b4", !1209, i64 0}
!1230 = !{!1231, !1231, i64 0}
!1231 = !{!"0xc9ae2d0.w4.b0", !1232, i64 0}
!1232 = !{!"0xc9ae2d0.w8.b0", !1233, i64 0}
!1233 = !{!"0xc9ae2d0.w16.b0", !1234, i64 0}
!1234 = !{!"0xc9ae2d0.w32.b0", !1235, i64 0}
!1235 = !{!"0xc9ae2d0.w64.b0", !1236, i64 0}
!1236 = !{!"0xc9ae2d0.w128.b0", !1237, i64 0}
!1237 = !{!"0xc9ae2d0.w256.b0", !1238, i64 0}
!1238 = !{!"0xc9ae2d0.w512.b0", !1239, i64 0}
!1239 = !{!"0xc9ae2d0.w1024.b0", !1240, i64 0}
!1240 = !{!"int64", !1241, i64 0}
!1241 = !{!"0xc9ae2d0", !8, i64 0}
!1242 = !{!1243, !1243, i64 0}
!1243 = !{!"0xc9ae2d0.w1.b4", !1244, i64 0}
!1244 = !{!"0xc9ae2d0.w2.b4", !1245, i64 0}
!1245 = !{!"0xc9ae2d0.w4.b4", !1232, i64 0}
!1246 = !{!1247, !1247, i64 0}
!1247 = !{!"float32", !1248, i64 0}
!1248 = !{!"0xc993ed0", !8, i64 0}
!1249 = !{!1250, !1250, i64 0}
!1250 = !{!"float32", !1251, i64 0}
!1251 = !{!"0xcaaca70", !8, i64 0}
!1252 = !{!1253, !1253, i64 0}
!1253 = !{!"0xca91e70.w1.b0", !1254, i64 0}
!1254 = !{!"0xca91e70.w2.b0", !1255, i64 0}
!1255 = !{!"0xca91e70.w4.b0", !1256, i64 0}
!1256 = !{!"0xca91e70.w8.b0", !1257, i64 0}
!1257 = !{!"0xca91e70.w16.b0", !1258, i64 0}
!1258 = !{!"0xca91e70.w32.b0", !1259, i64 0}
!1259 = !{!"0xca91e70.w64.b0", !1260, i64 0}
!1260 = !{!"0xca91e70.w128.b0", !1261, i64 0}
!1261 = !{!"0xca91e70.w256.b0", !1262, i64 0}
!1262 = !{!"0xca91e70.w512.b0", !1263, i64 0}
!1263 = !{!"0xca91e70.w1024.b0", !1264, i64 0}
!1264 = !{!"int32", !1265, i64 0}
!1265 = !{!"0xca91e70", !8, i64 0}
!1266 = !{!1267, !1267, i64 0}
!1267 = !{!"0xca91e70.w1.b1", !1254, i64 0}
!1268 = !{!1269, !1269, i64 0}
!1269 = !{!"0xca9a820.w1.b0", !1270, i64 0}
!1270 = !{!"0xca9a820.w2.b0", !1271, i64 0}
!1271 = !{!"0xca9a820.w4.b0", !1272, i64 0}
!1272 = !{!"0xca9a820.w8.b0", !1273, i64 0}
!1273 = !{!"0xca9a820.w16.b0", !1274, i64 0}
!1274 = !{!"0xca9a820.w32.b0", !1275, i64 0}
!1275 = !{!"0xca9a820.w64.b0", !1276, i64 0}
!1276 = !{!"0xca9a820.w128.b0", !1277, i64 0}
!1277 = !{!"0xca9a820.w256.b0", !1278, i64 0}
!1278 = !{!"0xca9a820.w512.b0", !1279, i64 0}
!1279 = !{!"0xca9a820.w1024.b0", !1280, i64 0}
!1280 = !{!"int64", !1281, i64 0}
!1281 = !{!"0xca9a820", !8, i64 0}
!1282 = !{!1283, !1283, i64 0}
!1283 = !{!"0xca9a820.w1.b1", !1270, i64 0}
!1284 = !{!1285, !1285, i64 0}
!1285 = !{!"0xca9a820.w1.b2", !1286, i64 0}
!1286 = !{!"0xca9a820.w2.b2", !1271, i64 0}
!1287 = !{!1288, !1288, i64 0}
!1288 = !{!"0xca9a820.w1.b3", !1286, i64 0}
!1289 = !{!1290, !1290, i64 0}
!1290 = !{!"0xca9a820.w1.b4", !1291, i64 0}
!1291 = !{!"0xca9a820.w2.b4", !1292, i64 0}
!1292 = !{!"0xca9a820.w4.b4", !1272, i64 0}
!1293 = !{!1294, !1294, i64 0}
!1294 = !{!"0xca99980.w4.b0", !1295, i64 0}
!1295 = !{!"0xca99980.w8.b0", !1296, i64 0}
!1296 = !{!"0xca99980.w16.b0", !1297, i64 0}
!1297 = !{!"0xca99980.w32.b0", !1298, i64 0}
!1298 = !{!"0xca99980.w64.b0", !1299, i64 0}
!1299 = !{!"0xca99980.w128.b0", !1300, i64 0}
!1300 = !{!"0xca99980.w256.b0", !1301, i64 0}
!1301 = !{!"0xca99980.w512.b0", !1302, i64 0}
!1302 = !{!"0xca99980.w1024.b0", !1303, i64 0}
!1303 = !{!"int64", !1304, i64 0}
!1304 = !{!"0xca99980", !8, i64 0}
!1305 = !{!1306, !1306, i64 0}
!1306 = !{!"0xca99980.w1.b4", !1307, i64 0}
!1307 = !{!"0xca99980.w2.b4", !1308, i64 0}
!1308 = !{!"0xca99980.w4.b4", !1295, i64 0}
!1309 = !{!1310, !1310, i64 0}
!1310 = !{!"0xca9cdc0.w1.b0", !1311, i64 0}
!1311 = !{!"0xca9cdc0.w2.b0", !1312, i64 0}
!1312 = !{!"0xca9cdc0.w4.b0", !1313, i64 0}
!1313 = !{!"0xca9cdc0.w8.b0", !1314, i64 0}
!1314 = !{!"0xca9cdc0.w16.b0", !1315, i64 0}
!1315 = !{!"0xca9cdc0.w32.b0", !1316, i64 0}
!1316 = !{!"0xca9cdc0.w64.b0", !1317, i64 0}
!1317 = !{!"0xca9cdc0.w128.b0", !1318, i64 0}
!1318 = !{!"0xca9cdc0.w256.b0", !1319, i64 0}
!1319 = !{!"0xca9cdc0.w512.b0", !1320, i64 0}
!1320 = !{!"0xca9cdc0.w1024.b0", !1321, i64 0}
!1321 = !{!"int64", !1322, i64 0}
!1322 = !{!"0xca9cdc0", !8, i64 0}
!1323 = !{!1324, !1324, i64 0}
!1324 = !{!"0xca9cdc0.w1.b1", !1311, i64 0}
!1325 = !{!1326, !1326, i64 0}
!1326 = !{!"0xca9cdc0.w1.b2", !1327, i64 0}
!1327 = !{!"0xca9cdc0.w2.b2", !1312, i64 0}
!1328 = !{!1329, !1329, i64 0}
!1329 = !{!"0xca9cdc0.w1.b3", !1327, i64 0}
!1330 = !{!1331, !1331, i64 0}
!1331 = !{!"0xca9cdc0.w1.b4", !1332, i64 0}
!1332 = !{!"0xca9cdc0.w2.b4", !1333, i64 0}
!1333 = !{!"0xca9cdc0.w4.b4", !1313, i64 0}
!1334 = !{!1335, !1335, i64 0}
!1335 = !{!"0xca9ddf0.w4.b0", !1336, i64 0}
!1336 = !{!"0xca9ddf0.w8.b0", !1337, i64 0}
!1337 = !{!"0xca9ddf0.w16.b0", !1338, i64 0}
!1338 = !{!"0xca9ddf0.w32.b0", !1339, i64 0}
!1339 = !{!"0xca9ddf0.w64.b0", !1340, i64 0}
!1340 = !{!"0xca9ddf0.w128.b0", !1341, i64 0}
!1341 = !{!"0xca9ddf0.w256.b0", !1342, i64 0}
!1342 = !{!"0xca9ddf0.w512.b0", !1343, i64 0}
!1343 = !{!"0xca9ddf0.w1024.b0", !1344, i64 0}
!1344 = !{!"int64", !1345, i64 0}
!1345 = !{!"0xca9ddf0", !8, i64 0}
!1346 = !{!1347, !1347, i64 0}
!1347 = !{!"0xca9ddf0.w1.b4", !1348, i64 0}
!1348 = !{!"0xca9ddf0.w2.b4", !1349, i64 0}
!1349 = !{!"0xca9ddf0.w4.b4", !1336, i64 0}
!1350 = !{!1351, !1351, i64 0}
!1351 = !{!"float32", !1352, i64 0}
!1352 = !{!"0xca83ac0", !8, i64 0}
!1353 = !{!1354, !1354, i64 0}
!1354 = !{!"float32", !1355, i64 0}
!1355 = !{!"0xca8b8b0", !8, i64 0}
!1356 = !{!1357, !1357, i64 0}
!1357 = !{!"0x913e3d0.w1.b0", !1358, i64 0}
!1358 = !{!"0x913e3d0.w2.b0", !1359, i64 0}
!1359 = !{!"0x913e3d0.w4.b0", !1360, i64 0}
!1360 = !{!"0x913e3d0.w8.b0", !1361, i64 0}
!1361 = !{!"0x913e3d0.w16.b0", !1362, i64 0}
!1362 = !{!"0x913e3d0.w32.b0", !1363, i64 0}
!1363 = !{!"0x913e3d0.w64.b0", !1364, i64 0}
!1364 = !{!"0x913e3d0.w128.b0", !1365, i64 0}
!1365 = !{!"0x913e3d0.w256.b0", !1366, i64 0}
!1366 = !{!"0x913e3d0.w512.b0", !1367, i64 0}
!1367 = !{!"0x913e3d0.w1024.b0", !1368, i64 0}
!1368 = !{!"int32", !1369, i64 0}
!1369 = !{!"0x913e3d0", !8, i64 0}
!1370 = !{!1371, !1371, i64 0}
!1371 = !{!"0x913e3d0.w1.b2", !1372, i64 0}
!1372 = !{!"0x913e3d0.w2.b2", !1359, i64 0}
!1373 = !{!1374, !1374, i64 0}
!1374 = !{!"0x913e3d0.w1.b3", !1372, i64 0}
!1375 = !{!1376, !1376, i64 0}
!1376 = !{!"0x913e3d0.w1.b4", !1377, i64 0}
!1377 = !{!"0x913e3d0.w2.b4", !1378, i64 0}
!1378 = !{!"0x913e3d0.w4.b4", !1360, i64 0}
!1379 = !{!1380, !1380, i64 0}
!1380 = !{!"0x913e3d0.w1.b5", !1377, i64 0}
!1381 = !{!1382, !1382, i64 0}
!1382 = !{!"0x913e3d0.w1.b1", !1358, i64 0}
!1383 = !{!1384, !1384, i64 0}
!1384 = !{!"0x91430a0.w1.b0", !1385, i64 0}
!1385 = !{!"0x91430a0.w2.b0", !1386, i64 0}
!1386 = !{!"0x91430a0.w4.b0", !1387, i64 0}
!1387 = !{!"0x91430a0.w8.b0", !1388, i64 0}
!1388 = !{!"0x91430a0.w16.b0", !1389, i64 0}
!1389 = !{!"0x91430a0.w32.b0", !1390, i64 0}
!1390 = !{!"0x91430a0.w64.b0", !1391, i64 0}
!1391 = !{!"0x91430a0.w128.b0", !1392, i64 0}
!1392 = !{!"0x91430a0.w256.b0", !1393, i64 0}
!1393 = !{!"0x91430a0.w512.b0", !1394, i64 0}
!1394 = !{!"0x91430a0.w1024.b0", !1395, i64 0}
!1395 = !{!"int64", !1396, i64 0}
!1396 = !{!"0x91430a0", !8, i64 0}
!1397 = !{!1398, !1398, i64 0}
!1398 = !{!"0x91430a0.w1.b1", !1385, i64 0}
!1399 = !{!1400, !1400, i64 0}
!1400 = !{!"0x91430a0.w1.b2", !1401, i64 0}
!1401 = !{!"0x91430a0.w2.b2", !1386, i64 0}
!1402 = !{!1403, !1403, i64 0}
!1403 = !{!"0x91430a0.w1.b3", !1401, i64 0}
!1404 = !{!1405, !1405, i64 0}
!1405 = !{!"0x91430a0.w1.b4", !1406, i64 0}
!1406 = !{!"0x91430a0.w2.b4", !1407, i64 0}
!1407 = !{!"0x91430a0.w4.b4", !1387, i64 0}
!1408 = !{!1409, !1409, i64 0}
!1409 = !{!"0x9145cd0.w4.b0", !1410, i64 0}
!1410 = !{!"0x9145cd0.w8.b0", !1411, i64 0}
!1411 = !{!"0x9145cd0.w16.b0", !1412, i64 0}
!1412 = !{!"0x9145cd0.w32.b0", !1413, i64 0}
!1413 = !{!"0x9145cd0.w64.b0", !1414, i64 0}
!1414 = !{!"0x9145cd0.w128.b0", !1415, i64 0}
!1415 = !{!"0x9145cd0.w256.b0", !1416, i64 0}
!1416 = !{!"0x9145cd0.w512.b0", !1417, i64 0}
!1417 = !{!"0x9145cd0.w1024.b0", !1418, i64 0}
!1418 = !{!"int64", !1419, i64 0}
!1419 = !{!"0x9145cd0", !8, i64 0}
!1420 = !{!1421, !1421, i64 0}
!1421 = !{!"0x9145cd0.w1.b4", !1422, i64 0}
!1422 = !{!"0x9145cd0.w2.b4", !1423, i64 0}
!1423 = !{!"0x9145cd0.w4.b4", !1410, i64 0}
!1424 = !{!1425, !1425, i64 0}
!1425 = !{!"0x9146d00.w1.b0", !1426, i64 0}
!1426 = !{!"0x9146d00.w2.b0", !1427, i64 0}
!1427 = !{!"0x9146d00.w4.b0", !1428, i64 0}
!1428 = !{!"0x9146d00.w8.b0", !1429, i64 0}
!1429 = !{!"0x9146d00.w16.b0", !1430, i64 0}
!1430 = !{!"0x9146d00.w32.b0", !1431, i64 0}
!1431 = !{!"0x9146d00.w64.b0", !1432, i64 0}
!1432 = !{!"0x9146d00.w128.b0", !1433, i64 0}
!1433 = !{!"0x9146d00.w256.b0", !1434, i64 0}
!1434 = !{!"0x9146d00.w512.b0", !1435, i64 0}
!1435 = !{!"0x9146d00.w1024.b0", !1436, i64 0}
!1436 = !{!"int64", !1437, i64 0}
!1437 = !{!"0x9146d00", !8, i64 0}
!1438 = !{!1439, !1439, i64 0}
!1439 = !{!"0x9146d00.w1.b1", !1426, i64 0}
!1440 = !{!1441, !1441, i64 0}
!1441 = !{!"0x9146d00.w1.b2", !1442, i64 0}
!1442 = !{!"0x9146d00.w2.b2", !1427, i64 0}
!1443 = !{!1444, !1444, i64 0}
!1444 = !{!"0x9146d00.w1.b3", !1442, i64 0}
!1445 = !{!1446, !1446, i64 0}
!1446 = !{!"0x9146d00.w1.b4", !1447, i64 0}
!1447 = !{!"0x9146d00.w2.b4", !1448, i64 0}
!1448 = !{!"0x9146d00.w4.b4", !1428, i64 0}
!1449 = !{!1450, !1450, i64 0}
!1450 = !{!"0x9146d00.w1.b5", !1447, i64 0}
!1451 = !{!1452, !1452, i64 0}
!1452 = !{!"0x91480d0.w4.b0", !1453, i64 0}
!1453 = !{!"0x91480d0.w8.b0", !1454, i64 0}
!1454 = !{!"0x91480d0.w16.b0", !1455, i64 0}
!1455 = !{!"0x91480d0.w32.b0", !1456, i64 0}
!1456 = !{!"0x91480d0.w64.b0", !1457, i64 0}
!1457 = !{!"0x91480d0.w128.b0", !1458, i64 0}
!1458 = !{!"0x91480d0.w256.b0", !1459, i64 0}
!1459 = !{!"0x91480d0.w512.b0", !1460, i64 0}
!1460 = !{!"0x91480d0.w1024.b0", !1461, i64 0}
!1461 = !{!"int64", !1462, i64 0}
!1462 = !{!"0x91480d0", !8, i64 0}
!1463 = !{!1464, !1464, i64 0}
!1464 = !{!"0x91480d0.w1.b4", !1465, i64 0}
!1465 = !{!"0x91480d0.w2.b4", !1466, i64 0}
!1466 = !{!"0x91480d0.w4.b4", !1453, i64 0}
!1467 = !{!1468, !1468, i64 0}
!1468 = !{!"0x91480d0.w1.b5", !1465, i64 0}
!1469 = !{!1470, !1470, i64 0}
!1470 = !{!"0x914a440.w1.b0", !1471, i64 0}
!1471 = !{!"0x914a440.w2.b0", !1472, i64 0}
!1472 = !{!"0x914a440.w4.b0", !1473, i64 0}
!1473 = !{!"0x914a440.w8.b0", !1474, i64 0}
!1474 = !{!"0x914a440.w16.b0", !1475, i64 0}
!1475 = !{!"0x914a440.w32.b0", !1476, i64 0}
!1476 = !{!"0x914a440.w64.b0", !1477, i64 0}
!1477 = !{!"0x914a440.w128.b0", !1478, i64 0}
!1478 = !{!"0x914a440.w256.b0", !1479, i64 0}
!1479 = !{!"0x914a440.w512.b0", !1480, i64 0}
!1480 = !{!"0x914a440.w1024.b0", !1481, i64 0}
!1481 = !{!"int64", !1482, i64 0}
!1482 = !{!"0x914a440", !8, i64 0}
!1483 = !{!1484, !1484, i64 0}
!1484 = !{!"0x914a440.w1.b1", !1471, i64 0}
!1485 = !{!1486, !1486, i64 0}
!1486 = !{!"0x914a440.w1.b2", !1487, i64 0}
!1487 = !{!"0x914a440.w2.b2", !1472, i64 0}
!1488 = !{!1489, !1489, i64 0}
!1489 = !{!"0x914a440.w1.b3", !1487, i64 0}
!1490 = !{!1491, !1491, i64 0}
!1491 = !{!"0x914afe0.w4.b0", !1492, i64 0}
!1492 = !{!"0x914afe0.w8.b0", !1493, i64 0}
!1493 = !{!"0x914afe0.w16.b0", !1494, i64 0}
!1494 = !{!"0x914afe0.w32.b0", !1495, i64 0}
!1495 = !{!"0x914afe0.w64.b0", !1496, i64 0}
!1496 = !{!"0x914afe0.w128.b0", !1497, i64 0}
!1497 = !{!"0x914afe0.w256.b0", !1498, i64 0}
!1498 = !{!"0x914afe0.w512.b0", !1499, i64 0}
!1499 = !{!"0x914afe0.w1024.b0", !1500, i64 0}
!1500 = !{!"int64", !1501, i64 0}
!1501 = !{!"0x914afe0", !8, i64 0}
!1502 = !{!1503, !1503, i64 0}
!1503 = !{!"0x913e110.w1.b0", !1504, i64 0}
!1504 = !{!"0x913e110.w2.b0", !1505, i64 0}
!1505 = !{!"0x913e110.w4.b0", !1506, i64 0}
!1506 = !{!"0x913e110.w8.b0", !1507, i64 0}
!1507 = !{!"0x913e110.w16.b0", !1508, i64 0}
!1508 = !{!"0x913e110.w32.b0", !1509, i64 0}
!1509 = !{!"0x913e110.w64.b0", !1510, i64 0}
!1510 = !{!"0x913e110.w128.b0", !1511, i64 0}
!1511 = !{!"0x913e110.w256.b0", !1512, i64 0}
!1512 = !{!"0x913e110.w512.b0", !1513, i64 0}
!1513 = !{!"0x913e110.w1024.b0", !1514, i64 0}
!1514 = !{!"int64", !1515, i64 0}
!1515 = !{!"0x913e110", !8, i64 0}
!1516 = !{!1517, !1517, i64 0}
!1517 = !{!"0x913e110.w1.b1", !1504, i64 0}
!1518 = !{!1519, !1519, i64 0}
!1519 = !{!"0x913e110.w1.b2", !1520, i64 0}
!1520 = !{!"0x913e110.w2.b2", !1505, i64 0}
!1521 = !{!1522, !1522, i64 0}
!1522 = !{!"0x913e110.w1.b3", !1520, i64 0}
!1523 = !{!1524, !1524, i64 0}
!1524 = !{!"0x914dd70.w4.b0", !1525, i64 0}
!1525 = !{!"0x914dd70.w8.b0", !1526, i64 0}
!1526 = !{!"0x914dd70.w16.b0", !1527, i64 0}
!1527 = !{!"0x914dd70.w32.b0", !1528, i64 0}
!1528 = !{!"0x914dd70.w64.b0", !1529, i64 0}
!1529 = !{!"0x914dd70.w128.b0", !1530, i64 0}
!1530 = !{!"0x914dd70.w256.b0", !1531, i64 0}
!1531 = !{!"0x914dd70.w512.b0", !1532, i64 0}
!1532 = !{!"0x914dd70.w1024.b0", !1533, i64 0}
!1533 = !{!"int64", !1534, i64 0}
!1534 = !{!"0x914dd70", !8, i64 0}
!1535 = !{!1536, !1536, i64 0}
!1536 = !{!"0x914fe50.w1.b0", !1537, i64 0}
!1537 = !{!"0x914fe50.w2.b0", !1538, i64 0}
!1538 = !{!"0x914fe50.w4.b0", !1539, i64 0}
!1539 = !{!"0x914fe50.w8.b0", !1540, i64 0}
!1540 = !{!"0x914fe50.w16.b0", !1541, i64 0}
!1541 = !{!"0x914fe50.w32.b0", !1542, i64 0}
!1542 = !{!"0x914fe50.w64.b0", !1543, i64 0}
!1543 = !{!"0x914fe50.w128.b0", !1544, i64 0}
!1544 = !{!"0x914fe50.w256.b0", !1545, i64 0}
!1545 = !{!"0x914fe50.w512.b0", !1546, i64 0}
!1546 = !{!"0x914fe50.w1024.b0", !1547, i64 0}
!1547 = !{!"int64", !1548, i64 0}
!1548 = !{!"0x914fe50", !8, i64 0}
!1549 = !{!1550, !1550, i64 0}
!1550 = !{!"0x914fe50.w1.b1", !1537, i64 0}
!1551 = !{!1552, !1552, i64 0}
!1552 = !{!"0x914fe50.w1.b2", !1553, i64 0}
!1553 = !{!"0x914fe50.w2.b2", !1538, i64 0}
!1554 = !{!1555, !1555, i64 0}
!1555 = !{!"0x914fe50.w1.b3", !1553, i64 0}
!1556 = !{!1557, !1557, i64 0}
!1557 = !{!"0x9150ad0.w4.b0", !1558, i64 0}
!1558 = !{!"0x9150ad0.w8.b0", !1559, i64 0}
!1559 = !{!"0x9150ad0.w16.b0", !1560, i64 0}
!1560 = !{!"0x9150ad0.w32.b0", !1561, i64 0}
!1561 = !{!"0x9150ad0.w64.b0", !1562, i64 0}
!1562 = !{!"0x9150ad0.w128.b0", !1563, i64 0}
!1563 = !{!"0x9150ad0.w256.b0", !1564, i64 0}
!1564 = !{!"0x9150ad0.w512.b0", !1565, i64 0}
!1565 = !{!"0x9150ad0.w1024.b0", !1566, i64 0}
!1566 = !{!"int64", !1567, i64 0}
!1567 = !{!"0x9150ad0", !8, i64 0}
!1568 = !{!1569, !1569, i64 0}
!1569 = !{!"0x9152a00.w1.b0", !1570, i64 0}
!1570 = !{!"0x9152a00.w2.b0", !1571, i64 0}
!1571 = !{!"0x9152a00.w4.b0", !1572, i64 0}
!1572 = !{!"0x9152a00.w8.b0", !1573, i64 0}
!1573 = !{!"0x9152a00.w16.b0", !1574, i64 0}
!1574 = !{!"0x9152a00.w32.b0", !1575, i64 0}
!1575 = !{!"0x9152a00.w64.b0", !1576, i64 0}
!1576 = !{!"0x9152a00.w128.b0", !1577, i64 0}
!1577 = !{!"0x9152a00.w256.b0", !1578, i64 0}
!1578 = !{!"0x9152a00.w512.b0", !1579, i64 0}
!1579 = !{!"0x9152a00.w1024.b0", !1580, i64 0}
!1580 = !{!"int64", !1581, i64 0}
!1581 = !{!"0x9152a00", !8, i64 0}
!1582 = !{!1583, !1583, i64 0}
!1583 = !{!"0x9152a00.w1.b1", !1570, i64 0}
!1584 = !{!1585, !1585, i64 0}
!1585 = !{!"0x9152a00.w1.b2", !1586, i64 0}
!1586 = !{!"0x9152a00.w2.b2", !1571, i64 0}
!1587 = !{!1588, !1588, i64 0}
!1588 = !{!"0x9152a00.w1.b3", !1586, i64 0}
!1589 = !{!1590, !1590, i64 0}
!1590 = !{!"0x9152a00.w1.b4", !1591, i64 0}
!1591 = !{!"0x9152a00.w2.b4", !1592, i64 0}
!1592 = !{!"0x9152a00.w4.b4", !1572, i64 0}
!1593 = !{!1594, !1594, i64 0}
!1594 = !{!"0x9153830.w4.b0", !1595, i64 0}
!1595 = !{!"0x9153830.w8.b0", !1596, i64 0}
!1596 = !{!"0x9153830.w16.b0", !1597, i64 0}
!1597 = !{!"0x9153830.w32.b0", !1598, i64 0}
!1598 = !{!"0x9153830.w64.b0", !1599, i64 0}
!1599 = !{!"0x9153830.w128.b0", !1600, i64 0}
!1600 = !{!"0x9153830.w256.b0", !1601, i64 0}
!1601 = !{!"0x9153830.w512.b0", !1602, i64 0}
!1602 = !{!"0x9153830.w1024.b0", !1603, i64 0}
!1603 = !{!"int64", !1604, i64 0}
!1604 = !{!"0x9153830", !8, i64 0}
!1605 = !{!1606, !1606, i64 0}
!1606 = !{!"0x9153830.w1.b4", !1607, i64 0}
!1607 = !{!"0x9153830.w2.b4", !1608, i64 0}
!1608 = !{!"0x9153830.w4.b4", !1595, i64 0}
!1609 = !{!1610, !1610, i64 0}
!1610 = !{!"float32", !1611, i64 0}
!1611 = !{!"0x91379a0", !8, i64 0}
!1612 = !{!1613, !1613, i64 0}
!1613 = !{!"float32", !1614, i64 0}
!1614 = !{!"0x9134e40", !8, i64 0}
!1615 = !{!1616, !1616, i64 0}
!1616 = !{!"float32", !1617, i64 0}
!1617 = !{!"0x9134620", !8, i64 0}
!1618 = !{!1619, !1619, i64 0}
!1619 = !{!"float32", !1620, i64 0}
!1620 = !{!"0x9135a30", !8, i64 0}
!1621 = !{!1622, !1622, i64 0}
!1622 = !{!"float32", !1623, i64 0}
!1623 = !{!"0x9135320", !8, i64 0}
!1624 = !{!1625, !1625, i64 0}
!1625 = !{!"float32", !1626, i64 0}
!1626 = !{!"0x9137200", !8, i64 0}
!1627 = !{!1628, !1628, i64 0}
!1628 = !{!"0xc9ef170.w1.b0", !1629, i64 0}
!1629 = !{!"0xc9ef170.w2.b0", !1630, i64 0}
!1630 = !{!"0xc9ef170.w4.b0", !1631, i64 0}
!1631 = !{!"0xc9ef170.w8.b0", !1632, i64 0}
!1632 = !{!"0xc9ef170.w16.b0", !1633, i64 0}
!1633 = !{!"0xc9ef170.w32.b0", !1634, i64 0}
!1634 = !{!"0xc9ef170.w64.b0", !1635, i64 0}
!1635 = !{!"0xc9ef170.w128.b0", !1636, i64 0}
!1636 = !{!"0xc9ef170.w256.b0", !1637, i64 0}
!1637 = !{!"0xc9ef170.w512.b0", !1638, i64 0}
!1638 = !{!"0xc9ef170.w1024.b0", !1639, i64 0}
!1639 = !{!"int32", !1640, i64 0}
!1640 = !{!"0xc9ef170", !8, i64 0}
!1641 = !{!1642, !1642, i64 0}
!1642 = !{!"0xc9ef170.w1.b2", !1643, i64 0}
!1643 = !{!"0xc9ef170.w2.b2", !1630, i64 0}
!1644 = !{!1645, !1645, i64 0}
!1645 = !{!"0xc9ef170.w1.b3", !1643, i64 0}
!1646 = !{!1647, !1647, i64 0}
!1647 = !{!"0xc9ef170.w1.b4", !1648, i64 0}
!1648 = !{!"0xc9ef170.w2.b4", !1649, i64 0}
!1649 = !{!"0xc9ef170.w4.b4", !1631, i64 0}
!1650 = !{!1651, !1651, i64 0}
!1651 = !{!"0xc9ef170.w1.b5", !1648, i64 0}
!1652 = !{!1653, !1653, i64 0}
!1653 = !{!"0xc9ef170.w1.b1", !1629, i64 0}
!1654 = !{!1655, !1655, i64 0}
!1655 = !{!"0xc9f35e0.w1.b0", !1656, i64 0}
!1656 = !{!"0xc9f35e0.w2.b0", !1657, i64 0}
!1657 = !{!"0xc9f35e0.w4.b0", !1658, i64 0}
!1658 = !{!"0xc9f35e0.w8.b0", !1659, i64 0}
!1659 = !{!"0xc9f35e0.w16.b0", !1660, i64 0}
!1660 = !{!"0xc9f35e0.w32.b0", !1661, i64 0}
!1661 = !{!"0xc9f35e0.w64.b0", !1662, i64 0}
!1662 = !{!"0xc9f35e0.w128.b0", !1663, i64 0}
!1663 = !{!"0xc9f35e0.w256.b0", !1664, i64 0}
!1664 = !{!"0xc9f35e0.w512.b0", !1665, i64 0}
!1665 = !{!"0xc9f35e0.w1024.b0", !1666, i64 0}
!1666 = !{!"int64", !1667, i64 0}
!1667 = !{!"0xc9f35e0", !8, i64 0}
!1668 = !{!1669, !1669, i64 0}
!1669 = !{!"0xc9f35e0.w1.b1", !1656, i64 0}
!1670 = !{!1671, !1671, i64 0}
!1671 = !{!"0xc9f35e0.w1.b2", !1672, i64 0}
!1672 = !{!"0xc9f35e0.w2.b2", !1657, i64 0}
!1673 = !{!1674, !1674, i64 0}
!1674 = !{!"0xc9f35e0.w1.b3", !1672, i64 0}
!1675 = !{!1676, !1676, i64 0}
!1676 = !{!"0xc9f35e0.w1.b4", !1677, i64 0}
!1677 = !{!"0xc9f35e0.w2.b4", !1678, i64 0}
!1678 = !{!"0xc9f35e0.w4.b4", !1658, i64 0}
!1679 = !{!1680, !1680, i64 0}
!1680 = !{!"0xc9f25b0.w4.b0", !1681, i64 0}
!1681 = !{!"0xc9f25b0.w8.b0", !1682, i64 0}
!1682 = !{!"0xc9f25b0.w16.b0", !1683, i64 0}
!1683 = !{!"0xc9f25b0.w32.b0", !1684, i64 0}
!1684 = !{!"0xc9f25b0.w64.b0", !1685, i64 0}
!1685 = !{!"0xc9f25b0.w128.b0", !1686, i64 0}
!1686 = !{!"0xc9f25b0.w256.b0", !1687, i64 0}
!1687 = !{!"0xc9f25b0.w512.b0", !1688, i64 0}
!1688 = !{!"0xc9f25b0.w1024.b0", !1689, i64 0}
!1689 = !{!"int64", !1690, i64 0}
!1690 = !{!"0xc9f25b0", !8, i64 0}
!1691 = !{!1692, !1692, i64 0}
!1692 = !{!"0xc9f25b0.w1.b4", !1693, i64 0}
!1693 = !{!"0xc9f25b0.w2.b4", !1694, i64 0}
!1694 = !{!"0xc9f25b0.w4.b4", !1681, i64 0}
!1695 = !{!1696, !1696, i64 0}
!1696 = !{!"0xc9fa1e0.w1.b0", !1697, i64 0}
!1697 = !{!"0xc9fa1e0.w2.b0", !1698, i64 0}
!1698 = !{!"0xc9fa1e0.w4.b0", !1699, i64 0}
!1699 = !{!"0xc9fa1e0.w8.b0", !1700, i64 0}
!1700 = !{!"0xc9fa1e0.w16.b0", !1701, i64 0}
!1701 = !{!"0xc9fa1e0.w32.b0", !1702, i64 0}
!1702 = !{!"0xc9fa1e0.w64.b0", !1703, i64 0}
!1703 = !{!"0xc9fa1e0.w128.b0", !1704, i64 0}
!1704 = !{!"0xc9fa1e0.w256.b0", !1705, i64 0}
!1705 = !{!"0xc9fa1e0.w512.b0", !1706, i64 0}
!1706 = !{!"0xc9fa1e0.w1024.b0", !1707, i64 0}
!1707 = !{!"int64", !1708, i64 0}
!1708 = !{!"0xc9fa1e0", !8, i64 0}
!1709 = !{!1710, !1710, i64 0}
!1710 = !{!"0xc9fa1e0.w1.b1", !1697, i64 0}
!1711 = !{!1712, !1712, i64 0}
!1712 = !{!"0xc9fa1e0.w1.b2", !1713, i64 0}
!1713 = !{!"0xc9fa1e0.w2.b2", !1698, i64 0}
!1714 = !{!1715, !1715, i64 0}
!1715 = !{!"0xc9fa1e0.w1.b3", !1713, i64 0}
!1716 = !{!1717, !1717, i64 0}
!1717 = !{!"0xc9fa1e0.w1.b4", !1718, i64 0}
!1718 = !{!"0xc9fa1e0.w2.b4", !1719, i64 0}
!1719 = !{!"0xc9fa1e0.w4.b4", !1699, i64 0}
!1720 = !{!1721, !1721, i64 0}
!1721 = !{!"0xc9fa1e0.w1.b5", !1718, i64 0}
!1722 = !{!1723, !1723, i64 0}
!1723 = !{!"0xc9fb570.w4.b0", !1724, i64 0}
!1724 = !{!"0xc9fb570.w8.b0", !1725, i64 0}
!1725 = !{!"0xc9fb570.w16.b0", !1726, i64 0}
!1726 = !{!"0xc9fb570.w32.b0", !1727, i64 0}
!1727 = !{!"0xc9fb570.w64.b0", !1728, i64 0}
!1728 = !{!"0xc9fb570.w128.b0", !1729, i64 0}
!1729 = !{!"0xc9fb570.w256.b0", !1730, i64 0}
!1730 = !{!"0xc9fb570.w512.b0", !1731, i64 0}
!1731 = !{!"0xc9fb570.w1024.b0", !1732, i64 0}
!1732 = !{!"int64", !1733, i64 0}
!1733 = !{!"0xc9fb570", !8, i64 0}
!1734 = !{!1735, !1735, i64 0}
!1735 = !{!"0xc9fb570.w1.b4", !1736, i64 0}
!1736 = !{!"0xc9fb570.w2.b4", !1737, i64 0}
!1737 = !{!"0xc9fb570.w4.b4", !1724, i64 0}
!1738 = !{!1739, !1739, i64 0}
!1739 = !{!"0xc9fb570.w1.b5", !1736, i64 0}
!1740 = !{!1741, !1741, i64 0}
!1741 = !{!"0xc9fd8e0.w1.b0", !1742, i64 0}
!1742 = !{!"0xc9fd8e0.w2.b0", !1743, i64 0}
!1743 = !{!"0xc9fd8e0.w4.b0", !1744, i64 0}
!1744 = !{!"0xc9fd8e0.w8.b0", !1745, i64 0}
!1745 = !{!"0xc9fd8e0.w16.b0", !1746, i64 0}
!1746 = !{!"0xc9fd8e0.w32.b0", !1747, i64 0}
!1747 = !{!"0xc9fd8e0.w64.b0", !1748, i64 0}
!1748 = !{!"0xc9fd8e0.w128.b0", !1749, i64 0}
!1749 = !{!"0xc9fd8e0.w256.b0", !1750, i64 0}
!1750 = !{!"0xc9fd8e0.w512.b0", !1751, i64 0}
!1751 = !{!"0xc9fd8e0.w1024.b0", !1752, i64 0}
!1752 = !{!"int64", !1753, i64 0}
!1753 = !{!"0xc9fd8e0", !8, i64 0}
!1754 = !{!1755, !1755, i64 0}
!1755 = !{!"0xc9fd8e0.w1.b1", !1742, i64 0}
!1756 = !{!1757, !1757, i64 0}
!1757 = !{!"0xc9fd8e0.w1.b2", !1758, i64 0}
!1758 = !{!"0xc9fd8e0.w2.b2", !1743, i64 0}
!1759 = !{!1760, !1760, i64 0}
!1760 = !{!"0xc9fd8e0.w1.b3", !1758, i64 0}
!1761 = !{!1762, !1762, i64 0}
!1762 = !{!"0xc9fe480.w4.b0", !1763, i64 0}
!1763 = !{!"0xc9fe480.w8.b0", !1764, i64 0}
!1764 = !{!"0xc9fe480.w16.b0", !1765, i64 0}
!1765 = !{!"0xc9fe480.w32.b0", !1766, i64 0}
!1766 = !{!"0xc9fe480.w64.b0", !1767, i64 0}
!1767 = !{!"0xc9fe480.w128.b0", !1768, i64 0}
!1768 = !{!"0xc9fe480.w256.b0", !1769, i64 0}
!1769 = !{!"0xc9fe480.w512.b0", !1770, i64 0}
!1770 = !{!"0xc9fe480.w1024.b0", !1771, i64 0}
!1771 = !{!"int64", !1772, i64 0}
!1772 = !{!"0xc9fe480", !8, i64 0}
!1773 = !{!1774, !1774, i64 0}
!1774 = !{!"0xc9f98b0.w1.b0", !1775, i64 0}
!1775 = !{!"0xc9f98b0.w2.b0", !1776, i64 0}
!1776 = !{!"0xc9f98b0.w4.b0", !1777, i64 0}
!1777 = !{!"0xc9f98b0.w8.b0", !1778, i64 0}
!1778 = !{!"0xc9f98b0.w16.b0", !1779, i64 0}
!1779 = !{!"0xc9f98b0.w32.b0", !1780, i64 0}
!1780 = !{!"0xc9f98b0.w64.b0", !1781, i64 0}
!1781 = !{!"0xc9f98b0.w128.b0", !1782, i64 0}
!1782 = !{!"0xc9f98b0.w256.b0", !1783, i64 0}
!1783 = !{!"0xc9f98b0.w512.b0", !1784, i64 0}
!1784 = !{!"0xc9f98b0.w1024.b0", !1785, i64 0}
!1785 = !{!"int64", !1786, i64 0}
!1786 = !{!"0xc9f98b0", !8, i64 0}
!1787 = !{!1788, !1788, i64 0}
!1788 = !{!"0xc9f98b0.w1.b1", !1775, i64 0}
!1789 = !{!1790, !1790, i64 0}
!1790 = !{!"0xc9f98b0.w1.b2", !1791, i64 0}
!1791 = !{!"0xc9f98b0.w2.b2", !1776, i64 0}
!1792 = !{!1793, !1793, i64 0}
!1793 = !{!"0xc9f98b0.w1.b3", !1791, i64 0}
!1794 = !{!1795, !1795, i64 0}
!1795 = !{!"0xca01210.w4.b0", !1796, i64 0}
!1796 = !{!"0xca01210.w8.b0", !1797, i64 0}
!1797 = !{!"0xca01210.w16.b0", !1798, i64 0}
!1798 = !{!"0xca01210.w32.b0", !1799, i64 0}
!1799 = !{!"0xca01210.w64.b0", !1800, i64 0}
!1800 = !{!"0xca01210.w128.b0", !1801, i64 0}
!1801 = !{!"0xca01210.w256.b0", !1802, i64 0}
!1802 = !{!"0xca01210.w512.b0", !1803, i64 0}
!1803 = !{!"0xca01210.w1024.b0", !1804, i64 0}
!1804 = !{!"int64", !1805, i64 0}
!1805 = !{!"0xca01210", !8, i64 0}
!1806 = !{!1807, !1807, i64 0}
!1807 = !{!"0xca032f0.w1.b0", !1808, i64 0}
!1808 = !{!"0xca032f0.w2.b0", !1809, i64 0}
!1809 = !{!"0xca032f0.w4.b0", !1810, i64 0}
!1810 = !{!"0xca032f0.w8.b0", !1811, i64 0}
!1811 = !{!"0xca032f0.w16.b0", !1812, i64 0}
!1812 = !{!"0xca032f0.w32.b0", !1813, i64 0}
!1813 = !{!"0xca032f0.w64.b0", !1814, i64 0}
!1814 = !{!"0xca032f0.w128.b0", !1815, i64 0}
!1815 = !{!"0xca032f0.w256.b0", !1816, i64 0}
!1816 = !{!"0xca032f0.w512.b0", !1817, i64 0}
!1817 = !{!"0xca032f0.w1024.b0", !1818, i64 0}
!1818 = !{!"int64", !1819, i64 0}
!1819 = !{!"0xca032f0", !8, i64 0}
!1820 = !{!1821, !1821, i64 0}
!1821 = !{!"0xca032f0.w1.b1", !1808, i64 0}
!1822 = !{!1823, !1823, i64 0}
!1823 = !{!"0xca032f0.w1.b2", !1824, i64 0}
!1824 = !{!"0xca032f0.w2.b2", !1809, i64 0}
!1825 = !{!1826, !1826, i64 0}
!1826 = !{!"0xca032f0.w1.b3", !1824, i64 0}
!1827 = !{!1828, !1828, i64 0}
!1828 = !{!"0xca03f70.w4.b0", !1829, i64 0}
!1829 = !{!"0xca03f70.w8.b0", !1830, i64 0}
!1830 = !{!"0xca03f70.w16.b0", !1831, i64 0}
!1831 = !{!"0xca03f70.w32.b0", !1832, i64 0}
!1832 = !{!"0xca03f70.w64.b0", !1833, i64 0}
!1833 = !{!"0xca03f70.w128.b0", !1834, i64 0}
!1834 = !{!"0xca03f70.w256.b0", !1835, i64 0}
!1835 = !{!"0xca03f70.w512.b0", !1836, i64 0}
!1836 = !{!"0xca03f70.w1024.b0", !1837, i64 0}
!1837 = !{!"int64", !1838, i64 0}
!1838 = !{!"0xca03f70", !8, i64 0}
!1839 = !{!1840, !1840, i64 0}
!1840 = !{!"0xca05ea0.w1.b0", !1841, i64 0}
!1841 = !{!"0xca05ea0.w2.b0", !1842, i64 0}
!1842 = !{!"0xca05ea0.w4.b0", !1843, i64 0}
!1843 = !{!"0xca05ea0.w8.b0", !1844, i64 0}
!1844 = !{!"0xca05ea0.w16.b0", !1845, i64 0}
!1845 = !{!"0xca05ea0.w32.b0", !1846, i64 0}
!1846 = !{!"0xca05ea0.w64.b0", !1847, i64 0}
!1847 = !{!"0xca05ea0.w128.b0", !1848, i64 0}
!1848 = !{!"0xca05ea0.w256.b0", !1849, i64 0}
!1849 = !{!"0xca05ea0.w512.b0", !1850, i64 0}
!1850 = !{!"0xca05ea0.w1024.b0", !1851, i64 0}
!1851 = !{!"int64", !1852, i64 0}
!1852 = !{!"0xca05ea0", !8, i64 0}
!1853 = !{!1854, !1854, i64 0}
!1854 = !{!"0xca05ea0.w1.b1", !1841, i64 0}
!1855 = !{!1856, !1856, i64 0}
!1856 = !{!"0xca05ea0.w1.b2", !1857, i64 0}
!1857 = !{!"0xca05ea0.w2.b2", !1842, i64 0}
!1858 = !{!1859, !1859, i64 0}
!1859 = !{!"0xca05ea0.w1.b3", !1857, i64 0}
!1860 = !{!1861, !1861, i64 0}
!1861 = !{!"0xca05ea0.w1.b4", !1862, i64 0}
!1862 = !{!"0xca05ea0.w2.b4", !1863, i64 0}
!1863 = !{!"0xca05ea0.w4.b4", !1843, i64 0}
!1864 = !{!1865, !1865, i64 0}
!1865 = !{!"0xca06cd0.w4.b0", !1866, i64 0}
!1866 = !{!"0xca06cd0.w8.b0", !1867, i64 0}
!1867 = !{!"0xca06cd0.w16.b0", !1868, i64 0}
!1868 = !{!"0xca06cd0.w32.b0", !1869, i64 0}
!1869 = !{!"0xca06cd0.w64.b0", !1870, i64 0}
!1870 = !{!"0xca06cd0.w128.b0", !1871, i64 0}
!1871 = !{!"0xca06cd0.w256.b0", !1872, i64 0}
!1872 = !{!"0xca06cd0.w512.b0", !1873, i64 0}
!1873 = !{!"0xca06cd0.w1024.b0", !1874, i64 0}
!1874 = !{!"int64", !1875, i64 0}
!1875 = !{!"0xca06cd0", !8, i64 0}
!1876 = !{!1877, !1877, i64 0}
!1877 = !{!"0xca06cd0.w1.b4", !1878, i64 0}
!1878 = !{!"0xca06cd0.w2.b4", !1879, i64 0}
!1879 = !{!"0xca06cd0.w4.b4", !1866, i64 0}
!1880 = !{!1881, !1881, i64 0}
!1881 = !{!"float32", !1882, i64 0}
!1882 = !{!"0xc9e85e0", !8, i64 0}
!1883 = !{!1884, !1884, i64 0}
!1884 = !{!"float32", !1885, i64 0}
!1885 = !{!"0xc9e5260", !8, i64 0}
!1886 = !{!1887, !1887, i64 0}
!1887 = !{!"float32", !1888, i64 0}
!1888 = !{!"0xc9e38a0", !8, i64 0}
!1889 = !{!1890, !1890, i64 0}
!1890 = !{!"float32", !1891, i64 0}
!1891 = !{!"0xc9eedd0", !8, i64 0}
!1892 = !{!1893, !1893, i64 0}
!1893 = !{!"float32", !1894, i64 0}
!1894 = !{!"0xc9e6b20", !8, i64 0}
!1895 = !{!1896, !1896, i64 0}
!1896 = !{!"float32", !1897, i64 0}
!1897 = !{!"0xc9e5f60", !8, i64 0}
!1898 = !{!1899, !1899, i64 0}
!1899 = !{!"float32", !1900, i64 0}
!1900 = !{!"0xc9e7e40", !8, i64 0}
!1901 = !{!1902, !1902, i64 0}
!1902 = !{!"0xa70d520.w1.b0", !1903, i64 0}
!1903 = !{!"0xa70d520.w2.b0", !1904, i64 0}
!1904 = !{!"0xa70d520.w4.b0", !1905, i64 0}
!1905 = !{!"0xa70d520.w8.b0", !1906, i64 0}
!1906 = !{!"0xa70d520.w16.b0", !1907, i64 0}
!1907 = !{!"0xa70d520.w32.b0", !1908, i64 0}
!1908 = !{!"0xa70d520.w64.b0", !1909, i64 0}
!1909 = !{!"0xa70d520.w128.b0", !1910, i64 0}
!1910 = !{!"0xa70d520.w256.b0", !1911, i64 0}
!1911 = !{!"0xa70d520.w512.b0", !1912, i64 0}
!1912 = !{!"0xa70d520.w1024.b0", !1913, i64 0}
!1913 = !{!"int32", !1914, i64 0}
!1914 = !{!"0xa70d520", !8, i64 0}
!1915 = !{!1916, !1916, i64 0}
!1916 = !{!"0xa70d520.w1.b1", !1903, i64 0}
!1917 = !{!1918, !1918, i64 0}
!1918 = !{!"0xcacd6e0.w1.b0", !1919, i64 0}
!1919 = !{!"0xcacd6e0.w2.b0", !1920, i64 0}
!1920 = !{!"0xcacd6e0.w4.b0", !1921, i64 0}
!1921 = !{!"0xcacd6e0.w8.b0", !1922, i64 0}
!1922 = !{!"0xcacd6e0.w16.b0", !1923, i64 0}
!1923 = !{!"0xcacd6e0.w32.b0", !1924, i64 0}
!1924 = !{!"0xcacd6e0.w64.b0", !1925, i64 0}
!1925 = !{!"0xcacd6e0.w128.b0", !1926, i64 0}
!1926 = !{!"0xcacd6e0.w256.b0", !1927, i64 0}
!1927 = !{!"0xcacd6e0.w512.b0", !1928, i64 0}
!1928 = !{!"0xcacd6e0.w1024.b0", !1929, i64 0}
!1929 = !{!"int64", !1930, i64 0}
!1930 = !{!"0xcacd6e0", !8, i64 0}
!1931 = !{!1932, !1932, i64 0}
!1932 = !{!"0xcacd6e0.w1.b1", !1919, i64 0}
!1933 = !{!1934, !1934, i64 0}
!1934 = !{!"0xcacd6e0.w1.b2", !1935, i64 0}
!1935 = !{!"0xcacd6e0.w2.b2", !1920, i64 0}
!1936 = !{!1937, !1937, i64 0}
!1937 = !{!"0xcacd6e0.w1.b3", !1935, i64 0}
!1938 = !{!1939, !1939, i64 0}
!1939 = !{!"0xcace010.w4.b0", !1940, i64 0}
!1940 = !{!"0xcace010.w8.b0", !1941, i64 0}
!1941 = !{!"0xcace010.w16.b0", !1942, i64 0}
!1942 = !{!"0xcace010.w32.b0", !1943, i64 0}
!1943 = !{!"0xcace010.w64.b0", !1944, i64 0}
!1944 = !{!"0xcace010.w128.b0", !1945, i64 0}
!1945 = !{!"0xcace010.w256.b0", !1946, i64 0}
!1946 = !{!"0xcace010.w512.b0", !1947, i64 0}
!1947 = !{!"0xcace010.w1024.b0", !1948, i64 0}
!1948 = !{!"int64", !1949, i64 0}
!1949 = !{!"0xcace010", !8, i64 0}
!1950 = !{!1951, !1951, i64 0}
!1951 = !{!"0xcacfe00.w1.b0", !1952, i64 0}
!1952 = !{!"0xcacfe00.w2.b0", !1953, i64 0}
!1953 = !{!"0xcacfe00.w4.b0", !1954, i64 0}
!1954 = !{!"0xcacfe00.w8.b0", !1955, i64 0}
!1955 = !{!"0xcacfe00.w16.b0", !1956, i64 0}
!1956 = !{!"0xcacfe00.w32.b0", !1957, i64 0}
!1957 = !{!"0xcacfe00.w64.b0", !1958, i64 0}
!1958 = !{!"0xcacfe00.w128.b0", !1959, i64 0}
!1959 = !{!"0xcacfe00.w256.b0", !1960, i64 0}
!1960 = !{!"0xcacfe00.w512.b0", !1961, i64 0}
!1961 = !{!"0xcacfe00.w1024.b0", !1962, i64 0}
!1962 = !{!"int64", !1963, i64 0}
!1963 = !{!"0xcacfe00", !8, i64 0}
!1964 = !{!1965, !1965, i64 0}
!1965 = !{!"0xcacfe00.w1.b1", !1952, i64 0}
!1966 = !{!1967, !1967, i64 0}
!1967 = !{!"0xcacfe00.w1.b2", !1968, i64 0}
!1968 = !{!"0xcacfe00.w2.b2", !1953, i64 0}
!1969 = !{!1970, !1970, i64 0}
!1970 = !{!"0xcacfe00.w1.b3", !1968, i64 0}
!1971 = !{!1972, !1972, i64 0}
!1972 = !{!"0xcacfe00.w1.b4", !1973, i64 0}
!1973 = !{!"0xcacfe00.w2.b4", !1974, i64 0}
!1974 = !{!"0xcacfe00.w4.b4", !1954, i64 0}
!1975 = !{!1976, !1976, i64 0}
!1976 = !{!"0xcad0e60.w4.b0", !1977, i64 0}
!1977 = !{!"0xcad0e60.w8.b0", !1978, i64 0}
!1978 = !{!"0xcad0e60.w16.b0", !1979, i64 0}
!1979 = !{!"0xcad0e60.w32.b0", !1980, i64 0}
!1980 = !{!"0xcad0e60.w64.b0", !1981, i64 0}
!1981 = !{!"0xcad0e60.w128.b0", !1982, i64 0}
!1982 = !{!"0xcad0e60.w256.b0", !1983, i64 0}
!1983 = !{!"0xcad0e60.w512.b0", !1984, i64 0}
!1984 = !{!"0xcad0e60.w1024.b0", !1985, i64 0}
!1985 = !{!"int64", !1986, i64 0}
!1986 = !{!"0xcad0e60", !8, i64 0}
!1987 = !{!1988, !1988, i64 0}
!1988 = !{!"0xcad0e60.w1.b4", !1989, i64 0}
!1989 = !{!"0xcad0e60.w2.b4", !1990, i64 0}
!1990 = !{!"0xcad0e60.w4.b4", !1977, i64 0}
!1991 = !{!1992, !1992, i64 0}
!1992 = !{!"float32", !1993, i64 0}
!1993 = !{!"0xcacb260", !8, i64 0}
!1994 = !{!1995, !1995, i64 0}
!1995 = !{!"float32", !1996, i64 0}
!1996 = !{!"0xcacb210", !8, i64 0}
!1997 = !{!1998, !1998, i64 0}
!1998 = !{!"0xca888f0.w1.b0", !1999, i64 0}
!1999 = !{!"0xca888f0.w2.b0", !2000, i64 0}
!2000 = !{!"0xca888f0.w4.b0", !2001, i64 0}
!2001 = !{!"0xca888f0.w8.b0", !2002, i64 0}
!2002 = !{!"0xca888f0.w16.b0", !2003, i64 0}
!2003 = !{!"0xca888f0.w32.b0", !2004, i64 0}
!2004 = !{!"0xca888f0.w64.b0", !2005, i64 0}
!2005 = !{!"0xca888f0.w128.b0", !2006, i64 0}
!2006 = !{!"0xca888f0.w256.b0", !2007, i64 0}
!2007 = !{!"0xca888f0.w512.b0", !2008, i64 0}
!2008 = !{!"0xca888f0.w1024.b0", !2009, i64 0}
!2009 = !{!"int32", !2010, i64 0}
!2010 = !{!"0xca888f0", !8, i64 0}
!2011 = !{!2012, !2012, i64 0}
!2012 = !{!"0xca888f0.w1.b2", !2013, i64 0}
!2013 = !{!"0xca888f0.w2.b2", !2000, i64 0}
!2014 = !{!2015, !2015, i64 0}
!2015 = !{!"0xca888f0.w1.b3", !2013, i64 0}
!2016 = !{!2017, !2017, i64 0}
!2017 = !{!"0xca888f0.w1.b4", !2018, i64 0}
!2018 = !{!"0xca888f0.w2.b4", !2019, i64 0}
!2019 = !{!"0xca888f0.w4.b4", !2001, i64 0}
!2020 = !{!2021, !2021, i64 0}
!2021 = !{!"0xca888f0.w1.b1", !1999, i64 0}
!2022 = !{!2023, !2023, i64 0}
!2023 = !{!"0xca782d0.w1.b0", !2024, i64 0}
!2024 = !{!"0xca782d0.w2.b0", !2025, i64 0}
!2025 = !{!"0xca782d0.w4.b0", !2026, i64 0}
!2026 = !{!"0xca782d0.w8.b0", !2027, i64 0}
!2027 = !{!"0xca782d0.w16.b0", !2028, i64 0}
!2028 = !{!"0xca782d0.w32.b0", !2029, i64 0}
!2029 = !{!"0xca782d0.w64.b0", !2030, i64 0}
!2030 = !{!"0xca782d0.w128.b0", !2031, i64 0}
!2031 = !{!"0xca782d0.w256.b0", !2032, i64 0}
!2032 = !{!"0xca782d0.w512.b0", !2033, i64 0}
!2033 = !{!"0xca782d0.w1024.b0", !2034, i64 0}
!2034 = !{!"int64", !2035, i64 0}
!2035 = !{!"0xca782d0", !8, i64 0}
!2036 = !{!2037, !2037, i64 0}
!2037 = !{!"0xca782d0.w1.b1", !2024, i64 0}
!2038 = !{!2039, !2039, i64 0}
!2039 = !{!"0xca782d0.w1.b2", !2040, i64 0}
!2040 = !{!"0xca782d0.w2.b2", !2025, i64 0}
!2041 = !{!2042, !2042, i64 0}
!2042 = !{!"0xca782d0.w1.b3", !2040, i64 0}
!2043 = !{!2044, !2044, i64 0}
!2044 = !{!"0xca782d0.w1.b4", !2045, i64 0}
!2045 = !{!"0xca782d0.w2.b4", !2046, i64 0}
!2046 = !{!"0xca782d0.w4.b4", !2026, i64 0}
!2047 = !{!2048, !2048, i64 0}
!2048 = !{!"0xca83a70.w4.b0", !2049, i64 0}
!2049 = !{!"0xca83a70.w8.b0", !2050, i64 0}
!2050 = !{!"0xca83a70.w16.b0", !2051, i64 0}
!2051 = !{!"0xca83a70.w32.b0", !2052, i64 0}
!2052 = !{!"0xca83a70.w64.b0", !2053, i64 0}
!2053 = !{!"0xca83a70.w128.b0", !2054, i64 0}
!2054 = !{!"0xca83a70.w256.b0", !2055, i64 0}
!2055 = !{!"0xca83a70.w512.b0", !2056, i64 0}
!2056 = !{!"0xca83a70.w1024.b0", !2057, i64 0}
!2057 = !{!"int64", !2058, i64 0}
!2058 = !{!"0xca83a70", !8, i64 0}
!2059 = !{!2060, !2060, i64 0}
!2060 = !{!"0xca83a70.w1.b4", !2061, i64 0}
!2061 = !{!"0xca83a70.w2.b4", !2062, i64 0}
!2062 = !{!"0xca83a70.w4.b4", !2049, i64 0}
!2063 = !{!2064, !2064, i64 0}
!2064 = !{!"0xca8c620.w1.b0", !2065, i64 0}
!2065 = !{!"0xca8c620.w2.b0", !2066, i64 0}
!2066 = !{!"0xca8c620.w4.b0", !2067, i64 0}
!2067 = !{!"0xca8c620.w8.b0", !2068, i64 0}
!2068 = !{!"0xca8c620.w16.b0", !2069, i64 0}
!2069 = !{!"0xca8c620.w32.b0", !2070, i64 0}
!2070 = !{!"0xca8c620.w64.b0", !2071, i64 0}
!2071 = !{!"0xca8c620.w128.b0", !2072, i64 0}
!2072 = !{!"0xca8c620.w256.b0", !2073, i64 0}
!2073 = !{!"0xca8c620.w512.b0", !2074, i64 0}
!2074 = !{!"0xca8c620.w1024.b0", !2075, i64 0}
!2075 = !{!"int64", !2076, i64 0}
!2076 = !{!"0xca8c620", !8, i64 0}
!2077 = !{!2078, !2078, i64 0}
!2078 = !{!"0xca8c620.w1.b1", !2065, i64 0}
!2079 = !{!2080, !2080, i64 0}
!2080 = !{!"0xca8c620.w1.b2", !2081, i64 0}
!2081 = !{!"0xca8c620.w2.b2", !2066, i64 0}
!2082 = !{!2083, !2083, i64 0}
!2083 = !{!"0xca8c620.w1.b3", !2081, i64 0}
!2084 = !{!2085, !2085, i64 0}
!2085 = !{!"0xca8c620.w1.b4", !2086, i64 0}
!2086 = !{!"0xca8c620.w2.b4", !2087, i64 0}
!2087 = !{!"0xca8c620.w4.b4", !2067, i64 0}
!2088 = !{!2089, !2089, i64 0}
!2089 = !{!"0xca8c620.w1.b5", !2086, i64 0}
!2090 = !{!2091, !2091, i64 0}
!2091 = !{!"0xca8d360.w4.b0", !2092, i64 0}
!2092 = !{!"0xca8d360.w8.b0", !2093, i64 0}
!2093 = !{!"0xca8d360.w16.b0", !2094, i64 0}
!2094 = !{!"0xca8d360.w32.b0", !2095, i64 0}
!2095 = !{!"0xca8d360.w64.b0", !2096, i64 0}
!2096 = !{!"0xca8d360.w128.b0", !2097, i64 0}
!2097 = !{!"0xca8d360.w256.b0", !2098, i64 0}
!2098 = !{!"0xca8d360.w512.b0", !2099, i64 0}
!2099 = !{!"0xca8d360.w1024.b0", !2100, i64 0}
!2100 = !{!"int64", !2101, i64 0}
!2101 = !{!"0xca8d360", !8, i64 0}
!2102 = !{!2103, !2103, i64 0}
!2103 = !{!"0xca8d360.w1.b4", !2104, i64 0}
!2104 = !{!"0xca8d360.w2.b4", !2105, i64 0}
!2105 = !{!"0xca8d360.w4.b4", !2092, i64 0}
!2106 = !{!2107, !2107, i64 0}
!2107 = !{!"0xca8d360.w1.b5", !2104, i64 0}
!2108 = !{!2109, !2109, i64 0}
!2109 = !{!"0xca8fb60.w1.b0", !2110, i64 0}
!2110 = !{!"0xca8fb60.w2.b0", !2111, i64 0}
!2111 = !{!"0xca8fb60.w4.b0", !2112, i64 0}
!2112 = !{!"0xca8fb60.w8.b0", !2113, i64 0}
!2113 = !{!"0xca8fb60.w16.b0", !2114, i64 0}
!2114 = !{!"0xca8fb60.w32.b0", !2115, i64 0}
!2115 = !{!"0xca8fb60.w64.b0", !2116, i64 0}
!2116 = !{!"0xca8fb60.w128.b0", !2117, i64 0}
!2117 = !{!"0xca8fb60.w256.b0", !2118, i64 0}
!2118 = !{!"0xca8fb60.w512.b0", !2119, i64 0}
!2119 = !{!"0xca8fb60.w1024.b0", !2120, i64 0}
!2120 = !{!"int64", !2121, i64 0}
!2121 = !{!"0xca8fb60", !8, i64 0}
!2122 = !{!2123, !2123, i64 0}
!2123 = !{!"0xca8fb60.w1.b1", !2110, i64 0}
!2124 = !{!2125, !2125, i64 0}
!2125 = !{!"0xca8fb60.w1.b2", !2126, i64 0}
!2126 = !{!"0xca8fb60.w2.b2", !2111, i64 0}
!2127 = !{!2128, !2128, i64 0}
!2128 = !{!"0xca8fb60.w1.b3", !2126, i64 0}
!2129 = !{!2130, !2130, i64 0}
!2130 = !{!"0xca90700.w4.b0", !2131, i64 0}
!2131 = !{!"0xca90700.w8.b0", !2132, i64 0}
!2132 = !{!"0xca90700.w16.b0", !2133, i64 0}
!2133 = !{!"0xca90700.w32.b0", !2134, i64 0}
!2134 = !{!"0xca90700.w64.b0", !2135, i64 0}
!2135 = !{!"0xca90700.w128.b0", !2136, i64 0}
!2136 = !{!"0xca90700.w256.b0", !2137, i64 0}
!2137 = !{!"0xca90700.w512.b0", !2138, i64 0}
!2138 = !{!"0xca90700.w1024.b0", !2139, i64 0}
!2139 = !{!"int64", !2140, i64 0}
!2140 = !{!"0xca90700", !8, i64 0}
!2141 = !{!2142, !2142, i64 0}
!2142 = !{!"0xca8bcf0.w1.b0", !2143, i64 0}
!2143 = !{!"0xca8bcf0.w2.b0", !2144, i64 0}
!2144 = !{!"0xca8bcf0.w4.b0", !2145, i64 0}
!2145 = !{!"0xca8bcf0.w8.b0", !2146, i64 0}
!2146 = !{!"0xca8bcf0.w16.b0", !2147, i64 0}
!2147 = !{!"0xca8bcf0.w32.b0", !2148, i64 0}
!2148 = !{!"0xca8bcf0.w64.b0", !2149, i64 0}
!2149 = !{!"0xca8bcf0.w128.b0", !2150, i64 0}
!2150 = !{!"0xca8bcf0.w256.b0", !2151, i64 0}
!2151 = !{!"0xca8bcf0.w512.b0", !2152, i64 0}
!2152 = !{!"0xca8bcf0.w1024.b0", !2153, i64 0}
!2153 = !{!"int64", !2154, i64 0}
!2154 = !{!"0xca8bcf0", !8, i64 0}
!2155 = !{!2156, !2156, i64 0}
!2156 = !{!"0xca8bcf0.w1.b1", !2143, i64 0}
!2157 = !{!2158, !2158, i64 0}
!2158 = !{!"0xca8bcf0.w1.b2", !2159, i64 0}
!2159 = !{!"0xca8bcf0.w2.b2", !2144, i64 0}
!2160 = !{!2161, !2161, i64 0}
!2161 = !{!"0xca8bcf0.w1.b3", !2159, i64 0}
!2162 = !{!2163, !2163, i64 0}
!2163 = !{!"0xca93490.w4.b0", !2164, i64 0}
!2164 = !{!"0xca93490.w8.b0", !2165, i64 0}
!2165 = !{!"0xca93490.w16.b0", !2166, i64 0}
!2166 = !{!"0xca93490.w32.b0", !2167, i64 0}
!2167 = !{!"0xca93490.w64.b0", !2168, i64 0}
!2168 = !{!"0xca93490.w128.b0", !2169, i64 0}
!2169 = !{!"0xca93490.w256.b0", !2170, i64 0}
!2170 = !{!"0xca93490.w512.b0", !2171, i64 0}
!2171 = !{!"0xca93490.w1024.b0", !2172, i64 0}
!2172 = !{!"int64", !2173, i64 0}
!2173 = !{!"0xca93490", !8, i64 0}
!2174 = !{!2175, !2175, i64 0}
!2175 = !{!"0xca95570.w1.b0", !2176, i64 0}
!2176 = !{!"0xca95570.w2.b0", !2177, i64 0}
!2177 = !{!"0xca95570.w4.b0", !2178, i64 0}
!2178 = !{!"0xca95570.w8.b0", !2179, i64 0}
!2179 = !{!"0xca95570.w16.b0", !2180, i64 0}
!2180 = !{!"0xca95570.w32.b0", !2181, i64 0}
!2181 = !{!"0xca95570.w64.b0", !2182, i64 0}
!2182 = !{!"0xca95570.w128.b0", !2183, i64 0}
!2183 = !{!"0xca95570.w256.b0", !2184, i64 0}
!2184 = !{!"0xca95570.w512.b0", !2185, i64 0}
!2185 = !{!"0xca95570.w1024.b0", !2186, i64 0}
!2186 = !{!"int64", !2187, i64 0}
!2187 = !{!"0xca95570", !8, i64 0}
!2188 = !{!2189, !2189, i64 0}
!2189 = !{!"0xca95570.w1.b1", !2176, i64 0}
!2190 = !{!2191, !2191, i64 0}
!2191 = !{!"0xca95570.w1.b2", !2192, i64 0}
!2192 = !{!"0xca95570.w2.b2", !2177, i64 0}
!2193 = !{!2194, !2194, i64 0}
!2194 = !{!"0xca95570.w1.b3", !2192, i64 0}
!2195 = !{!2196, !2196, i64 0}
!2196 = !{!"0xca95570.w1.b4", !2197, i64 0}
!2197 = !{!"0xca95570.w2.b4", !2198, i64 0}
!2198 = !{!"0xca95570.w4.b4", !2178, i64 0}
!2199 = !{!2200, !2200, i64 0}
!2200 = !{!"0xca95d50.w4.b0", !2201, i64 0}
!2201 = !{!"0xca95d50.w8.b0", !2202, i64 0}
!2202 = !{!"0xca95d50.w16.b0", !2203, i64 0}
!2203 = !{!"0xca95d50.w32.b0", !2204, i64 0}
!2204 = !{!"0xca95d50.w64.b0", !2205, i64 0}
!2205 = !{!"0xca95d50.w128.b0", !2206, i64 0}
!2206 = !{!"0xca95d50.w256.b0", !2207, i64 0}
!2207 = !{!"0xca95d50.w512.b0", !2208, i64 0}
!2208 = !{!"0xca95d50.w1024.b0", !2209, i64 0}
!2209 = !{!"int64", !2210, i64 0}
!2210 = !{!"0xca95d50", !8, i64 0}
!2211 = !{!2212, !2212, i64 0}
!2212 = !{!"0xca95d50.w1.b4", !2213, i64 0}
!2213 = !{!"0xca95d50.w2.b4", !2214, i64 0}
!2214 = !{!"0xca95d50.w4.b4", !2201, i64 0}
!2215 = !{!2216, !2216, i64 0}
!2216 = !{!"float32", !2217, i64 0}
!2217 = !{!"0xca7c640", !8, i64 0}
!2218 = !{!2219, !2219, i64 0}
!2219 = !{!"float32", !2220, i64 0}
!2220 = !{!"0xca7cbe0", !8, i64 0}
!2221 = !{!2222, !2222, i64 0}
!2222 = !{!"float32", !2223, i64 0}
!2223 = !{!"0xca82240", !8, i64 0}
!2224 = !{!2225, !2225, i64 0}
!2225 = !{!"float32", !2226, i64 0}
!2226 = !{!"0xca798f0", !8, i64 0}
!2227 = !{!2228, !2228, i64 0}
!2228 = !{!"float32", !2229, i64 0}
!2229 = !{!"0xca7af50", !8, i64 0}
!2230 = !{!2231, !2231, i64 0}
!2231 = !{!"float32", !2232, i64 0}
!2232 = !{!"0xca7b910", !8, i64 0}
!2233 = !{!2234, !2234, i64 0}
!2234 = !{!"0xa55b000.w1.b0", !2235, i64 0}
!2235 = !{!"0xa55b000.w2.b0", !2236, i64 0}
!2236 = !{!"0xa55b000.w4.b0", !2237, i64 0}
!2237 = !{!"0xa55b000.w8.b0", !2238, i64 0}
!2238 = !{!"0xa55b000.w16.b0", !2239, i64 0}
!2239 = !{!"0xa55b000.w32.b0", !2240, i64 0}
!2240 = !{!"0xa55b000.w64.b0", !2241, i64 0}
!2241 = !{!"0xa55b000.w128.b0", !2242, i64 0}
!2242 = !{!"0xa55b000.w256.b0", !2243, i64 0}
!2243 = !{!"0xa55b000.w512.b0", !2244, i64 0}
!2244 = !{!"0xa55b000.w1024.b0", !2245, i64 0}
!2245 = !{!"int32", !2246, i64 0}
!2246 = !{!"0xa55b000", !8, i64 0}
!2247 = !{!2248, !2248, i64 0}
!2248 = !{!"0xa55b000.w1.b2", !2249, i64 0}
!2249 = !{!"0xa55b000.w2.b2", !2236, i64 0}
!2250 = !{!2251, !2251, i64 0}
!2251 = !{!"0xa55b000.w1.b3", !2249, i64 0}
!2252 = !{!2253, !2253, i64 0}
!2253 = !{!"0xa55b000.w1.b4", !2254, i64 0}
!2254 = !{!"0xa55b000.w2.b4", !2255, i64 0}
!2255 = !{!"0xa55b000.w4.b4", !2237, i64 0}
!2256 = !{!2257, !2257, i64 0}
!2257 = !{!"0xa55b000.w1.b1", !2235, i64 0}
!2258 = !{!2259, !2259, i64 0}
!2259 = !{!"0xa558ad0.w1.b0", !2260, i64 0}
!2260 = !{!"0xa558ad0.w2.b0", !2261, i64 0}
!2261 = !{!"0xa558ad0.w4.b0", !2262, i64 0}
!2262 = !{!"0xa558ad0.w8.b0", !2263, i64 0}
!2263 = !{!"0xa558ad0.w16.b0", !2264, i64 0}
!2264 = !{!"0xa558ad0.w32.b0", !2265, i64 0}
!2265 = !{!"0xa558ad0.w64.b0", !2266, i64 0}
!2266 = !{!"0xa558ad0.w128.b0", !2267, i64 0}
!2267 = !{!"0xa558ad0.w256.b0", !2268, i64 0}
!2268 = !{!"0xa558ad0.w512.b0", !2269, i64 0}
!2269 = !{!"0xa558ad0.w1024.b0", !2270, i64 0}
!2270 = !{!"int64", !2271, i64 0}
!2271 = !{!"0xa558ad0", !8, i64 0}
!2272 = !{!2273, !2273, i64 0}
!2273 = !{!"0xa558ad0.w1.b1", !2260, i64 0}
!2274 = !{!2275, !2275, i64 0}
!2275 = !{!"0xa558ad0.w1.b2", !2276, i64 0}
!2276 = !{!"0xa558ad0.w2.b2", !2261, i64 0}
!2277 = !{!2278, !2278, i64 0}
!2278 = !{!"0xa558ad0.w1.b3", !2276, i64 0}
!2279 = !{!2280, !2280, i64 0}
!2280 = !{!"0xa558ad0.w1.b4", !2281, i64 0}
!2281 = !{!"0xa558ad0.w2.b4", !2282, i64 0}
!2282 = !{!"0xa558ad0.w4.b4", !2262, i64 0}
!2283 = !{!2284, !2284, i64 0}
!2284 = !{!"0xa556a90.w4.b0", !2285, i64 0}
!2285 = !{!"0xa556a90.w8.b0", !2286, i64 0}
!2286 = !{!"0xa556a90.w16.b0", !2287, i64 0}
!2287 = !{!"0xa556a90.w32.b0", !2288, i64 0}
!2288 = !{!"0xa556a90.w64.b0", !2289, i64 0}
!2289 = !{!"0xa556a90.w128.b0", !2290, i64 0}
!2290 = !{!"0xa556a90.w256.b0", !2291, i64 0}
!2291 = !{!"0xa556a90.w512.b0", !2292, i64 0}
!2292 = !{!"0xa556a90.w1024.b0", !2293, i64 0}
!2293 = !{!"int64", !2294, i64 0}
!2294 = !{!"0xa556a90", !8, i64 0}
!2295 = !{!2296, !2296, i64 0}
!2296 = !{!"0xa556a90.w1.b4", !2297, i64 0}
!2297 = !{!"0xa556a90.w2.b4", !2298, i64 0}
!2298 = !{!"0xa556a90.w4.b4", !2285, i64 0}
!2299 = !{!2300, !2300, i64 0}
!2300 = !{!"0xa55a400.w1.b0", !2301, i64 0}
!2301 = !{!"0xa55a400.w2.b0", !2302, i64 0}
!2302 = !{!"0xa55a400.w4.b0", !2303, i64 0}
!2303 = !{!"0xa55a400.w8.b0", !2304, i64 0}
!2304 = !{!"0xa55a400.w16.b0", !2305, i64 0}
!2305 = !{!"0xa55a400.w32.b0", !2306, i64 0}
!2306 = !{!"0xa55a400.w64.b0", !2307, i64 0}
!2307 = !{!"0xa55a400.w128.b0", !2308, i64 0}
!2308 = !{!"0xa55a400.w256.b0", !2309, i64 0}
!2309 = !{!"0xa55a400.w512.b0", !2310, i64 0}
!2310 = !{!"0xa55a400.w1024.b0", !2311, i64 0}
!2311 = !{!"int64", !2312, i64 0}
!2312 = !{!"0xa55a400", !8, i64 0}
!2313 = !{!2314, !2314, i64 0}
!2314 = !{!"0xa55a400.w1.b1", !2301, i64 0}
!2315 = !{!2316, !2316, i64 0}
!2316 = !{!"0xa55a400.w1.b2", !2317, i64 0}
!2317 = !{!"0xa55a400.w2.b2", !2302, i64 0}
!2318 = !{!2319, !2319, i64 0}
!2319 = !{!"0xa55a400.w1.b3", !2317, i64 0}
!2320 = !{!2321, !2321, i64 0}
!2321 = !{!"0xa55a400.w1.b4", !2322, i64 0}
!2322 = !{!"0xa55a400.w2.b4", !2323, i64 0}
!2323 = !{!"0xa55a400.w4.b4", !2303, i64 0}
!2324 = !{!2325, !2325, i64 0}
!2325 = !{!"0xa55a400.w1.b5", !2322, i64 0}
!2326 = !{!2327, !2327, i64 0}
!2327 = !{!"0xa55c790.w4.b0", !2328, i64 0}
!2328 = !{!"0xa55c790.w8.b0", !2329, i64 0}
!2329 = !{!"0xa55c790.w16.b0", !2330, i64 0}
!2330 = !{!"0xa55c790.w32.b0", !2331, i64 0}
!2331 = !{!"0xa55c790.w64.b0", !2332, i64 0}
!2332 = !{!"0xa55c790.w128.b0", !2333, i64 0}
!2333 = !{!"0xa55c790.w256.b0", !2334, i64 0}
!2334 = !{!"0xa55c790.w512.b0", !2335, i64 0}
!2335 = !{!"0xa55c790.w1024.b0", !2336, i64 0}
!2336 = !{!"int64", !2337, i64 0}
!2337 = !{!"0xa55c790", !8, i64 0}
!2338 = !{!2339, !2339, i64 0}
!2339 = !{!"0xa55c790.w1.b4", !2340, i64 0}
!2340 = !{!"0xa55c790.w2.b4", !2341, i64 0}
!2341 = !{!"0xa55c790.w4.b4", !2328, i64 0}
!2342 = !{!2343, !2343, i64 0}
!2343 = !{!"0xa55c790.w1.b5", !2340, i64 0}
!2344 = !{!2345, !2345, i64 0}
!2345 = !{!"0xa55eb00.w1.b0", !2346, i64 0}
!2346 = !{!"0xa55eb00.w2.b0", !2347, i64 0}
!2347 = !{!"0xa55eb00.w4.b0", !2348, i64 0}
!2348 = !{!"0xa55eb00.w8.b0", !2349, i64 0}
!2349 = !{!"0xa55eb00.w16.b0", !2350, i64 0}
!2350 = !{!"0xa55eb00.w32.b0", !2351, i64 0}
!2351 = !{!"0xa55eb00.w64.b0", !2352, i64 0}
!2352 = !{!"0xa55eb00.w128.b0", !2353, i64 0}
!2353 = !{!"0xa55eb00.w256.b0", !2354, i64 0}
!2354 = !{!"0xa55eb00.w512.b0", !2355, i64 0}
!2355 = !{!"0xa55eb00.w1024.b0", !2356, i64 0}
!2356 = !{!"int64", !2357, i64 0}
!2357 = !{!"0xa55eb00", !8, i64 0}
!2358 = !{!2359, !2359, i64 0}
!2359 = !{!"0xa55eb00.w1.b1", !2346, i64 0}
!2360 = !{!2361, !2361, i64 0}
!2361 = !{!"0xa55eb00.w1.b2", !2362, i64 0}
!2362 = !{!"0xa55eb00.w2.b2", !2347, i64 0}
!2363 = !{!2364, !2364, i64 0}
!2364 = !{!"0xa55eb00.w1.b3", !2362, i64 0}
!2365 = !{!2366, !2366, i64 0}
!2366 = !{!"0xa55f6a0.w4.b0", !2367, i64 0}
!2367 = !{!"0xa55f6a0.w8.b0", !2368, i64 0}
!2368 = !{!"0xa55f6a0.w16.b0", !2369, i64 0}
!2369 = !{!"0xa55f6a0.w32.b0", !2370, i64 0}
!2370 = !{!"0xa55f6a0.w64.b0", !2371, i64 0}
!2371 = !{!"0xa55f6a0.w128.b0", !2372, i64 0}
!2372 = !{!"0xa55f6a0.w256.b0", !2373, i64 0}
!2373 = !{!"0xa55f6a0.w512.b0", !2374, i64 0}
!2374 = !{!"0xa55f6a0.w1024.b0", !2375, i64 0}
!2375 = !{!"int64", !2376, i64 0}
!2376 = !{!"0xa55f6a0", !8, i64 0}
!2377 = !{!2378, !2378, i64 0}
!2378 = !{!"0xa5524b0.w1.b0", !2379, i64 0}
!2379 = !{!"0xa5524b0.w2.b0", !2380, i64 0}
!2380 = !{!"0xa5524b0.w4.b0", !2381, i64 0}
!2381 = !{!"0xa5524b0.w8.b0", !2382, i64 0}
!2382 = !{!"0xa5524b0.w16.b0", !2383, i64 0}
!2383 = !{!"0xa5524b0.w32.b0", !2384, i64 0}
!2384 = !{!"0xa5524b0.w64.b0", !2385, i64 0}
!2385 = !{!"0xa5524b0.w128.b0", !2386, i64 0}
!2386 = !{!"0xa5524b0.w256.b0", !2387, i64 0}
!2387 = !{!"0xa5524b0.w512.b0", !2388, i64 0}
!2388 = !{!"0xa5524b0.w1024.b0", !2389, i64 0}
!2389 = !{!"int64", !2390, i64 0}
!2390 = !{!"0xa5524b0", !8, i64 0}
!2391 = !{!2392, !2392, i64 0}
!2392 = !{!"0xa5524b0.w1.b1", !2379, i64 0}
!2393 = !{!2394, !2394, i64 0}
!2394 = !{!"0xa5524b0.w1.b2", !2395, i64 0}
!2395 = !{!"0xa5524b0.w2.b2", !2380, i64 0}
!2396 = !{!2397, !2397, i64 0}
!2397 = !{!"0xa5524b0.w1.b3", !2395, i64 0}
!2398 = !{!2399, !2399, i64 0}
!2399 = !{!"0xa5622a0.w4.b0", !2400, i64 0}
!2400 = !{!"0xa5622a0.w8.b0", !2401, i64 0}
!2401 = !{!"0xa5622a0.w16.b0", !2402, i64 0}
!2402 = !{!"0xa5622a0.w32.b0", !2403, i64 0}
!2403 = !{!"0xa5622a0.w64.b0", !2404, i64 0}
!2404 = !{!"0xa5622a0.w128.b0", !2405, i64 0}
!2405 = !{!"0xa5622a0.w256.b0", !2406, i64 0}
!2406 = !{!"0xa5622a0.w512.b0", !2407, i64 0}
!2407 = !{!"0xa5622a0.w1024.b0", !2408, i64 0}
!2408 = !{!"int64", !2409, i64 0}
!2409 = !{!"0xa5622a0", !8, i64 0}
!2410 = !{!2411, !2411, i64 0}
!2411 = !{!"0xa5644f0.w1.b0", !2412, i64 0}
!2412 = !{!"0xa5644f0.w2.b0", !2413, i64 0}
!2413 = !{!"0xa5644f0.w4.b0", !2414, i64 0}
!2414 = !{!"0xa5644f0.w8.b0", !2415, i64 0}
!2415 = !{!"0xa5644f0.w16.b0", !2416, i64 0}
!2416 = !{!"0xa5644f0.w32.b0", !2417, i64 0}
!2417 = !{!"0xa5644f0.w64.b0", !2418, i64 0}
!2418 = !{!"0xa5644f0.w128.b0", !2419, i64 0}
!2419 = !{!"0xa5644f0.w256.b0", !2420, i64 0}
!2420 = !{!"0xa5644f0.w512.b0", !2421, i64 0}
!2421 = !{!"0xa5644f0.w1024.b0", !2422, i64 0}
!2422 = !{!"int64", !2423, i64 0}
!2423 = !{!"0xa5644f0", !8, i64 0}
!2424 = !{!2425, !2425, i64 0}
!2425 = !{!"0xa5644f0.w1.b1", !2412, i64 0}
!2426 = !{!2427, !2427, i64 0}
!2427 = !{!"0xa5644f0.w1.b2", !2428, i64 0}
!2428 = !{!"0xa5644f0.w2.b2", !2413, i64 0}
!2429 = !{!2430, !2430, i64 0}
!2430 = !{!"0xa5644f0.w1.b3", !2428, i64 0}
!2431 = !{!2432, !2432, i64 0}
!2432 = !{!"0xa5644f0.w1.b4", !2433, i64 0}
!2433 = !{!"0xa5644f0.w2.b4", !2434, i64 0}
!2434 = !{!"0xa5644f0.w4.b4", !2414, i64 0}
!2435 = !{!2436, !2436, i64 0}
!2436 = !{!"0xa5650f0.w4.b0", !2437, i64 0}
!2437 = !{!"0xa5650f0.w8.b0", !2438, i64 0}
!2438 = !{!"0xa5650f0.w16.b0", !2439, i64 0}
!2439 = !{!"0xa5650f0.w32.b0", !2440, i64 0}
!2440 = !{!"0xa5650f0.w64.b0", !2441, i64 0}
!2441 = !{!"0xa5650f0.w128.b0", !2442, i64 0}
!2442 = !{!"0xa5650f0.w256.b0", !2443, i64 0}
!2443 = !{!"0xa5650f0.w512.b0", !2444, i64 0}
!2444 = !{!"0xa5650f0.w1024.b0", !2445, i64 0}
!2445 = !{!"int64", !2446, i64 0}
!2446 = !{!"0xa5650f0", !8, i64 0}
!2447 = !{!2448, !2448, i64 0}
!2448 = !{!"0xa5650f0.w1.b4", !2449, i64 0}
!2449 = !{!"0xa5650f0.w2.b4", !2450, i64 0}
!2450 = !{!"0xa5650f0.w4.b4", !2437, i64 0}
!2451 = !{!2452, !2452, i64 0}
!2452 = !{!"float32", !2453, i64 0}
!2453 = !{!"0xa552e50", !8, i64 0}
!2454 = !{!2455, !2455, i64 0}
!2455 = !{!"float32", !2456, i64 0}
!2456 = !{!"0xa54d920", !8, i64 0}
!2457 = !{!2458, !2458, i64 0}
!2458 = !{!"float32", !2459, i64 0}
!2459 = !{!"0xa54d660", !8, i64 0}
!2460 = !{!2461, !2461, i64 0}
!2461 = !{!"float32", !2462, i64 0}
!2462 = !{!"0xa5bff20", !8, i64 0}
!2463 = !{!2464, !2464, i64 0}
!2464 = !{!"float32", !2465, i64 0}
!2465 = !{!"0xa54c1d0", !8, i64 0}
!2466 = !{!2467, !2467, i64 0}
!2467 = !{!"float32", !2468, i64 0}
!2468 = !{!"0xa5c25e0", !8, i64 0}
!2469 = !{!2470, !2470, i64 0}
!2470 = !{!"0xd529e90.w1.b0", !2471, i64 0}
!2471 = !{!"0xd529e90.w2.b0", !2472, i64 0}
!2472 = !{!"0xd529e90.w4.b0", !2473, i64 0}
!2473 = !{!"0xd529e90.w8.b0", !2474, i64 0}
!2474 = !{!"0xd529e90.w16.b0", !2475, i64 0}
!2475 = !{!"0xd529e90.w32.b0", !2476, i64 0}
!2476 = !{!"0xd529e90.w64.b0", !2477, i64 0}
!2477 = !{!"0xd529e90.w128.b0", !2478, i64 0}
!2478 = !{!"0xd529e90.w256.b0", !2479, i64 0}
!2479 = !{!"0xd529e90.w512.b0", !2480, i64 0}
!2480 = !{!"0xd529e90.w1024.b0", !2481, i64 0}
!2481 = !{!"int32", !2482, i64 0}
!2482 = !{!"0xd529e90", !8, i64 0}
!2483 = !{!2484, !2484, i64 0}
!2484 = !{!"0xd529e90.w1.b2", !2485, i64 0}
!2485 = !{!"0xd529e90.w2.b2", !2472, i64 0}
!2486 = !{!2487, !2487, i64 0}
!2487 = !{!"0xd529e90.w1.b3", !2485, i64 0}
!2488 = !{!2489, !2489, i64 0}
!2489 = !{!"0xd529e90.w1.b4", !2490, i64 0}
!2490 = !{!"0xd529e90.w2.b4", !2491, i64 0}
!2491 = !{!"0xd529e90.w4.b4", !2473, i64 0}
!2492 = !{!2493, !2493, i64 0}
!2493 = !{!"0xd529e90.w1.b1", !2471, i64 0}
!2494 = !{!2495, !2495, i64 0}
!2495 = !{!"0x139b8380.w1.b0", !2496, i64 0}
!2496 = !{!"0x139b8380.w2.b0", !2497, i64 0}
!2497 = !{!"0x139b8380.w4.b0", !2498, i64 0}
!2498 = !{!"0x139b8380.w8.b0", !2499, i64 0}
!2499 = !{!"0x139b8380.w16.b0", !2500, i64 0}
!2500 = !{!"0x139b8380.w32.b0", !2501, i64 0}
!2501 = !{!"0x139b8380.w64.b0", !2502, i64 0}
!2502 = !{!"0x139b8380.w128.b0", !2503, i64 0}
!2503 = !{!"0x139b8380.w256.b0", !2504, i64 0}
!2504 = !{!"0x139b8380.w512.b0", !2505, i64 0}
!2505 = !{!"0x139b8380.w1024.b0", !2506, i64 0}
!2506 = !{!"int64", !2507, i64 0}
!2507 = !{!"0x139b8380", !8, i64 0}
!2508 = !{!2509, !2509, i64 0}
!2509 = !{!"0x139b8380.w1.b1", !2496, i64 0}
!2510 = !{!2511, !2511, i64 0}
!2511 = !{!"0x139b8380.w1.b2", !2512, i64 0}
!2512 = !{!"0x139b8380.w2.b2", !2497, i64 0}
!2513 = !{!2514, !2514, i64 0}
!2514 = !{!"0x139b8380.w1.b3", !2512, i64 0}
!2515 = !{!2516, !2516, i64 0}
!2516 = !{!"0x139b8380.w1.b4", !2517, i64 0}
!2517 = !{!"0x139b8380.w2.b4", !2518, i64 0}
!2518 = !{!"0x139b8380.w4.b4", !2498, i64 0}
!2519 = !{!2520, !2520, i64 0}
!2520 = !{!"0x1f2ec810.w4.b0", !2521, i64 0}
!2521 = !{!"0x1f2ec810.w8.b0", !2522, i64 0}
!2522 = !{!"0x1f2ec810.w16.b0", !2523, i64 0}
!2523 = !{!"0x1f2ec810.w32.b0", !2524, i64 0}
!2524 = !{!"0x1f2ec810.w64.b0", !2525, i64 0}
!2525 = !{!"0x1f2ec810.w128.b0", !2526, i64 0}
!2526 = !{!"0x1f2ec810.w256.b0", !2527, i64 0}
!2527 = !{!"0x1f2ec810.w512.b0", !2528, i64 0}
!2528 = !{!"0x1f2ec810.w1024.b0", !2529, i64 0}
!2529 = !{!"int64", !2530, i64 0}
!2530 = !{!"0x1f2ec810", !8, i64 0}
!2531 = !{!2532, !2532, i64 0}
!2532 = !{!"0x1f2ec810.w1.b4", !2533, i64 0}
!2533 = !{!"0x1f2ec810.w2.b4", !2534, i64 0}
!2534 = !{!"0x1f2ec810.w4.b4", !2521, i64 0}
!2535 = !{!2536, !2536, i64 0}
!2536 = !{!"0xf7e8f20.w1.b0", !2537, i64 0}
!2537 = !{!"0xf7e8f20.w2.b0", !2538, i64 0}
!2538 = !{!"0xf7e8f20.w4.b0", !2539, i64 0}
!2539 = !{!"0xf7e8f20.w8.b0", !2540, i64 0}
!2540 = !{!"0xf7e8f20.w16.b0", !2541, i64 0}
!2541 = !{!"0xf7e8f20.w32.b0", !2542, i64 0}
!2542 = !{!"0xf7e8f20.w64.b0", !2543, i64 0}
!2543 = !{!"0xf7e8f20.w128.b0", !2544, i64 0}
!2544 = !{!"0xf7e8f20.w256.b0", !2545, i64 0}
!2545 = !{!"0xf7e8f20.w512.b0", !2546, i64 0}
!2546 = !{!"0xf7e8f20.w1024.b0", !2547, i64 0}
!2547 = !{!"int64", !2548, i64 0}
!2548 = !{!"0xf7e8f20", !8, i64 0}
!2549 = !{!2550, !2550, i64 0}
!2550 = !{!"0xf7e8f20.w1.b1", !2537, i64 0}
!2551 = !{!2552, !2552, i64 0}
!2552 = !{!"0xf7e8f20.w1.b2", !2553, i64 0}
!2553 = !{!"0xf7e8f20.w2.b2", !2538, i64 0}
!2554 = !{!2555, !2555, i64 0}
!2555 = !{!"0xf7e8f20.w1.b3", !2553, i64 0}
!2556 = !{!2557, !2557, i64 0}
!2557 = !{!"0xf7e8f20.w1.b4", !2558, i64 0}
!2558 = !{!"0xf7e8f20.w2.b4", !2559, i64 0}
!2559 = !{!"0xf7e8f20.w4.b4", !2539, i64 0}
!2560 = !{!2561, !2561, i64 0}
!2561 = !{!"0xf7e8f20.w1.b5", !2558, i64 0}
!2562 = !{!2563, !2563, i64 0}
!2563 = !{!"0xa087410.w4.b0", !2564, i64 0}
!2564 = !{!"0xa087410.w8.b0", !2565, i64 0}
!2565 = !{!"0xa087410.w16.b0", !2566, i64 0}
!2566 = !{!"0xa087410.w32.b0", !2567, i64 0}
!2567 = !{!"0xa087410.w64.b0", !2568, i64 0}
!2568 = !{!"0xa087410.w128.b0", !2569, i64 0}
!2569 = !{!"0xa087410.w256.b0", !2570, i64 0}
!2570 = !{!"0xa087410.w512.b0", !2571, i64 0}
!2571 = !{!"0xa087410.w1024.b0", !2572, i64 0}
!2572 = !{!"int64", !2573, i64 0}
!2573 = !{!"0xa087410", !8, i64 0}
!2574 = !{!2575, !2575, i64 0}
!2575 = !{!"0xa087410.w1.b4", !2576, i64 0}
!2576 = !{!"0xa087410.w2.b4", !2577, i64 0}
!2577 = !{!"0xa087410.w4.b4", !2564, i64 0}
!2578 = !{!2579, !2579, i64 0}
!2579 = !{!"0xa087410.w1.b5", !2576, i64 0}
!2580 = !{!2581, !2581, i64 0}
!2581 = !{!"0x139a8100.w1.b0", !2582, i64 0}
!2582 = !{!"0x139a8100.w2.b0", !2583, i64 0}
!2583 = !{!"0x139a8100.w4.b0", !2584, i64 0}
!2584 = !{!"0x139a8100.w8.b0", !2585, i64 0}
!2585 = !{!"0x139a8100.w16.b0", !2586, i64 0}
!2586 = !{!"0x139a8100.w32.b0", !2587, i64 0}
!2587 = !{!"0x139a8100.w64.b0", !2588, i64 0}
!2588 = !{!"0x139a8100.w128.b0", !2589, i64 0}
!2589 = !{!"0x139a8100.w256.b0", !2590, i64 0}
!2590 = !{!"0x139a8100.w512.b0", !2591, i64 0}
!2591 = !{!"0x139a8100.w1024.b0", !2592, i64 0}
!2592 = !{!"int64", !2593, i64 0}
!2593 = !{!"0x139a8100", !8, i64 0}
!2594 = !{!2595, !2595, i64 0}
!2595 = !{!"0x139a8100.w1.b1", !2582, i64 0}
!2596 = !{!2597, !2597, i64 0}
!2597 = !{!"0x139a8100.w1.b2", !2598, i64 0}
!2598 = !{!"0x139a8100.w2.b2", !2583, i64 0}
!2599 = !{!2600, !2600, i64 0}
!2600 = !{!"0x139a8100.w1.b3", !2598, i64 0}
!2601 = !{!2602, !2602, i64 0}
!2602 = !{!"0x8d99c00.w4.b0", !2603, i64 0}
!2603 = !{!"0x8d99c00.w8.b0", !2604, i64 0}
!2604 = !{!"0x8d99c00.w16.b0", !2605, i64 0}
!2605 = !{!"0x8d99c00.w32.b0", !2606, i64 0}
!2606 = !{!"0x8d99c00.w64.b0", !2607, i64 0}
!2607 = !{!"0x8d99c00.w128.b0", !2608, i64 0}
!2608 = !{!"0x8d99c00.w256.b0", !2609, i64 0}
!2609 = !{!"0x8d99c00.w512.b0", !2610, i64 0}
!2610 = !{!"0x8d99c00.w1024.b0", !2611, i64 0}
!2611 = !{!"int64", !2612, i64 0}
!2612 = !{!"0x8d99c00", !8, i64 0}
!2613 = !{!2614, !2614, i64 0}
!2614 = !{!"0xae39fb0.w1.b0", !2615, i64 0}
!2615 = !{!"0xae39fb0.w2.b0", !2616, i64 0}
!2616 = !{!"0xae39fb0.w4.b0", !2617, i64 0}
!2617 = !{!"0xae39fb0.w8.b0", !2618, i64 0}
!2618 = !{!"0xae39fb0.w16.b0", !2619, i64 0}
!2619 = !{!"0xae39fb0.w32.b0", !2620, i64 0}
!2620 = !{!"0xae39fb0.w64.b0", !2621, i64 0}
!2621 = !{!"0xae39fb0.w128.b0", !2622, i64 0}
!2622 = !{!"0xae39fb0.w256.b0", !2623, i64 0}
!2623 = !{!"0xae39fb0.w512.b0", !2624, i64 0}
!2624 = !{!"0xae39fb0.w1024.b0", !2625, i64 0}
!2625 = !{!"int64", !2626, i64 0}
!2626 = !{!"0xae39fb0", !8, i64 0}
!2627 = !{!2628, !2628, i64 0}
!2628 = !{!"0xae39fb0.w1.b1", !2615, i64 0}
!2629 = !{!2630, !2630, i64 0}
!2630 = !{!"0xae39fb0.w1.b2", !2631, i64 0}
!2631 = !{!"0xae39fb0.w2.b2", !2616, i64 0}
!2632 = !{!2633, !2633, i64 0}
!2633 = !{!"0xae39fb0.w1.b3", !2631, i64 0}
!2634 = !{!2635, !2635, i64 0}
!2635 = !{!"0xecd3e00.w4.b0", !2636, i64 0}
!2636 = !{!"0xecd3e00.w8.b0", !2637, i64 0}
!2637 = !{!"0xecd3e00.w16.b0", !2638, i64 0}
!2638 = !{!"0xecd3e00.w32.b0", !2639, i64 0}
!2639 = !{!"0xecd3e00.w64.b0", !2640, i64 0}
!2640 = !{!"0xecd3e00.w128.b0", !2641, i64 0}
!2641 = !{!"0xecd3e00.w256.b0", !2642, i64 0}
!2642 = !{!"0xecd3e00.w512.b0", !2643, i64 0}
!2643 = !{!"0xecd3e00.w1024.b0", !2644, i64 0}
!2644 = !{!"int64", !2645, i64 0}
!2645 = !{!"0xecd3e00", !8, i64 0}
!2646 = !{!2647, !2647, i64 0}
!2647 = !{!"0x139a9780.w1.b0", !2648, i64 0}
!2648 = !{!"0x139a9780.w2.b0", !2649, i64 0}
!2649 = !{!"0x139a9780.w4.b0", !2650, i64 0}
!2650 = !{!"0x139a9780.w8.b0", !2651, i64 0}
!2651 = !{!"0x139a9780.w16.b0", !2652, i64 0}
!2652 = !{!"0x139a9780.w32.b0", !2653, i64 0}
!2653 = !{!"0x139a9780.w64.b0", !2654, i64 0}
!2654 = !{!"0x139a9780.w128.b0", !2655, i64 0}
!2655 = !{!"0x139a9780.w256.b0", !2656, i64 0}
!2656 = !{!"0x139a9780.w512.b0", !2657, i64 0}
!2657 = !{!"0x139a9780.w1024.b0", !2658, i64 0}
!2658 = !{!"int64", !2659, i64 0}
!2659 = !{!"0x139a9780", !8, i64 0}
!2660 = !{!2661, !2661, i64 0}
!2661 = !{!"0x139a9780.w1.b1", !2648, i64 0}
!2662 = !{!2663, !2663, i64 0}
!2663 = !{!"0x139a9780.w1.b2", !2664, i64 0}
!2664 = !{!"0x139a9780.w2.b2", !2649, i64 0}
!2665 = !{!2666, !2666, i64 0}
!2666 = !{!"0x139a9780.w1.b3", !2664, i64 0}
!2667 = !{!2668, !2668, i64 0}
!2668 = !{!"0x139a9780.w1.b4", !2669, i64 0}
!2669 = !{!"0x139a9780.w2.b4", !2670, i64 0}
!2670 = !{!"0x139a9780.w4.b4", !2650, i64 0}
!2671 = !{!2672, !2672, i64 0}
!2672 = !{!"0x1f2ff540.w4.b0", !2673, i64 0}
!2673 = !{!"0x1f2ff540.w8.b0", !2674, i64 0}
!2674 = !{!"0x1f2ff540.w16.b0", !2675, i64 0}
!2675 = !{!"0x1f2ff540.w32.b0", !2676, i64 0}
!2676 = !{!"0x1f2ff540.w64.b0", !2677, i64 0}
!2677 = !{!"0x1f2ff540.w128.b0", !2678, i64 0}
!2678 = !{!"0x1f2ff540.w256.b0", !2679, i64 0}
!2679 = !{!"0x1f2ff540.w512.b0", !2680, i64 0}
!2680 = !{!"0x1f2ff540.w1024.b0", !2681, i64 0}
!2681 = !{!"int64", !2682, i64 0}
!2682 = !{!"0x1f2ff540", !8, i64 0}
!2683 = !{!2684, !2684, i64 0}
!2684 = !{!"0x1f2ff540.w1.b4", !2685, i64 0}
!2685 = !{!"0x1f2ff540.w2.b4", !2686, i64 0}
!2686 = !{!"0x1f2ff540.w4.b4", !2673, i64 0}
!2687 = !{!2688, !2688, i64 0}
!2688 = !{!"float32", !2689, i64 0}
!2689 = !{!"0x135e6640", !8, i64 0}
!2690 = !{!2691, !2691, i64 0}
!2691 = !{!"float32", !2692, i64 0}
!2692 = !{!"0x1b7a8120", !8, i64 0}
!2693 = !{!2694, !2694, i64 0}
!2694 = !{!"float32", !2695, i64 0}
!2695 = !{!"0x72e5480", !8, i64 0}
!2696 = !{!2697, !2697, i64 0}
!2697 = !{!"float32", !2698, i64 0}
!2698 = !{!"0xd535140", !8, i64 0}
!2699 = !{!2700, !2700, i64 0}
!2700 = !{!"float32", !2701, i64 0}
!2701 = !{!"0xd4c64a0", !8, i64 0}
!2702 = !{!2703, !2703, i64 0}
!2703 = !{!"0xc9fb360.w1.b0", !2704, i64 0}
!2704 = !{!"0xc9fb360.w2.b0", !2705, i64 0}
!2705 = !{!"0xc9fb360.w4.b0", !2706, i64 0}
!2706 = !{!"0xc9fb360.w8.b0", !2707, i64 0}
!2707 = !{!"0xc9fb360.w16.b0", !2708, i64 0}
!2708 = !{!"0xc9fb360.w32.b0", !2709, i64 0}
!2709 = !{!"0xc9fb360.w64.b0", !2710, i64 0}
!2710 = !{!"0xc9fb360.w128.b0", !2711, i64 0}
!2711 = !{!"0xc9fb360.w256.b0", !2712, i64 0}
!2712 = !{!"0xc9fb360.w512.b0", !2713, i64 0}
!2713 = !{!"0xc9fb360.w1024.b0", !2714, i64 0}
!2714 = !{!"int32", !2715, i64 0}
!2715 = !{!"0xc9fb360", !8, i64 0}
!2716 = !{!2717, !2717, i64 0}
!2717 = !{!"0xc9fb360.w1.b1", !2704, i64 0}
!2718 = !{!2719, !2719, i64 0}
!2719 = !{!"0xca0b260.w1.b0", !2720, i64 0}
!2720 = !{!"0xca0b260.w2.b0", !2721, i64 0}
!2721 = !{!"0xca0b260.w4.b0", !2722, i64 0}
!2722 = !{!"0xca0b260.w8.b0", !2723, i64 0}
!2723 = !{!"0xca0b260.w16.b0", !2724, i64 0}
!2724 = !{!"0xca0b260.w32.b0", !2725, i64 0}
!2725 = !{!"0xca0b260.w64.b0", !2726, i64 0}
!2726 = !{!"0xca0b260.w128.b0", !2727, i64 0}
!2727 = !{!"0xca0b260.w256.b0", !2728, i64 0}
!2728 = !{!"0xca0b260.w512.b0", !2729, i64 0}
!2729 = !{!"0xca0b260.w1024.b0", !2730, i64 0}
!2730 = !{!"int64", !2731, i64 0}
!2731 = !{!"0xca0b260", !8, i64 0}
!2732 = !{!2733, !2733, i64 0}
!2733 = !{!"0xca0b260.w1.b1", !2720, i64 0}
!2734 = !{!2735, !2735, i64 0}
!2735 = !{!"0xca0b260.w1.b2", !2736, i64 0}
!2736 = !{!"0xca0b260.w2.b2", !2721, i64 0}
!2737 = !{!2738, !2738, i64 0}
!2738 = !{!"0xca0b260.w1.b3", !2736, i64 0}
!2739 = !{!2740, !2740, i64 0}
!2740 = !{!"0xc9fc530.w4.b0", !2741, i64 0}
!2741 = !{!"0xc9fc530.w8.b0", !2742, i64 0}
!2742 = !{!"0xc9fc530.w16.b0", !2743, i64 0}
!2743 = !{!"0xc9fc530.w32.b0", !2744, i64 0}
!2744 = !{!"0xc9fc530.w64.b0", !2745, i64 0}
!2745 = !{!"0xc9fc530.w128.b0", !2746, i64 0}
!2746 = !{!"0xc9fc530.w256.b0", !2747, i64 0}
!2747 = !{!"0xc9fc530.w512.b0", !2748, i64 0}
!2748 = !{!"0xc9fc530.w1024.b0", !2749, i64 0}
!2749 = !{!"int64", !2750, i64 0}
!2750 = !{!"0xc9fc530", !8, i64 0}
!2751 = !{!2752, !2752, i64 0}
!2752 = !{!"0xca0cdb0.w1.b0", !2753, i64 0}
!2753 = !{!"0xca0cdb0.w2.b0", !2754, i64 0}
!2754 = !{!"0xca0cdb0.w4.b0", !2755, i64 0}
!2755 = !{!"0xca0cdb0.w8.b0", !2756, i64 0}
!2756 = !{!"0xca0cdb0.w16.b0", !2757, i64 0}
!2757 = !{!"0xca0cdb0.w32.b0", !2758, i64 0}
!2758 = !{!"0xca0cdb0.w64.b0", !2759, i64 0}
!2759 = !{!"0xca0cdb0.w128.b0", !2760, i64 0}
!2760 = !{!"0xca0cdb0.w256.b0", !2761, i64 0}
!2761 = !{!"0xca0cdb0.w512.b0", !2762, i64 0}
!2762 = !{!"0xca0cdb0.w1024.b0", !2763, i64 0}
!2763 = !{!"int64", !2764, i64 0}
!2764 = !{!"0xca0cdb0", !8, i64 0}
!2765 = !{!2766, !2766, i64 0}
!2766 = !{!"0xca0cdb0.w1.b1", !2753, i64 0}
!2767 = !{!2768, !2768, i64 0}
!2768 = !{!"0xca0cdb0.w1.b2", !2769, i64 0}
!2769 = !{!"0xca0cdb0.w2.b2", !2754, i64 0}
!2770 = !{!2771, !2771, i64 0}
!2771 = !{!"0xca0cdb0.w1.b3", !2769, i64 0}
!2772 = !{!2773, !2773, i64 0}
!2773 = !{!"0xca0cdb0.w1.b4", !2774, i64 0}
!2774 = !{!"0xca0cdb0.w2.b4", !2775, i64 0}
!2775 = !{!"0xca0cdb0.w4.b4", !2755, i64 0}
!2776 = !{!2777, !2777, i64 0}
!2777 = !{!"0xca0de20.w4.b0", !2778, i64 0}
!2778 = !{!"0xca0de20.w8.b0", !2779, i64 0}
!2779 = !{!"0xca0de20.w16.b0", !2780, i64 0}
!2780 = !{!"0xca0de20.w32.b0", !2781, i64 0}
!2781 = !{!"0xca0de20.w64.b0", !2782, i64 0}
!2782 = !{!"0xca0de20.w128.b0", !2783, i64 0}
!2783 = !{!"0xca0de20.w256.b0", !2784, i64 0}
!2784 = !{!"0xca0de20.w512.b0", !2785, i64 0}
!2785 = !{!"0xca0de20.w1024.b0", !2786, i64 0}
!2786 = !{!"int64", !2787, i64 0}
!2787 = !{!"0xca0de20", !8, i64 0}
!2788 = !{!2789, !2789, i64 0}
!2789 = !{!"0xca0de20.w1.b4", !2790, i64 0}
!2790 = !{!"0xca0de20.w2.b4", !2791, i64 0}
!2791 = !{!"0xca0de20.w4.b4", !2778, i64 0}
!2792 = !{!2793, !2793, i64 0}
!2793 = !{!"float32", !2794, i64 0}
!2794 = !{!"0xc9f84a0", !8, i64 0}
!2795 = !{!2796, !2796, i64 0}
!2796 = !{!"float32", !2797, i64 0}
!2797 = !{!"0xc9f8450", !8, i64 0}
!2798 = distinct !{!2798, !1123}
!2799 = !{!2800, !2800, i64 0}
!2800 = !{!"0x1f352af0.w1.b0", !2801, i64 0}
!2801 = !{!"0x1f352af0.w2.b0", !2802, i64 0}
!2802 = !{!"0x1f352af0.w4.b0", !2803, i64 0}
!2803 = !{!"0x1f352af0.w8.b0", !2804, i64 0}
!2804 = !{!"0x1f352af0.w16.b0", !2805, i64 0}
!2805 = !{!"0x1f352af0.w32.b0", !2806, i64 0}
!2806 = !{!"0x1f352af0.w64.b0", !2807, i64 0}
!2807 = !{!"0x1f352af0.w128.b0", !2808, i64 0}
!2808 = !{!"0x1f352af0.w256.b0", !2809, i64 0}
!2809 = !{!"0x1f352af0.w512.b0", !2810, i64 0}
!2810 = !{!"0x1f352af0.w1024.b0", !2811, i64 0}
!2811 = !{!"int32", !2812, i64 0}
!2812 = !{!"0x1f352af0", !8, i64 0}
!2813 = !{!2814, !2814, i64 0}
!2814 = !{!"0x1f352af0.w1.b1", !2801, i64 0}
!2815 = !{!2816, !2816, i64 0}
!2816 = !{!"0x13a49f10.w1.b0", !2817, i64 0}
!2817 = !{!"0x13a49f10.w2.b0", !2818, i64 0}
!2818 = !{!"0x13a49f10.w4.b0", !2819, i64 0}
!2819 = !{!"0x13a49f10.w8.b0", !2820, i64 0}
!2820 = !{!"0x13a49f10.w16.b0", !2821, i64 0}
!2821 = !{!"0x13a49f10.w32.b0", !2822, i64 0}
!2822 = !{!"0x13a49f10.w64.b0", !2823, i64 0}
!2823 = !{!"0x13a49f10.w128.b0", !2824, i64 0}
!2824 = !{!"0x13a49f10.w256.b0", !2825, i64 0}
!2825 = !{!"0x13a49f10.w512.b0", !2826, i64 0}
!2826 = !{!"0x13a49f10.w1024.b0", !2827, i64 0}
!2827 = !{!"int64", !2828, i64 0}
!2828 = !{!"0x13a49f10", !8, i64 0}
!2829 = !{!2830, !2830, i64 0}
!2830 = !{!"0x13a49f10.w1.b1", !2817, i64 0}
!2831 = !{!2832, !2832, i64 0}
!2832 = !{!"0x13a49f10.w1.b2", !2833, i64 0}
!2833 = !{!"0x13a49f10.w2.b2", !2818, i64 0}
!2834 = !{!2835, !2835, i64 0}
!2835 = !{!"0x13a49f10.w1.b3", !2833, i64 0}
!2836 = !{!2837, !2837, i64 0}
!2837 = !{!"0x13a49f10.w1.b4", !2838, i64 0}
!2838 = !{!"0x13a49f10.w2.b4", !2839, i64 0}
!2839 = !{!"0x13a49f10.w4.b4", !2819, i64 0}
!2840 = !{!2841, !2841, i64 0}
!2841 = !{!"0x13b15bf0.w4.b0", !2842, i64 0}
!2842 = !{!"0x13b15bf0.w8.b0", !2843, i64 0}
!2843 = !{!"0x13b15bf0.w16.b0", !2844, i64 0}
!2844 = !{!"0x13b15bf0.w32.b0", !2845, i64 0}
!2845 = !{!"0x13b15bf0.w64.b0", !2846, i64 0}
!2846 = !{!"0x13b15bf0.w128.b0", !2847, i64 0}
!2847 = !{!"0x13b15bf0.w256.b0", !2848, i64 0}
!2848 = !{!"0x13b15bf0.w512.b0", !2849, i64 0}
!2849 = !{!"0x13b15bf0.w1024.b0", !2850, i64 0}
!2850 = !{!"int64", !2851, i64 0}
!2851 = !{!"0x13b15bf0", !8, i64 0}
!2852 = !{!2853, !2853, i64 0}
!2853 = !{!"0x13b15bf0.w1.b4", !2854, i64 0}
!2854 = !{!"0x13b15bf0.w2.b4", !2855, i64 0}
!2855 = !{!"0x13b15bf0.w4.b4", !2842, i64 0}
!2856 = !{!2857, !2857, i64 0}
!2857 = !{!"0x13a4d580.w1.b0", !2858, i64 0}
!2858 = !{!"0x13a4d580.w2.b0", !2859, i64 0}
!2859 = !{!"0x13a4d580.w4.b0", !2860, i64 0}
!2860 = !{!"0x13a4d580.w8.b0", !2861, i64 0}
!2861 = !{!"0x13a4d580.w16.b0", !2862, i64 0}
!2862 = !{!"0x13a4d580.w32.b0", !2863, i64 0}
!2863 = !{!"0x13a4d580.w64.b0", !2864, i64 0}
!2864 = !{!"0x13a4d580.w128.b0", !2865, i64 0}
!2865 = !{!"0x13a4d580.w256.b0", !2866, i64 0}
!2866 = !{!"0x13a4d580.w512.b0", !2867, i64 0}
!2867 = !{!"0x13a4d580.w1024.b0", !2868, i64 0}
!2868 = !{!"int64", !2869, i64 0}
!2869 = !{!"0x13a4d580", !8, i64 0}
!2870 = !{!2871, !2871, i64 0}
!2871 = !{!"0x13a4d580.w1.b1", !2858, i64 0}
!2872 = !{!2873, !2873, i64 0}
!2873 = !{!"0x13a4d580.w1.b2", !2874, i64 0}
!2874 = !{!"0x13a4d580.w2.b2", !2859, i64 0}
!2875 = !{!2876, !2876, i64 0}
!2876 = !{!"0x13a4d580.w1.b3", !2874, i64 0}
!2877 = !{!2878, !2878, i64 0}
!2878 = !{!"0x13a4d580.w1.b4", !2879, i64 0}
!2879 = !{!"0x13a4d580.w2.b4", !2880, i64 0}
!2880 = !{!"0x13a4d580.w4.b4", !2860, i64 0}
!2881 = !{!2882, !2882, i64 0}
!2882 = !{!"0x13a4cd20.w4.b0", !2883, i64 0}
!2883 = !{!"0x13a4cd20.w8.b0", !2884, i64 0}
!2884 = !{!"0x13a4cd20.w16.b0", !2885, i64 0}
!2885 = !{!"0x13a4cd20.w32.b0", !2886, i64 0}
!2886 = !{!"0x13a4cd20.w64.b0", !2887, i64 0}
!2887 = !{!"0x13a4cd20.w128.b0", !2888, i64 0}
!2888 = !{!"0x13a4cd20.w256.b0", !2889, i64 0}
!2889 = !{!"0x13a4cd20.w512.b0", !2890, i64 0}
!2890 = !{!"0x13a4cd20.w1024.b0", !2891, i64 0}
!2891 = !{!"int64", !2892, i64 0}
!2892 = !{!"0x13a4cd20", !8, i64 0}
!2893 = !{!2894, !2894, i64 0}
!2894 = !{!"0x13a4cd20.w1.b4", !2895, i64 0}
!2895 = !{!"0x13a4cd20.w2.b4", !2896, i64 0}
!2896 = !{!"0x13a4cd20.w4.b4", !2883, i64 0}
!2897 = !{!2898, !2898, i64 0}
!2898 = !{!"float32", !2899, i64 0}
!2899 = !{!"0x1f352aa0", !8, i64 0}
!2900 = !{!2901, !2901, i64 0}
!2901 = !{!"float32", !2902, i64 0}
!2902 = !{!"0x1f352a50", !8, i64 0}
!2903 = !{!2904, !2904, i64 0}
!2904 = !{!"0xca72a10.w1.b0", !2905, i64 0}
!2905 = !{!"0xca72a10.w2.b0", !2906, i64 0}
!2906 = !{!"0xca72a10.w4.b0", !2907, i64 0}
!2907 = !{!"0xca72a10.w8.b0", !2908, i64 0}
!2908 = !{!"0xca72a10.w16.b0", !2909, i64 0}
!2909 = !{!"0xca72a10.w32.b0", !2910, i64 0}
!2910 = !{!"0xca72a10.w64.b0", !2911, i64 0}
!2911 = !{!"0xca72a10.w128.b0", !2912, i64 0}
!2912 = !{!"0xca72a10.w256.b0", !2913, i64 0}
!2913 = !{!"0xca72a10.w512.b0", !2914, i64 0}
!2914 = !{!"0xca72a10.w1024.b0", !2915, i64 0}
!2915 = !{!"int32", !2916, i64 0}
!2916 = !{!"0xca72a10", !8, i64 0}
!2917 = !{!2918, !2918, i64 0}
!2918 = !{!"0xca72a10.w1.b1", !2905, i64 0}
!2919 = !{!2920, !2920, i64 0}
!2920 = !{!"0xca73740.w1.b0", !2921, i64 0}
!2921 = !{!"0xca73740.w2.b0", !2922, i64 0}
!2922 = !{!"0xca73740.w4.b0", !2923, i64 0}
!2923 = !{!"0xca73740.w8.b0", !2924, i64 0}
!2924 = !{!"0xca73740.w16.b0", !2925, i64 0}
!2925 = !{!"0xca73740.w32.b0", !2926, i64 0}
!2926 = !{!"0xca73740.w64.b0", !2927, i64 0}
!2927 = !{!"0xca73740.w128.b0", !2928, i64 0}
!2928 = !{!"0xca73740.w256.b0", !2929, i64 0}
!2929 = !{!"0xca73740.w512.b0", !2930, i64 0}
!2930 = !{!"0xca73740.w1024.b0", !2931, i64 0}
!2931 = !{!"int64", !2932, i64 0}
!2932 = !{!"0xca73740", !8, i64 0}
!2933 = !{!2934, !2934, i64 0}
!2934 = !{!"0xca73740.w1.b1", !2921, i64 0}
!2935 = !{!2936, !2936, i64 0}
!2936 = !{!"0xca73740.w1.b2", !2937, i64 0}
!2937 = !{!"0xca73740.w2.b2", !2922, i64 0}
!2938 = !{!2939, !2939, i64 0}
!2939 = !{!"0xca73740.w1.b3", !2937, i64 0}
!2940 = !{!2941, !2941, i64 0}
!2941 = !{!"0xca73740.w1.b4", !2942, i64 0}
!2942 = !{!"0xca73740.w2.b4", !2943, i64 0}
!2943 = !{!"0xca73740.w4.b4", !2923, i64 0}
!2944 = !{!2945, !2945, i64 0}
!2945 = !{!"0xca74360.w4.b0", !2946, i64 0}
!2946 = !{!"0xca74360.w8.b0", !2947, i64 0}
!2947 = !{!"0xca74360.w16.b0", !2948, i64 0}
!2948 = !{!"0xca74360.w32.b0", !2949, i64 0}
!2949 = !{!"0xca74360.w64.b0", !2950, i64 0}
!2950 = !{!"0xca74360.w128.b0", !2951, i64 0}
!2951 = !{!"0xca74360.w256.b0", !2952, i64 0}
!2952 = !{!"0xca74360.w512.b0", !2953, i64 0}
!2953 = !{!"0xca74360.w1024.b0", !2954, i64 0}
!2954 = !{!"int64", !2955, i64 0}
!2955 = !{!"0xca74360", !8, i64 0}
!2956 = !{!2957, !2957, i64 0}
!2957 = !{!"0xca74360.w1.b4", !2958, i64 0}
!2958 = !{!"0xca74360.w2.b4", !2959, i64 0}
!2959 = !{!"0xca74360.w4.b4", !2946, i64 0}
!2960 = !{!2961, !2961, i64 0}
!2961 = !{!"0xca76140.w1.b0", !2962, i64 0}
!2962 = !{!"0xca76140.w2.b0", !2963, i64 0}
!2963 = !{!"0xca76140.w4.b0", !2964, i64 0}
!2964 = !{!"0xca76140.w8.b0", !2965, i64 0}
!2965 = !{!"0xca76140.w16.b0", !2966, i64 0}
!2966 = !{!"0xca76140.w32.b0", !2967, i64 0}
!2967 = !{!"0xca76140.w64.b0", !2968, i64 0}
!2968 = !{!"0xca76140.w128.b0", !2969, i64 0}
!2969 = !{!"0xca76140.w256.b0", !2970, i64 0}
!2970 = !{!"0xca76140.w512.b0", !2971, i64 0}
!2971 = !{!"0xca76140.w1024.b0", !2972, i64 0}
!2972 = !{!"int64", !2973, i64 0}
!2973 = !{!"0xca76140", !8, i64 0}
!2974 = !{!2975, !2975, i64 0}
!2975 = !{!"0xca76140.w1.b1", !2962, i64 0}
!2976 = !{!2977, !2977, i64 0}
!2977 = !{!"0xca76140.w1.b2", !2978, i64 0}
!2978 = !{!"0xca76140.w2.b2", !2963, i64 0}
!2979 = !{!2980, !2980, i64 0}
!2980 = !{!"0xca76140.w1.b3", !2978, i64 0}
!2981 = !{!2982, !2982, i64 0}
!2982 = !{!"0xca76140.w1.b4", !2983, i64 0}
!2983 = !{!"0xca76140.w2.b4", !2984, i64 0}
!2984 = !{!"0xca76140.w4.b4", !2964, i64 0}
!2985 = !{!2986, !2986, i64 0}
!2986 = !{!"0xca77170.w4.b0", !2987, i64 0}
!2987 = !{!"0xca77170.w8.b0", !2988, i64 0}
!2988 = !{!"0xca77170.w16.b0", !2989, i64 0}
!2989 = !{!"0xca77170.w32.b0", !2990, i64 0}
!2990 = !{!"0xca77170.w64.b0", !2991, i64 0}
!2991 = !{!"0xca77170.w128.b0", !2992, i64 0}
!2992 = !{!"0xca77170.w256.b0", !2993, i64 0}
!2993 = !{!"0xca77170.w512.b0", !2994, i64 0}
!2994 = !{!"0xca77170.w1024.b0", !2995, i64 0}
!2995 = !{!"int64", !2996, i64 0}
!2996 = !{!"0xca77170", !8, i64 0}
!2997 = !{!2998, !2998, i64 0}
!2998 = !{!"0xca77170.w1.b4", !2999, i64 0}
!2999 = !{!"0xca77170.w2.b4", !3000, i64 0}
!3000 = !{!"0xca77170.w4.b4", !2987, i64 0}
!3001 = !{!3002, !3002, i64 0}
!3002 = !{!"float32", !3003, i64 0}
!3003 = !{!"0xa568dd0", !8, i64 0}
!3004 = !{!3005, !3005, i64 0}
!3005 = !{!"float32", !3006, i64 0}
!3006 = !{!"0xa568d80", !8, i64 0}
!3007 = !{!3008, !3008, i64 0}
!3008 = !{!"0xa913a80.w1.b0", !3009, i64 0}
!3009 = !{!"0xa913a80.w2.b0", !3010, i64 0}
!3010 = !{!"0xa913a80.w4.b0", !3011, i64 0}
!3011 = !{!"0xa913a80.w8.b0", !3012, i64 0}
!3012 = !{!"0xa913a80.w16.b0", !3013, i64 0}
!3013 = !{!"0xa913a80.w32.b0", !3014, i64 0}
!3014 = !{!"0xa913a80.w64.b0", !3015, i64 0}
!3015 = !{!"0xa913a80.w128.b0", !3016, i64 0}
!3016 = !{!"0xa913a80.w256.b0", !3017, i64 0}
!3017 = !{!"0xa913a80.w512.b0", !3018, i64 0}
!3018 = !{!"0xa913a80.w1024.b0", !3019, i64 0}
!3019 = !{!"int32", !3020, i64 0}
!3020 = !{!"0xa913a80", !8, i64 0}
!3021 = !{!3022, !3022, i64 0}
!3022 = !{!"0xa913a80.w1.b2", !3023, i64 0}
!3023 = !{!"0xa913a80.w2.b2", !3010, i64 0}
!3024 = !{!3025, !3025, i64 0}
!3025 = !{!"0xa913a80.w1.b3", !3023, i64 0}
!3026 = !{!3027, !3027, i64 0}
!3027 = !{!"0xa913a80.w1.b4", !3028, i64 0}
!3028 = !{!"0xa913a80.w2.b4", !3029, i64 0}
!3029 = !{!"0xa913a80.w4.b4", !3011, i64 0}
!3030 = !{!3031, !3031, i64 0}
!3031 = !{!"0xa913a80.w1.b1", !3009, i64 0}
!3032 = !{!3033, !3033, i64 0}
!3033 = !{!"0x139730a0.w1.b0", !3034, i64 0}
!3034 = !{!"0x139730a0.w2.b0", !3035, i64 0}
!3035 = !{!"0x139730a0.w4.b0", !3036, i64 0}
!3036 = !{!"0x139730a0.w8.b0", !3037, i64 0}
!3037 = !{!"0x139730a0.w16.b0", !3038, i64 0}
!3038 = !{!"0x139730a0.w32.b0", !3039, i64 0}
!3039 = !{!"0x139730a0.w64.b0", !3040, i64 0}
!3040 = !{!"0x139730a0.w128.b0", !3041, i64 0}
!3041 = !{!"0x139730a0.w256.b0", !3042, i64 0}
!3042 = !{!"0x139730a0.w512.b0", !3043, i64 0}
!3043 = !{!"0x139730a0.w1024.b0", !3044, i64 0}
!3044 = !{!"int64", !3045, i64 0}
!3045 = !{!"0x139730a0", !8, i64 0}
!3046 = !{!3047, !3047, i64 0}
!3047 = !{!"0x139730a0.w1.b1", !3034, i64 0}
!3048 = !{!3049, !3049, i64 0}
!3049 = !{!"0x139730a0.w1.b2", !3050, i64 0}
!3050 = !{!"0x139730a0.w2.b2", !3035, i64 0}
!3051 = !{!3052, !3052, i64 0}
!3052 = !{!"0x139730a0.w1.b3", !3050, i64 0}
!3053 = !{!3054, !3054, i64 0}
!3054 = !{!"0x139730a0.w1.b4", !3055, i64 0}
!3055 = !{!"0x139730a0.w2.b4", !3056, i64 0}
!3056 = !{!"0x139730a0.w4.b4", !3036, i64 0}
!3057 = !{!3058, !3058, i64 0}
!3058 = !{!"0x998a3d0.w4.b0", !3059, i64 0}
!3059 = !{!"0x998a3d0.w8.b0", !3060, i64 0}
!3060 = !{!"0x998a3d0.w16.b0", !3061, i64 0}
!3061 = !{!"0x998a3d0.w32.b0", !3062, i64 0}
!3062 = !{!"0x998a3d0.w64.b0", !3063, i64 0}
!3063 = !{!"0x998a3d0.w128.b0", !3064, i64 0}
!3064 = !{!"0x998a3d0.w256.b0", !3065, i64 0}
!3065 = !{!"0x998a3d0.w512.b0", !3066, i64 0}
!3066 = !{!"0x998a3d0.w1024.b0", !3067, i64 0}
!3067 = !{!"int64", !3068, i64 0}
!3068 = !{!"0x998a3d0", !8, i64 0}
!3069 = !{!3070, !3070, i64 0}
!3070 = !{!"0x998a3d0.w1.b4", !3071, i64 0}
!3071 = !{!"0x998a3d0.w2.b4", !3072, i64 0}
!3072 = !{!"0x998a3d0.w4.b4", !3059, i64 0}
!3073 = !{!3074, !3074, i64 0}
!3074 = !{!"0x1f34dd00.w1.b0", !3075, i64 0}
!3075 = !{!"0x1f34dd00.w2.b0", !3076, i64 0}
!3076 = !{!"0x1f34dd00.w4.b0", !3077, i64 0}
!3077 = !{!"0x1f34dd00.w8.b0", !3078, i64 0}
!3078 = !{!"0x1f34dd00.w16.b0", !3079, i64 0}
!3079 = !{!"0x1f34dd00.w32.b0", !3080, i64 0}
!3080 = !{!"0x1f34dd00.w64.b0", !3081, i64 0}
!3081 = !{!"0x1f34dd00.w128.b0", !3082, i64 0}
!3082 = !{!"0x1f34dd00.w256.b0", !3083, i64 0}
!3083 = !{!"0x1f34dd00.w512.b0", !3084, i64 0}
!3084 = !{!"0x1f34dd00.w1024.b0", !3085, i64 0}
!3085 = !{!"int64", !3086, i64 0}
!3086 = !{!"0x1f34dd00", !8, i64 0}
!3087 = !{!3088, !3088, i64 0}
!3088 = !{!"0x1f34dd00.w1.b1", !3075, i64 0}
!3089 = !{!3090, !3090, i64 0}
!3090 = !{!"0x1f34dd00.w1.b2", !3091, i64 0}
!3091 = !{!"0x1f34dd00.w2.b2", !3076, i64 0}
!3092 = !{!3093, !3093, i64 0}
!3093 = !{!"0x1f34dd00.w1.b3", !3091, i64 0}
!3094 = !{!3095, !3095, i64 0}
!3095 = !{!"0x1f34dd00.w1.b4", !3096, i64 0}
!3096 = !{!"0x1f34dd00.w2.b4", !3097, i64 0}
!3097 = !{!"0x1f34dd00.w4.b4", !3077, i64 0}
!3098 = !{!3099, !3099, i64 0}
!3099 = !{!"0x1f34dd00.w1.b5", !3096, i64 0}
!3100 = !{!3101, !3101, i64 0}
!3101 = !{!"0x9d38260.w4.b0", !3102, i64 0}
!3102 = !{!"0x9d38260.w8.b0", !3103, i64 0}
!3103 = !{!"0x9d38260.w16.b0", !3104, i64 0}
!3104 = !{!"0x9d38260.w32.b0", !3105, i64 0}
!3105 = !{!"0x9d38260.w64.b0", !3106, i64 0}
!3106 = !{!"0x9d38260.w128.b0", !3107, i64 0}
!3107 = !{!"0x9d38260.w256.b0", !3108, i64 0}
!3108 = !{!"0x9d38260.w512.b0", !3109, i64 0}
!3109 = !{!"0x9d38260.w1024.b0", !3110, i64 0}
!3110 = !{!"int64", !3111, i64 0}
!3111 = !{!"0x9d38260", !8, i64 0}
!3112 = !{!3113, !3113, i64 0}
!3113 = !{!"0x9d38260.w1.b4", !3114, i64 0}
!3114 = !{!"0x9d38260.w2.b4", !3115, i64 0}
!3115 = !{!"0x9d38260.w4.b4", !3102, i64 0}
!3116 = !{!3117, !3117, i64 0}
!3117 = !{!"0x9d38260.w1.b5", !3114, i64 0}
!3118 = !{!3119, !3119, i64 0}
!3119 = !{!"0xc922470.w1.b0", !3120, i64 0}
!3120 = !{!"0xc922470.w2.b0", !3121, i64 0}
!3121 = !{!"0xc922470.w4.b0", !3122, i64 0}
!3122 = !{!"0xc922470.w8.b0", !3123, i64 0}
!3123 = !{!"0xc922470.w16.b0", !3124, i64 0}
!3124 = !{!"0xc922470.w32.b0", !3125, i64 0}
!3125 = !{!"0xc922470.w64.b0", !3126, i64 0}
!3126 = !{!"0xc922470.w128.b0", !3127, i64 0}
!3127 = !{!"0xc922470.w256.b0", !3128, i64 0}
!3128 = !{!"0xc922470.w512.b0", !3129, i64 0}
!3129 = !{!"0xc922470.w1024.b0", !3130, i64 0}
!3130 = !{!"int64", !3131, i64 0}
!3131 = !{!"0xc922470", !8, i64 0}
!3132 = !{!3133, !3133, i64 0}
!3133 = !{!"0xc922470.w1.b1", !3120, i64 0}
!3134 = !{!3135, !3135, i64 0}
!3135 = !{!"0xc922470.w1.b2", !3136, i64 0}
!3136 = !{!"0xc922470.w2.b2", !3121, i64 0}
!3137 = !{!3138, !3138, i64 0}
!3138 = !{!"0xc922470.w1.b3", !3136, i64 0}
!3139 = !{!3140, !3140, i64 0}
!3140 = !{!"0xc5bece0.w4.b0", !3141, i64 0}
!3141 = !{!"0xc5bece0.w8.b0", !3142, i64 0}
!3142 = !{!"0xc5bece0.w16.b0", !3143, i64 0}
!3143 = !{!"0xc5bece0.w32.b0", !3144, i64 0}
!3144 = !{!"0xc5bece0.w64.b0", !3145, i64 0}
!3145 = !{!"0xc5bece0.w128.b0", !3146, i64 0}
!3146 = !{!"0xc5bece0.w256.b0", !3147, i64 0}
!3147 = !{!"0xc5bece0.w512.b0", !3148, i64 0}
!3148 = !{!"0xc5bece0.w1024.b0", !3149, i64 0}
!3149 = !{!"int64", !3150, i64 0}
!3150 = !{!"0xc5bece0", !8, i64 0}
!3151 = !{!3152, !3152, i64 0}
!3152 = !{!"0xb5cf980.w1.b0", !3153, i64 0}
!3153 = !{!"0xb5cf980.w2.b0", !3154, i64 0}
!3154 = !{!"0xb5cf980.w4.b0", !3155, i64 0}
!3155 = !{!"0xb5cf980.w8.b0", !3156, i64 0}
!3156 = !{!"0xb5cf980.w16.b0", !3157, i64 0}
!3157 = !{!"0xb5cf980.w32.b0", !3158, i64 0}
!3158 = !{!"0xb5cf980.w64.b0", !3159, i64 0}
!3159 = !{!"0xb5cf980.w128.b0", !3160, i64 0}
!3160 = !{!"0xb5cf980.w256.b0", !3161, i64 0}
!3161 = !{!"0xb5cf980.w512.b0", !3162, i64 0}
!3162 = !{!"0xb5cf980.w1024.b0", !3163, i64 0}
!3163 = !{!"int64", !3164, i64 0}
!3164 = !{!"0xb5cf980", !8, i64 0}
!3165 = !{!3166, !3166, i64 0}
!3166 = !{!"0xb5cf980.w1.b1", !3153, i64 0}
!3167 = !{!3168, !3168, i64 0}
!3168 = !{!"0xb5cf980.w1.b2", !3169, i64 0}
!3169 = !{!"0xb5cf980.w2.b2", !3154, i64 0}
!3170 = !{!3171, !3171, i64 0}
!3171 = !{!"0xb5cf980.w1.b3", !3169, i64 0}
!3172 = !{!3173, !3173, i64 0}
!3173 = !{!"0x139d9560.w4.b0", !3174, i64 0}
!3174 = !{!"0x139d9560.w8.b0", !3175, i64 0}
!3175 = !{!"0x139d9560.w16.b0", !3176, i64 0}
!3176 = !{!"0x139d9560.w32.b0", !3177, i64 0}
!3177 = !{!"0x139d9560.w64.b0", !3178, i64 0}
!3178 = !{!"0x139d9560.w128.b0", !3179, i64 0}
!3179 = !{!"0x139d9560.w256.b0", !3180, i64 0}
!3180 = !{!"0x139d9560.w512.b0", !3181, i64 0}
!3181 = !{!"0x139d9560.w1024.b0", !3182, i64 0}
!3182 = !{!"int64", !3183, i64 0}
!3183 = !{!"0x139d9560", !8, i64 0}
!3184 = !{!3185, !3185, i64 0}
!3185 = !{!"0x1f347630.w1.b0", !3186, i64 0}
!3186 = !{!"0x1f347630.w2.b0", !3187, i64 0}
!3187 = !{!"0x1f347630.w4.b0", !3188, i64 0}
!3188 = !{!"0x1f347630.w8.b0", !3189, i64 0}
!3189 = !{!"0x1f347630.w16.b0", !3190, i64 0}
!3190 = !{!"0x1f347630.w32.b0", !3191, i64 0}
!3191 = !{!"0x1f347630.w64.b0", !3192, i64 0}
!3192 = !{!"0x1f347630.w128.b0", !3193, i64 0}
!3193 = !{!"0x1f347630.w256.b0", !3194, i64 0}
!3194 = !{!"0x1f347630.w512.b0", !3195, i64 0}
!3195 = !{!"0x1f347630.w1024.b0", !3196, i64 0}
!3196 = !{!"int64", !3197, i64 0}
!3197 = !{!"0x1f347630", !8, i64 0}
!3198 = !{!3199, !3199, i64 0}
!3199 = !{!"0x1f347630.w1.b1", !3186, i64 0}
!3200 = !{!3201, !3201, i64 0}
!3201 = !{!"0x1f347630.w1.b2", !3202, i64 0}
!3202 = !{!"0x1f347630.w2.b2", !3187, i64 0}
!3203 = !{!3204, !3204, i64 0}
!3204 = !{!"0x1f347630.w1.b3", !3202, i64 0}
!3205 = !{!3206, !3206, i64 0}
!3206 = !{!"0x1f347630.w1.b4", !3207, i64 0}
!3207 = !{!"0x1f347630.w2.b4", !3208, i64 0}
!3208 = !{!"0x1f347630.w4.b4", !3188, i64 0}
!3209 = !{!3210, !3210, i64 0}
!3210 = !{!"0x1d0c12d0.w4.b0", !3211, i64 0}
!3211 = !{!"0x1d0c12d0.w8.b0", !3212, i64 0}
!3212 = !{!"0x1d0c12d0.w16.b0", !3213, i64 0}
!3213 = !{!"0x1d0c12d0.w32.b0", !3214, i64 0}
!3214 = !{!"0x1d0c12d0.w64.b0", !3215, i64 0}
!3215 = !{!"0x1d0c12d0.w128.b0", !3216, i64 0}
!3216 = !{!"0x1d0c12d0.w256.b0", !3217, i64 0}
!3217 = !{!"0x1d0c12d0.w512.b0", !3218, i64 0}
!3218 = !{!"0x1d0c12d0.w1024.b0", !3219, i64 0}
!3219 = !{!"int64", !3220, i64 0}
!3220 = !{!"0x1d0c12d0", !8, i64 0}
!3221 = !{!3222, !3222, i64 0}
!3222 = !{!"0x1d0c12d0.w1.b4", !3223, i64 0}
!3223 = !{!"0x1d0c12d0.w2.b4", !3224, i64 0}
!3224 = !{!"0x1d0c12d0.w4.b4", !3211, i64 0}
!3225 = !{!3226, !3226, i64 0}
!3226 = !{!"float32", !3227, i64 0}
!3227 = !{!"0xd52afe0", !8, i64 0}
!3228 = !{!3229, !3229, i64 0}
!3229 = !{!"float32", !3230, i64 0}
!3230 = !{!"0xa8c61c0", !8, i64 0}
!3231 = !{!3232, !3232, i64 0}
!3232 = !{!"float32", !3233, i64 0}
!3233 = !{!"0x1f3521a0", !8, i64 0}
!3234 = !{!3235, !3235, i64 0}
!3235 = !{!"float32", !3236, i64 0}
!3236 = !{!"0x13b11bd0", !8, i64 0}
!3237 = !{!3238, !3238, i64 0}
!3238 = !{!"float32", !3239, i64 0}
!3239 = !{!"0x1b7a6a00", !8, i64 0}
!3240 = !{!3241, !3241, i64 0}
!3241 = !{!"0xca319e0.w1.b0", !3242, i64 0}
!3242 = !{!"0xca319e0.w2.b0", !3243, i64 0}
!3243 = !{!"0xca319e0.w4.b0", !3244, i64 0}
!3244 = !{!"0xca319e0.w8.b0", !3245, i64 0}
!3245 = !{!"0xca319e0.w16.b0", !3246, i64 0}
!3246 = !{!"0xca319e0.w32.b0", !3247, i64 0}
!3247 = !{!"0xca319e0.w64.b0", !3248, i64 0}
!3248 = !{!"0xca319e0.w128.b0", !3249, i64 0}
!3249 = !{!"0xca319e0.w256.b0", !3250, i64 0}
!3250 = !{!"0xca319e0.w512.b0", !3251, i64 0}
!3251 = !{!"0xca319e0.w1024.b0", !3252, i64 0}
!3252 = !{!"int32", !3253, i64 0}
!3253 = !{!"0xca319e0", !8, i64 0}
!3254 = !{!3255, !3255, i64 0}
!3255 = !{!"0xca319e0.w1.b2", !3256, i64 0}
!3256 = !{!"0xca319e0.w2.b2", !3243, i64 0}
!3257 = !{!3258, !3258, i64 0}
!3258 = !{!"0xca319e0.w1.b3", !3256, i64 0}
!3259 = !{!3260, !3260, i64 0}
!3260 = !{!"0xca319e0.w1.b4", !3261, i64 0}
!3261 = !{!"0xca319e0.w2.b4", !3262, i64 0}
!3262 = !{!"0xca319e0.w4.b4", !3244, i64 0}
!3263 = !{!3264, !3264, i64 0}
!3264 = !{!"0xca319e0.w1.b5", !3261, i64 0}
!3265 = !{!3266, !3266, i64 0}
!3266 = !{!"0xca319e0.w1.b1", !3242, i64 0}
!3267 = !{!3268, !3268, i64 0}
!3268 = !{!"0xca373b0.w1.b0", !3269, i64 0}
!3269 = !{!"0xca373b0.w2.b0", !3270, i64 0}
!3270 = !{!"0xca373b0.w4.b0", !3271, i64 0}
!3271 = !{!"0xca373b0.w8.b0", !3272, i64 0}
!3272 = !{!"0xca373b0.w16.b0", !3273, i64 0}
!3273 = !{!"0xca373b0.w32.b0", !3274, i64 0}
!3274 = !{!"0xca373b0.w64.b0", !3275, i64 0}
!3275 = !{!"0xca373b0.w128.b0", !3276, i64 0}
!3276 = !{!"0xca373b0.w256.b0", !3277, i64 0}
!3277 = !{!"0xca373b0.w512.b0", !3278, i64 0}
!3278 = !{!"0xca373b0.w1024.b0", !3279, i64 0}
!3279 = !{!"int64", !3280, i64 0}
!3280 = !{!"0xca373b0", !8, i64 0}
!3281 = !{!3282, !3282, i64 0}
!3282 = !{!"0xca373b0.w1.b1", !3269, i64 0}
!3283 = !{!3284, !3284, i64 0}
!3284 = !{!"0xca373b0.w1.b2", !3285, i64 0}
!3285 = !{!"0xca373b0.w2.b2", !3270, i64 0}
!3286 = !{!3287, !3287, i64 0}
!3287 = !{!"0xca373b0.w1.b3", !3285, i64 0}
!3288 = !{!3289, !3289, i64 0}
!3289 = !{!"0xca373b0.w1.b4", !3290, i64 0}
!3290 = !{!"0xca373b0.w2.b4", !3291, i64 0}
!3291 = !{!"0xca373b0.w4.b4", !3271, i64 0}
!3292 = !{!3293, !3293, i64 0}
!3293 = !{!"0xca363c0.w4.b0", !3294, i64 0}
!3294 = !{!"0xca363c0.w8.b0", !3295, i64 0}
!3295 = !{!"0xca363c0.w16.b0", !3296, i64 0}
!3296 = !{!"0xca363c0.w32.b0", !3297, i64 0}
!3297 = !{!"0xca363c0.w64.b0", !3298, i64 0}
!3298 = !{!"0xca363c0.w128.b0", !3299, i64 0}
!3299 = !{!"0xca363c0.w256.b0", !3300, i64 0}
!3300 = !{!"0xca363c0.w512.b0", !3301, i64 0}
!3301 = !{!"0xca363c0.w1024.b0", !3302, i64 0}
!3302 = !{!"int64", !3303, i64 0}
!3303 = !{!"0xca363c0", !8, i64 0}
!3304 = !{!3305, !3305, i64 0}
!3305 = !{!"0xca363c0.w1.b4", !3306, i64 0}
!3306 = !{!"0xca363c0.w2.b4", !3307, i64 0}
!3307 = !{!"0xca363c0.w4.b4", !3294, i64 0}
!3308 = !{!3309, !3309, i64 0}
!3309 = !{!"0xca39c50.w1.b0", !3310, i64 0}
!3310 = !{!"0xca39c50.w2.b0", !3311, i64 0}
!3311 = !{!"0xca39c50.w4.b0", !3312, i64 0}
!3312 = !{!"0xca39c50.w8.b0", !3313, i64 0}
!3313 = !{!"0xca39c50.w16.b0", !3314, i64 0}
!3314 = !{!"0xca39c50.w32.b0", !3315, i64 0}
!3315 = !{!"0xca39c50.w64.b0", !3316, i64 0}
!3316 = !{!"0xca39c50.w128.b0", !3317, i64 0}
!3317 = !{!"0xca39c50.w256.b0", !3318, i64 0}
!3318 = !{!"0xca39c50.w512.b0", !3319, i64 0}
!3319 = !{!"0xca39c50.w1024.b0", !3320, i64 0}
!3320 = !{!"int64", !3321, i64 0}
!3321 = !{!"0xca39c50", !8, i64 0}
!3322 = !{!3323, !3323, i64 0}
!3323 = !{!"0xca39c50.w1.b1", !3310, i64 0}
!3324 = !{!3325, !3325, i64 0}
!3325 = !{!"0xca39c50.w1.b2", !3326, i64 0}
!3326 = !{!"0xca39c50.w2.b2", !3311, i64 0}
!3327 = !{!3328, !3328, i64 0}
!3328 = !{!"0xca39c50.w1.b3", !3326, i64 0}
!3329 = !{!3330, !3330, i64 0}
!3330 = !{!"0xca39c50.w1.b4", !3331, i64 0}
!3331 = !{!"0xca39c50.w2.b4", !3332, i64 0}
!3332 = !{!"0xca39c50.w4.b4", !3312, i64 0}
!3333 = !{!3334, !3334, i64 0}
!3334 = !{!"0xca39c50.w1.b5", !3331, i64 0}
!3335 = !{!3336, !3336, i64 0}
!3336 = !{!"0xca3aca0.w4.b0", !3337, i64 0}
!3337 = !{!"0xca3aca0.w8.b0", !3338, i64 0}
!3338 = !{!"0xca3aca0.w16.b0", !3339, i64 0}
!3339 = !{!"0xca3aca0.w32.b0", !3340, i64 0}
!3340 = !{!"0xca3aca0.w64.b0", !3341, i64 0}
!3341 = !{!"0xca3aca0.w128.b0", !3342, i64 0}
!3342 = !{!"0xca3aca0.w256.b0", !3343, i64 0}
!3343 = !{!"0xca3aca0.w512.b0", !3344, i64 0}
!3344 = !{!"0xca3aca0.w1024.b0", !3345, i64 0}
!3345 = !{!"int64", !3346, i64 0}
!3346 = !{!"0xca3aca0", !8, i64 0}
!3347 = !{!3348, !3348, i64 0}
!3348 = !{!"0xca3aca0.w1.b4", !3349, i64 0}
!3349 = !{!"0xca3aca0.w2.b4", !3350, i64 0}
!3350 = !{!"0xca3aca0.w4.b4", !3337, i64 0}
!3351 = !{!3352, !3352, i64 0}
!3352 = !{!"0xca3aca0.w1.b5", !3349, i64 0}
!3353 = !{!3354, !3354, i64 0}
!3354 = !{!"0xca3d020.w1.b0", !3355, i64 0}
!3355 = !{!"0xca3d020.w2.b0", !3356, i64 0}
!3356 = !{!"0xca3d020.w4.b0", !3357, i64 0}
!3357 = !{!"0xca3d020.w8.b0", !3358, i64 0}
!3358 = !{!"0xca3d020.w16.b0", !3359, i64 0}
!3359 = !{!"0xca3d020.w32.b0", !3360, i64 0}
!3360 = !{!"0xca3d020.w64.b0", !3361, i64 0}
!3361 = !{!"0xca3d020.w128.b0", !3362, i64 0}
!3362 = !{!"0xca3d020.w256.b0", !3363, i64 0}
!3363 = !{!"0xca3d020.w512.b0", !3364, i64 0}
!3364 = !{!"0xca3d020.w1024.b0", !3365, i64 0}
!3365 = !{!"int64", !3366, i64 0}
!3366 = !{!"0xca3d020", !8, i64 0}
!3367 = !{!3368, !3368, i64 0}
!3368 = !{!"0xca3d020.w1.b1", !3355, i64 0}
!3369 = !{!3370, !3370, i64 0}
!3370 = !{!"0xca3d020.w1.b2", !3371, i64 0}
!3371 = !{!"0xca3d020.w2.b2", !3356, i64 0}
!3372 = !{!3373, !3373, i64 0}
!3373 = !{!"0xca3d020.w1.b3", !3371, i64 0}
!3374 = !{!3375, !3375, i64 0}
!3375 = !{!"0xca3dbb0.w4.b0", !3376, i64 0}
!3376 = !{!"0xca3dbb0.w8.b0", !3377, i64 0}
!3377 = !{!"0xca3dbb0.w16.b0", !3378, i64 0}
!3378 = !{!"0xca3dbb0.w32.b0", !3379, i64 0}
!3379 = !{!"0xca3dbb0.w64.b0", !3380, i64 0}
!3380 = !{!"0xca3dbb0.w128.b0", !3381, i64 0}
!3381 = !{!"0xca3dbb0.w256.b0", !3382, i64 0}
!3382 = !{!"0xca3dbb0.w512.b0", !3383, i64 0}
!3383 = !{!"0xca3dbb0.w1024.b0", !3384, i64 0}
!3384 = !{!"int64", !3385, i64 0}
!3385 = !{!"0xca3dbb0", !8, i64 0}
!3386 = !{!3387, !3387, i64 0}
!3387 = !{!"0xca2fe70.w1.b0", !3388, i64 0}
!3388 = !{!"0xca2fe70.w2.b0", !3389, i64 0}
!3389 = !{!"0xca2fe70.w4.b0", !3390, i64 0}
!3390 = !{!"0xca2fe70.w8.b0", !3391, i64 0}
!3391 = !{!"0xca2fe70.w16.b0", !3392, i64 0}
!3392 = !{!"0xca2fe70.w32.b0", !3393, i64 0}
!3393 = !{!"0xca2fe70.w64.b0", !3394, i64 0}
!3394 = !{!"0xca2fe70.w128.b0", !3395, i64 0}
!3395 = !{!"0xca2fe70.w256.b0", !3396, i64 0}
!3396 = !{!"0xca2fe70.w512.b0", !3397, i64 0}
!3397 = !{!"0xca2fe70.w1024.b0", !3398, i64 0}
!3398 = !{!"int64", !3399, i64 0}
!3399 = !{!"0xca2fe70", !8, i64 0}
!3400 = !{!3401, !3401, i64 0}
!3401 = !{!"0xca2fe70.w1.b1", !3388, i64 0}
!3402 = !{!3403, !3403, i64 0}
!3403 = !{!"0xca2fe70.w1.b2", !3404, i64 0}
!3404 = !{!"0xca2fe70.w2.b2", !3389, i64 0}
!3405 = !{!3406, !3406, i64 0}
!3406 = !{!"0xca2fe70.w1.b3", !3404, i64 0}
!3407 = !{!3408, !3408, i64 0}
!3408 = !{!"0xca40910.w4.b0", !3409, i64 0}
!3409 = !{!"0xca40910.w8.b0", !3410, i64 0}
!3410 = !{!"0xca40910.w16.b0", !3411, i64 0}
!3411 = !{!"0xca40910.w32.b0", !3412, i64 0}
!3412 = !{!"0xca40910.w64.b0", !3413, i64 0}
!3413 = !{!"0xca40910.w128.b0", !3414, i64 0}
!3414 = !{!"0xca40910.w256.b0", !3415, i64 0}
!3415 = !{!"0xca40910.w512.b0", !3416, i64 0}
!3416 = !{!"0xca40910.w1024.b0", !3417, i64 0}
!3417 = !{!"int64", !3418, i64 0}
!3418 = !{!"0xca40910", !8, i64 0}
!3419 = !{!3420, !3420, i64 0}
!3420 = !{!"0xca429f0.w1.b0", !3421, i64 0}
!3421 = !{!"0xca429f0.w2.b0", !3422, i64 0}
!3422 = !{!"0xca429f0.w4.b0", !3423, i64 0}
!3423 = !{!"0xca429f0.w8.b0", !3424, i64 0}
!3424 = !{!"0xca429f0.w16.b0", !3425, i64 0}
!3425 = !{!"0xca429f0.w32.b0", !3426, i64 0}
!3426 = !{!"0xca429f0.w64.b0", !3427, i64 0}
!3427 = !{!"0xca429f0.w128.b0", !3428, i64 0}
!3428 = !{!"0xca429f0.w256.b0", !3429, i64 0}
!3429 = !{!"0xca429f0.w512.b0", !3430, i64 0}
!3430 = !{!"0xca429f0.w1024.b0", !3431, i64 0}
!3431 = !{!"int64", !3432, i64 0}
!3432 = !{!"0xca429f0", !8, i64 0}
!3433 = !{!3434, !3434, i64 0}
!3434 = !{!"0xca429f0.w1.b1", !3421, i64 0}
!3435 = !{!3436, !3436, i64 0}
!3436 = !{!"0xca429f0.w1.b2", !3437, i64 0}
!3437 = !{!"0xca429f0.w2.b2", !3422, i64 0}
!3438 = !{!3439, !3439, i64 0}
!3439 = !{!"0xca429f0.w1.b3", !3437, i64 0}
!3440 = !{!3441, !3441, i64 0}
!3441 = !{!"0xca43670.w4.b0", !3442, i64 0}
!3442 = !{!"0xca43670.w8.b0", !3443, i64 0}
!3443 = !{!"0xca43670.w16.b0", !3444, i64 0}
!3444 = !{!"0xca43670.w32.b0", !3445, i64 0}
!3445 = !{!"0xca43670.w64.b0", !3446, i64 0}
!3446 = !{!"0xca43670.w128.b0", !3447, i64 0}
!3447 = !{!"0xca43670.w256.b0", !3448, i64 0}
!3448 = !{!"0xca43670.w512.b0", !3449, i64 0}
!3449 = !{!"0xca43670.w1024.b0", !3450, i64 0}
!3450 = !{!"int64", !3451, i64 0}
!3451 = !{!"0xca43670", !8, i64 0}
!3452 = !{!3453, !3453, i64 0}
!3453 = !{!"0xca455a0.w1.b0", !3454, i64 0}
!3454 = !{!"0xca455a0.w2.b0", !3455, i64 0}
!3455 = !{!"0xca455a0.w4.b0", !3456, i64 0}
!3456 = !{!"0xca455a0.w8.b0", !3457, i64 0}
!3457 = !{!"0xca455a0.w16.b0", !3458, i64 0}
!3458 = !{!"0xca455a0.w32.b0", !3459, i64 0}
!3459 = !{!"0xca455a0.w64.b0", !3460, i64 0}
!3460 = !{!"0xca455a0.w128.b0", !3461, i64 0}
!3461 = !{!"0xca455a0.w256.b0", !3462, i64 0}
!3462 = !{!"0xca455a0.w512.b0", !3463, i64 0}
!3463 = !{!"0xca455a0.w1024.b0", !3464, i64 0}
!3464 = !{!"int64", !3465, i64 0}
!3465 = !{!"0xca455a0", !8, i64 0}
!3466 = !{!3467, !3467, i64 0}
!3467 = !{!"0xca455a0.w1.b1", !3454, i64 0}
!3468 = !{!3469, !3469, i64 0}
!3469 = !{!"0xca455a0.w1.b2", !3470, i64 0}
!3470 = !{!"0xca455a0.w2.b2", !3455, i64 0}
!3471 = !{!3472, !3472, i64 0}
!3472 = !{!"0xca455a0.w1.b3", !3470, i64 0}
!3473 = !{!3474, !3474, i64 0}
!3474 = !{!"0xca455a0.w1.b4", !3475, i64 0}
!3475 = !{!"0xca455a0.w2.b4", !3476, i64 0}
!3476 = !{!"0xca455a0.w4.b4", !3456, i64 0}
!3477 = !{!3478, !3478, i64 0}
!3478 = !{!"0xca463d0.w4.b0", !3479, i64 0}
!3479 = !{!"0xca463d0.w8.b0", !3480, i64 0}
!3480 = !{!"0xca463d0.w16.b0", !3481, i64 0}
!3481 = !{!"0xca463d0.w32.b0", !3482, i64 0}
!3482 = !{!"0xca463d0.w64.b0", !3483, i64 0}
!3483 = !{!"0xca463d0.w128.b0", !3484, i64 0}
!3484 = !{!"0xca463d0.w256.b0", !3485, i64 0}
!3485 = !{!"0xca463d0.w512.b0", !3486, i64 0}
!3486 = !{!"0xca463d0.w1024.b0", !3487, i64 0}
!3487 = !{!"int64", !3488, i64 0}
!3488 = !{!"0xca463d0", !8, i64 0}
!3489 = !{!3490, !3490, i64 0}
!3490 = !{!"0xca463d0.w1.b4", !3491, i64 0}
!3491 = !{!"0xca463d0.w2.b4", !3492, i64 0}
!3492 = !{!"0xca463d0.w4.b4", !3479, i64 0}
!3493 = !{!3494, !3494, i64 0}
!3494 = !{!"float32", !3495, i64 0}
!3495 = !{!"0xca30c80", !8, i64 0}
!3496 = !{!3497, !3497, i64 0}
!3497 = !{!"float32", !3498, i64 0}
!3498 = !{!"0xca28a40", !8, i64 0}
!3499 = !{!3500, !3500, i64 0}
!3500 = !{!"float32", !3501, i64 0}
!3501 = !{!"0xca2ab20", !8, i64 0}
!3502 = !{!3503, !3503, i64 0}
!3503 = !{!"float32", !3504, i64 0}
!3504 = !{!"0xca2b0a0", !8, i64 0}
!3505 = !{!3506, !3506, i64 0}
!3506 = !{!"float32", !3507, i64 0}
!3507 = !{!"0xca27da0", !8, i64 0}
!3508 = !{!3509, !3509, i64 0}
!3509 = !{!"float32", !3510, i64 0}
!3510 = !{!"0xca28560", !8, i64 0}
!3511 = !{!3512, !3512, i64 0}
!3512 = !{!"float32", !3513, i64 0}
!3513 = !{!"0xca28880", !8, i64 0}
!3514 = !{!3515, !3515, i64 0}
!3515 = !{!"0x93ed8e0.w1.b0", !3516, i64 0}
!3516 = !{!"0x93ed8e0.w2.b0", !3517, i64 0}
!3517 = !{!"0x93ed8e0.w4.b0", !3518, i64 0}
!3518 = !{!"0x93ed8e0.w8.b0", !3519, i64 0}
!3519 = !{!"0x93ed8e0.w16.b0", !3520, i64 0}
!3520 = !{!"0x93ed8e0.w32.b0", !3521, i64 0}
!3521 = !{!"0x93ed8e0.w64.b0", !3522, i64 0}
!3522 = !{!"0x93ed8e0.w128.b0", !3523, i64 0}
!3523 = !{!"0x93ed8e0.w256.b0", !3524, i64 0}
!3524 = !{!"0x93ed8e0.w512.b0", !3525, i64 0}
!3525 = !{!"0x93ed8e0.w1024.b0", !3526, i64 0}
!3526 = !{!"int32", !3527, i64 0}
!3527 = !{!"0x93ed8e0", !8, i64 0}
!3528 = !{!3529, !3529, i64 0}
!3529 = !{!"0x93ed8e0.w1.b2", !3530, i64 0}
!3530 = !{!"0x93ed8e0.w2.b2", !3517, i64 0}
!3531 = !{!3532, !3532, i64 0}
!3532 = !{!"0x93ed8e0.w1.b3", !3530, i64 0}
!3533 = !{!3534, !3534, i64 0}
!3534 = !{!"0x93ed8e0.w1.b4", !3535, i64 0}
!3535 = !{!"0x93ed8e0.w2.b4", !3536, i64 0}
!3536 = !{!"0x93ed8e0.w4.b4", !3518, i64 0}
!3537 = !{!3538, !3538, i64 0}
!3538 = !{!"0x93ed8e0.w1.b5", !3535, i64 0}
!3539 = !{!3540, !3540, i64 0}
!3540 = !{!"0x93ed8e0.w1.b6", !3541, i64 0}
!3541 = !{!"0x93ed8e0.w2.b6", !3536, i64 0}
!3542 = !{!3543, !3543, i64 0}
!3543 = !{!"0x93ed8e0.w1.b1", !3516, i64 0}
!3544 = !{!3545, !3545, i64 0}
!3545 = !{!"0xed25d10.w1.b0", !3546, i64 0}
!3546 = !{!"0xed25d10.w2.b0", !3547, i64 0}
!3547 = !{!"0xed25d10.w4.b0", !3548, i64 0}
!3548 = !{!"0xed25d10.w8.b0", !3549, i64 0}
!3549 = !{!"0xed25d10.w16.b0", !3550, i64 0}
!3550 = !{!"0xed25d10.w32.b0", !3551, i64 0}
!3551 = !{!"0xed25d10.w64.b0", !3552, i64 0}
!3552 = !{!"0xed25d10.w128.b0", !3553, i64 0}
!3553 = !{!"0xed25d10.w256.b0", !3554, i64 0}
!3554 = !{!"0xed25d10.w512.b0", !3555, i64 0}
!3555 = !{!"0xed25d10.w1024.b0", !3556, i64 0}
!3556 = !{!"int64", !3557, i64 0}
!3557 = !{!"0xed25d10", !8, i64 0}
!3558 = !{!3559, !3559, i64 0}
!3559 = !{!"0xed25d10.w1.b1", !3546, i64 0}
!3560 = !{!3561, !3561, i64 0}
!3561 = !{!"0xed25d10.w1.b2", !3562, i64 0}
!3562 = !{!"0xed25d10.w2.b2", !3547, i64 0}
!3563 = !{!3564, !3564, i64 0}
!3564 = !{!"0xed25d10.w1.b3", !3562, i64 0}
!3565 = !{!3566, !3566, i64 0}
!3566 = !{!"0xed25d10.w1.b4", !3567, i64 0}
!3567 = !{!"0xed25d10.w2.b4", !3568, i64 0}
!3568 = !{!"0xed25d10.w4.b4", !3548, i64 0}
!3569 = !{!3570, !3570, i64 0}
!3570 = !{!"0xecd13b0.w4.b0", !3571, i64 0}
!3571 = !{!"0xecd13b0.w8.b0", !3572, i64 0}
!3572 = !{!"0xecd13b0.w16.b0", !3573, i64 0}
!3573 = !{!"0xecd13b0.w32.b0", !3574, i64 0}
!3574 = !{!"0xecd13b0.w64.b0", !3575, i64 0}
!3575 = !{!"0xecd13b0.w128.b0", !3576, i64 0}
!3576 = !{!"0xecd13b0.w256.b0", !3577, i64 0}
!3577 = !{!"0xecd13b0.w512.b0", !3578, i64 0}
!3578 = !{!"0xecd13b0.w1024.b0", !3579, i64 0}
!3579 = !{!"int64", !3580, i64 0}
!3580 = !{!"0xecd13b0", !8, i64 0}
!3581 = !{!3582, !3582, i64 0}
!3582 = !{!"0xecd13b0.w1.b4", !3583, i64 0}
!3583 = !{!"0xecd13b0.w2.b4", !3584, i64 0}
!3584 = !{!"0xecd13b0.w4.b4", !3571, i64 0}
!3585 = !{!3586, !3586, i64 0}
!3586 = !{!"0xd9e70b0.w1.b0", !3587, i64 0}
!3587 = !{!"0xd9e70b0.w2.b0", !3588, i64 0}
!3588 = !{!"0xd9e70b0.w4.b0", !3589, i64 0}
!3589 = !{!"0xd9e70b0.w8.b0", !3590, i64 0}
!3590 = !{!"0xd9e70b0.w16.b0", !3591, i64 0}
!3591 = !{!"0xd9e70b0.w32.b0", !3592, i64 0}
!3592 = !{!"0xd9e70b0.w64.b0", !3593, i64 0}
!3593 = !{!"0xd9e70b0.w128.b0", !3594, i64 0}
!3594 = !{!"0xd9e70b0.w256.b0", !3595, i64 0}
!3595 = !{!"0xd9e70b0.w512.b0", !3596, i64 0}
!3596 = !{!"0xd9e70b0.w1024.b0", !3597, i64 0}
!3597 = !{!"int64", !3598, i64 0}
!3598 = !{!"0xd9e70b0", !8, i64 0}
!3599 = !{!3600, !3600, i64 0}
!3600 = !{!"0xd9e70b0.w1.b1", !3587, i64 0}
!3601 = !{!3602, !3602, i64 0}
!3602 = !{!"0xd9e70b0.w1.b2", !3603, i64 0}
!3603 = !{!"0xd9e70b0.w2.b2", !3588, i64 0}
!3604 = !{!3605, !3605, i64 0}
!3605 = !{!"0xd9e70b0.w1.b3", !3603, i64 0}
!3606 = !{!3607, !3607, i64 0}
!3607 = !{!"0xd9e70b0.w1.b4", !3608, i64 0}
!3608 = !{!"0xd9e70b0.w2.b4", !3609, i64 0}
!3609 = !{!"0xd9e70b0.w4.b4", !3589, i64 0}
!3610 = !{!3611, !3611, i64 0}
!3611 = !{!"0xd9e70b0.w1.b5", !3608, i64 0}
!3612 = !{!3613, !3613, i64 0}
!3613 = !{!"0x6cb7980.w4.b0", !3614, i64 0}
!3614 = !{!"0x6cb7980.w8.b0", !3615, i64 0}
!3615 = !{!"0x6cb7980.w16.b0", !3616, i64 0}
!3616 = !{!"0x6cb7980.w32.b0", !3617, i64 0}
!3617 = !{!"0x6cb7980.w64.b0", !3618, i64 0}
!3618 = !{!"0x6cb7980.w128.b0", !3619, i64 0}
!3619 = !{!"0x6cb7980.w256.b0", !3620, i64 0}
!3620 = !{!"0x6cb7980.w512.b0", !3621, i64 0}
!3621 = !{!"0x6cb7980.w1024.b0", !3622, i64 0}
!3622 = !{!"int64", !3623, i64 0}
!3623 = !{!"0x6cb7980", !8, i64 0}
!3624 = !{!3625, !3625, i64 0}
!3625 = !{!"0x6cb7980.w1.b4", !3626, i64 0}
!3626 = !{!"0x6cb7980.w2.b4", !3627, i64 0}
!3627 = !{!"0x6cb7980.w4.b4", !3614, i64 0}
!3628 = !{!3629, !3629, i64 0}
!3629 = !{!"0x6cb7980.w1.b5", !3626, i64 0}
!3630 = !{!3631, !3631, i64 0}
!3631 = !{!"0xbcfc150.w1.b0", !3632, i64 0}
!3632 = !{!"0xbcfc150.w2.b0", !3633, i64 0}
!3633 = !{!"0xbcfc150.w4.b0", !3634, i64 0}
!3634 = !{!"0xbcfc150.w8.b0", !3635, i64 0}
!3635 = !{!"0xbcfc150.w16.b0", !3636, i64 0}
!3636 = !{!"0xbcfc150.w32.b0", !3637, i64 0}
!3637 = !{!"0xbcfc150.w64.b0", !3638, i64 0}
!3638 = !{!"0xbcfc150.w128.b0", !3639, i64 0}
!3639 = !{!"0xbcfc150.w256.b0", !3640, i64 0}
!3640 = !{!"0xbcfc150.w512.b0", !3641, i64 0}
!3641 = !{!"0xbcfc150.w1024.b0", !3642, i64 0}
!3642 = !{!"int64", !3643, i64 0}
!3643 = !{!"0xbcfc150", !8, i64 0}
!3644 = !{!3645, !3645, i64 0}
!3645 = !{!"0xbcfc150.w1.b1", !3632, i64 0}
!3646 = !{!3647, !3647, i64 0}
!3647 = !{!"0xbcfc150.w1.b2", !3648, i64 0}
!3648 = !{!"0xbcfc150.w2.b2", !3633, i64 0}
!3649 = !{!3650, !3650, i64 0}
!3650 = !{!"0xbcfc150.w1.b3", !3648, i64 0}
!3651 = !{!3652, !3652, i64 0}
!3652 = !{!"0x13b017c0.w4.b0", !3653, i64 0}
!3653 = !{!"0x13b017c0.w8.b0", !3654, i64 0}
!3654 = !{!"0x13b017c0.w16.b0", !3655, i64 0}
!3655 = !{!"0x13b017c0.w32.b0", !3656, i64 0}
!3656 = !{!"0x13b017c0.w64.b0", !3657, i64 0}
!3657 = !{!"0x13b017c0.w128.b0", !3658, i64 0}
!3658 = !{!"0x13b017c0.w256.b0", !3659, i64 0}
!3659 = !{!"0x13b017c0.w512.b0", !3660, i64 0}
!3660 = !{!"0x13b017c0.w1024.b0", !3661, i64 0}
!3661 = !{!"int64", !3662, i64 0}
!3662 = !{!"0x13b017c0", !8, i64 0}
!3663 = !{!3664, !3664, i64 0}
!3664 = !{!"0xd4f0d70.w1.b0", !3665, i64 0}
!3665 = !{!"0xd4f0d70.w2.b0", !3666, i64 0}
!3666 = !{!"0xd4f0d70.w4.b0", !3667, i64 0}
!3667 = !{!"0xd4f0d70.w8.b0", !3668, i64 0}
!3668 = !{!"0xd4f0d70.w16.b0", !3669, i64 0}
!3669 = !{!"0xd4f0d70.w32.b0", !3670, i64 0}
!3670 = !{!"0xd4f0d70.w64.b0", !3671, i64 0}
!3671 = !{!"0xd4f0d70.w128.b0", !3672, i64 0}
!3672 = !{!"0xd4f0d70.w256.b0", !3673, i64 0}
!3673 = !{!"0xd4f0d70.w512.b0", !3674, i64 0}
!3674 = !{!"0xd4f0d70.w1024.b0", !3675, i64 0}
!3675 = !{!"int64", !3676, i64 0}
!3676 = !{!"0xd4f0d70", !8, i64 0}
!3677 = !{!3678, !3678, i64 0}
!3678 = !{!"0xd4f0d70.w1.b1", !3665, i64 0}
!3679 = !{!3680, !3680, i64 0}
!3680 = !{!"0xd4f0d70.w1.b2", !3681, i64 0}
!3681 = !{!"0xd4f0d70.w2.b2", !3666, i64 0}
!3682 = !{!3683, !3683, i64 0}
!3683 = !{!"0xd4f0d70.w1.b3", !3681, i64 0}
!3684 = !{!3685, !3685, i64 0}
!3685 = !{!"0x93f3b20.w4.b0", !3686, i64 0}
!3686 = !{!"0x93f3b20.w8.b0", !3687, i64 0}
!3687 = !{!"0x93f3b20.w16.b0", !3688, i64 0}
!3688 = !{!"0x93f3b20.w32.b0", !3689, i64 0}
!3689 = !{!"0x93f3b20.w64.b0", !3690, i64 0}
!3690 = !{!"0x93f3b20.w128.b0", !3691, i64 0}
!3691 = !{!"0x93f3b20.w256.b0", !3692, i64 0}
!3692 = !{!"0x93f3b20.w512.b0", !3693, i64 0}
!3693 = !{!"0x93f3b20.w1024.b0", !3694, i64 0}
!3694 = !{!"int64", !3695, i64 0}
!3695 = !{!"0x93f3b20", !8, i64 0}
!3696 = !{!3697, !3697, i64 0}
!3697 = !{!"0x180cde90.w1.b0", !3698, i64 0}
!3698 = !{!"0x180cde90.w2.b0", !3699, i64 0}
!3699 = !{!"0x180cde90.w4.b0", !3700, i64 0}
!3700 = !{!"0x180cde90.w8.b0", !3701, i64 0}
!3701 = !{!"0x180cde90.w16.b0", !3702, i64 0}
!3702 = !{!"0x180cde90.w32.b0", !3703, i64 0}
!3703 = !{!"0x180cde90.w64.b0", !3704, i64 0}
!3704 = !{!"0x180cde90.w128.b0", !3705, i64 0}
!3705 = !{!"0x180cde90.w256.b0", !3706, i64 0}
!3706 = !{!"0x180cde90.w512.b0", !3707, i64 0}
!3707 = !{!"0x180cde90.w1024.b0", !3708, i64 0}
!3708 = !{!"int64", !3709, i64 0}
!3709 = !{!"0x180cde90", !8, i64 0}
!3710 = !{!3711, !3711, i64 0}
!3711 = !{!"0x180cde90.w1.b1", !3698, i64 0}
!3712 = !{!3713, !3713, i64 0}
!3713 = !{!"0x180cde90.w1.b2", !3714, i64 0}
!3714 = !{!"0x180cde90.w2.b2", !3699, i64 0}
!3715 = !{!3716, !3716, i64 0}
!3716 = !{!"0x180cde90.w1.b3", !3714, i64 0}
!3717 = !{!3718, !3718, i64 0}
!3718 = !{!"0xd934cf0.w4.b0", !3719, i64 0}
!3719 = !{!"0xd934cf0.w8.b0", !3720, i64 0}
!3720 = !{!"0xd934cf0.w16.b0", !3721, i64 0}
!3721 = !{!"0xd934cf0.w32.b0", !3722, i64 0}
!3722 = !{!"0xd934cf0.w64.b0", !3723, i64 0}
!3723 = !{!"0xd934cf0.w128.b0", !3724, i64 0}
!3724 = !{!"0xd934cf0.w256.b0", !3725, i64 0}
!3725 = !{!"0xd934cf0.w512.b0", !3726, i64 0}
!3726 = !{!"0xd934cf0.w1024.b0", !3727, i64 0}
!3727 = !{!"int64", !3728, i64 0}
!3728 = !{!"0xd934cf0", !8, i64 0}
!3729 = !{!3730, !3730, i64 0}
!3730 = !{!"0x12516360.w1.b0", !3731, i64 0}
!3731 = !{!"0x12516360.w2.b0", !3732, i64 0}
!3732 = !{!"0x12516360.w4.b0", !3733, i64 0}
!3733 = !{!"0x12516360.w8.b0", !3734, i64 0}
!3734 = !{!"0x12516360.w16.b0", !3735, i64 0}
!3735 = !{!"0x12516360.w32.b0", !3736, i64 0}
!3736 = !{!"0x12516360.w64.b0", !3737, i64 0}
!3737 = !{!"0x12516360.w128.b0", !3738, i64 0}
!3738 = !{!"0x12516360.w256.b0", !3739, i64 0}
!3739 = !{!"0x12516360.w512.b0", !3740, i64 0}
!3740 = !{!"0x12516360.w1024.b0", !3741, i64 0}
!3741 = !{!"int64", !3742, i64 0}
!3742 = !{!"0x12516360", !8, i64 0}
!3743 = !{!3744, !3744, i64 0}
!3744 = !{!"0x12516360.w1.b1", !3731, i64 0}
!3745 = !{!3746, !3746, i64 0}
!3746 = !{!"0x12516360.w1.b2", !3747, i64 0}
!3747 = !{!"0x12516360.w2.b2", !3732, i64 0}
!3748 = !{!3749, !3749, i64 0}
!3749 = !{!"0x12516360.w1.b3", !3747, i64 0}
!3750 = !{!3751, !3751, i64 0}
!3751 = !{!"0x12516360.w1.b4", !3752, i64 0}
!3752 = !{!"0x12516360.w2.b4", !3753, i64 0}
!3753 = !{!"0x12516360.w4.b4", !3733, i64 0}
!3754 = !{!3755, !3755, i64 0}
!3755 = !{!"0x13b10700.w4.b0", !3756, i64 0}
!3756 = !{!"0x13b10700.w8.b0", !3757, i64 0}
!3757 = !{!"0x13b10700.w16.b0", !3758, i64 0}
!3758 = !{!"0x13b10700.w32.b0", !3759, i64 0}
!3759 = !{!"0x13b10700.w64.b0", !3760, i64 0}
!3760 = !{!"0x13b10700.w128.b0", !3761, i64 0}
!3761 = !{!"0x13b10700.w256.b0", !3762, i64 0}
!3762 = !{!"0x13b10700.w512.b0", !3763, i64 0}
!3763 = !{!"0x13b10700.w1024.b0", !3764, i64 0}
!3764 = !{!"int64", !3765, i64 0}
!3765 = !{!"0x13b10700", !8, i64 0}
!3766 = !{!3767, !3767, i64 0}
!3767 = !{!"0x13b10700.w1.b4", !3768, i64 0}
!3768 = !{!"0x13b10700.w2.b4", !3769, i64 0}
!3769 = !{!"0x13b10700.w4.b4", !3756, i64 0}
!3770 = !{!3771, !3771, i64 0}
!3771 = !{!"0xa89d700.w1.b0", !3772, i64 0}
!3772 = !{!"0xa89d700.w2.b0", !3773, i64 0}
!3773 = !{!"0xa89d700.w4.b0", !3774, i64 0}
!3774 = !{!"0xa89d700.w8.b0", !3775, i64 0}
!3775 = !{!"0xa89d700.w16.b0", !3776, i64 0}
!3776 = !{!"0xa89d700.w32.b0", !3777, i64 0}
!3777 = !{!"0xa89d700.w64.b0", !3778, i64 0}
!3778 = !{!"0xa89d700.w128.b0", !3779, i64 0}
!3779 = !{!"0xa89d700.w256.b0", !3780, i64 0}
!3780 = !{!"0xa89d700.w512.b0", !3781, i64 0}
!3781 = !{!"0xa89d700.w1024.b0", !3782, i64 0}
!3782 = !{!"int64", !3783, i64 0}
!3783 = !{!"0xa89d700", !8, i64 0}
!3784 = !{!3785, !3785, i64 0}
!3785 = !{!"0xa89d700.w1.b1", !3772, i64 0}
!3786 = !{!3787, !3787, i64 0}
!3787 = !{!"0xa89d700.w1.b2", !3788, i64 0}
!3788 = !{!"0xa89d700.w2.b2", !3773, i64 0}
!3789 = !{!3790, !3790, i64 0}
!3790 = !{!"0xa89d700.w1.b3", !3788, i64 0}
!3791 = !{!3792, !3792, i64 0}
!3792 = !{!"0xa89d700.w1.b4", !3793, i64 0}
!3793 = !{!"0xa89d700.w2.b4", !3794, i64 0}
!3794 = !{!"0xa89d700.w4.b4", !3774, i64 0}
!3795 = !{!3796, !3796, i64 0}
!3796 = !{!"0xa6ac270.w4.b0", !3797, i64 0}
!3797 = !{!"0xa6ac270.w8.b0", !3798, i64 0}
!3798 = !{!"0xa6ac270.w16.b0", !3799, i64 0}
!3799 = !{!"0xa6ac270.w32.b0", !3800, i64 0}
!3800 = !{!"0xa6ac270.w64.b0", !3801, i64 0}
!3801 = !{!"0xa6ac270.w128.b0", !3802, i64 0}
!3802 = !{!"0xa6ac270.w256.b0", !3803, i64 0}
!3803 = !{!"0xa6ac270.w512.b0", !3804, i64 0}
!3804 = !{!"0xa6ac270.w1024.b0", !3805, i64 0}
!3805 = !{!"int64", !3806, i64 0}
!3806 = !{!"0xa6ac270", !8, i64 0}
!3807 = !{!3808, !3808, i64 0}
!3808 = !{!"0xa6ac270.w1.b4", !3809, i64 0}
!3809 = !{!"0xa6ac270.w2.b4", !3810, i64 0}
!3810 = !{!"0xa6ac270.w4.b4", !3797, i64 0}
!3811 = !{!3812, !3812, i64 0}
!3812 = !{!"float32", !3813, i64 0}
!3813 = !{!"0xf8025f0", !8, i64 0}
!3814 = !{!3815, !3815, i64 0}
!3815 = !{!"float32", !3816, i64 0}
!3816 = !{!"0xd4bb720", !8, i64 0}
!3817 = !{!3818, !3818, i64 0}
!3818 = !{!"float32", !3819, i64 0}
!3819 = !{!"0x1b747730", !8, i64 0}
!3820 = !{!3821, !3821, i64 0}
!3821 = !{!"float32", !3822, i64 0}
!3822 = !{!"0x107515b0", !8, i64 0}
!3823 = !{!3824, !3824, i64 0}
!3824 = !{!"float32", !3825, i64 0}
!3825 = !{!"0xd4e12c0", !8, i64 0}
!3826 = !{!3827, !3827, i64 0}
!3827 = !{!"float32", !3828, i64 0}
!3828 = !{!"0x8a8dd20", !8, i64 0}
!3829 = !{!3830, !3830, i64 0}
!3830 = !{!"float32", !3831, i64 0}
!3831 = !{!"0x871a350", !8, i64 0}
!3832 = !{!3833, !3833, i64 0}
!3833 = !{!"0xd52fdd0.w1.b0", !3834, i64 0}
!3834 = !{!"0xd52fdd0.w2.b0", !3835, i64 0}
!3835 = !{!"0xd52fdd0.w4.b0", !3836, i64 0}
!3836 = !{!"0xd52fdd0.w8.b0", !3837, i64 0}
!3837 = !{!"0xd52fdd0.w16.b0", !3838, i64 0}
!3838 = !{!"0xd52fdd0.w32.b0", !3839, i64 0}
!3839 = !{!"0xd52fdd0.w64.b0", !3840, i64 0}
!3840 = !{!"0xd52fdd0.w128.b0", !3841, i64 0}
!3841 = !{!"0xd52fdd0.w256.b0", !3842, i64 0}
!3842 = !{!"0xd52fdd0.w512.b0", !3843, i64 0}
!3843 = !{!"0xd52fdd0.w1024.b0", !3844, i64 0}
!3844 = !{!"int32", !3845, i64 0}
!3845 = !{!"0xd52fdd0", !8, i64 0}
!3846 = !{!3847, !3847, i64 0}
!3847 = !{!"0xd52fdd0.w1.b1", !3834, i64 0}
!3848 = !{!3849, !3849, i64 0}
!3849 = !{!"0x1a4d42a0.w1.b0", !3850, i64 0}
!3850 = !{!"0x1a4d42a0.w2.b0", !3851, i64 0}
!3851 = !{!"0x1a4d42a0.w4.b0", !3852, i64 0}
!3852 = !{!"0x1a4d42a0.w8.b0", !3853, i64 0}
!3853 = !{!"0x1a4d42a0.w16.b0", !3854, i64 0}
!3854 = !{!"0x1a4d42a0.w32.b0", !3855, i64 0}
!3855 = !{!"0x1a4d42a0.w64.b0", !3856, i64 0}
!3856 = !{!"0x1a4d42a0.w128.b0", !3857, i64 0}
!3857 = !{!"0x1a4d42a0.w256.b0", !3858, i64 0}
!3858 = !{!"0x1a4d42a0.w512.b0", !3859, i64 0}
!3859 = !{!"0x1a4d42a0.w1024.b0", !3860, i64 0}
!3860 = !{!"int64", !3861, i64 0}
!3861 = !{!"0x1a4d42a0", !8, i64 0}
!3862 = !{!3863, !3863, i64 0}
!3863 = !{!"0x1a4d42a0.w1.b1", !3850, i64 0}
!3864 = !{!3865, !3865, i64 0}
!3865 = !{!"0x1a4d42a0.w1.b2", !3866, i64 0}
!3866 = !{!"0x1a4d42a0.w2.b2", !3851, i64 0}
!3867 = !{!3868, !3868, i64 0}
!3868 = !{!"0x1a4d42a0.w1.b3", !3866, i64 0}
!3869 = !{!3870, !3870, i64 0}
!3870 = !{!"0x1a4d42a0.w1.b4", !3871, i64 0}
!3871 = !{!"0x1a4d42a0.w2.b4", !3872, i64 0}
!3872 = !{!"0x1a4d42a0.w4.b4", !3852, i64 0}
!3873 = !{!3874, !3874, i64 0}
!3874 = !{!"0x7cd8390.w4.b0", !3875, i64 0}
!3875 = !{!"0x7cd8390.w8.b0", !3876, i64 0}
!3876 = !{!"0x7cd8390.w16.b0", !3877, i64 0}
!3877 = !{!"0x7cd8390.w32.b0", !3878, i64 0}
!3878 = !{!"0x7cd8390.w64.b0", !3879, i64 0}
!3879 = !{!"0x7cd8390.w128.b0", !3880, i64 0}
!3880 = !{!"0x7cd8390.w256.b0", !3881, i64 0}
!3881 = !{!"0x7cd8390.w512.b0", !3882, i64 0}
!3882 = !{!"0x7cd8390.w1024.b0", !3883, i64 0}
!3883 = !{!"int64", !3884, i64 0}
!3884 = !{!"0x7cd8390", !8, i64 0}
!3885 = !{!3886, !3886, i64 0}
!3886 = !{!"0x7cd8390.w1.b4", !3887, i64 0}
!3887 = !{!"0x7cd8390.w2.b4", !3888, i64 0}
!3888 = !{!"0x7cd8390.w4.b4", !3875, i64 0}
!3889 = !{!3890, !3890, i64 0}
!3890 = !{!"0xd9aa190.w1.b0", !3891, i64 0}
!3891 = !{!"0xd9aa190.w2.b0", !3892, i64 0}
!3892 = !{!"0xd9aa190.w4.b0", !3893, i64 0}
!3893 = !{!"0xd9aa190.w8.b0", !3894, i64 0}
!3894 = !{!"0xd9aa190.w16.b0", !3895, i64 0}
!3895 = !{!"0xd9aa190.w32.b0", !3896, i64 0}
!3896 = !{!"0xd9aa190.w64.b0", !3897, i64 0}
!3897 = !{!"0xd9aa190.w128.b0", !3898, i64 0}
!3898 = !{!"0xd9aa190.w256.b0", !3899, i64 0}
!3899 = !{!"0xd9aa190.w512.b0", !3900, i64 0}
!3900 = !{!"0xd9aa190.w1024.b0", !3901, i64 0}
!3901 = !{!"int64", !3902, i64 0}
!3902 = !{!"0xd9aa190", !8, i64 0}
!3903 = !{!3904, !3904, i64 0}
!3904 = !{!"0xd9aa190.w1.b1", !3891, i64 0}
!3905 = !{!3906, !3906, i64 0}
!3906 = !{!"0xd9aa190.w1.b2", !3907, i64 0}
!3907 = !{!"0xd9aa190.w2.b2", !3892, i64 0}
!3908 = !{!3909, !3909, i64 0}
!3909 = !{!"0xd9aa190.w1.b3", !3907, i64 0}
!3910 = !{!3911, !3911, i64 0}
!3911 = !{!"0xd9aa190.w1.b4", !3912, i64 0}
!3912 = !{!"0xd9aa190.w2.b4", !3913, i64 0}
!3913 = !{!"0xd9aa190.w4.b4", !3893, i64 0}
!3914 = !{!3915, !3915, i64 0}
!3915 = !{!"0xda919b0.w4.b0", !3916, i64 0}
!3916 = !{!"0xda919b0.w8.b0", !3917, i64 0}
!3917 = !{!"0xda919b0.w16.b0", !3918, i64 0}
!3918 = !{!"0xda919b0.w32.b0", !3919, i64 0}
!3919 = !{!"0xda919b0.w64.b0", !3920, i64 0}
!3920 = !{!"0xda919b0.w128.b0", !3921, i64 0}
!3921 = !{!"0xda919b0.w256.b0", !3922, i64 0}
!3922 = !{!"0xda919b0.w512.b0", !3923, i64 0}
!3923 = !{!"0xda919b0.w1024.b0", !3924, i64 0}
!3924 = !{!"int64", !3925, i64 0}
!3925 = !{!"0xda919b0", !8, i64 0}
!3926 = !{!3927, !3927, i64 0}
!3927 = !{!"0xda919b0.w1.b4", !3928, i64 0}
!3928 = !{!"0xda919b0.w2.b4", !3929, i64 0}
!3929 = !{!"0xda919b0.w4.b4", !3916, i64 0}
!3930 = !{!3931, !3931, i64 0}
!3931 = !{!"float32", !3932, i64 0}
!3932 = !{!"0x9970d50", !8, i64 0}
!3933 = !{!3934, !3934, i64 0}
!3934 = !{!"float32", !3935, i64 0}
!3935 = !{!"0xfa7b0f0", !8, i64 0}
!3936 = !{!3937, !3937, i64 0}
!3937 = !{!"0xa560ed0.w1.b0", !3938, i64 0}
!3938 = !{!"0xa560ed0.w2.b0", !3939, i64 0}
!3939 = !{!"0xa560ed0.w4.b0", !3940, i64 0}
!3940 = !{!"0xa560ed0.w8.b0", !3941, i64 0}
!3941 = !{!"0xa560ed0.w16.b0", !3942, i64 0}
!3942 = !{!"0xa560ed0.w32.b0", !3943, i64 0}
!3943 = !{!"0xa560ed0.w64.b0", !3944, i64 0}
!3944 = !{!"0xa560ed0.w128.b0", !3945, i64 0}
!3945 = !{!"0xa560ed0.w256.b0", !3946, i64 0}
!3946 = !{!"0xa560ed0.w512.b0", !3947, i64 0}
!3947 = !{!"0xa560ed0.w1024.b0", !3948, i64 0}
!3948 = !{!"int32", !3949, i64 0}
!3949 = !{!"0xa560ed0", !8, i64 0}
!3950 = !{!3951, !3951, i64 0}
!3951 = !{!"0xa560ed0.w1.b1", !3938, i64 0}
!3952 = !{!3953, !3953, i64 0}
!3953 = !{!"0xa566b60.w1.b0", !3954, i64 0}
!3954 = !{!"0xa566b60.w2.b0", !3955, i64 0}
!3955 = !{!"0xa566b60.w4.b0", !3956, i64 0}
!3956 = !{!"0xa566b60.w8.b0", !3957, i64 0}
!3957 = !{!"0xa566b60.w16.b0", !3958, i64 0}
!3958 = !{!"0xa566b60.w32.b0", !3959, i64 0}
!3959 = !{!"0xa566b60.w64.b0", !3960, i64 0}
!3960 = !{!"0xa566b60.w128.b0", !3961, i64 0}
!3961 = !{!"0xa566b60.w256.b0", !3962, i64 0}
!3962 = !{!"0xa566b60.w512.b0", !3963, i64 0}
!3963 = !{!"0xa566b60.w1024.b0", !3964, i64 0}
!3964 = !{!"int64", !3965, i64 0}
!3965 = !{!"0xa566b60", !8, i64 0}
!3966 = !{!3967, !3967, i64 0}
!3967 = !{!"0xa566b60.w1.b1", !3954, i64 0}
!3968 = !{!3969, !3969, i64 0}
!3969 = !{!"0xa566b60.w1.b2", !3970, i64 0}
!3970 = !{!"0xa566b60.w2.b2", !3955, i64 0}
!3971 = !{!3972, !3972, i64 0}
!3972 = !{!"0xa566b60.w1.b3", !3970, i64 0}
!3973 = !{!3974, !3974, i64 0}
!3974 = !{!"0xa566b60.w1.b4", !3975, i64 0}
!3975 = !{!"0xa566b60.w2.b4", !3976, i64 0}
!3976 = !{!"0xa566b60.w4.b4", !3956, i64 0}
!3977 = !{!3978, !3978, i64 0}
!3978 = !{!"0xa56a400.w4.b0", !3979, i64 0}
!3979 = !{!"0xa56a400.w8.b0", !3980, i64 0}
!3980 = !{!"0xa56a400.w16.b0", !3981, i64 0}
!3981 = !{!"0xa56a400.w32.b0", !3982, i64 0}
!3982 = !{!"0xa56a400.w64.b0", !3983, i64 0}
!3983 = !{!"0xa56a400.w128.b0", !3984, i64 0}
!3984 = !{!"0xa56a400.w256.b0", !3985, i64 0}
!3985 = !{!"0xa56a400.w512.b0", !3986, i64 0}
!3986 = !{!"0xa56a400.w1024.b0", !3987, i64 0}
!3987 = !{!"int64", !3988, i64 0}
!3988 = !{!"0xa56a400", !8, i64 0}
!3989 = !{!3990, !3990, i64 0}
!3990 = !{!"0xa56a400.w1.b4", !3991, i64 0}
!3991 = !{!"0xa56a400.w2.b4", !3992, i64 0}
!3992 = !{!"0xa56a400.w4.b4", !3979, i64 0}
!3993 = !{!3994, !3994, i64 0}
!3994 = !{!"0xa56c3e0.w1.b0", !3995, i64 0}
!3995 = !{!"0xa56c3e0.w2.b0", !3996, i64 0}
!3996 = !{!"0xa56c3e0.w4.b0", !3997, i64 0}
!3997 = !{!"0xa56c3e0.w8.b0", !3998, i64 0}
!3998 = !{!"0xa56c3e0.w16.b0", !3999, i64 0}
!3999 = !{!"0xa56c3e0.w32.b0", !4000, i64 0}
!4000 = !{!"0xa56c3e0.w64.b0", !4001, i64 0}
!4001 = !{!"0xa56c3e0.w128.b0", !4002, i64 0}
!4002 = !{!"0xa56c3e0.w256.b0", !4003, i64 0}
!4003 = !{!"0xa56c3e0.w512.b0", !4004, i64 0}
!4004 = !{!"0xa56c3e0.w1024.b0", !4005, i64 0}
!4005 = !{!"int64", !4006, i64 0}
!4006 = !{!"0xa56c3e0", !8, i64 0}
!4007 = !{!4008, !4008, i64 0}
!4008 = !{!"0xa56c3e0.w1.b1", !3995, i64 0}
!4009 = !{!4010, !4010, i64 0}
!4010 = !{!"0xa56c3e0.w1.b2", !4011, i64 0}
!4011 = !{!"0xa56c3e0.w2.b2", !3996, i64 0}
!4012 = !{!4013, !4013, i64 0}
!4013 = !{!"0xa56c3e0.w1.b3", !4011, i64 0}
!4014 = !{!4015, !4015, i64 0}
!4015 = !{!"0xa56c3e0.w1.b4", !4016, i64 0}
!4016 = !{!"0xa56c3e0.w2.b4", !4017, i64 0}
!4017 = !{!"0xa56c3e0.w4.b4", !3997, i64 0}
!4018 = !{!4019, !4019, i64 0}
!4019 = !{!"0xa56d1c0.w4.b0", !4020, i64 0}
!4020 = !{!"0xa56d1c0.w8.b0", !4021, i64 0}
!4021 = !{!"0xa56d1c0.w16.b0", !4022, i64 0}
!4022 = !{!"0xa56d1c0.w32.b0", !4023, i64 0}
!4023 = !{!"0xa56d1c0.w64.b0", !4024, i64 0}
!4024 = !{!"0xa56d1c0.w128.b0", !4025, i64 0}
!4025 = !{!"0xa56d1c0.w256.b0", !4026, i64 0}
!4026 = !{!"0xa56d1c0.w512.b0", !4027, i64 0}
!4027 = !{!"0xa56d1c0.w1024.b0", !4028, i64 0}
!4028 = !{!"int64", !4029, i64 0}
!4029 = !{!"0xa56d1c0", !8, i64 0}
!4030 = !{!4031, !4031, i64 0}
!4031 = !{!"0xa56d1c0.w1.b4", !4032, i64 0}
!4032 = !{!"0xa56d1c0.w2.b4", !4033, i64 0}
!4033 = !{!"0xa56d1c0.w4.b4", !4020, i64 0}
!4034 = !{!4035, !4035, i64 0}
!4035 = !{!"float32", !4036, i64 0}
!4036 = !{!"0xa560e80", !8, i64 0}
!4037 = !{!4038, !4038, i64 0}
!4038 = !{!"float32", !4039, i64 0}
!4039 = !{!"0x1367e290", !8, i64 0}
!4040 = !{!4041, !4041, i64 0}
!4041 = !{!"0x13982dd0.w1.b0", !4042, i64 0}
!4042 = !{!"0x13982dd0.w2.b0", !4043, i64 0}
!4043 = !{!"0x13982dd0.w4.b0", !4044, i64 0}
!4044 = !{!"0x13982dd0.w8.b0", !4045, i64 0}
!4045 = !{!"0x13982dd0.w16.b0", !4046, i64 0}
!4046 = !{!"0x13982dd0.w32.b0", !4047, i64 0}
!4047 = !{!"0x13982dd0.w64.b0", !4048, i64 0}
!4048 = !{!"0x13982dd0.w128.b0", !4049, i64 0}
!4049 = !{!"0x13982dd0.w256.b0", !4050, i64 0}
!4050 = !{!"0x13982dd0.w512.b0", !4051, i64 0}
!4051 = !{!"0x13982dd0.w1024.b0", !4052, i64 0}
!4052 = !{!"int32", !4053, i64 0}
!4053 = !{!"0x13982dd0", !8, i64 0}
!4054 = !{!4055, !4055, i64 0}
!4055 = !{!"0x13982dd0.w1.b1", !4042, i64 0}
!4056 = !{!4057, !4057, i64 0}
!4057 = !{!"0xc5fe5f0.w1.b0", !4058, i64 0}
!4058 = !{!"0xc5fe5f0.w2.b0", !4059, i64 0}
!4059 = !{!"0xc5fe5f0.w4.b0", !4060, i64 0}
!4060 = !{!"0xc5fe5f0.w8.b0", !4061, i64 0}
!4061 = !{!"0xc5fe5f0.w16.b0", !4062, i64 0}
!4062 = !{!"0xc5fe5f0.w32.b0", !4063, i64 0}
!4063 = !{!"0xc5fe5f0.w64.b0", !4064, i64 0}
!4064 = !{!"0xc5fe5f0.w128.b0", !4065, i64 0}
!4065 = !{!"0xc5fe5f0.w256.b0", !4066, i64 0}
!4066 = !{!"0xc5fe5f0.w512.b0", !4067, i64 0}
!4067 = !{!"0xc5fe5f0.w1024.b0", !4068, i64 0}
!4068 = !{!"int64", !4069, i64 0}
!4069 = !{!"0xc5fe5f0", !8, i64 0}
!4070 = !{!4071, !4071, i64 0}
!4071 = !{!"0xc5fe5f0.w1.b1", !4058, i64 0}
!4072 = !{!4073, !4073, i64 0}
!4073 = !{!"0xc5fe5f0.w1.b2", !4074, i64 0}
!4074 = !{!"0xc5fe5f0.w2.b2", !4059, i64 0}
!4075 = !{!4076, !4076, i64 0}
!4076 = !{!"0xc5fe5f0.w1.b3", !4074, i64 0}
!4077 = !{!4078, !4078, i64 0}
!4078 = !{!"0xc5fe5f0.w1.b4", !4079, i64 0}
!4079 = !{!"0xc5fe5f0.w2.b4", !4080, i64 0}
!4080 = !{!"0xc5fe5f0.w4.b4", !4060, i64 0}
!4081 = !{!4082, !4082, i64 0}
!4082 = !{!"0xc5e7070.w4.b0", !4083, i64 0}
!4083 = !{!"0xc5e7070.w8.b0", !4084, i64 0}
!4084 = !{!"0xc5e7070.w16.b0", !4085, i64 0}
!4085 = !{!"0xc5e7070.w32.b0", !4086, i64 0}
!4086 = !{!"0xc5e7070.w64.b0", !4087, i64 0}
!4087 = !{!"0xc5e7070.w128.b0", !4088, i64 0}
!4088 = !{!"0xc5e7070.w256.b0", !4089, i64 0}
!4089 = !{!"0xc5e7070.w512.b0", !4090, i64 0}
!4090 = !{!"0xc5e7070.w1024.b0", !4091, i64 0}
!4091 = !{!"int64", !4092, i64 0}
!4092 = !{!"0xc5e7070", !8, i64 0}
!4093 = !{!4094, !4094, i64 0}
!4094 = !{!"0xc5e7070.w1.b4", !4095, i64 0}
!4095 = !{!"0xc5e7070.w2.b4", !4096, i64 0}
!4096 = !{!"0xc5e7070.w4.b4", !4083, i64 0}
!4097 = !{!4098, !4098, i64 0}
!4098 = !{!"0xfa26e30.w1.b0", !4099, i64 0}
!4099 = !{!"0xfa26e30.w2.b0", !4100, i64 0}
!4100 = !{!"0xfa26e30.w4.b0", !4101, i64 0}
!4101 = !{!"0xfa26e30.w8.b0", !4102, i64 0}
!4102 = !{!"0xfa26e30.w16.b0", !4103, i64 0}
!4103 = !{!"0xfa26e30.w32.b0", !4104, i64 0}
!4104 = !{!"0xfa26e30.w64.b0", !4105, i64 0}
!4105 = !{!"0xfa26e30.w128.b0", !4106, i64 0}
!4106 = !{!"0xfa26e30.w256.b0", !4107, i64 0}
!4107 = !{!"0xfa26e30.w512.b0", !4108, i64 0}
!4108 = !{!"0xfa26e30.w1024.b0", !4109, i64 0}
!4109 = !{!"int64", !4110, i64 0}
!4110 = !{!"0xfa26e30", !8, i64 0}
!4111 = !{!4112, !4112, i64 0}
!4112 = !{!"0xfa26e30.w1.b1", !4099, i64 0}
!4113 = !{!4114, !4114, i64 0}
!4114 = !{!"0xf789d50.w1.b0", !4115, i64 0}
!4115 = !{!"0xf789d50.w2.b0", !4116, i64 0}
!4116 = !{!"0xf789d50.w4.b0", !4117, i64 0}
!4117 = !{!"0xf789d50.w8.b0", !4118, i64 0}
!4118 = !{!"0xf789d50.w16.b0", !4119, i64 0}
!4119 = !{!"0xf789d50.w32.b0", !4120, i64 0}
!4120 = !{!"0xf789d50.w64.b0", !4121, i64 0}
!4121 = !{!"0xf789d50.w128.b0", !4122, i64 0}
!4122 = !{!"0xf789d50.w256.b0", !4123, i64 0}
!4123 = !{!"0xf789d50.w512.b0", !4124, i64 0}
!4124 = !{!"0xf789d50.w1024.b0", !4125, i64 0}
!4125 = !{!"int64", !4126, i64 0}
!4126 = !{!"0xf789d50", !8, i64 0}
!4127 = !{!4128, !4128, i64 0}
!4128 = !{!"0xf789d50.w1.b1", !4115, i64 0}
!4129 = !{!4130, !4130, i64 0}
!4130 = !{!"0xa5507b0.w1.b0", !4131, i64 0}
!4131 = !{!"0xa5507b0.w2.b0", !4132, i64 0}
!4132 = !{!"0xa5507b0.w4.b0", !4133, i64 0}
!4133 = !{!"0xa5507b0.w8.b0", !4134, i64 0}
!4134 = !{!"0xa5507b0.w16.b0", !4135, i64 0}
!4135 = !{!"0xa5507b0.w32.b0", !4136, i64 0}
!4136 = !{!"0xa5507b0.w64.b0", !4137, i64 0}
!4137 = !{!"0xa5507b0.w128.b0", !4138, i64 0}
!4138 = !{!"0xa5507b0.w256.b0", !4139, i64 0}
!4139 = !{!"0xa5507b0.w512.b0", !4140, i64 0}
!4140 = !{!"0xa5507b0.w1024.b0", !4141, i64 0}
!4141 = !{!"int32", !4142, i64 0}
!4142 = !{!"0xa5507b0", !8, i64 0}
!4143 = !{!4144, !4144, i64 0}
!4144 = !{!"0xa5507b0.w1.b2", !4145, i64 0}
!4145 = !{!"0xa5507b0.w2.b2", !4132, i64 0}
!4146 = !{!4147, !4147, i64 0}
!4147 = !{!"0xa5507b0.w1.b3", !4145, i64 0}
!4148 = !{!4149, !4149, i64 0}
!4149 = !{!"0xa5507b0.w1.b4", !4150, i64 0}
!4150 = !{!"0xa5507b0.w2.b4", !4151, i64 0}
!4151 = !{!"0xa5507b0.w4.b4", !4133, i64 0}
!4152 = !{!4153, !4153, i64 0}
!4153 = !{!"0xa5507b0.w1.b5", !4150, i64 0}
!4154 = !{!4155, !4155, i64 0}
!4155 = !{!"0xa5507b0.w1.b1", !4131, i64 0}
!4156 = !{!4157, !4157, i64 0}
!4157 = !{!"0xa54eae0.w1.b0", !4158, i64 0}
!4158 = !{!"0xa54eae0.w2.b0", !4159, i64 0}
!4159 = !{!"0xa54eae0.w4.b0", !4160, i64 0}
!4160 = !{!"0xa54eae0.w8.b0", !4161, i64 0}
!4161 = !{!"0xa54eae0.w16.b0", !4162, i64 0}
!4162 = !{!"0xa54eae0.w32.b0", !4163, i64 0}
!4163 = !{!"0xa54eae0.w64.b0", !4164, i64 0}
!4164 = !{!"0xa54eae0.w128.b0", !4165, i64 0}
!4165 = !{!"0xa54eae0.w256.b0", !4166, i64 0}
!4166 = !{!"0xa54eae0.w512.b0", !4167, i64 0}
!4167 = !{!"0xa54eae0.w1024.b0", !4168, i64 0}
!4168 = !{!"int64", !4169, i64 0}
!4169 = !{!"0xa54eae0", !8, i64 0}
!4170 = !{!4171, !4171, i64 0}
!4171 = !{!"0xa54eae0.w1.b1", !4158, i64 0}
!4172 = !{!4173, !4173, i64 0}
!4173 = !{!"0xa54eae0.w1.b2", !4174, i64 0}
!4174 = !{!"0xa54eae0.w2.b2", !4159, i64 0}
!4175 = !{!4176, !4176, i64 0}
!4176 = !{!"0xa54eae0.w1.b3", !4174, i64 0}
!4177 = !{!4178, !4178, i64 0}
!4178 = !{!"0xa54eae0.w1.b4", !4179, i64 0}
!4179 = !{!"0xa54eae0.w2.b4", !4180, i64 0}
!4180 = !{!"0xa54eae0.w4.b4", !4160, i64 0}
!4181 = !{!4182, !4182, i64 0}
!4182 = !{!"0xc80ca40.w4.b0", !4183, i64 0}
!4183 = !{!"0xc80ca40.w8.b0", !4184, i64 0}
!4184 = !{!"0xc80ca40.w16.b0", !4185, i64 0}
!4185 = !{!"0xc80ca40.w32.b0", !4186, i64 0}
!4186 = !{!"0xc80ca40.w64.b0", !4187, i64 0}
!4187 = !{!"0xc80ca40.w128.b0", !4188, i64 0}
!4188 = !{!"0xc80ca40.w256.b0", !4189, i64 0}
!4189 = !{!"0xc80ca40.w512.b0", !4190, i64 0}
!4190 = !{!"0xc80ca40.w1024.b0", !4191, i64 0}
!4191 = !{!"int64", !4192, i64 0}
!4192 = !{!"0xc80ca40", !8, i64 0}
!4193 = !{!4194, !4194, i64 0}
!4194 = !{!"0xc80ca40.w1.b4", !4195, i64 0}
!4195 = !{!"0xc80ca40.w2.b4", !4196, i64 0}
!4196 = !{!"0xc80ca40.w4.b4", !4183, i64 0}
!4197 = !{!4198, !4198, i64 0}
!4198 = !{!"0x1398cad0.w1.b0", !4199, i64 0}
!4199 = !{!"0x1398cad0.w2.b0", !4200, i64 0}
!4200 = !{!"0x1398cad0.w4.b0", !4201, i64 0}
!4201 = !{!"0x1398cad0.w8.b0", !4202, i64 0}
!4202 = !{!"0x1398cad0.w16.b0", !4203, i64 0}
!4203 = !{!"0x1398cad0.w32.b0", !4204, i64 0}
!4204 = !{!"0x1398cad0.w64.b0", !4205, i64 0}
!4205 = !{!"0x1398cad0.w128.b0", !4206, i64 0}
!4206 = !{!"0x1398cad0.w256.b0", !4207, i64 0}
!4207 = !{!"0x1398cad0.w512.b0", !4208, i64 0}
!4208 = !{!"0x1398cad0.w1024.b0", !4209, i64 0}
!4209 = !{!"int64", !4210, i64 0}
!4210 = !{!"0x1398cad0", !8, i64 0}
!4211 = !{!4212, !4212, i64 0}
!4212 = !{!"0x1398cad0.w1.b1", !4199, i64 0}
!4213 = !{!4214, !4214, i64 0}
!4214 = !{!"0x1398cad0.w1.b2", !4215, i64 0}
!4215 = !{!"0x1398cad0.w2.b2", !4200, i64 0}
!4216 = !{!4217, !4217, i64 0}
!4217 = !{!"0x1398cad0.w1.b3", !4215, i64 0}
!4218 = !{!4219, !4219, i64 0}
!4219 = !{!"0x1398cad0.w1.b4", !4220, i64 0}
!4220 = !{!"0x1398cad0.w2.b4", !4221, i64 0}
!4221 = !{!"0x1398cad0.w4.b4", !4201, i64 0}
!4222 = !{!4223, !4223, i64 0}
!4223 = !{!"0x1398cad0.w1.b5", !4220, i64 0}
!4224 = !{!4225, !4225, i64 0}
!4225 = !{!"0xf7efed0.w4.b0", !4226, i64 0}
!4226 = !{!"0xf7efed0.w8.b0", !4227, i64 0}
!4227 = !{!"0xf7efed0.w16.b0", !4228, i64 0}
!4228 = !{!"0xf7efed0.w32.b0", !4229, i64 0}
!4229 = !{!"0xf7efed0.w64.b0", !4230, i64 0}
!4230 = !{!"0xf7efed0.w128.b0", !4231, i64 0}
!4231 = !{!"0xf7efed0.w256.b0", !4232, i64 0}
!4232 = !{!"0xf7efed0.w512.b0", !4233, i64 0}
!4233 = !{!"0xf7efed0.w1024.b0", !4234, i64 0}
!4234 = !{!"int64", !4235, i64 0}
!4235 = !{!"0xf7efed0", !8, i64 0}
!4236 = !{!4237, !4237, i64 0}
!4237 = !{!"0xf7efed0.w1.b4", !4238, i64 0}
!4238 = !{!"0xf7efed0.w2.b4", !4239, i64 0}
!4239 = !{!"0xf7efed0.w4.b4", !4226, i64 0}
!4240 = !{!4241, !4241, i64 0}
!4241 = !{!"0xf7efed0.w1.b5", !4238, i64 0}
!4242 = !{!4243, !4243, i64 0}
!4243 = !{!"0xcf3e5e0.w1.b0", !4244, i64 0}
!4244 = !{!"0xcf3e5e0.w2.b0", !4245, i64 0}
!4245 = !{!"0xcf3e5e0.w4.b0", !4246, i64 0}
!4246 = !{!"0xcf3e5e0.w8.b0", !4247, i64 0}
!4247 = !{!"0xcf3e5e0.w16.b0", !4248, i64 0}
!4248 = !{!"0xcf3e5e0.w32.b0", !4249, i64 0}
!4249 = !{!"0xcf3e5e0.w64.b0", !4250, i64 0}
!4250 = !{!"0xcf3e5e0.w128.b0", !4251, i64 0}
!4251 = !{!"0xcf3e5e0.w256.b0", !4252, i64 0}
!4252 = !{!"0xcf3e5e0.w512.b0", !4253, i64 0}
!4253 = !{!"0xcf3e5e0.w1024.b0", !4254, i64 0}
!4254 = !{!"int64", !4255, i64 0}
!4255 = !{!"0xcf3e5e0", !8, i64 0}
!4256 = !{!4257, !4257, i64 0}
!4257 = !{!"0xcf3e5e0.w1.b1", !4244, i64 0}
!4258 = !{!4259, !4259, i64 0}
!4259 = !{!"0xcf3e5e0.w1.b2", !4260, i64 0}
!4260 = !{!"0xcf3e5e0.w2.b2", !4245, i64 0}
!4261 = !{!4262, !4262, i64 0}
!4262 = !{!"0xcf3e5e0.w1.b3", !4260, i64 0}
!4263 = !{!4264, !4264, i64 0}
!4264 = !{!"0xca7ff80.w4.b0", !4265, i64 0}
!4265 = !{!"0xca7ff80.w8.b0", !4266, i64 0}
!4266 = !{!"0xca7ff80.w16.b0", !4267, i64 0}
!4267 = !{!"0xca7ff80.w32.b0", !4268, i64 0}
!4268 = !{!"0xca7ff80.w64.b0", !4269, i64 0}
!4269 = !{!"0xca7ff80.w128.b0", !4270, i64 0}
!4270 = !{!"0xca7ff80.w256.b0", !4271, i64 0}
!4271 = !{!"0xca7ff80.w512.b0", !4272, i64 0}
!4272 = !{!"0xca7ff80.w1024.b0", !4273, i64 0}
!4273 = !{!"int64", !4274, i64 0}
!4274 = !{!"0xca7ff80", !8, i64 0}
!4275 = !{!4276, !4276, i64 0}
!4276 = !{!"0xcaa8910.w1.b0", !4277, i64 0}
!4277 = !{!"0xcaa8910.w2.b0", !4278, i64 0}
!4278 = !{!"0xcaa8910.w4.b0", !4279, i64 0}
!4279 = !{!"0xcaa8910.w8.b0", !4280, i64 0}
!4280 = !{!"0xcaa8910.w16.b0", !4281, i64 0}
!4281 = !{!"0xcaa8910.w32.b0", !4282, i64 0}
!4282 = !{!"0xcaa8910.w64.b0", !4283, i64 0}
!4283 = !{!"0xcaa8910.w128.b0", !4284, i64 0}
!4284 = !{!"0xcaa8910.w256.b0", !4285, i64 0}
!4285 = !{!"0xcaa8910.w512.b0", !4286, i64 0}
!4286 = !{!"0xcaa8910.w1024.b0", !4287, i64 0}
!4287 = !{!"int64", !4288, i64 0}
!4288 = !{!"0xcaa8910", !8, i64 0}
!4289 = !{!4290, !4290, i64 0}
!4290 = !{!"0xcaa8910.w1.b1", !4277, i64 0}
!4291 = !{!4292, !4292, i64 0}
!4292 = !{!"0xcaa8910.w1.b2", !4293, i64 0}
!4293 = !{!"0xcaa8910.w2.b2", !4278, i64 0}
!4294 = !{!4295, !4295, i64 0}
!4295 = !{!"0xcaa8910.w1.b3", !4293, i64 0}
!4296 = !{!4297, !4297, i64 0}
!4297 = !{!"0x1f32e0c0.w4.b0", !4298, i64 0}
!4298 = !{!"0x1f32e0c0.w8.b0", !4299, i64 0}
!4299 = !{!"0x1f32e0c0.w16.b0", !4300, i64 0}
!4300 = !{!"0x1f32e0c0.w32.b0", !4301, i64 0}
!4301 = !{!"0x1f32e0c0.w64.b0", !4302, i64 0}
!4302 = !{!"0x1f32e0c0.w128.b0", !4303, i64 0}
!4303 = !{!"0x1f32e0c0.w256.b0", !4304, i64 0}
!4304 = !{!"0x1f32e0c0.w512.b0", !4305, i64 0}
!4305 = !{!"0x1f32e0c0.w1024.b0", !4306, i64 0}
!4306 = !{!"int64", !4307, i64 0}
!4307 = !{!"0x1f32e0c0", !8, i64 0}
!4308 = !{!4309, !4309, i64 0}
!4309 = !{!"0xa551570.w1.b0", !4310, i64 0}
!4310 = !{!"0xa551570.w2.b0", !4311, i64 0}
!4311 = !{!"0xa551570.w4.b0", !4312, i64 0}
!4312 = !{!"0xa551570.w8.b0", !4313, i64 0}
!4313 = !{!"0xa551570.w16.b0", !4314, i64 0}
!4314 = !{!"0xa551570.w32.b0", !4315, i64 0}
!4315 = !{!"0xa551570.w64.b0", !4316, i64 0}
!4316 = !{!"0xa551570.w128.b0", !4317, i64 0}
!4317 = !{!"0xa551570.w256.b0", !4318, i64 0}
!4318 = !{!"0xa551570.w512.b0", !4319, i64 0}
!4319 = !{!"0xa551570.w1024.b0", !4320, i64 0}
!4320 = !{!"int64", !4321, i64 0}
!4321 = !{!"0xa551570", !8, i64 0}
!4322 = !{!4323, !4323, i64 0}
!4323 = !{!"0xa551570.w1.b1", !4310, i64 0}
!4324 = !{!4325, !4325, i64 0}
!4325 = !{!"0xa551570.w1.b2", !4326, i64 0}
!4326 = !{!"0xa551570.w2.b2", !4311, i64 0}
!4327 = !{!4328, !4328, i64 0}
!4328 = !{!"0xa551570.w1.b3", !4326, i64 0}
!4329 = !{!4330, !4330, i64 0}
!4330 = !{!"0x1f2b1740.w4.b0", !4331, i64 0}
!4331 = !{!"0x1f2b1740.w8.b0", !4332, i64 0}
!4332 = !{!"0x1f2b1740.w16.b0", !4333, i64 0}
!4333 = !{!"0x1f2b1740.w32.b0", !4334, i64 0}
!4334 = !{!"0x1f2b1740.w64.b0", !4335, i64 0}
!4335 = !{!"0x1f2b1740.w128.b0", !4336, i64 0}
!4336 = !{!"0x1f2b1740.w256.b0", !4337, i64 0}
!4337 = !{!"0x1f2b1740.w512.b0", !4338, i64 0}
!4338 = !{!"0x1f2b1740.w1024.b0", !4339, i64 0}
!4339 = !{!"int64", !4340, i64 0}
!4340 = !{!"0x1f2b1740", !8, i64 0}
!4341 = !{!4342, !4342, i64 0}
!4342 = !{!"0x1f345340.w1.b0", !4343, i64 0}
!4343 = !{!"0x1f345340.w2.b0", !4344, i64 0}
!4344 = !{!"0x1f345340.w4.b0", !4345, i64 0}
!4345 = !{!"0x1f345340.w8.b0", !4346, i64 0}
!4346 = !{!"0x1f345340.w16.b0", !4347, i64 0}
!4347 = !{!"0x1f345340.w32.b0", !4348, i64 0}
!4348 = !{!"0x1f345340.w64.b0", !4349, i64 0}
!4349 = !{!"0x1f345340.w128.b0", !4350, i64 0}
!4350 = !{!"0x1f345340.w256.b0", !4351, i64 0}
!4351 = !{!"0x1f345340.w512.b0", !4352, i64 0}
!4352 = !{!"0x1f345340.w1024.b0", !4353, i64 0}
!4353 = !{!"int64", !4354, i64 0}
!4354 = !{!"0x1f345340", !8, i64 0}
!4355 = !{!4356, !4356, i64 0}
!4356 = !{!"0x1f345340.w1.b1", !4343, i64 0}
!4357 = !{!4358, !4358, i64 0}
!4358 = !{!"0x1f345340.w1.b2", !4359, i64 0}
!4359 = !{!"0x1f345340.w2.b2", !4344, i64 0}
!4360 = !{!4361, !4361, i64 0}
!4361 = !{!"0x1f345340.w1.b3", !4359, i64 0}
!4362 = !{!4363, !4363, i64 0}
!4363 = !{!"0x1f345340.w1.b4", !4364, i64 0}
!4364 = !{!"0x1f345340.w2.b4", !4365, i64 0}
!4365 = !{!"0x1f345340.w4.b4", !4345, i64 0}
!4366 = !{!4367, !4367, i64 0}
!4367 = !{!"0xcaa64a0.w4.b0", !4368, i64 0}
!4368 = !{!"0xcaa64a0.w8.b0", !4369, i64 0}
!4369 = !{!"0xcaa64a0.w16.b0", !4370, i64 0}
!4370 = !{!"0xcaa64a0.w32.b0", !4371, i64 0}
!4371 = !{!"0xcaa64a0.w64.b0", !4372, i64 0}
!4372 = !{!"0xcaa64a0.w128.b0", !4373, i64 0}
!4373 = !{!"0xcaa64a0.w256.b0", !4374, i64 0}
!4374 = !{!"0xcaa64a0.w512.b0", !4375, i64 0}
!4375 = !{!"0xcaa64a0.w1024.b0", !4376, i64 0}
!4376 = !{!"int64", !4377, i64 0}
!4377 = !{!"0xcaa64a0", !8, i64 0}
!4378 = !{!4379, !4379, i64 0}
!4379 = !{!"0xcaa64a0.w1.b4", !4380, i64 0}
!4380 = !{!"0xcaa64a0.w2.b4", !4381, i64 0}
!4381 = !{!"0xcaa64a0.w4.b4", !4368, i64 0}
!4382 = !{!4383, !4383, i64 0}
!4383 = !{!"float32", !4384, i64 0}
!4384 = !{!"0xa6e2de0", !8, i64 0}
!4385 = !{!4386, !4386, i64 0}
!4386 = !{!"float32", !4387, i64 0}
!4387 = !{!"0xa6df370", !8, i64 0}
!4388 = !{!4389, !4389, i64 0}
!4389 = !{!"float32", !4390, i64 0}
!4390 = !{!"0xcadce10", !8, i64 0}
!4391 = !{!4392, !4392, i64 0}
!4392 = !{!"float32", !4393, i64 0}
!4393 = !{!"0xcaaa960", !8, i64 0}
!4394 = !{!4395, !4395, i64 0}
!4395 = !{!"float32", !4396, i64 0}
!4396 = !{!"0xa709a70", !8, i64 0}
!4397 = !{!4398, !4398, i64 0}
!4398 = !{!"0xa705270.w8.b0", !4399, i64 0}
!4399 = !{!"0xa705270.w16.b0", !4400, i64 0}
!4400 = !{!"0xa705270.w32.b0", !4401, i64 0}
!4401 = !{!"0xa705270.w64.b0", !4402, i64 0}
!4402 = !{!"0xa705270.w128.b0", !4403, i64 0}
!4403 = !{!"0xa705270.w256.b0", !4404, i64 0}
!4404 = !{!"0xa705270.w512.b0", !4405, i64 0}
!4405 = !{!"0xa705270.w1024.b0", !4406, i64 0}
!4406 = !{!"float32", !4407, i64 0}
!4407 = !{!"0xa705270", !8, i64 0}
!4408 = !{!4406, !4406, i64 0}
!4409 = !{!4410, !4410, i64 0}
!4410 = !{!"float32", !4411, i64 0}
!4411 = !{!"0xa70b1a0", !8, i64 0}
!4412 = !{!4413, !4413, i64 0}
!4413 = !{!"float32", !4414, i64 0}
!4414 = !{!"0xc9b7b10", !8, i64 0}
!4415 = !{!4416, !4416, i64 0}
!4416 = !{!"0xcf15aa0.w1.b0", !4417, i64 0}
!4417 = !{!"0xcf15aa0.w2.b0", !4418, i64 0}
!4418 = !{!"0xcf15aa0.w4.b0", !4419, i64 0}
!4419 = !{!"0xcf15aa0.w8.b0", !4420, i64 0}
!4420 = !{!"0xcf15aa0.w16.b0", !4421, i64 0}
!4421 = !{!"0xcf15aa0.w32.b0", !4422, i64 0}
!4422 = !{!"0xcf15aa0.w64.b0", !4423, i64 0}
!4423 = !{!"0xcf15aa0.w128.b0", !4424, i64 0}
!4424 = !{!"0xcf15aa0.w256.b0", !4425, i64 0}
!4425 = !{!"0xcf15aa0.w512.b0", !4426, i64 0}
!4426 = !{!"0xcf15aa0.w1024.b0", !4427, i64 0}
!4427 = !{!"int32", !4428, i64 0}
!4428 = !{!"0xcf15aa0", !8, i64 0}
!4429 = !{!4430, !4430, i64 0}
!4430 = !{!"0xcf15aa0.w1.b2", !4431, i64 0}
!4431 = !{!"0xcf15aa0.w2.b2", !4418, i64 0}
!4432 = !{!4433, !4433, i64 0}
!4433 = !{!"0xcf15aa0.w1.b3", !4431, i64 0}
!4434 = !{!4435, !4435, i64 0}
!4435 = !{!"0xcf15aa0.w1.b4", !4436, i64 0}
!4436 = !{!"0xcf15aa0.w2.b4", !4437, i64 0}
!4437 = !{!"0xcf15aa0.w4.b4", !4419, i64 0}
!4438 = !{!4439, !4439, i64 0}
!4439 = !{!"0xcf15aa0.w1.b1", !4417, i64 0}
!4440 = !{!4441, !4441, i64 0}
!4441 = !{!"0xcf0f680.w1.b0", !4442, i64 0}
!4442 = !{!"0xcf0f680.w2.b0", !4443, i64 0}
!4443 = !{!"0xcf0f680.w4.b0", !4444, i64 0}
!4444 = !{!"0xcf0f680.w8.b0", !4445, i64 0}
!4445 = !{!"0xcf0f680.w16.b0", !4446, i64 0}
!4446 = !{!"0xcf0f680.w32.b0", !4447, i64 0}
!4447 = !{!"0xcf0f680.w64.b0", !4448, i64 0}
!4448 = !{!"0xcf0f680.w128.b0", !4449, i64 0}
!4449 = !{!"0xcf0f680.w256.b0", !4450, i64 0}
!4450 = !{!"0xcf0f680.w512.b0", !4451, i64 0}
!4451 = !{!"0xcf0f680.w1024.b0", !4452, i64 0}
!4452 = !{!"int64", !4453, i64 0}
!4453 = !{!"0xcf0f680", !8, i64 0}
!4454 = !{!4455, !4455, i64 0}
!4455 = !{!"0xcf0f680.w1.b1", !4442, i64 0}
!4456 = !{!4457, !4457, i64 0}
!4457 = !{!"0xcf0f680.w1.b2", !4458, i64 0}
!4458 = !{!"0xcf0f680.w2.b2", !4443, i64 0}
!4459 = !{!4460, !4460, i64 0}
!4460 = !{!"0xcf0f680.w1.b3", !4458, i64 0}
!4461 = !{!4462, !4462, i64 0}
!4462 = !{!"0xcf0f680.w1.b4", !4463, i64 0}
!4463 = !{!"0xcf0f680.w2.b4", !4464, i64 0}
!4464 = !{!"0xcf0f680.w4.b4", !4444, i64 0}
!4465 = !{!4466, !4466, i64 0}
!4466 = !{!"0xcf10f70.w4.b0", !4467, i64 0}
!4467 = !{!"0xcf10f70.w8.b0", !4468, i64 0}
!4468 = !{!"0xcf10f70.w16.b0", !4469, i64 0}
!4469 = !{!"0xcf10f70.w32.b0", !4470, i64 0}
!4470 = !{!"0xcf10f70.w64.b0", !4471, i64 0}
!4471 = !{!"0xcf10f70.w128.b0", !4472, i64 0}
!4472 = !{!"0xcf10f70.w256.b0", !4473, i64 0}
!4473 = !{!"0xcf10f70.w512.b0", !4474, i64 0}
!4474 = !{!"0xcf10f70.w1024.b0", !4475, i64 0}
!4475 = !{!"int64", !4476, i64 0}
!4476 = !{!"0xcf10f70", !8, i64 0}
!4477 = !{!4478, !4478, i64 0}
!4478 = !{!"0xcf10f70.w1.b4", !4479, i64 0}
!4479 = !{!"0xcf10f70.w2.b4", !4480, i64 0}
!4480 = !{!"0xcf10f70.w4.b4", !4467, i64 0}
!4481 = !{!4482, !4482, i64 0}
!4482 = !{!"0xa5280d0.w1.b0", !4483, i64 0}
!4483 = !{!"0xa5280d0.w2.b0", !4484, i64 0}
!4484 = !{!"0xa5280d0.w4.b0", !4485, i64 0}
!4485 = !{!"0xa5280d0.w8.b0", !4486, i64 0}
!4486 = !{!"0xa5280d0.w16.b0", !4487, i64 0}
!4487 = !{!"0xa5280d0.w32.b0", !4488, i64 0}
!4488 = !{!"0xa5280d0.w64.b0", !4489, i64 0}
!4489 = !{!"0xa5280d0.w128.b0", !4490, i64 0}
!4490 = !{!"0xa5280d0.w256.b0", !4491, i64 0}
!4491 = !{!"0xa5280d0.w512.b0", !4492, i64 0}
!4492 = !{!"0xa5280d0.w1024.b0", !4493, i64 0}
!4493 = !{!"int64", !4494, i64 0}
!4494 = !{!"0xa5280d0", !8, i64 0}
!4495 = !{!4496, !4496, i64 0}
!4496 = !{!"0xa5280d0.w1.b1", !4483, i64 0}
!4497 = !{!4498, !4498, i64 0}
!4498 = !{!"0xa5280d0.w1.b2", !4499, i64 0}
!4499 = !{!"0xa5280d0.w2.b2", !4484, i64 0}
!4500 = !{!4501, !4501, i64 0}
!4501 = !{!"0xa5280d0.w1.b3", !4499, i64 0}
!4502 = !{!4503, !4503, i64 0}
!4503 = !{!"0xa5280d0.w1.b4", !4504, i64 0}
!4504 = !{!"0xa5280d0.w2.b4", !4505, i64 0}
!4505 = !{!"0xa5280d0.w4.b4", !4485, i64 0}
!4506 = !{!4507, !4507, i64 0}
!4507 = !{!"0xa5280d0.w1.b5", !4504, i64 0}
!4508 = !{!4509, !4509, i64 0}
!4509 = !{!"0xa529d60.w4.b0", !4510, i64 0}
!4510 = !{!"0xa529d60.w8.b0", !4511, i64 0}
!4511 = !{!"0xa529d60.w16.b0", !4512, i64 0}
!4512 = !{!"0xa529d60.w32.b0", !4513, i64 0}
!4513 = !{!"0xa529d60.w64.b0", !4514, i64 0}
!4514 = !{!"0xa529d60.w128.b0", !4515, i64 0}
!4515 = !{!"0xa529d60.w256.b0", !4516, i64 0}
!4516 = !{!"0xa529d60.w512.b0", !4517, i64 0}
!4517 = !{!"0xa529d60.w1024.b0", !4518, i64 0}
!4518 = !{!"int64", !4519, i64 0}
!4519 = !{!"0xa529d60", !8, i64 0}
!4520 = !{!4521, !4521, i64 0}
!4521 = !{!"0xa529d60.w1.b4", !4522, i64 0}
!4522 = !{!"0xa529d60.w2.b4", !4523, i64 0}
!4523 = !{!"0xa529d60.w4.b4", !4510, i64 0}
!4524 = !{!4525, !4525, i64 0}
!4525 = !{!"0xa529d60.w1.b5", !4522, i64 0}
!4526 = !{!4527, !4527, i64 0}
!4527 = !{!"0xa52c2a0.w1.b0", !4528, i64 0}
!4528 = !{!"0xa52c2a0.w2.b0", !4529, i64 0}
!4529 = !{!"0xa52c2a0.w4.b0", !4530, i64 0}
!4530 = !{!"0xa52c2a0.w8.b0", !4531, i64 0}
!4531 = !{!"0xa52c2a0.w16.b0", !4532, i64 0}
!4532 = !{!"0xa52c2a0.w32.b0", !4533, i64 0}
!4533 = !{!"0xa52c2a0.w64.b0", !4534, i64 0}
!4534 = !{!"0xa52c2a0.w128.b0", !4535, i64 0}
!4535 = !{!"0xa52c2a0.w256.b0", !4536, i64 0}
!4536 = !{!"0xa52c2a0.w512.b0", !4537, i64 0}
!4537 = !{!"0xa52c2a0.w1024.b0", !4538, i64 0}
!4538 = !{!"int64", !4539, i64 0}
!4539 = !{!"0xa52c2a0", !8, i64 0}
!4540 = !{!4541, !4541, i64 0}
!4541 = !{!"0xa52c2a0.w1.b1", !4528, i64 0}
!4542 = !{!4543, !4543, i64 0}
!4543 = !{!"0xa52c2a0.w1.b2", !4544, i64 0}
!4544 = !{!"0xa52c2a0.w2.b2", !4529, i64 0}
!4545 = !{!4546, !4546, i64 0}
!4546 = !{!"0xa52c2a0.w1.b3", !4544, i64 0}
!4547 = !{!4548, !4548, i64 0}
!4548 = !{!"0xa52cc60.w4.b0", !4549, i64 0}
!4549 = !{!"0xa52cc60.w8.b0", !4550, i64 0}
!4550 = !{!"0xa52cc60.w16.b0", !4551, i64 0}
!4551 = !{!"0xa52cc60.w32.b0", !4552, i64 0}
!4552 = !{!"0xa52cc60.w64.b0", !4553, i64 0}
!4553 = !{!"0xa52cc60.w128.b0", !4554, i64 0}
!4554 = !{!"0xa52cc60.w256.b0", !4555, i64 0}
!4555 = !{!"0xa52cc60.w512.b0", !4556, i64 0}
!4556 = !{!"0xa52cc60.w1024.b0", !4557, i64 0}
!4557 = !{!"int64", !4558, i64 0}
!4558 = !{!"0xa52cc60", !8, i64 0}
!4559 = !{!4560, !4560, i64 0}
!4560 = !{!"0xcf14950.w1.b0", !4561, i64 0}
!4561 = !{!"0xcf14950.w2.b0", !4562, i64 0}
!4562 = !{!"0xcf14950.w4.b0", !4563, i64 0}
!4563 = !{!"0xcf14950.w8.b0", !4564, i64 0}
!4564 = !{!"0xcf14950.w16.b0", !4565, i64 0}
!4565 = !{!"0xcf14950.w32.b0", !4566, i64 0}
!4566 = !{!"0xcf14950.w64.b0", !4567, i64 0}
!4567 = !{!"0xcf14950.w128.b0", !4568, i64 0}
!4568 = !{!"0xcf14950.w256.b0", !4569, i64 0}
!4569 = !{!"0xcf14950.w512.b0", !4570, i64 0}
!4570 = !{!"0xcf14950.w1024.b0", !4571, i64 0}
!4571 = !{!"int64", !4572, i64 0}
!4572 = !{!"0xcf14950", !8, i64 0}
!4573 = !{!4574, !4574, i64 0}
!4574 = !{!"0xcf14950.w1.b1", !4561, i64 0}
!4575 = !{!4576, !4576, i64 0}
!4576 = !{!"0xcf14950.w1.b2", !4577, i64 0}
!4577 = !{!"0xcf14950.w2.b2", !4562, i64 0}
!4578 = !{!4579, !4579, i64 0}
!4579 = !{!"0xcf14950.w1.b3", !4577, i64 0}
!4580 = !{!4581, !4581, i64 0}
!4581 = !{!"0xa52f900.w4.b0", !4582, i64 0}
!4582 = !{!"0xa52f900.w8.b0", !4583, i64 0}
!4583 = !{!"0xa52f900.w16.b0", !4584, i64 0}
!4584 = !{!"0xa52f900.w32.b0", !4585, i64 0}
!4585 = !{!"0xa52f900.w64.b0", !4586, i64 0}
!4586 = !{!"0xa52f900.w128.b0", !4587, i64 0}
!4587 = !{!"0xa52f900.w256.b0", !4588, i64 0}
!4588 = !{!"0xa52f900.w512.b0", !4589, i64 0}
!4589 = !{!"0xa52f900.w1024.b0", !4590, i64 0}
!4590 = !{!"int64", !4591, i64 0}
!4591 = !{!"0xa52f900", !8, i64 0}
!4592 = !{!4593, !4593, i64 0}
!4593 = !{!"0xa531b50.w1.b0", !4594, i64 0}
!4594 = !{!"0xa531b50.w2.b0", !4595, i64 0}
!4595 = !{!"0xa531b50.w4.b0", !4596, i64 0}
!4596 = !{!"0xa531b50.w8.b0", !4597, i64 0}
!4597 = !{!"0xa531b50.w16.b0", !4598, i64 0}
!4598 = !{!"0xa531b50.w32.b0", !4599, i64 0}
!4599 = !{!"0xa531b50.w64.b0", !4600, i64 0}
!4600 = !{!"0xa531b50.w128.b0", !4601, i64 0}
!4601 = !{!"0xa531b50.w256.b0", !4602, i64 0}
!4602 = !{!"0xa531b50.w512.b0", !4603, i64 0}
!4603 = !{!"0xa531b50.w1024.b0", !4604, i64 0}
!4604 = !{!"int64", !4605, i64 0}
!4605 = !{!"0xa531b50", !8, i64 0}
!4606 = !{!4607, !4607, i64 0}
!4607 = !{!"0xa531b50.w1.b1", !4594, i64 0}
!4608 = !{!4609, !4609, i64 0}
!4609 = !{!"0xa531b50.w1.b2", !4610, i64 0}
!4610 = !{!"0xa531b50.w2.b2", !4595, i64 0}
!4611 = !{!4612, !4612, i64 0}
!4612 = !{!"0xa531b50.w1.b3", !4610, i64 0}
!4613 = !{!4614, !4614, i64 0}
!4614 = !{!"0xa531b50.w1.b4", !4615, i64 0}
!4615 = !{!"0xa531b50.w2.b4", !4616, i64 0}
!4616 = !{!"0xa531b50.w4.b4", !4596, i64 0}
!4617 = !{!4618, !4618, i64 0}
!4618 = !{!"0xa532750.w4.b0", !4619, i64 0}
!4619 = !{!"0xa532750.w8.b0", !4620, i64 0}
!4620 = !{!"0xa532750.w16.b0", !4621, i64 0}
!4621 = !{!"0xa532750.w32.b0", !4622, i64 0}
!4622 = !{!"0xa532750.w64.b0", !4623, i64 0}
!4623 = !{!"0xa532750.w128.b0", !4624, i64 0}
!4624 = !{!"0xa532750.w256.b0", !4625, i64 0}
!4625 = !{!"0xa532750.w512.b0", !4626, i64 0}
!4626 = !{!"0xa532750.w1024.b0", !4627, i64 0}
!4627 = !{!"int64", !4628, i64 0}
!4628 = !{!"0xa532750", !8, i64 0}
!4629 = !{!4630, !4630, i64 0}
!4630 = !{!"0xa532750.w1.b4", !4631, i64 0}
!4631 = !{!"0xa532750.w2.b4", !4632, i64 0}
!4632 = !{!"0xa532750.w4.b4", !4619, i64 0}
!4633 = !{!4634, !4634, i64 0}
!4634 = !{!"float32", !4635, i64 0}
!4635 = !{!"0x1f340940", !8, i64 0}
!4636 = !{!4637, !4637, i64 0}
!4637 = !{!"float32", !4638, i64 0}
!4638 = !{!"0x1f2b8ee0", !8, i64 0}
!4639 = !{!4640, !4640, i64 0}
!4640 = !{!"float32", !4641, i64 0}
!4641 = !{!"0xcf0f7e0", !8, i64 0}
!4642 = !{!4643, !4643, i64 0}
!4643 = !{!"float32", !4644, i64 0}
!4644 = !{!"0x1f2f11b0", !8, i64 0}
!4645 = !{!4646, !4646, i64 0}
!4646 = !{!"float32", !4647, i64 0}
!4647 = !{!"0x1f341ec0", !8, i64 0}
!4648 = !{!4649, !4649, i64 0}
!4649 = !{!"float32", !4650, i64 0}
!4650 = !{!"0x1f3421e0", !8, i64 0}
!4651 = !{!4652, !4652, i64 0}
!4652 = !{!"0xcaac160.w1.b0", !4653, i64 0}
!4653 = !{!"0xcaac160.w2.b0", !4654, i64 0}
!4654 = !{!"0xcaac160.w4.b0", !4655, i64 0}
!4655 = !{!"0xcaac160.w8.b0", !4656, i64 0}
!4656 = !{!"0xcaac160.w16.b0", !4657, i64 0}
!4657 = !{!"0xcaac160.w32.b0", !4658, i64 0}
!4658 = !{!"0xcaac160.w64.b0", !4659, i64 0}
!4659 = !{!"0xcaac160.w128.b0", !4660, i64 0}
!4660 = !{!"0xcaac160.w256.b0", !4661, i64 0}
!4661 = !{!"0xcaac160.w512.b0", !4662, i64 0}
!4662 = !{!"0xcaac160.w1024.b0", !4663, i64 0}
!4663 = !{!"int32", !4664, i64 0}
!4664 = !{!"0xcaac160", !8, i64 0}
!4665 = !{!4666, !4666, i64 0}
!4666 = !{!"0xcaac160.w1.b2", !4667, i64 0}
!4667 = !{!"0xcaac160.w2.b2", !4654, i64 0}
!4668 = !{!4669, !4669, i64 0}
!4669 = !{!"0xcaac160.w1.b3", !4667, i64 0}
!4670 = !{!4671, !4671, i64 0}
!4671 = !{!"0xcaac160.w1.b4", !4672, i64 0}
!4672 = !{!"0xcaac160.w2.b4", !4673, i64 0}
!4673 = !{!"0xcaac160.w4.b4", !4655, i64 0}
!4674 = !{!4675, !4675, i64 0}
!4675 = !{!"0xcaac160.w1.b5", !4672, i64 0}
!4676 = !{!4677, !4677, i64 0}
!4677 = !{!"0xcaac160.w1.b6", !4678, i64 0}
!4678 = !{!"0xcaac160.w2.b6", !4673, i64 0}
!4679 = !{!4680, !4680, i64 0}
!4680 = !{!"0xcaac160.w1.b1", !4653, i64 0}
!4681 = !{!4682, !4682, i64 0}
!4682 = !{!"0xcaabe80.w1.b0", !4683, i64 0}
!4683 = !{!"0xcaabe80.w2.b0", !4684, i64 0}
!4684 = !{!"0xcaabe80.w4.b0", !4685, i64 0}
!4685 = !{!"0xcaabe80.w8.b0", !4686, i64 0}
!4686 = !{!"0xcaabe80.w16.b0", !4687, i64 0}
!4687 = !{!"0xcaabe80.w32.b0", !4688, i64 0}
!4688 = !{!"0xcaabe80.w64.b0", !4689, i64 0}
!4689 = !{!"0xcaabe80.w128.b0", !4690, i64 0}
!4690 = !{!"0xcaabe80.w256.b0", !4691, i64 0}
!4691 = !{!"0xcaabe80.w512.b0", !4692, i64 0}
!4692 = !{!"0xcaabe80.w1024.b0", !4693, i64 0}
!4693 = !{!"int64", !4694, i64 0}
!4694 = !{!"0xcaabe80", !8, i64 0}
!4695 = !{!4696, !4696, i64 0}
!4696 = !{!"0xcaabe80.w1.b1", !4683, i64 0}
!4697 = !{!4698, !4698, i64 0}
!4698 = !{!"0xcaabe80.w1.b2", !4699, i64 0}
!4699 = !{!"0xcaabe80.w2.b2", !4684, i64 0}
!4700 = !{!4701, !4701, i64 0}
!4701 = !{!"0xcaabe80.w1.b3", !4699, i64 0}
!4702 = !{!4703, !4703, i64 0}
!4703 = !{!"0xcaabe80.w1.b4", !4704, i64 0}
!4704 = !{!"0xcaabe80.w2.b4", !4705, i64 0}
!4705 = !{!"0xcaabe80.w4.b4", !4685, i64 0}
!4706 = !{!4707, !4707, i64 0}
!4707 = !{!"0xc995630.w4.b0", !4708, i64 0}
!4708 = !{!"0xc995630.w8.b0", !4709, i64 0}
!4709 = !{!"0xc995630.w16.b0", !4710, i64 0}
!4710 = !{!"0xc995630.w32.b0", !4711, i64 0}
!4711 = !{!"0xc995630.w64.b0", !4712, i64 0}
!4712 = !{!"0xc995630.w128.b0", !4713, i64 0}
!4713 = !{!"0xc995630.w256.b0", !4714, i64 0}
!4714 = !{!"0xc995630.w512.b0", !4715, i64 0}
!4715 = !{!"0xc995630.w1024.b0", !4716, i64 0}
!4716 = !{!"int64", !4717, i64 0}
!4717 = !{!"0xc995630", !8, i64 0}
!4718 = !{!4719, !4719, i64 0}
!4719 = !{!"0xc995630.w1.b4", !4720, i64 0}
!4720 = !{!"0xc995630.w2.b4", !4721, i64 0}
!4721 = !{!"0xc995630.w4.b4", !4708, i64 0}
!4722 = !{!4723, !4723, i64 0}
!4723 = !{!"0xc997570.w1.b0", !4724, i64 0}
!4724 = !{!"0xc997570.w2.b0", !4725, i64 0}
!4725 = !{!"0xc997570.w4.b0", !4726, i64 0}
!4726 = !{!"0xc997570.w8.b0", !4727, i64 0}
!4727 = !{!"0xc997570.w16.b0", !4728, i64 0}
!4728 = !{!"0xc997570.w32.b0", !4729, i64 0}
!4729 = !{!"0xc997570.w64.b0", !4730, i64 0}
!4730 = !{!"0xc997570.w128.b0", !4731, i64 0}
!4731 = !{!"0xc997570.w256.b0", !4732, i64 0}
!4732 = !{!"0xc997570.w512.b0", !4733, i64 0}
!4733 = !{!"0xc997570.w1024.b0", !4734, i64 0}
!4734 = !{!"int64", !4735, i64 0}
!4735 = !{!"0xc997570", !8, i64 0}
!4736 = !{!4737, !4737, i64 0}
!4737 = !{!"0xc997570.w1.b1", !4724, i64 0}
!4738 = !{!4739, !4739, i64 0}
!4739 = !{!"0xc997570.w1.b2", !4740, i64 0}
!4740 = !{!"0xc997570.w2.b2", !4725, i64 0}
!4741 = !{!4742, !4742, i64 0}
!4742 = !{!"0xc997570.w1.b3", !4740, i64 0}
!4743 = !{!4744, !4744, i64 0}
!4744 = !{!"0xc997570.w1.b4", !4745, i64 0}
!4745 = !{!"0xc997570.w2.b4", !4746, i64 0}
!4746 = !{!"0xc997570.w4.b4", !4726, i64 0}
!4747 = !{!4748, !4748, i64 0}
!4748 = !{!"0xc997570.w1.b5", !4745, i64 0}
!4749 = !{!4750, !4750, i64 0}
!4750 = !{!"0xc9988b0.w4.b0", !4751, i64 0}
!4751 = !{!"0xc9988b0.w8.b0", !4752, i64 0}
!4752 = !{!"0xc9988b0.w16.b0", !4753, i64 0}
!4753 = !{!"0xc9988b0.w32.b0", !4754, i64 0}
!4754 = !{!"0xc9988b0.w64.b0", !4755, i64 0}
!4755 = !{!"0xc9988b0.w128.b0", !4756, i64 0}
!4756 = !{!"0xc9988b0.w256.b0", !4757, i64 0}
!4757 = !{!"0xc9988b0.w512.b0", !4758, i64 0}
!4758 = !{!"0xc9988b0.w1024.b0", !4759, i64 0}
!4759 = !{!"int64", !4760, i64 0}
!4760 = !{!"0xc9988b0", !8, i64 0}
!4761 = !{!4762, !4762, i64 0}
!4762 = !{!"0xc9988b0.w1.b4", !4763, i64 0}
!4763 = !{!"0xc9988b0.w2.b4", !4764, i64 0}
!4764 = !{!"0xc9988b0.w4.b4", !4751, i64 0}
!4765 = !{!4766, !4766, i64 0}
!4766 = !{!"0xc9988b0.w1.b5", !4763, i64 0}
!4767 = !{!4768, !4768, i64 0}
!4768 = !{!"0xc99ac20.w1.b0", !4769, i64 0}
!4769 = !{!"0xc99ac20.w2.b0", !4770, i64 0}
!4770 = !{!"0xc99ac20.w4.b0", !4771, i64 0}
!4771 = !{!"0xc99ac20.w8.b0", !4772, i64 0}
!4772 = !{!"0xc99ac20.w16.b0", !4773, i64 0}
!4773 = !{!"0xc99ac20.w32.b0", !4774, i64 0}
!4774 = !{!"0xc99ac20.w64.b0", !4775, i64 0}
!4775 = !{!"0xc99ac20.w128.b0", !4776, i64 0}
!4776 = !{!"0xc99ac20.w256.b0", !4777, i64 0}
!4777 = !{!"0xc99ac20.w512.b0", !4778, i64 0}
!4778 = !{!"0xc99ac20.w1024.b0", !4779, i64 0}
!4779 = !{!"int64", !4780, i64 0}
!4780 = !{!"0xc99ac20", !8, i64 0}
!4781 = !{!4782, !4782, i64 0}
!4782 = !{!"0xc99ac20.w1.b1", !4769, i64 0}
!4783 = !{!4784, !4784, i64 0}
!4784 = !{!"0xc99ac20.w1.b2", !4785, i64 0}
!4785 = !{!"0xc99ac20.w2.b2", !4770, i64 0}
!4786 = !{!4787, !4787, i64 0}
!4787 = !{!"0xc99ac20.w1.b3", !4785, i64 0}
!4788 = !{!4789, !4789, i64 0}
!4789 = !{!"0xc99b7c0.w4.b0", !4790, i64 0}
!4790 = !{!"0xc99b7c0.w8.b0", !4791, i64 0}
!4791 = !{!"0xc99b7c0.w16.b0", !4792, i64 0}
!4792 = !{!"0xc99b7c0.w32.b0", !4793, i64 0}
!4793 = !{!"0xc99b7c0.w64.b0", !4794, i64 0}
!4794 = !{!"0xc99b7c0.w128.b0", !4795, i64 0}
!4795 = !{!"0xc99b7c0.w256.b0", !4796, i64 0}
!4796 = !{!"0xc99b7c0.w512.b0", !4797, i64 0}
!4797 = !{!"0xc99b7c0.w1024.b0", !4798, i64 0}
!4798 = !{!"int64", !4799, i64 0}
!4799 = !{!"0xc99b7c0", !8, i64 0}
!4800 = !{!4801, !4801, i64 0}
!4801 = !{!"0xc996c40.w1.b0", !4802, i64 0}
!4802 = !{!"0xc996c40.w2.b0", !4803, i64 0}
!4803 = !{!"0xc996c40.w4.b0", !4804, i64 0}
!4804 = !{!"0xc996c40.w8.b0", !4805, i64 0}
!4805 = !{!"0xc996c40.w16.b0", !4806, i64 0}
!4806 = !{!"0xc996c40.w32.b0", !4807, i64 0}
!4807 = !{!"0xc996c40.w64.b0", !4808, i64 0}
!4808 = !{!"0xc996c40.w128.b0", !4809, i64 0}
!4809 = !{!"0xc996c40.w256.b0", !4810, i64 0}
!4810 = !{!"0xc996c40.w512.b0", !4811, i64 0}
!4811 = !{!"0xc996c40.w1024.b0", !4812, i64 0}
!4812 = !{!"int64", !4813, i64 0}
!4813 = !{!"0xc996c40", !8, i64 0}
!4814 = !{!4815, !4815, i64 0}
!4815 = !{!"0xc996c40.w1.b1", !4802, i64 0}
!4816 = !{!4817, !4817, i64 0}
!4817 = !{!"0xc996c40.w1.b2", !4818, i64 0}
!4818 = !{!"0xc996c40.w2.b2", !4803, i64 0}
!4819 = !{!4820, !4820, i64 0}
!4820 = !{!"0xc996c40.w1.b3", !4818, i64 0}
!4821 = !{!4822, !4822, i64 0}
!4822 = !{!"0xc99e550.w4.b0", !4823, i64 0}
!4823 = !{!"0xc99e550.w8.b0", !4824, i64 0}
!4824 = !{!"0xc99e550.w16.b0", !4825, i64 0}
!4825 = !{!"0xc99e550.w32.b0", !4826, i64 0}
!4826 = !{!"0xc99e550.w64.b0", !4827, i64 0}
!4827 = !{!"0xc99e550.w128.b0", !4828, i64 0}
!4828 = !{!"0xc99e550.w256.b0", !4829, i64 0}
!4829 = !{!"0xc99e550.w512.b0", !4830, i64 0}
!4830 = !{!"0xc99e550.w1024.b0", !4831, i64 0}
!4831 = !{!"int64", !4832, i64 0}
!4832 = !{!"0xc99e550", !8, i64 0}
!4833 = !{!4834, !4834, i64 0}
!4834 = !{!"0xc9a0630.w1.b0", !4835, i64 0}
!4835 = !{!"0xc9a0630.w2.b0", !4836, i64 0}
!4836 = !{!"0xc9a0630.w4.b0", !4837, i64 0}
!4837 = !{!"0xc9a0630.w8.b0", !4838, i64 0}
!4838 = !{!"0xc9a0630.w16.b0", !4839, i64 0}
!4839 = !{!"0xc9a0630.w32.b0", !4840, i64 0}
!4840 = !{!"0xc9a0630.w64.b0", !4841, i64 0}
!4841 = !{!"0xc9a0630.w128.b0", !4842, i64 0}
!4842 = !{!"0xc9a0630.w256.b0", !4843, i64 0}
!4843 = !{!"0xc9a0630.w512.b0", !4844, i64 0}
!4844 = !{!"0xc9a0630.w1024.b0", !4845, i64 0}
!4845 = !{!"int64", !4846, i64 0}
!4846 = !{!"0xc9a0630", !8, i64 0}
!4847 = !{!4848, !4848, i64 0}
!4848 = !{!"0xc9a0630.w1.b1", !4835, i64 0}
!4849 = !{!4850, !4850, i64 0}
!4850 = !{!"0xc9a0630.w1.b2", !4851, i64 0}
!4851 = !{!"0xc9a0630.w2.b2", !4836, i64 0}
!4852 = !{!4853, !4853, i64 0}
!4853 = !{!"0xc9a0630.w1.b3", !4851, i64 0}
!4854 = !{!4855, !4855, i64 0}
!4855 = !{!"0xc9a12b0.w4.b0", !4856, i64 0}
!4856 = !{!"0xc9a12b0.w8.b0", !4857, i64 0}
!4857 = !{!"0xc9a12b0.w16.b0", !4858, i64 0}
!4858 = !{!"0xc9a12b0.w32.b0", !4859, i64 0}
!4859 = !{!"0xc9a12b0.w64.b0", !4860, i64 0}
!4860 = !{!"0xc9a12b0.w128.b0", !4861, i64 0}
!4861 = !{!"0xc9a12b0.w256.b0", !4862, i64 0}
!4862 = !{!"0xc9a12b0.w512.b0", !4863, i64 0}
!4863 = !{!"0xc9a12b0.w1024.b0", !4864, i64 0}
!4864 = !{!"int64", !4865, i64 0}
!4865 = !{!"0xc9a12b0", !8, i64 0}
!4866 = !{!4867, !4867, i64 0}
!4867 = !{!"0xc9a31e0.w1.b0", !4868, i64 0}
!4868 = !{!"0xc9a31e0.w2.b0", !4869, i64 0}
!4869 = !{!"0xc9a31e0.w4.b0", !4870, i64 0}
!4870 = !{!"0xc9a31e0.w8.b0", !4871, i64 0}
!4871 = !{!"0xc9a31e0.w16.b0", !4872, i64 0}
!4872 = !{!"0xc9a31e0.w32.b0", !4873, i64 0}
!4873 = !{!"0xc9a31e0.w64.b0", !4874, i64 0}
!4874 = !{!"0xc9a31e0.w128.b0", !4875, i64 0}
!4875 = !{!"0xc9a31e0.w256.b0", !4876, i64 0}
!4876 = !{!"0xc9a31e0.w512.b0", !4877, i64 0}
!4877 = !{!"0xc9a31e0.w1024.b0", !4878, i64 0}
!4878 = !{!"int64", !4879, i64 0}
!4879 = !{!"0xc9a31e0", !8, i64 0}
!4880 = !{!4881, !4881, i64 0}
!4881 = !{!"0xc9a31e0.w1.b1", !4868, i64 0}
!4882 = !{!4883, !4883, i64 0}
!4883 = !{!"0xc9a31e0.w1.b2", !4884, i64 0}
!4884 = !{!"0xc9a31e0.w2.b2", !4869, i64 0}
!4885 = !{!4886, !4886, i64 0}
!4886 = !{!"0xc9a31e0.w1.b3", !4884, i64 0}
!4887 = !{!4888, !4888, i64 0}
!4888 = !{!"0xc9a31e0.w1.b4", !4889, i64 0}
!4889 = !{!"0xc9a31e0.w2.b4", !4890, i64 0}
!4890 = !{!"0xc9a31e0.w4.b4", !4870, i64 0}
!4891 = !{!4892, !4892, i64 0}
!4892 = !{!"0xc9a4010.w4.b0", !4893, i64 0}
!4893 = !{!"0xc9a4010.w8.b0", !4894, i64 0}
!4894 = !{!"0xc9a4010.w16.b0", !4895, i64 0}
!4895 = !{!"0xc9a4010.w32.b0", !4896, i64 0}
!4896 = !{!"0xc9a4010.w64.b0", !4897, i64 0}
!4897 = !{!"0xc9a4010.w128.b0", !4898, i64 0}
!4898 = !{!"0xc9a4010.w256.b0", !4899, i64 0}
!4899 = !{!"0xc9a4010.w512.b0", !4900, i64 0}
!4900 = !{!"0xc9a4010.w1024.b0", !4901, i64 0}
!4901 = !{!"int64", !4902, i64 0}
!4902 = !{!"0xc9a4010", !8, i64 0}
!4903 = !{!4904, !4904, i64 0}
!4904 = !{!"0xc9a4010.w1.b4", !4905, i64 0}
!4905 = !{!"0xc9a4010.w2.b4", !4906, i64 0}
!4906 = !{!"0xc9a4010.w4.b4", !4893, i64 0}
!4907 = !{!4908, !4908, i64 0}
!4908 = !{!"0xc99aba0.w1.b0", !4909, i64 0}
!4909 = !{!"0xc99aba0.w2.b0", !4910, i64 0}
!4910 = !{!"0xc99aba0.w4.b0", !4911, i64 0}
!4911 = !{!"0xc99aba0.w8.b0", !4912, i64 0}
!4912 = !{!"0xc99aba0.w16.b0", !4913, i64 0}
!4913 = !{!"0xc99aba0.w32.b0", !4914, i64 0}
!4914 = !{!"0xc99aba0.w64.b0", !4915, i64 0}
!4915 = !{!"0xc99aba0.w128.b0", !4916, i64 0}
!4916 = !{!"0xc99aba0.w256.b0", !4917, i64 0}
!4917 = !{!"0xc99aba0.w512.b0", !4918, i64 0}
!4918 = !{!"0xc99aba0.w1024.b0", !4919, i64 0}
!4919 = !{!"int64", !4920, i64 0}
!4920 = !{!"0xc99aba0", !8, i64 0}
!4921 = !{!4922, !4922, i64 0}
!4922 = !{!"0xc99aba0.w1.b1", !4909, i64 0}
!4923 = !{!4924, !4924, i64 0}
!4924 = !{!"0xc99aba0.w1.b2", !4925, i64 0}
!4925 = !{!"0xc99aba0.w2.b2", !4910, i64 0}
!4926 = !{!4927, !4927, i64 0}
!4927 = !{!"0xc99aba0.w1.b3", !4925, i64 0}
!4928 = !{!4929, !4929, i64 0}
!4929 = !{!"0xc99aba0.w1.b4", !4930, i64 0}
!4930 = !{!"0xc99aba0.w2.b4", !4931, i64 0}
!4931 = !{!"0xc99aba0.w4.b4", !4911, i64 0}
!4932 = !{!4933, !4933, i64 0}
!4933 = !{!"0xc9a72f0.w4.b0", !4934, i64 0}
!4934 = !{!"0xc9a72f0.w8.b0", !4935, i64 0}
!4935 = !{!"0xc9a72f0.w16.b0", !4936, i64 0}
!4936 = !{!"0xc9a72f0.w32.b0", !4937, i64 0}
!4937 = !{!"0xc9a72f0.w64.b0", !4938, i64 0}
!4938 = !{!"0xc9a72f0.w128.b0", !4939, i64 0}
!4939 = !{!"0xc9a72f0.w256.b0", !4940, i64 0}
!4940 = !{!"0xc9a72f0.w512.b0", !4941, i64 0}
!4941 = !{!"0xc9a72f0.w1024.b0", !4942, i64 0}
!4942 = !{!"int64", !4943, i64 0}
!4943 = !{!"0xc9a72f0", !8, i64 0}
!4944 = !{!4945, !4945, i64 0}
!4945 = !{!"0xc9a72f0.w1.b4", !4946, i64 0}
!4946 = !{!"0xc9a72f0.w2.b4", !4947, i64 0}
!4947 = !{!"0xc9a72f0.w4.b4", !4934, i64 0}
!4948 = !{!4949, !4949, i64 0}
!4949 = !{!"float32", !4950, i64 0}
!4950 = !{!"0xcaa48e0", !8, i64 0}
!4951 = !{!4952, !4952, i64 0}
!4952 = !{!"float32", !4953, i64 0}
!4953 = !{!"0xcaa0b60", !8, i64 0}
!4954 = !{!4955, !4955, i64 0}
!4955 = !{!"float32", !4956, i64 0}
!4956 = !{!"0xcaa4e40", !8, i64 0}
!4957 = !{!4958, !4958, i64 0}
!4958 = !{!"float32", !4959, i64 0}
!4959 = !{!"0xcaaaa10", !8, i64 0}
!4960 = !{!4961, !4961, i64 0}
!4961 = !{!"float32", !4962, i64 0}
!4962 = !{!"0xcaa1800", !8, i64 0}
!4963 = !{!4964, !4964, i64 0}
!4964 = !{!"float32", !4965, i64 0}
!4965 = !{!"0xcaa3e20", !8, i64 0}
!4966 = !{!4967, !4967, i64 0}
!4967 = !{!"float32", !4968, i64 0}
!4968 = !{!"0xcaa2ae0", !8, i64 0}
!4969 = !{!4970, !4970, i64 0}
!4970 = !{!"float32", !4971, i64 0}
!4971 = !{!"0xcaa2db0", !8, i64 0}
!4972 = !{!4973, !4973, i64 0}
!4973 = !{!"0x180b9690.w1.b0", !4974, i64 0}
!4974 = !{!"0x180b9690.w2.b0", !4975, i64 0}
!4975 = !{!"0x180b9690.w4.b0", !4976, i64 0}
!4976 = !{!"0x180b9690.w8.b0", !4977, i64 0}
!4977 = !{!"0x180b9690.w16.b0", !4978, i64 0}
!4978 = !{!"0x180b9690.w32.b0", !4979, i64 0}
!4979 = !{!"0x180b9690.w64.b0", !4980, i64 0}
!4980 = !{!"0x180b9690.w128.b0", !4981, i64 0}
!4981 = !{!"0x180b9690.w256.b0", !4982, i64 0}
!4982 = !{!"0x180b9690.w512.b0", !4983, i64 0}
!4983 = !{!"0x180b9690.w1024.b0", !4984, i64 0}
!4984 = !{!"int32", !4985, i64 0}
!4985 = !{!"0x180b9690", !8, i64 0}
!4986 = !{!4987, !4987, i64 0}
!4987 = !{!"0x180b9690.w1.b2", !4988, i64 0}
!4988 = !{!"0x180b9690.w2.b2", !4975, i64 0}
!4989 = !{!4990, !4990, i64 0}
!4990 = !{!"0x180b9690.w1.b3", !4988, i64 0}
!4991 = !{!4992, !4992, i64 0}
!4992 = !{!"0x180b9690.w1.b4", !4993, i64 0}
!4993 = !{!"0x180b9690.w2.b4", !4994, i64 0}
!4994 = !{!"0x180b9690.w4.b4", !4976, i64 0}
!4995 = !{!4996, !4996, i64 0}
!4996 = !{!"0x180b9690.w1.b1", !4974, i64 0}
!4997 = !{!4998, !4998, i64 0}
!4998 = !{!"0x1f3486e0.w1.b0", !4999, i64 0}
!4999 = !{!"0x1f3486e0.w2.b0", !5000, i64 0}
!5000 = !{!"0x1f3486e0.w4.b0", !5001, i64 0}
!5001 = !{!"0x1f3486e0.w8.b0", !5002, i64 0}
!5002 = !{!"0x1f3486e0.w16.b0", !5003, i64 0}
!5003 = !{!"0x1f3486e0.w32.b0", !5004, i64 0}
!5004 = !{!"0x1f3486e0.w64.b0", !5005, i64 0}
!5005 = !{!"0x1f3486e0.w128.b0", !5006, i64 0}
!5006 = !{!"0x1f3486e0.w256.b0", !5007, i64 0}
!5007 = !{!"0x1f3486e0.w512.b0", !5008, i64 0}
!5008 = !{!"0x1f3486e0.w1024.b0", !5009, i64 0}
!5009 = !{!"int64", !5010, i64 0}
!5010 = !{!"0x1f3486e0", !8, i64 0}
!5011 = !{!5012, !5012, i64 0}
!5012 = !{!"0x1f3486e0.w1.b1", !4999, i64 0}
!5013 = !{!5014, !5014, i64 0}
!5014 = !{!"0x1f3486e0.w1.b2", !5015, i64 0}
!5015 = !{!"0x1f3486e0.w2.b2", !5000, i64 0}
!5016 = !{!5017, !5017, i64 0}
!5017 = !{!"0x1f3486e0.w1.b3", !5015, i64 0}
!5018 = !{!5019, !5019, i64 0}
!5019 = !{!"0x1f3486e0.w1.b4", !5020, i64 0}
!5020 = !{!"0x1f3486e0.w2.b4", !5021, i64 0}
!5021 = !{!"0x1f3486e0.w4.b4", !5001, i64 0}
!5022 = !{!5023, !5023, i64 0}
!5023 = !{!"0xa51eae0.w4.b0", !5024, i64 0}
!5024 = !{!"0xa51eae0.w8.b0", !5025, i64 0}
!5025 = !{!"0xa51eae0.w16.b0", !5026, i64 0}
!5026 = !{!"0xa51eae0.w32.b0", !5027, i64 0}
!5027 = !{!"0xa51eae0.w64.b0", !5028, i64 0}
!5028 = !{!"0xa51eae0.w128.b0", !5029, i64 0}
!5029 = !{!"0xa51eae0.w256.b0", !5030, i64 0}
!5030 = !{!"0xa51eae0.w512.b0", !5031, i64 0}
!5031 = !{!"0xa51eae0.w1024.b0", !5032, i64 0}
!5032 = !{!"int64", !5033, i64 0}
!5033 = !{!"0xa51eae0", !8, i64 0}
!5034 = !{!5035, !5035, i64 0}
!5035 = !{!"0xa51eae0.w1.b4", !5036, i64 0}
!5036 = !{!"0xa51eae0.w2.b4", !5037, i64 0}
!5037 = !{!"0xa51eae0.w4.b4", !5024, i64 0}
!5038 = !{!5039, !5039, i64 0}
!5039 = !{!"0x1b74d810.w1.b0", !5040, i64 0}
!5040 = !{!"0x1b74d810.w2.b0", !5041, i64 0}
!5041 = !{!"0x1b74d810.w4.b0", !5042, i64 0}
!5042 = !{!"0x1b74d810.w8.b0", !5043, i64 0}
!5043 = !{!"0x1b74d810.w16.b0", !5044, i64 0}
!5044 = !{!"0x1b74d810.w32.b0", !5045, i64 0}
!5045 = !{!"0x1b74d810.w64.b0", !5046, i64 0}
!5046 = !{!"0x1b74d810.w128.b0", !5047, i64 0}
!5047 = !{!"0x1b74d810.w256.b0", !5048, i64 0}
!5048 = !{!"0x1b74d810.w512.b0", !5049, i64 0}
!5049 = !{!"0x1b74d810.w1024.b0", !5050, i64 0}
!5050 = !{!"int64", !5051, i64 0}
!5051 = !{!"0x1b74d810", !8, i64 0}
!5052 = !{!5053, !5053, i64 0}
!5053 = !{!"0x1b74d810.w1.b1", !5040, i64 0}
!5054 = !{!5055, !5055, i64 0}
!5055 = !{!"0x1b74d810.w1.b2", !5056, i64 0}
!5056 = !{!"0x1b74d810.w2.b2", !5041, i64 0}
!5057 = !{!5058, !5058, i64 0}
!5058 = !{!"0x1b74d810.w1.b3", !5056, i64 0}
!5059 = !{!5060, !5060, i64 0}
!5060 = !{!"0x1b74d810.w1.b4", !5061, i64 0}
!5061 = !{!"0x1b74d810.w2.b4", !5062, i64 0}
!5062 = !{!"0x1b74d810.w4.b4", !5042, i64 0}
!5063 = !{!5064, !5064, i64 0}
!5064 = !{!"0x1b74d810.w1.b5", !5061, i64 0}
!5065 = !{!5066, !5066, i64 0}
!5066 = !{!"0xecce5e0.w4.b0", !5067, i64 0}
!5067 = !{!"0xecce5e0.w8.b0", !5068, i64 0}
!5068 = !{!"0xecce5e0.w16.b0", !5069, i64 0}
!5069 = !{!"0xecce5e0.w32.b0", !5070, i64 0}
!5070 = !{!"0xecce5e0.w64.b0", !5071, i64 0}
!5071 = !{!"0xecce5e0.w128.b0", !5072, i64 0}
!5072 = !{!"0xecce5e0.w256.b0", !5073, i64 0}
!5073 = !{!"0xecce5e0.w512.b0", !5074, i64 0}
!5074 = !{!"0xecce5e0.w1024.b0", !5075, i64 0}
!5075 = !{!"int64", !5076, i64 0}
!5076 = !{!"0xecce5e0", !8, i64 0}
!5077 = !{!5078, !5078, i64 0}
!5078 = !{!"0xecce5e0.w1.b4", !5079, i64 0}
!5079 = !{!"0xecce5e0.w2.b4", !5080, i64 0}
!5080 = !{!"0xecce5e0.w4.b4", !5067, i64 0}
!5081 = !{!5082, !5082, i64 0}
!5082 = !{!"0xecce5e0.w1.b5", !5079, i64 0}
!5083 = !{!5084, !5084, i64 0}
!5084 = !{!"0x13af1c30.w1.b0", !5085, i64 0}
!5085 = !{!"0x13af1c30.w2.b0", !5086, i64 0}
!5086 = !{!"0x13af1c30.w4.b0", !5087, i64 0}
!5087 = !{!"0x13af1c30.w8.b0", !5088, i64 0}
!5088 = !{!"0x13af1c30.w16.b0", !5089, i64 0}
!5089 = !{!"0x13af1c30.w32.b0", !5090, i64 0}
!5090 = !{!"0x13af1c30.w64.b0", !5091, i64 0}
!5091 = !{!"0x13af1c30.w128.b0", !5092, i64 0}
!5092 = !{!"0x13af1c30.w256.b0", !5093, i64 0}
!5093 = !{!"0x13af1c30.w512.b0", !5094, i64 0}
!5094 = !{!"0x13af1c30.w1024.b0", !5095, i64 0}
!5095 = !{!"int64", !5096, i64 0}
!5096 = !{!"0x13af1c30", !8, i64 0}
!5097 = !{!5098, !5098, i64 0}
!5098 = !{!"0x13af1c30.w1.b1", !5085, i64 0}
!5099 = !{!5100, !5100, i64 0}
!5100 = !{!"0x13af1c30.w1.b2", !5101, i64 0}
!5101 = !{!"0x13af1c30.w2.b2", !5086, i64 0}
!5102 = !{!5103, !5103, i64 0}
!5103 = !{!"0x13af1c30.w1.b3", !5101, i64 0}
!5104 = !{!5105, !5105, i64 0}
!5105 = !{!"0xecf6080.w4.b0", !5106, i64 0}
!5106 = !{!"0xecf6080.w8.b0", !5107, i64 0}
!5107 = !{!"0xecf6080.w16.b0", !5108, i64 0}
!5108 = !{!"0xecf6080.w32.b0", !5109, i64 0}
!5109 = !{!"0xecf6080.w64.b0", !5110, i64 0}
!5110 = !{!"0xecf6080.w128.b0", !5111, i64 0}
!5111 = !{!"0xecf6080.w256.b0", !5112, i64 0}
!5112 = !{!"0xecf6080.w512.b0", !5113, i64 0}
!5113 = !{!"0xecf6080.w1024.b0", !5114, i64 0}
!5114 = !{!"int64", !5115, i64 0}
!5115 = !{!"0xecf6080", !8, i64 0}
!5116 = !{!5117, !5117, i64 0}
!5117 = !{!"0x13aeccd0.w1.b0", !5118, i64 0}
!5118 = !{!"0x13aeccd0.w2.b0", !5119, i64 0}
!5119 = !{!"0x13aeccd0.w4.b0", !5120, i64 0}
!5120 = !{!"0x13aeccd0.w8.b0", !5121, i64 0}
!5121 = !{!"0x13aeccd0.w16.b0", !5122, i64 0}
!5122 = !{!"0x13aeccd0.w32.b0", !5123, i64 0}
!5123 = !{!"0x13aeccd0.w64.b0", !5124, i64 0}
!5124 = !{!"0x13aeccd0.w128.b0", !5125, i64 0}
!5125 = !{!"0x13aeccd0.w256.b0", !5126, i64 0}
!5126 = !{!"0x13aeccd0.w512.b0", !5127, i64 0}
!5127 = !{!"0x13aeccd0.w1024.b0", !5128, i64 0}
!5128 = !{!"int64", !5129, i64 0}
!5129 = !{!"0x13aeccd0", !8, i64 0}
!5130 = !{!5131, !5131, i64 0}
!5131 = !{!"0x13aeccd0.w1.b1", !5118, i64 0}
!5132 = !{!5133, !5133, i64 0}
!5133 = !{!"0x13aeccd0.w1.b2", !5134, i64 0}
!5134 = !{!"0x13aeccd0.w2.b2", !5119, i64 0}
!5135 = !{!5136, !5136, i64 0}
!5136 = !{!"0x13aeccd0.w1.b3", !5134, i64 0}
!5137 = !{!5138, !5138, i64 0}
!5138 = !{!"0x13b10190.w4.b0", !5139, i64 0}
!5139 = !{!"0x13b10190.w8.b0", !5140, i64 0}
!5140 = !{!"0x13b10190.w16.b0", !5141, i64 0}
!5141 = !{!"0x13b10190.w32.b0", !5142, i64 0}
!5142 = !{!"0x13b10190.w64.b0", !5143, i64 0}
!5143 = !{!"0x13b10190.w128.b0", !5144, i64 0}
!5144 = !{!"0x13b10190.w256.b0", !5145, i64 0}
!5145 = !{!"0x13b10190.w512.b0", !5146, i64 0}
!5146 = !{!"0x13b10190.w1024.b0", !5147, i64 0}
!5147 = !{!"int64", !5148, i64 0}
!5148 = !{!"0x13b10190", !8, i64 0}
!5149 = !{!5150, !5150, i64 0}
!5150 = !{!"0x1f356a10.w1.b0", !5151, i64 0}
!5151 = !{!"0x1f356a10.w2.b0", !5152, i64 0}
!5152 = !{!"0x1f356a10.w4.b0", !5153, i64 0}
!5153 = !{!"0x1f356a10.w8.b0", !5154, i64 0}
!5154 = !{!"0x1f356a10.w16.b0", !5155, i64 0}
!5155 = !{!"0x1f356a10.w32.b0", !5156, i64 0}
!5156 = !{!"0x1f356a10.w64.b0", !5157, i64 0}
!5157 = !{!"0x1f356a10.w128.b0", !5158, i64 0}
!5158 = !{!"0x1f356a10.w256.b0", !5159, i64 0}
!5159 = !{!"0x1f356a10.w512.b0", !5160, i64 0}
!5160 = !{!"0x1f356a10.w1024.b0", !5161, i64 0}
!5161 = !{!"int64", !5162, i64 0}
!5162 = !{!"0x1f356a10", !8, i64 0}
!5163 = !{!5164, !5164, i64 0}
!5164 = !{!"0x1f356a10.w1.b1", !5151, i64 0}
!5165 = !{!5166, !5166, i64 0}
!5166 = !{!"0x1f356a10.w1.b2", !5167, i64 0}
!5167 = !{!"0x1f356a10.w2.b2", !5152, i64 0}
!5168 = !{!5169, !5169, i64 0}
!5169 = !{!"0x1f356a10.w1.b3", !5167, i64 0}
!5170 = !{!5171, !5171, i64 0}
!5171 = !{!"0x1f356a10.w1.b4", !5172, i64 0}
!5172 = !{!"0x1f356a10.w2.b4", !5173, i64 0}
!5173 = !{!"0x1f356a10.w4.b4", !5153, i64 0}
!5174 = !{!5175, !5175, i64 0}
!5175 = !{!"0xd52f2b0.w4.b0", !5176, i64 0}
!5176 = !{!"0xd52f2b0.w8.b0", !5177, i64 0}
!5177 = !{!"0xd52f2b0.w16.b0", !5178, i64 0}
!5178 = !{!"0xd52f2b0.w32.b0", !5179, i64 0}
!5179 = !{!"0xd52f2b0.w64.b0", !5180, i64 0}
!5180 = !{!"0xd52f2b0.w128.b0", !5181, i64 0}
!5181 = !{!"0xd52f2b0.w256.b0", !5182, i64 0}
!5182 = !{!"0xd52f2b0.w512.b0", !5183, i64 0}
!5183 = !{!"0xd52f2b0.w1024.b0", !5184, i64 0}
!5184 = !{!"int64", !5185, i64 0}
!5185 = !{!"0xd52f2b0", !8, i64 0}
!5186 = !{!5187, !5187, i64 0}
!5187 = !{!"0xd52f2b0.w1.b4", !5188, i64 0}
!5188 = !{!"0xd52f2b0.w2.b4", !5189, i64 0}
!5189 = !{!"0xd52f2b0.w4.b4", !5176, i64 0}
!5190 = !{!5191, !5191, i64 0}
!5191 = !{!"float32", !5192, i64 0}
!5192 = !{!"0x1398d570", !8, i64 0}
!5193 = distinct !{!5193, !1123}
!5194 = distinct !{!5194, !1123}
!5195 = !{!5196, !5196, i64 0}
!5196 = !{!"float32", !5197, i64 0}
!5197 = !{!"0x8d998c0", !8, i64 0}
!5198 = distinct !{!5198, !1123}
!5199 = distinct !{!5199, !1123}
!5200 = distinct !{!5200, !1123}
!5201 = distinct !{!5201, !1123}
!5202 = distinct !{!5202, !1123}
!5203 = distinct !{!5203, !1123}
!5204 = distinct !{!5204, !1123}
!5205 = distinct !{!5205, !1123}
!5206 = distinct !{!5206, !1123}
!5207 = distinct !{!5207, !1123}
!5208 = distinct !{!5208, !1123}
!5209 = distinct !{!5209, !1123}
!5210 = distinct !{!5210, !1123}
!5211 = distinct !{!5211, !1123}
!5212 = distinct !{!5212, !1123}
!5213 = distinct !{!5213, !1123}
!5214 = !{!5215, !5215, i64 0}
!5215 = !{!"float32", !5216, i64 0}
!5216 = !{!"0x9cc4e70", !8, i64 0}
!5217 = !{!5218, !5218, i64 0}
!5218 = !{!"float32", !5219, i64 0}
!5219 = !{!"0xd4eee60", !8, i64 0}
!5220 = !{!5221, !5221, i64 0}
!5221 = !{!"float32", !5222, i64 0}
!5222 = !{!"0x92d1d30", !8, i64 0}
!5223 = !{!5224, !5224, i64 0}
!5224 = !{!"float32", !5225, i64 0}
!5225 = !{!"0x135e2890", !8, i64 0}
!5226 = !{!5227, !5227, i64 0}
!5227 = !{!"0xd962970.w1.b0", !5228, i64 0}
!5228 = !{!"0xd962970.w2.b0", !5229, i64 0}
!5229 = !{!"0xd962970.w4.b0", !5230, i64 0}
!5230 = !{!"0xd962970.w8.b0", !5231, i64 0}
!5231 = !{!"0xd962970.w16.b0", !5232, i64 0}
!5232 = !{!"0xd962970.w32.b0", !5233, i64 0}
!5233 = !{!"0xd962970.w64.b0", !5234, i64 0}
!5234 = !{!"0xd962970.w128.b0", !5235, i64 0}
!5235 = !{!"0xd962970.w256.b0", !5236, i64 0}
!5236 = !{!"0xd962970.w512.b0", !5237, i64 0}
!5237 = !{!"0xd962970.w1024.b0", !5238, i64 0}
!5238 = !{!"int32", !5239, i64 0}
!5239 = !{!"0xd962970", !8, i64 0}
!5240 = !{!5241, !5241, i64 0}
!5241 = !{!"0xd962970.w1.b1", !5228, i64 0}
!5242 = !{!5243, !5243, i64 0}
!5243 = !{!"0xf801670.w1.b0", !5244, i64 0}
!5244 = !{!"0xf801670.w2.b0", !5245, i64 0}
!5245 = !{!"0xf801670.w4.b0", !5246, i64 0}
!5246 = !{!"0xf801670.w8.b0", !5247, i64 0}
!5247 = !{!"0xf801670.w16.b0", !5248, i64 0}
!5248 = !{!"0xf801670.w32.b0", !5249, i64 0}
!5249 = !{!"0xf801670.w64.b0", !5250, i64 0}
!5250 = !{!"0xf801670.w128.b0", !5251, i64 0}
!5251 = !{!"0xf801670.w256.b0", !5252, i64 0}
!5252 = !{!"0xf801670.w512.b0", !5253, i64 0}
!5253 = !{!"0xf801670.w1024.b0", !5254, i64 0}
!5254 = !{!"int64", !5255, i64 0}
!5255 = !{!"0xf801670", !8, i64 0}
!5256 = !{!5257, !5257, i64 0}
!5257 = !{!"0xf801670.w1.b1", !5244, i64 0}
!5258 = !{!5259, !5259, i64 0}
!5259 = !{!"0xf801670.w1.b2", !5260, i64 0}
!5260 = !{!"0xf801670.w2.b2", !5245, i64 0}
!5261 = !{!5262, !5262, i64 0}
!5262 = !{!"0xf801670.w1.b3", !5260, i64 0}
!5263 = !{!5264, !5264, i64 0}
!5264 = !{!"0xf801670.w1.b4", !5265, i64 0}
!5265 = !{!"0xf801670.w2.b4", !5266, i64 0}
!5266 = !{!"0xf801670.w4.b4", !5246, i64 0}
!5267 = !{!5268, !5268, i64 0}
!5268 = !{!"0x86d3d50.w4.b0", !5269, i64 0}
!5269 = !{!"0x86d3d50.w8.b0", !5270, i64 0}
!5270 = !{!"0x86d3d50.w16.b0", !5271, i64 0}
!5271 = !{!"0x86d3d50.w32.b0", !5272, i64 0}
!5272 = !{!"0x86d3d50.w64.b0", !5273, i64 0}
!5273 = !{!"0x86d3d50.w128.b0", !5274, i64 0}
!5274 = !{!"0x86d3d50.w256.b0", !5275, i64 0}
!5275 = !{!"0x86d3d50.w512.b0", !5276, i64 0}
!5276 = !{!"0x86d3d50.w1024.b0", !5277, i64 0}
!5277 = !{!"int64", !5278, i64 0}
!5278 = !{!"0x86d3d50", !8, i64 0}
!5279 = !{!5280, !5280, i64 0}
!5280 = !{!"0x86d3d50.w1.b4", !5281, i64 0}
!5281 = !{!"0x86d3d50.w2.b4", !5282, i64 0}
!5282 = !{!"0x86d3d50.w4.b4", !5269, i64 0}
!5283 = !{!5284, !5284, i64 0}
!5284 = !{!"0x86e98c0.w1.b0", !5285, i64 0}
!5285 = !{!"0x86e98c0.w2.b0", !5286, i64 0}
!5286 = !{!"0x86e98c0.w4.b0", !5287, i64 0}
!5287 = !{!"0x86e98c0.w8.b0", !5288, i64 0}
!5288 = !{!"0x86e98c0.w16.b0", !5289, i64 0}
!5289 = !{!"0x86e98c0.w32.b0", !5290, i64 0}
!5290 = !{!"0x86e98c0.w64.b0", !5291, i64 0}
!5291 = !{!"0x86e98c0.w128.b0", !5292, i64 0}
!5292 = !{!"0x86e98c0.w256.b0", !5293, i64 0}
!5293 = !{!"0x86e98c0.w512.b0", !5294, i64 0}
!5294 = !{!"0x86e98c0.w1024.b0", !5295, i64 0}
!5295 = !{!"int64", !5296, i64 0}
!5296 = !{!"0x86e98c0", !8, i64 0}
!5297 = !{!5298, !5298, i64 0}
!5298 = !{!"0x86e98c0.w1.b1", !5285, i64 0}
!5299 = !{!5300, !5300, i64 0}
!5300 = !{!"0x86e98c0.w1.b2", !5301, i64 0}
!5301 = !{!"0x86e98c0.w2.b2", !5286, i64 0}
!5302 = !{!5303, !5303, i64 0}
!5303 = !{!"0x86e98c0.w1.b3", !5301, i64 0}
!5304 = !{!5305, !5305, i64 0}
!5305 = !{!"0x86e98c0.w1.b4", !5306, i64 0}
!5306 = !{!"0x86e98c0.w2.b4", !5307, i64 0}
!5307 = !{!"0x86e98c0.w4.b4", !5287, i64 0}
!5308 = !{!5309, !5309, i64 0}
!5309 = !{!"0xa8676e0.w4.b0", !5310, i64 0}
!5310 = !{!"0xa8676e0.w8.b0", !5311, i64 0}
!5311 = !{!"0xa8676e0.w16.b0", !5312, i64 0}
!5312 = !{!"0xa8676e0.w32.b0", !5313, i64 0}
!5313 = !{!"0xa8676e0.w64.b0", !5314, i64 0}
!5314 = !{!"0xa8676e0.w128.b0", !5315, i64 0}
!5315 = !{!"0xa8676e0.w256.b0", !5316, i64 0}
!5316 = !{!"0xa8676e0.w512.b0", !5317, i64 0}
!5317 = !{!"0xa8676e0.w1024.b0", !5318, i64 0}
!5318 = !{!"int64", !5319, i64 0}
!5319 = !{!"0xa8676e0", !8, i64 0}
!5320 = !{!5321, !5321, i64 0}
!5321 = !{!"0xa8676e0.w1.b4", !5322, i64 0}
!5322 = !{!"0xa8676e0.w2.b4", !5323, i64 0}
!5323 = !{!"0xa8676e0.w4.b4", !5310, i64 0}
!5324 = !{!5325, !5325, i64 0}
!5325 = !{!"float32", !5326, i64 0}
!5326 = !{!"0xfa89c70", !8, i64 0}
!5327 = !{!5328, !5328, i64 0}
!5328 = !{!"float32", !5329, i64 0}
!5329 = !{!"0x13958170", !8, i64 0}
!5330 = !{!5331, !5331, i64 0}
!5331 = !{!"0x1367d8e0.w1.b0", !5332, i64 0}
!5332 = !{!"0x1367d8e0.w2.b0", !5333, i64 0}
!5333 = !{!"0x1367d8e0.w4.b0", !5334, i64 0}
!5334 = !{!"0x1367d8e0.w8.b0", !5335, i64 0}
!5335 = !{!"0x1367d8e0.w16.b0", !5336, i64 0}
!5336 = !{!"0x1367d8e0.w32.b0", !5337, i64 0}
!5337 = !{!"0x1367d8e0.w64.b0", !5338, i64 0}
!5338 = !{!"0x1367d8e0.w128.b0", !5339, i64 0}
!5339 = !{!"0x1367d8e0.w256.b0", !5340, i64 0}
!5340 = !{!"0x1367d8e0.w512.b0", !5341, i64 0}
!5341 = !{!"0x1367d8e0.w1024.b0", !5342, i64 0}
!5342 = !{!"int32", !5343, i64 0}
!5343 = !{!"0x1367d8e0", !8, i64 0}
!5344 = !{!5345, !5345, i64 0}
!5345 = !{!"0x1367d8e0.w1.b1", !5332, i64 0}
!5346 = !{!5347, !5347, i64 0}
!5347 = !{!"0x1f2abde0.w1.b0", !5348, i64 0}
!5348 = !{!"0x1f2abde0.w2.b0", !5349, i64 0}
!5349 = !{!"0x1f2abde0.w4.b0", !5350, i64 0}
!5350 = !{!"0x1f2abde0.w8.b0", !5351, i64 0}
!5351 = !{!"0x1f2abde0.w16.b0", !5352, i64 0}
!5352 = !{!"0x1f2abde0.w32.b0", !5353, i64 0}
!5353 = !{!"0x1f2abde0.w64.b0", !5354, i64 0}
!5354 = !{!"0x1f2abde0.w128.b0", !5355, i64 0}
!5355 = !{!"0x1f2abde0.w256.b0", !5356, i64 0}
!5356 = !{!"0x1f2abde0.w512.b0", !5357, i64 0}
!5357 = !{!"0x1f2abde0.w1024.b0", !5358, i64 0}
!5358 = !{!"int64", !5359, i64 0}
!5359 = !{!"0x1f2abde0", !8, i64 0}
!5360 = !{!5361, !5361, i64 0}
!5361 = !{!"0x1f2abde0.w1.b1", !5348, i64 0}
!5362 = !{!5363, !5363, i64 0}
!5363 = !{!"0x1f2abde0.w1.b2", !5364, i64 0}
!5364 = !{!"0x1f2abde0.w2.b2", !5349, i64 0}
!5365 = !{!5366, !5366, i64 0}
!5366 = !{!"0x1f2abde0.w1.b3", !5364, i64 0}
!5367 = !{!5368, !5368, i64 0}
!5368 = !{!"0x1f2abde0.w1.b4", !5369, i64 0}
!5369 = !{!"0x1f2abde0.w2.b4", !5370, i64 0}
!5370 = !{!"0x1f2abde0.w4.b4", !5350, i64 0}
!5371 = !{!5372, !5372, i64 0}
!5372 = !{!"0x139a7d20.w4.b0", !5373, i64 0}
!5373 = !{!"0x139a7d20.w8.b0", !5374, i64 0}
!5374 = !{!"0x139a7d20.w16.b0", !5375, i64 0}
!5375 = !{!"0x139a7d20.w32.b0", !5376, i64 0}
!5376 = !{!"0x139a7d20.w64.b0", !5377, i64 0}
!5377 = !{!"0x139a7d20.w128.b0", !5378, i64 0}
!5378 = !{!"0x139a7d20.w256.b0", !5379, i64 0}
!5379 = !{!"0x139a7d20.w512.b0", !5380, i64 0}
!5380 = !{!"0x139a7d20.w1024.b0", !5381, i64 0}
!5381 = !{!"int64", !5382, i64 0}
!5382 = !{!"0x139a7d20", !8, i64 0}
!5383 = !{!5384, !5384, i64 0}
!5384 = !{!"0x139a7d20.w1.b4", !5385, i64 0}
!5385 = !{!"0x139a7d20.w2.b4", !5386, i64 0}
!5386 = !{!"0x139a7d20.w4.b4", !5373, i64 0}
!5387 = !{!5388, !5388, i64 0}
!5388 = !{!"0x139e5f70.w1.b0", !5389, i64 0}
!5389 = !{!"0x139e5f70.w2.b0", !5390, i64 0}
!5390 = !{!"0x139e5f70.w4.b0", !5391, i64 0}
!5391 = !{!"0x139e5f70.w8.b0", !5392, i64 0}
!5392 = !{!"0x139e5f70.w16.b0", !5393, i64 0}
!5393 = !{!"0x139e5f70.w32.b0", !5394, i64 0}
!5394 = !{!"0x139e5f70.w64.b0", !5395, i64 0}
!5395 = !{!"0x139e5f70.w128.b0", !5396, i64 0}
!5396 = !{!"0x139e5f70.w256.b0", !5397, i64 0}
!5397 = !{!"0x139e5f70.w512.b0", !5398, i64 0}
!5398 = !{!"0x139e5f70.w1024.b0", !5399, i64 0}
!5399 = !{!"int64", !5400, i64 0}
!5400 = !{!"0x139e5f70", !8, i64 0}
!5401 = !{!5402, !5402, i64 0}
!5402 = !{!"0x139e5f70.w1.b1", !5389, i64 0}
!5403 = !{!5404, !5404, i64 0}
!5404 = !{!"0x139e5f70.w1.b2", !5405, i64 0}
!5405 = !{!"0x139e5f70.w2.b2", !5390, i64 0}
!5406 = !{!5407, !5407, i64 0}
!5407 = !{!"0x139e5f70.w1.b3", !5405, i64 0}
!5408 = !{!5409, !5409, i64 0}
!5409 = !{!"0x139e5f70.w1.b4", !5410, i64 0}
!5410 = !{!"0x139e5f70.w2.b4", !5411, i64 0}
!5411 = !{!"0x139e5f70.w4.b4", !5391, i64 0}
!5412 = !{!5413, !5413, i64 0}
!5413 = !{!"0xa8ab710.w4.b0", !5414, i64 0}
!5414 = !{!"0xa8ab710.w8.b0", !5415, i64 0}
!5415 = !{!"0xa8ab710.w16.b0", !5416, i64 0}
!5416 = !{!"0xa8ab710.w32.b0", !5417, i64 0}
!5417 = !{!"0xa8ab710.w64.b0", !5418, i64 0}
!5418 = !{!"0xa8ab710.w128.b0", !5419, i64 0}
!5419 = !{!"0xa8ab710.w256.b0", !5420, i64 0}
!5420 = !{!"0xa8ab710.w512.b0", !5421, i64 0}
!5421 = !{!"0xa8ab710.w1024.b0", !5422, i64 0}
!5422 = !{!"int64", !5423, i64 0}
!5423 = !{!"0xa8ab710", !8, i64 0}
!5424 = !{!5425, !5425, i64 0}
!5425 = !{!"0xa8ab710.w1.b4", !5426, i64 0}
!5426 = !{!"0xa8ab710.w2.b4", !5427, i64 0}
!5427 = !{!"0xa8ab710.w4.b4", !5414, i64 0}
!5428 = !{!5429, !5429, i64 0}
!5429 = !{!"float32", !5430, i64 0}
!5430 = !{!"0x1b785f50", !8, i64 0}
!5431 = !{!5432, !5432, i64 0}
!5432 = !{!"float32", !5433, i64 0}
!5433 = !{!"0x1b785f00", !8, i64 0}
!5434 = !{!5435, !5435, i64 0}
!5435 = !{!"0x1f2f09a0.w1.b0", !5436, i64 0}
!5436 = !{!"0x1f2f09a0.w2.b0", !5437, i64 0}
!5437 = !{!"0x1f2f09a0.w4.b0", !5438, i64 0}
!5438 = !{!"0x1f2f09a0.w8.b0", !5439, i64 0}
!5439 = !{!"0x1f2f09a0.w16.b0", !5440, i64 0}
!5440 = !{!"0x1f2f09a0.w32.b0", !5441, i64 0}
!5441 = !{!"0x1f2f09a0.w64.b0", !5442, i64 0}
!5442 = !{!"0x1f2f09a0.w128.b0", !5443, i64 0}
!5443 = !{!"0x1f2f09a0.w256.b0", !5444, i64 0}
!5444 = !{!"0x1f2f09a0.w512.b0", !5445, i64 0}
!5445 = !{!"0x1f2f09a0.w1024.b0", !5446, i64 0}
!5446 = !{!"int32", !5447, i64 0}
!5447 = !{!"0x1f2f09a0", !8, i64 0}
!5448 = !{!5449, !5449, i64 0}
!5449 = !{!"0x1f2f09a0.w1.b2", !5450, i64 0}
!5450 = !{!"0x1f2f09a0.w2.b2", !5437, i64 0}
!5451 = !{!5452, !5452, i64 0}
!5452 = !{!"0x1f2f09a0.w1.b3", !5450, i64 0}
!5453 = !{!5454, !5454, i64 0}
!5454 = !{!"0x1f2f09a0.w1.b4", !5455, i64 0}
!5455 = !{!"0x1f2f09a0.w2.b4", !5456, i64 0}
!5456 = !{!"0x1f2f09a0.w4.b4", !5438, i64 0}
!5457 = !{!5458, !5458, i64 0}
!5458 = !{!"0x1f2f09a0.w1.b1", !5436, i64 0}
!5459 = !{!5460, !5460, i64 0}
!5460 = !{!"0x1f35b000.w1.b0", !5461, i64 0}
!5461 = !{!"0x1f35b000.w2.b0", !5462, i64 0}
!5462 = !{!"0x1f35b000.w4.b0", !5463, i64 0}
!5463 = !{!"0x1f35b000.w8.b0", !5464, i64 0}
!5464 = !{!"0x1f35b000.w16.b0", !5465, i64 0}
!5465 = !{!"0x1f35b000.w32.b0", !5466, i64 0}
!5466 = !{!"0x1f35b000.w64.b0", !5467, i64 0}
!5467 = !{!"0x1f35b000.w128.b0", !5468, i64 0}
!5468 = !{!"0x1f35b000.w256.b0", !5469, i64 0}
!5469 = !{!"0x1f35b000.w512.b0", !5470, i64 0}
!5470 = !{!"0x1f35b000.w1024.b0", !5471, i64 0}
!5471 = !{!"int64", !5472, i64 0}
!5472 = !{!"0x1f35b000", !8, i64 0}
!5473 = !{!5474, !5474, i64 0}
!5474 = !{!"0x1f35b000.w1.b1", !5461, i64 0}
!5475 = !{!5476, !5476, i64 0}
!5476 = !{!"0x1f35b000.w1.b2", !5477, i64 0}
!5477 = !{!"0x1f35b000.w2.b2", !5462, i64 0}
!5478 = !{!5479, !5479, i64 0}
!5479 = !{!"0x1f35b000.w1.b3", !5477, i64 0}
!5480 = !{!5481, !5481, i64 0}
!5481 = !{!"0x1f35b000.w1.b4", !5482, i64 0}
!5482 = !{!"0x1f35b000.w2.b4", !5483, i64 0}
!5483 = !{!"0x1f35b000.w4.b4", !5463, i64 0}
!5484 = !{!5485, !5485, i64 0}
!5485 = !{!"0x1f35b0b0.w4.b0", !5486, i64 0}
!5486 = !{!"0x1f35b0b0.w8.b0", !5487, i64 0}
!5487 = !{!"0x1f35b0b0.w16.b0", !5488, i64 0}
!5488 = !{!"0x1f35b0b0.w32.b0", !5489, i64 0}
!5489 = !{!"0x1f35b0b0.w64.b0", !5490, i64 0}
!5490 = !{!"0x1f35b0b0.w128.b0", !5491, i64 0}
!5491 = !{!"0x1f35b0b0.w256.b0", !5492, i64 0}
!5492 = !{!"0x1f35b0b0.w512.b0", !5493, i64 0}
!5493 = !{!"0x1f35b0b0.w1024.b0", !5494, i64 0}
!5494 = !{!"int64", !5495, i64 0}
!5495 = !{!"0x1f35b0b0", !8, i64 0}
!5496 = !{!5497, !5497, i64 0}
!5497 = !{!"0x1f35b0b0.w1.b4", !5498, i64 0}
!5498 = !{!"0x1f35b0b0.w2.b4", !5499, i64 0}
!5499 = !{!"0x1f35b0b0.w4.b4", !5486, i64 0}
!5500 = !{!5501, !5501, i64 0}
!5501 = !{!"0x1f2cc850.w1.b0", !5502, i64 0}
!5502 = !{!"0x1f2cc850.w2.b0", !5503, i64 0}
!5503 = !{!"0x1f2cc850.w4.b0", !5504, i64 0}
!5504 = !{!"0x1f2cc850.w8.b0", !5505, i64 0}
!5505 = !{!"0x1f2cc850.w16.b0", !5506, i64 0}
!5506 = !{!"0x1f2cc850.w32.b0", !5507, i64 0}
!5507 = !{!"0x1f2cc850.w64.b0", !5508, i64 0}
!5508 = !{!"0x1f2cc850.w128.b0", !5509, i64 0}
!5509 = !{!"0x1f2cc850.w256.b0", !5510, i64 0}
!5510 = !{!"0x1f2cc850.w512.b0", !5511, i64 0}
!5511 = !{!"0x1f2cc850.w1024.b0", !5512, i64 0}
!5512 = !{!"int64", !5513, i64 0}
!5513 = !{!"0x1f2cc850", !8, i64 0}
!5514 = !{!5515, !5515, i64 0}
!5515 = !{!"0x1f2cc850.w1.b1", !5502, i64 0}
!5516 = !{!5517, !5517, i64 0}
!5517 = !{!"0x1f2cc850.w1.b2", !5518, i64 0}
!5518 = !{!"0x1f2cc850.w2.b2", !5503, i64 0}
!5519 = !{!5520, !5520, i64 0}
!5520 = !{!"0x1f2cc850.w1.b3", !5518, i64 0}
!5521 = !{!5522, !5522, i64 0}
!5522 = !{!"0x1f2cc850.w1.b4", !5523, i64 0}
!5523 = !{!"0x1f2cc850.w2.b4", !5524, i64 0}
!5524 = !{!"0x1f2cc850.w4.b4", !5504, i64 0}
!5525 = !{!5526, !5526, i64 0}
!5526 = !{!"0x1f2cc850.w1.b5", !5523, i64 0}
!5527 = !{!5528, !5528, i64 0}
!5528 = !{!"0x1f35a310.w4.b0", !5529, i64 0}
!5529 = !{!"0x1f35a310.w8.b0", !5530, i64 0}
!5530 = !{!"0x1f35a310.w16.b0", !5531, i64 0}
!5531 = !{!"0x1f35a310.w32.b0", !5532, i64 0}
!5532 = !{!"0x1f35a310.w64.b0", !5533, i64 0}
!5533 = !{!"0x1f35a310.w128.b0", !5534, i64 0}
!5534 = !{!"0x1f35a310.w256.b0", !5535, i64 0}
!5535 = !{!"0x1f35a310.w512.b0", !5536, i64 0}
!5536 = !{!"0x1f35a310.w1024.b0", !5537, i64 0}
!5537 = !{!"int64", !5538, i64 0}
!5538 = !{!"0x1f35a310", !8, i64 0}
!5539 = !{!5540, !5540, i64 0}
!5540 = !{!"0x1f35a310.w1.b4", !5541, i64 0}
!5541 = !{!"0x1f35a310.w2.b4", !5542, i64 0}
!5542 = !{!"0x1f35a310.w4.b4", !5529, i64 0}
!5543 = !{!5544, !5544, i64 0}
!5544 = !{!"0x1f35a310.w1.b5", !5541, i64 0}
!5545 = !{!5546, !5546, i64 0}
!5546 = !{!"0x1f30e8b0.w1.b0", !5547, i64 0}
!5547 = !{!"0x1f30e8b0.w2.b0", !5548, i64 0}
!5548 = !{!"0x1f30e8b0.w4.b0", !5549, i64 0}
!5549 = !{!"0x1f30e8b0.w8.b0", !5550, i64 0}
!5550 = !{!"0x1f30e8b0.w16.b0", !5551, i64 0}
!5551 = !{!"0x1f30e8b0.w32.b0", !5552, i64 0}
!5552 = !{!"0x1f30e8b0.w64.b0", !5553, i64 0}
!5553 = !{!"0x1f30e8b0.w128.b0", !5554, i64 0}
!5554 = !{!"0x1f30e8b0.w256.b0", !5555, i64 0}
!5555 = !{!"0x1f30e8b0.w512.b0", !5556, i64 0}
!5556 = !{!"0x1f30e8b0.w1024.b0", !5557, i64 0}
!5557 = !{!"int64", !5558, i64 0}
!5558 = !{!"0x1f30e8b0", !8, i64 0}
!5559 = !{!5560, !5560, i64 0}
!5560 = !{!"0x1f30e8b0.w1.b1", !5547, i64 0}
!5561 = !{!5562, !5562, i64 0}
!5562 = !{!"0x1f30e8b0.w1.b2", !5563, i64 0}
!5563 = !{!"0x1f30e8b0.w2.b2", !5548, i64 0}
!5564 = !{!5565, !5565, i64 0}
!5565 = !{!"0x1f30e8b0.w1.b3", !5563, i64 0}
!5566 = !{!5567, !5567, i64 0}
!5567 = !{!"0x1f30f270.w4.b0", !5568, i64 0}
!5568 = !{!"0x1f30f270.w8.b0", !5569, i64 0}
!5569 = !{!"0x1f30f270.w16.b0", !5570, i64 0}
!5570 = !{!"0x1f30f270.w32.b0", !5571, i64 0}
!5571 = !{!"0x1f30f270.w64.b0", !5572, i64 0}
!5572 = !{!"0x1f30f270.w128.b0", !5573, i64 0}
!5573 = !{!"0x1f30f270.w256.b0", !5574, i64 0}
!5574 = !{!"0x1f30f270.w512.b0", !5575, i64 0}
!5575 = !{!"0x1f30f270.w1024.b0", !5576, i64 0}
!5576 = !{!"int64", !5577, i64 0}
!5577 = !{!"0x1f30f270", !8, i64 0}
!5578 = !{!5579, !5579, i64 0}
!5579 = !{!"0x1f35b420.w1.b0", !5580, i64 0}
!5580 = !{!"0x1f35b420.w2.b0", !5581, i64 0}
!5581 = !{!"0x1f35b420.w4.b0", !5582, i64 0}
!5582 = !{!"0x1f35b420.w8.b0", !5583, i64 0}
!5583 = !{!"0x1f35b420.w16.b0", !5584, i64 0}
!5584 = !{!"0x1f35b420.w32.b0", !5585, i64 0}
!5585 = !{!"0x1f35b420.w64.b0", !5586, i64 0}
!5586 = !{!"0x1f35b420.w128.b0", !5587, i64 0}
!5587 = !{!"0x1f35b420.w256.b0", !5588, i64 0}
!5588 = !{!"0x1f35b420.w512.b0", !5589, i64 0}
!5589 = !{!"0x1f35b420.w1024.b0", !5590, i64 0}
!5590 = !{!"int64", !5591, i64 0}
!5591 = !{!"0x1f35b420", !8, i64 0}
!5592 = !{!5593, !5593, i64 0}
!5593 = !{!"0x1f35b420.w1.b1", !5580, i64 0}
!5594 = !{!5595, !5595, i64 0}
!5595 = !{!"0x1f35b420.w1.b2", !5596, i64 0}
!5596 = !{!"0x1f35b420.w2.b2", !5581, i64 0}
!5597 = !{!5598, !5598, i64 0}
!5598 = !{!"0x1f35b420.w1.b3", !5596, i64 0}
!5599 = !{!5600, !5600, i64 0}
!5600 = !{!"0x1f2b7480.w4.b0", !5601, i64 0}
!5601 = !{!"0x1f2b7480.w8.b0", !5602, i64 0}
!5602 = !{!"0x1f2b7480.w16.b0", !5603, i64 0}
!5603 = !{!"0x1f2b7480.w32.b0", !5604, i64 0}
!5604 = !{!"0x1f2b7480.w64.b0", !5605, i64 0}
!5605 = !{!"0x1f2b7480.w128.b0", !5606, i64 0}
!5606 = !{!"0x1f2b7480.w256.b0", !5607, i64 0}
!5607 = !{!"0x1f2b7480.w512.b0", !5608, i64 0}
!5608 = !{!"0x1f2b7480.w1024.b0", !5609, i64 0}
!5609 = !{!"int64", !5610, i64 0}
!5610 = !{!"0x1f2b7480", !8, i64 0}
!5611 = !{!5612, !5612, i64 0}
!5612 = !{!"0x1f2b96d0.w1.b0", !5613, i64 0}
!5613 = !{!"0x1f2b96d0.w2.b0", !5614, i64 0}
!5614 = !{!"0x1f2b96d0.w4.b0", !5615, i64 0}
!5615 = !{!"0x1f2b96d0.w8.b0", !5616, i64 0}
!5616 = !{!"0x1f2b96d0.w16.b0", !5617, i64 0}
!5617 = !{!"0x1f2b96d0.w32.b0", !5618, i64 0}
!5618 = !{!"0x1f2b96d0.w64.b0", !5619, i64 0}
!5619 = !{!"0x1f2b96d0.w128.b0", !5620, i64 0}
!5620 = !{!"0x1f2b96d0.w256.b0", !5621, i64 0}
!5621 = !{!"0x1f2b96d0.w512.b0", !5622, i64 0}
!5622 = !{!"0x1f2b96d0.w1024.b0", !5623, i64 0}
!5623 = !{!"int64", !5624, i64 0}
!5624 = !{!"0x1f2b96d0", !8, i64 0}
!5625 = !{!5626, !5626, i64 0}
!5626 = !{!"0x1f2b96d0.w1.b1", !5613, i64 0}
!5627 = !{!5628, !5628, i64 0}
!5628 = !{!"0x1f2b96d0.w1.b2", !5629, i64 0}
!5629 = !{!"0x1f2b96d0.w2.b2", !5614, i64 0}
!5630 = !{!5631, !5631, i64 0}
!5631 = !{!"0x1f2b96d0.w1.b3", !5629, i64 0}
!5632 = !{!5633, !5633, i64 0}
!5633 = !{!"0x1f2b96d0.w1.b4", !5634, i64 0}
!5634 = !{!"0x1f2b96d0.w2.b4", !5635, i64 0}
!5635 = !{!"0x1f2b96d0.w4.b4", !5615, i64 0}
!5636 = !{!5637, !5637, i64 0}
!5637 = !{!"0x1f2ba2d0.w4.b0", !5638, i64 0}
!5638 = !{!"0x1f2ba2d0.w8.b0", !5639, i64 0}
!5639 = !{!"0x1f2ba2d0.w16.b0", !5640, i64 0}
!5640 = !{!"0x1f2ba2d0.w32.b0", !5641, i64 0}
!5641 = !{!"0x1f2ba2d0.w64.b0", !5642, i64 0}
!5642 = !{!"0x1f2ba2d0.w128.b0", !5643, i64 0}
!5643 = !{!"0x1f2ba2d0.w256.b0", !5644, i64 0}
!5644 = !{!"0x1f2ba2d0.w512.b0", !5645, i64 0}
!5645 = !{!"0x1f2ba2d0.w1024.b0", !5646, i64 0}
!5646 = !{!"int64", !5647, i64 0}
!5647 = !{!"0x1f2ba2d0", !8, i64 0}
!5648 = !{!5649, !5649, i64 0}
!5649 = !{!"0x1f2ba2d0.w1.b4", !5650, i64 0}
!5650 = !{!"0x1f2ba2d0.w2.b4", !5651, i64 0}
!5651 = !{!"0x1f2ba2d0.w4.b4", !5638, i64 0}
!5652 = !{!5653, !5653, i64 0}
!5653 = !{!"float32", !5654, i64 0}
!5654 = !{!"0x1f285e80", !8, i64 0}
!5655 = !{!5656, !5656, i64 0}
!5656 = !{!"float32", !5657, i64 0}
!5657 = !{!"0x1f2ae9a0", !8, i64 0}
!5658 = !{!5659, !5659, i64 0}
!5659 = !{!"float32", !5660, i64 0}
!5660 = !{!"0x1f2cd0e0", !8, i64 0}
!5661 = !{!5662, !5662, i64 0}
!5662 = !{!"float32", !5663, i64 0}
!5663 = !{!"0x1f2ae950", !8, i64 0}
!5664 = !{!5665, !5665, i64 0}
!5665 = !{!"float32", !5666, i64 0}
!5666 = !{!"0x1f2af4d0", !8, i64 0}
!5667 = !{!5668, !5668, i64 0}
!5668 = !{!"float32", !5669, i64 0}
!5669 = !{!"0x1f2af6c0", !8, i64 0}
!5670 = !{!5671, !5671, i64 0}
!5671 = !{!"0x13d76100.w1.b0", !5672, i64 0}
!5672 = !{!"0x13d76100.w2.b0", !5673, i64 0}
!5673 = !{!"0x13d76100.w4.b0", !5674, i64 0}
!5674 = !{!"0x13d76100.w8.b0", !5675, i64 0}
!5675 = !{!"0x13d76100.w16.b0", !5676, i64 0}
!5676 = !{!"0x13d76100.w32.b0", !5677, i64 0}
!5677 = !{!"0x13d76100.w64.b0", !5678, i64 0}
!5678 = !{!"0x13d76100.w128.b0", !5679, i64 0}
!5679 = !{!"0x13d76100.w256.b0", !5680, i64 0}
!5680 = !{!"0x13d76100.w512.b0", !5681, i64 0}
!5681 = !{!"0x13d76100.w1024.b0", !5682, i64 0}
!5682 = !{!"int32", !5683, i64 0}
!5683 = !{!"0x13d76100", !8, i64 0}
!5684 = !{!5685, !5685, i64 0}
!5685 = !{!"0x13d76100.w1.b2", !5686, i64 0}
!5686 = !{!"0x13d76100.w2.b2", !5673, i64 0}
!5687 = !{!5688, !5688, i64 0}
!5688 = !{!"0x13d76100.w1.b3", !5686, i64 0}
!5689 = !{!5690, !5690, i64 0}
!5690 = !{!"0x13d76100.w1.b4", !5691, i64 0}
!5691 = !{!"0x13d76100.w2.b4", !5692, i64 0}
!5692 = !{!"0x13d76100.w4.b4", !5674, i64 0}
!5693 = !{!5694, !5694, i64 0}
!5694 = !{!"0x13d76100.w1.b1", !5672, i64 0}
!5695 = !{!5696, !5696, i64 0}
!5696 = !{!"0x1f2fed50.w1.b0", !5697, i64 0}
!5697 = !{!"0x1f2fed50.w2.b0", !5698, i64 0}
!5698 = !{!"0x1f2fed50.w4.b0", !5699, i64 0}
!5699 = !{!"0x1f2fed50.w8.b0", !5700, i64 0}
!5700 = !{!"0x1f2fed50.w16.b0", !5701, i64 0}
!5701 = !{!"0x1f2fed50.w32.b0", !5702, i64 0}
!5702 = !{!"0x1f2fed50.w64.b0", !5703, i64 0}
!5703 = !{!"0x1f2fed50.w128.b0", !5704, i64 0}
!5704 = !{!"0x1f2fed50.w256.b0", !5705, i64 0}
!5705 = !{!"0x1f2fed50.w512.b0", !5706, i64 0}
!5706 = !{!"0x1f2fed50.w1024.b0", !5707, i64 0}
!5707 = !{!"int64", !5708, i64 0}
!5708 = !{!"0x1f2fed50", !8, i64 0}
!5709 = !{!5710, !5710, i64 0}
!5710 = !{!"0x1f2fed50.w1.b1", !5697, i64 0}
!5711 = !{!5712, !5712, i64 0}
!5712 = !{!"0x1f2fed50.w1.b2", !5713, i64 0}
!5713 = !{!"0x1f2fed50.w2.b2", !5698, i64 0}
!5714 = !{!5715, !5715, i64 0}
!5715 = !{!"0x1f2fed50.w1.b3", !5713, i64 0}
!5716 = !{!5717, !5717, i64 0}
!5717 = !{!"0x1f2fed50.w1.b4", !5718, i64 0}
!5718 = !{!"0x1f2fed50.w2.b4", !5719, i64 0}
!5719 = !{!"0x1f2fed50.w4.b4", !5699, i64 0}
!5720 = !{!5721, !5721, i64 0}
!5721 = !{!"0x1d0c1f10.w4.b0", !5722, i64 0}
!5722 = !{!"0x1d0c1f10.w8.b0", !5723, i64 0}
!5723 = !{!"0x1d0c1f10.w16.b0", !5724, i64 0}
!5724 = !{!"0x1d0c1f10.w32.b0", !5725, i64 0}
!5725 = !{!"0x1d0c1f10.w64.b0", !5726, i64 0}
!5726 = !{!"0x1d0c1f10.w128.b0", !5727, i64 0}
!5727 = !{!"0x1d0c1f10.w256.b0", !5728, i64 0}
!5728 = !{!"0x1d0c1f10.w512.b0", !5729, i64 0}
!5729 = !{!"0x1d0c1f10.w1024.b0", !5730, i64 0}
!5730 = !{!"int64", !5731, i64 0}
!5731 = !{!"0x1d0c1f10", !8, i64 0}
!5732 = !{!5733, !5733, i64 0}
!5733 = !{!"0x1d0c1f10.w1.b4", !5734, i64 0}
!5734 = !{!"0x1d0c1f10.w2.b4", !5735, i64 0}
!5735 = !{!"0x1d0c1f10.w4.b4", !5722, i64 0}
!5736 = !{!5737, !5737, i64 0}
!5737 = !{!"0x1d0c1ec0.w1.b0", !5738, i64 0}
!5738 = !{!"0x1d0c1ec0.w2.b0", !5739, i64 0}
!5739 = !{!"0x1d0c1ec0.w4.b0", !5740, i64 0}
!5740 = !{!"0x1d0c1ec0.w8.b0", !5741, i64 0}
!5741 = !{!"0x1d0c1ec0.w16.b0", !5742, i64 0}
!5742 = !{!"0x1d0c1ec0.w32.b0", !5743, i64 0}
!5743 = !{!"0x1d0c1ec0.w64.b0", !5744, i64 0}
!5744 = !{!"0x1d0c1ec0.w128.b0", !5745, i64 0}
!5745 = !{!"0x1d0c1ec0.w256.b0", !5746, i64 0}
!5746 = !{!"0x1d0c1ec0.w512.b0", !5747, i64 0}
!5747 = !{!"0x1d0c1ec0.w1024.b0", !5748, i64 0}
!5748 = !{!"int64", !5749, i64 0}
!5749 = !{!"0x1d0c1ec0", !8, i64 0}
!5750 = !{!5751, !5751, i64 0}
!5751 = !{!"0x1d0c1ec0.w1.b1", !5738, i64 0}
!5752 = !{!5753, !5753, i64 0}
!5753 = !{!"0x1d0c1ec0.w1.b2", !5754, i64 0}
!5754 = !{!"0x1d0c1ec0.w2.b2", !5739, i64 0}
!5755 = !{!5756, !5756, i64 0}
!5756 = !{!"0x1d0c1ec0.w1.b3", !5754, i64 0}
!5757 = !{!5758, !5758, i64 0}
!5758 = !{!"0x1d0c1ec0.w1.b4", !5759, i64 0}
!5759 = !{!"0x1d0c1ec0.w2.b4", !5760, i64 0}
!5760 = !{!"0x1d0c1ec0.w4.b4", !5740, i64 0}
!5761 = !{!5762, !5762, i64 0}
!5762 = !{!"0x1d0c1ec0.w1.b5", !5759, i64 0}
!5763 = !{!5764, !5764, i64 0}
!5764 = !{!"0xf7fff10.w4.b0", !5765, i64 0}
!5765 = !{!"0xf7fff10.w8.b0", !5766, i64 0}
!5766 = !{!"0xf7fff10.w16.b0", !5767, i64 0}
!5767 = !{!"0xf7fff10.w32.b0", !5768, i64 0}
!5768 = !{!"0xf7fff10.w64.b0", !5769, i64 0}
!5769 = !{!"0xf7fff10.w128.b0", !5770, i64 0}
!5770 = !{!"0xf7fff10.w256.b0", !5771, i64 0}
!5771 = !{!"0xf7fff10.w512.b0", !5772, i64 0}
!5772 = !{!"0xf7fff10.w1024.b0", !5773, i64 0}
!5773 = !{!"int64", !5774, i64 0}
!5774 = !{!"0xf7fff10", !8, i64 0}
!5775 = !{!5776, !5776, i64 0}
!5776 = !{!"0xf7fff10.w1.b4", !5777, i64 0}
!5777 = !{!"0xf7fff10.w2.b4", !5778, i64 0}
!5778 = !{!"0xf7fff10.w4.b4", !5765, i64 0}
!5779 = !{!5780, !5780, i64 0}
!5780 = !{!"0xf7fff10.w1.b5", !5777, i64 0}
!5781 = !{!5782, !5782, i64 0}
!5782 = !{!"0x1d0c1e00.w1.b0", !5783, i64 0}
!5783 = !{!"0x1d0c1e00.w2.b0", !5784, i64 0}
!5784 = !{!"0x1d0c1e00.w4.b0", !5785, i64 0}
!5785 = !{!"0x1d0c1e00.w8.b0", !5786, i64 0}
!5786 = !{!"0x1d0c1e00.w16.b0", !5787, i64 0}
!5787 = !{!"0x1d0c1e00.w32.b0", !5788, i64 0}
!5788 = !{!"0x1d0c1e00.w64.b0", !5789, i64 0}
!5789 = !{!"0x1d0c1e00.w128.b0", !5790, i64 0}
!5790 = !{!"0x1d0c1e00.w256.b0", !5791, i64 0}
!5791 = !{!"0x1d0c1e00.w512.b0", !5792, i64 0}
!5792 = !{!"0x1d0c1e00.w1024.b0", !5793, i64 0}
!5793 = !{!"int64", !5794, i64 0}
!5794 = !{!"0x1d0c1e00", !8, i64 0}
!5795 = !{!5796, !5796, i64 0}
!5796 = !{!"0x1d0c1e00.w1.b1", !5783, i64 0}
!5797 = !{!5798, !5798, i64 0}
!5798 = !{!"0x1d0c1e00.w1.b2", !5799, i64 0}
!5799 = !{!"0x1d0c1e00.w2.b2", !5784, i64 0}
!5800 = !{!5801, !5801, i64 0}
!5801 = !{!"0x1d0c1e00.w1.b3", !5799, i64 0}
!5802 = !{!5803, !5803, i64 0}
!5803 = !{!"0xbd30880.w4.b0", !5804, i64 0}
!5804 = !{!"0xbd30880.w8.b0", !5805, i64 0}
!5805 = !{!"0xbd30880.w16.b0", !5806, i64 0}
!5806 = !{!"0xbd30880.w32.b0", !5807, i64 0}
!5807 = !{!"0xbd30880.w64.b0", !5808, i64 0}
!5808 = !{!"0xbd30880.w128.b0", !5809, i64 0}
!5809 = !{!"0xbd30880.w256.b0", !5810, i64 0}
!5810 = !{!"0xbd30880.w512.b0", !5811, i64 0}
!5811 = !{!"0xbd30880.w1024.b0", !5812, i64 0}
!5812 = !{!"int64", !5813, i64 0}
!5813 = !{!"0xbd30880", !8, i64 0}
!5814 = !{!5815, !5815, i64 0}
!5815 = !{!"0xf7f11f0.w1.b0", !5816, i64 0}
!5816 = !{!"0xf7f11f0.w2.b0", !5817, i64 0}
!5817 = !{!"0xf7f11f0.w4.b0", !5818, i64 0}
!5818 = !{!"0xf7f11f0.w8.b0", !5819, i64 0}
!5819 = !{!"0xf7f11f0.w16.b0", !5820, i64 0}
!5820 = !{!"0xf7f11f0.w32.b0", !5821, i64 0}
!5821 = !{!"0xf7f11f0.w64.b0", !5822, i64 0}
!5822 = !{!"0xf7f11f0.w128.b0", !5823, i64 0}
!5823 = !{!"0xf7f11f0.w256.b0", !5824, i64 0}
!5824 = !{!"0xf7f11f0.w512.b0", !5825, i64 0}
!5825 = !{!"0xf7f11f0.w1024.b0", !5826, i64 0}
!5826 = !{!"int64", !5827, i64 0}
!5827 = !{!"0xf7f11f0", !8, i64 0}
!5828 = !{!5829, !5829, i64 0}
!5829 = !{!"0xf7f11f0.w1.b1", !5816, i64 0}
!5830 = !{!5831, !5831, i64 0}
!5831 = !{!"0xf7f11f0.w1.b2", !5832, i64 0}
!5832 = !{!"0xf7f11f0.w2.b2", !5817, i64 0}
!5833 = !{!5834, !5834, i64 0}
!5834 = !{!"0xf7f11f0.w1.b3", !5832, i64 0}
!5835 = !{!5836, !5836, i64 0}
!5836 = !{!"0xf7f2190.w4.b0", !5837, i64 0}
!5837 = !{!"0xf7f2190.w8.b0", !5838, i64 0}
!5838 = !{!"0xf7f2190.w16.b0", !5839, i64 0}
!5839 = !{!"0xf7f2190.w32.b0", !5840, i64 0}
!5840 = !{!"0xf7f2190.w64.b0", !5841, i64 0}
!5841 = !{!"0xf7f2190.w128.b0", !5842, i64 0}
!5842 = !{!"0xf7f2190.w256.b0", !5843, i64 0}
!5843 = !{!"0xf7f2190.w512.b0", !5844, i64 0}
!5844 = !{!"0xf7f2190.w1024.b0", !5845, i64 0}
!5845 = !{!"int64", !5846, i64 0}
!5846 = !{!"0xf7f2190", !8, i64 0}
!5847 = !{!5848, !5848, i64 0}
!5848 = !{!"0xf7f2d30.w1.b0", !5849, i64 0}
!5849 = !{!"0xf7f2d30.w2.b0", !5850, i64 0}
!5850 = !{!"0xf7f2d30.w4.b0", !5851, i64 0}
!5851 = !{!"0xf7f2d30.w8.b0", !5852, i64 0}
!5852 = !{!"0xf7f2d30.w16.b0", !5853, i64 0}
!5853 = !{!"0xf7f2d30.w32.b0", !5854, i64 0}
!5854 = !{!"0xf7f2d30.w64.b0", !5855, i64 0}
!5855 = !{!"0xf7f2d30.w128.b0", !5856, i64 0}
!5856 = !{!"0xf7f2d30.w256.b0", !5857, i64 0}
!5857 = !{!"0xf7f2d30.w512.b0", !5858, i64 0}
!5858 = !{!"0xf7f2d30.w1024.b0", !5859, i64 0}
!5859 = !{!"int64", !5860, i64 0}
!5860 = !{!"0xf7f2d30", !8, i64 0}
!5861 = !{!5862, !5862, i64 0}
!5862 = !{!"0xf7f2d30.w1.b1", !5849, i64 0}
!5863 = !{!5864, !5864, i64 0}
!5864 = !{!"0xf7f2d30.w1.b2", !5865, i64 0}
!5865 = !{!"0xf7f2d30.w2.b2", !5850, i64 0}
!5866 = !{!5867, !5867, i64 0}
!5867 = !{!"0xf7f2d30.w1.b3", !5865, i64 0}
!5868 = !{!5869, !5869, i64 0}
!5869 = !{!"0xf7f2d30.w1.b4", !5870, i64 0}
!5870 = !{!"0xf7f2d30.w2.b4", !5871, i64 0}
!5871 = !{!"0xf7f2d30.w4.b4", !5851, i64 0}
!5872 = !{!5873, !5873, i64 0}
!5873 = !{!"0xf7f3ec0.w4.b0", !5874, i64 0}
!5874 = !{!"0xf7f3ec0.w8.b0", !5875, i64 0}
!5875 = !{!"0xf7f3ec0.w16.b0", !5876, i64 0}
!5876 = !{!"0xf7f3ec0.w32.b0", !5877, i64 0}
!5877 = !{!"0xf7f3ec0.w64.b0", !5878, i64 0}
!5878 = !{!"0xf7f3ec0.w128.b0", !5879, i64 0}
!5879 = !{!"0xf7f3ec0.w256.b0", !5880, i64 0}
!5880 = !{!"0xf7f3ec0.w512.b0", !5881, i64 0}
!5881 = !{!"0xf7f3ec0.w1024.b0", !5882, i64 0}
!5882 = !{!"int64", !5883, i64 0}
!5883 = !{!"0xf7f3ec0", !8, i64 0}
!5884 = !{!5885, !5885, i64 0}
!5885 = !{!"0xf7f3ec0.w1.b4", !5886, i64 0}
!5886 = !{!"0xf7f3ec0.w2.b4", !5887, i64 0}
!5887 = !{!"0xf7f3ec0.w4.b4", !5874, i64 0}
!5888 = !{!5889, !5889, i64 0}
!5889 = !{!"float32", !5890, i64 0}
!5890 = !{!"0x889c830", !8, i64 0}
!5891 = distinct !{!5891, !1123}
!5892 = distinct !{!5892, !1123}
!5893 = !{!5894, !5894, i64 0}
!5894 = !{!"float32", !5895, i64 0}
!5895 = !{!"0x13d754d0", !8, i64 0}
!5896 = distinct !{!5896, !1123}
!5897 = distinct !{!5897, !1123}
!5898 = distinct !{!5898, !1123}
!5899 = !{!5900, !5900, i64 0}
!5900 = !{!"float32", !5901, i64 0}
!5901 = !{!"0x116a7b40", !8, i64 0}
!5902 = !{!5903, !5903, i64 0}
!5903 = !{!"0xa8c6810.w16.b0", !5904, i64 0}
!5904 = !{!"0xa8c6810.w32.b0", !5905, i64 0}
!5905 = !{!"0xa8c6810.w64.b0", !5906, i64 0}
!5906 = !{!"0xa8c6810.w128.b0", !5907, i64 0}
!5907 = !{!"0xa8c6810.w256.b0", !5908, i64 0}
!5908 = !{!"0xa8c6810.w512.b0", !5909, i64 0}
!5909 = !{!"0xa8c6810.w1024.b0", !5910, i64 0}
!5910 = !{!"float32", !5911, i64 0}
!5911 = !{!"0xa8c6810", !8, i64 0}
!5912 = !{!5913, !5913, i64 0}
!5913 = !{!"float32", !5914, i64 0}
!5914 = !{!"0x1368c160", !8, i64 0}
!5915 = !{!5916, !5916, i64 0}
!5916 = !{!"float32", !5917, i64 0}
!5917 = !{!"0x8a82210", !8, i64 0}
!5918 = !{!5919, !5919, i64 0}
!5919 = !{!"float32", !5920, i64 0}
!5920 = !{!"0x13996f60", !8, i64 0}
!5921 = !{!5910, !5910, i64 0}
!5922 = !{!5923, !5923, i64 0}
!5923 = !{!"0xecd4bd0.w1.b0", !5924, i64 0}
!5924 = !{!"0xecd4bd0.w2.b0", !5925, i64 0}
!5925 = !{!"0xecd4bd0.w4.b0", !5926, i64 0}
!5926 = !{!"0xecd4bd0.w8.b0", !5927, i64 0}
!5927 = !{!"0xecd4bd0.w16.b0", !5928, i64 0}
!5928 = !{!"0xecd4bd0.w32.b0", !5929, i64 0}
!5929 = !{!"0xecd4bd0.w64.b0", !5930, i64 0}
!5930 = !{!"0xecd4bd0.w128.b0", !5931, i64 0}
!5931 = !{!"0xecd4bd0.w256.b0", !5932, i64 0}
!5932 = !{!"0xecd4bd0.w512.b0", !5933, i64 0}
!5933 = !{!"0xecd4bd0.w1024.b0", !5934, i64 0}
!5934 = !{!"int32", !5935, i64 0}
!5935 = !{!"0xecd4bd0", !8, i64 0}
!5936 = !{!5937, !5937, i64 0}
!5937 = !{!"0xecd4bd0.w1.b1", !5924, i64 0}
!5938 = !{!5939, !5939, i64 0}
!5939 = !{!"0x1b73cf60.w1.b0", !5940, i64 0}
!5940 = !{!"0x1b73cf60.w2.b0", !5941, i64 0}
!5941 = !{!"0x1b73cf60.w4.b0", !5942, i64 0}
!5942 = !{!"0x1b73cf60.w8.b0", !5943, i64 0}
!5943 = !{!"0x1b73cf60.w16.b0", !5944, i64 0}
!5944 = !{!"0x1b73cf60.w32.b0", !5945, i64 0}
!5945 = !{!"0x1b73cf60.w64.b0", !5946, i64 0}
!5946 = !{!"0x1b73cf60.w128.b0", !5947, i64 0}
!5947 = !{!"0x1b73cf60.w256.b0", !5948, i64 0}
!5948 = !{!"0x1b73cf60.w512.b0", !5949, i64 0}
!5949 = !{!"0x1b73cf60.w1024.b0", !5950, i64 0}
!5950 = !{!"int64", !5951, i64 0}
!5951 = !{!"0x1b73cf60", !8, i64 0}
!5952 = !{!5953, !5953, i64 0}
!5953 = !{!"0x1b73cf60.w1.b1", !5940, i64 0}
!5954 = !{!5955, !5955, i64 0}
!5955 = !{!"0x1b73cf60.w1.b2", !5956, i64 0}
!5956 = !{!"0x1b73cf60.w2.b2", !5941, i64 0}
!5957 = !{!5958, !5958, i64 0}
!5958 = !{!"0x1b73cf60.w1.b3", !5956, i64 0}
!5959 = !{!5960, !5960, i64 0}
!5960 = !{!"0x1b73cf60.w1.b4", !5961, i64 0}
!5961 = !{!"0x1b73cf60.w2.b4", !5962, i64 0}
!5962 = !{!"0x1b73cf60.w4.b4", !5942, i64 0}
!5963 = !{!5964, !5964, i64 0}
!5964 = !{!"0x13664740.w4.b0", !5965, i64 0}
!5965 = !{!"0x13664740.w8.b0", !5966, i64 0}
!5966 = !{!"0x13664740.w16.b0", !5967, i64 0}
!5967 = !{!"0x13664740.w32.b0", !5968, i64 0}
!5968 = !{!"0x13664740.w64.b0", !5969, i64 0}
!5969 = !{!"0x13664740.w128.b0", !5970, i64 0}
!5970 = !{!"0x13664740.w256.b0", !5971, i64 0}
!5971 = !{!"0x13664740.w512.b0", !5972, i64 0}
!5972 = !{!"0x13664740.w1024.b0", !5973, i64 0}
!5973 = !{!"int64", !5974, i64 0}
!5974 = !{!"0x13664740", !8, i64 0}
!5975 = !{!5976, !5976, i64 0}
!5976 = !{!"0x13664740.w1.b4", !5977, i64 0}
!5977 = !{!"0x13664740.w2.b4", !5978, i64 0}
!5978 = !{!"0x13664740.w4.b4", !5965, i64 0}
!5979 = !{!5980, !5980, i64 0}
!5980 = !{!"0x1f2e9390.w1.b0", !5981, i64 0}
!5981 = !{!"0x1f2e9390.w2.b0", !5982, i64 0}
!5982 = !{!"0x1f2e9390.w4.b0", !5983, i64 0}
!5983 = !{!"0x1f2e9390.w8.b0", !5984, i64 0}
!5984 = !{!"0x1f2e9390.w16.b0", !5985, i64 0}
!5985 = !{!"0x1f2e9390.w32.b0", !5986, i64 0}
!5986 = !{!"0x1f2e9390.w64.b0", !5987, i64 0}
!5987 = !{!"0x1f2e9390.w128.b0", !5988, i64 0}
!5988 = !{!"0x1f2e9390.w256.b0", !5989, i64 0}
!5989 = !{!"0x1f2e9390.w512.b0", !5990, i64 0}
!5990 = !{!"0x1f2e9390.w1024.b0", !5991, i64 0}
!5991 = !{!"int64", !5992, i64 0}
!5992 = !{!"0x1f2e9390", !8, i64 0}
!5993 = !{!5994, !5994, i64 0}
!5994 = !{!"0x1f2e9390.w1.b1", !5981, i64 0}
!5995 = !{!5996, !5996, i64 0}
!5996 = !{!"0x1f2e9390.w1.b2", !5997, i64 0}
!5997 = !{!"0x1f2e9390.w2.b2", !5982, i64 0}
!5998 = !{!5999, !5999, i64 0}
!5999 = !{!"0x1f2e9390.w1.b3", !5997, i64 0}
!6000 = !{!6001, !6001, i64 0}
!6001 = !{!"0x1f2e9390.w1.b4", !6002, i64 0}
!6002 = !{!"0x1f2e9390.w2.b4", !6003, i64 0}
!6003 = !{!"0x1f2e9390.w4.b4", !5983, i64 0}
!6004 = !{!6005, !6005, i64 0}
!6005 = !{!"0x86cb740.w4.b0", !6006, i64 0}
!6006 = !{!"0x86cb740.w8.b0", !6007, i64 0}
!6007 = !{!"0x86cb740.w16.b0", !6008, i64 0}
!6008 = !{!"0x86cb740.w32.b0", !6009, i64 0}
!6009 = !{!"0x86cb740.w64.b0", !6010, i64 0}
!6010 = !{!"0x86cb740.w128.b0", !6011, i64 0}
!6011 = !{!"0x86cb740.w256.b0", !6012, i64 0}
!6012 = !{!"0x86cb740.w512.b0", !6013, i64 0}
!6013 = !{!"0x86cb740.w1024.b0", !6014, i64 0}
!6014 = !{!"int64", !6015, i64 0}
!6015 = !{!"0x86cb740", !8, i64 0}
!6016 = !{!6017, !6017, i64 0}
!6017 = !{!"0x86cb740.w1.b4", !6018, i64 0}
!6018 = !{!"0x86cb740.w2.b4", !6019, i64 0}
!6019 = !{!"0x86cb740.w4.b4", !6006, i64 0}
!6020 = !{!6021, !6021, i64 0}
!6021 = !{!"float32", !6022, i64 0}
!6022 = !{!"0x8459ca0", !8, i64 0}
!6023 = !{!6024, !6024, i64 0}
!6024 = !{!"float32", !6025, i64 0}
!6025 = !{!"0xecf6150", !8, i64 0}
!6026 = !{!6027, !6027, i64 0}
!6027 = !{!"0xf7f4bd0.w1.b0", !6028, i64 0}
!6028 = !{!"0xf7f4bd0.w2.b0", !6029, i64 0}
!6029 = !{!"0xf7f4bd0.w4.b0", !6030, i64 0}
!6030 = !{!"0xf7f4bd0.w8.b0", !6031, i64 0}
!6031 = !{!"0xf7f4bd0.w16.b0", !6032, i64 0}
!6032 = !{!"0xf7f4bd0.w32.b0", !6033, i64 0}
!6033 = !{!"0xf7f4bd0.w64.b0", !6034, i64 0}
!6034 = !{!"0xf7f4bd0.w128.b0", !6035, i64 0}
!6035 = !{!"0xf7f4bd0.w256.b0", !6036, i64 0}
!6036 = !{!"0xf7f4bd0.w512.b0", !6037, i64 0}
!6037 = !{!"0xf7f4bd0.w1024.b0", !6038, i64 0}
!6038 = !{!"int32", !6039, i64 0}
!6039 = !{!"0xf7f4bd0", !8, i64 0}
!6040 = !{!6041, !6041, i64 0}
!6041 = !{!"0xf7f4bd0.w1.b2", !6042, i64 0}
!6042 = !{!"0xf7f4bd0.w2.b2", !6029, i64 0}
!6043 = !{!6044, !6044, i64 0}
!6044 = !{!"0xf7f4bd0.w1.b3", !6042, i64 0}
!6045 = !{!6046, !6046, i64 0}
!6046 = !{!"0xf7f4bd0.w1.b4", !6047, i64 0}
!6047 = !{!"0xf7f4bd0.w2.b4", !6048, i64 0}
!6048 = !{!"0xf7f4bd0.w4.b4", !6030, i64 0}
!6049 = !{!6050, !6050, i64 0}
!6050 = !{!"0xf7f4bd0.w1.b5", !6047, i64 0}
!6051 = !{!6052, !6052, i64 0}
!6052 = !{!"0xf7f4bd0.w1.b6", !6053, i64 0}
!6053 = !{!"0xf7f4bd0.w2.b6", !6048, i64 0}
!6054 = !{!6055, !6055, i64 0}
!6055 = !{!"0xf7f4bd0.w1.b1", !6028, i64 0}
!6056 = !{!6057, !6057, i64 0}
!6057 = !{!"0x13afebd0.w1.b0", !6058, i64 0}
!6058 = !{!"0x13afebd0.w2.b0", !6059, i64 0}
!6059 = !{!"0x13afebd0.w4.b0", !6060, i64 0}
!6060 = !{!"0x13afebd0.w8.b0", !6061, i64 0}
!6061 = !{!"0x13afebd0.w16.b0", !6062, i64 0}
!6062 = !{!"0x13afebd0.w32.b0", !6063, i64 0}
!6063 = !{!"0x13afebd0.w64.b0", !6064, i64 0}
!6064 = !{!"0x13afebd0.w128.b0", !6065, i64 0}
!6065 = !{!"0x13afebd0.w256.b0", !6066, i64 0}
!6066 = !{!"0x13afebd0.w512.b0", !6067, i64 0}
!6067 = !{!"0x13afebd0.w1024.b0", !6068, i64 0}
!6068 = !{!"int64", !6069, i64 0}
!6069 = !{!"0x13afebd0", !8, i64 0}
!6070 = !{!6071, !6071, i64 0}
!6071 = !{!"0x13afebd0.w1.b1", !6058, i64 0}
!6072 = !{!6073, !6073, i64 0}
!6073 = !{!"0x13afebd0.w1.b2", !6074, i64 0}
!6074 = !{!"0x13afebd0.w2.b2", !6059, i64 0}
!6075 = !{!6076, !6076, i64 0}
!6076 = !{!"0x13afebd0.w1.b3", !6074, i64 0}
!6077 = !{!6078, !6078, i64 0}
!6078 = !{!"0x13afebd0.w1.b4", !6079, i64 0}
!6079 = !{!"0x13afebd0.w2.b4", !6080, i64 0}
!6080 = !{!"0x13afebd0.w4.b4", !6060, i64 0}
!6081 = !{!6082, !6082, i64 0}
!6082 = !{!"0x139a1e40.w4.b0", !6083, i64 0}
!6083 = !{!"0x139a1e40.w8.b0", !6084, i64 0}
!6084 = !{!"0x139a1e40.w16.b0", !6085, i64 0}
!6085 = !{!"0x139a1e40.w32.b0", !6086, i64 0}
!6086 = !{!"0x139a1e40.w64.b0", !6087, i64 0}
!6087 = !{!"0x139a1e40.w128.b0", !6088, i64 0}
!6088 = !{!"0x139a1e40.w256.b0", !6089, i64 0}
!6089 = !{!"0x139a1e40.w512.b0", !6090, i64 0}
!6090 = !{!"0x139a1e40.w1024.b0", !6091, i64 0}
!6091 = !{!"int64", !6092, i64 0}
!6092 = !{!"0x139a1e40", !8, i64 0}
!6093 = !{!6094, !6094, i64 0}
!6094 = !{!"0x139a1e40.w1.b4", !6095, i64 0}
!6095 = !{!"0x139a1e40.w2.b4", !6096, i64 0}
!6096 = !{!"0x139a1e40.w4.b4", !6083, i64 0}
!6097 = !{!6098, !6098, i64 0}
!6098 = !{!"0x139bd890.w1.b0", !6099, i64 0}
!6099 = !{!"0x139bd890.w2.b0", !6100, i64 0}
!6100 = !{!"0x139bd890.w4.b0", !6101, i64 0}
!6101 = !{!"0x139bd890.w8.b0", !6102, i64 0}
!6102 = !{!"0x139bd890.w16.b0", !6103, i64 0}
!6103 = !{!"0x139bd890.w32.b0", !6104, i64 0}
!6104 = !{!"0x139bd890.w64.b0", !6105, i64 0}
!6105 = !{!"0x139bd890.w128.b0", !6106, i64 0}
!6106 = !{!"0x139bd890.w256.b0", !6107, i64 0}
!6107 = !{!"0x139bd890.w512.b0", !6108, i64 0}
!6108 = !{!"0x139bd890.w1024.b0", !6109, i64 0}
!6109 = !{!"int64", !6110, i64 0}
!6110 = !{!"0x139bd890", !8, i64 0}
!6111 = !{!6112, !6112, i64 0}
!6112 = !{!"0x139bd890.w1.b1", !6099, i64 0}
!6113 = !{!6114, !6114, i64 0}
!6114 = !{!"0x139bd890.w1.b2", !6115, i64 0}
!6115 = !{!"0x139bd890.w2.b2", !6100, i64 0}
!6116 = !{!6117, !6117, i64 0}
!6117 = !{!"0x139bd890.w1.b3", !6115, i64 0}
!6118 = !{!6119, !6119, i64 0}
!6119 = !{!"0x139bd890.w1.b4", !6120, i64 0}
!6120 = !{!"0x139bd890.w2.b4", !6121, i64 0}
!6121 = !{!"0x139bd890.w4.b4", !6101, i64 0}
!6122 = !{!6123, !6123, i64 0}
!6123 = !{!"0x139bd890.w1.b5", !6120, i64 0}
!6124 = !{!6125, !6125, i64 0}
!6125 = !{!"0x99484a0.w4.b0", !6126, i64 0}
!6126 = !{!"0x99484a0.w8.b0", !6127, i64 0}
!6127 = !{!"0x99484a0.w16.b0", !6128, i64 0}
!6128 = !{!"0x99484a0.w32.b0", !6129, i64 0}
!6129 = !{!"0x99484a0.w64.b0", !6130, i64 0}
!6130 = !{!"0x99484a0.w128.b0", !6131, i64 0}
!6131 = !{!"0x99484a0.w256.b0", !6132, i64 0}
!6132 = !{!"0x99484a0.w512.b0", !6133, i64 0}
!6133 = !{!"0x99484a0.w1024.b0", !6134, i64 0}
!6134 = !{!"int64", !6135, i64 0}
!6135 = !{!"0x99484a0", !8, i64 0}
!6136 = !{!6137, !6137, i64 0}
!6137 = !{!"0x99484a0.w1.b4", !6138, i64 0}
!6138 = !{!"0x99484a0.w2.b4", !6139, i64 0}
!6139 = !{!"0x99484a0.w4.b4", !6126, i64 0}
!6140 = !{!6141, !6141, i64 0}
!6141 = !{!"0x99484a0.w1.b5", !6138, i64 0}
!6142 = !{!6143, !6143, i64 0}
!6143 = !{!"0x1398dc10.w1.b0", !6144, i64 0}
!6144 = !{!"0x1398dc10.w2.b0", !6145, i64 0}
!6145 = !{!"0x1398dc10.w4.b0", !6146, i64 0}
!6146 = !{!"0x1398dc10.w8.b0", !6147, i64 0}
!6147 = !{!"0x1398dc10.w16.b0", !6148, i64 0}
!6148 = !{!"0x1398dc10.w32.b0", !6149, i64 0}
!6149 = !{!"0x1398dc10.w64.b0", !6150, i64 0}
!6150 = !{!"0x1398dc10.w128.b0", !6151, i64 0}
!6151 = !{!"0x1398dc10.w256.b0", !6152, i64 0}
!6152 = !{!"0x1398dc10.w512.b0", !6153, i64 0}
!6153 = !{!"0x1398dc10.w1024.b0", !6154, i64 0}
!6154 = !{!"int64", !6155, i64 0}
!6155 = !{!"0x1398dc10", !8, i64 0}
!6156 = !{!6157, !6157, i64 0}
!6157 = !{!"0x1398dc10.w1.b1", !6144, i64 0}
!6158 = !{!6159, !6159, i64 0}
!6159 = !{!"0x1398dc10.w1.b2", !6160, i64 0}
!6160 = !{!"0x1398dc10.w2.b2", !6145, i64 0}
!6161 = !{!6162, !6162, i64 0}
!6162 = !{!"0x1398dc10.w1.b3", !6160, i64 0}
!6163 = !{!6164, !6164, i64 0}
!6164 = !{!"0x1a551cf0.w4.b0", !6165, i64 0}
!6165 = !{!"0x1a551cf0.w8.b0", !6166, i64 0}
!6166 = !{!"0x1a551cf0.w16.b0", !6167, i64 0}
!6167 = !{!"0x1a551cf0.w32.b0", !6168, i64 0}
!6168 = !{!"0x1a551cf0.w64.b0", !6169, i64 0}
!6169 = !{!"0x1a551cf0.w128.b0", !6170, i64 0}
!6170 = !{!"0x1a551cf0.w256.b0", !6171, i64 0}
!6171 = !{!"0x1a551cf0.w512.b0", !6172, i64 0}
!6172 = !{!"0x1a551cf0.w1024.b0", !6173, i64 0}
!6173 = !{!"int64", !6174, i64 0}
!6174 = !{!"0x1a551cf0", !8, i64 0}
!6175 = !{!6176, !6176, i64 0}
!6176 = !{!"0x8f8f800.w1.b0", !6177, i64 0}
!6177 = !{!"0x8f8f800.w2.b0", !6178, i64 0}
!6178 = !{!"0x8f8f800.w4.b0", !6179, i64 0}
!6179 = !{!"0x8f8f800.w8.b0", !6180, i64 0}
!6180 = !{!"0x8f8f800.w16.b0", !6181, i64 0}
!6181 = !{!"0x8f8f800.w32.b0", !6182, i64 0}
!6182 = !{!"0x8f8f800.w64.b0", !6183, i64 0}
!6183 = !{!"0x8f8f800.w128.b0", !6184, i64 0}
!6184 = !{!"0x8f8f800.w256.b0", !6185, i64 0}
!6185 = !{!"0x8f8f800.w512.b0", !6186, i64 0}
!6186 = !{!"0x8f8f800.w1024.b0", !6187, i64 0}
!6187 = !{!"int64", !6188, i64 0}
!6188 = !{!"0x8f8f800", !8, i64 0}
!6189 = !{!6190, !6190, i64 0}
!6190 = !{!"0x8f8f800.w1.b1", !6177, i64 0}
!6191 = !{!6192, !6192, i64 0}
!6192 = !{!"0x8f8f800.w1.b2", !6193, i64 0}
!6193 = !{!"0x8f8f800.w2.b2", !6178, i64 0}
!6194 = !{!6195, !6195, i64 0}
!6195 = !{!"0x8f8f800.w1.b3", !6193, i64 0}
!6196 = !{!6197, !6197, i64 0}
!6197 = !{!"0x13b11880.w4.b0", !6198, i64 0}
!6198 = !{!"0x13b11880.w8.b0", !6199, i64 0}
!6199 = !{!"0x13b11880.w16.b0", !6200, i64 0}
!6200 = !{!"0x13b11880.w32.b0", !6201, i64 0}
!6201 = !{!"0x13b11880.w64.b0", !6202, i64 0}
!6202 = !{!"0x13b11880.w128.b0", !6203, i64 0}
!6203 = !{!"0x13b11880.w256.b0", !6204, i64 0}
!6204 = !{!"0x13b11880.w512.b0", !6205, i64 0}
!6205 = !{!"0x13b11880.w1024.b0", !6206, i64 0}
!6206 = !{!"int64", !6207, i64 0}
!6207 = !{!"0x13b11880", !8, i64 0}
!6208 = !{!6209, !6209, i64 0}
!6209 = !{!"0x13afefa0.w1.b0", !6210, i64 0}
!6210 = !{!"0x13afefa0.w2.b0", !6211, i64 0}
!6211 = !{!"0x13afefa0.w4.b0", !6212, i64 0}
!6212 = !{!"0x13afefa0.w8.b0", !6213, i64 0}
!6213 = !{!"0x13afefa0.w16.b0", !6214, i64 0}
!6214 = !{!"0x13afefa0.w32.b0", !6215, i64 0}
!6215 = !{!"0x13afefa0.w64.b0", !6216, i64 0}
!6216 = !{!"0x13afefa0.w128.b0", !6217, i64 0}
!6217 = !{!"0x13afefa0.w256.b0", !6218, i64 0}
!6218 = !{!"0x13afefa0.w512.b0", !6219, i64 0}
!6219 = !{!"0x13afefa0.w1024.b0", !6220, i64 0}
!6220 = !{!"int64", !6221, i64 0}
!6221 = !{!"0x13afefa0", !8, i64 0}
!6222 = !{!6223, !6223, i64 0}
!6223 = !{!"0x13afefa0.w1.b1", !6210, i64 0}
!6224 = !{!6225, !6225, i64 0}
!6225 = !{!"0x13afefa0.w1.b2", !6226, i64 0}
!6226 = !{!"0x13afefa0.w2.b2", !6211, i64 0}
!6227 = !{!6228, !6228, i64 0}
!6228 = !{!"0x13afefa0.w1.b3", !6226, i64 0}
!6229 = !{!6230, !6230, i64 0}
!6230 = !{!"0xa946f60.w4.b0", !6231, i64 0}
!6231 = !{!"0xa946f60.w8.b0", !6232, i64 0}
!6232 = !{!"0xa946f60.w16.b0", !6233, i64 0}
!6233 = !{!"0xa946f60.w32.b0", !6234, i64 0}
!6234 = !{!"0xa946f60.w64.b0", !6235, i64 0}
!6235 = !{!"0xa946f60.w128.b0", !6236, i64 0}
!6236 = !{!"0xa946f60.w256.b0", !6237, i64 0}
!6237 = !{!"0xa946f60.w512.b0", !6238, i64 0}
!6238 = !{!"0xa946f60.w1024.b0", !6239, i64 0}
!6239 = !{!"int64", !6240, i64 0}
!6240 = !{!"0xa946f60", !8, i64 0}
!6241 = !{!6242, !6242, i64 0}
!6242 = !{!"0x139d2a20.w1.b0", !6243, i64 0}
!6243 = !{!"0x139d2a20.w2.b0", !6244, i64 0}
!6244 = !{!"0x139d2a20.w4.b0", !6245, i64 0}
!6245 = !{!"0x139d2a20.w8.b0", !6246, i64 0}
!6246 = !{!"0x139d2a20.w16.b0", !6247, i64 0}
!6247 = !{!"0x139d2a20.w32.b0", !6248, i64 0}
!6248 = !{!"0x139d2a20.w64.b0", !6249, i64 0}
!6249 = !{!"0x139d2a20.w128.b0", !6250, i64 0}
!6250 = !{!"0x139d2a20.w256.b0", !6251, i64 0}
!6251 = !{!"0x139d2a20.w512.b0", !6252, i64 0}
!6252 = !{!"0x139d2a20.w1024.b0", !6253, i64 0}
!6253 = !{!"int64", !6254, i64 0}
!6254 = !{!"0x139d2a20", !8, i64 0}
!6255 = !{!6256, !6256, i64 0}
!6256 = !{!"0x139d2a20.w1.b1", !6243, i64 0}
!6257 = !{!6258, !6258, i64 0}
!6258 = !{!"0x139d2a20.w1.b2", !6259, i64 0}
!6259 = !{!"0x139d2a20.w2.b2", !6244, i64 0}
!6260 = !{!6261, !6261, i64 0}
!6261 = !{!"0x139d2a20.w1.b3", !6259, i64 0}
!6262 = !{!6263, !6263, i64 0}
!6263 = !{!"0x139d2a20.w1.b4", !6264, i64 0}
!6264 = !{!"0x139d2a20.w2.b4", !6265, i64 0}
!6265 = !{!"0x139d2a20.w4.b4", !6245, i64 0}
!6266 = !{!6267, !6267, i64 0}
!6267 = !{!"0x13dbebc0.w4.b0", !6268, i64 0}
!6268 = !{!"0x13dbebc0.w8.b0", !6269, i64 0}
!6269 = !{!"0x13dbebc0.w16.b0", !6270, i64 0}
!6270 = !{!"0x13dbebc0.w32.b0", !6271, i64 0}
!6271 = !{!"0x13dbebc0.w64.b0", !6272, i64 0}
!6272 = !{!"0x13dbebc0.w128.b0", !6273, i64 0}
!6273 = !{!"0x13dbebc0.w256.b0", !6274, i64 0}
!6274 = !{!"0x13dbebc0.w512.b0", !6275, i64 0}
!6275 = !{!"0x13dbebc0.w1024.b0", !6276, i64 0}
!6276 = !{!"int64", !6277, i64 0}
!6277 = !{!"0x13dbebc0", !8, i64 0}
!6278 = !{!6279, !6279, i64 0}
!6279 = !{!"0x13dbebc0.w1.b4", !6280, i64 0}
!6280 = !{!"0x13dbebc0.w2.b4", !6281, i64 0}
!6281 = !{!"0x13dbebc0.w4.b4", !6268, i64 0}
!6282 = !{!6283, !6283, i64 0}
!6283 = !{!"0x1398de40.w1.b0", !6284, i64 0}
!6284 = !{!"0x1398de40.w2.b0", !6285, i64 0}
!6285 = !{!"0x1398de40.w4.b0", !6286, i64 0}
!6286 = !{!"0x1398de40.w8.b0", !6287, i64 0}
!6287 = !{!"0x1398de40.w16.b0", !6288, i64 0}
!6288 = !{!"0x1398de40.w32.b0", !6289, i64 0}
!6289 = !{!"0x1398de40.w64.b0", !6290, i64 0}
!6290 = !{!"0x1398de40.w128.b0", !6291, i64 0}
!6291 = !{!"0x1398de40.w256.b0", !6292, i64 0}
!6292 = !{!"0x1398de40.w512.b0", !6293, i64 0}
!6293 = !{!"0x1398de40.w1024.b0", !6294, i64 0}
!6294 = !{!"int64", !6295, i64 0}
!6295 = !{!"0x1398de40", !8, i64 0}
!6296 = !{!6297, !6297, i64 0}
!6297 = !{!"0x1398de40.w1.b1", !6284, i64 0}
!6298 = !{!6299, !6299, i64 0}
!6299 = !{!"0x1398de40.w1.b2", !6300, i64 0}
!6300 = !{!"0x1398de40.w2.b2", !6285, i64 0}
!6301 = !{!6302, !6302, i64 0}
!6302 = !{!"0x1398de40.w1.b3", !6300, i64 0}
!6303 = !{!6304, !6304, i64 0}
!6304 = !{!"0x1398de40.w1.b4", !6305, i64 0}
!6305 = !{!"0x1398de40.w2.b4", !6306, i64 0}
!6306 = !{!"0x1398de40.w4.b4", !6286, i64 0}
!6307 = !{!6308, !6308, i64 0}
!6308 = !{!"0x135503a0.w4.b0", !6309, i64 0}
!6309 = !{!"0x135503a0.w8.b0", !6310, i64 0}
!6310 = !{!"0x135503a0.w16.b0", !6311, i64 0}
!6311 = !{!"0x135503a0.w32.b0", !6312, i64 0}
!6312 = !{!"0x135503a0.w64.b0", !6313, i64 0}
!6313 = !{!"0x135503a0.w128.b0", !6314, i64 0}
!6314 = !{!"0x135503a0.w256.b0", !6315, i64 0}
!6315 = !{!"0x135503a0.w512.b0", !6316, i64 0}
!6316 = !{!"0x135503a0.w1024.b0", !6317, i64 0}
!6317 = !{!"int64", !6318, i64 0}
!6318 = !{!"0x135503a0", !8, i64 0}
!6319 = !{!6320, !6320, i64 0}
!6320 = !{!"0x135503a0.w1.b4", !6321, i64 0}
!6321 = !{!"0x135503a0.w2.b4", !6322, i64 0}
!6322 = !{!"0x135503a0.w4.b4", !6309, i64 0}
!6323 = !{!6324, !6324, i64 0}
!6324 = !{!"float32", !6325, i64 0}
!6325 = !{!"0x139af0a0", !8, i64 0}
!6326 = !{!6327, !6327, i64 0}
!6327 = !{!"float32", !6328, i64 0}
!6328 = !{!"0x1b7adb40", !8, i64 0}
!6329 = !{!6330, !6330, i64 0}
!6330 = !{!"float32", !6331, i64 0}
!6331 = !{!"0x135e3470", !8, i64 0}
!6332 = !{!6333, !6333, i64 0}
!6333 = !{!"float32", !6334, i64 0}
!6334 = !{!"0x13b2e800", !8, i64 0}
!6335 = !{!6336, !6336, i64 0}
!6336 = !{!"float32", !6337, i64 0}
!6337 = !{!"0x13991480", !8, i64 0}
!6338 = !{!6339, !6339, i64 0}
!6339 = !{!"float32", !6340, i64 0}
!6340 = !{!"0x7cb3520", !8, i64 0}
!6341 = !{!6342, !6342, i64 0}
!6342 = !{!"float32", !6343, i64 0}
!6343 = !{!"0x13988fd0", !8, i64 0}
!6344 = !{!6345, !6345, i64 0}
!6345 = !{!"float32", !6346, i64 0}
!6346 = !{!"0x13d769e0", !8, i64 0}
!6347 = !{!6348, !6348, i64 0}
!6348 = !{!"0xca6ac50.w1.b0", !6349, i64 0}
!6349 = !{!"0xca6ac50.w2.b0", !6350, i64 0}
!6350 = !{!"0xca6ac50.w4.b0", !6351, i64 0}
!6351 = !{!"0xca6ac50.w8.b0", !6352, i64 0}
!6352 = !{!"0xca6ac50.w16.b0", !6353, i64 0}
!6353 = !{!"0xca6ac50.w32.b0", !6354, i64 0}
!6354 = !{!"0xca6ac50.w64.b0", !6355, i64 0}
!6355 = !{!"0xca6ac50.w128.b0", !6356, i64 0}
!6356 = !{!"0xca6ac50.w256.b0", !6357, i64 0}
!6357 = !{!"0xca6ac50.w512.b0", !6358, i64 0}
!6358 = !{!"0xca6ac50.w1024.b0", !6359, i64 0}
!6359 = !{!"int32", !6360, i64 0}
!6360 = !{!"0xca6ac50", !8, i64 0}
!6361 = !{!6362, !6362, i64 0}
!6362 = !{!"0xca6ac50.w1.b2", !6363, i64 0}
!6363 = !{!"0xca6ac50.w2.b2", !6350, i64 0}
!6364 = !{!6365, !6365, i64 0}
!6365 = !{!"0xca6ac50.w1.b3", !6363, i64 0}
!6366 = !{!6367, !6367, i64 0}
!6367 = !{!"0xca6ac50.w1.b4", !6368, i64 0}
!6368 = !{!"0xca6ac50.w2.b4", !6369, i64 0}
!6369 = !{!"0xca6ac50.w4.b4", !6351, i64 0}
!6370 = !{!6371, !6371, i64 0}
!6371 = !{!"0xca6ac50.w1.b5", !6368, i64 0}
!6372 = !{!6373, !6373, i64 0}
!6373 = !{!"0xca6ac50.w1.b1", !6349, i64 0}
!6374 = !{!6375, !6375, i64 0}
!6375 = !{!"0xca6bbb0.w1.b0", !6376, i64 0}
!6376 = !{!"0xca6bbb0.w2.b0", !6377, i64 0}
!6377 = !{!"0xca6bbb0.w4.b0", !6378, i64 0}
!6378 = !{!"0xca6bbb0.w8.b0", !6379, i64 0}
!6379 = !{!"0xca6bbb0.w16.b0", !6380, i64 0}
!6380 = !{!"0xca6bbb0.w32.b0", !6381, i64 0}
!6381 = !{!"0xca6bbb0.w64.b0", !6382, i64 0}
!6382 = !{!"0xca6bbb0.w128.b0", !6383, i64 0}
!6383 = !{!"0xca6bbb0.w256.b0", !6384, i64 0}
!6384 = !{!"0xca6bbb0.w512.b0", !6385, i64 0}
!6385 = !{!"0xca6bbb0.w1024.b0", !6386, i64 0}
!6386 = !{!"int64", !6387, i64 0}
!6387 = !{!"0xca6bbb0", !8, i64 0}
!6388 = !{!6389, !6389, i64 0}
!6389 = !{!"0xca6bbb0.w1.b1", !6376, i64 0}
!6390 = !{!6391, !6391, i64 0}
!6391 = !{!"0xca6bbb0.w1.b2", !6392, i64 0}
!6392 = !{!"0xca6bbb0.w2.b2", !6377, i64 0}
!6393 = !{!6394, !6394, i64 0}
!6394 = !{!"0xca6bbb0.w1.b3", !6392, i64 0}
!6395 = !{!6396, !6396, i64 0}
!6396 = !{!"0xca6bbb0.w1.b4", !6397, i64 0}
!6397 = !{!"0xca6bbb0.w2.b4", !6398, i64 0}
!6398 = !{!"0xca6bbb0.w4.b4", !6378, i64 0}
!6399 = !{!6400, !6400, i64 0}
!6400 = !{!"0xca6a2e0.w4.b0", !6401, i64 0}
!6401 = !{!"0xca6a2e0.w8.b0", !6402, i64 0}
!6402 = !{!"0xca6a2e0.w16.b0", !6403, i64 0}
!6403 = !{!"0xca6a2e0.w32.b0", !6404, i64 0}
!6404 = !{!"0xca6a2e0.w64.b0", !6405, i64 0}
!6405 = !{!"0xca6a2e0.w128.b0", !6406, i64 0}
!6406 = !{!"0xca6a2e0.w256.b0", !6407, i64 0}
!6407 = !{!"0xca6a2e0.w512.b0", !6408, i64 0}
!6408 = !{!"0xca6a2e0.w1024.b0", !6409, i64 0}
!6409 = !{!"int64", !6410, i64 0}
!6410 = !{!"0xca6a2e0", !8, i64 0}
!6411 = !{!6412, !6412, i64 0}
!6412 = !{!"0xca6a2e0.w1.b4", !6413, i64 0}
!6413 = !{!"0xca6a2e0.w2.b4", !6414, i64 0}
!6414 = !{!"0xca6a2e0.w4.b4", !6401, i64 0}
!6415 = !{!6416, !6416, i64 0}
!6416 = !{!"0xca69630.w1.b0", !6417, i64 0}
!6417 = !{!"0xca69630.w2.b0", !6418, i64 0}
!6418 = !{!"0xca69630.w4.b0", !6419, i64 0}
!6419 = !{!"0xca69630.w8.b0", !6420, i64 0}
!6420 = !{!"0xca69630.w16.b0", !6421, i64 0}
!6421 = !{!"0xca69630.w32.b0", !6422, i64 0}
!6422 = !{!"0xca69630.w64.b0", !6423, i64 0}
!6423 = !{!"0xca69630.w128.b0", !6424, i64 0}
!6424 = !{!"0xca69630.w256.b0", !6425, i64 0}
!6425 = !{!"0xca69630.w512.b0", !6426, i64 0}
!6426 = !{!"0xca69630.w1024.b0", !6427, i64 0}
!6427 = !{!"int64", !6428, i64 0}
!6428 = !{!"0xca69630", !8, i64 0}
!6429 = !{!6430, !6430, i64 0}
!6430 = !{!"0xca69630.w1.b1", !6417, i64 0}
!6431 = !{!6432, !6432, i64 0}
!6432 = !{!"0xca69630.w1.b2", !6433, i64 0}
!6433 = !{!"0xca69630.w2.b2", !6418, i64 0}
!6434 = !{!6435, !6435, i64 0}
!6435 = !{!"0xca69630.w1.b3", !6433, i64 0}
!6436 = !{!6437, !6437, i64 0}
!6437 = !{!"0xca69630.w1.b4", !6438, i64 0}
!6438 = !{!"0xca69630.w2.b4", !6439, i64 0}
!6439 = !{!"0xca69630.w4.b4", !6419, i64 0}
!6440 = !{!6441, !6441, i64 0}
!6441 = !{!"0xca69630.w1.b5", !6438, i64 0}
!6442 = !{!6443, !6443, i64 0}
!6443 = !{!"0xca6e170.w4.b0", !6444, i64 0}
!6444 = !{!"0xca6e170.w8.b0", !6445, i64 0}
!6445 = !{!"0xca6e170.w16.b0", !6446, i64 0}
!6446 = !{!"0xca6e170.w32.b0", !6447, i64 0}
!6447 = !{!"0xca6e170.w64.b0", !6448, i64 0}
!6448 = !{!"0xca6e170.w128.b0", !6449, i64 0}
!6449 = !{!"0xca6e170.w256.b0", !6450, i64 0}
!6450 = !{!"0xca6e170.w512.b0", !6451, i64 0}
!6451 = !{!"0xca6e170.w1024.b0", !6452, i64 0}
!6452 = !{!"int64", !6453, i64 0}
!6453 = !{!"0xca6e170", !8, i64 0}
!6454 = !{!6455, !6455, i64 0}
!6455 = !{!"0xca6e170.w1.b4", !6456, i64 0}
!6456 = !{!"0xca6e170.w2.b4", !6457, i64 0}
!6457 = !{!"0xca6e170.w4.b4", !6444, i64 0}
!6458 = !{!6459, !6459, i64 0}
!6459 = !{!"0xca6e170.w1.b5", !6456, i64 0}
!6460 = !{!6461, !6461, i64 0}
!6461 = !{!"0xca706b0.w1.b0", !6462, i64 0}
!6462 = !{!"0xca706b0.w2.b0", !6463, i64 0}
!6463 = !{!"0xca706b0.w4.b0", !6464, i64 0}
!6464 = !{!"0xca706b0.w8.b0", !6465, i64 0}
!6465 = !{!"0xca706b0.w16.b0", !6466, i64 0}
!6466 = !{!"0xca706b0.w32.b0", !6467, i64 0}
!6467 = !{!"0xca706b0.w64.b0", !6468, i64 0}
!6468 = !{!"0xca706b0.w128.b0", !6469, i64 0}
!6469 = !{!"0xca706b0.w256.b0", !6470, i64 0}
!6470 = !{!"0xca706b0.w512.b0", !6471, i64 0}
!6471 = !{!"0xca706b0.w1024.b0", !6472, i64 0}
!6472 = !{!"int64", !6473, i64 0}
!6473 = !{!"0xca706b0", !8, i64 0}
!6474 = !{!6475, !6475, i64 0}
!6475 = !{!"0xca706b0.w1.b1", !6462, i64 0}
!6476 = !{!6477, !6477, i64 0}
!6477 = !{!"0xca706b0.w1.b2", !6478, i64 0}
!6478 = !{!"0xca706b0.w2.b2", !6463, i64 0}
!6479 = !{!6480, !6480, i64 0}
!6480 = !{!"0xca706b0.w1.b3", !6478, i64 0}
!6481 = !{!6482, !6482, i64 0}
!6482 = !{!"0xca71070.w4.b0", !6483, i64 0}
!6483 = !{!"0xca71070.w8.b0", !6484, i64 0}
!6484 = !{!"0xca71070.w16.b0", !6485, i64 0}
!6485 = !{!"0xca71070.w32.b0", !6486, i64 0}
!6486 = !{!"0xca71070.w64.b0", !6487, i64 0}
!6487 = !{!"0xca71070.w128.b0", !6488, i64 0}
!6488 = !{!"0xca71070.w256.b0", !6489, i64 0}
!6489 = !{!"0xca71070.w512.b0", !6490, i64 0}
!6490 = !{!"0xca71070.w1024.b0", !6491, i64 0}
!6491 = !{!"int64", !6492, i64 0}
!6492 = !{!"0xca71070", !8, i64 0}
!6493 = !{!6494, !6494, i64 0}
!6494 = !{!"0xca68fc0.w1.b0", !6495, i64 0}
!6495 = !{!"0xca68fc0.w2.b0", !6496, i64 0}
!6496 = !{!"0xca68fc0.w4.b0", !6497, i64 0}
!6497 = !{!"0xca68fc0.w8.b0", !6498, i64 0}
!6498 = !{!"0xca68fc0.w16.b0", !6499, i64 0}
!6499 = !{!"0xca68fc0.w32.b0", !6500, i64 0}
!6500 = !{!"0xca68fc0.w64.b0", !6501, i64 0}
!6501 = !{!"0xca68fc0.w128.b0", !6502, i64 0}
!6502 = !{!"0xca68fc0.w256.b0", !6503, i64 0}
!6503 = !{!"0xca68fc0.w512.b0", !6504, i64 0}
!6504 = !{!"0xca68fc0.w1024.b0", !6505, i64 0}
!6505 = !{!"int64", !6506, i64 0}
!6506 = !{!"0xca68fc0", !8, i64 0}
!6507 = !{!6508, !6508, i64 0}
!6508 = !{!"0xca68fc0.w1.b1", !6495, i64 0}
!6509 = !{!6510, !6510, i64 0}
!6510 = !{!"0xca68fc0.w1.b2", !6511, i64 0}
!6511 = !{!"0xca68fc0.w2.b2", !6496, i64 0}
!6512 = !{!6513, !6513, i64 0}
!6513 = !{!"0xca68fc0.w1.b3", !6511, i64 0}
!6514 = !{!6515, !6515, i64 0}
!6515 = !{!"0x9112410.w4.b0", !6516, i64 0}
!6516 = !{!"0x9112410.w8.b0", !6517, i64 0}
!6517 = !{!"0x9112410.w16.b0", !6518, i64 0}
!6518 = !{!"0x9112410.w32.b0", !6519, i64 0}
!6519 = !{!"0x9112410.w64.b0", !6520, i64 0}
!6520 = !{!"0x9112410.w128.b0", !6521, i64 0}
!6521 = !{!"0x9112410.w256.b0", !6522, i64 0}
!6522 = !{!"0x9112410.w512.b0", !6523, i64 0}
!6523 = !{!"0x9112410.w1024.b0", !6524, i64 0}
!6524 = !{!"int64", !6525, i64 0}
!6525 = !{!"0x9112410", !8, i64 0}
!6526 = !{!6527, !6527, i64 0}
!6527 = !{!"0x9114020.w1.b0", !6528, i64 0}
!6528 = !{!"0x9114020.w2.b0", !6529, i64 0}
!6529 = !{!"0x9114020.w4.b0", !6530, i64 0}
!6530 = !{!"0x9114020.w8.b0", !6531, i64 0}
!6531 = !{!"0x9114020.w16.b0", !6532, i64 0}
!6532 = !{!"0x9114020.w32.b0", !6533, i64 0}
!6533 = !{!"0x9114020.w64.b0", !6534, i64 0}
!6534 = !{!"0x9114020.w128.b0", !6535, i64 0}
!6535 = !{!"0x9114020.w256.b0", !6536, i64 0}
!6536 = !{!"0x9114020.w512.b0", !6537, i64 0}
!6537 = !{!"0x9114020.w1024.b0", !6538, i64 0}
!6538 = !{!"int64", !6539, i64 0}
!6539 = !{!"0x9114020", !8, i64 0}
!6540 = !{!6541, !6541, i64 0}
!6541 = !{!"0x9114020.w1.b1", !6528, i64 0}
!6542 = !{!6543, !6543, i64 0}
!6543 = !{!"0x9114020.w1.b2", !6544, i64 0}
!6544 = !{!"0x9114020.w2.b2", !6529, i64 0}
!6545 = !{!6546, !6546, i64 0}
!6546 = !{!"0x9114020.w1.b3", !6544, i64 0}
!6547 = !{!6548, !6548, i64 0}
!6548 = !{!"0x9114ef0.w4.b0", !6549, i64 0}
!6549 = !{!"0x9114ef0.w8.b0", !6550, i64 0}
!6550 = !{!"0x9114ef0.w16.b0", !6551, i64 0}
!6551 = !{!"0x9114ef0.w32.b0", !6552, i64 0}
!6552 = !{!"0x9114ef0.w64.b0", !6553, i64 0}
!6553 = !{!"0x9114ef0.w128.b0", !6554, i64 0}
!6554 = !{!"0x9114ef0.w256.b0", !6555, i64 0}
!6555 = !{!"0x9114ef0.w512.b0", !6556, i64 0}
!6556 = !{!"0x9114ef0.w1024.b0", !6557, i64 0}
!6557 = !{!"int64", !6558, i64 0}
!6558 = !{!"0x9114ef0", !8, i64 0}
!6559 = !{!6560, !6560, i64 0}
!6560 = !{!"0x9116fb0.w1.b0", !6561, i64 0}
!6561 = !{!"0x9116fb0.w2.b0", !6562, i64 0}
!6562 = !{!"0x9116fb0.w4.b0", !6563, i64 0}
!6563 = !{!"0x9116fb0.w8.b0", !6564, i64 0}
!6564 = !{!"0x9116fb0.w16.b0", !6565, i64 0}
!6565 = !{!"0x9116fb0.w32.b0", !6566, i64 0}
!6566 = !{!"0x9116fb0.w64.b0", !6567, i64 0}
!6567 = !{!"0x9116fb0.w128.b0", !6568, i64 0}
!6568 = !{!"0x9116fb0.w256.b0", !6569, i64 0}
!6569 = !{!"0x9116fb0.w512.b0", !6570, i64 0}
!6570 = !{!"0x9116fb0.w1024.b0", !6571, i64 0}
!6571 = !{!"int64", !6572, i64 0}
!6572 = !{!"0x9116fb0", !8, i64 0}
!6573 = !{!6574, !6574, i64 0}
!6574 = !{!"0x9116fb0.w1.b1", !6561, i64 0}
!6575 = !{!6576, !6576, i64 0}
!6576 = !{!"0x9116fb0.w1.b2", !6577, i64 0}
!6577 = !{!"0x9116fb0.w2.b2", !6562, i64 0}
!6578 = !{!6579, !6579, i64 0}
!6579 = !{!"0x9116fb0.w1.b3", !6577, i64 0}
!6580 = !{!6581, !6581, i64 0}
!6581 = !{!"0x9116fb0.w1.b4", !6582, i64 0}
!6582 = !{!"0x9116fb0.w2.b4", !6583, i64 0}
!6583 = !{!"0x9116fb0.w4.b4", !6563, i64 0}
!6584 = !{!6585, !6585, i64 0}
!6585 = !{!"0x9117d50.w4.b0", !6586, i64 0}
!6586 = !{!"0x9117d50.w8.b0", !6587, i64 0}
!6587 = !{!"0x9117d50.w16.b0", !6588, i64 0}
!6588 = !{!"0x9117d50.w32.b0", !6589, i64 0}
!6589 = !{!"0x9117d50.w64.b0", !6590, i64 0}
!6590 = !{!"0x9117d50.w128.b0", !6591, i64 0}
!6591 = !{!"0x9117d50.w256.b0", !6592, i64 0}
!6592 = !{!"0x9117d50.w512.b0", !6593, i64 0}
!6593 = !{!"0x9117d50.w1024.b0", !6594, i64 0}
!6594 = !{!"int64", !6595, i64 0}
!6595 = !{!"0x9117d50", !8, i64 0}
!6596 = !{!6597, !6597, i64 0}
!6597 = !{!"0x9117d50.w1.b4", !6598, i64 0}
!6598 = !{!"0x9117d50.w2.b4", !6599, i64 0}
!6599 = !{!"0x9117d50.w4.b4", !6586, i64 0}
!6600 = !{!6601, !6601, i64 0}
!6601 = !{!"float32", !6602, i64 0}
!6602 = !{!"0xca63c20", !8, i64 0}
!6603 = !{!6604, !6604, i64 0}
!6604 = !{!"float32", !6605, i64 0}
!6605 = !{!"0xca5b900", !8, i64 0}
!6606 = !{!6607, !6607, i64 0}
!6607 = !{!"float32", !6608, i64 0}
!6608 = !{!"0xca5d7e0", !8, i64 0}
!6609 = !{!6610, !6610, i64 0}
!6610 = !{!"float32", !6611, i64 0}
!6611 = !{!"0xca5df80", !8, i64 0}
!6612 = !{!6613, !6613, i64 0}
!6613 = !{!"float32", !6614, i64 0}
!6614 = !{!"0xca5b420", !8, i64 0}
!6615 = !{!6616, !6616, i64 0}
!6616 = !{!"float32", !6617, i64 0}
!6617 = !{!"0xca5ac00", !8, i64 0}
!6618 = !{!6619, !6619, i64 0}
!6619 = !{!"float32", !6620, i64 0}
!6620 = !{!"0xca5c010", !8, i64 0}
!6621 = !{!6622, !6622, i64 0}
!6622 = !{!"0xcae6870.w1.b0", !6623, i64 0}
!6623 = !{!"0xcae6870.w2.b0", !6624, i64 0}
!6624 = !{!"0xcae6870.w4.b0", !6625, i64 0}
!6625 = !{!"0xcae6870.w8.b0", !6626, i64 0}
!6626 = !{!"0xcae6870.w16.b0", !6627, i64 0}
!6627 = !{!"0xcae6870.w32.b0", !6628, i64 0}
!6628 = !{!"0xcae6870.w64.b0", !6629, i64 0}
!6629 = !{!"0xcae6870.w128.b0", !6630, i64 0}
!6630 = !{!"0xcae6870.w256.b0", !6631, i64 0}
!6631 = !{!"0xcae6870.w512.b0", !6632, i64 0}
!6632 = !{!"0xcae6870.w1024.b0", !6633, i64 0}
!6633 = !{!"int32", !6634, i64 0}
!6634 = !{!"0xcae6870", !8, i64 0}
!6635 = !{!6636, !6636, i64 0}
!6636 = !{!"0xcae6870.w1.b1", !6623, i64 0}
!6637 = !{!6638, !6638, i64 0}
!6638 = !{!"0xcae83b0.w1.b0", !6639, i64 0}
!6639 = !{!"0xcae83b0.w2.b0", !6640, i64 0}
!6640 = !{!"0xcae83b0.w4.b0", !6641, i64 0}
!6641 = !{!"0xcae83b0.w8.b0", !6642, i64 0}
!6642 = !{!"0xcae83b0.w16.b0", !6643, i64 0}
!6643 = !{!"0xcae83b0.w32.b0", !6644, i64 0}
!6644 = !{!"0xcae83b0.w64.b0", !6645, i64 0}
!6645 = !{!"0xcae83b0.w128.b0", !6646, i64 0}
!6646 = !{!"0xcae83b0.w256.b0", !6647, i64 0}
!6647 = !{!"0xcae83b0.w512.b0", !6648, i64 0}
!6648 = !{!"0xcae83b0.w1024.b0", !6649, i64 0}
!6649 = !{!"int64", !6650, i64 0}
!6650 = !{!"0xcae83b0", !8, i64 0}
!6651 = !{!6652, !6652, i64 0}
!6652 = !{!"0xcae83b0.w1.b1", !6639, i64 0}
!6653 = !{!6654, !6654, i64 0}
!6654 = !{!"0xcae83b0.w1.b2", !6655, i64 0}
!6655 = !{!"0xcae83b0.w2.b2", !6640, i64 0}
!6656 = !{!6657, !6657, i64 0}
!6657 = !{!"0xcae83b0.w1.b3", !6655, i64 0}
!6658 = !{!6659, !6659, i64 0}
!6659 = !{!"0xcaea2b0.w4.b0", !6660, i64 0}
!6660 = !{!"0xcaea2b0.w8.b0", !6661, i64 0}
!6661 = !{!"0xcaea2b0.w16.b0", !6662, i64 0}
!6662 = !{!"0xcaea2b0.w32.b0", !6663, i64 0}
!6663 = !{!"0xcaea2b0.w64.b0", !6664, i64 0}
!6664 = !{!"0xcaea2b0.w128.b0", !6665, i64 0}
!6665 = !{!"0xcaea2b0.w256.b0", !6666, i64 0}
!6666 = !{!"0xcaea2b0.w512.b0", !6667, i64 0}
!6667 = !{!"0xcaea2b0.w1024.b0", !6668, i64 0}
!6668 = !{!"int64", !6669, i64 0}
!6669 = !{!"0xcaea2b0", !8, i64 0}
!6670 = !{!6671, !6671, i64 0}
!6671 = !{!"0xcaebe00.w1.b0", !6672, i64 0}
!6672 = !{!"0xcaebe00.w2.b0", !6673, i64 0}
!6673 = !{!"0xcaebe00.w4.b0", !6674, i64 0}
!6674 = !{!"0xcaebe00.w8.b0", !6675, i64 0}
!6675 = !{!"0xcaebe00.w16.b0", !6676, i64 0}
!6676 = !{!"0xcaebe00.w32.b0", !6677, i64 0}
!6677 = !{!"0xcaebe00.w64.b0", !6678, i64 0}
!6678 = !{!"0xcaebe00.w128.b0", !6679, i64 0}
!6679 = !{!"0xcaebe00.w256.b0", !6680, i64 0}
!6680 = !{!"0xcaebe00.w512.b0", !6681, i64 0}
!6681 = !{!"0xcaebe00.w1024.b0", !6682, i64 0}
!6682 = !{!"int64", !6683, i64 0}
!6683 = !{!"0xcaebe00", !8, i64 0}
!6684 = !{!6685, !6685, i64 0}
!6685 = !{!"0xcaebe00.w1.b1", !6672, i64 0}
!6686 = !{!6687, !6687, i64 0}
!6687 = !{!"0xcaebe00.w1.b2", !6688, i64 0}
!6688 = !{!"0xcaebe00.w2.b2", !6673, i64 0}
!6689 = !{!6690, !6690, i64 0}
!6690 = !{!"0xcaebe00.w1.b3", !6688, i64 0}
!6691 = !{!6692, !6692, i64 0}
!6692 = !{!"0xcaebe00.w1.b4", !6693, i64 0}
!6693 = !{!"0xcaebe00.w2.b4", !6694, i64 0}
!6694 = !{!"0xcaebe00.w4.b4", !6674, i64 0}
!6695 = !{!6696, !6696, i64 0}
!6696 = !{!"0xcaecbe0.w4.b0", !6697, i64 0}
!6697 = !{!"0xcaecbe0.w8.b0", !6698, i64 0}
!6698 = !{!"0xcaecbe0.w16.b0", !6699, i64 0}
!6699 = !{!"0xcaecbe0.w32.b0", !6700, i64 0}
!6700 = !{!"0xcaecbe0.w64.b0", !6701, i64 0}
!6701 = !{!"0xcaecbe0.w128.b0", !6702, i64 0}
!6702 = !{!"0xcaecbe0.w256.b0", !6703, i64 0}
!6703 = !{!"0xcaecbe0.w512.b0", !6704, i64 0}
!6704 = !{!"0xcaecbe0.w1024.b0", !6705, i64 0}
!6705 = !{!"int64", !6706, i64 0}
!6706 = !{!"0xcaecbe0", !8, i64 0}
!6707 = !{!6708, !6708, i64 0}
!6708 = !{!"0xcaecbe0.w1.b4", !6709, i64 0}
!6709 = !{!"0xcaecbe0.w2.b4", !6710, i64 0}
!6710 = !{!"0xcaecbe0.w4.b4", !6697, i64 0}
!6711 = !{!6712, !6712, i64 0}
!6712 = !{!"float32", !6713, i64 0}
!6713 = !{!"0xca80d40", !8, i64 0}
!6714 = !{!6715, !6715, i64 0}
!6715 = !{!"float32", !6716, i64 0}
!6716 = !{!"0xca80cf0", !8, i64 0}
!6717 = !{!6718, !6718, i64 0}
!6718 = !{!"0xcad67c0.w1.b0", !6719, i64 0}
!6719 = !{!"0xcad67c0.w2.b0", !6720, i64 0}
!6720 = !{!"0xcad67c0.w4.b0", !6721, i64 0}
!6721 = !{!"0xcad67c0.w8.b0", !6722, i64 0}
!6722 = !{!"0xcad67c0.w16.b0", !6723, i64 0}
!6723 = !{!"0xcad67c0.w32.b0", !6724, i64 0}
!6724 = !{!"0xcad67c0.w64.b0", !6725, i64 0}
!6725 = !{!"0xcad67c0.w128.b0", !6726, i64 0}
!6726 = !{!"0xcad67c0.w256.b0", !6727, i64 0}
!6727 = !{!"0xcad67c0.w512.b0", !6728, i64 0}
!6728 = !{!"0xcad67c0.w1024.b0", !6729, i64 0}
!6729 = !{!"int32", !6730, i64 0}
!6730 = !{!"0xcad67c0", !8, i64 0}
!6731 = !{!6732, !6732, i64 0}
!6732 = !{!"0xcad67c0.w1.b1", !6719, i64 0}
!6733 = !{!6734, !6734, i64 0}
!6734 = !{!"0xcad5fd0.w1.b0", !6735, i64 0}
!6735 = !{!"0xcad5fd0.w2.b0", !6736, i64 0}
!6736 = !{!"0xcad5fd0.w4.b0", !6737, i64 0}
!6737 = !{!"0xcad5fd0.w8.b0", !6738, i64 0}
!6738 = !{!"0xcad5fd0.w16.b0", !6739, i64 0}
!6739 = !{!"0xcad5fd0.w32.b0", !6740, i64 0}
!6740 = !{!"0xcad5fd0.w64.b0", !6741, i64 0}
!6741 = !{!"0xcad5fd0.w128.b0", !6742, i64 0}
!6742 = !{!"0xcad5fd0.w256.b0", !6743, i64 0}
!6743 = !{!"0xcad5fd0.w512.b0", !6744, i64 0}
!6744 = !{!"0xcad5fd0.w1024.b0", !6745, i64 0}
!6745 = !{!"int64", !6746, i64 0}
!6746 = !{!"0xcad5fd0", !8, i64 0}
!6747 = !{!6748, !6748, i64 0}
!6748 = !{!"0xcad5fd0.w1.b1", !6735, i64 0}
!6749 = !{!6750, !6750, i64 0}
!6750 = !{!"0xcad5fd0.w1.b2", !6751, i64 0}
!6751 = !{!"0xcad5fd0.w2.b2", !6736, i64 0}
!6752 = !{!6753, !6753, i64 0}
!6753 = !{!"0xcad5fd0.w1.b3", !6751, i64 0}
!6754 = !{!6755, !6755, i64 0}
!6755 = !{!"0xcad77b0.w4.b0", !6756, i64 0}
!6756 = !{!"0xcad77b0.w8.b0", !6757, i64 0}
!6757 = !{!"0xcad77b0.w16.b0", !6758, i64 0}
!6758 = !{!"0xcad77b0.w32.b0", !6759, i64 0}
!6759 = !{!"0xcad77b0.w64.b0", !6760, i64 0}
!6760 = !{!"0xcad77b0.w128.b0", !6761, i64 0}
!6761 = !{!"0xcad77b0.w256.b0", !6762, i64 0}
!6762 = !{!"0xcad77b0.w512.b0", !6763, i64 0}
!6763 = !{!"0xcad77b0.w1024.b0", !6764, i64 0}
!6764 = !{!"int64", !6765, i64 0}
!6765 = !{!"0xcad77b0", !8, i64 0}
!6766 = !{!6767, !6767, i64 0}
!6767 = !{!"0xcad9430.w1.b0", !6768, i64 0}
!6768 = !{!"0xcad9430.w2.b0", !6769, i64 0}
!6769 = !{!"0xcad9430.w4.b0", !6770, i64 0}
!6770 = !{!"0xcad9430.w8.b0", !6771, i64 0}
!6771 = !{!"0xcad9430.w16.b0", !6772, i64 0}
!6772 = !{!"0xcad9430.w32.b0", !6773, i64 0}
!6773 = !{!"0xcad9430.w64.b0", !6774, i64 0}
!6774 = !{!"0xcad9430.w128.b0", !6775, i64 0}
!6775 = !{!"0xcad9430.w256.b0", !6776, i64 0}
!6776 = !{!"0xcad9430.w512.b0", !6777, i64 0}
!6777 = !{!"0xcad9430.w1024.b0", !6778, i64 0}
!6778 = !{!"int64", !6779, i64 0}
!6779 = !{!"0xcad9430", !8, i64 0}
!6780 = !{!6781, !6781, i64 0}
!6781 = !{!"0xcad9430.w1.b1", !6768, i64 0}
!6782 = !{!6783, !6783, i64 0}
!6783 = !{!"0xcad9430.w1.b2", !6784, i64 0}
!6784 = !{!"0xcad9430.w2.b2", !6769, i64 0}
!6785 = !{!6786, !6786, i64 0}
!6786 = !{!"0xcad9430.w1.b3", !6784, i64 0}
!6787 = !{!6788, !6788, i64 0}
!6788 = !{!"0xcada210.w4.b0", !6789, i64 0}
!6789 = !{!"0xcada210.w8.b0", !6790, i64 0}
!6790 = !{!"0xcada210.w16.b0", !6791, i64 0}
!6791 = !{!"0xcada210.w32.b0", !6792, i64 0}
!6792 = !{!"0xcada210.w64.b0", !6793, i64 0}
!6793 = !{!"0xcada210.w128.b0", !6794, i64 0}
!6794 = !{!"0xcada210.w256.b0", !6795, i64 0}
!6795 = !{!"0xcada210.w512.b0", !6796, i64 0}
!6796 = !{!"0xcada210.w1024.b0", !6797, i64 0}
!6797 = !{!"int64", !6798, i64 0}
!6798 = !{!"0xcada210", !8, i64 0}
!6799 = !{!6800, !6800, i64 0}
!6800 = !{!"float32", !6801, i64 0}
!6801 = !{!"0xcaccd00", !8, i64 0}
!6802 = !{!6803, !6803, i64 0}
!6803 = !{!"float32", !6804, i64 0}
!6804 = !{!"0xcad36c0", !8, i64 0}
!6805 = !{!6806, !6806, i64 0}
!6806 = !{!"0x13af1de0.w1.b0", !6807, i64 0}
!6807 = !{!"0x13af1de0.w2.b0", !6808, i64 0}
!6808 = !{!"0x13af1de0.w4.b0", !6809, i64 0}
!6809 = !{!"0x13af1de0.w8.b0", !6810, i64 0}
!6810 = !{!"0x13af1de0.w16.b0", !6811, i64 0}
!6811 = !{!"0x13af1de0.w32.b0", !6812, i64 0}
!6812 = !{!"0x13af1de0.w64.b0", !6813, i64 0}
!6813 = !{!"0x13af1de0.w128.b0", !6814, i64 0}
!6814 = !{!"0x13af1de0.w256.b0", !6815, i64 0}
!6815 = !{!"0x13af1de0.w512.b0", !6816, i64 0}
!6816 = !{!"0x13af1de0.w1024.b0", !6817, i64 0}
!6817 = !{!"int32", !6818, i64 0}
!6818 = !{!"0x13af1de0", !8, i64 0}
!6819 = !{!6820, !6820, i64 0}
!6820 = !{!"0x13af1de0.w1.b1", !6807, i64 0}
!6821 = !{!6822, !6822, i64 0}
!6822 = !{!"0x1368c800.w1.b0", !6823, i64 0}
!6823 = !{!"0x1368c800.w2.b0", !6824, i64 0}
!6824 = !{!"0x1368c800.w4.b0", !6825, i64 0}
!6825 = !{!"0x1368c800.w8.b0", !6826, i64 0}
!6826 = !{!"0x1368c800.w16.b0", !6827, i64 0}
!6827 = !{!"0x1368c800.w32.b0", !6828, i64 0}
!6828 = !{!"0x1368c800.w64.b0", !6829, i64 0}
!6829 = !{!"0x1368c800.w128.b0", !6830, i64 0}
!6830 = !{!"0x1368c800.w256.b0", !6831, i64 0}
!6831 = !{!"0x1368c800.w512.b0", !6832, i64 0}
!6832 = !{!"0x1368c800.w1024.b0", !6833, i64 0}
!6833 = !{!"int64", !6834, i64 0}
!6834 = !{!"0x1368c800", !8, i64 0}
!6835 = !{!6836, !6836, i64 0}
!6836 = !{!"0x1368c800.w1.b1", !6823, i64 0}
!6837 = !{!6838, !6838, i64 0}
!6838 = !{!"0x1368c800.w1.b2", !6839, i64 0}
!6839 = !{!"0x1368c800.w2.b2", !6824, i64 0}
!6840 = !{!6841, !6841, i64 0}
!6841 = !{!"0x1368c800.w1.b3", !6839, i64 0}
!6842 = !{!6843, !6843, i64 0}
!6843 = !{!"0x1368c800.w1.b4", !6844, i64 0}
!6844 = !{!"0x1368c800.w2.b4", !6845, i64 0}
!6845 = !{!"0x1368c800.w4.b4", !6825, i64 0}
!6846 = !{!6847, !6847, i64 0}
!6847 = !{!"0x139b73a0.w4.b0", !6848, i64 0}
!6848 = !{!"0x139b73a0.w8.b0", !6849, i64 0}
!6849 = !{!"0x139b73a0.w16.b0", !6850, i64 0}
!6850 = !{!"0x139b73a0.w32.b0", !6851, i64 0}
!6851 = !{!"0x139b73a0.w64.b0", !6852, i64 0}
!6852 = !{!"0x139b73a0.w128.b0", !6853, i64 0}
!6853 = !{!"0x139b73a0.w256.b0", !6854, i64 0}
!6854 = !{!"0x139b73a0.w512.b0", !6855, i64 0}
!6855 = !{!"0x139b73a0.w1024.b0", !6856, i64 0}
!6856 = !{!"int64", !6857, i64 0}
!6857 = !{!"0x139b73a0", !8, i64 0}
!6858 = !{!6859, !6859, i64 0}
!6859 = !{!"0x139b73a0.w1.b4", !6860, i64 0}
!6860 = !{!"0x139b73a0.w2.b4", !6861, i64 0}
!6861 = !{!"0x139b73a0.w4.b4", !6848, i64 0}
!6862 = !{!6863, !6863, i64 0}
!6863 = !{!"0x1b7a4f70.w1.b0", !6864, i64 0}
!6864 = !{!"0x1b7a4f70.w2.b0", !6865, i64 0}
!6865 = !{!"0x1b7a4f70.w4.b0", !6866, i64 0}
!6866 = !{!"0x1b7a4f70.w8.b0", !6867, i64 0}
!6867 = !{!"0x1b7a4f70.w16.b0", !6868, i64 0}
!6868 = !{!"0x1b7a4f70.w32.b0", !6869, i64 0}
!6869 = !{!"0x1b7a4f70.w64.b0", !6870, i64 0}
!6870 = !{!"0x1b7a4f70.w128.b0", !6871, i64 0}
!6871 = !{!"0x1b7a4f70.w256.b0", !6872, i64 0}
!6872 = !{!"0x1b7a4f70.w512.b0", !6873, i64 0}
!6873 = !{!"0x1b7a4f70.w1024.b0", !6874, i64 0}
!6874 = !{!"int64", !6875, i64 0}
!6875 = !{!"0x1b7a4f70", !8, i64 0}
!6876 = !{!6877, !6877, i64 0}
!6877 = !{!"0x1b7a4f70.w1.b1", !6864, i64 0}
!6878 = !{!6879, !6879, i64 0}
!6879 = !{!"0x1b7a4f70.w1.b2", !6880, i64 0}
!6880 = !{!"0x1b7a4f70.w2.b2", !6865, i64 0}
!6881 = !{!6882, !6882, i64 0}
!6882 = !{!"0x1b7a4f70.w1.b3", !6880, i64 0}
!6883 = !{!6884, !6884, i64 0}
!6884 = !{!"0x1b7a4f70.w1.b4", !6885, i64 0}
!6885 = !{!"0x1b7a4f70.w2.b4", !6886, i64 0}
!6886 = !{!"0x1b7a4f70.w4.b4", !6866, i64 0}
!6887 = !{!6888, !6888, i64 0}
!6888 = !{!"0xd530170.w4.b0", !6889, i64 0}
!6889 = !{!"0xd530170.w8.b0", !6890, i64 0}
!6890 = !{!"0xd530170.w16.b0", !6891, i64 0}
!6891 = !{!"0xd530170.w32.b0", !6892, i64 0}
!6892 = !{!"0xd530170.w64.b0", !6893, i64 0}
!6893 = !{!"0xd530170.w128.b0", !6894, i64 0}
!6894 = !{!"0xd530170.w256.b0", !6895, i64 0}
!6895 = !{!"0xd530170.w512.b0", !6896, i64 0}
!6896 = !{!"0xd530170.w1024.b0", !6897, i64 0}
!6897 = !{!"int64", !6898, i64 0}
!6898 = !{!"0xd530170", !8, i64 0}
!6899 = !{!6900, !6900, i64 0}
!6900 = !{!"0xd530170.w1.b4", !6901, i64 0}
!6901 = !{!"0xd530170.w2.b4", !6902, i64 0}
!6902 = !{!"0xd530170.w4.b4", !6889, i64 0}
!6903 = !{!6904, !6904, i64 0}
!6904 = !{!"float32", !6905, i64 0}
!6905 = !{!"0x139e81b0", !8, i64 0}
!6906 = !{!6907, !6907, i64 0}
!6907 = !{!"float32", !6908, i64 0}
!6908 = !{!"0x83b4550", !8, i64 0}
!6909 = !{!6910, !6910, i64 0}
!6910 = !{!"0x1f340ce0.w1.b0", !6911, i64 0}
!6911 = !{!"0x1f340ce0.w2.b0", !6912, i64 0}
!6912 = !{!"0x1f340ce0.w4.b0", !6913, i64 0}
!6913 = !{!"0x1f340ce0.w8.b0", !6914, i64 0}
!6914 = !{!"0x1f340ce0.w16.b0", !6915, i64 0}
!6915 = !{!"0x1f340ce0.w32.b0", !6916, i64 0}
!6916 = !{!"0x1f340ce0.w64.b0", !6917, i64 0}
!6917 = !{!"0x1f340ce0.w128.b0", !6918, i64 0}
!6918 = !{!"0x1f340ce0.w256.b0", !6919, i64 0}
!6919 = !{!"0x1f340ce0.w512.b0", !6920, i64 0}
!6920 = !{!"0x1f340ce0.w1024.b0", !6921, i64 0}
!6921 = !{!"int32", !6922, i64 0}
!6922 = !{!"0x1f340ce0", !8, i64 0}
!6923 = !{!6924, !6924, i64 0}
!6924 = !{!"0x1f340ce0.w1.b1", !6911, i64 0}
!6925 = !{!6926, !6926, i64 0}
!6926 = !{!"0xa52f150.w1.b0", !6927, i64 0}
!6927 = !{!"0xa52f150.w2.b0", !6928, i64 0}
!6928 = !{!"0xa52f150.w4.b0", !6929, i64 0}
!6929 = !{!"0xa52f150.w8.b0", !6930, i64 0}
!6930 = !{!"0xa52f150.w16.b0", !6931, i64 0}
!6931 = !{!"0xa52f150.w32.b0", !6932, i64 0}
!6932 = !{!"0xa52f150.w64.b0", !6933, i64 0}
!6933 = !{!"0xa52f150.w128.b0", !6934, i64 0}
!6934 = !{!"0xa52f150.w256.b0", !6935, i64 0}
!6935 = !{!"0xa52f150.w512.b0", !6936, i64 0}
!6936 = !{!"0xa52f150.w1024.b0", !6937, i64 0}
!6937 = !{!"int64", !6938, i64 0}
!6938 = !{!"0xa52f150", !8, i64 0}
!6939 = !{!6940, !6940, i64 0}
!6940 = !{!"0xa52f150.w1.b1", !6927, i64 0}
!6941 = !{!6942, !6942, i64 0}
!6942 = !{!"0xa52f150.w1.b2", !6943, i64 0}
!6943 = !{!"0xa52f150.w2.b2", !6928, i64 0}
!6944 = !{!6945, !6945, i64 0}
!6945 = !{!"0xa52f150.w1.b3", !6943, i64 0}
!6946 = !{!6947, !6947, i64 0}
!6947 = !{!"0xa52f150.w1.b4", !6948, i64 0}
!6948 = !{!"0xa52f150.w2.b4", !6949, i64 0}
!6949 = !{!"0xa52f150.w4.b4", !6929, i64 0}
!6950 = !{!6951, !6951, i64 0}
!6951 = !{!"0xa52ec40.w4.b0", !6952, i64 0}
!6952 = !{!"0xa52ec40.w8.b0", !6953, i64 0}
!6953 = !{!"0xa52ec40.w16.b0", !6954, i64 0}
!6954 = !{!"0xa52ec40.w32.b0", !6955, i64 0}
!6955 = !{!"0xa52ec40.w64.b0", !6956, i64 0}
!6956 = !{!"0xa52ec40.w128.b0", !6957, i64 0}
!6957 = !{!"0xa52ec40.w256.b0", !6958, i64 0}
!6958 = !{!"0xa52ec40.w512.b0", !6959, i64 0}
!6959 = !{!"0xa52ec40.w1024.b0", !6960, i64 0}
!6960 = !{!"int64", !6961, i64 0}
!6961 = !{!"0xa52ec40", !8, i64 0}
!6962 = !{!6963, !6963, i64 0}
!6963 = !{!"0xa52ec40.w1.b4", !6964, i64 0}
!6964 = !{!"0xa52ec40.w2.b4", !6965, i64 0}
!6965 = !{!"0xa52ec40.w4.b4", !6952, i64 0}
!6966 = !{!6967, !6967, i64 0}
!6967 = !{!"0x1f320c80.w1.b0", !6968, i64 0}
!6968 = !{!"0x1f320c80.w2.b0", !6969, i64 0}
!6969 = !{!"0x1f320c80.w4.b0", !6970, i64 0}
!6970 = !{!"0x1f320c80.w8.b0", !6971, i64 0}
!6971 = !{!"0x1f320c80.w16.b0", !6972, i64 0}
!6972 = !{!"0x1f320c80.w32.b0", !6973, i64 0}
!6973 = !{!"0x1f320c80.w64.b0", !6974, i64 0}
!6974 = !{!"0x1f320c80.w128.b0", !6975, i64 0}
!6975 = !{!"0x1f320c80.w256.b0", !6976, i64 0}
!6976 = !{!"0x1f320c80.w512.b0", !6977, i64 0}
!6977 = !{!"0x1f320c80.w1024.b0", !6978, i64 0}
!6978 = !{!"int64", !6979, i64 0}
!6979 = !{!"0x1f320c80", !8, i64 0}
!6980 = !{!6981, !6981, i64 0}
!6981 = !{!"0x1f320c80.w1.b1", !6968, i64 0}
!6982 = !{!6983, !6983, i64 0}
!6983 = !{!"0x1f320c80.w1.b2", !6984, i64 0}
!6984 = !{!"0x1f320c80.w2.b2", !6969, i64 0}
!6985 = !{!6986, !6986, i64 0}
!6986 = !{!"0x1f320c80.w1.b3", !6984, i64 0}
!6987 = !{!6988, !6988, i64 0}
!6988 = !{!"0x1f320c80.w1.b4", !6989, i64 0}
!6989 = !{!"0x1f320c80.w2.b4", !6990, i64 0}
!6990 = !{!"0x1f320c80.w4.b4", !6970, i64 0}
!6991 = !{!6992, !6992, i64 0}
!6992 = !{!"0x1f321680.w4.b0", !6993, i64 0}
!6993 = !{!"0x1f321680.w8.b0", !6994, i64 0}
!6994 = !{!"0x1f321680.w16.b0", !6995, i64 0}
!6995 = !{!"0x1f321680.w32.b0", !6996, i64 0}
!6996 = !{!"0x1f321680.w64.b0", !6997, i64 0}
!6997 = !{!"0x1f321680.w128.b0", !6998, i64 0}
!6998 = !{!"0x1f321680.w256.b0", !6999, i64 0}
!6999 = !{!"0x1f321680.w512.b0", !7000, i64 0}
!7000 = !{!"0x1f321680.w1024.b0", !7001, i64 0}
!7001 = !{!"int64", !7002, i64 0}
!7002 = !{!"0x1f321680", !8, i64 0}
!7003 = !{!7004, !7004, i64 0}
!7004 = !{!"0x1f321680.w1.b4", !7005, i64 0}
!7005 = !{!"0x1f321680.w2.b4", !7006, i64 0}
!7006 = !{!"0x1f321680.w4.b4", !6993, i64 0}
!7007 = !{!7008, !7008, i64 0}
!7008 = !{!"float32", !7009, i64 0}
!7009 = !{!"0xa52e440", !8, i64 0}
!7010 = !{!7011, !7011, i64 0}
!7011 = !{!"float32", !7012, i64 0}
!7012 = !{!"0xa534330", !8, i64 0}
!7013 = !{!7014, !7014, i64 0}
!7014 = !{!"0x1368c090.w1.b0", !7015, i64 0}
!7015 = !{!"0x1368c090.w2.b0", !7016, i64 0}
!7016 = !{!"0x1368c090.w4.b0", !7017, i64 0}
!7017 = !{!"0x1368c090.w8.b0", !7018, i64 0}
!7018 = !{!"0x1368c090.w16.b0", !7019, i64 0}
!7019 = !{!"0x1368c090.w32.b0", !7020, i64 0}
!7020 = !{!"0x1368c090.w64.b0", !7021, i64 0}
!7021 = !{!"0x1368c090.w128.b0", !7022, i64 0}
!7022 = !{!"0x1368c090.w256.b0", !7023, i64 0}
!7023 = !{!"0x1368c090.w512.b0", !7024, i64 0}
!7024 = !{!"0x1368c090.w1024.b0", !7025, i64 0}
!7025 = !{!"int32", !7026, i64 0}
!7026 = !{!"0x1368c090", !8, i64 0}
!7027 = !{!7028, !7028, i64 0}
!7028 = !{!"0x1368c090.w1.b1", !7015, i64 0}
!7029 = !{!7030, !7030, i64 0}
!7030 = !{!"0x13b14fe0.w1.b0", !7031, i64 0}
!7031 = !{!"0x13b14fe0.w2.b0", !7032, i64 0}
!7032 = !{!"0x13b14fe0.w4.b0", !7033, i64 0}
!7033 = !{!"0x13b14fe0.w8.b0", !7034, i64 0}
!7034 = !{!"0x13b14fe0.w16.b0", !7035, i64 0}
!7035 = !{!"0x13b14fe0.w32.b0", !7036, i64 0}
!7036 = !{!"0x13b14fe0.w64.b0", !7037, i64 0}
!7037 = !{!"0x13b14fe0.w128.b0", !7038, i64 0}
!7038 = !{!"0x13b14fe0.w256.b0", !7039, i64 0}
!7039 = !{!"0x13b14fe0.w512.b0", !7040, i64 0}
!7040 = !{!"0x13b14fe0.w1024.b0", !7041, i64 0}
!7041 = !{!"int64", !7042, i64 0}
!7042 = !{!"0x13b14fe0", !8, i64 0}
!7043 = !{!7044, !7044, i64 0}
!7044 = !{!"0x13b14fe0.w1.b1", !7031, i64 0}
!7045 = !{!7046, !7046, i64 0}
!7046 = !{!"0x13b14fe0.w1.b2", !7047, i64 0}
!7047 = !{!"0x13b14fe0.w2.b2", !7032, i64 0}
!7048 = !{!7049, !7049, i64 0}
!7049 = !{!"0x13b14fe0.w1.b3", !7047, i64 0}
!7050 = !{!7051, !7051, i64 0}
!7051 = !{!"0x13b14fe0.w1.b4", !7052, i64 0}
!7052 = !{!"0x13b14fe0.w2.b4", !7053, i64 0}
!7053 = !{!"0x13b14fe0.w4.b4", !7033, i64 0}
!7054 = !{!7055, !7055, i64 0}
!7055 = !{!"0xcf09e80.w4.b0", !7056, i64 0}
!7056 = !{!"0xcf09e80.w8.b0", !7057, i64 0}
!7057 = !{!"0xcf09e80.w16.b0", !7058, i64 0}
!7058 = !{!"0xcf09e80.w32.b0", !7059, i64 0}
!7059 = !{!"0xcf09e80.w64.b0", !7060, i64 0}
!7060 = !{!"0xcf09e80.w128.b0", !7061, i64 0}
!7061 = !{!"0xcf09e80.w256.b0", !7062, i64 0}
!7062 = !{!"0xcf09e80.w512.b0", !7063, i64 0}
!7063 = !{!"0xcf09e80.w1024.b0", !7064, i64 0}
!7064 = !{!"int64", !7065, i64 0}
!7065 = !{!"0xcf09e80", !8, i64 0}
!7066 = !{!7067, !7067, i64 0}
!7067 = !{!"0xcf09e80.w1.b4", !7068, i64 0}
!7068 = !{!"0xcf09e80.w2.b4", !7069, i64 0}
!7069 = !{!"0xcf09e80.w4.b4", !7056, i64 0}
!7070 = !{!7071, !7071, i64 0}
!7071 = !{!"0xcf0b2a0.w1.b0", !7072, i64 0}
!7072 = !{!"0xcf0b2a0.w2.b0", !7073, i64 0}
!7073 = !{!"0xcf0b2a0.w4.b0", !7074, i64 0}
!7074 = !{!"0xcf0b2a0.w8.b0", !7075, i64 0}
!7075 = !{!"0xcf0b2a0.w16.b0", !7076, i64 0}
!7076 = !{!"0xcf0b2a0.w32.b0", !7077, i64 0}
!7077 = !{!"0xcf0b2a0.w64.b0", !7078, i64 0}
!7078 = !{!"0xcf0b2a0.w128.b0", !7079, i64 0}
!7079 = !{!"0xcf0b2a0.w256.b0", !7080, i64 0}
!7080 = !{!"0xcf0b2a0.w512.b0", !7081, i64 0}
!7081 = !{!"0xcf0b2a0.w1024.b0", !7082, i64 0}
!7082 = !{!"int64", !7083, i64 0}
!7083 = !{!"0xcf0b2a0", !8, i64 0}
!7084 = !{!7085, !7085, i64 0}
!7085 = !{!"0xcf0b2a0.w1.b1", !7072, i64 0}
!7086 = !{!7087, !7087, i64 0}
!7087 = !{!"0xcf0b2a0.w1.b2", !7088, i64 0}
!7088 = !{!"0xcf0b2a0.w2.b2", !7073, i64 0}
!7089 = !{!7090, !7090, i64 0}
!7090 = !{!"0xcf0b2a0.w1.b3", !7088, i64 0}
!7091 = !{!7092, !7092, i64 0}
!7092 = !{!"0xcf0b2a0.w1.b4", !7093, i64 0}
!7093 = !{!"0xcf0b2a0.w2.b4", !7094, i64 0}
!7094 = !{!"0xcf0b2a0.w4.b4", !7074, i64 0}
!7095 = !{!7096, !7096, i64 0}
!7096 = !{!"0x1f284f90.w4.b0", !7097, i64 0}
!7097 = !{!"0x1f284f90.w8.b0", !7098, i64 0}
!7098 = !{!"0x1f284f90.w16.b0", !7099, i64 0}
!7099 = !{!"0x1f284f90.w32.b0", !7100, i64 0}
!7100 = !{!"0x1f284f90.w64.b0", !7101, i64 0}
!7101 = !{!"0x1f284f90.w128.b0", !7102, i64 0}
!7102 = !{!"0x1f284f90.w256.b0", !7103, i64 0}
!7103 = !{!"0x1f284f90.w512.b0", !7104, i64 0}
!7104 = !{!"0x1f284f90.w1024.b0", !7105, i64 0}
!7105 = !{!"int64", !7106, i64 0}
!7106 = !{!"0x1f284f90", !8, i64 0}
!7107 = !{!7108, !7108, i64 0}
!7108 = !{!"0x1f284f90.w1.b4", !7109, i64 0}
!7109 = !{!"0x1f284f90.w2.b4", !7110, i64 0}
!7110 = !{!"0x1f284f90.w4.b4", !7097, i64 0}
!7111 = !{!7112, !7112, i64 0}
!7112 = !{!"float32", !7113, i64 0}
!7113 = !{!"0xf7f1cf0", !8, i64 0}
!7114 = !{!7115, !7115, i64 0}
!7115 = !{!"float32", !7116, i64 0}
!7116 = !{!"0x116a78d0", !8, i64 0}
!7117 = !{!7118, !7118, i64 0}
!7118 = !{!"0xcadf3c0.w1.b0", !7119, i64 0}
!7119 = !{!"0xcadf3c0.w2.b0", !7120, i64 0}
!7120 = !{!"0xcadf3c0.w4.b0", !7121, i64 0}
!7121 = !{!"0xcadf3c0.w8.b0", !7122, i64 0}
!7122 = !{!"0xcadf3c0.w16.b0", !7123, i64 0}
!7123 = !{!"0xcadf3c0.w32.b0", !7124, i64 0}
!7124 = !{!"0xcadf3c0.w64.b0", !7125, i64 0}
!7125 = !{!"0xcadf3c0.w128.b0", !7126, i64 0}
!7126 = !{!"0xcadf3c0.w256.b0", !7127, i64 0}
!7127 = !{!"0xcadf3c0.w512.b0", !7128, i64 0}
!7128 = !{!"0xcadf3c0.w1024.b0", !7129, i64 0}
!7129 = !{!"int32", !7130, i64 0}
!7130 = !{!"0xcadf3c0", !8, i64 0}
!7131 = !{!7132, !7132, i64 0}
!7132 = !{!"0xcadf3c0.w1.b1", !7119, i64 0}
!7133 = !{!7134, !7134, i64 0}
!7134 = !{!"0xcae01e0.w1.b0", !7135, i64 0}
!7135 = !{!"0xcae01e0.w2.b0", !7136, i64 0}
!7136 = !{!"0xcae01e0.w4.b0", !7137, i64 0}
!7137 = !{!"0xcae01e0.w8.b0", !7138, i64 0}
!7138 = !{!"0xcae01e0.w16.b0", !7139, i64 0}
!7139 = !{!"0xcae01e0.w32.b0", !7140, i64 0}
!7140 = !{!"0xcae01e0.w64.b0", !7141, i64 0}
!7141 = !{!"0xcae01e0.w128.b0", !7142, i64 0}
!7142 = !{!"0xcae01e0.w256.b0", !7143, i64 0}
!7143 = !{!"0xcae01e0.w512.b0", !7144, i64 0}
!7144 = !{!"0xcae01e0.w1024.b0", !7145, i64 0}
!7145 = !{!"int64", !7146, i64 0}
!7146 = !{!"0xcae01e0", !8, i64 0}
!7147 = !{!7148, !7148, i64 0}
!7148 = !{!"0xcae01e0.w1.b1", !7135, i64 0}
!7149 = !{!7150, !7150, i64 0}
!7150 = !{!"0xcae01e0.w1.b2", !7151, i64 0}
!7151 = !{!"0xcae01e0.w2.b2", !7136, i64 0}
!7152 = !{!7153, !7153, i64 0}
!7153 = !{!"0xcae01e0.w1.b3", !7151, i64 0}
!7154 = !{!7155, !7155, i64 0}
!7155 = !{!"0xcae01e0.w1.b4", !7156, i64 0}
!7156 = !{!"0xcae01e0.w2.b4", !7157, i64 0}
!7157 = !{!"0xcae01e0.w4.b4", !7137, i64 0}
!7158 = !{!7159, !7159, i64 0}
!7159 = !{!"0xcae1030.w4.b0", !7160, i64 0}
!7160 = !{!"0xcae1030.w8.b0", !7161, i64 0}
!7161 = !{!"0xcae1030.w16.b0", !7162, i64 0}
!7162 = !{!"0xcae1030.w32.b0", !7163, i64 0}
!7163 = !{!"0xcae1030.w64.b0", !7164, i64 0}
!7164 = !{!"0xcae1030.w128.b0", !7165, i64 0}
!7165 = !{!"0xcae1030.w256.b0", !7166, i64 0}
!7166 = !{!"0xcae1030.w512.b0", !7167, i64 0}
!7167 = !{!"0xcae1030.w1024.b0", !7168, i64 0}
!7168 = !{!"int64", !7169, i64 0}
!7169 = !{!"0xcae1030", !8, i64 0}
!7170 = !{!7171, !7171, i64 0}
!7171 = !{!"0xcae1030.w1.b4", !7172, i64 0}
!7172 = !{!"0xcae1030.w2.b4", !7173, i64 0}
!7173 = !{!"0xcae1030.w4.b4", !7160, i64 0}
!7174 = !{!7175, !7175, i64 0}
!7175 = !{!"0xcae2e10.w1.b0", !7176, i64 0}
!7176 = !{!"0xcae2e10.w2.b0", !7177, i64 0}
!7177 = !{!"0xcae2e10.w4.b0", !7178, i64 0}
!7178 = !{!"0xcae2e10.w8.b0", !7179, i64 0}
!7179 = !{!"0xcae2e10.w16.b0", !7180, i64 0}
!7180 = !{!"0xcae2e10.w32.b0", !7181, i64 0}
!7181 = !{!"0xcae2e10.w64.b0", !7182, i64 0}
!7182 = !{!"0xcae2e10.w128.b0", !7183, i64 0}
!7183 = !{!"0xcae2e10.w256.b0", !7184, i64 0}
!7184 = !{!"0xcae2e10.w512.b0", !7185, i64 0}
!7185 = !{!"0xcae2e10.w1024.b0", !7186, i64 0}
!7186 = !{!"int64", !7187, i64 0}
!7187 = !{!"0xcae2e10", !8, i64 0}
!7188 = !{!7189, !7189, i64 0}
!7189 = !{!"0xcae2e10.w1.b1", !7176, i64 0}
!7190 = !{!7191, !7191, i64 0}
!7191 = !{!"0xcae2e10.w1.b2", !7192, i64 0}
!7192 = !{!"0xcae2e10.w2.b2", !7177, i64 0}
!7193 = !{!7194, !7194, i64 0}
!7194 = !{!"0xcae2e10.w1.b3", !7192, i64 0}
!7195 = !{!7196, !7196, i64 0}
!7196 = !{!"0xcae3a10.w4.b0", !7197, i64 0}
!7197 = !{!"0xcae3a10.w8.b0", !7198, i64 0}
!7198 = !{!"0xcae3a10.w16.b0", !7199, i64 0}
!7199 = !{!"0xcae3a10.w32.b0", !7200, i64 0}
!7200 = !{!"0xcae3a10.w64.b0", !7201, i64 0}
!7201 = !{!"0xcae3a10.w128.b0", !7202, i64 0}
!7202 = !{!"0xcae3a10.w256.b0", !7203, i64 0}
!7203 = !{!"0xcae3a10.w512.b0", !7204, i64 0}
!7204 = !{!"0xcae3a10.w1024.b0", !7205, i64 0}
!7205 = !{!"int64", !7206, i64 0}
!7206 = !{!"0xcae3a10", !8, i64 0}
!7207 = !{!7208, !7208, i64 0}
!7208 = !{!"float32", !7209, i64 0}
!7209 = !{!"0xcad3600", !8, i64 0}
!7210 = !{!7211, !7211, i64 0}
!7211 = !{!"float32", !7212, i64 0}
!7212 = !{!"0xcad3760", !8, i64 0}
!7213 = !{!7214, !7214, i64 0}
!7214 = !{!"0xcf2c2c0.w1.b0", !7215, i64 0}
!7215 = !{!"0xcf2c2c0.w2.b0", !7216, i64 0}
!7216 = !{!"0xcf2c2c0.w4.b0", !7217, i64 0}
!7217 = !{!"0xcf2c2c0.w8.b0", !7218, i64 0}
!7218 = !{!"0xcf2c2c0.w16.b0", !7219, i64 0}
!7219 = !{!"0xcf2c2c0.w32.b0", !7220, i64 0}
!7220 = !{!"0xcf2c2c0.w64.b0", !7221, i64 0}
!7221 = !{!"0xcf2c2c0.w128.b0", !7222, i64 0}
!7222 = !{!"0xcf2c2c0.w256.b0", !7223, i64 0}
!7223 = !{!"0xcf2c2c0.w512.b0", !7224, i64 0}
!7224 = !{!"0xcf2c2c0.w1024.b0", !7225, i64 0}
!7225 = !{!"int32", !7226, i64 0}
!7226 = !{!"0xcf2c2c0", !8, i64 0}
!7227 = !{!7228, !7228, i64 0}
!7228 = !{!"0xcf2c2c0.w1.b1", !7215, i64 0}
!7229 = !{!7230, !7230, i64 0}
!7230 = !{!"0xcf2e080.w1.b0", !7231, i64 0}
!7231 = !{!"0xcf2e080.w2.b0", !7232, i64 0}
!7232 = !{!"0xcf2e080.w4.b0", !7233, i64 0}
!7233 = !{!"0xcf2e080.w8.b0", !7234, i64 0}
!7234 = !{!"0xcf2e080.w16.b0", !7235, i64 0}
!7235 = !{!"0xcf2e080.w32.b0", !7236, i64 0}
!7236 = !{!"0xcf2e080.w64.b0", !7237, i64 0}
!7237 = !{!"0xcf2e080.w128.b0", !7238, i64 0}
!7238 = !{!"0xcf2e080.w256.b0", !7239, i64 0}
!7239 = !{!"0xcf2e080.w512.b0", !7240, i64 0}
!7240 = !{!"0xcf2e080.w1024.b0", !7241, i64 0}
!7241 = !{!"int64", !7242, i64 0}
!7242 = !{!"0xcf2e080", !8, i64 0}
!7243 = !{!7244, !7244, i64 0}
!7244 = !{!"0xcf2e080.w1.b1", !7231, i64 0}
!7245 = !{!7246, !7246, i64 0}
!7246 = !{!"0xcf2e080.w1.b2", !7247, i64 0}
!7247 = !{!"0xcf2e080.w2.b2", !7232, i64 0}
!7248 = !{!7249, !7249, i64 0}
!7249 = !{!"0xcf2e080.w1.b3", !7247, i64 0}
!7250 = !{!7251, !7251, i64 0}
!7251 = !{!"0xcf2e080.w1.b4", !7252, i64 0}
!7252 = !{!"0xcf2e080.w2.b4", !7253, i64 0}
!7253 = !{!"0xcf2e080.w4.b4", !7233, i64 0}
!7254 = !{!7255, !7255, i64 0}
!7255 = !{!"0xcf33d10.w4.b0", !7256, i64 0}
!7256 = !{!"0xcf33d10.w8.b0", !7257, i64 0}
!7257 = !{!"0xcf33d10.w16.b0", !7258, i64 0}
!7258 = !{!"0xcf33d10.w32.b0", !7259, i64 0}
!7259 = !{!"0xcf33d10.w64.b0", !7260, i64 0}
!7260 = !{!"0xcf33d10.w128.b0", !7261, i64 0}
!7261 = !{!"0xcf33d10.w256.b0", !7262, i64 0}
!7262 = !{!"0xcf33d10.w512.b0", !7263, i64 0}
!7263 = !{!"0xcf33d10.w1024.b0", !7264, i64 0}
!7264 = !{!"int64", !7265, i64 0}
!7265 = !{!"0xcf33d10", !8, i64 0}
!7266 = !{!7267, !7267, i64 0}
!7267 = !{!"0xcf33d10.w1.b4", !7268, i64 0}
!7268 = !{!"0xcf33d10.w2.b4", !7269, i64 0}
!7269 = !{!"0xcf33d10.w4.b4", !7256, i64 0}
!7270 = !{!7271, !7271, i64 0}
!7271 = !{!"0xcf35af0.w1.b0", !7272, i64 0}
!7272 = !{!"0xcf35af0.w2.b0", !7273, i64 0}
!7273 = !{!"0xcf35af0.w4.b0", !7274, i64 0}
!7274 = !{!"0xcf35af0.w8.b0", !7275, i64 0}
!7275 = !{!"0xcf35af0.w16.b0", !7276, i64 0}
!7276 = !{!"0xcf35af0.w32.b0", !7277, i64 0}
!7277 = !{!"0xcf35af0.w64.b0", !7278, i64 0}
!7278 = !{!"0xcf35af0.w128.b0", !7279, i64 0}
!7279 = !{!"0xcf35af0.w256.b0", !7280, i64 0}
!7280 = !{!"0xcf35af0.w512.b0", !7281, i64 0}
!7281 = !{!"0xcf35af0.w1024.b0", !7282, i64 0}
!7282 = !{!"int64", !7283, i64 0}
!7283 = !{!"0xcf35af0", !8, i64 0}
!7284 = !{!7285, !7285, i64 0}
!7285 = !{!"0xcf35af0.w1.b1", !7272, i64 0}
!7286 = !{!7287, !7287, i64 0}
!7287 = !{!"0xcf35af0.w1.b2", !7288, i64 0}
!7288 = !{!"0xcf35af0.w2.b2", !7273, i64 0}
!7289 = !{!7290, !7290, i64 0}
!7290 = !{!"0xcf35af0.w1.b3", !7288, i64 0}
!7291 = !{!7292, !7292, i64 0}
!7292 = !{!"0xcf35af0.w1.b4", !7293, i64 0}
!7293 = !{!"0xcf35af0.w2.b4", !7294, i64 0}
!7294 = !{!"0xcf35af0.w4.b4", !7274, i64 0}
!7295 = !{!7296, !7296, i64 0}
!7296 = !{!"0xcf36760.w4.b0", !7297, i64 0}
!7297 = !{!"0xcf36760.w8.b0", !7298, i64 0}
!7298 = !{!"0xcf36760.w16.b0", !7299, i64 0}
!7299 = !{!"0xcf36760.w32.b0", !7300, i64 0}
!7300 = !{!"0xcf36760.w64.b0", !7301, i64 0}
!7301 = !{!"0xcf36760.w128.b0", !7302, i64 0}
!7302 = !{!"0xcf36760.w256.b0", !7303, i64 0}
!7303 = !{!"0xcf36760.w512.b0", !7304, i64 0}
!7304 = !{!"0xcf36760.w1024.b0", !7305, i64 0}
!7305 = !{!"int64", !7306, i64 0}
!7306 = !{!"0xcf36760", !8, i64 0}
!7307 = !{!7308, !7308, i64 0}
!7308 = !{!"0xcf36760.w1.b4", !7309, i64 0}
!7309 = !{!"0xcf36760.w2.b4", !7310, i64 0}
!7310 = !{!"0xcf36760.w4.b4", !7297, i64 0}
!7311 = !{!7312, !7312, i64 0}
!7312 = !{!"float32", !7313, i64 0}
!7313 = !{!"0x1f3303b0", !8, i64 0}
!7314 = !{!7315, !7315, i64 0}
!7315 = !{!"float32", !7316, i64 0}
!7316 = !{!"0xcf2f600", !8, i64 0}
!7317 = !{!7318, !7318, i64 0}
!7318 = !{!"0xf73f300.w1.b0", !7319, i64 0}
!7319 = !{!"0xf73f300.w2.b0", !7320, i64 0}
!7320 = !{!"0xf73f300.w4.b0", !7321, i64 0}
!7321 = !{!"0xf73f300.w8.b0", !7322, i64 0}
!7322 = !{!"0xf73f300.w16.b0", !7323, i64 0}
!7323 = !{!"0xf73f300.w32.b0", !7324, i64 0}
!7324 = !{!"0xf73f300.w64.b0", !7325, i64 0}
!7325 = !{!"0xf73f300.w128.b0", !7326, i64 0}
!7326 = !{!"0xf73f300.w256.b0", !7327, i64 0}
!7327 = !{!"0xf73f300.w512.b0", !7328, i64 0}
!7328 = !{!"0xf73f300.w1024.b0", !7329, i64 0}
!7329 = !{!"int32", !7330, i64 0}
!7330 = !{!"0xf73f300", !8, i64 0}
!7331 = !{!7332, !7332, i64 0}
!7332 = !{!"0xf73f300.w1.b1", !7319, i64 0}
!7333 = !{!7334, !7334, i64 0}
!7334 = !{!"0x139b7ea0.w1.b0", !7335, i64 0}
!7335 = !{!"0x139b7ea0.w2.b0", !7336, i64 0}
!7336 = !{!"0x139b7ea0.w4.b0", !7337, i64 0}
!7337 = !{!"0x139b7ea0.w8.b0", !7338, i64 0}
!7338 = !{!"0x139b7ea0.w16.b0", !7339, i64 0}
!7339 = !{!"0x139b7ea0.w32.b0", !7340, i64 0}
!7340 = !{!"0x139b7ea0.w64.b0", !7341, i64 0}
!7341 = !{!"0x139b7ea0.w128.b0", !7342, i64 0}
!7342 = !{!"0x139b7ea0.w256.b0", !7343, i64 0}
!7343 = !{!"0x139b7ea0.w512.b0", !7344, i64 0}
!7344 = !{!"0x139b7ea0.w1024.b0", !7345, i64 0}
!7345 = !{!"int64", !7346, i64 0}
!7346 = !{!"0x139b7ea0", !8, i64 0}
!7347 = !{!7348, !7348, i64 0}
!7348 = !{!"0x139b7ea0.w1.b1", !7335, i64 0}
!7349 = !{!7350, !7350, i64 0}
!7350 = !{!"0x139bd400.w1.b0", !7351, i64 0}
!7351 = !{!"0x139bd400.w2.b0", !7352, i64 0}
!7352 = !{!"0x139bd400.w4.b0", !7353, i64 0}
!7353 = !{!"0x139bd400.w8.b0", !7354, i64 0}
!7354 = !{!"0x139bd400.w16.b0", !7355, i64 0}
!7355 = !{!"0x139bd400.w32.b0", !7356, i64 0}
!7356 = !{!"0x139bd400.w64.b0", !7357, i64 0}
!7357 = !{!"0x139bd400.w128.b0", !7358, i64 0}
!7358 = !{!"0x139bd400.w256.b0", !7359, i64 0}
!7359 = !{!"0x139bd400.w512.b0", !7360, i64 0}
!7360 = !{!"0x139bd400.w1024.b0", !7361, i64 0}
!7361 = !{!"int64", !7362, i64 0}
!7362 = !{!"0x139bd400", !8, i64 0}
!7363 = !{!7364, !7364, i64 0}
!7364 = !{!"0x139bd400.w1.b1", !7351, i64 0}
!7365 = !{!7366, !7366, i64 0}
!7366 = !{!"0x139d2d90.w1.b0", !7367, i64 0}
!7367 = !{!"0x139d2d90.w2.b0", !7368, i64 0}
!7368 = !{!"0x139d2d90.w4.b0", !7369, i64 0}
!7369 = !{!"0x139d2d90.w8.b0", !7370, i64 0}
!7370 = !{!"0x139d2d90.w16.b0", !7371, i64 0}
!7371 = !{!"0x139d2d90.w32.b0", !7372, i64 0}
!7372 = !{!"0x139d2d90.w64.b0", !7373, i64 0}
!7373 = !{!"0x139d2d90.w128.b0", !7374, i64 0}
!7374 = !{!"0x139d2d90.w256.b0", !7375, i64 0}
!7375 = !{!"0x139d2d90.w512.b0", !7376, i64 0}
!7376 = !{!"0x139d2d90.w1024.b0", !7377, i64 0}
!7377 = !{!"int64", !7378, i64 0}
!7378 = !{!"0x139d2d90", !8, i64 0}
!7379 = !{!7380, !7380, i64 0}
!7380 = !{!"0x139d2d90.w1.b1", !7367, i64 0}
!7381 = !{!7382, !7382, i64 0}
!7382 = !{!"0xf7a1ad0.w1.b0", !7383, i64 0}
!7383 = !{!"0xf7a1ad0.w2.b0", !7384, i64 0}
!7384 = !{!"0xf7a1ad0.w4.b0", !7385, i64 0}
!7385 = !{!"0xf7a1ad0.w8.b0", !7386, i64 0}
!7386 = !{!"0xf7a1ad0.w16.b0", !7387, i64 0}
!7387 = !{!"0xf7a1ad0.w32.b0", !7388, i64 0}
!7388 = !{!"0xf7a1ad0.w64.b0", !7389, i64 0}
!7389 = !{!"0xf7a1ad0.w128.b0", !7390, i64 0}
!7390 = !{!"0xf7a1ad0.w256.b0", !7391, i64 0}
!7391 = !{!"0xf7a1ad0.w512.b0", !7392, i64 0}
!7392 = !{!"0xf7a1ad0.w1024.b0", !7393, i64 0}
!7393 = !{!"int64", !7394, i64 0}
!7394 = !{!"0xf7a1ad0", !8, i64 0}
!7395 = !{!7396, !7396, i64 0}
!7396 = !{!"0xf7a1ad0.w1.b1", !7383, i64 0}
!7397 = !{!7398, !7398, i64 0}
!7398 = !{!"float32", !7399, i64 0}
!7399 = !{!"0x13b2d2b0", !8, i64 0}
!7400 = !{!7401, !7401, i64 0}
!7401 = !{!"float32", !7402, i64 0}
!7402 = !{!"0x13af39b0", !8, i64 0}
!7403 = distinct !{!7403, !1123}
!7404 = !{!7405, !7405, i64 0}
!7405 = !{!"float32", !7406, i64 0}
!7406 = !{!"0x1f2ab600", !8, i64 0}
!7407 = distinct !{!7407, !1123}
!7408 = !{!7409, !7409, i64 0}
!7409 = !{!"0x1f338570.w1.b0", !7410, i64 0}
!7410 = !{!"0x1f338570.w2.b0", !7411, i64 0}
!7411 = !{!"0x1f338570.w4.b0", !7412, i64 0}
!7412 = !{!"0x1f338570.w8.b0", !7413, i64 0}
!7413 = !{!"0x1f338570.w16.b0", !7414, i64 0}
!7414 = !{!"0x1f338570.w32.b0", !7415, i64 0}
!7415 = !{!"0x1f338570.w64.b0", !7416, i64 0}
!7416 = !{!"0x1f338570.w128.b0", !7417, i64 0}
!7417 = !{!"0x1f338570.w256.b0", !7418, i64 0}
!7418 = !{!"0x1f338570.w512.b0", !7419, i64 0}
!7419 = !{!"0x1f338570.w1024.b0", !7420, i64 0}
!7420 = !{!"int32", !7421, i64 0}
!7421 = !{!"0x1f338570", !8, i64 0}
!7422 = !{!7423, !7423, i64 0}
!7423 = !{!"0x1f338570.w1.b2", !7424, i64 0}
!7424 = !{!"0x1f338570.w2.b2", !7411, i64 0}
!7425 = !{!7426, !7426, i64 0}
!7426 = !{!"0x1f338570.w1.b3", !7424, i64 0}
!7427 = !{!7428, !7428, i64 0}
!7428 = !{!"0x1f338570.w1.b4", !7429, i64 0}
!7429 = !{!"0x1f338570.w2.b4", !7430, i64 0}
!7430 = !{!"0x1f338570.w4.b4", !7412, i64 0}
!7431 = !{!7432, !7432, i64 0}
!7432 = !{!"0x1f338570.w1.b5", !7429, i64 0}
!7433 = !{!7434, !7434, i64 0}
!7434 = !{!"0x1f338570.w1.b6", !7435, i64 0}
!7435 = !{!"0x1f338570.w2.b6", !7430, i64 0}
!7436 = !{!7437, !7437, i64 0}
!7437 = !{!"0x1f338570.w1.b1", !7410, i64 0}
!7438 = !{!7439, !7439, i64 0}
!7439 = !{!"0x1f337970.w1.b0", !7440, i64 0}
!7440 = !{!"0x1f337970.w2.b0", !7441, i64 0}
!7441 = !{!"0x1f337970.w4.b0", !7442, i64 0}
!7442 = !{!"0x1f337970.w8.b0", !7443, i64 0}
!7443 = !{!"0x1f337970.w16.b0", !7444, i64 0}
!7444 = !{!"0x1f337970.w32.b0", !7445, i64 0}
!7445 = !{!"0x1f337970.w64.b0", !7446, i64 0}
!7446 = !{!"0x1f337970.w128.b0", !7447, i64 0}
!7447 = !{!"0x1f337970.w256.b0", !7448, i64 0}
!7448 = !{!"0x1f337970.w512.b0", !7449, i64 0}
!7449 = !{!"0x1f337970.w1024.b0", !7450, i64 0}
!7450 = !{!"int64", !7451, i64 0}
!7451 = !{!"0x1f337970", !8, i64 0}
!7452 = !{!7453, !7453, i64 0}
!7453 = !{!"0x1f337970.w1.b1", !7440, i64 0}
!7454 = !{!7455, !7455, i64 0}
!7455 = !{!"0x1f337970.w1.b2", !7456, i64 0}
!7456 = !{!"0x1f337970.w2.b2", !7441, i64 0}
!7457 = !{!7458, !7458, i64 0}
!7458 = !{!"0x1f337970.w1.b3", !7456, i64 0}
!7459 = !{!7460, !7460, i64 0}
!7460 = !{!"0x1f337970.w1.b4", !7461, i64 0}
!7461 = !{!"0x1f337970.w2.b4", !7462, i64 0}
!7462 = !{!"0x1f337970.w4.b4", !7442, i64 0}
!7463 = !{!7464, !7464, i64 0}
!7464 = !{!"0x1f33a3e0.w4.b0", !7465, i64 0}
!7465 = !{!"0x1f33a3e0.w8.b0", !7466, i64 0}
!7466 = !{!"0x1f33a3e0.w16.b0", !7467, i64 0}
!7467 = !{!"0x1f33a3e0.w32.b0", !7468, i64 0}
!7468 = !{!"0x1f33a3e0.w64.b0", !7469, i64 0}
!7469 = !{!"0x1f33a3e0.w128.b0", !7470, i64 0}
!7470 = !{!"0x1f33a3e0.w256.b0", !7471, i64 0}
!7471 = !{!"0x1f33a3e0.w512.b0", !7472, i64 0}
!7472 = !{!"0x1f33a3e0.w1024.b0", !7473, i64 0}
!7473 = !{!"int64", !7474, i64 0}
!7474 = !{!"0x1f33a3e0", !8, i64 0}
!7475 = !{!7476, !7476, i64 0}
!7476 = !{!"0x1f33a3e0.w1.b4", !7477, i64 0}
!7477 = !{!"0x1f33a3e0.w2.b4", !7478, i64 0}
!7478 = !{!"0x1f33a3e0.w4.b4", !7465, i64 0}
!7479 = !{!7480, !7480, i64 0}
!7480 = !{!"0x1f33b930.w1.b0", !7481, i64 0}
!7481 = !{!"0x1f33b930.w2.b0", !7482, i64 0}
!7482 = !{!"0x1f33b930.w4.b0", !7483, i64 0}
!7483 = !{!"0x1f33b930.w8.b0", !7484, i64 0}
!7484 = !{!"0x1f33b930.w16.b0", !7485, i64 0}
!7485 = !{!"0x1f33b930.w32.b0", !7486, i64 0}
!7486 = !{!"0x1f33b930.w64.b0", !7487, i64 0}
!7487 = !{!"0x1f33b930.w128.b0", !7488, i64 0}
!7488 = !{!"0x1f33b930.w256.b0", !7489, i64 0}
!7489 = !{!"0x1f33b930.w512.b0", !7490, i64 0}
!7490 = !{!"0x1f33b930.w1024.b0", !7491, i64 0}
!7491 = !{!"int64", !7492, i64 0}
!7492 = !{!"0x1f33b930", !8, i64 0}
!7493 = !{!7494, !7494, i64 0}
!7494 = !{!"0x1f33b930.w1.b1", !7481, i64 0}
!7495 = !{!7496, !7496, i64 0}
!7496 = !{!"0x1f33b930.w1.b2", !7497, i64 0}
!7497 = !{!"0x1f33b930.w2.b2", !7482, i64 0}
!7498 = !{!7499, !7499, i64 0}
!7499 = !{!"0x1f33b930.w1.b3", !7497, i64 0}
!7500 = !{!7501, !7501, i64 0}
!7501 = !{!"0x1f33b930.w1.b4", !7502, i64 0}
!7502 = !{!"0x1f33b930.w2.b4", !7503, i64 0}
!7503 = !{!"0x1f33b930.w4.b4", !7483, i64 0}
!7504 = !{!7505, !7505, i64 0}
!7505 = !{!"0x1f33b930.w1.b5", !7502, i64 0}
!7506 = !{!7507, !7507, i64 0}
!7507 = !{!"0x1f33c310.w4.b0", !7508, i64 0}
!7508 = !{!"0x1f33c310.w8.b0", !7509, i64 0}
!7509 = !{!"0x1f33c310.w16.b0", !7510, i64 0}
!7510 = !{!"0x1f33c310.w32.b0", !7511, i64 0}
!7511 = !{!"0x1f33c310.w64.b0", !7512, i64 0}
!7512 = !{!"0x1f33c310.w128.b0", !7513, i64 0}
!7513 = !{!"0x1f33c310.w256.b0", !7514, i64 0}
!7514 = !{!"0x1f33c310.w512.b0", !7515, i64 0}
!7515 = !{!"0x1f33c310.w1024.b0", !7516, i64 0}
!7516 = !{!"int64", !7517, i64 0}
!7517 = !{!"0x1f33c310", !8, i64 0}
!7518 = !{!7519, !7519, i64 0}
!7519 = !{!"0x1f33c310.w1.b4", !7520, i64 0}
!7520 = !{!"0x1f33c310.w2.b4", !7521, i64 0}
!7521 = !{!"0x1f33c310.w4.b4", !7508, i64 0}
!7522 = !{!7523, !7523, i64 0}
!7523 = !{!"0x1f33c310.w1.b5", !7520, i64 0}
!7524 = !{!7525, !7525, i64 0}
!7525 = !{!"0xcf23960.w1.b0", !7526, i64 0}
!7526 = !{!"0xcf23960.w2.b0", !7527, i64 0}
!7527 = !{!"0xcf23960.w4.b0", !7528, i64 0}
!7528 = !{!"0xcf23960.w8.b0", !7529, i64 0}
!7529 = !{!"0xcf23960.w16.b0", !7530, i64 0}
!7530 = !{!"0xcf23960.w32.b0", !7531, i64 0}
!7531 = !{!"0xcf23960.w64.b0", !7532, i64 0}
!7532 = !{!"0xcf23960.w128.b0", !7533, i64 0}
!7533 = !{!"0xcf23960.w256.b0", !7534, i64 0}
!7534 = !{!"0xcf23960.w512.b0", !7535, i64 0}
!7535 = !{!"0xcf23960.w1024.b0", !7536, i64 0}
!7536 = !{!"int64", !7537, i64 0}
!7537 = !{!"0xcf23960", !8, i64 0}
!7538 = !{!7539, !7539, i64 0}
!7539 = !{!"0xcf23960.w1.b1", !7526, i64 0}
!7540 = !{!7541, !7541, i64 0}
!7541 = !{!"0xcf23960.w1.b2", !7542, i64 0}
!7542 = !{!"0xcf23960.w2.b2", !7527, i64 0}
!7543 = !{!7544, !7544, i64 0}
!7544 = !{!"0xcf23960.w1.b3", !7542, i64 0}
!7545 = !{!7546, !7546, i64 0}
!7546 = !{!"0x1f3346e0.w4.b0", !7547, i64 0}
!7547 = !{!"0x1f3346e0.w8.b0", !7548, i64 0}
!7548 = !{!"0x1f3346e0.w16.b0", !7549, i64 0}
!7549 = !{!"0x1f3346e0.w32.b0", !7550, i64 0}
!7550 = !{!"0x1f3346e0.w64.b0", !7551, i64 0}
!7551 = !{!"0x1f3346e0.w128.b0", !7552, i64 0}
!7552 = !{!"0x1f3346e0.w256.b0", !7553, i64 0}
!7553 = !{!"0x1f3346e0.w512.b0", !7554, i64 0}
!7554 = !{!"0x1f3346e0.w1024.b0", !7555, i64 0}
!7555 = !{!"int64", !7556, i64 0}
!7556 = !{!"0x1f3346e0", !8, i64 0}
!7557 = !{!7558, !7558, i64 0}
!7558 = !{!"0x1f33b2c0.w1.b0", !7559, i64 0}
!7559 = !{!"0x1f33b2c0.w2.b0", !7560, i64 0}
!7560 = !{!"0x1f33b2c0.w4.b0", !7561, i64 0}
!7561 = !{!"0x1f33b2c0.w8.b0", !7562, i64 0}
!7562 = !{!"0x1f33b2c0.w16.b0", !7563, i64 0}
!7563 = !{!"0x1f33b2c0.w32.b0", !7564, i64 0}
!7564 = !{!"0x1f33b2c0.w64.b0", !7565, i64 0}
!7565 = !{!"0x1f33b2c0.w128.b0", !7566, i64 0}
!7566 = !{!"0x1f33b2c0.w256.b0", !7567, i64 0}
!7567 = !{!"0x1f33b2c0.w512.b0", !7568, i64 0}
!7568 = !{!"0x1f33b2c0.w1024.b0", !7569, i64 0}
!7569 = !{!"int64", !7570, i64 0}
!7570 = !{!"0x1f33b2c0", !8, i64 0}
!7571 = !{!7572, !7572, i64 0}
!7572 = !{!"0x1f33b2c0.w1.b1", !7559, i64 0}
!7573 = !{!7574, !7574, i64 0}
!7574 = !{!"0x1f33b2c0.w1.b2", !7575, i64 0}
!7575 = !{!"0x1f33b2c0.w2.b2", !7560, i64 0}
!7576 = !{!7577, !7577, i64 0}
!7577 = !{!"0x1f33b2c0.w1.b3", !7575, i64 0}
!7578 = !{!7579, !7579, i64 0}
!7579 = !{!"0xcf26f10.w4.b0", !7580, i64 0}
!7580 = !{!"0xcf26f10.w8.b0", !7581, i64 0}
!7581 = !{!"0xcf26f10.w16.b0", !7582, i64 0}
!7582 = !{!"0xcf26f10.w32.b0", !7583, i64 0}
!7583 = !{!"0xcf26f10.w64.b0", !7584, i64 0}
!7584 = !{!"0xcf26f10.w128.b0", !7585, i64 0}
!7585 = !{!"0xcf26f10.w256.b0", !7586, i64 0}
!7586 = !{!"0xcf26f10.w512.b0", !7587, i64 0}
!7587 = !{!"0xcf26f10.w1024.b0", !7588, i64 0}
!7588 = !{!"int64", !7589, i64 0}
!7589 = !{!"0xcf26f10", !8, i64 0}
!7590 = !{!7591, !7591, i64 0}
!7591 = !{!"0xcf27e00.w1.b0", !7592, i64 0}
!7592 = !{!"0xcf27e00.w2.b0", !7593, i64 0}
!7593 = !{!"0xcf27e00.w4.b0", !7594, i64 0}
!7594 = !{!"0xcf27e00.w8.b0", !7595, i64 0}
!7595 = !{!"0xcf27e00.w16.b0", !7596, i64 0}
!7596 = !{!"0xcf27e00.w32.b0", !7597, i64 0}
!7597 = !{!"0xcf27e00.w64.b0", !7598, i64 0}
!7598 = !{!"0xcf27e00.w128.b0", !7599, i64 0}
!7599 = !{!"0xcf27e00.w256.b0", !7600, i64 0}
!7600 = !{!"0xcf27e00.w512.b0", !7601, i64 0}
!7601 = !{!"0xcf27e00.w1024.b0", !7602, i64 0}
!7602 = !{!"int64", !7603, i64 0}
!7603 = !{!"0xcf27e00", !8, i64 0}
!7604 = !{!7605, !7605, i64 0}
!7605 = !{!"0xcf27e00.w1.b1", !7592, i64 0}
!7606 = !{!7607, !7607, i64 0}
!7607 = !{!"0xcf27e00.w1.b2", !7608, i64 0}
!7608 = !{!"0xcf27e00.w2.b2", !7593, i64 0}
!7609 = !{!7610, !7610, i64 0}
!7610 = !{!"0xcf27e00.w1.b3", !7608, i64 0}
!7611 = !{!7612, !7612, i64 0}
!7612 = !{!"0xcf29a50.w4.b0", !7613, i64 0}
!7613 = !{!"0xcf29a50.w8.b0", !7614, i64 0}
!7614 = !{!"0xcf29a50.w16.b0", !7615, i64 0}
!7615 = !{!"0xcf29a50.w32.b0", !7616, i64 0}
!7616 = !{!"0xcf29a50.w64.b0", !7617, i64 0}
!7617 = !{!"0xcf29a50.w128.b0", !7618, i64 0}
!7618 = !{!"0xcf29a50.w256.b0", !7619, i64 0}
!7619 = !{!"0xcf29a50.w512.b0", !7620, i64 0}
!7620 = !{!"0xcf29a50.w1024.b0", !7621, i64 0}
!7621 = !{!"int64", !7622, i64 0}
!7622 = !{!"0xcf29a50", !8, i64 0}
!7623 = !{!7624, !7624, i64 0}
!7624 = !{!"0xcf2bae0.w1.b0", !7625, i64 0}
!7625 = !{!"0xcf2bae0.w2.b0", !7626, i64 0}
!7626 = !{!"0xcf2bae0.w4.b0", !7627, i64 0}
!7627 = !{!"0xcf2bae0.w8.b0", !7628, i64 0}
!7628 = !{!"0xcf2bae0.w16.b0", !7629, i64 0}
!7629 = !{!"0xcf2bae0.w32.b0", !7630, i64 0}
!7630 = !{!"0xcf2bae0.w64.b0", !7631, i64 0}
!7631 = !{!"0xcf2bae0.w128.b0", !7632, i64 0}
!7632 = !{!"0xcf2bae0.w256.b0", !7633, i64 0}
!7633 = !{!"0xcf2bae0.w512.b0", !7634, i64 0}
!7634 = !{!"0xcf2bae0.w1024.b0", !7635, i64 0}
!7635 = !{!"int64", !7636, i64 0}
!7636 = !{!"0xcf2bae0", !8, i64 0}
!7637 = !{!7638, !7638, i64 0}
!7638 = !{!"0xcf2bae0.w1.b1", !7625, i64 0}
!7639 = !{!7640, !7640, i64 0}
!7640 = !{!"0xcf2bae0.w1.b2", !7641, i64 0}
!7641 = !{!"0xcf2bae0.w2.b2", !7626, i64 0}
!7642 = !{!7643, !7643, i64 0}
!7643 = !{!"0xcf2bae0.w1.b3", !7641, i64 0}
!7644 = !{!7645, !7645, i64 0}
!7645 = !{!"0xcf2bae0.w1.b4", !7646, i64 0}
!7646 = !{!"0xcf2bae0.w2.b4", !7647, i64 0}
!7647 = !{!"0xcf2bae0.w4.b4", !7627, i64 0}
!7648 = !{!7649, !7649, i64 0}
!7649 = !{!"0xcf2c880.w4.b0", !7650, i64 0}
!7650 = !{!"0xcf2c880.w8.b0", !7651, i64 0}
!7651 = !{!"0xcf2c880.w16.b0", !7652, i64 0}
!7652 = !{!"0xcf2c880.w32.b0", !7653, i64 0}
!7653 = !{!"0xcf2c880.w64.b0", !7654, i64 0}
!7654 = !{!"0xcf2c880.w128.b0", !7655, i64 0}
!7655 = !{!"0xcf2c880.w256.b0", !7656, i64 0}
!7656 = !{!"0xcf2c880.w512.b0", !7657, i64 0}
!7657 = !{!"0xcf2c880.w1024.b0", !7658, i64 0}
!7658 = !{!"int64", !7659, i64 0}
!7659 = !{!"0xcf2c880", !8, i64 0}
!7660 = !{!7661, !7661, i64 0}
!7661 = !{!"0xcf2c880.w1.b4", !7662, i64 0}
!7662 = !{!"0xcf2c880.w2.b4", !7663, i64 0}
!7663 = !{!"0xcf2c880.w4.b4", !7650, i64 0}
!7664 = !{!7665, !7665, i64 0}
!7665 = !{!"0xcf238e0.w1.b0", !7666, i64 0}
!7666 = !{!"0xcf238e0.w2.b0", !7667, i64 0}
!7667 = !{!"0xcf238e0.w4.b0", !7668, i64 0}
!7668 = !{!"0xcf238e0.w8.b0", !7669, i64 0}
!7669 = !{!"0xcf238e0.w16.b0", !7670, i64 0}
!7670 = !{!"0xcf238e0.w32.b0", !7671, i64 0}
!7671 = !{!"0xcf238e0.w64.b0", !7672, i64 0}
!7672 = !{!"0xcf238e0.w128.b0", !7673, i64 0}
!7673 = !{!"0xcf238e0.w256.b0", !7674, i64 0}
!7674 = !{!"0xcf238e0.w512.b0", !7675, i64 0}
!7675 = !{!"0xcf238e0.w1024.b0", !7676, i64 0}
!7676 = !{!"int64", !7677, i64 0}
!7677 = !{!"0xcf238e0", !8, i64 0}
!7678 = !{!7679, !7679, i64 0}
!7679 = !{!"0xcf238e0.w1.b1", !7666, i64 0}
!7680 = !{!7681, !7681, i64 0}
!7681 = !{!"0xcf238e0.w1.b2", !7682, i64 0}
!7682 = !{!"0xcf238e0.w2.b2", !7667, i64 0}
!7683 = !{!7684, !7684, i64 0}
!7684 = !{!"0xcf238e0.w1.b3", !7682, i64 0}
!7685 = !{!7686, !7686, i64 0}
!7686 = !{!"0xcf238e0.w1.b4", !7687, i64 0}
!7687 = !{!"0xcf238e0.w2.b4", !7688, i64 0}
!7688 = !{!"0xcf238e0.w4.b4", !7668, i64 0}
!7689 = !{!7690, !7690, i64 0}
!7690 = !{!"0xcf2fb60.w4.b0", !7691, i64 0}
!7691 = !{!"0xcf2fb60.w8.b0", !7692, i64 0}
!7692 = !{!"0xcf2fb60.w16.b0", !7693, i64 0}
!7693 = !{!"0xcf2fb60.w32.b0", !7694, i64 0}
!7694 = !{!"0xcf2fb60.w64.b0", !7695, i64 0}
!7695 = !{!"0xcf2fb60.w128.b0", !7696, i64 0}
!7696 = !{!"0xcf2fb60.w256.b0", !7697, i64 0}
!7697 = !{!"0xcf2fb60.w512.b0", !7698, i64 0}
!7698 = !{!"0xcf2fb60.w1024.b0", !7699, i64 0}
!7699 = !{!"int64", !7700, i64 0}
!7700 = !{!"0xcf2fb60", !8, i64 0}
!7701 = !{!7702, !7702, i64 0}
!7702 = !{!"0xcf2fb60.w1.b4", !7703, i64 0}
!7703 = !{!"0xcf2fb60.w2.b4", !7704, i64 0}
!7704 = !{!"0xcf2fb60.w4.b4", !7691, i64 0}
!7705 = !{!7706, !7706, i64 0}
!7706 = !{!"float32", !7707, i64 0}
!7707 = !{!"0x1f327720", !8, i64 0}
!7708 = !{!7709, !7709, i64 0}
!7709 = !{!"float32", !7710, i64 0}
!7710 = !{!"0x1f322510", !8, i64 0}
!7711 = !{!7712, !7712, i64 0}
!7712 = !{!"float32", !7713, i64 0}
!7713 = !{!"0x1f326260", !8, i64 0}
!7714 = !{!7715, !7715, i64 0}
!7715 = !{!"float32", !7716, i64 0}
!7716 = !{!"0x1f3266c0", !8, i64 0}
!7717 = !{!7718, !7718, i64 0}
!7718 = !{!"float32", !7719, i64 0}
!7719 = !{!"0x1f32e380", !8, i64 0}
!7720 = !{!7721, !7721, i64 0}
!7721 = !{!"float32", !7722, i64 0}
!7722 = !{!"0x1f326340", !8, i64 0}
!7723 = !{!7724, !7724, i64 0}
!7724 = !{!"float32", !7725, i64 0}
!7725 = !{!"0x1f328c90", !8, i64 0}
!7726 = !{!7727, !7727, i64 0}
!7727 = !{!"float32", !7728, i64 0}
!7728 = !{!"0x1f3281e0", !8, i64 0}
!7729 = !{!7730, !7730, i64 0}
!7730 = !{!"0xed1dd10.w1.b0", !7731, i64 0}
!7731 = !{!"0xed1dd10.w2.b0", !7732, i64 0}
!7732 = !{!"0xed1dd10.w4.b0", !7733, i64 0}
!7733 = !{!"0xed1dd10.w8.b0", !7734, i64 0}
!7734 = !{!"0xed1dd10.w16.b0", !7735, i64 0}
!7735 = !{!"0xed1dd10.w32.b0", !7736, i64 0}
!7736 = !{!"0xed1dd10.w64.b0", !7737, i64 0}
!7737 = !{!"0xed1dd10.w128.b0", !7738, i64 0}
!7738 = !{!"0xed1dd10.w256.b0", !7739, i64 0}
!7739 = !{!"0xed1dd10.w512.b0", !7740, i64 0}
!7740 = !{!"0xed1dd10.w1024.b0", !7741, i64 0}
!7741 = !{!"int32", !7742, i64 0}
!7742 = !{!"0xed1dd10", !8, i64 0}
!7743 = !{!7744, !7744, i64 0}
!7744 = !{!"0xed1dd10.w1.b2", !7745, i64 0}
!7745 = !{!"0xed1dd10.w2.b2", !7732, i64 0}
!7746 = !{!7747, !7747, i64 0}
!7747 = !{!"0xed1dd10.w1.b3", !7745, i64 0}
!7748 = !{!7749, !7749, i64 0}
!7749 = !{!"0xed1dd10.w1.b1", !7731, i64 0}
!7750 = !{!7751, !7751, i64 0}
!7751 = !{!"0xd92fa90.w1.b0", !7752, i64 0}
!7752 = !{!"0xd92fa90.w2.b0", !7753, i64 0}
!7753 = !{!"0xd92fa90.w4.b0", !7754, i64 0}
!7754 = !{!"0xd92fa90.w8.b0", !7755, i64 0}
!7755 = !{!"0xd92fa90.w16.b0", !7756, i64 0}
!7756 = !{!"0xd92fa90.w32.b0", !7757, i64 0}
!7757 = !{!"0xd92fa90.w64.b0", !7758, i64 0}
!7758 = !{!"0xd92fa90.w128.b0", !7759, i64 0}
!7759 = !{!"0xd92fa90.w256.b0", !7760, i64 0}
!7760 = !{!"0xd92fa90.w512.b0", !7761, i64 0}
!7761 = !{!"0xd92fa90.w1024.b0", !7762, i64 0}
!7762 = !{!"int64", !7763, i64 0}
!7763 = !{!"0xd92fa90", !8, i64 0}
!7764 = !{!7765, !7765, i64 0}
!7765 = !{!"0xd92fa90.w1.b1", !7752, i64 0}
!7766 = !{!7767, !7767, i64 0}
!7767 = !{!"0x6de4540.w1.b0", !7768, i64 0}
!7768 = !{!"0x6de4540.w2.b0", !7769, i64 0}
!7769 = !{!"0x6de4540.w4.b0", !7770, i64 0}
!7770 = !{!"0x6de4540.w8.b0", !7771, i64 0}
!7771 = !{!"0x6de4540.w16.b0", !7772, i64 0}
!7772 = !{!"0x6de4540.w32.b0", !7773, i64 0}
!7773 = !{!"0x6de4540.w64.b0", !7774, i64 0}
!7774 = !{!"0x6de4540.w128.b0", !7775, i64 0}
!7775 = !{!"0x6de4540.w256.b0", !7776, i64 0}
!7776 = !{!"0x6de4540.w512.b0", !7777, i64 0}
!7777 = !{!"0x6de4540.w1024.b0", !7778, i64 0}
!7778 = !{!"int64", !7779, i64 0}
!7779 = !{!"0x6de4540", !8, i64 0}
!7780 = !{!7781, !7781, i64 0}
!7781 = !{!"0x6de4540.w1.b1", !7768, i64 0}
!7782 = !{!7783, !7783, i64 0}
!7783 = !{!"0xed3b920.w1.b0", !7784, i64 0}
!7784 = !{!"0xed3b920.w2.b0", !7785, i64 0}
!7785 = !{!"0xed3b920.w4.b0", !7786, i64 0}
!7786 = !{!"0xed3b920.w8.b0", !7787, i64 0}
!7787 = !{!"0xed3b920.w16.b0", !7788, i64 0}
!7788 = !{!"0xed3b920.w32.b0", !7789, i64 0}
!7789 = !{!"0xed3b920.w64.b0", !7790, i64 0}
!7790 = !{!"0xed3b920.w128.b0", !7791, i64 0}
!7791 = !{!"0xed3b920.w256.b0", !7792, i64 0}
!7792 = !{!"0xed3b920.w512.b0", !7793, i64 0}
!7793 = !{!"0xed3b920.w1024.b0", !7794, i64 0}
!7794 = !{!"int64", !7795, i64 0}
!7795 = !{!"0xed3b920", !8, i64 0}
!7796 = !{!7797, !7797, i64 0}
!7797 = !{!"0xed3b920.w1.b1", !7784, i64 0}
!7798 = !{!7799, !7799, i64 0}
!7799 = !{!"0xd922d40.w1.b0", !7800, i64 0}
!7800 = !{!"0xd922d40.w2.b0", !7801, i64 0}
!7801 = !{!"0xd922d40.w4.b0", !7802, i64 0}
!7802 = !{!"0xd922d40.w8.b0", !7803, i64 0}
!7803 = !{!"0xd922d40.w16.b0", !7804, i64 0}
!7804 = !{!"0xd922d40.w32.b0", !7805, i64 0}
!7805 = !{!"0xd922d40.w64.b0", !7806, i64 0}
!7806 = !{!"0xd922d40.w128.b0", !7807, i64 0}
!7807 = !{!"0xd922d40.w256.b0", !7808, i64 0}
!7808 = !{!"0xd922d40.w512.b0", !7809, i64 0}
!7809 = !{!"0xd922d40.w1024.b0", !7810, i64 0}
!7810 = !{!"int64", !7811, i64 0}
!7811 = !{!"0xd922d40", !8, i64 0}
!7812 = !{!7813, !7813, i64 0}
!7813 = !{!"0xd922d40.w1.b1", !7800, i64 0}
!7814 = !{!7815, !7815, i64 0}
!7815 = !{!"0xbd28d70.w1.b0", !7816, i64 0}
!7816 = !{!"0xbd28d70.w2.b0", !7817, i64 0}
!7817 = !{!"0xbd28d70.w4.b0", !7818, i64 0}
!7818 = !{!"0xbd28d70.w8.b0", !7819, i64 0}
!7819 = !{!"0xbd28d70.w16.b0", !7820, i64 0}
!7820 = !{!"0xbd28d70.w32.b0", !7821, i64 0}
!7821 = !{!"0xbd28d70.w64.b0", !7822, i64 0}
!7822 = !{!"0xbd28d70.w128.b0", !7823, i64 0}
!7823 = !{!"0xbd28d70.w256.b0", !7824, i64 0}
!7824 = !{!"0xbd28d70.w512.b0", !7825, i64 0}
!7825 = !{!"0xbd28d70.w1024.b0", !7826, i64 0}
!7826 = !{!"int64", !7827, i64 0}
!7827 = !{!"0xbd28d70", !8, i64 0}
!7828 = !{!7829, !7829, i64 0}
!7829 = !{!"0x180c6f20.w1.b0", !7830, i64 0}
!7830 = !{!"0x180c6f20.w2.b0", !7831, i64 0}
!7831 = !{!"0x180c6f20.w4.b0", !7832, i64 0}
!7832 = !{!"0x180c6f20.w8.b0", !7833, i64 0}
!7833 = !{!"0x180c6f20.w16.b0", !7834, i64 0}
!7834 = !{!"0x180c6f20.w32.b0", !7835, i64 0}
!7835 = !{!"0x180c6f20.w64.b0", !7836, i64 0}
!7836 = !{!"0x180c6f20.w128.b0", !7837, i64 0}
!7837 = !{!"0x180c6f20.w256.b0", !7838, i64 0}
!7838 = !{!"0x180c6f20.w512.b0", !7839, i64 0}
!7839 = !{!"0x180c6f20.w1024.b0", !7840, i64 0}
!7840 = !{!"int64", !7841, i64 0}
!7841 = !{!"0x180c6f20", !8, i64 0}
!7842 = !{!7843, !7843, i64 0}
!7843 = !{!"0x86cb9d0.w1.b0", !7844, i64 0}
!7844 = !{!"0x86cb9d0.w2.b0", !7845, i64 0}
!7845 = !{!"0x86cb9d0.w4.b0", !7846, i64 0}
!7846 = !{!"0x86cb9d0.w8.b0", !7847, i64 0}
!7847 = !{!"0x86cb9d0.w16.b0", !7848, i64 0}
!7848 = !{!"0x86cb9d0.w32.b0", !7849, i64 0}
!7849 = !{!"0x86cb9d0.w64.b0", !7850, i64 0}
!7850 = !{!"0x86cb9d0.w128.b0", !7851, i64 0}
!7851 = !{!"0x86cb9d0.w256.b0", !7852, i64 0}
!7852 = !{!"0x86cb9d0.w512.b0", !7853, i64 0}
!7853 = !{!"0x86cb9d0.w1024.b0", !7854, i64 0}
!7854 = !{!"int64", !7855, i64 0}
!7855 = !{!"0x86cb9d0", !8, i64 0}
!7856 = !{!7857, !7857, i64 0}
!7857 = !{!"0x86cb9d0.w1.b1", !7844, i64 0}
!7858 = !{!7859, !7859, i64 0}
!7859 = !{!"0x6ce4fe0.w1.b0", !7860, i64 0}
!7860 = !{!"0x6ce4fe0.w2.b0", !7861, i64 0}
!7861 = !{!"0x6ce4fe0.w4.b0", !7862, i64 0}
!7862 = !{!"0x6ce4fe0.w8.b0", !7863, i64 0}
!7863 = !{!"0x6ce4fe0.w16.b0", !7864, i64 0}
!7864 = !{!"0x6ce4fe0.w32.b0", !7865, i64 0}
!7865 = !{!"0x6ce4fe0.w64.b0", !7866, i64 0}
!7866 = !{!"0x6ce4fe0.w128.b0", !7867, i64 0}
!7867 = !{!"0x6ce4fe0.w256.b0", !7868, i64 0}
!7868 = !{!"0x6ce4fe0.w512.b0", !7869, i64 0}
!7869 = !{!"0x6ce4fe0.w1024.b0", !7870, i64 0}
!7870 = !{!"int64", !7871, i64 0}
!7871 = !{!"0x6ce4fe0", !8, i64 0}
!7872 = !{!7873, !7873, i64 0}
!7873 = !{!"0x6ce4fe0.w1.b1", !7860, i64 0}
!7874 = !{!7875, !7875, i64 0}
!7875 = !{!"float32", !7876, i64 0}
!7876 = !{!"0x13b12540", !8, i64 0}
!7877 = !{!7878, !7878, i64 0}
!7878 = !{!"float32", !7879, i64 0}
!7879 = !{!"0x1f2ae0c0", !8, i64 0}
!7880 = !{!7881, !7881, i64 0}
!7881 = !{!"float32", !7882, i64 0}
!7882 = !{!"0x1f2ae140", !8, i64 0}
!7883 = distinct !{!7883, !1123}
!7884 = !{!7885, !7885, i64 0}
!7885 = !{!"float32", !7886, i64 0}
!7886 = !{!"0x1272f490", !8, i64 0}
!7887 = !{!7888, !7888, i64 0}
!7888 = !{!"float32", !7889, i64 0}
!7889 = !{!"0x1a552080", !8, i64 0}
!7890 = !{!7891, !7891, i64 0}
!7891 = !{!"0xcf45170.w1.b0", !7892, i64 0}
!7892 = !{!"0xcf45170.w2.b0", !7893, i64 0}
!7893 = !{!"0xcf45170.w4.b0", !7894, i64 0}
!7894 = !{!"0xcf45170.w8.b0", !7895, i64 0}
!7895 = !{!"0xcf45170.w16.b0", !7896, i64 0}
!7896 = !{!"0xcf45170.w32.b0", !7897, i64 0}
!7897 = !{!"0xcf45170.w64.b0", !7898, i64 0}
!7898 = !{!"0xcf45170.w128.b0", !7899, i64 0}
!7899 = !{!"0xcf45170.w256.b0", !7900, i64 0}
!7900 = !{!"0xcf45170.w512.b0", !7901, i64 0}
!7901 = !{!"0xcf45170.w1024.b0", !7902, i64 0}
!7902 = !{!"int32", !7903, i64 0}
!7903 = !{!"0xcf45170", !8, i64 0}
!7904 = !{!7905, !7905, i64 0}
!7905 = !{!"0xcf45170.w1.b2", !7906, i64 0}
!7906 = !{!"0xcf45170.w2.b2", !7893, i64 0}
!7907 = !{!7908, !7908, i64 0}
!7908 = !{!"0xcf45170.w1.b3", !7906, i64 0}
!7909 = !{!7910, !7910, i64 0}
!7910 = !{!"0xcf45170.w1.b4", !7911, i64 0}
!7911 = !{!"0xcf45170.w2.b4", !7912, i64 0}
!7912 = !{!"0xcf45170.w4.b4", !7894, i64 0}
!7913 = !{!7914, !7914, i64 0}
!7914 = !{!"0xcf45170.w1.b1", !7892, i64 0}
!7915 = !{!7916, !7916, i64 0}
!7916 = !{!"0xcf42570.w1.b0", !7917, i64 0}
!7917 = !{!"0xcf42570.w2.b0", !7918, i64 0}
!7918 = !{!"0xcf42570.w4.b0", !7919, i64 0}
!7919 = !{!"0xcf42570.w8.b0", !7920, i64 0}
!7920 = !{!"0xcf42570.w16.b0", !7921, i64 0}
!7921 = !{!"0xcf42570.w32.b0", !7922, i64 0}
!7922 = !{!"0xcf42570.w64.b0", !7923, i64 0}
!7923 = !{!"0xcf42570.w128.b0", !7924, i64 0}
!7924 = !{!"0xcf42570.w256.b0", !7925, i64 0}
!7925 = !{!"0xcf42570.w512.b0", !7926, i64 0}
!7926 = !{!"0xcf42570.w1024.b0", !7927, i64 0}
!7927 = !{!"int64", !7928, i64 0}
!7928 = !{!"0xcf42570", !8, i64 0}
!7929 = !{!7930, !7930, i64 0}
!7930 = !{!"0xcf42570.w1.b1", !7917, i64 0}
!7931 = !{!7932, !7932, i64 0}
!7932 = !{!"0xcf42570.w1.b2", !7933, i64 0}
!7933 = !{!"0xcf42570.w2.b2", !7918, i64 0}
!7934 = !{!7935, !7935, i64 0}
!7935 = !{!"0xcf42570.w1.b3", !7933, i64 0}
!7936 = !{!7937, !7937, i64 0}
!7937 = !{!"0xcf42570.w1.b4", !7938, i64 0}
!7938 = !{!"0xcf42570.w2.b4", !7939, i64 0}
!7939 = !{!"0xcf42570.w4.b4", !7919, i64 0}
!7940 = !{!7941, !7941, i64 0}
!7941 = !{!"0xa5a3bf0.w4.b0", !7942, i64 0}
!7942 = !{!"0xa5a3bf0.w8.b0", !7943, i64 0}
!7943 = !{!"0xa5a3bf0.w16.b0", !7944, i64 0}
!7944 = !{!"0xa5a3bf0.w32.b0", !7945, i64 0}
!7945 = !{!"0xa5a3bf0.w64.b0", !7946, i64 0}
!7946 = !{!"0xa5a3bf0.w128.b0", !7947, i64 0}
!7947 = !{!"0xa5a3bf0.w256.b0", !7948, i64 0}
!7948 = !{!"0xa5a3bf0.w512.b0", !7949, i64 0}
!7949 = !{!"0xa5a3bf0.w1024.b0", !7950, i64 0}
!7950 = !{!"int64", !7951, i64 0}
!7951 = !{!"0xa5a3bf0", !8, i64 0}
!7952 = !{!7953, !7953, i64 0}
!7953 = !{!"0xa5a3bf0.w1.b4", !7954, i64 0}
!7954 = !{!"0xa5a3bf0.w2.b4", !7955, i64 0}
!7955 = !{!"0xa5a3bf0.w4.b4", !7942, i64 0}
!7956 = !{!7957, !7957, i64 0}
!7957 = !{!"0xcf42960.w1.b0", !7958, i64 0}
!7958 = !{!"0xcf42960.w2.b0", !7959, i64 0}
!7959 = !{!"0xcf42960.w4.b0", !7960, i64 0}
!7960 = !{!"0xcf42960.w8.b0", !7961, i64 0}
!7961 = !{!"0xcf42960.w16.b0", !7962, i64 0}
!7962 = !{!"0xcf42960.w32.b0", !7963, i64 0}
!7963 = !{!"0xcf42960.w64.b0", !7964, i64 0}
!7964 = !{!"0xcf42960.w128.b0", !7965, i64 0}
!7965 = !{!"0xcf42960.w256.b0", !7966, i64 0}
!7966 = !{!"0xcf42960.w512.b0", !7967, i64 0}
!7967 = !{!"0xcf42960.w1024.b0", !7968, i64 0}
!7968 = !{!"int64", !7969, i64 0}
!7969 = !{!"0xcf42960", !8, i64 0}
!7970 = !{!7971, !7971, i64 0}
!7971 = !{!"0xcf42960.w1.b1", !7958, i64 0}
!7972 = !{!7973, !7973, i64 0}
!7973 = !{!"0xcf42960.w1.b2", !7974, i64 0}
!7974 = !{!"0xcf42960.w2.b2", !7959, i64 0}
!7975 = !{!7976, !7976, i64 0}
!7976 = !{!"0xcf42960.w1.b3", !7974, i64 0}
!7977 = !{!7978, !7978, i64 0}
!7978 = !{!"0xcf42960.w1.b4", !7979, i64 0}
!7979 = !{!"0xcf42960.w2.b4", !7980, i64 0}
!7980 = !{!"0xcf42960.w4.b4", !7960, i64 0}
!7981 = !{!7982, !7982, i64 0}
!7982 = !{!"0xcf42960.w1.b5", !7979, i64 0}
!7983 = !{!7984, !7984, i64 0}
!7984 = !{!"0xa5a1160.w4.b0", !7985, i64 0}
!7985 = !{!"0xa5a1160.w8.b0", !7986, i64 0}
!7986 = !{!"0xa5a1160.w16.b0", !7987, i64 0}
!7987 = !{!"0xa5a1160.w32.b0", !7988, i64 0}
!7988 = !{!"0xa5a1160.w64.b0", !7989, i64 0}
!7989 = !{!"0xa5a1160.w128.b0", !7990, i64 0}
!7990 = !{!"0xa5a1160.w256.b0", !7991, i64 0}
!7991 = !{!"0xa5a1160.w512.b0", !7992, i64 0}
!7992 = !{!"0xa5a1160.w1024.b0", !7993, i64 0}
!7993 = !{!"int64", !7994, i64 0}
!7994 = !{!"0xa5a1160", !8, i64 0}
!7995 = !{!7996, !7996, i64 0}
!7996 = !{!"0xa5a1160.w1.b4", !7997, i64 0}
!7997 = !{!"0xa5a1160.w2.b4", !7998, i64 0}
!7998 = !{!"0xa5a1160.w4.b4", !7985, i64 0}
!7999 = !{!8000, !8000, i64 0}
!8000 = !{!"0xa5a1160.w1.b5", !7997, i64 0}
!8001 = !{!8002, !8002, i64 0}
!8002 = !{!"0xa5b0850.w1.b0", !8003, i64 0}
!8003 = !{!"0xa5b0850.w2.b0", !8004, i64 0}
!8004 = !{!"0xa5b0850.w4.b0", !8005, i64 0}
!8005 = !{!"0xa5b0850.w8.b0", !8006, i64 0}
!8006 = !{!"0xa5b0850.w16.b0", !8007, i64 0}
!8007 = !{!"0xa5b0850.w32.b0", !8008, i64 0}
!8008 = !{!"0xa5b0850.w64.b0", !8009, i64 0}
!8009 = !{!"0xa5b0850.w128.b0", !8010, i64 0}
!8010 = !{!"0xa5b0850.w256.b0", !8011, i64 0}
!8011 = !{!"0xa5b0850.w512.b0", !8012, i64 0}
!8012 = !{!"0xa5b0850.w1024.b0", !8013, i64 0}
!8013 = !{!"int64", !8014, i64 0}
!8014 = !{!"0xa5b0850", !8, i64 0}
!8015 = !{!8016, !8016, i64 0}
!8016 = !{!"0xa5b0850.w1.b1", !8003, i64 0}
!8017 = !{!8018, !8018, i64 0}
!8018 = !{!"0xa5b0850.w1.b2", !8019, i64 0}
!8019 = !{!"0xa5b0850.w2.b2", !8004, i64 0}
!8020 = !{!8021, !8021, i64 0}
!8021 = !{!"0xa5b0850.w1.b3", !8019, i64 0}
!8022 = !{!8023, !8023, i64 0}
!8023 = !{!"0xa5b13f0.w4.b0", !8024, i64 0}
!8024 = !{!"0xa5b13f0.w8.b0", !8025, i64 0}
!8025 = !{!"0xa5b13f0.w16.b0", !8026, i64 0}
!8026 = !{!"0xa5b13f0.w32.b0", !8027, i64 0}
!8027 = !{!"0xa5b13f0.w64.b0", !8028, i64 0}
!8028 = !{!"0xa5b13f0.w128.b0", !8029, i64 0}
!8029 = !{!"0xa5b13f0.w256.b0", !8030, i64 0}
!8030 = !{!"0xa5b13f0.w512.b0", !8031, i64 0}
!8031 = !{!"0xa5b13f0.w1024.b0", !8032, i64 0}
!8032 = !{!"int64", !8033, i64 0}
!8033 = !{!"0xa5b13f0", !8, i64 0}
!8034 = !{!8035, !8035, i64 0}
!8035 = !{!"0xcf46360.w1.b0", !8036, i64 0}
!8036 = !{!"0xcf46360.w2.b0", !8037, i64 0}
!8037 = !{!"0xcf46360.w4.b0", !8038, i64 0}
!8038 = !{!"0xcf46360.w8.b0", !8039, i64 0}
!8039 = !{!"0xcf46360.w16.b0", !8040, i64 0}
!8040 = !{!"0xcf46360.w32.b0", !8041, i64 0}
!8041 = !{!"0xcf46360.w64.b0", !8042, i64 0}
!8042 = !{!"0xcf46360.w128.b0", !8043, i64 0}
!8043 = !{!"0xcf46360.w256.b0", !8044, i64 0}
!8044 = !{!"0xcf46360.w512.b0", !8045, i64 0}
!8045 = !{!"0xcf46360.w1024.b0", !8046, i64 0}
!8046 = !{!"int64", !8047, i64 0}
!8047 = !{!"0xcf46360", !8, i64 0}
!8048 = !{!8049, !8049, i64 0}
!8049 = !{!"0xcf46360.w1.b1", !8036, i64 0}
!8050 = !{!8051, !8051, i64 0}
!8051 = !{!"0xcf46360.w1.b2", !8052, i64 0}
!8052 = !{!"0xcf46360.w2.b2", !8037, i64 0}
!8053 = !{!8054, !8054, i64 0}
!8054 = !{!"0xcf46360.w1.b3", !8052, i64 0}
!8055 = !{!8056, !8056, i64 0}
!8056 = !{!"0xa5b3ff0.w4.b0", !8057, i64 0}
!8057 = !{!"0xa5b3ff0.w8.b0", !8058, i64 0}
!8058 = !{!"0xa5b3ff0.w16.b0", !8059, i64 0}
!8059 = !{!"0xa5b3ff0.w32.b0", !8060, i64 0}
!8060 = !{!"0xa5b3ff0.w64.b0", !8061, i64 0}
!8061 = !{!"0xa5b3ff0.w128.b0", !8062, i64 0}
!8062 = !{!"0xa5b3ff0.w256.b0", !8063, i64 0}
!8063 = !{!"0xa5b3ff0.w512.b0", !8064, i64 0}
!8064 = !{!"0xa5b3ff0.w1024.b0", !8065, i64 0}
!8065 = !{!"int64", !8066, i64 0}
!8066 = !{!"0xa5b3ff0", !8, i64 0}
!8067 = !{!8068, !8068, i64 0}
!8068 = !{!"0xa5b6240.w1.b0", !8069, i64 0}
!8069 = !{!"0xa5b6240.w2.b0", !8070, i64 0}
!8070 = !{!"0xa5b6240.w4.b0", !8071, i64 0}
!8071 = !{!"0xa5b6240.w8.b0", !8072, i64 0}
!8072 = !{!"0xa5b6240.w16.b0", !8073, i64 0}
!8073 = !{!"0xa5b6240.w32.b0", !8074, i64 0}
!8074 = !{!"0xa5b6240.w64.b0", !8075, i64 0}
!8075 = !{!"0xa5b6240.w128.b0", !8076, i64 0}
!8076 = !{!"0xa5b6240.w256.b0", !8077, i64 0}
!8077 = !{!"0xa5b6240.w512.b0", !8078, i64 0}
!8078 = !{!"0xa5b6240.w1024.b0", !8079, i64 0}
!8079 = !{!"int64", !8080, i64 0}
!8080 = !{!"0xa5b6240", !8, i64 0}
!8081 = !{!8082, !8082, i64 0}
!8082 = !{!"0xa5b6240.w1.b1", !8069, i64 0}
!8083 = !{!8084, !8084, i64 0}
!8084 = !{!"0xa5b6240.w1.b2", !8085, i64 0}
!8085 = !{!"0xa5b6240.w2.b2", !8070, i64 0}
!8086 = !{!8087, !8087, i64 0}
!8087 = !{!"0xa5b6240.w1.b3", !8085, i64 0}
!8088 = !{!8089, !8089, i64 0}
!8089 = !{!"0xa5b6240.w1.b4", !8090, i64 0}
!8090 = !{!"0xa5b6240.w2.b4", !8091, i64 0}
!8091 = !{!"0xa5b6240.w4.b4", !8071, i64 0}
!8092 = !{!8093, !8093, i64 0}
!8093 = !{!"0xa5b6e40.w4.b0", !8094, i64 0}
!8094 = !{!"0xa5b6e40.w8.b0", !8095, i64 0}
!8095 = !{!"0xa5b6e40.w16.b0", !8096, i64 0}
!8096 = !{!"0xa5b6e40.w32.b0", !8097, i64 0}
!8097 = !{!"0xa5b6e40.w64.b0", !8098, i64 0}
!8098 = !{!"0xa5b6e40.w128.b0", !8099, i64 0}
!8099 = !{!"0xa5b6e40.w256.b0", !8100, i64 0}
!8100 = !{!"0xa5b6e40.w512.b0", !8101, i64 0}
!8101 = !{!"0xa5b6e40.w1024.b0", !8102, i64 0}
!8102 = !{!"int64", !8103, i64 0}
!8103 = !{!"0xa5b6e40", !8, i64 0}
!8104 = !{!8105, !8105, i64 0}
!8105 = !{!"0xa5b6e40.w1.b4", !8106, i64 0}
!8106 = !{!"0xa5b6e40.w2.b4", !8107, i64 0}
!8107 = !{!"0xa5b6e40.w4.b4", !8094, i64 0}
!8108 = !{!8109, !8109, i64 0}
!8109 = !{!"float32", !8110, i64 0}
!8110 = !{!"0xcf42440", !8, i64 0}
!8111 = !{!8112, !8112, i64 0}
!8112 = !{!"float32", !8113, i64 0}
!8113 = !{!"0xcf3cb00", !8, i64 0}
!8114 = distinct !{!8114, !1123}
!8115 = !{!8116, !8116, i64 0}
!8116 = !{!"float32", !8117, i64 0}
!8117 = !{!"0xcf3b150", !8, i64 0}
!8118 = !{!8119, !8119, i64 0}
!8119 = !{!"float32", !8120, i64 0}
!8120 = !{!"0xcf3b3b0", !8, i64 0}
!8121 = !{!8122, !8122, i64 0}
!8122 = !{!"float32", !8123, i64 0}
!8123 = !{!"0xa5a2030", !8, i64 0}
!8124 = !{!8125, !8125, i64 0}
!8125 = !{!"float32", !8126, i64 0}
!8126 = !{!"0xcf2c690", !8, i64 0}
!8127 = !{!8128, !8128, i64 0}
!8128 = !{!"float32", !8129, i64 0}
!8129 = !{!"0xcf3d060", !8, i64 0}
!8130 = !{!8131, !8131, i64 0}
!8131 = !{!"0xcf44890.w32.b0", !8132, i64 0}
!8132 = !{!"0xcf44890.w64.b0", !8133, i64 0}
!8133 = !{!"0xcf44890.w128.b0", !8134, i64 0}
!8134 = !{!"0xcf44890.w256.b0", !8135, i64 0}
!8135 = !{!"0xcf44890.w512.b0", !8136, i64 0}
!8136 = !{!"0xcf44890.w1024.b0", !8137, i64 0}
!8137 = !{!"float32", !8138, i64 0}
!8138 = !{!"0xcf44890", !8, i64 0}
!8139 = !{!8140, !8140, i64 0}
!8140 = !{!"0xcf3ab80.w1.b0", !8141, i64 0}
!8141 = !{!"0xcf3ab80.w2.b0", !8142, i64 0}
!8142 = !{!"0xcf3ab80.w4.b0", !8143, i64 0}
!8143 = !{!"0xcf3ab80.w8.b0", !8144, i64 0}
!8144 = !{!"0xcf3ab80.w16.b0", !8145, i64 0}
!8145 = !{!"0xcf3ab80.w32.b0", !8146, i64 0}
!8146 = !{!"0xcf3ab80.w64.b0", !8147, i64 0}
!8147 = !{!"0xcf3ab80.w128.b0", !8148, i64 0}
!8148 = !{!"0xcf3ab80.w256.b0", !8149, i64 0}
!8149 = !{!"0xcf3ab80.w512.b0", !8150, i64 0}
!8150 = !{!"0xcf3ab80.w1024.b0", !8151, i64 0}
!8151 = !{!"int32", !8152, i64 0}
!8152 = !{!"0xcf3ab80", !8, i64 0}
!8153 = !{!8154, !8154, i64 0}
!8154 = !{!"0xcf3ab80.w1.b1", !8141, i64 0}
!8155 = !{!8156, !8156, i64 0}
!8156 = !{!"0xa5b88c0.w1.b0", !8157, i64 0}
!8157 = !{!"0xa5b88c0.w2.b0", !8158, i64 0}
!8158 = !{!"0xa5b88c0.w4.b0", !8159, i64 0}
!8159 = !{!"0xa5b88c0.w8.b0", !8160, i64 0}
!8160 = !{!"0xa5b88c0.w16.b0", !8161, i64 0}
!8161 = !{!"0xa5b88c0.w32.b0", !8162, i64 0}
!8162 = !{!"0xa5b88c0.w64.b0", !8163, i64 0}
!8163 = !{!"0xa5b88c0.w128.b0", !8164, i64 0}
!8164 = !{!"0xa5b88c0.w256.b0", !8165, i64 0}
!8165 = !{!"0xa5b88c0.w512.b0", !8166, i64 0}
!8166 = !{!"0xa5b88c0.w1024.b0", !8167, i64 0}
!8167 = !{!"int64", !8168, i64 0}
!8168 = !{!"0xa5b88c0", !8, i64 0}
!8169 = !{!8170, !8170, i64 0}
!8170 = !{!"0xa5b88c0.w1.b1", !8157, i64 0}
!8171 = !{!8172, !8172, i64 0}
!8172 = !{!"0xa5b88c0.w1.b2", !8173, i64 0}
!8173 = !{!"0xa5b88c0.w2.b2", !8158, i64 0}
!8174 = !{!8175, !8175, i64 0}
!8175 = !{!"0xa5b88c0.w1.b3", !8173, i64 0}
!8176 = !{!8177, !8177, i64 0}
!8177 = !{!"0xa5b88c0.w1.b4", !8178, i64 0}
!8178 = !{!"0xa5b88c0.w2.b4", !8179, i64 0}
!8179 = !{!"0xa5b88c0.w4.b4", !8159, i64 0}
!8180 = !{!8181, !8181, i64 0}
!8181 = !{!"0xa5bc090.w4.b0", !8182, i64 0}
!8182 = !{!"0xa5bc090.w8.b0", !8183, i64 0}
!8183 = !{!"0xa5bc090.w16.b0", !8184, i64 0}
!8184 = !{!"0xa5bc090.w32.b0", !8185, i64 0}
!8185 = !{!"0xa5bc090.w64.b0", !8186, i64 0}
!8186 = !{!"0xa5bc090.w128.b0", !8187, i64 0}
!8187 = !{!"0xa5bc090.w256.b0", !8188, i64 0}
!8188 = !{!"0xa5bc090.w512.b0", !8189, i64 0}
!8189 = !{!"0xa5bc090.w1024.b0", !8190, i64 0}
!8190 = !{!"int64", !8191, i64 0}
!8191 = !{!"0xa5bc090", !8, i64 0}
!8192 = !{!8193, !8193, i64 0}
!8193 = !{!"0xa5bc090.w1.b4", !8194, i64 0}
!8194 = !{!"0xa5bc090.w2.b4", !8195, i64 0}
!8195 = !{!"0xa5bc090.w4.b4", !8182, i64 0}
!8196 = !{!8197, !8197, i64 0}
!8197 = !{!"0xa5be070.w1.b0", !8198, i64 0}
!8198 = !{!"0xa5be070.w2.b0", !8199, i64 0}
!8199 = !{!"0xa5be070.w4.b0", !8200, i64 0}
!8200 = !{!"0xa5be070.w8.b0", !8201, i64 0}
!8201 = !{!"0xa5be070.w16.b0", !8202, i64 0}
!8202 = !{!"0xa5be070.w32.b0", !8203, i64 0}
!8203 = !{!"0xa5be070.w64.b0", !8204, i64 0}
!8204 = !{!"0xa5be070.w128.b0", !8205, i64 0}
!8205 = !{!"0xa5be070.w256.b0", !8206, i64 0}
!8206 = !{!"0xa5be070.w512.b0", !8207, i64 0}
!8207 = !{!"0xa5be070.w1024.b0", !8208, i64 0}
!8208 = !{!"int64", !8209, i64 0}
!8209 = !{!"0xa5be070", !8, i64 0}
!8210 = !{!8211, !8211, i64 0}
!8211 = !{!"0xa5be070.w1.b1", !8198, i64 0}
!8212 = !{!8213, !8213, i64 0}
!8213 = !{!"0xa5be070.w1.b2", !8214, i64 0}
!8214 = !{!"0xa5be070.w2.b2", !8199, i64 0}
!8215 = !{!8216, !8216, i64 0}
!8216 = !{!"0xa5be070.w1.b3", !8214, i64 0}
!8217 = !{!8218, !8218, i64 0}
!8218 = !{!"0xa5be070.w1.b4", !8219, i64 0}
!8219 = !{!"0xa5be070.w2.b4", !8220, i64 0}
!8220 = !{!"0xa5be070.w4.b4", !8200, i64 0}
!8221 = !{!8222, !8222, i64 0}
!8222 = !{!"0xa5bee50.w4.b0", !8223, i64 0}
!8223 = !{!"0xa5bee50.w8.b0", !8224, i64 0}
!8224 = !{!"0xa5bee50.w16.b0", !8225, i64 0}
!8225 = !{!"0xa5bee50.w32.b0", !8226, i64 0}
!8226 = !{!"0xa5bee50.w64.b0", !8227, i64 0}
!8227 = !{!"0xa5bee50.w128.b0", !8228, i64 0}
!8228 = !{!"0xa5bee50.w256.b0", !8229, i64 0}
!8229 = !{!"0xa5bee50.w512.b0", !8230, i64 0}
!8230 = !{!"0xa5bee50.w1024.b0", !8231, i64 0}
!8231 = !{!"int64", !8232, i64 0}
!8232 = !{!"0xa5bee50", !8, i64 0}
!8233 = !{!8234, !8234, i64 0}
!8234 = !{!"0xa5bee50.w1.b4", !8235, i64 0}
!8235 = !{!"0xa5bee50.w2.b4", !8236, i64 0}
!8236 = !{!"0xa5bee50.w4.b4", !8223, i64 0}
!8237 = !{!8238, !8238, i64 0}
!8238 = !{!"float32", !8239, i64 0}
!8239 = !{!"0xa5b2b20", !8, i64 0}
!8240 = !{!8241, !8241, i64 0}
!8241 = !{!"float32", !8242, i64 0}
!8242 = !{!"0xa5b2ad0", !8, i64 0}
