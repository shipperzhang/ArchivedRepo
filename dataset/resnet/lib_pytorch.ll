; ModuleID = 'TVMMod'
source_filename = "TVMMod"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%0 = type { i32*, i32 }
%1 = type { i8*, %2, i32, %3, i64*, i64*, i64 }
%2 = type { i32, i32 }
%3 = type { i8, i8, i16 }
%4 = type { i8*, i8* }
%5 = type { i8*, i8* }
%6 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%7 = type { i8*, i8* }
%8 = type { i8*, i8*, i8*, i8*, i8* }
%9 = type { i8*, i8*, i8* }
%10 = type { i8*, i8* }
%11 = type { i8*, i8*, i8*, i8*, i32 }
%12 = type { i8*, i8* }
%13 = type { i8*, i8*, i8*, i8* }
%14 = type { i8*, i8* }
%15 = type { i8*, i8* }
%16 = type { i8*, i8* }
%17 = type { i8*, i8* }
%18 = type { i8*, i8*, i8*, i8*, i32 }
%19 = type { i8*, i8* }
%20 = type { i8*, i8* }
%21 = type { i8*, i8*, i8*, i8* }
%22 = type { i8*, i8* }
%23 = type { i8*, i8* }
%24 = type { i8*, i8* }
%25 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%26 = type { i8*, i8* }
%27 = type { i8*, i8* }
%28 = type { i8*, i8* }
%29 = type { i8*, i8*, i8*, i8*, i32 }
%30 = type { i8*, i8* }
%31 = type { i8*, i8*, i8*, i8*, i32 }
%32 = type { i8*, i8* }
%33 = type { i8*, i8* }
%34 = type { i8*, i8*, i8*, i8* }
%35 = type { i8*, i8* }
%36 = type { i8*, i8* }
%37 = type { i8*, i8*, i8*, i8* }
%38 = type { i8*, i8* }
%39 = type { i8*, i8*, i8*, i8*, i32 }
%40 = type { i8*, i8*, i8*, i8* }
%41 = type { i8*, i8* }
%42 = type { i8*, i8* }
%43 = type { i8*, i8*, i8*, i8*, i8* }
%44 = type { i8*, i8*, i8*, i8*, i32 }
%45 = type { i8*, i8* }

@__TVMAPISetLastError = linkonce dllexport local_unnamed_addr global void (i8*)* null, align 8
@__TVMBackendParallelLaunch = linkonce dllexport local_unnamed_addr global i32 (i32 (i32, %0*, i8*)*, i8*, i32)* null, align 8
@.str = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_20: num_args should be 2\00", align 1
@.str.1 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_20: Expect arg[0] to be pointer\00", align 1
@.str.2 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_20: Expect arg[1] to be pointer\00", align 1
@.str.3 = private constant [55 x i8] c"Assert fail: (dev_type == 1), device_type need to be 1\00", align 1
@.str.4 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg0, 0, 4)), arg0.ndim is expected to equal 5\00", align 1
@.str.5 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg0, 0, 5) == (uint8)2) && (tvm_struct_get(arg0, 0, 6) == (uint8)32)) && (tvm_struct_get(arg0, 0, 7) == (uint16)1)), arg0.dtype is expected to be float32\00", align 1
@.str.6 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[0])), Argument arg0.shape[0] has an unsatisfied constraint\00", align 1
@.str.7 = private constant [95 x i8] c"Assert fail: (8 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.8 = private constant [96 x i8] c"Assert fail: (14 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.9 = private constant [96 x i8] c"Assert fail: (14 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.10 = private constant [96 x i8] c"Assert fail: (32 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.11 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (448 == int32(arg0.strides[2]))) && (6272 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.12 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg0, 0, 8)), Argument arg0.byte_offset has an unsatisfied constraint\00", align 1
@.str.13 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg1, 0, 4)), arg1.ndim is expected to equal 5\00", align 1
@.str.14 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg1, 0, 5) == (uint8)2) && (tvm_struct_get(arg1, 0, 6) == (uint8)32)) && (tvm_struct_get(arg1, 0, 7) == (uint16)1)), arg1.dtype is expected to be float32\00", align 1
@.str.15 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.16 = private constant [95 x i8] c"Assert fail: (2 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.17 = private constant [96 x i8] c"Assert fail: (14 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.18 = private constant [96 x i8] c"Assert fail: (14 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.19 = private constant [97 x i8] c"Assert fail: (128 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.20 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (128 == int32(arg1.strides[3]))) && (1792 == int32(arg1.strides[2]))) && (25088 == int32(arg1.strides[1]))) && (50176 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.21 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg1, 0, 8)), Argument arg1.byte_offset has an unsatisfied constraint\00", align 1
@.str.22 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg1, 0, 10)), Argument arg1.device_type has an unsatisfied constraint\00", align 1
@.str.23 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg1, 0, 9)), Argument arg1.device_id has an unsatisfied constraint\00", align 1
@.str.24 = private constant [101 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_nn_batch_flatten_multiply: num_args should be 2\00", align 1
@.str.25 = private constant [176 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_nn_batch_flatten_multiply: Expect arg[0] to be pointer\00", align 1
@.str.26 = private constant [176 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_nn_batch_flatten_multiply: Expect arg[1] to be pointer\00", align 1
@.str.27 = private constant [96 x i8] c"Assert fail: (16 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.28 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.29 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.30 = private constant [232 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (32 == int32(arg0.strides[2]))) && (32 == int32(arg0.strides[1]))) && (512 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.31 = private constant [81 x i8] c"Assert fail: (2 == tvm_struct_get(arg1, 0, 4)), arg1.ndim is expected to equal 2\00", align 1
@.str.32 = private constant [97 x i8] c"Assert fail: (512 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.33 = private constant [124 x i8] c"Assert fail: ((1 == int32(arg1.strides[1])) && (512 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.34 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: num_args should be 5\00", align 1
@.str.35 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[0] to be pointer\00", align 1
@.str.36 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[1] to be pointer\00", align 1
@.str.37 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[2] to be pointer\00", align 1
@.str.38 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[3] to be pointer\00", align 1
@.str.39 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2: Expect arg[4] to be pointer\00", align 1
@.str.40 = private constant [95 x i8] c"Assert fail: (1 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.41 = private constant [96 x i8] c"Assert fail: (28 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.42 = private constant [96 x i8] c"Assert fail: (28 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.43 = private constant [97 x i8] c"Assert fail: (128 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.44 = private constant [242 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (128 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (100352 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.45 = private constant [81 x i8] c"Assert fail: (6 == tvm_struct_get(arg1, 0, 4)), arg1.ndim is expected to equal 6\00", align 1
@.str.46 = private constant [95 x i8] c"Assert fail: (4 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.47 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.48 = private constant [95 x i8] c"Assert fail: (3 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.49 = private constant [95 x i8] c"Assert fail: (3 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.50 = private constant [96 x i8] c"Assert fail: (32 == int32(arg1.shape[5])), Argument arg1.shape[5] has an unsatisfied constraint\00", align 1
@.str.51 = private constant [278 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (4096 == int32(arg1.strides[3]))) && (12288 == int32(arg1.strides[2]))) && (36864 == int32(arg1.strides[1]))) && (36864 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.52 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg2, 0, 4)), arg2.ndim is expected to equal 5\00", align 1
@.str.53 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg2, 0, 5) == (uint8)2) && (tvm_struct_get(arg2, 0, 6) == (uint8)32)) && (tvm_struct_get(arg2, 0, 7) == (uint16)1)), arg2.dtype is expected to be float32\00", align 1
@.str.54 = private constant [95 x i8] c"Assert fail: (1 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.55 = private constant [95 x i8] c"Assert fail: (4 == int32(arg2.shape[1])), Argument arg2.shape[1] has an unsatisfied constraint\00", align 1
@.str.56 = private constant [95 x i8] c"Assert fail: (1 == int32(arg2.shape[2])), Argument arg2.shape[2] has an unsatisfied constraint\00", align 1
@.str.57 = private constant [95 x i8] c"Assert fail: (1 == int32(arg2.shape[3])), Argument arg2.shape[3] has an unsatisfied constraint\00", align 1
@.str.58 = private constant [96 x i8] c"Assert fail: (32 == int32(arg2.shape[4])), Argument arg2.shape[4] has an unsatisfied constraint\00", align 1
@.str.59 = private constant [232 x i8] c"Assert fail: (((((1 == int32(arg2.strides[4])) && (32 == int32(arg2.strides[3]))) && (32 == int32(arg2.strides[2]))) && (32 == int32(arg2.strides[1]))) && (128 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.60 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg2, 0, 8)), Argument arg2.byte_offset has an unsatisfied constraint\00", align 1
@.str.61 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg2, 0, 10)), Argument arg2.device_type has an unsatisfied constraint\00", align 1
@.str.62 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg2, 0, 9)), Argument arg2.device_id has an unsatisfied constraint\00", align 1
@.str.63 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg3, 0, 4)), arg3.ndim is expected to equal 5\00", align 1
@.str.64 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg3, 0, 5) == (uint8)2) && (tvm_struct_get(arg3, 0, 6) == (uint8)32)) && (tvm_struct_get(arg3, 0, 7) == (uint16)1)), arg3.dtype is expected to be float32\00", align 1
@.str.65 = private constant [95 x i8] c"Assert fail: (1 == int32(arg3.shape[0])), Argument arg3.shape[0] has an unsatisfied constraint\00", align 1
@.str.66 = private constant [95 x i8] c"Assert fail: (4 == int32(arg3.shape[1])), Argument arg3.shape[1] has an unsatisfied constraint\00", align 1
@.str.67 = private constant [96 x i8] c"Assert fail: (28 == int32(arg3.shape[2])), Argument arg3.shape[2] has an unsatisfied constraint\00", align 1
@.str.68 = private constant [96 x i8] c"Assert fail: (28 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.69 = private constant [96 x i8] c"Assert fail: (32 == int32(arg3.shape[4])), Argument arg3.shape[4] has an unsatisfied constraint\00", align 1
@.str.70 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg3.strides[4])) && (32 == int32(arg3.strides[3]))) && (896 == int32(arg3.strides[2]))) && (25088 == int32(arg3.strides[1]))) && (100352 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.71 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg3, 0, 8)), Argument arg3.byte_offset has an unsatisfied constraint\00", align 1
@.str.72 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg3, 0, 10)), Argument arg3.device_type has an unsatisfied constraint\00", align 1
@.str.73 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg3, 0, 9)), Argument arg3.device_id has an unsatisfied constraint\00", align 1
@.str.74 = private constant [81 x i8] c"Assert fail: (5 == tvm_struct_get(arg4, 0, 4)), arg4.ndim is expected to equal 5\00", align 1
@.str.75 = private constant [186 x i8] c"Assert fail: (((tvm_struct_get(arg4, 0, 5) == (uint8)2) && (tvm_struct_get(arg4, 0, 6) == (uint8)32)) && (tvm_struct_get(arg4, 0, 7) == (uint16)1)), arg4.dtype is expected to be float32\00", align 1
@.str.76 = private constant [95 x i8] c"Assert fail: (1 == int32(arg4.shape[0])), Argument arg4.shape[0] has an unsatisfied constraint\00", align 1
@.str.77 = private constant [95 x i8] c"Assert fail: (4 == int32(arg4.shape[1])), Argument arg4.shape[1] has an unsatisfied constraint\00", align 1
@.str.78 = private constant [96 x i8] c"Assert fail: (28 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.79 = private constant [96 x i8] c"Assert fail: (28 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.80 = private constant [96 x i8] c"Assert fail: (32 == int32(arg4.shape[4])), Argument arg4.shape[4] has an unsatisfied constraint\00", align 1
@.str.81 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (32 == int32(arg4.strides[3]))) && (896 == int32(arg4.strides[2]))) && (25088 == int32(arg4.strides[1]))) && (100352 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.82 = private constant [112 x i8] c"Assert fail: ((uint64)0 == tvm_struct_get(arg4, 0, 8)), Argument arg4.byte_offset has an unsatisfied constraint\00", align 1
@.str.83 = private constant [105 x i8] c"Assert fail: (1 == tvm_struct_get(arg4, 0, 10)), Argument arg4.device_type has an unsatisfied constraint\00", align 1
@.str.84 = private constant [107 x i8] c"Assert fail: (dev_id == tvm_struct_get(arg4, 0, 9)), Argument arg4.device_id has an unsatisfied constraint\00", align 1
@__TVMBackendAllocWorkspace = linkonce dllexport local_unnamed_addr global i8* (i32, i32, i64, i32, i32)* null, align 8
@__TVMBackendFreeWorkspace = linkonce dllexport local_unnamed_addr global i32 (i32, i32, i8*)* null, align 8
@.str.87 = private constant [98 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: num_args should be 5\00", align 1
@.str.88 = private constant [173 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[0] to be pointer\00", align 1
@.str.89 = private constant [173 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[1] to be pointer\00", align 1
@.str.90 = private constant [173 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[2] to be pointer\00", align 1
@.str.91 = private constant [173 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[3] to be pointer\00", align 1
@.str.92 = private constant [173 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu: Expect arg[4] to be pointer\00", align 1
@.str.93 = private constant [95 x i8] c"Assert fail: (7 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.94 = private constant [95 x i8] c"Assert fail: (7 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.95 = private constant [97 x i8] c"Assert fail: (512 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.96 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (512 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (25088 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.97 = private constant [96 x i8] c"Assert fail: (16 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.98 = private constant [97 x i8] c"Assert fail: (512 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.99 = private constant [281 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (16384 == int32(arg1.strides[3]))) && (49152 == int32(arg1.strides[2]))) && (147456 == int32(arg1.strides[1]))) && (147456 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.100 = private constant [96 x i8] c"Assert fail: (16 == int32(arg2.shape[1])), Argument arg2.shape[1] has an unsatisfied constraint\00", align 1
@.str.101 = private constant [232 x i8] c"Assert fail: (((((1 == int32(arg2.strides[4])) && (32 == int32(arg2.strides[3]))) && (32 == int32(arg2.strides[2]))) && (32 == int32(arg2.strides[1]))) && (512 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.102 = private constant [96 x i8] c"Assert fail: (16 == int32(arg3.shape[1])), Argument arg3.shape[1] has an unsatisfied constraint\00", align 1
@.str.103 = private constant [95 x i8] c"Assert fail: (7 == int32(arg3.shape[2])), Argument arg3.shape[2] has an unsatisfied constraint\00", align 1
@.str.104 = private constant [95 x i8] c"Assert fail: (7 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.105 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg3.strides[4])) && (32 == int32(arg3.strides[3]))) && (224 == int32(arg3.strides[2]))) && (1568 == int32(arg3.strides[1]))) && (25088 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.106 = private constant [96 x i8] c"Assert fail: (16 == int32(arg4.shape[1])), Argument arg4.shape[1] has an unsatisfied constraint\00", align 1
@.str.107 = private constant [95 x i8] c"Assert fail: (7 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.108 = private constant [95 x i8] c"Assert fail: (7 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.109 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (32 == int32(arg4.strides[3]))) && (224 == int32(arg4.strides[2]))) && (1568 == int32(arg4.strides[1]))) && (25088 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.112 = private constant [71 x i8] c"Assert fail: (num_args == 4), fused_nn_dense_add: num_args should be 4\00", align 1
@.str.113 = private constant [146 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_dense_add: Expect arg[0] to be pointer\00", align 1
@.str.114 = private constant [146 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_dense_add: Expect arg[1] to be pointer\00", align 1
@.str.115 = private constant [146 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_dense_add: Expect arg[2] to be pointer\00", align 1
@.str.116 = private constant [146 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_dense_add: Expect arg[3] to be pointer\00", align 1
@.str.117 = private constant [81 x i8] c"Assert fail: (2 == tvm_struct_get(arg0, 0, 4)), arg0.ndim is expected to equal 2\00", align 1
@.str.118 = private constant [97 x i8] c"Assert fail: (512 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.119 = private constant [124 x i8] c"Assert fail: ((1 == int32(arg0.strides[1])) && (512 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.120 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.121 = private constant [81 x i8] c"Assert fail: (1 == tvm_struct_get(arg2, 0, 4)), arg2.ndim is expected to equal 1\00", align 1
@.str.122 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg2.shape[0])), Argument arg2.shape[0] has an unsatisfied constraint\00", align 1
@.str.123 = private constant [87 x i8] c"Assert fail: (1 == int32(arg2.strides[0])), arg2.strides: expected to be compact array\00", align 1
@.str.124 = private constant [81 x i8] c"Assert fail: (2 == tvm_struct_get(arg3, 0, 4)), arg3.ndim is expected to equal 2\00", align 1
@.str.125 = private constant [98 x i8] c"Assert fail: (1000 == int32(arg3.shape[1])), Argument arg3.shape[1] has an unsatisfied constraint\00", align 1
@.str.126 = private constant [125 x i8] c"Assert fail: ((1 == int32(arg3.strides[1])) && (1000 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.128 = private constant [96 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7: num_args should be 4\00", align 1
@.str.129 = private constant [171 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7: Expect arg[0] to be pointer\00", align 1
@.str.130 = private constant [171 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7: Expect arg[1] to be pointer\00", align 1
@.str.131 = private constant [171 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7: Expect arg[2] to be pointer\00", align 1
@.str.132 = private constant [171 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7: Expect arg[3] to be pointer\00", align 1
@.str.133 = private constant [97 x i8] c"Assert fail: (224 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.134 = private constant [97 x i8] c"Assert fail: (224 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.135 = private constant [95 x i8] c"Assert fail: (3 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.136 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (3 == int32(arg0.strides[3]))) && (672 == int32(arg0.strides[2]))) && (150528 == int32(arg0.strides[1]))) && (150528 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.137 = private constant [95 x i8] c"Assert fail: (2 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.138 = private constant [95 x i8] c"Assert fail: (7 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.139 = private constant [95 x i8] c"Assert fail: (7 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.140 = private constant [95 x i8] c"Assert fail: (3 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.141 = private constant [272 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (96 == int32(arg1.strides[3]))) && (672 == int32(arg1.strides[2]))) && (4704 == int32(arg1.strides[1]))) && (4704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.142 = private constant [95 x i8] c"Assert fail: (2 == int32(arg2.shape[1])), Argument arg2.shape[1] has an unsatisfied constraint\00", align 1
@.str.143 = private constant [231 x i8] c"Assert fail: (((((1 == int32(arg2.strides[4])) && (32 == int32(arg2.strides[3]))) && (32 == int32(arg2.strides[2]))) && (32 == int32(arg2.strides[1]))) && (64 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.144 = private constant [95 x i8] c"Assert fail: (2 == int32(arg3.shape[1])), Argument arg3.shape[1] has an unsatisfied constraint\00", align 1
@.str.145 = private constant [97 x i8] c"Assert fail: (112 == int32(arg3.shape[2])), Argument arg3.shape[2] has an unsatisfied constraint\00", align 1
@.str.146 = private constant [97 x i8] c"Assert fail: (112 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.147 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg3.strides[4])) && (32 == int32(arg3.strides[3]))) && (3584 == int32(arg3.strides[2]))) && (401408 == int32(arg3.strides[1]))) && (802816 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.150 = private constant [96 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1: num_args should be 4\00", align 1
@.str.151 = private constant [171 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1: Expect arg[0] to be pointer\00", align 1
@.str.152 = private constant [171 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1: Expect arg[1] to be pointer\00", align 1
@.str.153 = private constant [171 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1: Expect arg[2] to be pointer\00", align 1
@.str.154 = private constant [171 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1: Expect arg[3] to be pointer\00", align 1
@.str.155 = private constant [96 x i8] c"Assert fail: (32 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.156 = private constant [95 x i8] c"Assert fail: (8 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.157 = private constant [236 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (8 == int32(arg0.strides[3]))) && (112 == int32(arg0.strides[2]))) && (1568 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.158 = private constant [96 x i8] c"Assert fail: (32 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.159 = private constant [95 x i8] c"Assert fail: (8 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.160 = private constant [274 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (256 == int32(arg1.strides[3]))) && (768 == int32(arg1.strides[2]))) && (2304 == int32(arg1.strides[1]))) && (73728 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.163 = private constant [72 x i8] c"Assert fail: (num_args == 2), fused_nn_max_pool2d: num_args should be 2\00", align 1
@.str.164 = private constant [147 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_max_pool2d: Expect arg[0] to be pointer\00", align 1
@.str.165 = private constant [147 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_max_pool2d: Expect arg[1] to be pointer\00", align 1
@.str.166 = private constant [95 x i8] c"Assert fail: (2 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.167 = private constant [97 x i8] c"Assert fail: (112 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.168 = private constant [97 x i8] c"Assert fail: (112 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.169 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (401408 == int32(arg0.strides[1]))) && (802816 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.170 = private constant [96 x i8] c"Assert fail: (56 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.171 = private constant [96 x i8] c"Assert fail: (56 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.172 = private constant [96 x i8] c"Assert fail: (32 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.173 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (32 == int32(arg1.strides[3]))) && (1792 == int32(arg1.strides[2]))) && (100352 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.175 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_21: num_args should be 2\00", align 1
@.str.176 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_21: Expect arg[0] to be pointer\00", align 1
@.str.177 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_21: Expect arg[1] to be pointer\00", align 1
@.str.178 = private constant [95 x i8] c"Assert fail: (4 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.179 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (896 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.180 = private constant [96 x i8] c"Assert fail: (16 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.181 = private constant [96 x i8] c"Assert fail: (28 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.182 = private constant [96 x i8] c"Assert fail: (28 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.183 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (8 == int32(arg1.strides[3]))) && (224 == int32(arg1.strides[2]))) && (6272 == int32(arg1.strides[1]))) && (100352 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.185 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_26: num_args should be 2\00", align 1
@.str.186 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_26: Expect arg[0] to be pointer\00", align 1
@.str.187 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_26: Expect arg[1] to be pointer\00", align 1
@.str.188 = private constant [96 x i8] c"Assert fail: (56 == int32(arg0.shape[2])), Argument arg0.shape[2] has an unsatisfied constraint\00", align 1
@.str.189 = private constant [96 x i8] c"Assert fail: (56 == int32(arg0.shape[3])), Argument arg0.shape[3] has an unsatisfied constraint\00", align 1
@.str.190 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (100352 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.191 = private constant [95 x i8] c"Assert fail: (8 == int32(arg1.shape[1])), Argument arg1.shape[1] has an unsatisfied constraint\00", align 1
@.str.192 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (8 == int32(arg1.strides[3]))) && (448 == int32(arg1.strides[2]))) && (25088 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.194 = private constant [96 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6: num_args should be 4\00", align 1
@.str.195 = private constant [171 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6: Expect arg[0] to be pointer\00", align 1
@.str.196 = private constant [171 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6: Expect arg[1] to be pointer\00", align 1
@.str.197 = private constant [171 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6: Expect arg[2] to be pointer\00", align 1
@.str.198 = private constant [171 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6: Expect arg[3] to be pointer\00", align 1
@.str.199 = private constant [96 x i8] c"Assert fail: (64 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.200 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (64 == int32(arg0.strides[3]))) && (3584 == int32(arg0.strides[2]))) && (200704 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.201 = private constant [96 x i8] c"Assert fail: (64 == int32(arg1.shape[4])), Argument arg1.shape[4] has an unsatisfied constraint\00", align 1
@.str.202 = private constant [277 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (2048 == int32(arg1.strides[3]))) && (6144 == int32(arg1.strides[2]))) && (18432 == int32(arg1.strides[1]))) && (18432 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.203 = private constant [96 x i8] c"Assert fail: (56 == int32(arg3.shape[2])), Argument arg3.shape[2] has an unsatisfied constraint\00", align 1
@.str.204 = private constant [96 x i8] c"Assert fail: (56 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.205 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg3.strides[4])) && (32 == int32(arg3.strides[3]))) && (1792 == int32(arg3.strides[2]))) && (100352 == int32(arg3.strides[1]))) && (200704 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.208 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_22: num_args should be 2\00", align 1
@.str.209 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_22: Expect arg[0] to be pointer\00", align 1
@.str.210 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_22: Expect arg[1] to be pointer\00", align 1
@.str.211 = private constant [242 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (128 == int32(arg1.strides[3]))) && (3584 == int32(arg1.strides[2]))) && (100352 == int32(arg1.strides[1]))) && (100352 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.213 = private constant [96 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2: num_args should be 4\00", align 1
@.str.214 = private constant [171 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2: Expect arg[0] to be pointer\00", align 1
@.str.215 = private constant [171 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2: Expect arg[1] to be pointer\00", align 1
@.str.216 = private constant [171 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2: Expect arg[2] to be pointer\00", align 1
@.str.217 = private constant [171 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2: Expect arg[3] to be pointer\00", align 1
@.str.218 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (128 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.219 = private constant [96 x i8] c"Assert fail: (16 == int32(arg1.shape[5])), Argument arg1.shape[5] has an unsatisfied constraint\00", align 1
@.str.220 = private constant [277 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (16 == int32(arg1.strides[4]))) && (2048 == int32(arg1.strides[3]))) && (6144 == int32(arg1.strides[2]))) && (18432 == int32(arg1.strides[1]))) && (36864 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.221 = private constant [96 x i8] c"Assert fail: (16 == int32(arg2.shape[4])), Argument arg2.shape[4] has an unsatisfied constraint\00", align 1
@.str.222 = private constant [232 x i8] c"Assert fail: (((((1 == int32(arg2.strides[4])) && (16 == int32(arg2.strides[3]))) && (16 == int32(arg2.strides[2]))) && (16 == int32(arg2.strides[1]))) && (256 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.223 = private constant [96 x i8] c"Assert fail: (14 == int32(arg3.shape[2])), Argument arg3.shape[2] has an unsatisfied constraint\00", align 1
@.str.224 = private constant [96 x i8] c"Assert fail: (14 == int32(arg3.shape[3])), Argument arg3.shape[3] has an unsatisfied constraint\00", align 1
@.str.225 = private constant [96 x i8] c"Assert fail: (16 == int32(arg3.shape[4])), Argument arg3.shape[4] has an unsatisfied constraint\00", align 1
@.str.226 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg3.strides[4])) && (16 == int32(arg3.strides[3]))) && (224 == int32(arg3.strides[2]))) && (3136 == int32(arg3.strides[1]))) && (50176 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.229 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_27: num_args should be 2\00", align 1
@.str.230 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_27: Expect arg[0] to be pointer\00", align 1
@.str.231 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_27: Expect arg[1] to be pointer\00", align 1
@.str.232 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (64 == int32(arg1.strides[3]))) && (1792 == int32(arg1.strides[2]))) && (50176 == int32(arg1.strides[1]))) && (100352 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.234 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_17: num_args should be 2\00", align 1
@.str.235 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_17: Expect arg[0] to be pointer\00", align 1
@.str.236 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_17: Expect arg[1] to be pointer\00", align 1
@.str.237 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (32 == int32(arg0.strides[3]))) && (224 == int32(arg0.strides[2]))) && (1568 == int32(arg0.strides[1]))) && (25088 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.238 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (512 == int32(arg1.strides[3]))) && (3584 == int32(arg1.strides[2]))) && (25088 == int32(arg1.strides[1]))) && (25088 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.240 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: num_args should be 5\00", align 1
@.str.241 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[0] to be pointer\00", align 1
@.str.242 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[1] to be pointer\00", align 1
@.str.243 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[2] to be pointer\00", align 1
@.str.244 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[3] to be pointer\00", align 1
@.str.245 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3: Expect arg[4] to be pointer\00", align 1
@.str.246 = private constant [95 x i8] c"Assert fail: (2 == int32(arg4.shape[1])), Argument arg4.shape[1] has an unsatisfied constraint\00", align 1
@.str.247 = private constant [96 x i8] c"Assert fail: (56 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.248 = private constant [96 x i8] c"Assert fail: (56 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.249 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (32 == int32(arg4.strides[3]))) && (1792 == int32(arg4.strides[2]))) && (100352 == int32(arg4.strides[1]))) && (200704 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.252 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_24: num_args should be 2\00", align 1
@.str.253 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_24: Expect arg[0] to be pointer\00", align 1
@.str.254 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_24: Expect arg[1] to be pointer\00", align 1
@.str.255 = private constant [241 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (64 == int32(arg1.strides[3]))) && (3584 == int32(arg1.strides[2]))) && (200704 == int32(arg1.strides[1]))) && (200704 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.257 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_23: num_args should be 2\00", align 1
@.str.258 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_23: Expect arg[0] to be pointer\00", align 1
@.str.259 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_23: Expect arg[1] to be pointer\00", align 1
@.str.260 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (64 == int32(arg0.strides[3]))) && (1792 == int32(arg0.strides[2]))) && (50176 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.262 = private constant [96 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3: num_args should be 4\00", align 1
@.str.263 = private constant [171 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3: Expect arg[0] to be pointer\00", align 1
@.str.264 = private constant [171 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3: Expect arg[1] to be pointer\00", align 1
@.str.265 = private constant [171 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3: Expect arg[2] to be pointer\00", align 1
@.str.266 = private constant [171 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3: Expect arg[3] to be pointer\00", align 1
@.str.267 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (8 == int32(arg0.strides[3]))) && (224 == int32(arg0.strides[2]))) && (6272 == int32(arg0.strides[1]))) && (100352 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.268 = private constant [95 x i8] c"Assert fail: (8 == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint\00", align 1
@.str.269 = private constant [274 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (256 == int32(arg1.strides[3]))) && (768 == int32(arg1.strides[2]))) && (2304 == int32(arg1.strides[1]))) && (36864 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.270 = private constant [95 x i8] c"Assert fail: (8 == int32(arg2.shape[1])), Argument arg2.shape[1] has an unsatisfied constraint\00", align 1
@.str.271 = private constant [232 x i8] c"Assert fail: (((((1 == int32(arg2.strides[4])) && (32 == int32(arg2.strides[3]))) && (32 == int32(arg2.strides[2]))) && (32 == int32(arg2.strides[1]))) && (256 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.272 = private constant [95 x i8] c"Assert fail: (8 == int32(arg3.shape[1])), Argument arg3.shape[1] has an unsatisfied constraint\00", align 1
@.str.273 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg3.strides[4])) && (32 == int32(arg3.strides[3]))) && (448 == int32(arg3.strides[2]))) && (6272 == int32(arg3.strides[1]))) && (50176 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.276 = private constant [96 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4: num_args should be 4\00", align 1
@.str.277 = private constant [171 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4: Expect arg[0] to be pointer\00", align 1
@.str.278 = private constant [171 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4: Expect arg[1] to be pointer\00", align 1
@.str.279 = private constant [171 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4: Expect arg[2] to be pointer\00", align 1
@.str.280 = private constant [171 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4: Expect arg[3] to be pointer\00", align 1
@.str.283 = private constant [81 x i8] c"Assert fail: (num_args == 2), fused_nn_adaptive_avg_pool2d: num_args should be 2\00", align 1
@.str.284 = private constant [156 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_adaptive_avg_pool2d: Expect arg[0] to be pointer\00", align 1
@.str.285 = private constant [156 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_adaptive_avg_pool2d: Expect arg[1] to be pointer\00", align 1
@.str.286 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.287 = private constant [95 x i8] c"Assert fail: (1 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.288 = private constant [232 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (32 == int32(arg1.strides[3]))) && (32 == int32(arg1.strides[2]))) && (32 == int32(arg1.strides[1]))) && (512 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.291 = private constant [88 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_2: num_args should be 4\00", align 1
@.str.292 = private constant [163 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_2: Expect arg[0] to be pointer\00", align 1
@.str.293 = private constant [163 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_2: Expect arg[1] to be pointer\00", align 1
@.str.294 = private constant [163 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_2: Expect arg[2] to be pointer\00", align 1
@.str.295 = private constant [163 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_2: Expect arg[3] to be pointer\00", align 1
@.str.296 = private constant [275 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (4096 == int32(arg1.strides[3]))) && (4096 == int32(arg1.strides[2]))) && (4096 == int32(arg1.strides[1]))) && (8192 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.298 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_25: num_args should be 2\00", align 1
@.str.299 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_25: Expect arg[0] to be pointer\00", align 1
@.str.300 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_25: Expect arg[1] to be pointer\00", align 1
@.str.301 = private constant [81 x i8] c"Assert fail: (4 == tvm_struct_get(arg0, 0, 4)), arg0.ndim is expected to equal 4\00", align 1
@.str.302 = private constant [95 x i8] c"Assert fail: (3 == int32(arg0.shape[1])), Argument arg0.shape[1] has an unsatisfied constraint\00", align 1
@.str.303 = private constant [203 x i8] c"Assert fail: ((((1 == int32(arg0.strides[3])) && (224 == int32(arg0.strides[2]))) && (50176 == int32(arg0.strides[1]))) && (150528 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.304 = private constant [97 x i8] c"Assert fail: (224 == int32(arg1.shape[2])), Argument arg1.shape[2] has an unsatisfied constraint\00", align 1
@.str.305 = private constant [97 x i8] c"Assert fail: (224 == int32(arg1.shape[3])), Argument arg1.shape[3] has an unsatisfied constraint\00", align 1
@.str.306 = private constant [239 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (3 == int32(arg1.strides[3]))) && (672 == int32(arg1.strides[2]))) && (150528 == int32(arg1.strides[1]))) && (150528 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.308 = private constant [94 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu: num_args should be 4\00", align 1
@.str.309 = private constant [169 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu: Expect arg[0] to be pointer\00", align 1
@.str.310 = private constant [169 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu: Expect arg[1] to be pointer\00", align 1
@.str.311 = private constant [169 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu: Expect arg[2] to be pointer\00", align 1
@.str.312 = private constant [169 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu: Expect arg[3] to be pointer\00", align 1
@.str.315 = private constant [96 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5: num_args should be 4\00", align 1
@.str.316 = private constant [171 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5: Expect arg[0] to be pointer\00", align 1
@.str.317 = private constant [171 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5: Expect arg[1] to be pointer\00", align 1
@.str.318 = private constant [171 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5: Expect arg[2] to be pointer\00", align 1
@.str.319 = private constant [171 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5: Expect arg[3] to be pointer\00", align 1
@.str.320 = private constant [96 x i8] c"Assert fail: (64 == int32(arg1.shape[5])), Argument arg1.shape[5] has an unsatisfied constraint\00", align 1
@.str.321 = private constant [277 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (64 == int32(arg1.strides[4]))) && (2048 == int32(arg1.strides[3]))) && (6144 == int32(arg1.strides[2]))) && (18432 == int32(arg1.strides[1]))) && (36864 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.322 = private constant [96 x i8] c"Assert fail: (64 == int32(arg2.shape[4])), Argument arg2.shape[4] has an unsatisfied constraint\00", align 1
@.str.323 = private constant [232 x i8] c"Assert fail: (((((1 == int32(arg2.strides[4])) && (64 == int32(arg2.strides[3]))) && (64 == int32(arg2.strides[2]))) && (64 == int32(arg2.strides[1]))) && (128 == int32(arg2.strides[0]))), arg2.strides: expected to be compact array\00", align 1
@.str.324 = private constant [96 x i8] c"Assert fail: (64 == int32(arg3.shape[4])), Argument arg3.shape[4] has an unsatisfied constraint\00", align 1
@.str.325 = private constant [240 x i8] c"Assert fail: (((((1 == int32(arg3.strides[4])) && (64 == int32(arg3.strides[3]))) && (1792 == int32(arg3.strides[2]))) && (50176 == int32(arg3.strides[1]))) && (100352 == int32(arg3.strides[0]))), arg3.strides: expected to be compact array\00", align 1
@.str.328 = private constant [88 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add_1: num_args should be 4\00", align 1
@.str.329 = private constant [163 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_1: Expect arg[0] to be pointer\00", align 1
@.str.330 = private constant [163 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_1: Expect arg[1] to be pointer\00", align 1
@.str.331 = private constant [163 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_1: Expect arg[2] to be pointer\00", align 1
@.str.332 = private constant [163 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_1: Expect arg[3] to be pointer\00", align 1
@.str.333 = private constant [275 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (16 == int32(arg1.strides[4]))) && (1024 == int32(arg1.strides[3]))) && (1024 == int32(arg1.strides[2]))) && (1024 == int32(arg1.strides[1]))) && (2048 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.335 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_18: num_args should be 2\00", align 1
@.str.336 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_18: Expect arg[0] to be pointer\00", align 1
@.str.337 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_18: Expect arg[1] to be pointer\00", align 1
@.str.338 = private constant [96 x i8] c"Assert fail: (16 == int32(arg0.shape[4])), Argument arg0.shape[4] has an unsatisfied constraint\00", align 1
@.str.339 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (16 == int32(arg0.strides[3]))) && (224 == int32(arg0.strides[2]))) && (3136 == int32(arg0.strides[1]))) && (50176 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.340 = private constant [236 x i8] c"Assert fail: (((((1 == int32(arg1.strides[4])) && (8 == int32(arg1.strides[3]))) && (112 == int32(arg1.strides[2]))) && (1568 == int32(arg1.strides[1]))) && (50176 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.342 = private constant [100 x i8] c"Assert fail: (num_args == 5), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: num_args should be 5\00", align 1
@.str.343 = private constant [175 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[0] to be pointer\00", align 1
@.str.344 = private constant [175 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[1] to be pointer\00", align 1
@.str.345 = private constant [175 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[2] to be pointer\00", align 1
@.str.346 = private constant [175 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[3] to be pointer\00", align 1
@.str.347 = private constant [175 x i8] c"Assert fail: ((((arg4.code == 3) || (arg4.code == 13)) || (arg4.code == 7)) || (arg4.code == 4)), fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1: Expect arg[4] to be pointer\00", align 1
@.str.348 = private constant [96 x i8] c"Assert fail: (14 == int32(arg4.shape[2])), Argument arg4.shape[2] has an unsatisfied constraint\00", align 1
@.str.349 = private constant [96 x i8] c"Assert fail: (14 == int32(arg4.shape[3])), Argument arg4.shape[3] has an unsatisfied constraint\00", align 1
@.str.350 = private constant [96 x i8] c"Assert fail: (16 == int32(arg4.shape[4])), Argument arg4.shape[4] has an unsatisfied constraint\00", align 1
@.str.351 = private constant [237 x i8] c"Assert fail: (((((1 == int32(arg4.strides[4])) && (16 == int32(arg4.strides[3]))) && (224 == int32(arg4.strides[2]))) && (3136 == int32(arg4.strides[1]))) && (50176 == int32(arg4.strides[0]))), arg4.strides: expected to be compact array\00", align 1
@.str.354 = private constant [86 x i8] c"Assert fail: (num_args == 4), fused_nn_contrib_conv2d_NCHWc_add: num_args should be 4\00", align 1
@.str.355 = private constant [161 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_nn_contrib_conv2d_NCHWc_add: Expect arg[0] to be pointer\00", align 1
@.str.356 = private constant [161 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_nn_contrib_conv2d_NCHWc_add: Expect arg[1] to be pointer\00", align 1
@.str.357 = private constant [161 x i8] c"Assert fail: ((((arg2.code == 3) || (arg2.code == 13)) || (arg2.code == 7)) || (arg2.code == 4)), fused_nn_contrib_conv2d_NCHWc_add: Expect arg[2] to be pointer\00", align 1
@.str.358 = private constant [161 x i8] c"Assert fail: ((((arg3.code == 3) || (arg3.code == 13)) || (arg3.code == 7)) || (arg3.code == 4)), fused_nn_contrib_conv2d_NCHWc_add: Expect arg[3] to be pointer\00", align 1
@.str.359 = private constant [238 x i8] c"Assert fail: (((((1 == int32(arg0.strides[4])) && (8 == int32(arg0.strides[3]))) && (448 == int32(arg0.strides[2]))) && (25088 == int32(arg0.strides[1]))) && (200704 == int32(arg0.strides[0]))), arg0.strides: expected to be compact array\00", align 1
@.str.360 = private constant [272 x i8] c"Assert fail: ((((((1 == int32(arg1.strides[5])) && (32 == int32(arg1.strides[4]))) && (256 == int32(arg1.strides[3]))) && (256 == int32(arg1.strides[2]))) && (256 == int32(arg1.strides[1]))) && (2048 == int32(arg1.strides[0]))), arg1.strides: expected to be compact array\00", align 1
@.str.362 = private constant [78 x i8] c"Assert fail: (num_args == 2), fused_layout_transform_19: num_args should be 2\00", align 1
@.str.363 = private constant [153 x i8] c"Assert fail: ((((arg0.code == 3) || (arg0.code == 13)) || (arg0.code == 7)) || (arg0.code == 4)), fused_layout_transform_19: Expect arg[0] to be pointer\00", align 1
@.str.364 = private constant [153 x i8] c"Assert fail: ((((arg1.code == 3) || (arg1.code == 13)) || (arg1.code == 7)) || (arg1.code == 4)), fused_layout_transform_19: Expect arg[1] to be pointer\00", align 1

define dllexport i32 @fused_layout_transform_20(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !9
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.1, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !23
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.2, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !25
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !39
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 8
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !41
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 14
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !44
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 14
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !46
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !51
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 50176, i32 6272, i32 448, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !63
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.11, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !67
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !81
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 2
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !83
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 14
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.17, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !86
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 14
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.18, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !88
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 128
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !92
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 50176, i32 25088, i32 1792, i32 128>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !104
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.20, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_20_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_20_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %4, align 8
  %3 = getelementptr inbounds %4, %4* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %4, %4* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %4* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 1792
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 14
  %27 = mul nsw i32 %26, 448
  %28 = insertelement <16 x i32> undef, i32 %27, i32 0
  %29 = sdiv i32 %25, 14
  %30 = mul nsw i32 %29, 25088
  %31 = insertelement <16 x i32> undef, i32 %30, i32 0
  %32 = add <16 x i32> %28, %31
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %33 = shl i64 %indvars.iv7, 7
  %34 = add nsw i64 %33, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %35 = shl i32 %indvars.iv7.tr, 5
  %36 = insertelement <16 x i32> undef, i32 %35, i32 0
  %37 = add <16 x i32> %32, %36
  %38 = shufflevector <16 x i32> %37, <16 x i32> undef, <16 x i32> zeroinitializer
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %39 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %39, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %40 = shl nsw i64 %indvars.iv, 4
  %41 = add nsw i64 %34, %40
  %42 = trunc i64 %40 to i32
  %43 = insertelement <16 x i32> undef, i32 %42, i32 0
  %44 = trunc i64 %40 to i32
  %45 = or i32 %44, 1
  %46 = insertelement <16 x i32> %43, i32 %45, i32 1
  %47 = trunc i64 %40 to i32
  %48 = or i32 %47, 2
  %49 = insertelement <16 x i32> %46, i32 %48, i32 2
  %50 = trunc i64 %40 to i32
  %51 = or i32 %50, 3
  %52 = insertelement <16 x i32> %49, i32 %51, i32 3
  %53 = trunc i64 %40 to i32
  %54 = or i32 %53, 4
  %55 = insertelement <16 x i32> %52, i32 %54, i32 4
  %56 = trunc i64 %40 to i32
  %57 = or i32 %56, 5
  %58 = insertelement <16 x i32> %55, i32 %57, i32 5
  %59 = trunc i64 %40 to i32
  %60 = or i32 %59, 6
  %61 = insertelement <16 x i32> %58, i32 %60, i32 6
  %62 = trunc i64 %40 to i32
  %63 = or i32 %62, 7
  %64 = insertelement <16 x i32> %61, i32 %63, i32 7
  %65 = trunc i64 %40 to i32
  %66 = or i32 %65, 8
  %67 = insertelement <16 x i32> %64, i32 %66, i32 8
  %68 = trunc i64 %40 to i32
  %69 = or i32 %68, 9
  %70 = insertelement <16 x i32> %67, i32 %69, i32 9
  %71 = trunc i64 %40 to i32
  %72 = or i32 %71, 10
  %73 = insertelement <16 x i32> %70, i32 %72, i32 10
  %74 = trunc i64 %40 to i32
  %75 = or i32 %74, 11
  %76 = insertelement <16 x i32> %73, i32 %75, i32 11
  %77 = trunc i64 %40 to i32
  %78 = or i32 %77, 12
  %79 = insertelement <16 x i32> %76, i32 %78, i32 12
  %80 = trunc i64 %40 to i32
  %81 = or i32 %80, 13
  %82 = insertelement <16 x i32> %79, i32 %81, i32 13
  %83 = trunc i64 %40 to i32
  %84 = or i32 %83, 14
  %85 = insertelement <16 x i32> %82, i32 %84, i32 14
  %86 = trunc i64 %40 to i32
  %87 = or i32 %86, 15
  %88 = insertelement <16 x i32> %85, i32 %87, i32 15
  %89 = sdiv <16 x i32> %88, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %90 = mul <16 x i32> %89, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %91 = sub <16 x i32> %88, %90
  %92 = add nsw <16 x i32> %91, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %93 = icmp sgt <16 x i32> %91, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %94 = select <16 x i1> %93, <16 x i32> %91, <16 x i32> %92
  %not. = xor <16 x i1> %93, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %95 = sext <16 x i1> %not. to <16 x i32>
  %96 = add nsw <16 x i32> %89, %95
  %97 = mul nsw <16 x i32> %96, <i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272, i32 6272>
  %98 = add <16 x i32> %38, %94
  %99 = add <16 x i32> %98, %97
  %100 = extractelement <16 x i32> %99, i64 0
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !108
  %104 = insertelement <16 x float> undef, float %103, i32 0
  %105 = extractelement <16 x i32> %99, i64 1
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !108
  %109 = insertelement <16 x float> %104, float %108, i32 1
  %110 = extractelement <16 x i32> %99, i64 2
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = load float, float* %112, align 4, !tbaa !108
  %114 = insertelement <16 x float> %109, float %113, i32 2
  %115 = extractelement <16 x i32> %99, i64 3
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !108
  %119 = insertelement <16 x float> %114, float %118, i32 3
  %120 = extractelement <16 x i32> %99, i64 4
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !108
  %124 = insertelement <16 x float> %119, float %123, i32 4
  %125 = extractelement <16 x i32> %99, i64 5
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float* %7, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !108
  %129 = insertelement <16 x float> %124, float %128, i32 5
  %130 = extractelement <16 x i32> %99, i64 6
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %7, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !108
  %134 = insertelement <16 x float> %129, float %133, i32 6
  %135 = extractelement <16 x i32> %99, i64 7
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = load float, float* %137, align 4, !tbaa !108
  %139 = insertelement <16 x float> %134, float %138, i32 7
  %140 = extractelement <16 x i32> %99, i64 8
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !108
  %144 = insertelement <16 x float> %139, float %143, i32 8
  %145 = extractelement <16 x i32> %99, i64 9
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !108
  %149 = insertelement <16 x float> %144, float %148, i32 9
  %150 = extractelement <16 x i32> %99, i64 10
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !108
  %154 = insertelement <16 x float> %149, float %153, i32 10
  %155 = extractelement <16 x i32> %99, i64 11
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !108
  %159 = insertelement <16 x float> %154, float %158, i32 11
  %160 = extractelement <16 x i32> %99, i64 12
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = load float, float* %162, align 4, !tbaa !108
  %164 = insertelement <16 x float> %159, float %163, i32 12
  %165 = extractelement <16 x i32> %99, i64 13
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !108
  %169 = insertelement <16 x float> %164, float %168, i32 13
  %170 = extractelement <16 x i32> %99, i64 14
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !108
  %174 = insertelement <16 x float> %169, float %173, i32 14
  %175 = extractelement <16 x i32> %99, i64 15
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds float, float* %7, i64 %176
  %178 = load float, float* %177, align 4, !tbaa !108
  %179 = insertelement <16 x float> %174, float %178, i32 15
  %180 = getelementptr inbounds float, float* %4, i64 %41
  %181 = bitcast float* %180 to <16 x float>*
  store <16 x float> %179, <16 x float>* %181, align 64, !tbaa !111
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 8
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 14
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_nn_batch_flatten_multiply(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([101 x i8], [101 x i8]* @.str.24, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !114
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.25, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !128
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([176 x i8], [176 x i8]* @.str.26, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !130
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !144
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 16
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !146
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 1
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.28, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !149
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 1
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.29, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !151
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !155
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 512, i32 32, i32 32, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !167
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %81, %rdx.shuf
  %rdx.shuf43 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx44 = and <4 x i1> %bin.rdx, %rdx.shuf43
  %86 = extractelement <4 x i1> %bin.rdx44, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.30, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 2
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.31, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !171
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !185
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 512
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = icmp eq i64* %29, null
  br i1 %118, label %if_end34, label %if_then33, !prof !50

if_then33:                                        ; preds = %assert_end32
  %119 = load i64, i64* %29, align 8, !tbaa !187
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 512
  %122 = getelementptr inbounds i64, i64* %29, i64 1
  %123 = load i64, i64* %122, align 8, !tbaa !201
  %124 = trunc i64 %123 to i32
  %125 = icmp eq i32 %124, 1
  %126 = and i1 %121, %125
  br i1 %126, label %if_end34, label %assert_fail35, !prof !5

if_end34:                                         ; preds = %assert_end32, %if_then33
  %127 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %128 = load i64, i64* %127, align 8
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %assert_end38, label %assert_fail37, !prof !5

assert_fail35:                                    ; preds = %if_then33
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([124 x i8], [124 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_fail37:                                    ; preds = %if_end34
  %131 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %131(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %if_end34
  %132 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %133 = load i32, i32* %132, align 4
  %134 = icmp eq i32 %133, 1
  br i1 %134, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %136 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %137 = load i32, i32* %136, align 4
  %138 = icmp eq i32 %23, %137
  br i1 %138, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %139 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %139(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  tail call fastcc void @fused_layout_transform_nn_batch_flatten_multiply_compute_(i8* %25, i8* %15)
  ret i32 0
}

; Function Attrs: noinline norecurse nounwind
define private fastcc void @fused_layout_transform_nn_batch_flatten_multiply_compute_(i8* noalias nocapture, i8* noalias nocapture readonly) unnamed_addr #2 {
entry:
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %0, i8* align 64 %1, i64 2048, i1 false)
  ret void
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 5
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.34, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !203
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !217
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !220
  %26 = getelementptr inbounds i8, i8* %0, i64 32
  %27 = bitcast i8* %26 to %1**
  %28 = load %1*, %1** %27, align 8
  %29 = getelementptr inbounds i8, i8* %1, i64 16
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !222
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %33 = load i8*, i8** %32, align 8
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %37 = load i64*, i64** %36, align 8
  %38 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  %54 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %55 = load i8*, i8** %54, align 8
  %56 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %59 = load i64*, i64** %58, align 8
  %60 = getelementptr inbounds %1, %1* %28, i64 0, i32 0
  %61 = load i8*, i8** %60, align 8
  %62 = getelementptr inbounds %1, %1* %28, i64 0, i32 4
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %28, i64 0, i32 5
  %65 = load i64*, i64** %64, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.35, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %67 = getelementptr inbounds i8, i8* %1, i64 4
  %68 = bitcast i8* %67 to i32*
  %69 = load i32, i32* %68, align 4, !tbaa !226
  switch i32 %69, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.36, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.37, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %72 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %72(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.38, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %31, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.39, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %74 = icmp eq i32 %39, 1
  br i1 %74, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %75 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %75(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %76 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %77 = load i32, i32* %76, align 4
  %78 = icmp eq i32 %77, 5
  br i1 %78, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %80 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %81 = load i16, i16* %80, align 2
  %82 = icmp eq i16 %81, 1
  %83 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %84 = load i8, i8* %83, align 1
  %85 = icmp eq i8 %84, 32
  %86 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %87 = load i8, i8* %86, align 1
  %88 = icmp eq i8 %87, 2
  %89 = and i1 %85, %88
  %90 = and i1 %82, %89
  br i1 %90, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %92 = load i64, i64* %35, align 8, !tbaa !228
  %93 = trunc i64 %92 to i32
  %94 = icmp eq i32 %93, 1
  br i1 %94, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %96 = getelementptr inbounds i64, i64* %35, i64 1
  %97 = load i64, i64* %96, align 8, !tbaa !242
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 1
  br i1 %99, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %101 = getelementptr inbounds i64, i64* %35, i64 2
  %102 = load i64, i64* %101, align 8, !tbaa !244
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 28
  br i1 %104, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %106 = getelementptr inbounds i64, i64* %35, i64 3
  %107 = load i64, i64* %106, align 8, !tbaa !247
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 28
  br i1 %109, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %111 = getelementptr inbounds i64, i64* %35, i64 4
  %112 = load i64, i64* %111, align 8, !tbaa !249
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 128
  br i1 %114, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %116 = icmp eq i64* %37, null
  br i1 %116, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %117 = bitcast i64* %37 to <4 x i64>*
  %118 = load <4 x i64>, <4 x i64>* %117, align 8, !tbaa !253
  %119 = trunc <4 x i64> %118 to <4 x i32>
  %120 = icmp eq <4 x i32> %119, <i32 100352, i32 100352, i32 3584, i32 128>
  %121 = getelementptr inbounds i64, i64* %37, i64 4
  %122 = load i64, i64* %121, align 8, !tbaa !265
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 1
  %rdx.shuf143 = shufflevector <4 x i1> %120, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx144 = and <4 x i1> %120, %rdx.shuf143
  %rdx.shuf145 = shufflevector <4 x i1> %bin.rdx144, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx146 = and <4 x i1> %bin.rdx144, %rdx.shuf145
  %125 = extractelement <4 x i1> %bin.rdx146, i32 0
  %126 = and i1 %125, %124
  br i1 %126, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %127 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %128 = load i64, i64* %127, align 8
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %131 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %131(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %132 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %133 = load i32, i32* %132, align 4
  %134 = icmp eq i32 %133, 6
  br i1 %134, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %136 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %137 = load i16, i16* %136, align 2
  %138 = icmp eq i16 %137, 1
  %139 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %140 = load i8, i8* %139, align 1
  %141 = icmp eq i8 %140, 32
  %142 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %143 = load i8, i8* %142, align 1
  %144 = icmp eq i8 %143, 2
  %145 = and i1 %141, %144
  %146 = and i1 %138, %145
  br i1 %146, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %148 = load i64, i64* %45, align 8, !tbaa !269
  %149 = trunc i64 %148 to i32
  %150 = icmp eq i32 %149, 4
  br i1 %150, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %151 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %151(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.46, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %152 = getelementptr inbounds i64, i64* %45, i64 1
  %153 = load i64, i64* %152, align 8, !tbaa !283
  %154 = trunc i64 %153 to i32
  %155 = icmp eq i32 %154, 1
  br i1 %155, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %157 = getelementptr inbounds i64, i64* %45, i64 2
  %158 = load i64, i64* %157, align 8, !tbaa !285
  %159 = trunc i64 %158 to i32
  %160 = icmp eq i32 %159, 3
  br i1 %160, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %161 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %161(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %162 = getelementptr inbounds i64, i64* %45, i64 3
  %163 = load i64, i64* %162, align 8, !tbaa !288
  %164 = trunc i64 %163 to i32
  %165 = icmp eq i32 %164, 3
  br i1 %165, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %166 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %166(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %167 = getelementptr inbounds i64, i64* %45, i64 4
  %168 = load i64, i64* %167, align 8, !tbaa !290
  %169 = trunc i64 %168 to i32
  %170 = icmp eq i32 %169, 128
  br i1 %170, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %172 = getelementptr inbounds i64, i64* %45, i64 5
  %173 = load i64, i64* %172, align 8, !tbaa !294
  %174 = trunc i64 %173 to i32
  %175 = icmp eq i32 %174, 32
  br i1 %175, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %176 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %176(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %177 = icmp eq i64* %47, null
  br i1 %177, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %178 = bitcast i64* %47 to <4 x i64>*
  %179 = load <4 x i64>, <4 x i64>* %178, align 8, !tbaa !296
  %180 = trunc <4 x i64> %179 to <4 x i32>
  %181 = icmp eq <4 x i32> %180, <i32 36864, i32 36864, i32 12288, i32 4096>
  %182 = getelementptr inbounds i64, i64* %47, i64 4
  %183 = load i64, i64* %182, align 8, !tbaa !308
  %184 = trunc i64 %183 to i32
  %185 = icmp eq i32 %184, 32
  %186 = getelementptr inbounds i64, i64* %47, i64 5
  %187 = load i64, i64* %186, align 8, !tbaa !312
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  %rdx.shuf139 = shufflevector <4 x i1> %181, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %181, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %190 = extractelement <4 x i1> %bin.rdx142, i32 0
  %191 = and i1 %190, %185
  %192 = and i1 %191, %189
  br i1 %192, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %193 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %194 = load i64, i64* %193, align 8
  %195 = icmp eq i64 %194, 0
  br i1 %195, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([278 x i8], [278 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %197 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %197(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %198 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %199 = load i32, i32* %198, align 4
  %200 = icmp eq i32 %199, 1
  br i1 %200, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %201 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %201(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %202 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %203 = load i32, i32* %202, align 4
  %204 = icmp eq i32 %41, %203
  br i1 %204, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %205 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %205(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %206 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %207 = load i32, i32* %206, align 4
  %208 = icmp eq i32 %207, 5
  br i1 %208, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %209 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %209(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %210 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %211 = load i16, i16* %210, align 2
  %212 = icmp eq i16 %211, 1
  %213 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %214 = load i8, i8* %213, align 1
  %215 = icmp eq i8 %214, 32
  %216 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %217 = load i8, i8* %216, align 1
  %218 = icmp eq i8 %217, 2
  %219 = and i1 %215, %218
  %220 = and i1 %212, %219
  br i1 %220, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %222 = load i64, i64* %51, align 8, !tbaa !314
  %223 = trunc i64 %222 to i32
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %226 = getelementptr inbounds i64, i64* %51, i64 1
  %227 = load i64, i64* %226, align 8, !tbaa !328
  %228 = trunc i64 %227 to i32
  %229 = icmp eq i32 %228, 4
  br i1 %229, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %230 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %230(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.55, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %231 = getelementptr inbounds i64, i64* %51, i64 2
  %232 = load i64, i64* %231, align 8, !tbaa !330
  %233 = trunc i64 %232 to i32
  %234 = icmp eq i32 %233, 1
  br i1 %234, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %235 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %235(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %236 = getelementptr inbounds i64, i64* %51, i64 3
  %237 = load i64, i64* %236, align 8, !tbaa !333
  %238 = trunc i64 %237 to i32
  %239 = icmp eq i32 %238, 1
  br i1 %239, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %240 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %240(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %241 = getelementptr inbounds i64, i64* %51, i64 4
  %242 = load i64, i64* %241, align 8, !tbaa !335
  %243 = trunc i64 %242 to i32
  %244 = icmp eq i32 %243, 32
  br i1 %244, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %246 = icmp eq i64* %53, null
  br i1 %246, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %247 = bitcast i64* %53 to <4 x i64>*
  %248 = load <4 x i64>, <4 x i64>* %247, align 8, !tbaa !339
  %249 = trunc <4 x i64> %248 to <4 x i32>
  %250 = icmp eq <4 x i32> %249, <i32 128, i32 32, i32 32, i32 32>
  %251 = getelementptr inbounds i64, i64* %53, i64 4
  %252 = load i64, i64* %251, align 8, !tbaa !351
  %253 = trunc i64 %252 to i32
  %254 = icmp eq i32 %253, 1
  %rdx.shuf135 = shufflevector <4 x i1> %250, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %250, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %255 = extractelement <4 x i1> %bin.rdx138, i32 0
  %256 = and i1 %255, %254
  br i1 %256, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %257 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %258 = load i64, i64* %257, align 8
  %259 = icmp eq i64 %258, 0
  br i1 %259, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %262 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %263 = load i32, i32* %262, align 4
  %264 = icmp eq i32 %263, 1
  br i1 %264, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %265 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %265(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %266 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %267 = load i32, i32* %266, align 4
  %268 = icmp eq i32 %41, %267
  br i1 %268, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %269 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %269(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %270 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %271 = load i32, i32* %270, align 4
  %272 = icmp eq i32 %271, 5
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %275 = load i16, i16* %274, align 2
  %276 = icmp eq i16 %275, 1
  %277 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %278 = load i8, i8* %277, align 1
  %279 = icmp eq i8 %278, 32
  %280 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %281 = load i8, i8* %280, align 1
  %282 = icmp eq i8 %281, 2
  %283 = and i1 %279, %282
  %284 = and i1 %276, %283
  br i1 %284, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %285 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %285(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %286 = load i64, i64* %57, align 8, !tbaa !355
  %287 = trunc i64 %286 to i32
  %288 = icmp eq i32 %287, 1
  br i1 %288, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %289 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %289(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %290 = getelementptr inbounds i64, i64* %57, i64 1
  %291 = load i64, i64* %290, align 8, !tbaa !369
  %292 = trunc i64 %291 to i32
  %293 = icmp eq i32 %292, 4
  br i1 %293, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %294 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %294(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %295 = getelementptr inbounds i64, i64* %57, i64 2
  %296 = load i64, i64* %295, align 8, !tbaa !371
  %297 = trunc i64 %296 to i32
  %298 = icmp eq i32 %297, 28
  br i1 %298, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %300 = getelementptr inbounds i64, i64* %57, i64 3
  %301 = load i64, i64* %300, align 8, !tbaa !374
  %302 = trunc i64 %301 to i32
  %303 = icmp eq i32 %302, 28
  br i1 %303, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %304 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %304(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %305 = getelementptr inbounds i64, i64* %57, i64 4
  %306 = load i64, i64* %305, align 8, !tbaa !376
  %307 = trunc i64 %306 to i32
  %308 = icmp eq i32 %307, 32
  br i1 %308, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %309 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %309(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %310 = icmp eq i64* %59, null
  br i1 %310, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %311 = bitcast i64* %59 to <4 x i64>*
  %312 = load <4 x i64>, <4 x i64>* %311, align 8, !tbaa !380
  %313 = trunc <4 x i64> %312 to <4 x i32>
  %314 = icmp eq <4 x i32> %313, <i32 100352, i32 25088, i32 896, i32 32>
  %315 = getelementptr inbounds i64, i64* %59, i64 4
  %316 = load i64, i64* %315, align 8, !tbaa !392
  %317 = trunc i64 %316 to i32
  %318 = icmp eq i32 %317, 1
  %rdx.shuf131 = shufflevector <4 x i1> %314, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %314, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %319 = extractelement <4 x i1> %bin.rdx134, i32 0
  %320 = and i1 %319, %318
  br i1 %320, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %321 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %322 = load i64, i64* %321, align 8
  %323 = icmp eq i64 %322, 0
  br i1 %323, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %325 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %325(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %326 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %327 = load i32, i32* %326, align 4
  %328 = icmp eq i32 %327, 1
  br i1 %328, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %330 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %41, %331
  br i1 %332, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %334 = getelementptr inbounds %1, %1* %28, i64 0, i32 2
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %335, 5
  br i1 %336, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %338 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 2
  %339 = load i16, i16* %338, align 2
  %340 = icmp eq i16 %339, 1
  %341 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 1
  %342 = load i8, i8* %341, align 1
  %343 = icmp eq i8 %342, 32
  %344 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 0
  %345 = load i8, i8* %344, align 1
  %346 = icmp eq i8 %345, 2
  %347 = and i1 %343, %346
  %348 = and i1 %340, %347
  br i1 %348, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %350 = load i64, i64* %63, align 8, !tbaa !396
  %351 = trunc i64 %350 to i32
  %352 = icmp eq i32 %351, 1
  br i1 %352, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %354 = getelementptr inbounds i64, i64* %63, i64 1
  %355 = load i64, i64* %354, align 8, !tbaa !410
  %356 = trunc i64 %355 to i32
  %357 = icmp eq i32 %356, 4
  br i1 %357, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %358 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %358(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.77, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %359 = getelementptr inbounds i64, i64* %63, i64 2
  %360 = load i64, i64* %359, align 8, !tbaa !412
  %361 = trunc i64 %360 to i32
  %362 = icmp eq i32 %361, 28
  br i1 %362, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %363 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %363(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.78, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %364 = getelementptr inbounds i64, i64* %63, i64 3
  %365 = load i64, i64* %364, align 8, !tbaa !415
  %366 = trunc i64 %365 to i32
  %367 = icmp eq i32 %366, 28
  br i1 %367, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %368 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %368(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.79, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %369 = getelementptr inbounds i64, i64* %63, i64 4
  %370 = load i64, i64* %369, align 8, !tbaa !417
  %371 = trunc i64 %370 to i32
  %372 = icmp eq i32 %371, 32
  br i1 %372, label %assert_end118, label %assert_fail117, !prof !5

assert_fail117:                                   ; preds = %assert_end116
  %373 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %373(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.80, i64 0, i64 0))
  ret i32 -1

assert_end118:                                    ; preds = %assert_end116
  %374 = icmp eq i64* %65, null
  br i1 %374, label %if_end120, label %if_then119, !prof !50

if_then119:                                       ; preds = %assert_end118
  %375 = bitcast i64* %65 to <4 x i64>*
  %376 = load <4 x i64>, <4 x i64>* %375, align 8, !tbaa !421
  %377 = trunc <4 x i64> %376 to <4 x i32>
  %378 = icmp eq <4 x i32> %377, <i32 100352, i32 25088, i32 896, i32 32>
  %379 = getelementptr inbounds i64, i64* %65, i64 4
  %380 = load i64, i64* %379, align 8, !tbaa !433
  %381 = trunc i64 %380 to i32
  %382 = icmp eq i32 %381, 1
  %rdx.shuf = shufflevector <4 x i1> %378, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %378, %rdx.shuf
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx, %rdx.shuf129
  %383 = extractelement <4 x i1> %bin.rdx130, i32 0
  %384 = and i1 %383, %382
  br i1 %384, label %if_end120, label %assert_fail121, !prof !5

if_end120:                                        ; preds = %assert_end118, %if_then119
  %385 = getelementptr inbounds %1, %1* %28, i64 0, i32 6
  %386 = load i64, i64* %385, align 8
  %387 = icmp eq i64 %386, 0
  br i1 %387, label %assert_end124, label %assert_fail123, !prof !5

assert_fail121:                                   ; preds = %if_then119
  %388 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %388(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.81, i64 0, i64 0))
  ret i32 -1

assert_fail123:                                   ; preds = %if_end120
  %389 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %389(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.82, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %if_end120
  %390 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 0
  %391 = load i32, i32* %390, align 4
  %392 = icmp eq i32 %391, 1
  br i1 %392, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %393 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %393(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.83, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %394 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 1
  %395 = load i32, i32* %394, align 4
  %396 = icmp eq i32 %41, %395
  br i1 %396, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %397 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %397(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %398 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2_compute_(i8* %33, i8* %43, i8* %61, i8* %49, i8* %55, i32 %41)
  ret i32 %398
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 460800, i32 2, i32 32)
  %8 = alloca %5, align 8
  %9 = getelementptr inbounds %5, %5* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %5, %5* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %5* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.85, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %24, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %6, align 8
  %16 = getelementptr inbounds %6, %6* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %6, %6* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %6, %6* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %6, %6* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %6, %6* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = getelementptr inbounds %6, %6* %15, i64 0, i32 5
  store i32 %5, i32* %21, align 8
  %22 = bitcast %6* %15 to i8*
  %23 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %24 = call i32 %23(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.86, i8* nonnull %22, i32 0)
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %26 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %27 = call i32 %26(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.85(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 29
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 30
  %15 = select i1 %14, i32 %13, i32 30
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 30
  %18 = select i1 %17, i32 %16, i32 30
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 30
  %21 = select i1 %20, i32 %16, i32 30
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -3840
  %23 = add i32 %22, -3840
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv, 3840
  %29 = trunc i64 %indvars.iv to i32
  %.off = add i32 %29, -1
  %30 = icmp ult i32 %.off, 28
  %31 = trunc i64 %indvars.iv to i32
  %32 = mul i32 %31, 3584
  br i1 %30, label %if_end.us.29, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %33 = mul i32 %indvar, 3840
  %34 = add i32 %23, %33
  %35 = sext i32 %34 to i64
  %scevgep = getelementptr float, float* %4, i64 %35
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 15360, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_body2.preheader, %if_end.us.29
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %36 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %36, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.29:                                     ; preds = %for_begin1.preheader
  %37 = getelementptr inbounds float, float* %4, i64 %28
  %38 = bitcast float* %37 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %38, align 64, !tbaa !437
  %39 = or i64 %28, 128
  %40 = add i32 %32, -3584
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %7, i64 %41
  %43 = bitcast float* %42 to <128 x float>*
  %44 = load <128 x float>, <128 x float>* %43, align 64, !tbaa !440
  %45 = getelementptr inbounds float, float* %4, i64 %39
  %46 = bitcast float* %45 to <128 x float>*
  store <128 x float> %44, <128 x float>* %46, align 64, !tbaa !437
  %47 = add nsw i64 %28, 256
  %48 = add i32 %32, -3456
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to <128 x float>*
  %52 = load <128 x float>, <128 x float>* %51, align 64, !tbaa !440
  %53 = getelementptr inbounds float, float* %4, i64 %47
  %54 = bitcast float* %53 to <128 x float>*
  store <128 x float> %52, <128 x float>* %54, align 64, !tbaa !437
  %55 = add nsw i64 %28, 384
  %56 = add i32 %32, -3328
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds float, float* %7, i64 %57
  %59 = bitcast float* %58 to <128 x float>*
  %60 = load <128 x float>, <128 x float>* %59, align 64, !tbaa !440
  %61 = getelementptr inbounds float, float* %4, i64 %55
  %62 = bitcast float* %61 to <128 x float>*
  store <128 x float> %60, <128 x float>* %62, align 64, !tbaa !437
  %63 = add nsw i64 %28, 512
  %64 = add i32 %32, -3200
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <128 x float>*
  %68 = load <128 x float>, <128 x float>* %67, align 64, !tbaa !440
  %69 = getelementptr inbounds float, float* %4, i64 %63
  %70 = bitcast float* %69 to <128 x float>*
  store <128 x float> %68, <128 x float>* %70, align 64, !tbaa !437
  %71 = add nsw i64 %28, 640
  %72 = add i32 %32, -3072
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = bitcast float* %74 to <128 x float>*
  %76 = load <128 x float>, <128 x float>* %75, align 64, !tbaa !440
  %77 = getelementptr inbounds float, float* %4, i64 %71
  %78 = bitcast float* %77 to <128 x float>*
  store <128 x float> %76, <128 x float>* %78, align 64, !tbaa !437
  %79 = add nsw i64 %28, 768
  %80 = add i32 %32, -2944
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <128 x float>*
  %84 = load <128 x float>, <128 x float>* %83, align 64, !tbaa !440
  %85 = getelementptr inbounds float, float* %4, i64 %79
  %86 = bitcast float* %85 to <128 x float>*
  store <128 x float> %84, <128 x float>* %86, align 64, !tbaa !437
  %87 = add nsw i64 %28, 896
  %88 = add i32 %32, -2816
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds float, float* %7, i64 %89
  %91 = bitcast float* %90 to <128 x float>*
  %92 = load <128 x float>, <128 x float>* %91, align 64, !tbaa !440
  %93 = getelementptr inbounds float, float* %4, i64 %87
  %94 = bitcast float* %93 to <128 x float>*
  store <128 x float> %92, <128 x float>* %94, align 64, !tbaa !437
  %95 = add nsw i64 %28, 1024
  %96 = add i32 %32, -2688
  %97 = sext i32 %96 to i64
  %98 = getelementptr inbounds float, float* %7, i64 %97
  %99 = bitcast float* %98 to <128 x float>*
  %100 = load <128 x float>, <128 x float>* %99, align 64, !tbaa !440
  %101 = getelementptr inbounds float, float* %4, i64 %95
  %102 = bitcast float* %101 to <128 x float>*
  store <128 x float> %100, <128 x float>* %102, align 64, !tbaa !437
  %103 = add nsw i64 %28, 1152
  %104 = add i32 %32, -2560
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds float, float* %7, i64 %105
  %107 = bitcast float* %106 to <128 x float>*
  %108 = load <128 x float>, <128 x float>* %107, align 64, !tbaa !440
  %109 = getelementptr inbounds float, float* %4, i64 %103
  %110 = bitcast float* %109 to <128 x float>*
  store <128 x float> %108, <128 x float>* %110, align 64, !tbaa !437
  %111 = add nsw i64 %28, 1280
  %112 = add i32 %32, -2432
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to <128 x float>*
  %116 = load <128 x float>, <128 x float>* %115, align 64, !tbaa !440
  %117 = getelementptr inbounds float, float* %4, i64 %111
  %118 = bitcast float* %117 to <128 x float>*
  store <128 x float> %116, <128 x float>* %118, align 64, !tbaa !437
  %119 = add nsw i64 %28, 1408
  %120 = add i32 %32, -2304
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = bitcast float* %122 to <128 x float>*
  %124 = load <128 x float>, <128 x float>* %123, align 64, !tbaa !440
  %125 = getelementptr inbounds float, float* %4, i64 %119
  %126 = bitcast float* %125 to <128 x float>*
  store <128 x float> %124, <128 x float>* %126, align 64, !tbaa !437
  %127 = add nsw i64 %28, 1536
  %128 = add i32 %32, -2176
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds float, float* %7, i64 %129
  %131 = bitcast float* %130 to <128 x float>*
  %132 = load <128 x float>, <128 x float>* %131, align 64, !tbaa !440
  %133 = getelementptr inbounds float, float* %4, i64 %127
  %134 = bitcast float* %133 to <128 x float>*
  store <128 x float> %132, <128 x float>* %134, align 64, !tbaa !437
  %135 = add nsw i64 %28, 1664
  %136 = add i32 %32, -2048
  %137 = sext i32 %136 to i64
  %138 = getelementptr inbounds float, float* %7, i64 %137
  %139 = bitcast float* %138 to <128 x float>*
  %140 = load <128 x float>, <128 x float>* %139, align 64, !tbaa !440
  %141 = getelementptr inbounds float, float* %4, i64 %135
  %142 = bitcast float* %141 to <128 x float>*
  store <128 x float> %140, <128 x float>* %142, align 64, !tbaa !437
  %143 = add nsw i64 %28, 1792
  %144 = add i32 %32, -1920
  %145 = sext i32 %144 to i64
  %146 = getelementptr inbounds float, float* %7, i64 %145
  %147 = bitcast float* %146 to <128 x float>*
  %148 = load <128 x float>, <128 x float>* %147, align 64, !tbaa !440
  %149 = getelementptr inbounds float, float* %4, i64 %143
  %150 = bitcast float* %149 to <128 x float>*
  store <128 x float> %148, <128 x float>* %150, align 64, !tbaa !437
  %151 = add nsw i64 %28, 1920
  %152 = add i32 %32, -1792
  %153 = sext i32 %152 to i64
  %154 = getelementptr inbounds float, float* %7, i64 %153
  %155 = bitcast float* %154 to <128 x float>*
  %156 = load <128 x float>, <128 x float>* %155, align 64, !tbaa !440
  %157 = getelementptr inbounds float, float* %4, i64 %151
  %158 = bitcast float* %157 to <128 x float>*
  store <128 x float> %156, <128 x float>* %158, align 64, !tbaa !437
  %159 = add nsw i64 %28, 2048
  %160 = add i32 %32, -1664
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = bitcast float* %162 to <128 x float>*
  %164 = load <128 x float>, <128 x float>* %163, align 64, !tbaa !440
  %165 = getelementptr inbounds float, float* %4, i64 %159
  %166 = bitcast float* %165 to <128 x float>*
  store <128 x float> %164, <128 x float>* %166, align 64, !tbaa !437
  %167 = add nsw i64 %28, 2176
  %168 = add i32 %32, -1536
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to <128 x float>*
  %172 = load <128 x float>, <128 x float>* %171, align 64, !tbaa !440
  %173 = getelementptr inbounds float, float* %4, i64 %167
  %174 = bitcast float* %173 to <128 x float>*
  store <128 x float> %172, <128 x float>* %174, align 64, !tbaa !437
  %175 = add nsw i64 %28, 2304
  %176 = add i32 %32, -1408
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds float, float* %7, i64 %177
  %179 = bitcast float* %178 to <128 x float>*
  %180 = load <128 x float>, <128 x float>* %179, align 64, !tbaa !440
  %181 = getelementptr inbounds float, float* %4, i64 %175
  %182 = bitcast float* %181 to <128 x float>*
  store <128 x float> %180, <128 x float>* %182, align 64, !tbaa !437
  %183 = add nsw i64 %28, 2432
  %184 = add i32 %32, -1280
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds float, float* %7, i64 %185
  %187 = bitcast float* %186 to <128 x float>*
  %188 = load <128 x float>, <128 x float>* %187, align 64, !tbaa !440
  %189 = getelementptr inbounds float, float* %4, i64 %183
  %190 = bitcast float* %189 to <128 x float>*
  store <128 x float> %188, <128 x float>* %190, align 64, !tbaa !437
  %191 = add nsw i64 %28, 2560
  %192 = add i32 %32, -1152
  %193 = sext i32 %192 to i64
  %194 = getelementptr inbounds float, float* %7, i64 %193
  %195 = bitcast float* %194 to <128 x float>*
  %196 = load <128 x float>, <128 x float>* %195, align 64, !tbaa !440
  %197 = getelementptr inbounds float, float* %4, i64 %191
  %198 = bitcast float* %197 to <128 x float>*
  store <128 x float> %196, <128 x float>* %198, align 64, !tbaa !437
  %199 = add nsw i64 %28, 2688
  %200 = add i32 %32, -1024
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds float, float* %7, i64 %201
  %203 = bitcast float* %202 to <128 x float>*
  %204 = load <128 x float>, <128 x float>* %203, align 64, !tbaa !440
  %205 = getelementptr inbounds float, float* %4, i64 %199
  %206 = bitcast float* %205 to <128 x float>*
  store <128 x float> %204, <128 x float>* %206, align 64, !tbaa !437
  %207 = add nsw i64 %28, 2816
  %208 = add i32 %32, -896
  %209 = sext i32 %208 to i64
  %210 = getelementptr inbounds float, float* %7, i64 %209
  %211 = bitcast float* %210 to <128 x float>*
  %212 = load <128 x float>, <128 x float>* %211, align 64, !tbaa !440
  %213 = getelementptr inbounds float, float* %4, i64 %207
  %214 = bitcast float* %213 to <128 x float>*
  store <128 x float> %212, <128 x float>* %214, align 64, !tbaa !437
  %215 = add nsw i64 %28, 2944
  %216 = add i32 %32, -768
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds float, float* %7, i64 %217
  %219 = bitcast float* %218 to <128 x float>*
  %220 = load <128 x float>, <128 x float>* %219, align 64, !tbaa !440
  %221 = getelementptr inbounds float, float* %4, i64 %215
  %222 = bitcast float* %221 to <128 x float>*
  store <128 x float> %220, <128 x float>* %222, align 64, !tbaa !437
  %223 = add nsw i64 %28, 3072
  %224 = add i32 %32, -640
  %225 = sext i32 %224 to i64
  %226 = getelementptr inbounds float, float* %7, i64 %225
  %227 = bitcast float* %226 to <128 x float>*
  %228 = load <128 x float>, <128 x float>* %227, align 64, !tbaa !440
  %229 = getelementptr inbounds float, float* %4, i64 %223
  %230 = bitcast float* %229 to <128 x float>*
  store <128 x float> %228, <128 x float>* %230, align 64, !tbaa !437
  %231 = add nsw i64 %28, 3200
  %232 = add i32 %32, -512
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <128 x float>*
  %236 = load <128 x float>, <128 x float>* %235, align 64, !tbaa !440
  %237 = getelementptr inbounds float, float* %4, i64 %231
  %238 = bitcast float* %237 to <128 x float>*
  store <128 x float> %236, <128 x float>* %238, align 64, !tbaa !437
  %239 = add nsw i64 %28, 3328
  %240 = add i32 %32, -384
  %241 = sext i32 %240 to i64
  %242 = getelementptr inbounds float, float* %7, i64 %241
  %243 = bitcast float* %242 to <128 x float>*
  %244 = load <128 x float>, <128 x float>* %243, align 64, !tbaa !440
  %245 = getelementptr inbounds float, float* %4, i64 %239
  %246 = bitcast float* %245 to <128 x float>*
  store <128 x float> %244, <128 x float>* %246, align 64, !tbaa !437
  %247 = add nsw i64 %28, 3456
  %248 = add i32 %32, -256
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds float, float* %7, i64 %249
  %251 = bitcast float* %250 to <128 x float>*
  %252 = load <128 x float>, <128 x float>* %251, align 64, !tbaa !440
  %253 = getelementptr inbounds float, float* %4, i64 %247
  %254 = bitcast float* %253 to <128 x float>*
  store <128 x float> %252, <128 x float>* %254, align 64, !tbaa !437
  %255 = add nsw i64 %28, 3584
  %256 = add i32 %32, -128
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds float, float* %7, i64 %257
  %259 = bitcast float* %258 to <128 x float>*
  %260 = load <128 x float>, <128 x float>* %259, align 64, !tbaa !440
  %261 = getelementptr inbounds float, float* %4, i64 %255
  %262 = bitcast float* %261 to <128 x float>*
  store <128 x float> %260, <128 x float>* %262, align 64, !tbaa !437
  %263 = add nsw i64 %28, 3712
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = bitcast float* %264 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %265, align 64, !tbaa !437
  br label %for_end3
}

define private i32 @__tvm_parallel_lambda.86(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to float**
  %18 = load float*, float** %17, align 8
  %19 = getelementptr inbounds i8, i8* %2, i64 40
  %20 = bitcast i8* %19 to i32*
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, 111
  %25 = sdiv i32 %24, %23
  %26 = add nsw i32 %0, 1
  %27 = mul nsw i32 %25, %26
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = mul nsw i32 %25, %0
  %31 = icmp slt i32 %30, 112
  %32 = select i1 %31, i32 %30, i32 112
  %33 = icmp slt i32 %32, %29
  br i1 %33, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %34 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %35 = bitcast float* %34 to <32 x float>*
  %36 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %37 = bitcast float* %36 to <32 x float>*
  %38 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %39 = bitcast float* %38 to <32 x float>*
  %40 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %41 = bitcast float* %40 to <32 x float>*
  %42 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %43 = bitcast float* %42 to <32 x float>*
  %44 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %45 = bitcast float* %44 to <32 x float>*
  %46 = add i32 %32, 1
  %47 = sext i32 %46 to i64
  %48 = add nsw i64 %47, -1
  %49 = sext i32 %29 to i64
  %50 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin13.preheader
  %indvars.iv68 = phi i64 [ %48, %for_body.lr.ph ], [ %indvars.iv.next69, %for_begin13.preheader ]
  %51 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %52 = tail call i8* %51(i32 1, i32 %21, i64 3584, i32 2, i32 32)
  %53 = trunc i64 %indvars.iv68 to i32
  %54 = srem i32 %53, 28
  %55 = sdiv i32 %53, 28
  %56 = mul nsw i32 %55, 36864
  %57 = sext i32 %56 to i64
  %58 = mul nsw i32 %54, 3840
  %59 = sext i32 %58 to i64
  %60 = mul nsw i32 %54, 3840
  %61 = add nsw i32 %60, 3840
  %62 = sext i32 %61 to i64
  %63 = add nsw i64 %57, 12288
  %64 = mul nsw i32 %54, 3840
  %65 = add nsw i32 %64, 7680
  %66 = sext i32 %65 to i64
  %67 = add nsw i64 %57, 24576
  br label %for_body2

for_end:                                          ; preds = %for_begin13.preheader, %entry
  ret i32 0

for_begin13.preheader:                            ; preds = %for_end9.2
  %68 = mul nsw i64 %indvars.iv68, 896
  %69 = shl nsw i32 %55, 5
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds float, float* %15, i64 %70
  %72 = bitcast float* %71 to <32 x float>*
  %73 = load <32 x float>, <32 x float>* %72, align 64, !tbaa !443
  %74 = getelementptr inbounds float, float* %18, i64 %68
  %75 = bitcast float* %74 to <32 x float>*
  %76 = load <32 x float>, <32 x float>* %75, align 64, !tbaa !446
  %77 = bitcast i8* %52 to <32 x float>*
  %78 = load <32 x float>, <32 x float>* %77, align 64, !tbaa !449
  %79 = fadd <32 x float> %73, %78
  %80 = fadd <32 x float> %76, %79
  %81 = fcmp ogt <32 x float> %80, zeroinitializer
  %82 = select <32 x i1> %81, <32 x float> %80, <32 x float> zeroinitializer
  %83 = getelementptr inbounds float, float* %12, i64 %68
  %84 = bitcast float* %83 to <32 x float>*
  store <32 x float> %82, <32 x float>* %84, align 64, !tbaa !452
  %85 = mul i64 %indvars.iv68, 3848290697216
  %sext = ashr exact i64 %85, 32
  %86 = or i64 %sext, 32
  %87 = getelementptr inbounds float, float* %18, i64 %86
  %88 = bitcast float* %87 to <32 x float>*
  %89 = load <32 x float>, <32 x float>* %88, align 64, !tbaa !446
  %90 = getelementptr inbounds i8, i8* %52, i64 128
  %91 = bitcast i8* %90 to <32 x float>*
  %92 = load <32 x float>, <32 x float>* %91, align 64, !tbaa !449
  %93 = fadd <32 x float> %73, %92
  %94 = fadd <32 x float> %89, %93
  %95 = fcmp ogt <32 x float> %94, zeroinitializer
  %96 = select <32 x i1> %95, <32 x float> %94, <32 x float> zeroinitializer
  %97 = getelementptr inbounds float, float* %12, i64 %86
  %98 = bitcast float* %97 to <32 x float>*
  store <32 x float> %96, <32 x float>* %98, align 64, !tbaa !452
  %99 = mul i64 %indvars.iv68, 3848290697216
  %sext70 = ashr exact i64 %99, 32
  %100 = or i64 %sext70, 64
  %101 = getelementptr inbounds float, float* %18, i64 %100
  %102 = bitcast float* %101 to <32 x float>*
  %103 = load <32 x float>, <32 x float>* %102, align 64, !tbaa !446
  %104 = getelementptr inbounds i8, i8* %52, i64 256
  %105 = bitcast i8* %104 to <32 x float>*
  %106 = load <32 x float>, <32 x float>* %105, align 64, !tbaa !449
  %107 = fadd <32 x float> %73, %106
  %108 = fadd <32 x float> %103, %107
  %109 = fcmp ogt <32 x float> %108, zeroinitializer
  %110 = select <32 x i1> %109, <32 x float> %108, <32 x float> zeroinitializer
  %111 = getelementptr inbounds float, float* %12, i64 %100
  %112 = bitcast float* %111 to <32 x float>*
  store <32 x float> %110, <32 x float>* %112, align 64, !tbaa !452
  %113 = mul i64 %indvars.iv68, 3848290697216
  %sext71 = ashr exact i64 %113, 32
  %114 = or i64 %sext71, 96
  %115 = getelementptr inbounds float, float* %18, i64 %114
  %116 = bitcast float* %115 to <32 x float>*
  %117 = load <32 x float>, <32 x float>* %116, align 64, !tbaa !446
  %118 = getelementptr inbounds i8, i8* %52, i64 384
  %119 = bitcast i8* %118 to <32 x float>*
  %120 = load <32 x float>, <32 x float>* %119, align 64, !tbaa !449
  %121 = fadd <32 x float> %73, %120
  %122 = fadd <32 x float> %117, %121
  %123 = fcmp ogt <32 x float> %122, zeroinitializer
  %124 = select <32 x i1> %123, <32 x float> %122, <32 x float> zeroinitializer
  %125 = getelementptr inbounds float, float* %12, i64 %114
  %126 = bitcast float* %125 to <32 x float>*
  store <32 x float> %124, <32 x float>* %126, align 64, !tbaa !452
  %127 = mul i64 %indvars.iv68, 3848290697216
  %sext72 = add i64 %127, 549755813888
  %128 = ashr exact i64 %sext72, 32
  %129 = getelementptr inbounds float, float* %18, i64 %128
  %130 = bitcast float* %129 to <32 x float>*
  %131 = load <32 x float>, <32 x float>* %130, align 64, !tbaa !446
  %132 = getelementptr inbounds i8, i8* %52, i64 512
  %133 = bitcast i8* %132 to <32 x float>*
  %134 = load <32 x float>, <32 x float>* %133, align 64, !tbaa !449
  %135 = fadd <32 x float> %73, %134
  %136 = fadd <32 x float> %131, %135
  %137 = fcmp ogt <32 x float> %136, zeroinitializer
  %138 = select <32 x i1> %137, <32 x float> %136, <32 x float> zeroinitializer
  %139 = getelementptr inbounds float, float* %12, i64 %128
  %140 = bitcast float* %139 to <32 x float>*
  store <32 x float> %138, <32 x float>* %140, align 64, !tbaa !452
  %141 = mul i64 %indvars.iv68, 3848290697216
  %sext73 = add i64 %141, 687194767360
  %142 = ashr exact i64 %sext73, 32
  %143 = getelementptr inbounds float, float* %18, i64 %142
  %144 = bitcast float* %143 to <32 x float>*
  %145 = load <32 x float>, <32 x float>* %144, align 64, !tbaa !446
  %146 = getelementptr inbounds i8, i8* %52, i64 640
  %147 = bitcast i8* %146 to <32 x float>*
  %148 = load <32 x float>, <32 x float>* %147, align 64, !tbaa !449
  %149 = fadd <32 x float> %73, %148
  %150 = fadd <32 x float> %145, %149
  %151 = fcmp ogt <32 x float> %150, zeroinitializer
  %152 = select <32 x i1> %151, <32 x float> %150, <32 x float> zeroinitializer
  %153 = getelementptr inbounds float, float* %12, i64 %142
  %154 = bitcast float* %153 to <32 x float>*
  store <32 x float> %152, <32 x float>* %154, align 64, !tbaa !452
  %155 = mul i64 %indvars.iv68, 3848290697216
  %sext74 = add i64 %155, 824633720832
  %156 = ashr exact i64 %sext74, 32
  %157 = getelementptr inbounds float, float* %18, i64 %156
  %158 = bitcast float* %157 to <32 x float>*
  %159 = load <32 x float>, <32 x float>* %158, align 64, !tbaa !446
  %160 = getelementptr inbounds i8, i8* %52, i64 768
  %161 = bitcast i8* %160 to <32 x float>*
  %162 = load <32 x float>, <32 x float>* %161, align 64, !tbaa !449
  %163 = fadd <32 x float> %73, %162
  %164 = fadd <32 x float> %159, %163
  %165 = fcmp ogt <32 x float> %164, zeroinitializer
  %166 = select <32 x i1> %165, <32 x float> %164, <32 x float> zeroinitializer
  %167 = getelementptr inbounds float, float* %12, i64 %156
  %168 = bitcast float* %167 to <32 x float>*
  store <32 x float> %166, <32 x float>* %168, align 64, !tbaa !452
  %169 = mul i64 %indvars.iv68, 3848290697216
  %sext75 = add i64 %169, 962072674304
  %170 = ashr exact i64 %sext75, 32
  %171 = getelementptr inbounds float, float* %18, i64 %170
  %172 = bitcast float* %171 to <32 x float>*
  %173 = load <32 x float>, <32 x float>* %172, align 64, !tbaa !446
  %174 = getelementptr inbounds i8, i8* %52, i64 896
  %175 = bitcast i8* %174 to <32 x float>*
  %176 = load <32 x float>, <32 x float>* %175, align 64, !tbaa !449
  %177 = fadd <32 x float> %73, %176
  %178 = fadd <32 x float> %173, %177
  %179 = fcmp ogt <32 x float> %178, zeroinitializer
  %180 = select <32 x i1> %179, <32 x float> %178, <32 x float> zeroinitializer
  %181 = getelementptr inbounds float, float* %12, i64 %170
  %182 = bitcast float* %181 to <32 x float>*
  store <32 x float> %180, <32 x float>* %182, align 64, !tbaa !452
  %183 = mul i64 %indvars.iv68, 3848290697216
  %sext76 = add i64 %183, 1099511627776
  %184 = ashr exact i64 %sext76, 32
  %185 = getelementptr inbounds float, float* %18, i64 %184
  %186 = bitcast float* %185 to <32 x float>*
  %187 = load <32 x float>, <32 x float>* %186, align 64, !tbaa !446
  %188 = getelementptr inbounds i8, i8* %52, i64 1024
  %189 = bitcast i8* %188 to <32 x float>*
  %190 = load <32 x float>, <32 x float>* %189, align 64, !tbaa !449
  %191 = fadd <32 x float> %73, %190
  %192 = fadd <32 x float> %187, %191
  %193 = fcmp ogt <32 x float> %192, zeroinitializer
  %194 = select <32 x i1> %193, <32 x float> %192, <32 x float> zeroinitializer
  %195 = getelementptr inbounds float, float* %12, i64 %184
  %196 = bitcast float* %195 to <32 x float>*
  store <32 x float> %194, <32 x float>* %196, align 64, !tbaa !452
  %197 = mul i64 %indvars.iv68, 3848290697216
  %sext77 = add i64 %197, 1236950581248
  %198 = ashr exact i64 %sext77, 32
  %199 = getelementptr inbounds float, float* %18, i64 %198
  %200 = bitcast float* %199 to <32 x float>*
  %201 = load <32 x float>, <32 x float>* %200, align 64, !tbaa !446
  %202 = getelementptr inbounds i8, i8* %52, i64 1152
  %203 = bitcast i8* %202 to <32 x float>*
  %204 = load <32 x float>, <32 x float>* %203, align 64, !tbaa !449
  %205 = fadd <32 x float> %73, %204
  %206 = fadd <32 x float> %201, %205
  %207 = fcmp ogt <32 x float> %206, zeroinitializer
  %208 = select <32 x i1> %207, <32 x float> %206, <32 x float> zeroinitializer
  %209 = getelementptr inbounds float, float* %12, i64 %198
  %210 = bitcast float* %209 to <32 x float>*
  store <32 x float> %208, <32 x float>* %210, align 64, !tbaa !452
  %211 = mul i64 %indvars.iv68, 3848290697216
  %sext78 = add i64 %211, 1374389534720
  %212 = ashr exact i64 %sext78, 32
  %213 = getelementptr inbounds float, float* %18, i64 %212
  %214 = bitcast float* %213 to <32 x float>*
  %215 = load <32 x float>, <32 x float>* %214, align 64, !tbaa !446
  %216 = getelementptr inbounds i8, i8* %52, i64 1280
  %217 = bitcast i8* %216 to <32 x float>*
  %218 = load <32 x float>, <32 x float>* %217, align 64, !tbaa !449
  %219 = fadd <32 x float> %73, %218
  %220 = fadd <32 x float> %215, %219
  %221 = fcmp ogt <32 x float> %220, zeroinitializer
  %222 = select <32 x i1> %221, <32 x float> %220, <32 x float> zeroinitializer
  %223 = getelementptr inbounds float, float* %12, i64 %212
  %224 = bitcast float* %223 to <32 x float>*
  store <32 x float> %222, <32 x float>* %224, align 64, !tbaa !452
  %225 = mul i64 %indvars.iv68, 3848290697216
  %sext79 = add i64 %225, 1511828488192
  %226 = ashr exact i64 %sext79, 32
  %227 = getelementptr inbounds float, float* %18, i64 %226
  %228 = bitcast float* %227 to <32 x float>*
  %229 = load <32 x float>, <32 x float>* %228, align 64, !tbaa !446
  %230 = getelementptr inbounds i8, i8* %52, i64 1408
  %231 = bitcast i8* %230 to <32 x float>*
  %232 = load <32 x float>, <32 x float>* %231, align 64, !tbaa !449
  %233 = fadd <32 x float> %73, %232
  %234 = fadd <32 x float> %229, %233
  %235 = fcmp ogt <32 x float> %234, zeroinitializer
  %236 = select <32 x i1> %235, <32 x float> %234, <32 x float> zeroinitializer
  %237 = getelementptr inbounds float, float* %12, i64 %226
  %238 = bitcast float* %237 to <32 x float>*
  store <32 x float> %236, <32 x float>* %238, align 64, !tbaa !452
  %239 = mul i64 %indvars.iv68, 3848290697216
  %sext80 = add i64 %239, 1649267441664
  %240 = ashr exact i64 %sext80, 32
  %241 = getelementptr inbounds float, float* %18, i64 %240
  %242 = bitcast float* %241 to <32 x float>*
  %243 = load <32 x float>, <32 x float>* %242, align 64, !tbaa !446
  %244 = getelementptr inbounds i8, i8* %52, i64 1536
  %245 = bitcast i8* %244 to <32 x float>*
  %246 = load <32 x float>, <32 x float>* %245, align 64, !tbaa !449
  %247 = fadd <32 x float> %73, %246
  %248 = fadd <32 x float> %243, %247
  %249 = fcmp ogt <32 x float> %248, zeroinitializer
  %250 = select <32 x i1> %249, <32 x float> %248, <32 x float> zeroinitializer
  %251 = getelementptr inbounds float, float* %12, i64 %240
  %252 = bitcast float* %251 to <32 x float>*
  store <32 x float> %250, <32 x float>* %252, align 64, !tbaa !452
  %253 = mul i64 %indvars.iv68, 3848290697216
  %sext81 = add i64 %253, 1786706395136
  %254 = ashr exact i64 %sext81, 32
  %255 = getelementptr inbounds float, float* %18, i64 %254
  %256 = bitcast float* %255 to <32 x float>*
  %257 = load <32 x float>, <32 x float>* %256, align 64, !tbaa !446
  %258 = getelementptr inbounds i8, i8* %52, i64 1664
  %259 = bitcast i8* %258 to <32 x float>*
  %260 = load <32 x float>, <32 x float>* %259, align 64, !tbaa !449
  %261 = fadd <32 x float> %73, %260
  %262 = fadd <32 x float> %257, %261
  %263 = fcmp ogt <32 x float> %262, zeroinitializer
  %264 = select <32 x i1> %263, <32 x float> %262, <32 x float> zeroinitializer
  %265 = getelementptr inbounds float, float* %12, i64 %254
  %266 = bitcast float* %265 to <32 x float>*
  store <32 x float> %264, <32 x float>* %266, align 64, !tbaa !452
  %267 = mul i64 %indvars.iv68, 3848290697216
  %sext82 = add i64 %267, 1924145348608
  %268 = ashr exact i64 %sext82, 32
  %269 = getelementptr inbounds float, float* %18, i64 %268
  %270 = bitcast float* %269 to <32 x float>*
  %271 = load <32 x float>, <32 x float>* %270, align 64, !tbaa !446
  %272 = getelementptr inbounds i8, i8* %52, i64 1792
  %273 = bitcast i8* %272 to <32 x float>*
  %274 = load <32 x float>, <32 x float>* %273, align 64, !tbaa !449
  %275 = fadd <32 x float> %73, %274
  %276 = fadd <32 x float> %271, %275
  %277 = fcmp ogt <32 x float> %276, zeroinitializer
  %278 = select <32 x i1> %277, <32 x float> %276, <32 x float> zeroinitializer
  %279 = getelementptr inbounds float, float* %12, i64 %268
  %280 = bitcast float* %279 to <32 x float>*
  store <32 x float> %278, <32 x float>* %280, align 64, !tbaa !452
  %281 = mul i64 %indvars.iv68, 3848290697216
  %sext83 = add i64 %281, 2061584302080
  %282 = ashr exact i64 %sext83, 32
  %283 = getelementptr inbounds float, float* %18, i64 %282
  %284 = bitcast float* %283 to <32 x float>*
  %285 = load <32 x float>, <32 x float>* %284, align 64, !tbaa !446
  %286 = getelementptr inbounds i8, i8* %52, i64 1920
  %287 = bitcast i8* %286 to <32 x float>*
  %288 = load <32 x float>, <32 x float>* %287, align 64, !tbaa !449
  %289 = fadd <32 x float> %73, %288
  %290 = fadd <32 x float> %285, %289
  %291 = fcmp ogt <32 x float> %290, zeroinitializer
  %292 = select <32 x i1> %291, <32 x float> %290, <32 x float> zeroinitializer
  %293 = getelementptr inbounds float, float* %12, i64 %282
  %294 = bitcast float* %293 to <32 x float>*
  store <32 x float> %292, <32 x float>* %294, align 64, !tbaa !452
  %295 = mul i64 %indvars.iv68, 3848290697216
  %sext84 = add i64 %295, 2199023255552
  %296 = ashr exact i64 %sext84, 32
  %297 = getelementptr inbounds float, float* %18, i64 %296
  %298 = bitcast float* %297 to <32 x float>*
  %299 = load <32 x float>, <32 x float>* %298, align 64, !tbaa !446
  %300 = getelementptr inbounds i8, i8* %52, i64 2048
  %301 = bitcast i8* %300 to <32 x float>*
  %302 = load <32 x float>, <32 x float>* %301, align 64, !tbaa !449
  %303 = fadd <32 x float> %73, %302
  %304 = fadd <32 x float> %299, %303
  %305 = fcmp ogt <32 x float> %304, zeroinitializer
  %306 = select <32 x i1> %305, <32 x float> %304, <32 x float> zeroinitializer
  %307 = getelementptr inbounds float, float* %12, i64 %296
  %308 = bitcast float* %307 to <32 x float>*
  store <32 x float> %306, <32 x float>* %308, align 64, !tbaa !452
  %309 = mul i64 %indvars.iv68, 3848290697216
  %sext85 = add i64 %309, 2336462209024
  %310 = ashr exact i64 %sext85, 32
  %311 = getelementptr inbounds float, float* %18, i64 %310
  %312 = bitcast float* %311 to <32 x float>*
  %313 = load <32 x float>, <32 x float>* %312, align 64, !tbaa !446
  %314 = getelementptr inbounds i8, i8* %52, i64 2176
  %315 = bitcast i8* %314 to <32 x float>*
  %316 = load <32 x float>, <32 x float>* %315, align 64, !tbaa !449
  %317 = fadd <32 x float> %73, %316
  %318 = fadd <32 x float> %313, %317
  %319 = fcmp ogt <32 x float> %318, zeroinitializer
  %320 = select <32 x i1> %319, <32 x float> %318, <32 x float> zeroinitializer
  %321 = getelementptr inbounds float, float* %12, i64 %310
  %322 = bitcast float* %321 to <32 x float>*
  store <32 x float> %320, <32 x float>* %322, align 64, !tbaa !452
  %323 = mul i64 %indvars.iv68, 3848290697216
  %sext86 = add i64 %323, 2473901162496
  %324 = ashr exact i64 %sext86, 32
  %325 = getelementptr inbounds float, float* %18, i64 %324
  %326 = bitcast float* %325 to <32 x float>*
  %327 = load <32 x float>, <32 x float>* %326, align 64, !tbaa !446
  %328 = getelementptr inbounds i8, i8* %52, i64 2304
  %329 = bitcast i8* %328 to <32 x float>*
  %330 = load <32 x float>, <32 x float>* %329, align 64, !tbaa !449
  %331 = fadd <32 x float> %73, %330
  %332 = fadd <32 x float> %327, %331
  %333 = fcmp ogt <32 x float> %332, zeroinitializer
  %334 = select <32 x i1> %333, <32 x float> %332, <32 x float> zeroinitializer
  %335 = getelementptr inbounds float, float* %12, i64 %324
  %336 = bitcast float* %335 to <32 x float>*
  store <32 x float> %334, <32 x float>* %336, align 64, !tbaa !452
  %337 = mul i64 %indvars.iv68, 3848290697216
  %sext87 = add i64 %337, 2611340115968
  %338 = ashr exact i64 %sext87, 32
  %339 = getelementptr inbounds float, float* %18, i64 %338
  %340 = bitcast float* %339 to <32 x float>*
  %341 = load <32 x float>, <32 x float>* %340, align 64, !tbaa !446
  %342 = getelementptr inbounds i8, i8* %52, i64 2432
  %343 = bitcast i8* %342 to <32 x float>*
  %344 = load <32 x float>, <32 x float>* %343, align 64, !tbaa !449
  %345 = fadd <32 x float> %73, %344
  %346 = fadd <32 x float> %341, %345
  %347 = fcmp ogt <32 x float> %346, zeroinitializer
  %348 = select <32 x i1> %347, <32 x float> %346, <32 x float> zeroinitializer
  %349 = getelementptr inbounds float, float* %12, i64 %338
  %350 = bitcast float* %349 to <32 x float>*
  store <32 x float> %348, <32 x float>* %350, align 64, !tbaa !452
  %351 = mul i64 %indvars.iv68, 3848290697216
  %sext88 = add i64 %351, 2748779069440
  %352 = ashr exact i64 %sext88, 32
  %353 = getelementptr inbounds float, float* %18, i64 %352
  %354 = bitcast float* %353 to <32 x float>*
  %355 = load <32 x float>, <32 x float>* %354, align 64, !tbaa !446
  %356 = getelementptr inbounds i8, i8* %52, i64 2560
  %357 = bitcast i8* %356 to <32 x float>*
  %358 = load <32 x float>, <32 x float>* %357, align 64, !tbaa !449
  %359 = fadd <32 x float> %73, %358
  %360 = fadd <32 x float> %355, %359
  %361 = fcmp ogt <32 x float> %360, zeroinitializer
  %362 = select <32 x i1> %361, <32 x float> %360, <32 x float> zeroinitializer
  %363 = getelementptr inbounds float, float* %12, i64 %352
  %364 = bitcast float* %363 to <32 x float>*
  store <32 x float> %362, <32 x float>* %364, align 64, !tbaa !452
  %365 = mul i64 %indvars.iv68, 3848290697216
  %sext89 = add i64 %365, 2886218022912
  %366 = ashr exact i64 %sext89, 32
  %367 = getelementptr inbounds float, float* %18, i64 %366
  %368 = bitcast float* %367 to <32 x float>*
  %369 = load <32 x float>, <32 x float>* %368, align 64, !tbaa !446
  %370 = getelementptr inbounds i8, i8* %52, i64 2688
  %371 = bitcast i8* %370 to <32 x float>*
  %372 = load <32 x float>, <32 x float>* %371, align 64, !tbaa !449
  %373 = fadd <32 x float> %73, %372
  %374 = fadd <32 x float> %369, %373
  %375 = fcmp ogt <32 x float> %374, zeroinitializer
  %376 = select <32 x i1> %375, <32 x float> %374, <32 x float> zeroinitializer
  %377 = getelementptr inbounds float, float* %12, i64 %366
  %378 = bitcast float* %377 to <32 x float>*
  store <32 x float> %376, <32 x float>* %378, align 64, !tbaa !452
  %379 = mul i64 %indvars.iv68, 3848290697216
  %sext90 = add i64 %379, 3023656976384
  %380 = ashr exact i64 %sext90, 32
  %381 = getelementptr inbounds float, float* %18, i64 %380
  %382 = bitcast float* %381 to <32 x float>*
  %383 = load <32 x float>, <32 x float>* %382, align 64, !tbaa !446
  %384 = getelementptr inbounds i8, i8* %52, i64 2816
  %385 = bitcast i8* %384 to <32 x float>*
  %386 = load <32 x float>, <32 x float>* %385, align 64, !tbaa !449
  %387 = fadd <32 x float> %73, %386
  %388 = fadd <32 x float> %383, %387
  %389 = fcmp ogt <32 x float> %388, zeroinitializer
  %390 = select <32 x i1> %389, <32 x float> %388, <32 x float> zeroinitializer
  %391 = getelementptr inbounds float, float* %12, i64 %380
  %392 = bitcast float* %391 to <32 x float>*
  store <32 x float> %390, <32 x float>* %392, align 64, !tbaa !452
  %393 = mul i64 %indvars.iv68, 3848290697216
  %sext91 = add i64 %393, 3161095929856
  %394 = ashr exact i64 %sext91, 32
  %395 = getelementptr inbounds float, float* %18, i64 %394
  %396 = bitcast float* %395 to <32 x float>*
  %397 = load <32 x float>, <32 x float>* %396, align 64, !tbaa !446
  %398 = getelementptr inbounds i8, i8* %52, i64 2944
  %399 = bitcast i8* %398 to <32 x float>*
  %400 = load <32 x float>, <32 x float>* %399, align 64, !tbaa !449
  %401 = fadd <32 x float> %73, %400
  %402 = fadd <32 x float> %397, %401
  %403 = fcmp ogt <32 x float> %402, zeroinitializer
  %404 = select <32 x i1> %403, <32 x float> %402, <32 x float> zeroinitializer
  %405 = getelementptr inbounds float, float* %12, i64 %394
  %406 = bitcast float* %405 to <32 x float>*
  store <32 x float> %404, <32 x float>* %406, align 64, !tbaa !452
  %407 = mul i64 %indvars.iv68, 3848290697216
  %sext92 = add i64 %407, 3298534883328
  %408 = ashr exact i64 %sext92, 32
  %409 = getelementptr inbounds float, float* %18, i64 %408
  %410 = bitcast float* %409 to <32 x float>*
  %411 = load <32 x float>, <32 x float>* %410, align 64, !tbaa !446
  %412 = getelementptr inbounds i8, i8* %52, i64 3072
  %413 = bitcast i8* %412 to <32 x float>*
  %414 = load <32 x float>, <32 x float>* %413, align 64, !tbaa !449
  %415 = fadd <32 x float> %73, %414
  %416 = fadd <32 x float> %411, %415
  %417 = fcmp ogt <32 x float> %416, zeroinitializer
  %418 = select <32 x i1> %417, <32 x float> %416, <32 x float> zeroinitializer
  %419 = getelementptr inbounds float, float* %12, i64 %408
  %420 = bitcast float* %419 to <32 x float>*
  store <32 x float> %418, <32 x float>* %420, align 64, !tbaa !452
  %421 = mul i64 %indvars.iv68, 3848290697216
  %sext93 = add i64 %421, 3435973836800
  %422 = ashr exact i64 %sext93, 32
  %423 = getelementptr inbounds float, float* %18, i64 %422
  %424 = bitcast float* %423 to <32 x float>*
  %425 = load <32 x float>, <32 x float>* %424, align 64, !tbaa !446
  %426 = getelementptr inbounds i8, i8* %52, i64 3200
  %427 = bitcast i8* %426 to <32 x float>*
  %428 = load <32 x float>, <32 x float>* %427, align 64, !tbaa !449
  %429 = fadd <32 x float> %73, %428
  %430 = fadd <32 x float> %425, %429
  %431 = fcmp ogt <32 x float> %430, zeroinitializer
  %432 = select <32 x i1> %431, <32 x float> %430, <32 x float> zeroinitializer
  %433 = getelementptr inbounds float, float* %12, i64 %422
  %434 = bitcast float* %433 to <32 x float>*
  store <32 x float> %432, <32 x float>* %434, align 64, !tbaa !452
  %435 = mul i64 %indvars.iv68, 3848290697216
  %sext94 = add i64 %435, 3573412790272
  %436 = ashr exact i64 %sext94, 32
  %437 = getelementptr inbounds float, float* %18, i64 %436
  %438 = bitcast float* %437 to <32 x float>*
  %439 = load <32 x float>, <32 x float>* %438, align 64, !tbaa !446
  %440 = getelementptr inbounds i8, i8* %52, i64 3328
  %441 = bitcast i8* %440 to <32 x float>*
  %442 = load <32 x float>, <32 x float>* %441, align 64, !tbaa !449
  %443 = fadd <32 x float> %73, %442
  %444 = fadd <32 x float> %439, %443
  %445 = fcmp ogt <32 x float> %444, zeroinitializer
  %446 = select <32 x i1> %445, <32 x float> %444, <32 x float> zeroinitializer
  %447 = getelementptr inbounds float, float* %12, i64 %436
  %448 = bitcast float* %447 to <32 x float>*
  store <32 x float> %446, <32 x float>* %448, align 64, !tbaa !452
  %449 = mul i64 %indvars.iv68, 3848290697216
  %sext95 = add i64 %449, 3710851743744
  %450 = ashr exact i64 %sext95, 32
  %451 = getelementptr inbounds float, float* %18, i64 %450
  %452 = bitcast float* %451 to <32 x float>*
  %453 = load <32 x float>, <32 x float>* %452, align 64, !tbaa !446
  %454 = getelementptr inbounds i8, i8* %52, i64 3456
  %455 = bitcast i8* %454 to <32 x float>*
  %456 = load <32 x float>, <32 x float>* %455, align 64, !tbaa !449
  %457 = fadd <32 x float> %73, %456
  %458 = fadd <32 x float> %453, %457
  %459 = fcmp ogt <32 x float> %458, zeroinitializer
  %460 = select <32 x i1> %459, <32 x float> %458, <32 x float> zeroinitializer
  %461 = getelementptr inbounds float, float* %12, i64 %450
  %462 = bitcast float* %461 to <32 x float>*
  store <32 x float> %460, <32 x float>* %462, align 64, !tbaa !452
  %463 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %464 = tail call i32 %463(i32 1, i32 %21, i8* nonnull %52)
  %indvars.iv.next69 = add nsw i64 %indvars.iv68, 1
  %465 = icmp slt i64 %indvars.iv.next69, %49
  br i1 %465, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %466 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %52, i64 %466
  %467 = add nsw i64 %466, %59
  call void @llvm.memset.p0i8.i64(i8* nonnull align 128 %50, i8 0, i64 896, i1 false)
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %468 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %553, %for_body8 ]
  %469 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %547, %for_body8 ]
  %470 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %546, %for_body8 ]
  %471 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %545, %for_body8 ]
  %472 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %544, %for_body8 ]
  %473 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %543, %for_body8 ]
  %474 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %542, %for_body8 ]
  %475 = add nsw i64 %467, %indvars.iv
  %476 = getelementptr inbounds float, float* %6, i64 %475
  %477 = load float, float* %476, align 4, !tbaa !437
  %478 = insertelement <32 x float> undef, float %477, i32 0
  %479 = shufflevector <32 x float> %478, <32 x float> undef, <32 x i32> zeroinitializer
  %480 = shl nsw i64 %indvars.iv, 5
  %481 = add nsw i64 %480, %57
  %482 = getelementptr inbounds float, float* %9, i64 %481
  %483 = bitcast float* %482 to <32 x float>*
  %484 = load <32 x float>, <32 x float>* %483, align 64, !tbaa !455
  %485 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %479, <32 x float> %484, <32 x float> %474)
  %486 = add nsw i64 %475, 128
  %487 = getelementptr inbounds float, float* %6, i64 %486
  %488 = load float, float* %487, align 4, !tbaa !437
  %489 = insertelement <32 x float> undef, float %488, i32 0
  %490 = shufflevector <32 x float> %489, <32 x float> undef, <32 x i32> zeroinitializer
  %491 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %490, <32 x float> %484, <32 x float> %473)
  %492 = add nsw i64 %475, 256
  %493 = getelementptr inbounds float, float* %6, i64 %492
  %494 = load float, float* %493, align 4, !tbaa !437
  %495 = insertelement <32 x float> undef, float %494, i32 0
  %496 = shufflevector <32 x float> %495, <32 x float> undef, <32 x i32> zeroinitializer
  %497 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %496, <32 x float> %484, <32 x float> %472)
  %498 = add nsw i64 %475, 384
  %499 = getelementptr inbounds float, float* %6, i64 %498
  %500 = load float, float* %499, align 4, !tbaa !437
  %501 = insertelement <32 x float> undef, float %500, i32 0
  %502 = shufflevector <32 x float> %501, <32 x float> undef, <32 x i32> zeroinitializer
  %503 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %502, <32 x float> %484, <32 x float> %471)
  %504 = add nsw i64 %475, 512
  %505 = getelementptr inbounds float, float* %6, i64 %504
  %506 = load float, float* %505, align 4, !tbaa !437
  %507 = insertelement <32 x float> undef, float %506, i32 0
  %508 = shufflevector <32 x float> %507, <32 x float> undef, <32 x i32> zeroinitializer
  %509 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %484, <32 x float> %470)
  %510 = add nsw i64 %475, 640
  %511 = getelementptr inbounds float, float* %6, i64 %510
  %512 = load float, float* %511, align 4, !tbaa !437
  %513 = insertelement <32 x float> undef, float %512, i32 0
  %514 = shufflevector <32 x float> %513, <32 x float> undef, <32 x i32> zeroinitializer
  %515 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %484, <32 x float> %469)
  %516 = add nsw i64 %475, 768
  %517 = getelementptr inbounds float, float* %6, i64 %516
  %518 = load float, float* %517, align 4, !tbaa !437
  %519 = insertelement <32 x float> undef, float %518, i32 0
  %520 = shufflevector <32 x float> %519, <32 x float> undef, <32 x i32> zeroinitializer
  %521 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %484, <32 x float> %468)
  %522 = add nsw i64 %481, 4096
  %523 = getelementptr inbounds float, float* %9, i64 %522
  %524 = bitcast float* %523 to <32 x float>*
  %525 = load <32 x float>, <32 x float>* %524, align 64, !tbaa !455
  %526 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %490, <32 x float> %525, <32 x float> %485)
  %527 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %496, <32 x float> %525, <32 x float> %491)
  %528 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %502, <32 x float> %525, <32 x float> %497)
  %529 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %525, <32 x float> %503)
  %530 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %525, <32 x float> %509)
  %531 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %525, <32 x float> %515)
  %532 = add nsw i64 %475, 896
  %533 = getelementptr inbounds float, float* %6, i64 %532
  %534 = load float, float* %533, align 4, !tbaa !437
  %535 = insertelement <32 x float> undef, float %534, i32 0
  %536 = shufflevector <32 x float> %535, <32 x float> undef, <32 x i32> zeroinitializer
  %537 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %536, <32 x float> %525, <32 x float> %521)
  %538 = add nsw i64 %481, 8192
  %539 = getelementptr inbounds float, float* %9, i64 %538
  %540 = bitcast float* %539 to <32 x float>*
  %541 = load <32 x float>, <32 x float>* %540, align 64, !tbaa !455
  %542 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %496, <32 x float> %541, <32 x float> %526)
  %543 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %502, <32 x float> %541, <32 x float> %527)
  %544 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %541, <32 x float> %528)
  %545 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %541, <32 x float> %529)
  %546 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %541, <32 x float> %530)
  %547 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %536, <32 x float> %541, <32 x float> %531)
  %548 = add nsw i64 %475, 1024
  %549 = getelementptr inbounds float, float* %6, i64 %548
  %550 = load float, float* %549, align 4, !tbaa !437
  %551 = insertelement <32 x float> undef, float %550, i32 0
  %552 = shufflevector <32 x float> %551, <32 x float> undef, <32 x i32> zeroinitializer
  %553 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %552, <32 x float> %541, <32 x float> %537)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %554 = add nsw i64 %466, %62
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %555 = phi <32 x float> [ %553, %for_end9 ], [ %640, %for_body8.1 ]
  %556 = phi <32 x float> [ %547, %for_end9 ], [ %634, %for_body8.1 ]
  %557 = phi <32 x float> [ %546, %for_end9 ], [ %633, %for_body8.1 ]
  %558 = phi <32 x float> [ %545, %for_end9 ], [ %632, %for_body8.1 ]
  %559 = phi <32 x float> [ %544, %for_end9 ], [ %631, %for_body8.1 ]
  %560 = phi <32 x float> [ %543, %for_end9 ], [ %630, %for_body8.1 ]
  %561 = phi <32 x float> [ %542, %for_end9 ], [ %629, %for_body8.1 ]
  %562 = add nsw i64 %554, %indvars.iv.1
  %563 = getelementptr inbounds float, float* %6, i64 %562
  %564 = load float, float* %563, align 4, !tbaa !437
  %565 = insertelement <32 x float> undef, float %564, i32 0
  %566 = shufflevector <32 x float> %565, <32 x float> undef, <32 x i32> zeroinitializer
  %567 = shl nsw i64 %indvars.iv.1, 5
  %568 = add nsw i64 %63, %567
  %569 = getelementptr inbounds float, float* %9, i64 %568
  %570 = bitcast float* %569 to <32 x float>*
  %571 = load <32 x float>, <32 x float>* %570, align 64, !tbaa !455
  %572 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %566, <32 x float> %571, <32 x float> %561)
  %573 = add nsw i64 %562, 128
  %574 = getelementptr inbounds float, float* %6, i64 %573
  %575 = load float, float* %574, align 4, !tbaa !437
  %576 = insertelement <32 x float> undef, float %575, i32 0
  %577 = shufflevector <32 x float> %576, <32 x float> undef, <32 x i32> zeroinitializer
  %578 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %577, <32 x float> %571, <32 x float> %560)
  %579 = add nsw i64 %562, 256
  %580 = getelementptr inbounds float, float* %6, i64 %579
  %581 = load float, float* %580, align 4, !tbaa !437
  %582 = insertelement <32 x float> undef, float %581, i32 0
  %583 = shufflevector <32 x float> %582, <32 x float> undef, <32 x i32> zeroinitializer
  %584 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %583, <32 x float> %571, <32 x float> %559)
  %585 = add nsw i64 %562, 384
  %586 = getelementptr inbounds float, float* %6, i64 %585
  %587 = load float, float* %586, align 4, !tbaa !437
  %588 = insertelement <32 x float> undef, float %587, i32 0
  %589 = shufflevector <32 x float> %588, <32 x float> undef, <32 x i32> zeroinitializer
  %590 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %589, <32 x float> %571, <32 x float> %558)
  %591 = add nsw i64 %562, 512
  %592 = getelementptr inbounds float, float* %6, i64 %591
  %593 = load float, float* %592, align 4, !tbaa !437
  %594 = insertelement <32 x float> undef, float %593, i32 0
  %595 = shufflevector <32 x float> %594, <32 x float> undef, <32 x i32> zeroinitializer
  %596 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %571, <32 x float> %557)
  %597 = add nsw i64 %562, 640
  %598 = getelementptr inbounds float, float* %6, i64 %597
  %599 = load float, float* %598, align 4, !tbaa !437
  %600 = insertelement <32 x float> undef, float %599, i32 0
  %601 = shufflevector <32 x float> %600, <32 x float> undef, <32 x i32> zeroinitializer
  %602 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %601, <32 x float> %571, <32 x float> %556)
  %603 = add nsw i64 %562, 768
  %604 = getelementptr inbounds float, float* %6, i64 %603
  %605 = load float, float* %604, align 4, !tbaa !437
  %606 = insertelement <32 x float> undef, float %605, i32 0
  %607 = shufflevector <32 x float> %606, <32 x float> undef, <32 x i32> zeroinitializer
  %608 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %607, <32 x float> %571, <32 x float> %555)
  %609 = add nsw i64 %568, 4096
  %610 = getelementptr inbounds float, float* %9, i64 %609
  %611 = bitcast float* %610 to <32 x float>*
  %612 = load <32 x float>, <32 x float>* %611, align 64, !tbaa !455
  %613 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %577, <32 x float> %612, <32 x float> %572)
  %614 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %583, <32 x float> %612, <32 x float> %578)
  %615 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %589, <32 x float> %612, <32 x float> %584)
  %616 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %612, <32 x float> %590)
  %617 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %601, <32 x float> %612, <32 x float> %596)
  %618 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %607, <32 x float> %612, <32 x float> %602)
  %619 = add nsw i64 %562, 896
  %620 = getelementptr inbounds float, float* %6, i64 %619
  %621 = load float, float* %620, align 4, !tbaa !437
  %622 = insertelement <32 x float> undef, float %621, i32 0
  %623 = shufflevector <32 x float> %622, <32 x float> undef, <32 x i32> zeroinitializer
  %624 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %623, <32 x float> %612, <32 x float> %608)
  %625 = add nsw i64 %568, 8192
  %626 = getelementptr inbounds float, float* %9, i64 %625
  %627 = bitcast float* %626 to <32 x float>*
  %628 = load <32 x float>, <32 x float>* %627, align 64, !tbaa !455
  %629 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %583, <32 x float> %628, <32 x float> %613)
  %630 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %589, <32 x float> %628, <32 x float> %614)
  %631 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %628, <32 x float> %615)
  %632 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %601, <32 x float> %628, <32 x float> %616)
  %633 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %607, <32 x float> %628, <32 x float> %617)
  %634 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %623, <32 x float> %628, <32 x float> %618)
  %635 = add nsw i64 %562, 1024
  %636 = getelementptr inbounds float, float* %6, i64 %635
  %637 = load float, float* %636, align 4, !tbaa !437
  %638 = insertelement <32 x float> undef, float %637, i32 0
  %639 = shufflevector <32 x float> %638, <32 x float> undef, <32 x i32> zeroinitializer
  %640 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %639, <32 x float> %628, <32 x float> %624)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %641 = add nsw i64 %466, %66
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %642 = phi <32 x float> [ %640, %for_end9.1 ], [ %727, %for_body8.2 ]
  %643 = phi <32 x float> [ %634, %for_end9.1 ], [ %721, %for_body8.2 ]
  %644 = phi <32 x float> [ %633, %for_end9.1 ], [ %720, %for_body8.2 ]
  %645 = phi <32 x float> [ %632, %for_end9.1 ], [ %719, %for_body8.2 ]
  %646 = phi <32 x float> [ %631, %for_end9.1 ], [ %718, %for_body8.2 ]
  %647 = phi <32 x float> [ %630, %for_end9.1 ], [ %717, %for_body8.2 ]
  %648 = phi <32 x float> [ %629, %for_end9.1 ], [ %716, %for_body8.2 ]
  %649 = add nsw i64 %641, %indvars.iv.2
  %650 = getelementptr inbounds float, float* %6, i64 %649
  %651 = load float, float* %650, align 4, !tbaa !437
  %652 = insertelement <32 x float> undef, float %651, i32 0
  %653 = shufflevector <32 x float> %652, <32 x float> undef, <32 x i32> zeroinitializer
  %654 = shl nsw i64 %indvars.iv.2, 5
  %655 = add nsw i64 %67, %654
  %656 = getelementptr inbounds float, float* %9, i64 %655
  %657 = bitcast float* %656 to <32 x float>*
  %658 = load <32 x float>, <32 x float>* %657, align 64, !tbaa !455
  %659 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %653, <32 x float> %658, <32 x float> %648)
  %660 = add nsw i64 %649, 128
  %661 = getelementptr inbounds float, float* %6, i64 %660
  %662 = load float, float* %661, align 4, !tbaa !437
  %663 = insertelement <32 x float> undef, float %662, i32 0
  %664 = shufflevector <32 x float> %663, <32 x float> undef, <32 x i32> zeroinitializer
  %665 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %664, <32 x float> %658, <32 x float> %647)
  %666 = add nsw i64 %649, 256
  %667 = getelementptr inbounds float, float* %6, i64 %666
  %668 = load float, float* %667, align 4, !tbaa !437
  %669 = insertelement <32 x float> undef, float %668, i32 0
  %670 = shufflevector <32 x float> %669, <32 x float> undef, <32 x i32> zeroinitializer
  %671 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %670, <32 x float> %658, <32 x float> %646)
  %672 = add nsw i64 %649, 384
  %673 = getelementptr inbounds float, float* %6, i64 %672
  %674 = load float, float* %673, align 4, !tbaa !437
  %675 = insertelement <32 x float> undef, float %674, i32 0
  %676 = shufflevector <32 x float> %675, <32 x float> undef, <32 x i32> zeroinitializer
  %677 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %676, <32 x float> %658, <32 x float> %645)
  %678 = add nsw i64 %649, 512
  %679 = getelementptr inbounds float, float* %6, i64 %678
  %680 = load float, float* %679, align 4, !tbaa !437
  %681 = insertelement <32 x float> undef, float %680, i32 0
  %682 = shufflevector <32 x float> %681, <32 x float> undef, <32 x i32> zeroinitializer
  %683 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %682, <32 x float> %658, <32 x float> %644)
  %684 = add nsw i64 %649, 640
  %685 = getelementptr inbounds float, float* %6, i64 %684
  %686 = load float, float* %685, align 4, !tbaa !437
  %687 = insertelement <32 x float> undef, float %686, i32 0
  %688 = shufflevector <32 x float> %687, <32 x float> undef, <32 x i32> zeroinitializer
  %689 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %688, <32 x float> %658, <32 x float> %643)
  %690 = add nsw i64 %649, 768
  %691 = getelementptr inbounds float, float* %6, i64 %690
  %692 = load float, float* %691, align 4, !tbaa !437
  %693 = insertelement <32 x float> undef, float %692, i32 0
  %694 = shufflevector <32 x float> %693, <32 x float> undef, <32 x i32> zeroinitializer
  %695 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %694, <32 x float> %658, <32 x float> %642)
  %696 = add nsw i64 %655, 4096
  %697 = getelementptr inbounds float, float* %9, i64 %696
  %698 = bitcast float* %697 to <32 x float>*
  %699 = load <32 x float>, <32 x float>* %698, align 64, !tbaa !455
  %700 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %664, <32 x float> %699, <32 x float> %659)
  %701 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %670, <32 x float> %699, <32 x float> %665)
  %702 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %676, <32 x float> %699, <32 x float> %671)
  %703 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %682, <32 x float> %699, <32 x float> %677)
  %704 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %688, <32 x float> %699, <32 x float> %683)
  %705 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %694, <32 x float> %699, <32 x float> %689)
  %706 = add nsw i64 %649, 896
  %707 = getelementptr inbounds float, float* %6, i64 %706
  %708 = load float, float* %707, align 4, !tbaa !437
  %709 = insertelement <32 x float> undef, float %708, i32 0
  %710 = shufflevector <32 x float> %709, <32 x float> undef, <32 x i32> zeroinitializer
  %711 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %710, <32 x float> %699, <32 x float> %695)
  %712 = add nsw i64 %655, 8192
  %713 = getelementptr inbounds float, float* %9, i64 %712
  %714 = bitcast float* %713 to <32 x float>*
  %715 = load <32 x float>, <32 x float>* %714, align 64, !tbaa !455
  %716 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %670, <32 x float> %715, <32 x float> %700)
  %717 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %676, <32 x float> %715, <32 x float> %701)
  %718 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %682, <32 x float> %715, <32 x float> %702)
  %719 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %688, <32 x float> %715, <32 x float> %703)
  %720 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %694, <32 x float> %715, <32 x float> %704)
  %721 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %710, <32 x float> %715, <32 x float> %705)
  %722 = add nsw i64 %649, 1024
  %723 = getelementptr inbounds float, float* %6, i64 %722
  %724 = load float, float* %723, align 4, !tbaa !437
  %725 = insertelement <32 x float> undef, float %724, i32 0
  %726 = shufflevector <32 x float> %725, <32 x float> undef, <32 x i32> zeroinitializer
  %727 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %726, <32 x float> %715, <32 x float> %711)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 128
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %716, <32 x float>* %.sub, align 128, !tbaa !458
  store <32 x float> %717, <32 x float>* %35, align 128, !tbaa !458
  store <32 x float> %718, <32 x float>* %37, align 128, !tbaa !458
  store <32 x float> %719, <32 x float>* %39, align 128, !tbaa !458
  store <32 x float> %720, <32 x float>* %41, align 128, !tbaa !458
  store <32 x float> %721, <32 x float>* %43, align 128, !tbaa !458
  store <32 x float> %727, <32 x float>* %45, align 128, !tbaa !458
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %scevgep, i8* nonnull align 128 %4, i64 896, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond61 = icmp eq i64 %indvar.next, 4
  br i1 %exitcond61, label %for_begin13.preheader, label %for_body2, !prof !50
}

; Function Attrs: nounwind readnone speculatable
declare <32 x float> @llvm.fmuladd.v32f32(<32 x float>, <32 x float>, <32 x float>) #3

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 5
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.87, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !467
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !481
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !484
  %26 = getelementptr inbounds i8, i8* %0, i64 32
  %27 = bitcast i8* %26 to %1**
  %28 = load %1*, %1** %27, align 8
  %29 = getelementptr inbounds i8, i8* %1, i64 16
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !486
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %33 = load i8*, i8** %32, align 8
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %37 = load i64*, i64** %36, align 8
  %38 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  %54 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %55 = load i8*, i8** %54, align 8
  %56 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %59 = load i64*, i64** %58, align 8
  %60 = getelementptr inbounds %1, %1* %28, i64 0, i32 0
  %61 = load i8*, i8** %60, align 8
  %62 = getelementptr inbounds %1, %1* %28, i64 0, i32 4
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %28, i64 0, i32 5
  %65 = load i64*, i64** %64, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.88, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %67 = getelementptr inbounds i8, i8* %1, i64 4
  %68 = bitcast i8* %67 to i32*
  %69 = load i32, i32* %68, align 4, !tbaa !490
  switch i32 %69, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.89, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.90, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %72 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %72(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.91, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %31, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([173 x i8], [173 x i8]* @.str.92, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %74 = icmp eq i32 %39, 1
  br i1 %74, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %75 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %75(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %76 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %77 = load i32, i32* %76, align 4
  %78 = icmp eq i32 %77, 5
  br i1 %78, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %80 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %81 = load i16, i16* %80, align 2
  %82 = icmp eq i16 %81, 1
  %83 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %84 = load i8, i8* %83, align 1
  %85 = icmp eq i8 %84, 32
  %86 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %87 = load i8, i8* %86, align 1
  %88 = icmp eq i8 %87, 2
  %89 = and i1 %85, %88
  %90 = and i1 %82, %89
  br i1 %90, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %92 = load i64, i64* %35, align 8, !tbaa !492
  %93 = trunc i64 %92 to i32
  %94 = icmp eq i32 %93, 1
  br i1 %94, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %96 = getelementptr inbounds i64, i64* %35, i64 1
  %97 = load i64, i64* %96, align 8, !tbaa !506
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 1
  br i1 %99, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %101 = getelementptr inbounds i64, i64* %35, i64 2
  %102 = load i64, i64* %101, align 8, !tbaa !508
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 7
  br i1 %104, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %106 = getelementptr inbounds i64, i64* %35, i64 3
  %107 = load i64, i64* %106, align 8, !tbaa !511
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 7
  br i1 %109, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.94, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %111 = getelementptr inbounds i64, i64* %35, i64 4
  %112 = load i64, i64* %111, align 8, !tbaa !513
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 512
  br i1 %114, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.95, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %116 = icmp eq i64* %37, null
  br i1 %116, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %117 = bitcast i64* %37 to <4 x i64>*
  %118 = load <4 x i64>, <4 x i64>* %117, align 8, !tbaa !517
  %119 = trunc <4 x i64> %118 to <4 x i32>
  %120 = icmp eq <4 x i32> %119, <i32 25088, i32 25088, i32 3584, i32 512>
  %121 = getelementptr inbounds i64, i64* %37, i64 4
  %122 = load i64, i64* %121, align 8, !tbaa !529
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 1
  %rdx.shuf143 = shufflevector <4 x i1> %120, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx144 = and <4 x i1> %120, %rdx.shuf143
  %rdx.shuf145 = shufflevector <4 x i1> %bin.rdx144, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx146 = and <4 x i1> %bin.rdx144, %rdx.shuf145
  %125 = extractelement <4 x i1> %bin.rdx146, i32 0
  %126 = and i1 %125, %124
  br i1 %126, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %127 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %128 = load i64, i64* %127, align 8
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.96, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %131 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %131(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %132 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %133 = load i32, i32* %132, align 4
  %134 = icmp eq i32 %133, 6
  br i1 %134, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %136 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %137 = load i16, i16* %136, align 2
  %138 = icmp eq i16 %137, 1
  %139 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %140 = load i8, i8* %139, align 1
  %141 = icmp eq i8 %140, 32
  %142 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %143 = load i8, i8* %142, align 1
  %144 = icmp eq i8 %143, 2
  %145 = and i1 %141, %144
  %146 = and i1 %138, %145
  br i1 %146, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %148 = load i64, i64* %45, align 8, !tbaa !533
  %149 = trunc i64 %148 to i32
  %150 = icmp eq i32 %149, 16
  br i1 %150, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %151 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %151(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %152 = getelementptr inbounds i64, i64* %45, i64 1
  %153 = load i64, i64* %152, align 8, !tbaa !547
  %154 = trunc i64 %153 to i32
  %155 = icmp eq i32 %154, 1
  br i1 %155, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %157 = getelementptr inbounds i64, i64* %45, i64 2
  %158 = load i64, i64* %157, align 8, !tbaa !549
  %159 = trunc i64 %158 to i32
  %160 = icmp eq i32 %159, 3
  br i1 %160, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %161 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %161(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %162 = getelementptr inbounds i64, i64* %45, i64 3
  %163 = load i64, i64* %162, align 8, !tbaa !552
  %164 = trunc i64 %163 to i32
  %165 = icmp eq i32 %164, 3
  br i1 %165, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %166 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %166(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %167 = getelementptr inbounds i64, i64* %45, i64 4
  %168 = load i64, i64* %167, align 8, !tbaa !554
  %169 = trunc i64 %168 to i32
  %170 = icmp eq i32 %169, 512
  br i1 %170, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.98, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %172 = getelementptr inbounds i64, i64* %45, i64 5
  %173 = load i64, i64* %172, align 8, !tbaa !558
  %174 = trunc i64 %173 to i32
  %175 = icmp eq i32 %174, 32
  br i1 %175, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %176 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %176(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %177 = icmp eq i64* %47, null
  br i1 %177, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %178 = bitcast i64* %47 to <4 x i64>*
  %179 = load <4 x i64>, <4 x i64>* %178, align 8, !tbaa !560
  %180 = trunc <4 x i64> %179 to <4 x i32>
  %181 = icmp eq <4 x i32> %180, <i32 147456, i32 147456, i32 49152, i32 16384>
  %182 = getelementptr inbounds i64, i64* %47, i64 4
  %183 = load i64, i64* %182, align 8, !tbaa !572
  %184 = trunc i64 %183 to i32
  %185 = icmp eq i32 %184, 32
  %186 = getelementptr inbounds i64, i64* %47, i64 5
  %187 = load i64, i64* %186, align 8, !tbaa !576
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  %rdx.shuf139 = shufflevector <4 x i1> %181, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %181, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %190 = extractelement <4 x i1> %bin.rdx142, i32 0
  %191 = and i1 %190, %185
  %192 = and i1 %191, %189
  br i1 %192, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %193 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %194 = load i64, i64* %193, align 8
  %195 = icmp eq i64 %194, 0
  br i1 %195, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([281 x i8], [281 x i8]* @.str.99, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %197 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %197(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %198 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %199 = load i32, i32* %198, align 4
  %200 = icmp eq i32 %199, 1
  br i1 %200, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %201 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %201(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %202 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %203 = load i32, i32* %202, align 4
  %204 = icmp eq i32 %41, %203
  br i1 %204, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %205 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %205(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %206 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %207 = load i32, i32* %206, align 4
  %208 = icmp eq i32 %207, 5
  br i1 %208, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %209 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %209(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %210 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %211 = load i16, i16* %210, align 2
  %212 = icmp eq i16 %211, 1
  %213 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %214 = load i8, i8* %213, align 1
  %215 = icmp eq i8 %214, 32
  %216 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %217 = load i8, i8* %216, align 1
  %218 = icmp eq i8 %217, 2
  %219 = and i1 %215, %218
  %220 = and i1 %212, %219
  br i1 %220, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %222 = load i64, i64* %51, align 8, !tbaa !578
  %223 = trunc i64 %222 to i32
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %226 = getelementptr inbounds i64, i64* %51, i64 1
  %227 = load i64, i64* %226, align 8, !tbaa !592
  %228 = trunc i64 %227 to i32
  %229 = icmp eq i32 %228, 16
  br i1 %229, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %230 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %230(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %231 = getelementptr inbounds i64, i64* %51, i64 2
  %232 = load i64, i64* %231, align 8, !tbaa !594
  %233 = trunc i64 %232 to i32
  %234 = icmp eq i32 %233, 1
  br i1 %234, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %235 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %235(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %236 = getelementptr inbounds i64, i64* %51, i64 3
  %237 = load i64, i64* %236, align 8, !tbaa !597
  %238 = trunc i64 %237 to i32
  %239 = icmp eq i32 %238, 1
  br i1 %239, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %240 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %240(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %241 = getelementptr inbounds i64, i64* %51, i64 4
  %242 = load i64, i64* %241, align 8, !tbaa !599
  %243 = trunc i64 %242 to i32
  %244 = icmp eq i32 %243, 32
  br i1 %244, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %246 = icmp eq i64* %53, null
  br i1 %246, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %247 = bitcast i64* %53 to <4 x i64>*
  %248 = load <4 x i64>, <4 x i64>* %247, align 8, !tbaa !603
  %249 = trunc <4 x i64> %248 to <4 x i32>
  %250 = icmp eq <4 x i32> %249, <i32 512, i32 32, i32 32, i32 32>
  %251 = getelementptr inbounds i64, i64* %53, i64 4
  %252 = load i64, i64* %251, align 8, !tbaa !615
  %253 = trunc i64 %252 to i32
  %254 = icmp eq i32 %253, 1
  %rdx.shuf135 = shufflevector <4 x i1> %250, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %250, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %255 = extractelement <4 x i1> %bin.rdx138, i32 0
  %256 = and i1 %255, %254
  br i1 %256, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %257 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %258 = load i64, i64* %257, align 8
  %259 = icmp eq i64 %258, 0
  br i1 %259, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.101, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %262 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %263 = load i32, i32* %262, align 4
  %264 = icmp eq i32 %263, 1
  br i1 %264, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %265 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %265(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %266 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %267 = load i32, i32* %266, align 4
  %268 = icmp eq i32 %41, %267
  br i1 %268, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %269 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %269(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %270 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %271 = load i32, i32* %270, align 4
  %272 = icmp eq i32 %271, 5
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %275 = load i16, i16* %274, align 2
  %276 = icmp eq i16 %275, 1
  %277 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %278 = load i8, i8* %277, align 1
  %279 = icmp eq i8 %278, 32
  %280 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %281 = load i8, i8* %280, align 1
  %282 = icmp eq i8 %281, 2
  %283 = and i1 %279, %282
  %284 = and i1 %276, %283
  br i1 %284, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %285 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %285(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %286 = load i64, i64* %57, align 8, !tbaa !619
  %287 = trunc i64 %286 to i32
  %288 = icmp eq i32 %287, 1
  br i1 %288, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %289 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %289(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %290 = getelementptr inbounds i64, i64* %57, i64 1
  %291 = load i64, i64* %290, align 8, !tbaa !633
  %292 = trunc i64 %291 to i32
  %293 = icmp eq i32 %292, 16
  br i1 %293, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %294 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %294(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %295 = getelementptr inbounds i64, i64* %57, i64 2
  %296 = load i64, i64* %295, align 8, !tbaa !635
  %297 = trunc i64 %296 to i32
  %298 = icmp eq i32 %297, 7
  br i1 %298, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %300 = getelementptr inbounds i64, i64* %57, i64 3
  %301 = load i64, i64* %300, align 8, !tbaa !638
  %302 = trunc i64 %301 to i32
  %303 = icmp eq i32 %302, 7
  br i1 %303, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %304 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %304(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.104, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %305 = getelementptr inbounds i64, i64* %57, i64 4
  %306 = load i64, i64* %305, align 8, !tbaa !640
  %307 = trunc i64 %306 to i32
  %308 = icmp eq i32 %307, 32
  br i1 %308, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %309 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %309(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %310 = icmp eq i64* %59, null
  br i1 %310, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %311 = bitcast i64* %59 to <4 x i64>*
  %312 = load <4 x i64>, <4 x i64>* %311, align 8, !tbaa !644
  %313 = trunc <4 x i64> %312 to <4 x i32>
  %314 = icmp eq <4 x i32> %313, <i32 25088, i32 1568, i32 224, i32 32>
  %315 = getelementptr inbounds i64, i64* %59, i64 4
  %316 = load i64, i64* %315, align 8, !tbaa !656
  %317 = trunc i64 %316 to i32
  %318 = icmp eq i32 %317, 1
  %rdx.shuf131 = shufflevector <4 x i1> %314, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %314, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %319 = extractelement <4 x i1> %bin.rdx134, i32 0
  %320 = and i1 %319, %318
  br i1 %320, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %321 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %322 = load i64, i64* %321, align 8
  %323 = icmp eq i64 %322, 0
  br i1 %323, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.105, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %325 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %325(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %326 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %327 = load i32, i32* %326, align 4
  %328 = icmp eq i32 %327, 1
  br i1 %328, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %330 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %41, %331
  br i1 %332, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %334 = getelementptr inbounds %1, %1* %28, i64 0, i32 2
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %335, 5
  br i1 %336, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %338 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 2
  %339 = load i16, i16* %338, align 2
  %340 = icmp eq i16 %339, 1
  %341 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 1
  %342 = load i8, i8* %341, align 1
  %343 = icmp eq i8 %342, 32
  %344 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 0
  %345 = load i8, i8* %344, align 1
  %346 = icmp eq i8 %345, 2
  %347 = and i1 %343, %346
  %348 = and i1 %340, %347
  br i1 %348, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %350 = load i64, i64* %63, align 8, !tbaa !660
  %351 = trunc i64 %350 to i32
  %352 = icmp eq i32 %351, 1
  br i1 %352, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %354 = getelementptr inbounds i64, i64* %63, i64 1
  %355 = load i64, i64* %354, align 8, !tbaa !674
  %356 = trunc i64 %355 to i32
  %357 = icmp eq i32 %356, 16
  br i1 %357, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %358 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %358(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %359 = getelementptr inbounds i64, i64* %63, i64 2
  %360 = load i64, i64* %359, align 8, !tbaa !676
  %361 = trunc i64 %360 to i32
  %362 = icmp eq i32 %361, 7
  br i1 %362, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %363 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %363(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.107, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %364 = getelementptr inbounds i64, i64* %63, i64 3
  %365 = load i64, i64* %364, align 8, !tbaa !679
  %366 = trunc i64 %365 to i32
  %367 = icmp eq i32 %366, 7
  br i1 %367, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %368 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %368(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.108, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %369 = getelementptr inbounds i64, i64* %63, i64 4
  %370 = load i64, i64* %369, align 8, !tbaa !681
  %371 = trunc i64 %370 to i32
  %372 = icmp eq i32 %371, 32
  br i1 %372, label %assert_end118, label %assert_fail117, !prof !5

assert_fail117:                                   ; preds = %assert_end116
  %373 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %373(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.80, i64 0, i64 0))
  ret i32 -1

assert_end118:                                    ; preds = %assert_end116
  %374 = icmp eq i64* %65, null
  br i1 %374, label %if_end120, label %if_then119, !prof !50

if_then119:                                       ; preds = %assert_end118
  %375 = bitcast i64* %65 to <4 x i64>*
  %376 = load <4 x i64>, <4 x i64>* %375, align 8, !tbaa !685
  %377 = trunc <4 x i64> %376 to <4 x i32>
  %378 = icmp eq <4 x i32> %377, <i32 25088, i32 1568, i32 224, i32 32>
  %379 = getelementptr inbounds i64, i64* %65, i64 4
  %380 = load i64, i64* %379, align 8, !tbaa !697
  %381 = trunc i64 %380 to i32
  %382 = icmp eq i32 %381, 1
  %rdx.shuf = shufflevector <4 x i1> %378, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %378, %rdx.shuf
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx, %rdx.shuf129
  %383 = extractelement <4 x i1> %bin.rdx130, i32 0
  %384 = and i1 %383, %382
  br i1 %384, label %if_end120, label %assert_fail121, !prof !5

if_end120:                                        ; preds = %assert_end118, %if_then119
  %385 = getelementptr inbounds %1, %1* %28, i64 0, i32 6
  %386 = load i64, i64* %385, align 8
  %387 = icmp eq i64 %386, 0
  br i1 %387, label %assert_end124, label %assert_fail123, !prof !5

assert_fail121:                                   ; preds = %if_then119
  %388 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %388(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.109, i64 0, i64 0))
  ret i32 -1

assert_fail123:                                   ; preds = %if_end120
  %389 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %389(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.82, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %if_end120
  %390 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 0
  %391 = load i32, i32* %390, align 4
  %392 = icmp eq i32 %391, 1
  br i1 %392, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %393 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %393(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.83, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %394 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 1
  %395 = load i32, i32* %394, align 4
  %396 = icmp eq i32 %41, %395
  br i1 %396, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %397 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %397(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %398 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_compute_(i8* %33, i8* %43, i8* %61, i8* %49, i8* %55, i32 %41)
  ret i32 %398
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 165888, i32 2, i32 32)
  %8 = alloca %7, align 8
  %9 = getelementptr inbounds %7, %7* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %7, %7* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %7* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.110, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %23, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %8, align 8
  %16 = getelementptr inbounds %8, %8* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %8, %8* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %8, %8* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %8, %8* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %8, %8* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = bitcast %8* %15 to i8*
  %22 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %23 = call i32 %22(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.111, i8* nonnull %21, i32 0)
  %24 = icmp eq i32 %23, 0
  br i1 %24, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %25 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %26 = call i32 %25(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.110(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 8
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 9
  %15 = select i1 %14, i32 %13, i32 9
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 9
  %18 = select i1 %17, i32 %16, i32 9
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 9
  %21 = select i1 %20, i32 %16, i32 9
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -4608
  %23 = add i32 %22, -4608
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv, 4608
  %29 = trunc i64 %indvars.iv to i32
  %.off = add i32 %29, -1
  %30 = icmp ult i32 %.off, 7
  %31 = trunc i64 %indvars.iv to i32
  %32 = mul i32 %31, 3584
  br i1 %30, label %if_end.us.8, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %33 = mul i32 %indvar, 4608
  %34 = add i32 %23, %33
  %35 = sext i32 %34 to i64
  %scevgep = getelementptr float, float* %4, i64 %35
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 18432, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_body2.preheader, %if_end.us.8
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %36 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %36, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.8:                                      ; preds = %for_begin1.preheader
  %37 = getelementptr inbounds float, float* %4, i64 %28
  %38 = bitcast float* %37 to <512 x float>*
  store <512 x float> zeroinitializer, <512 x float>* %38, align 64, !tbaa !701
  %39 = add nsw i64 %28, 512
  %40 = add i32 %32, -3584
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %7, i64 %41
  %43 = bitcast float* %42 to <512 x float>*
  %44 = load <512 x float>, <512 x float>* %43, align 64, !tbaa !704
  %45 = getelementptr inbounds float, float* %4, i64 %39
  %46 = bitcast float* %45 to <512 x float>*
  store <512 x float> %44, <512 x float>* %46, align 64, !tbaa !701
  %47 = add nsw i64 %28, 1024
  %48 = add i32 %32, -3072
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to <512 x float>*
  %52 = load <512 x float>, <512 x float>* %51, align 64, !tbaa !704
  %53 = getelementptr inbounds float, float* %4, i64 %47
  %54 = bitcast float* %53 to <512 x float>*
  store <512 x float> %52, <512 x float>* %54, align 64, !tbaa !701
  %55 = add nsw i64 %28, 1536
  %56 = add i32 %32, -2560
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds float, float* %7, i64 %57
  %59 = bitcast float* %58 to <512 x float>*
  %60 = load <512 x float>, <512 x float>* %59, align 64, !tbaa !704
  %61 = getelementptr inbounds float, float* %4, i64 %55
  %62 = bitcast float* %61 to <512 x float>*
  store <512 x float> %60, <512 x float>* %62, align 64, !tbaa !701
  %63 = add nsw i64 %28, 2048
  %64 = add i32 %32, -2048
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <512 x float>*
  %68 = load <512 x float>, <512 x float>* %67, align 64, !tbaa !704
  %69 = getelementptr inbounds float, float* %4, i64 %63
  %70 = bitcast float* %69 to <512 x float>*
  store <512 x float> %68, <512 x float>* %70, align 64, !tbaa !701
  %71 = add nsw i64 %28, 2560
  %72 = add i32 %32, -1536
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = bitcast float* %74 to <512 x float>*
  %76 = load <512 x float>, <512 x float>* %75, align 64, !tbaa !704
  %77 = getelementptr inbounds float, float* %4, i64 %71
  %78 = bitcast float* %77 to <512 x float>*
  store <512 x float> %76, <512 x float>* %78, align 64, !tbaa !701
  %79 = add nsw i64 %28, 3072
  %80 = add i32 %32, -1024
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <512 x float>*
  %84 = load <512 x float>, <512 x float>* %83, align 64, !tbaa !704
  %85 = getelementptr inbounds float, float* %4, i64 %79
  %86 = bitcast float* %85 to <512 x float>*
  store <512 x float> %84, <512 x float>* %86, align 64, !tbaa !701
  %87 = add nsw i64 %28, 3584
  %88 = add i32 %32, -512
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds float, float* %7, i64 %89
  %91 = bitcast float* %90 to <512 x float>*
  %92 = load <512 x float>, <512 x float>* %91, align 64, !tbaa !704
  %93 = getelementptr inbounds float, float* %4, i64 %87
  %94 = bitcast float* %93 to <512 x float>*
  store <512 x float> %92, <512 x float>* %94, align 64, !tbaa !701
  %95 = add nsw i64 %28, 4096
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = bitcast float* %96 to <512 x float>*
  store <512 x float> zeroinitializer, <512 x float>* %97, align 64, !tbaa !701
  br label %for_end3
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.111(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.2
  %indvars.iv48 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next49, %for_end6.2 ]
  %33 = trunc i64 %indvars.iv48 to i32
  %34 = srem i32 %33, 7
  %35 = sdiv i32 %33, 7
  %36 = mul nsw i32 %35, 147456
  %37 = sext i32 %36 to i64
  %38 = mul nsw i32 %34, 4608
  %39 = sext i32 %38 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.2, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %125, %for_body5 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %119, %for_body5 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %118, %for_body5 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %117, %for_body5 ]
  %44 = phi <32 x float> [ zeroinitializer, %for_body ], [ %116, %for_body5 ]
  %45 = phi <32 x float> [ zeroinitializer, %for_body ], [ %115, %for_body5 ]
  %46 = phi <32 x float> [ zeroinitializer, %for_body ], [ %114, %for_body5 ]
  %47 = add nsw i64 %indvars.iv, %39
  %48 = getelementptr inbounds float, float* %4, i64 %47
  %49 = load float, float* %48, align 4, !tbaa !701
  %50 = insertelement <32 x float> undef, float %49, i32 0
  %51 = shufflevector <32 x float> %50, <32 x float> undef, <32 x i32> zeroinitializer
  %52 = shl nsw i64 %indvars.iv, 5
  %53 = add nsw i64 %52, %37
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <32 x float>*
  %56 = load <32 x float>, <32 x float>* %55, align 64, !tbaa !707
  %57 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %51, <32 x float> %56, <32 x float> %46)
  %58 = add nsw i64 %47, 512
  %59 = getelementptr inbounds float, float* %4, i64 %58
  %60 = load float, float* %59, align 4, !tbaa !701
  %61 = insertelement <32 x float> undef, float %60, i32 0
  %62 = shufflevector <32 x float> %61, <32 x float> undef, <32 x i32> zeroinitializer
  %63 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %56, <32 x float> %45)
  %64 = add nsw i64 %47, 1024
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !701
  %67 = insertelement <32 x float> undef, float %66, i32 0
  %68 = shufflevector <32 x float> %67, <32 x float> undef, <32 x i32> zeroinitializer
  %69 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %56, <32 x float> %44)
  %70 = add nsw i64 %47, 1536
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !701
  %73 = insertelement <32 x float> undef, float %72, i32 0
  %74 = shufflevector <32 x float> %73, <32 x float> undef, <32 x i32> zeroinitializer
  %75 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %56, <32 x float> %43)
  %76 = add nsw i64 %47, 2048
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !701
  %79 = insertelement <32 x float> undef, float %78, i32 0
  %80 = shufflevector <32 x float> %79, <32 x float> undef, <32 x i32> zeroinitializer
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %56, <32 x float> %42)
  %82 = add nsw i64 %47, 2560
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !701
  %85 = insertelement <32 x float> undef, float %84, i32 0
  %86 = shufflevector <32 x float> %85, <32 x float> undef, <32 x i32> zeroinitializer
  %87 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %56, <32 x float> %41)
  %88 = add nsw i64 %47, 3072
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !701
  %91 = insertelement <32 x float> undef, float %90, i32 0
  %92 = shufflevector <32 x float> %91, <32 x float> undef, <32 x i32> zeroinitializer
  %93 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %56, <32 x float> %40)
  %94 = add nsw i64 %53, 16384
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to <32 x float>*
  %97 = load <32 x float>, <32 x float>* %96, align 64, !tbaa !707
  %98 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %97, <32 x float> %57)
  %99 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %97, <32 x float> %63)
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %97, <32 x float> %69)
  %101 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %97, <32 x float> %75)
  %102 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %97, <32 x float> %81)
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %97, <32 x float> %87)
  %104 = add nsw i64 %47, 3584
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !701
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %97, <32 x float> %93)
  %110 = add nsw i64 %53, 32768
  %111 = getelementptr inbounds float, float* %7, i64 %110
  %112 = bitcast float* %111 to <32 x float>*
  %113 = load <32 x float>, <32 x float>* %112, align 64, !tbaa !707
  %114 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %113, <32 x float> %98)
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %113, <32 x float> %99)
  %116 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %113, <32 x float> %100)
  %117 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %113, <32 x float> %101)
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %113, <32 x float> %102)
  %119 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %113, <32 x float> %103)
  %120 = add nsw i64 %47, 4096
  %121 = getelementptr inbounds float, float* %4, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !701
  %123 = insertelement <32 x float> undef, float %122, i32 0
  %124 = shufflevector <32 x float> %123, <32 x float> undef, <32 x i32> zeroinitializer
  %125 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %124, <32 x float> %113, <32 x float> %109)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %126 = mul nsw i32 %34, 4608
  %127 = add nsw i32 %126, 4608
  %128 = add nsw i64 %37, 49152
  %129 = sext i32 %127 to i64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %130 = phi <32 x float> [ %125, %for_end6 ], [ %215, %for_body5.1 ]
  %131 = phi <32 x float> [ %119, %for_end6 ], [ %209, %for_body5.1 ]
  %132 = phi <32 x float> [ %118, %for_end6 ], [ %208, %for_body5.1 ]
  %133 = phi <32 x float> [ %117, %for_end6 ], [ %207, %for_body5.1 ]
  %134 = phi <32 x float> [ %116, %for_end6 ], [ %206, %for_body5.1 ]
  %135 = phi <32 x float> [ %115, %for_end6 ], [ %205, %for_body5.1 ]
  %136 = phi <32 x float> [ %114, %for_end6 ], [ %204, %for_body5.1 ]
  %137 = add nsw i64 %indvars.iv.1, %129
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !701
  %140 = insertelement <32 x float> undef, float %139, i32 0
  %141 = shufflevector <32 x float> %140, <32 x float> undef, <32 x i32> zeroinitializer
  %142 = shl nsw i64 %indvars.iv.1, 5
  %143 = add nsw i64 %128, %142
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <32 x float>*
  %146 = load <32 x float>, <32 x float>* %145, align 64, !tbaa !707
  %147 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %141, <32 x float> %146, <32 x float> %136)
  %148 = add nsw i64 %137, 512
  %149 = getelementptr inbounds float, float* %4, i64 %148
  %150 = load float, float* %149, align 4, !tbaa !701
  %151 = insertelement <32 x float> undef, float %150, i32 0
  %152 = shufflevector <32 x float> %151, <32 x float> undef, <32 x i32> zeroinitializer
  %153 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %152, <32 x float> %146, <32 x float> %135)
  %154 = add nsw i64 %137, 1024
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !701
  %157 = insertelement <32 x float> undef, float %156, i32 0
  %158 = shufflevector <32 x float> %157, <32 x float> undef, <32 x i32> zeroinitializer
  %159 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %146, <32 x float> %134)
  %160 = add nsw i64 %137, 1536
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !701
  %163 = insertelement <32 x float> undef, float %162, i32 0
  %164 = shufflevector <32 x float> %163, <32 x float> undef, <32 x i32> zeroinitializer
  %165 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %164, <32 x float> %146, <32 x float> %133)
  %166 = add nsw i64 %137, 2048
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !701
  %169 = insertelement <32 x float> undef, float %168, i32 0
  %170 = shufflevector <32 x float> %169, <32 x float> undef, <32 x i32> zeroinitializer
  %171 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %170, <32 x float> %146, <32 x float> %132)
  %172 = add nsw i64 %137, 2560
  %173 = getelementptr inbounds float, float* %4, i64 %172
  %174 = load float, float* %173, align 4, !tbaa !701
  %175 = insertelement <32 x float> undef, float %174, i32 0
  %176 = shufflevector <32 x float> %175, <32 x float> undef, <32 x i32> zeroinitializer
  %177 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %176, <32 x float> %146, <32 x float> %131)
  %178 = add nsw i64 %137, 3072
  %179 = getelementptr inbounds float, float* %4, i64 %178
  %180 = load float, float* %179, align 4, !tbaa !701
  %181 = insertelement <32 x float> undef, float %180, i32 0
  %182 = shufflevector <32 x float> %181, <32 x float> undef, <32 x i32> zeroinitializer
  %183 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %182, <32 x float> %146, <32 x float> %130)
  %184 = add nsw i64 %143, 16384
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to <32 x float>*
  %187 = load <32 x float>, <32 x float>* %186, align 64, !tbaa !707
  %188 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %152, <32 x float> %187, <32 x float> %147)
  %189 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %187, <32 x float> %153)
  %190 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %164, <32 x float> %187, <32 x float> %159)
  %191 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %170, <32 x float> %187, <32 x float> %165)
  %192 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %176, <32 x float> %187, <32 x float> %171)
  %193 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %182, <32 x float> %187, <32 x float> %177)
  %194 = add nsw i64 %137, 3584
  %195 = getelementptr inbounds float, float* %4, i64 %194
  %196 = load float, float* %195, align 4, !tbaa !701
  %197 = insertelement <32 x float> undef, float %196, i32 0
  %198 = shufflevector <32 x float> %197, <32 x float> undef, <32 x i32> zeroinitializer
  %199 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %198, <32 x float> %187, <32 x float> %183)
  %200 = add nsw i64 %143, 32768
  %201 = getelementptr inbounds float, float* %7, i64 %200
  %202 = bitcast float* %201 to <32 x float>*
  %203 = load <32 x float>, <32 x float>* %202, align 64, !tbaa !707
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %203, <32 x float> %188)
  %205 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %164, <32 x float> %203, <32 x float> %189)
  %206 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %170, <32 x float> %203, <32 x float> %190)
  %207 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %176, <32 x float> %203, <32 x float> %191)
  %208 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %182, <32 x float> %203, <32 x float> %192)
  %209 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %198, <32 x float> %203, <32 x float> %193)
  %210 = add nsw i64 %137, 4096
  %211 = getelementptr inbounds float, float* %4, i64 %210
  %212 = load float, float* %211, align 4, !tbaa !701
  %213 = insertelement <32 x float> undef, float %212, i32 0
  %214 = shufflevector <32 x float> %213, <32 x float> undef, <32 x i32> zeroinitializer
  %215 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %214, <32 x float> %203, <32 x float> %199)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %216 = mul nsw i32 %34, 4608
  %217 = add nsw i32 %216, 9216
  %218 = add nsw i64 %37, 98304
  %219 = sext i32 %217 to i64
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %220 = phi <32 x float> [ %215, %for_end6.1 ], [ %305, %for_body5.2 ]
  %221 = phi <32 x float> [ %209, %for_end6.1 ], [ %299, %for_body5.2 ]
  %222 = phi <32 x float> [ %208, %for_end6.1 ], [ %298, %for_body5.2 ]
  %223 = phi <32 x float> [ %207, %for_end6.1 ], [ %297, %for_body5.2 ]
  %224 = phi <32 x float> [ %206, %for_end6.1 ], [ %296, %for_body5.2 ]
  %225 = phi <32 x float> [ %205, %for_end6.1 ], [ %295, %for_body5.2 ]
  %226 = phi <32 x float> [ %204, %for_end6.1 ], [ %294, %for_body5.2 ]
  %227 = add nsw i64 %indvars.iv.2, %219
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = load float, float* %228, align 4, !tbaa !701
  %230 = insertelement <32 x float> undef, float %229, i32 0
  %231 = shufflevector <32 x float> %230, <32 x float> undef, <32 x i32> zeroinitializer
  %232 = shl nsw i64 %indvars.iv.2, 5
  %233 = add nsw i64 %218, %232
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <32 x float>*
  %236 = load <32 x float>, <32 x float>* %235, align 64, !tbaa !707
  %237 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %231, <32 x float> %236, <32 x float> %226)
  %238 = add nsw i64 %227, 512
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !701
  %241 = insertelement <32 x float> undef, float %240, i32 0
  %242 = shufflevector <32 x float> %241, <32 x float> undef, <32 x i32> zeroinitializer
  %243 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %236, <32 x float> %225)
  %244 = add nsw i64 %227, 1024
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !701
  %247 = insertelement <32 x float> undef, float %246, i32 0
  %248 = shufflevector <32 x float> %247, <32 x float> undef, <32 x i32> zeroinitializer
  %249 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %236, <32 x float> %224)
  %250 = add nsw i64 %227, 1536
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !701
  %253 = insertelement <32 x float> undef, float %252, i32 0
  %254 = shufflevector <32 x float> %253, <32 x float> undef, <32 x i32> zeroinitializer
  %255 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %254, <32 x float> %236, <32 x float> %223)
  %256 = add nsw i64 %227, 2048
  %257 = getelementptr inbounds float, float* %4, i64 %256
  %258 = load float, float* %257, align 4, !tbaa !701
  %259 = insertelement <32 x float> undef, float %258, i32 0
  %260 = shufflevector <32 x float> %259, <32 x float> undef, <32 x i32> zeroinitializer
  %261 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %260, <32 x float> %236, <32 x float> %222)
  %262 = add nsw i64 %227, 2560
  %263 = getelementptr inbounds float, float* %4, i64 %262
  %264 = load float, float* %263, align 4, !tbaa !701
  %265 = insertelement <32 x float> undef, float %264, i32 0
  %266 = shufflevector <32 x float> %265, <32 x float> undef, <32 x i32> zeroinitializer
  %267 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %266, <32 x float> %236, <32 x float> %221)
  %268 = add nsw i64 %227, 3072
  %269 = getelementptr inbounds float, float* %4, i64 %268
  %270 = load float, float* %269, align 4, !tbaa !701
  %271 = insertelement <32 x float> undef, float %270, i32 0
  %272 = shufflevector <32 x float> %271, <32 x float> undef, <32 x i32> zeroinitializer
  %273 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %272, <32 x float> %236, <32 x float> %220)
  %274 = add nsw i64 %233, 16384
  %275 = getelementptr inbounds float, float* %7, i64 %274
  %276 = bitcast float* %275 to <32 x float>*
  %277 = load <32 x float>, <32 x float>* %276, align 64, !tbaa !707
  %278 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %277, <32 x float> %237)
  %279 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %277, <32 x float> %243)
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %254, <32 x float> %277, <32 x float> %249)
  %281 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %260, <32 x float> %277, <32 x float> %255)
  %282 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %266, <32 x float> %277, <32 x float> %261)
  %283 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %272, <32 x float> %277, <32 x float> %267)
  %284 = add nsw i64 %227, 3584
  %285 = getelementptr inbounds float, float* %4, i64 %284
  %286 = load float, float* %285, align 4, !tbaa !701
  %287 = insertelement <32 x float> undef, float %286, i32 0
  %288 = shufflevector <32 x float> %287, <32 x float> undef, <32 x i32> zeroinitializer
  %289 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %288, <32 x float> %277, <32 x float> %273)
  %290 = add nsw i64 %233, 32768
  %291 = getelementptr inbounds float, float* %7, i64 %290
  %292 = bitcast float* %291 to <32 x float>*
  %293 = load <32 x float>, <32 x float>* %292, align 64, !tbaa !707
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %293, <32 x float> %278)
  %295 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %254, <32 x float> %293, <32 x float> %279)
  %296 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %260, <32 x float> %293, <32 x float> %280)
  %297 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %266, <32 x float> %293, <32 x float> %281)
  %298 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %272, <32 x float> %293, <32 x float> %282)
  %299 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %288, <32 x float> %293, <32 x float> %283)
  %300 = add nsw i64 %227, 4096
  %301 = getelementptr inbounds float, float* %4, i64 %300
  %302 = load float, float* %301, align 4, !tbaa !701
  %303 = insertelement <32 x float> undef, float %302, i32 0
  %304 = shufflevector <32 x float> %303, <32 x float> undef, <32 x i32> zeroinitializer
  %305 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %304, <32 x float> %293, <32 x float> %289)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %306 = mul nsw i64 %indvars.iv48, 224
  %307 = shl nsw i32 %35, 5
  %308 = sext i32 %307 to i64
  %309 = getelementptr inbounds float, float* %13, i64 %308
  %310 = bitcast float* %309 to <32 x float>*
  %311 = load <32 x float>, <32 x float>* %310, align 64, !tbaa !710
  %312 = getelementptr inbounds float, float* %16, i64 %306
  %313 = bitcast float* %312 to <32 x float>*
  %314 = load <32 x float>, <32 x float>* %313, align 64, !tbaa !713
  %315 = fadd <32 x float> %311, %294
  %316 = fadd <32 x float> %314, %315
  %317 = fcmp ogt <32 x float> %316, zeroinitializer
  %318 = select <32 x i1> %317, <32 x float> %316, <32 x float> zeroinitializer
  %319 = getelementptr inbounds float, float* %10, i64 %306
  %320 = bitcast float* %319 to <32 x float>*
  store <32 x float> %318, <32 x float>* %320, align 64, !tbaa !716
  %321 = add nsw i64 %306, 32
  %322 = getelementptr inbounds float, float* %16, i64 %321
  %323 = bitcast float* %322 to <32 x float>*
  %324 = load <32 x float>, <32 x float>* %323, align 64, !tbaa !713
  %325 = fadd <32 x float> %311, %295
  %326 = fadd <32 x float> %324, %325
  %327 = fcmp ogt <32 x float> %326, zeroinitializer
  %328 = select <32 x i1> %327, <32 x float> %326, <32 x float> zeroinitializer
  %329 = getelementptr inbounds float, float* %10, i64 %321
  %330 = bitcast float* %329 to <32 x float>*
  store <32 x float> %328, <32 x float>* %330, align 64, !tbaa !716
  %331 = add nsw i64 %306, 64
  %332 = getelementptr inbounds float, float* %16, i64 %331
  %333 = bitcast float* %332 to <32 x float>*
  %334 = load <32 x float>, <32 x float>* %333, align 64, !tbaa !713
  %335 = fadd <32 x float> %311, %296
  %336 = fadd <32 x float> %334, %335
  %337 = fcmp ogt <32 x float> %336, zeroinitializer
  %338 = select <32 x i1> %337, <32 x float> %336, <32 x float> zeroinitializer
  %339 = getelementptr inbounds float, float* %10, i64 %331
  %340 = bitcast float* %339 to <32 x float>*
  store <32 x float> %338, <32 x float>* %340, align 64, !tbaa !716
  %341 = add nsw i64 %306, 96
  %342 = getelementptr inbounds float, float* %16, i64 %341
  %343 = bitcast float* %342 to <32 x float>*
  %344 = load <32 x float>, <32 x float>* %343, align 64, !tbaa !713
  %345 = fadd <32 x float> %311, %297
  %346 = fadd <32 x float> %344, %345
  %347 = fcmp ogt <32 x float> %346, zeroinitializer
  %348 = select <32 x i1> %347, <32 x float> %346, <32 x float> zeroinitializer
  %349 = getelementptr inbounds float, float* %10, i64 %341
  %350 = bitcast float* %349 to <32 x float>*
  store <32 x float> %348, <32 x float>* %350, align 64, !tbaa !716
  %351 = add nsw i64 %306, 128
  %352 = getelementptr inbounds float, float* %16, i64 %351
  %353 = bitcast float* %352 to <32 x float>*
  %354 = load <32 x float>, <32 x float>* %353, align 64, !tbaa !713
  %355 = fadd <32 x float> %311, %298
  %356 = fadd <32 x float> %354, %355
  %357 = fcmp ogt <32 x float> %356, zeroinitializer
  %358 = select <32 x i1> %357, <32 x float> %356, <32 x float> zeroinitializer
  %359 = getelementptr inbounds float, float* %10, i64 %351
  %360 = bitcast float* %359 to <32 x float>*
  store <32 x float> %358, <32 x float>* %360, align 64, !tbaa !716
  %361 = add nsw i64 %306, 160
  %362 = getelementptr inbounds float, float* %16, i64 %361
  %363 = bitcast float* %362 to <32 x float>*
  %364 = load <32 x float>, <32 x float>* %363, align 64, !tbaa !713
  %365 = fadd <32 x float> %311, %299
  %366 = fadd <32 x float> %364, %365
  %367 = fcmp ogt <32 x float> %366, zeroinitializer
  %368 = select <32 x i1> %367, <32 x float> %366, <32 x float> zeroinitializer
  %369 = getelementptr inbounds float, float* %10, i64 %361
  %370 = bitcast float* %369 to <32 x float>*
  store <32 x float> %368, <32 x float>* %370, align 64, !tbaa !716
  %371 = add nsw i64 %306, 192
  %372 = getelementptr inbounds float, float* %16, i64 %371
  %373 = bitcast float* %372 to <32 x float>*
  %374 = load <32 x float>, <32 x float>* %373, align 64, !tbaa !713
  %375 = fadd <32 x float> %311, %305
  %376 = fadd <32 x float> %374, %375
  %377 = fcmp ogt <32 x float> %376, zeroinitializer
  %378 = select <32 x i1> %377, <32 x float> %376, <32 x float> zeroinitializer
  %379 = getelementptr inbounds float, float* %10, i64 %371
  %380 = bitcast float* %379 to <32 x float>*
  store <32 x float> %378, <32 x float>* %380, align 64, !tbaa !716
  %indvars.iv.next49 = add nsw i64 %indvars.iv48, 1
  %381 = icmp slt i64 %indvars.iv.next49, %32
  br i1 %381, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_dense_add(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([71 x i8], [71 x i8]* @.str.112, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !719
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !733
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !736
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.113, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !738
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.114, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.115, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([146 x i8], [146 x i8]* @.str.116, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 2
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.117, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !740
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !754
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 512
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.118, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = icmp eq i64* %31, null
  br i1 %88, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end18
  %89 = load i64, i64* %31, align 8, !tbaa !756
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 512
  %92 = getelementptr inbounds i64, i64* %31, i64 1
  %93 = load i64, i64* %92, align 8, !tbaa !770
  %94 = trunc i64 %93 to i32
  %95 = icmp eq i32 %94, 1
  %96 = and i1 %91, %95
  br i1 %96, label %if_end, label %assert_fail19, !prof !5

if_end:                                           ; preds = %assert_end18, %if_then
  %97 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %98 = load i64, i64* %97, align 8
  %99 = icmp eq i64 %98, 0
  br i1 %99, label %assert_end22, label %assert_fail21, !prof !5

assert_fail19:                                    ; preds = %if_then
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([124 x i8], [124 x i8]* @.str.119, i64 0, i64 0))
  ret i32 -1

assert_fail21:                                    ; preds = %if_end
  %101 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %101(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %if_end
  %102 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %103 = load i32, i32* %102, align 4
  %104 = icmp eq i32 %103, 2
  br i1 %104, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.31, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %106 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %107 = load i16, i16* %106, align 2
  %108 = icmp eq i16 %107, 1
  %109 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %110 = load i8, i8* %109, align 1
  %111 = icmp eq i8 %110, 32
  %112 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %113 = load i8, i8* %112, align 1
  %114 = icmp eq i8 %113, 2
  %115 = and i1 %111, %114
  %116 = and i1 %108, %115
  br i1 %116, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %118 = load i64, i64* %39, align 8, !tbaa !772
  %119 = trunc i64 %118 to i32
  %120 = icmp eq i32 %119, 1000
  br i1 %120, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %121 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %121(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.120, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %122 = getelementptr inbounds i64, i64* %39, i64 1
  %123 = load i64, i64* %122, align 8, !tbaa !786
  %124 = trunc i64 %123 to i32
  %125 = icmp eq i32 %124, 512
  br i1 %125, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %126 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %126(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.32, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %127 = icmp eq i64* %41, null
  br i1 %127, label %if_end32, label %if_then31, !prof !50

if_then31:                                        ; preds = %assert_end30
  %128 = load i64, i64* %41, align 8, !tbaa !788
  %129 = trunc i64 %128 to i32
  %130 = icmp eq i32 %129, 512
  %131 = getelementptr inbounds i64, i64* %41, i64 1
  %132 = load i64, i64* %131, align 8, !tbaa !802
  %133 = trunc i64 %132 to i32
  %134 = icmp eq i32 %133, 1
  %135 = and i1 %130, %134
  br i1 %135, label %if_end32, label %assert_fail33, !prof !5

if_end32:                                         ; preds = %assert_end30, %if_then31
  %136 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %137 = load i64, i64* %136, align 8
  %138 = icmp eq i64 %137, 0
  br i1 %138, label %assert_end36, label %assert_fail35, !prof !5

assert_fail33:                                    ; preds = %if_then31
  %139 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %139(i8* getelementptr inbounds ([124 x i8], [124 x i8]* @.str.33, i64 0, i64 0))
  ret i32 -1

assert_fail35:                                    ; preds = %if_end32
  %140 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %140(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %if_end32
  %141 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %142 = load i32, i32* %141, align 4
  %143 = icmp eq i32 %142, 1
  br i1 %143, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %144 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %144(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %145 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %146 = load i32, i32* %145, align 4
  %147 = icmp eq i32 %35, %146
  br i1 %147, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %149 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.121, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %153 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %154 = load i16, i16* %153, align 2
  %155 = icmp eq i16 %154, 1
  %156 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %157 = load i8, i8* %156, align 1
  %158 = icmp eq i8 %157, 32
  %159 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %160 = load i8, i8* %159, align 1
  %161 = icmp eq i8 %160, 2
  %162 = and i1 %158, %161
  %163 = and i1 %155, %162
  br i1 %163, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %164 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %164(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %165 = load i64, i64* %45, align 8, !tbaa !804
  %166 = trunc i64 %165 to i32
  %167 = icmp eq i32 %166, 1000
  br i1 %167, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %168 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %168(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.122, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %169 = icmp eq i64* %47, null
  br i1 %169, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %170 = load i64, i64* %47, align 8, !tbaa !818
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 1
  br i1 %172, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %173 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %174 = load i64, i64* %173, align 8
  %175 = icmp eq i64 %174, 0
  br i1 %175, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %176 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %176(i8* getelementptr inbounds ([87 x i8], [87 x i8]* @.str.123, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %177 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %177(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %178 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %179 = load i32, i32* %178, align 4
  %180 = icmp eq i32 %179, 1
  br i1 %180, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %181 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %181(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %182 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %183 = load i32, i32* %182, align 4
  %184 = icmp eq i32 %35, %183
  br i1 %184, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %185 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %185(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %186 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %187 = load i32, i32* %186, align 4
  %188 = icmp eq i32 %187, 2
  br i1 %188, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %189 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %189(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.124, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %190 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %191 = load i16, i16* %190, align 2
  %192 = icmp eq i16 %191, 1
  %193 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %194 = load i8, i8* %193, align 1
  %195 = icmp eq i8 %194, 32
  %196 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %197 = load i8, i8* %196, align 1
  %198 = icmp eq i8 %197, 2
  %199 = and i1 %195, %198
  %200 = and i1 %192, %199
  br i1 %200, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %201 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %201(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %202 = load i64, i64* %51, align 8, !tbaa !832
  %203 = trunc i64 %202 to i32
  %204 = icmp eq i32 %203, 1
  br i1 %204, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %205 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %205(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %206 = getelementptr inbounds i64, i64* %51, i64 1
  %207 = load i64, i64* %206, align 8, !tbaa !846
  %208 = trunc i64 %207 to i32
  %209 = icmp eq i32 %208, 1000
  br i1 %209, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %210 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %210(i8* getelementptr inbounds ([98 x i8], [98 x i8]* @.str.125, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %211 = icmp eq i64* %53, null
  br i1 %211, label %if_end66, label %if_then65, !prof !50

if_then65:                                        ; preds = %assert_end64
  %212 = load i64, i64* %53, align 8, !tbaa !848
  %213 = trunc i64 %212 to i32
  %214 = icmp eq i32 %213, 1000
  %215 = getelementptr inbounds i64, i64* %53, i64 1
  %216 = load i64, i64* %215, align 8, !tbaa !862
  %217 = trunc i64 %216 to i32
  %218 = icmp eq i32 %217, 1
  %219 = and i1 %214, %218
  br i1 %219, label %if_end66, label %assert_fail67, !prof !5

if_end66:                                         ; preds = %assert_end64, %if_then65
  %220 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %221 = load i64, i64* %220, align 8
  %222 = icmp eq i64 %221, 0
  br i1 %222, label %assert_end70, label %assert_fail69, !prof !5

assert_fail67:                                    ; preds = %if_then65
  %223 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %223(i8* getelementptr inbounds ([125 x i8], [125 x i8]* @.str.126, i64 0, i64 0))
  ret i32 -1

assert_fail69:                                    ; preds = %if_end66
  %224 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %224(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %if_end66
  %225 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %226 = load i32, i32* %225, align 4
  %227 = icmp eq i32 %226, 1
  br i1 %227, label %assert_end72, label %assert_fail71, !prof !5

assert_fail71:                                    ; preds = %assert_end70
  %228 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %228(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end72:                                     ; preds = %assert_end70
  %229 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %230 = load i32, i32* %229, align 4
  %231 = icmp eq i32 %35, %230
  br i1 %231, label %assert_end74, label %assert_fail73, !prof !5

assert_fail73:                                    ; preds = %assert_end72
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %assert_end72
  %233 = tail call fastcc i32 @fused_nn_dense_add_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %233
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_dense_add_compute_(i8* noalias, i8* noalias, i8* noalias nocapture, i8* noalias nocapture readonly, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 4000, i32 2, i32 32)
  %7 = alloca %9, align 8
  %8 = getelementptr inbounds %9, %9* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %9, %9* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %9, %9* %7, i64 0, i32 2
  store i8* %6, i8** %10, align 8
  %11 = bitcast %9* %7 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.127, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %for_begin.preheader, label %call_fail, !prof !5

for_begin.preheader:                              ; preds = %entry
  %15 = bitcast i8* %3 to float*
  %16 = bitcast i8* %6 to float*
  %17 = bitcast i8* %2 to float*
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %for_begin.preheader
  %index = phi i64 [ 0, %for_begin.preheader ], [ %index.next, %vector.body ]
  %18 = getelementptr inbounds float, float* %15, i64 %index
  %19 = bitcast float* %18 to <4 x float>*
  %wide.load = load <4 x float>, <4 x float>* %19, align 4, !tbaa !864
  %20 = getelementptr inbounds float, float* %18, i64 4
  %21 = bitcast float* %20 to <4 x float>*
  %wide.load5 = load <4 x float>, <4 x float>* %21, align 4, !tbaa !864
  %22 = getelementptr inbounds float, float* %16, i64 %index
  %23 = bitcast float* %22 to <4 x float>*
  %wide.load6 = load <4 x float>, <4 x float>* %23, align 4, !tbaa !867
  %24 = getelementptr inbounds float, float* %22, i64 4
  %25 = bitcast float* %24 to <4 x float>*
  %wide.load7 = load <4 x float>, <4 x float>* %25, align 4, !tbaa !867
  %26 = fadd <4 x float> %wide.load, %wide.load6
  %27 = fadd <4 x float> %wide.load5, %wide.load7
  %28 = getelementptr inbounds float, float* %17, i64 %index
  %29 = bitcast float* %28 to <4 x float>*
  store <4 x float> %26, <4 x float>* %29, align 4, !tbaa !870
  %30 = getelementptr inbounds float, float* %28, i64 4
  %31 = bitcast float* %30 to <4 x float>*
  store <4 x float> %27, <4 x float>* %31, align 4, !tbaa !870
  %index.next = add i64 %index, 8
  %32 = icmp eq i64 %index.next, 1000
  br i1 %32, label %for_end, label %vector.body, !llvm.loop !873

call_fail:                                        ; preds = %for_end, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %for_end ]
  ret i32 %merge

for_end:                                          ; preds = %vector.body
  %33 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %34 = call i32 %33(i32 1, i32 %4, i8* nonnull %6)
  br label %call_fail
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.127(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = add nsw i32 %12, 999
  %14 = sdiv i32 %13, %12
  %15 = add nsw i32 %0, 1
  %16 = mul nsw i32 %14, %15
  %17 = icmp slt i32 %16, 1000
  %18 = select i1 %17, i32 %16, i32 1000
  %19 = mul nsw i32 %14, %0
  %20 = icmp slt i32 %19, 1000
  %21 = select i1 %20, i32 %19, i32 1000
  %22 = icmp slt i32 %21, %18
  br i1 %22, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %23 = bitcast float* %4 to <16 x float>*
  %24 = add i32 %21, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %18 to i64
  %28 = load <16 x float>, <16 x float>* %23, align 64, !tbaa !875
  %29 = getelementptr inbounds float, float* %4, i64 16
  %30 = bitcast float* %29 to <16 x float>*
  %31 = load <16 x float>, <16 x float>* %30, align 64, !tbaa !875
  %32 = getelementptr inbounds float, float* %4, i64 32
  %33 = bitcast float* %32 to <16 x float>*
  %34 = load <16 x float>, <16 x float>* %33, align 64, !tbaa !875
  %35 = getelementptr inbounds float, float* %4, i64 48
  %36 = bitcast float* %35 to <16 x float>*
  %37 = load <16 x float>, <16 x float>* %36, align 64, !tbaa !875
  %38 = getelementptr inbounds float, float* %4, i64 64
  %39 = bitcast float* %38 to <16 x float>*
  %40 = load <16 x float>, <16 x float>* %39, align 64, !tbaa !875
  %41 = getelementptr inbounds float, float* %4, i64 80
  %42 = bitcast float* %41 to <16 x float>*
  %43 = load <16 x float>, <16 x float>* %42, align 64, !tbaa !875
  %44 = getelementptr inbounds float, float* %4, i64 96
  %45 = bitcast float* %44 to <16 x float>*
  %46 = load <16 x float>, <16 x float>* %45, align 64, !tbaa !875
  %47 = getelementptr inbounds float, float* %4, i64 112
  %48 = bitcast float* %47 to <16 x float>*
  %49 = load <16 x float>, <16 x float>* %48, align 64, !tbaa !875
  %50 = getelementptr inbounds float, float* %4, i64 128
  %51 = bitcast float* %50 to <16 x float>*
  %52 = load <16 x float>, <16 x float>* %51, align 64, !tbaa !875
  %53 = getelementptr inbounds float, float* %4, i64 144
  %54 = bitcast float* %53 to <16 x float>*
  %55 = load <16 x float>, <16 x float>* %54, align 64, !tbaa !875
  %56 = getelementptr inbounds float, float* %4, i64 160
  %57 = bitcast float* %56 to <16 x float>*
  %58 = load <16 x float>, <16 x float>* %57, align 64, !tbaa !875
  %59 = getelementptr inbounds float, float* %4, i64 176
  %60 = bitcast float* %59 to <16 x float>*
  %61 = load <16 x float>, <16 x float>* %60, align 64, !tbaa !875
  %62 = getelementptr inbounds float, float* %4, i64 192
  %63 = bitcast float* %62 to <16 x float>*
  %64 = load <16 x float>, <16 x float>* %63, align 64, !tbaa !875
  %65 = getelementptr inbounds float, float* %4, i64 208
  %66 = bitcast float* %65 to <16 x float>*
  %67 = load <16 x float>, <16 x float>* %66, align 64, !tbaa !875
  %68 = getelementptr inbounds float, float* %4, i64 224
  %69 = bitcast float* %68 to <16 x float>*
  %70 = load <16 x float>, <16 x float>* %69, align 64, !tbaa !875
  %71 = getelementptr inbounds float, float* %4, i64 240
  %72 = bitcast float* %71 to <16 x float>*
  %73 = load <16 x float>, <16 x float>* %72, align 64, !tbaa !875
  %74 = getelementptr inbounds float, float* %4, i64 256
  %75 = bitcast float* %74 to <16 x float>*
  %76 = load <16 x float>, <16 x float>* %75, align 64, !tbaa !875
  %77 = getelementptr inbounds float, float* %4, i64 272
  %78 = bitcast float* %77 to <16 x float>*
  %79 = load <16 x float>, <16 x float>* %78, align 64, !tbaa !875
  %80 = getelementptr inbounds float, float* %4, i64 288
  %81 = bitcast float* %80 to <16 x float>*
  %82 = load <16 x float>, <16 x float>* %81, align 64, !tbaa !875
  %83 = getelementptr inbounds float, float* %4, i64 304
  %84 = bitcast float* %83 to <16 x float>*
  %85 = load <16 x float>, <16 x float>* %84, align 64, !tbaa !875
  %86 = getelementptr inbounds float, float* %4, i64 320
  %87 = bitcast float* %86 to <16 x float>*
  %88 = load <16 x float>, <16 x float>* %87, align 64, !tbaa !875
  %89 = getelementptr inbounds float, float* %4, i64 336
  %90 = bitcast float* %89 to <16 x float>*
  %91 = load <16 x float>, <16 x float>* %90, align 64, !tbaa !875
  %92 = getelementptr inbounds float, float* %4, i64 352
  %93 = bitcast float* %92 to <16 x float>*
  %94 = load <16 x float>, <16 x float>* %93, align 64, !tbaa !875
  %95 = getelementptr inbounds float, float* %4, i64 368
  %96 = bitcast float* %95 to <16 x float>*
  %97 = load <16 x float>, <16 x float>* %96, align 64, !tbaa !875
  %98 = getelementptr inbounds float, float* %4, i64 384
  %99 = bitcast float* %98 to <16 x float>*
  %100 = load <16 x float>, <16 x float>* %99, align 64, !tbaa !875
  %101 = getelementptr inbounds float, float* %4, i64 400
  %102 = bitcast float* %101 to <16 x float>*
  %103 = load <16 x float>, <16 x float>* %102, align 64, !tbaa !875
  %104 = getelementptr inbounds float, float* %4, i64 416
  %105 = bitcast float* %104 to <16 x float>*
  %106 = load <16 x float>, <16 x float>* %105, align 64, !tbaa !875
  %107 = getelementptr inbounds float, float* %4, i64 432
  %108 = bitcast float* %107 to <16 x float>*
  %109 = load <16 x float>, <16 x float>* %108, align 64, !tbaa !875
  %110 = getelementptr inbounds float, float* %4, i64 448
  %111 = bitcast float* %110 to <16 x float>*
  %112 = load <16 x float>, <16 x float>* %111, align 64, !tbaa !875
  %113 = getelementptr inbounds float, float* %4, i64 464
  %114 = bitcast float* %113 to <16 x float>*
  %115 = load <16 x float>, <16 x float>* %114, align 64, !tbaa !875
  %116 = getelementptr inbounds float, float* %4, i64 480
  %117 = bitcast float* %116 to <16 x float>*
  %118 = load <16 x float>, <16 x float>* %117, align 64, !tbaa !875
  %119 = getelementptr inbounds float, float* %4, i64 496
  %120 = bitcast float* %119 to <16 x float>*
  %121 = load <16 x float>, <16 x float>* %120, align 64, !tbaa !875
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_begin1.preheader ]
  %122 = trunc i64 %indvars.iv to i32
  %123 = shl i32 %122, 9
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to <16 x float>*
  %127 = load <16 x float>, <16 x float>* %126, align 64, !tbaa !878
  %128 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %28, <16 x float> %127, <16 x float> zeroinitializer)
  %129 = or i64 %124, 16
  %130 = getelementptr inbounds float, float* %7, i64 %129
  %131 = bitcast float* %130 to <16 x float>*
  %132 = load <16 x float>, <16 x float>* %131, align 64, !tbaa !878
  %133 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %31, <16 x float> %132, <16 x float> %128)
  %134 = or i64 %124, 32
  %135 = getelementptr inbounds float, float* %7, i64 %134
  %136 = bitcast float* %135 to <16 x float>*
  %137 = load <16 x float>, <16 x float>* %136, align 64, !tbaa !878
  %138 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %34, <16 x float> %137, <16 x float> %133)
  %139 = or i64 %124, 48
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to <16 x float>*
  %142 = load <16 x float>, <16 x float>* %141, align 64, !tbaa !878
  %143 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %37, <16 x float> %142, <16 x float> %138)
  %144 = or i64 %124, 64
  %145 = getelementptr inbounds float, float* %7, i64 %144
  %146 = bitcast float* %145 to <16 x float>*
  %147 = load <16 x float>, <16 x float>* %146, align 64, !tbaa !878
  %148 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %40, <16 x float> %147, <16 x float> %143)
  %149 = or i64 %124, 80
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <16 x float>*
  %152 = load <16 x float>, <16 x float>* %151, align 64, !tbaa !878
  %153 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %43, <16 x float> %152, <16 x float> %148)
  %154 = or i64 %124, 96
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to <16 x float>*
  %157 = load <16 x float>, <16 x float>* %156, align 64, !tbaa !878
  %158 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %46, <16 x float> %157, <16 x float> %153)
  %159 = or i64 %124, 112
  %160 = getelementptr inbounds float, float* %7, i64 %159
  %161 = bitcast float* %160 to <16 x float>*
  %162 = load <16 x float>, <16 x float>* %161, align 64, !tbaa !878
  %163 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %49, <16 x float> %162, <16 x float> %158)
  %164 = or i64 %124, 128
  %165 = getelementptr inbounds float, float* %7, i64 %164
  %166 = bitcast float* %165 to <16 x float>*
  %167 = load <16 x float>, <16 x float>* %166, align 64, !tbaa !878
  %168 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %52, <16 x float> %167, <16 x float> %163)
  %169 = or i64 %124, 144
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to <16 x float>*
  %172 = load <16 x float>, <16 x float>* %171, align 64, !tbaa !878
  %173 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %55, <16 x float> %172, <16 x float> %168)
  %174 = or i64 %124, 160
  %175 = getelementptr inbounds float, float* %7, i64 %174
  %176 = bitcast float* %175 to <16 x float>*
  %177 = load <16 x float>, <16 x float>* %176, align 64, !tbaa !878
  %178 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %58, <16 x float> %177, <16 x float> %173)
  %179 = or i64 %124, 176
  %180 = getelementptr inbounds float, float* %7, i64 %179
  %181 = bitcast float* %180 to <16 x float>*
  %182 = load <16 x float>, <16 x float>* %181, align 64, !tbaa !878
  %183 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %61, <16 x float> %182, <16 x float> %178)
  %184 = or i64 %124, 192
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to <16 x float>*
  %187 = load <16 x float>, <16 x float>* %186, align 64, !tbaa !878
  %188 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %64, <16 x float> %187, <16 x float> %183)
  %189 = or i64 %124, 208
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to <16 x float>*
  %192 = load <16 x float>, <16 x float>* %191, align 64, !tbaa !878
  %193 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %67, <16 x float> %192, <16 x float> %188)
  %194 = or i64 %124, 224
  %195 = getelementptr inbounds float, float* %7, i64 %194
  %196 = bitcast float* %195 to <16 x float>*
  %197 = load <16 x float>, <16 x float>* %196, align 64, !tbaa !878
  %198 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %70, <16 x float> %197, <16 x float> %193)
  %199 = or i64 %124, 240
  %200 = getelementptr inbounds float, float* %7, i64 %199
  %201 = bitcast float* %200 to <16 x float>*
  %202 = load <16 x float>, <16 x float>* %201, align 64, !tbaa !878
  %203 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %73, <16 x float> %202, <16 x float> %198)
  %204 = or i64 %124, 256
  %205 = getelementptr inbounds float, float* %7, i64 %204
  %206 = bitcast float* %205 to <16 x float>*
  %207 = load <16 x float>, <16 x float>* %206, align 64, !tbaa !878
  %208 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %76, <16 x float> %207, <16 x float> %203)
  %209 = or i64 %124, 272
  %210 = getelementptr inbounds float, float* %7, i64 %209
  %211 = bitcast float* %210 to <16 x float>*
  %212 = load <16 x float>, <16 x float>* %211, align 64, !tbaa !878
  %213 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %79, <16 x float> %212, <16 x float> %208)
  %214 = or i64 %124, 288
  %215 = getelementptr inbounds float, float* %7, i64 %214
  %216 = bitcast float* %215 to <16 x float>*
  %217 = load <16 x float>, <16 x float>* %216, align 64, !tbaa !878
  %218 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %82, <16 x float> %217, <16 x float> %213)
  %219 = or i64 %124, 304
  %220 = getelementptr inbounds float, float* %7, i64 %219
  %221 = bitcast float* %220 to <16 x float>*
  %222 = load <16 x float>, <16 x float>* %221, align 64, !tbaa !878
  %223 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %85, <16 x float> %222, <16 x float> %218)
  %224 = or i64 %124, 320
  %225 = getelementptr inbounds float, float* %7, i64 %224
  %226 = bitcast float* %225 to <16 x float>*
  %227 = load <16 x float>, <16 x float>* %226, align 64, !tbaa !878
  %228 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %88, <16 x float> %227, <16 x float> %223)
  %229 = or i64 %124, 336
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to <16 x float>*
  %232 = load <16 x float>, <16 x float>* %231, align 64, !tbaa !878
  %233 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %91, <16 x float> %232, <16 x float> %228)
  %234 = or i64 %124, 352
  %235 = getelementptr inbounds float, float* %7, i64 %234
  %236 = bitcast float* %235 to <16 x float>*
  %237 = load <16 x float>, <16 x float>* %236, align 64, !tbaa !878
  %238 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %94, <16 x float> %237, <16 x float> %233)
  %239 = or i64 %124, 368
  %240 = getelementptr inbounds float, float* %7, i64 %239
  %241 = bitcast float* %240 to <16 x float>*
  %242 = load <16 x float>, <16 x float>* %241, align 64, !tbaa !878
  %243 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %97, <16 x float> %242, <16 x float> %238)
  %244 = or i64 %124, 384
  %245 = getelementptr inbounds float, float* %7, i64 %244
  %246 = bitcast float* %245 to <16 x float>*
  %247 = load <16 x float>, <16 x float>* %246, align 64, !tbaa !878
  %248 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %100, <16 x float> %247, <16 x float> %243)
  %249 = or i64 %124, 400
  %250 = getelementptr inbounds float, float* %7, i64 %249
  %251 = bitcast float* %250 to <16 x float>*
  %252 = load <16 x float>, <16 x float>* %251, align 64, !tbaa !878
  %253 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %103, <16 x float> %252, <16 x float> %248)
  %254 = or i64 %124, 416
  %255 = getelementptr inbounds float, float* %7, i64 %254
  %256 = bitcast float* %255 to <16 x float>*
  %257 = load <16 x float>, <16 x float>* %256, align 64, !tbaa !878
  %258 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %106, <16 x float> %257, <16 x float> %253)
  %259 = or i64 %124, 432
  %260 = getelementptr inbounds float, float* %7, i64 %259
  %261 = bitcast float* %260 to <16 x float>*
  %262 = load <16 x float>, <16 x float>* %261, align 64, !tbaa !878
  %263 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %109, <16 x float> %262, <16 x float> %258)
  %264 = or i64 %124, 448
  %265 = getelementptr inbounds float, float* %7, i64 %264
  %266 = bitcast float* %265 to <16 x float>*
  %267 = load <16 x float>, <16 x float>* %266, align 64, !tbaa !878
  %268 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %112, <16 x float> %267, <16 x float> %263)
  %269 = or i64 %124, 464
  %270 = getelementptr inbounds float, float* %7, i64 %269
  %271 = bitcast float* %270 to <16 x float>*
  %272 = load <16 x float>, <16 x float>* %271, align 64, !tbaa !878
  %273 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %115, <16 x float> %272, <16 x float> %268)
  %274 = or i64 %124, 480
  %275 = getelementptr inbounds float, float* %7, i64 %274
  %276 = bitcast float* %275 to <16 x float>*
  %277 = load <16 x float>, <16 x float>* %276, align 64, !tbaa !878
  %278 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %118, <16 x float> %277, <16 x float> %273)
  %279 = or i64 %124, 496
  %280 = getelementptr inbounds float, float* %7, i64 %279
  %281 = bitcast float* %280 to <16 x float>*
  %282 = load <16 x float>, <16 x float>* %281, align 64, !tbaa !878
  %283 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %121, <16 x float> %282, <16 x float> %278)
  %284 = getelementptr inbounds float, float* %10, i64 %indvars.iv
  %.0.vec.extract = extractelement <16 x float> %283, i32 0
  %285 = fadd float %.0.vec.extract, 0.000000e+00
  %.4.vec.extract = extractelement <16 x float> %283, i32 1
  %286 = fadd float %.4.vec.extract, %285
  %.8.vec.extract = extractelement <16 x float> %283, i32 2
  %287 = fadd float %.8.vec.extract, %286
  %.12.vec.extract = extractelement <16 x float> %283, i32 3
  %288 = fadd float %.12.vec.extract, %287
  %.16.vec.extract = extractelement <16 x float> %283, i32 4
  %289 = fadd float %.16.vec.extract, %288
  %.20.vec.extract = extractelement <16 x float> %283, i32 5
  %290 = fadd float %.20.vec.extract, %289
  %.24.vec.extract = extractelement <16 x float> %283, i32 6
  %291 = fadd float %.24.vec.extract, %290
  %.28.vec.extract = extractelement <16 x float> %283, i32 7
  %292 = fadd float %.28.vec.extract, %291
  %.32.vec.extract = extractelement <16 x float> %283, i32 8
  %293 = fadd float %.32.vec.extract, %292
  %.36.vec.extract = extractelement <16 x float> %283, i32 9
  %294 = fadd float %.36.vec.extract, %293
  %.40.vec.extract = extractelement <16 x float> %283, i32 10
  %295 = fadd float %.40.vec.extract, %294
  %.44.vec.extract = extractelement <16 x float> %283, i32 11
  %296 = fadd float %.44.vec.extract, %295
  %.48.vec.extract = extractelement <16 x float> %283, i32 12
  %297 = fadd float %.48.vec.extract, %296
  %.52.vec.extract = extractelement <16 x float> %283, i32 13
  %298 = fadd float %.52.vec.extract, %297
  %.56.vec.extract = extractelement <16 x float> %283, i32 14
  %299 = fadd float %.56.vec.extract, %298
  %.60.vec.extract = extractelement <16 x float> %283, i32 15
  %300 = fadd float %.60.vec.extract, %299
  store float %300, float* %284, align 4, !tbaa !867
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %301 = icmp slt i64 %indvars.iv.next, %27
  br i1 %301, label %for_begin1.preheader, label %for_end, !prof !5

for_end:                                          ; preds = %for_begin1.preheader, %entry
  ret i32 0
}

; Function Attrs: nounwind readnone speculatable
declare <16 x float> @llvm.fmuladd.v16f32(<16 x float>, <16 x float>, <16 x float>) #3

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.128, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !881
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !895
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !898
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.129, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !900
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.130, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.131, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.132, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !902
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !916
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 1
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !918
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 224
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.133, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !921
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 224
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.134, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !923
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 3
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.135, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !927
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 150528, i32 150528, i32 672, i32 3>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !939
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.136, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !943
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 2
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.137, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !957
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 1
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !959
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 7
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.138, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !962
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 7
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.139, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !964
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 3
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.140, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !968
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !970
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 4704, i32 4704, i32 672, i32 96>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !982
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !986
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([272 x i8], [272 x i8]* @.str.141, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !988
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !1002
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 2
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.142, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !1004
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !1007
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !1009
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !1013
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 64, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !1025
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([231 x i8], [231 x i8]* @.str.143, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !1029
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !1043
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 2
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.144, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !1045
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 112
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.145, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !1048
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 112
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.146, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !1050
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !1054
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 802816, i32 401408, i32 3584, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !1066
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.147, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 629292, i32 2, i32 32)
  %7 = alloca %10, align 8
  %8 = getelementptr inbounds %10, %10* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %10, %10* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %10* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.148, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %11, align 8
  %15 = getelementptr inbounds %11, %11* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %11, %11* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %11, %11* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %11, %11* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %11, %11* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %11* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.149, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.148(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 228
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 229
  %15 = select i1 %14, i32 %13, i32 229
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 229
  %18 = select i1 %17, i32 %16, i32 229
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 229
  %21 = select i1 %20, i32 %16, i32 229
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -687
  %23 = add i32 %22, -687
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv8 = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next9, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv8, 687
  %29 = trunc i64 %indvars.iv8 to i32
  %.off = add i32 %29, -3
  %30 = icmp ult i32 %.off, 224
  %31 = mul i64 %indvars.iv8, 672
  %32 = add i64 %31, 4294965271
  br i1 %30, label %for_body2.us, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %33 = mul i32 %indvar, 687
  %34 = add i32 %23, %33
  %35 = sext i32 %34 to i64
  %scevgep = getelementptr float, float* %4, i64 %35
  %scevgep6 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %scevgep6, i8 0, i64 2748, i1 false)
  br label %for_end3

for_body2.us:                                     ; preds = %for_begin1.preheader, %if_end.us
  %indvars.iv = phi i64 [ %indvars.iv.next, %if_end.us ], [ 0, %for_begin1.preheader ]
  %36 = mul nuw nsw i64 %indvars.iv, 3
  %37 = add nsw i64 %36, %28
  %38 = trunc i64 %indvars.iv to i32
  %39 = add i32 %38, -3
  %40 = icmp ult i32 %39, 224
  br i1 %40, label %if_then.us, label %if_end.us

if_then.us:                                       ; preds = %for_body2.us
  %41 = add i64 %32, %36
  %sext = shl i64 %41, 32
  %42 = ashr exact i64 %sext, 32
  %43 = getelementptr inbounds float, float* %7, i64 %42
  %44 = bitcast float* %43 to <3 x float>*
  %45 = load <3 x float>, <3 x float>* %44, align 4, !tbaa !1070
  br label %if_end.us

if_end.us:                                        ; preds = %if_then.us, %for_body2.us
  %46 = phi <3 x float> [ %45, %if_then.us ], [ zeroinitializer, %for_body2.us ]
  %47 = getelementptr inbounds float, float* %4, i64 %37
  %48 = bitcast float* %47 to <3 x float>*
  store <3 x float> %46, <3 x float>* %48, align 4, !tbaa !1073
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 229
  br i1 %exitcond, label %for_end3, label %for_body2.us, !prof !50

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %if_end.us, %for_body2.preheader
  %indvars.iv.next9 = add nsw i64 %indvars.iv8, 1
  %49 = icmp slt i64 %indvars.iv.next9, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %49, label %for_begin1.preheader, label %for_end, !prof !5
}

define private i32 @__tvm_parallel_lambda.149(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 223
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 224
  %24 = select i1 %23, i32 %22, i32 224
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 224
  %27 = select i1 %26, i32 %25, i32 224
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body, label %for_end, !prof !5

for_body:                                         ; preds = %entry, %for_end20
  %29 = phi i32 [ %350, %for_end20 ], [ %27, %entry ]
  %30 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %31 = tail call i8* %30(i32 1, i32 %16, i64 14336, i32 2, i32 32)
  %32 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %33 = tail call i8* %32(i32 1, i32 %16, i64 1024, i32 2, i32 32)
  %34 = bitcast i8* %33 to <32 x float>*
  %35 = getelementptr inbounds i8, i8* %33, i64 128
  %36 = bitcast i8* %35 to <32 x float>*
  %37 = getelementptr inbounds i8, i8* %33, i64 256
  %38 = bitcast i8* %37 to <32 x float>*
  %39 = getelementptr inbounds i8, i8* %33, i64 384
  %40 = bitcast i8* %39 to <32 x float>*
  %41 = getelementptr inbounds i8, i8* %33, i64 512
  %42 = bitcast i8* %41 to <32 x float>*
  %43 = getelementptr inbounds i8, i8* %33, i64 640
  %44 = bitcast i8* %43 to <32 x float>*
  %45 = getelementptr inbounds i8, i8* %33, i64 768
  %46 = bitcast i8* %45 to <32 x float>*
  %47 = getelementptr inbounds i8, i8* %33, i64 896
  %48 = bitcast i8* %47 to <32 x float>*
  %49 = srem i32 %29, 112
  %50 = mul nsw i32 %49, 1374
  %51 = sdiv i32 %29, 112
  %52 = mul nsw i32 %51, 4704
  %53 = bitcast i8* %31 to float*
  %54 = sext i32 %52 to i64
  %55 = sext i32 %50 to i64
  br label %for_body4

for_end:                                          ; preds = %for_end20, %entry
  ret i32 0

for_begin18.preheader:                            ; preds = %for_begin15.preheader
  %56 = mul nsw i32 %29, 3584
  %57 = shl nsw i32 %51, 5
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds float, float* %13, i64 %58
  %60 = bitcast float* %59 to <32 x float>*
  %61 = load <32 x float>, <32 x float>* %60, align 64, !tbaa !1076
  br label %for_begin21.preheader

for_body4:                                        ; preds = %for_begin15.preheader, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_begin15.preheader ]
  %62 = mul nuw nsw i64 %indvar, 48
  %63 = add nsw i64 %62, %55
  call void @llvm.memset.p0i8.i64(i8* align 64 %33, i8 0, i64 1024, i1 false)
  br label %for_begin9.preheader

for_begin15.preheader:                            ; preds = %for_end11
  store <32 x float> %207, <32 x float>* %34, align 64, !tbaa !1079
  store <32 x float> %213, <32 x float>* %36, align 64, !tbaa !1079
  store <32 x float> %219, <32 x float>* %38, align 64, !tbaa !1079
  store <32 x float> %225, <32 x float>* %40, align 64, !tbaa !1079
  store <32 x float> %231, <32 x float>* %42, align 64, !tbaa !1079
  store <32 x float> %237, <32 x float>* %44, align 64, !tbaa !1079
  store <32 x float> %243, <32 x float>* %46, align 64, !tbaa !1079
  store <32 x float> %249, <32 x float>* %48, align 64, !tbaa !1079
  %64 = shl i64 %indvar, 8
  %65 = getelementptr inbounds float, float* %53, i64 %64
  %66 = bitcast float* %65 to <32 x float>*
  store <32 x float> %207, <32 x float>* %66, align 64, !tbaa !1088
  %67 = or i64 %64, 32
  %68 = getelementptr inbounds float, float* %53, i64 %67
  %69 = bitcast float* %68 to <32 x float>*
  store <32 x float> %213, <32 x float>* %69, align 64, !tbaa !1088
  %70 = or i64 %64, 64
  %71 = getelementptr inbounds float, float* %53, i64 %70
  %72 = bitcast float* %71 to <32 x float>*
  store <32 x float> %219, <32 x float>* %72, align 64, !tbaa !1088
  %73 = or i64 %64, 96
  %74 = getelementptr inbounds float, float* %53, i64 %73
  %75 = bitcast float* %74 to <32 x float>*
  store <32 x float> %225, <32 x float>* %75, align 64, !tbaa !1088
  %76 = or i64 %64, 128
  %77 = getelementptr inbounds float, float* %53, i64 %76
  %78 = bitcast float* %77 to <32 x float>*
  store <32 x float> %231, <32 x float>* %78, align 64, !tbaa !1088
  %79 = or i64 %64, 160
  %80 = getelementptr inbounds float, float* %53, i64 %79
  %81 = bitcast float* %80 to <32 x float>*
  store <32 x float> %237, <32 x float>* %81, align 64, !tbaa !1088
  %82 = or i64 %64, 192
  %83 = getelementptr inbounds float, float* %53, i64 %82
  %84 = bitcast float* %83 to <32 x float>*
  store <32 x float> %243, <32 x float>* %84, align 64, !tbaa !1088
  %85 = or i64 %64, 224
  %86 = getelementptr inbounds float, float* %53, i64 %85
  %87 = bitcast float* %86 to <32 x float>*
  store <32 x float> %249, <32 x float>* %87, align 64, !tbaa !1088
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond89 = icmp eq i64 %indvar.next, 14
  br i1 %exitcond89, label %for_begin18.preheader, label %for_body4, !prof !50

for_begin9.preheader:                             ; preds = %for_end11, %for_body4
  %indvars.iv83 = phi i64 [ 0, %for_body4 ], [ %indvars.iv.next84, %for_end11 ]
  %.lcssa45.lcssa75 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %249, %for_end11 ]
  %.lcssa43.lcssa73 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %243, %for_end11 ]
  %.lcssa41.lcssa71 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %237, %for_end11 ]
  %.lcssa39.lcssa69 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %231, %for_end11 ]
  %.lcssa37.lcssa67 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %225, %for_end11 ]
  %.lcssa35.lcssa65 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %219, %for_end11 ]
  %.lcssa33.lcssa64 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %213, %for_end11 ]
  %.lcssa.lcssa62 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %207, %for_end11 ]
  %88 = mul nuw nsw i64 %indvars.iv83, 687
  %89 = add nsw i64 %63, %88
  %90 = mul nuw nsw i64 %indvars.iv83, 672
  %91 = add nsw i64 %90, %54
  br label %for_begin12.preheader

for_begin12.preheader:                            ; preds = %for_begin12.preheader, %for_begin9.preheader
  %indvars.iv = phi i64 [ 0, %for_begin9.preheader ], [ %indvars.iv.next, %for_begin12.preheader ]
  %.lcssa4560 = phi <32 x float> [ %.lcssa45.lcssa75, %for_begin9.preheader ], [ %249, %for_begin12.preheader ]
  %.lcssa4358 = phi <32 x float> [ %.lcssa43.lcssa73, %for_begin9.preheader ], [ %243, %for_begin12.preheader ]
  %.lcssa4156 = phi <32 x float> [ %.lcssa41.lcssa71, %for_begin9.preheader ], [ %237, %for_begin12.preheader ]
  %.lcssa3954 = phi <32 x float> [ %.lcssa39.lcssa69, %for_begin9.preheader ], [ %231, %for_begin12.preheader ]
  %.lcssa3752 = phi <32 x float> [ %.lcssa37.lcssa67, %for_begin9.preheader ], [ %225, %for_begin12.preheader ]
  %.lcssa3550 = phi <32 x float> [ %.lcssa35.lcssa65, %for_begin9.preheader ], [ %219, %for_begin12.preheader ]
  %.lcssa3348 = phi <32 x float> [ %.lcssa33.lcssa64, %for_begin9.preheader ], [ %213, %for_begin12.preheader ]
  %.lcssa47 = phi <32 x float> [ %.lcssa.lcssa62, %for_begin9.preheader ], [ %207, %for_begin12.preheader ]
  %92 = mul nuw nsw i64 %indvars.iv, 3
  %93 = add nsw i64 %89, %92
  %94 = mul nuw nsw i64 %indvars.iv, 96
  %95 = add nsw i64 %91, %94
  %96 = getelementptr inbounds float, float* %4, i64 %93
  %97 = load float, float* %96, align 4, !tbaa !1073
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = getelementptr inbounds float, float* %7, i64 %95
  %101 = bitcast float* %100 to <32 x float>*
  %102 = load <32 x float>, <32 x float>* %101, align 64, !tbaa !1091
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %102, <32 x float> %.lcssa47)
  %104 = add nsw i64 %93, 6
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !1073
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %102, <32 x float> %.lcssa3348)
  %110 = add nsw i64 %93, 12
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !1073
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %102, <32 x float> %.lcssa3550)
  %116 = add nsw i64 %93, 18
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !1073
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %102, <32 x float> %.lcssa3752)
  %122 = add nsw i64 %93, 24
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !1073
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %102, <32 x float> %.lcssa3954)
  %128 = add nsw i64 %93, 30
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = load float, float* %129, align 4, !tbaa !1073
  %131 = insertelement <32 x float> undef, float %130, i32 0
  %132 = shufflevector <32 x float> %131, <32 x float> undef, <32 x i32> zeroinitializer
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %132, <32 x float> %102, <32 x float> %.lcssa4156)
  %134 = add nsw i64 %93, 36
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !1073
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %102, <32 x float> %.lcssa4358)
  %140 = add nsw i64 %93, 42
  %141 = getelementptr inbounds float, float* %4, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !1073
  %143 = insertelement <32 x float> undef, float %142, i32 0
  %144 = shufflevector <32 x float> %143, <32 x float> undef, <32 x i32> zeroinitializer
  %145 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %144, <32 x float> %102, <32 x float> %.lcssa4560)
  %146 = add nsw i64 %93, 1
  %147 = getelementptr inbounds float, float* %4, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !1073
  %149 = insertelement <32 x float> undef, float %148, i32 0
  %150 = shufflevector <32 x float> %149, <32 x float> undef, <32 x i32> zeroinitializer
  %151 = add nsw i64 %95, 32
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = bitcast float* %152 to <32 x float>*
  %154 = load <32 x float>, <32 x float>* %153, align 64, !tbaa !1091
  %155 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %150, <32 x float> %154, <32 x float> %103)
  %156 = add nsw i64 %93, 7
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !1073
  %159 = insertelement <32 x float> undef, float %158, i32 0
  %160 = shufflevector <32 x float> %159, <32 x float> undef, <32 x i32> zeroinitializer
  %161 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %160, <32 x float> %154, <32 x float> %109)
  %162 = add nsw i64 %93, 13
  %163 = getelementptr inbounds float, float* %4, i64 %162
  %164 = load float, float* %163, align 4, !tbaa !1073
  %165 = insertelement <32 x float> undef, float %164, i32 0
  %166 = shufflevector <32 x float> %165, <32 x float> undef, <32 x i32> zeroinitializer
  %167 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %166, <32 x float> %154, <32 x float> %115)
  %168 = add nsw i64 %93, 19
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = load float, float* %169, align 4, !tbaa !1073
  %171 = insertelement <32 x float> undef, float %170, i32 0
  %172 = shufflevector <32 x float> %171, <32 x float> undef, <32 x i32> zeroinitializer
  %173 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %172, <32 x float> %154, <32 x float> %121)
  %174 = add nsw i64 %93, 25
  %175 = getelementptr inbounds float, float* %4, i64 %174
  %176 = load float, float* %175, align 4, !tbaa !1073
  %177 = insertelement <32 x float> undef, float %176, i32 0
  %178 = shufflevector <32 x float> %177, <32 x float> undef, <32 x i32> zeroinitializer
  %179 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %178, <32 x float> %154, <32 x float> %127)
  %180 = add nsw i64 %93, 31
  %181 = getelementptr inbounds float, float* %4, i64 %180
  %182 = load float, float* %181, align 4, !tbaa !1073
  %183 = insertelement <32 x float> undef, float %182, i32 0
  %184 = shufflevector <32 x float> %183, <32 x float> undef, <32 x i32> zeroinitializer
  %185 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %184, <32 x float> %154, <32 x float> %133)
  %186 = add nsw i64 %93, 37
  %187 = getelementptr inbounds float, float* %4, i64 %186
  %188 = load float, float* %187, align 4, !tbaa !1073
  %189 = insertelement <32 x float> undef, float %188, i32 0
  %190 = shufflevector <32 x float> %189, <32 x float> undef, <32 x i32> zeroinitializer
  %191 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %190, <32 x float> %154, <32 x float> %139)
  %192 = add nsw i64 %93, 43
  %193 = getelementptr inbounds float, float* %4, i64 %192
  %194 = load float, float* %193, align 4, !tbaa !1073
  %195 = insertelement <32 x float> undef, float %194, i32 0
  %196 = shufflevector <32 x float> %195, <32 x float> undef, <32 x i32> zeroinitializer
  %197 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %196, <32 x float> %154, <32 x float> %145)
  %198 = add nsw i64 %93, 2
  %199 = getelementptr inbounds float, float* %4, i64 %198
  %200 = load float, float* %199, align 4, !tbaa !1073
  %201 = insertelement <32 x float> undef, float %200, i32 0
  %202 = shufflevector <32 x float> %201, <32 x float> undef, <32 x i32> zeroinitializer
  %203 = add nsw i64 %95, 64
  %204 = getelementptr inbounds float, float* %7, i64 %203
  %205 = bitcast float* %204 to <32 x float>*
  %206 = load <32 x float>, <32 x float>* %205, align 64, !tbaa !1091
  %207 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %202, <32 x float> %206, <32 x float> %155)
  %208 = add nsw i64 %93, 8
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !1073
  %211 = insertelement <32 x float> undef, float %210, i32 0
  %212 = shufflevector <32 x float> %211, <32 x float> undef, <32 x i32> zeroinitializer
  %213 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %212, <32 x float> %206, <32 x float> %161)
  %214 = add nsw i64 %93, 14
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !1073
  %217 = insertelement <32 x float> undef, float %216, i32 0
  %218 = shufflevector <32 x float> %217, <32 x float> undef, <32 x i32> zeroinitializer
  %219 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %206, <32 x float> %167)
  %220 = add nsw i64 %93, 20
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !1073
  %223 = insertelement <32 x float> undef, float %222, i32 0
  %224 = shufflevector <32 x float> %223, <32 x float> undef, <32 x i32> zeroinitializer
  %225 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %224, <32 x float> %206, <32 x float> %173)
  %226 = add nsw i64 %93, 26
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = load float, float* %227, align 4, !tbaa !1073
  %229 = insertelement <32 x float> undef, float %228, i32 0
  %230 = shufflevector <32 x float> %229, <32 x float> undef, <32 x i32> zeroinitializer
  %231 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %230, <32 x float> %206, <32 x float> %179)
  %232 = add nsw i64 %93, 32
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !1073
  %235 = insertelement <32 x float> undef, float %234, i32 0
  %236 = shufflevector <32 x float> %235, <32 x float> undef, <32 x i32> zeroinitializer
  %237 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %236, <32 x float> %206, <32 x float> %185)
  %238 = add nsw i64 %93, 38
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !1073
  %241 = insertelement <32 x float> undef, float %240, i32 0
  %242 = shufflevector <32 x float> %241, <32 x float> undef, <32 x i32> zeroinitializer
  %243 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %206, <32 x float> %191)
  %244 = add nsw i64 %93, 44
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !1073
  %247 = insertelement <32 x float> undef, float %246, i32 0
  %248 = shufflevector <32 x float> %247, <32 x float> undef, <32 x i32> zeroinitializer
  %249 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %206, <32 x float> %197)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 7
  br i1 %exitcond, label %for_end11, label %for_begin12.preheader, !prof !50

for_end11:                                        ; preds = %for_begin12.preheader
  %indvars.iv.next84 = add nuw nsw i64 %indvars.iv83, 1
  %exitcond85 = icmp eq i64 %indvars.iv.next84, 7
  br i1 %exitcond85, label %for_begin15.preheader, label %for_begin9.preheader, !prof !50

for_begin21.preheader:                            ; preds = %for_begin21.preheader, %for_begin18.preheader
  %indvars.iv93 = phi i64 [ 0, %for_begin18.preheader ], [ %indvars.iv.next94, %for_begin21.preheader ]
  %250 = shl nsw i64 %indvars.iv93, 8
  %251 = trunc i64 %250 to i32
  %252 = add i32 %56, %251
  %253 = getelementptr inbounds float, float* %53, i64 %250
  %254 = bitcast float* %253 to <32 x float>*
  %255 = load <32 x float>, <32 x float>* %254, align 64, !tbaa !1088
  %256 = fadd <32 x float> %61, %255
  %257 = fcmp ogt <32 x float> %256, zeroinitializer
  %258 = select <32 x i1> %257, <32 x float> %256, <32 x float> zeroinitializer
  %259 = sext i32 %252 to i64
  %260 = getelementptr inbounds float, float* %10, i64 %259
  %261 = bitcast float* %260 to <32 x float>*
  store <32 x float> %258, <32 x float>* %261, align 64, !tbaa !1094
  %262 = or i64 %250, 32
  %263 = trunc i64 %262 to i32
  %264 = add i32 %56, %263
  %265 = getelementptr inbounds float, float* %53, i64 %262
  %266 = bitcast float* %265 to <32 x float>*
  %267 = load <32 x float>, <32 x float>* %266, align 64, !tbaa !1088
  %268 = fadd <32 x float> %61, %267
  %269 = fcmp ogt <32 x float> %268, zeroinitializer
  %270 = select <32 x i1> %269, <32 x float> %268, <32 x float> zeroinitializer
  %271 = sext i32 %264 to i64
  %272 = getelementptr inbounds float, float* %10, i64 %271
  %273 = bitcast float* %272 to <32 x float>*
  store <32 x float> %270, <32 x float>* %273, align 64, !tbaa !1094
  %274 = or i64 %250, 64
  %275 = trunc i64 %274 to i32
  %276 = add i32 %56, %275
  %277 = getelementptr inbounds float, float* %53, i64 %274
  %278 = bitcast float* %277 to <32 x float>*
  %279 = load <32 x float>, <32 x float>* %278, align 64, !tbaa !1088
  %280 = fadd <32 x float> %61, %279
  %281 = fcmp ogt <32 x float> %280, zeroinitializer
  %282 = select <32 x i1> %281, <32 x float> %280, <32 x float> zeroinitializer
  %283 = sext i32 %276 to i64
  %284 = getelementptr inbounds float, float* %10, i64 %283
  %285 = bitcast float* %284 to <32 x float>*
  store <32 x float> %282, <32 x float>* %285, align 64, !tbaa !1094
  %286 = or i64 %250, 96
  %287 = trunc i64 %286 to i32
  %288 = add i32 %56, %287
  %289 = getelementptr inbounds float, float* %53, i64 %286
  %290 = bitcast float* %289 to <32 x float>*
  %291 = load <32 x float>, <32 x float>* %290, align 64, !tbaa !1088
  %292 = fadd <32 x float> %61, %291
  %293 = fcmp ogt <32 x float> %292, zeroinitializer
  %294 = select <32 x i1> %293, <32 x float> %292, <32 x float> zeroinitializer
  %295 = sext i32 %288 to i64
  %296 = getelementptr inbounds float, float* %10, i64 %295
  %297 = bitcast float* %296 to <32 x float>*
  store <32 x float> %294, <32 x float>* %297, align 64, !tbaa !1094
  %298 = or i64 %250, 128
  %299 = trunc i64 %298 to i32
  %300 = add i32 %56, %299
  %301 = getelementptr inbounds float, float* %53, i64 %298
  %302 = bitcast float* %301 to <32 x float>*
  %303 = load <32 x float>, <32 x float>* %302, align 64, !tbaa !1088
  %304 = fadd <32 x float> %61, %303
  %305 = fcmp ogt <32 x float> %304, zeroinitializer
  %306 = select <32 x i1> %305, <32 x float> %304, <32 x float> zeroinitializer
  %307 = sext i32 %300 to i64
  %308 = getelementptr inbounds float, float* %10, i64 %307
  %309 = bitcast float* %308 to <32 x float>*
  store <32 x float> %306, <32 x float>* %309, align 64, !tbaa !1094
  %310 = or i64 %250, 160
  %311 = trunc i64 %310 to i32
  %312 = add i32 %56, %311
  %313 = getelementptr inbounds float, float* %53, i64 %310
  %314 = bitcast float* %313 to <32 x float>*
  %315 = load <32 x float>, <32 x float>* %314, align 64, !tbaa !1088
  %316 = fadd <32 x float> %61, %315
  %317 = fcmp ogt <32 x float> %316, zeroinitializer
  %318 = select <32 x i1> %317, <32 x float> %316, <32 x float> zeroinitializer
  %319 = sext i32 %312 to i64
  %320 = getelementptr inbounds float, float* %10, i64 %319
  %321 = bitcast float* %320 to <32 x float>*
  store <32 x float> %318, <32 x float>* %321, align 64, !tbaa !1094
  %322 = or i64 %250, 192
  %323 = trunc i64 %322 to i32
  %324 = add i32 %56, %323
  %325 = getelementptr inbounds float, float* %53, i64 %322
  %326 = bitcast float* %325 to <32 x float>*
  %327 = load <32 x float>, <32 x float>* %326, align 64, !tbaa !1088
  %328 = fadd <32 x float> %61, %327
  %329 = fcmp ogt <32 x float> %328, zeroinitializer
  %330 = select <32 x i1> %329, <32 x float> %328, <32 x float> zeroinitializer
  %331 = sext i32 %324 to i64
  %332 = getelementptr inbounds float, float* %10, i64 %331
  %333 = bitcast float* %332 to <32 x float>*
  store <32 x float> %330, <32 x float>* %333, align 64, !tbaa !1094
  %334 = or i64 %250, 224
  %335 = trunc i64 %334 to i32
  %336 = add i32 %56, %335
  %337 = getelementptr inbounds float, float* %53, i64 %334
  %338 = bitcast float* %337 to <32 x float>*
  %339 = load <32 x float>, <32 x float>* %338, align 64, !tbaa !1088
  %340 = fadd <32 x float> %61, %339
  %341 = fcmp ogt <32 x float> %340, zeroinitializer
  %342 = select <32 x i1> %341, <32 x float> %340, <32 x float> zeroinitializer
  %343 = sext i32 %336 to i64
  %344 = getelementptr inbounds float, float* %10, i64 %343
  %345 = bitcast float* %344 to <32 x float>*
  store <32 x float> %342, <32 x float>* %345, align 64, !tbaa !1094
  %indvars.iv.next94 = add nuw nsw i64 %indvars.iv93, 1
  %exitcond95 = icmp eq i64 %indvars.iv.next94, 14
  br i1 %exitcond95, label %for_end20, label %for_begin21.preheader, !prof !50

for_end20:                                        ; preds = %for_begin21.preheader
  %346 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %347 = tail call i32 %346(i32 1, i32 %16, i8* %33)
  %348 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %349 = tail call i32 %348(i32 1, i32 %16, i8* nonnull %31)
  %350 = add nsw i32 %29, 1
  %351 = icmp slt i32 %350, %24
  br i1 %351, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.150, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !1097
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !1111
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !1114
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.151, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !1116
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.152, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.153, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.154, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !1118
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !1132
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 32
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.155, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !1134
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 14
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !1137
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 14
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !1139
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 8
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.156, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !1143
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 50176, i32 1568, i32 112, i32 8>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !1155
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([236 x i8], [236 x i8]* @.str.157, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !1159
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 16
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !1173
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 32
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.158, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !1175
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 3
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !1178
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 3
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !1180
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 8
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !1184
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !1186
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 73728, i32 2304, i32 768, i32 256>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !1198
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !1202
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([274 x i8], [274 x i8]* @.str.160, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !1204
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !1218
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 16
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !1220
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !1223
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !1225
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !1229
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 512, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !1241
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.101, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !1245
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !1259
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 16
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !1261
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 7
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !1264
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 7
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.104, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !1266
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !1270
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 25088, i32 1568, i32 224, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !1282
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.105, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 230400, i32 2, i32 32)
  %7 = alloca %12, align 8
  %8 = getelementptr inbounds %12, %12* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %12, %12* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %12* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.161, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %21, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %13, align 8
  %15 = getelementptr inbounds %13, %13* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %13, %13* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %13, %13* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %13, %13* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = bitcast %13* %14 to i8*
  %20 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %21 = call i32 %20(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.162, i8* nonnull %19, i32 0)
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %23 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %24 = call i32 %23(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.161(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 479
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 480
  %15 = select i1 %14, i32 %13, i32 480
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 480
  %18 = select i1 %17, i32 %16, i32 480
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 480
  %21 = select i1 %20, i32 %16, i32 480
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -120
  %23 = add i32 %22, -120
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv, 120
  %29 = trunc i64 %indvars.iv to i32
  %30 = srem i32 %29, 15
  %31 = icmp sgt i32 %30, 0
  %32 = mul nsw i32 %30, 112
  %33 = sdiv i32 %29, 15
  %34 = mul nsw i32 %33, 1568
  %35 = add nsw i32 %32, -120
  %36 = add i32 %35, %34
  br i1 %31, label %if_end.us.14, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %37 = mul i32 %indvar, 120
  %38 = add i32 %23, %37
  %39 = sext i32 %38 to i64
  %scevgep = getelementptr float, float* %4, i64 %39
  %scevgep6 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 32 %scevgep6, i8 0, i64 480, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_body2.preheader, %if_end.us.14
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %40 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %40, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.14:                                     ; preds = %for_begin1.preheader
  %41 = getelementptr inbounds float, float* %4, i64 %28
  %42 = bitcast float* %41 to <8 x float>*
  store <8 x float> zeroinitializer, <8 x float>* %42, align 32, !tbaa !1286
  %43 = add nsw i64 %28, 8
  %44 = add i32 %36, 8
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = bitcast float* %46 to <8 x float>*
  %48 = load <8 x float>, <8 x float>* %47, align 32, !tbaa !1289
  %49 = getelementptr inbounds float, float* %4, i64 %43
  %50 = bitcast float* %49 to <8 x float>*
  store <8 x float> %48, <8 x float>* %50, align 32, !tbaa !1286
  %51 = add nsw i64 %28, 16
  %52 = add i32 %36, 16
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <8 x float>*
  %56 = load <8 x float>, <8 x float>* %55, align 32, !tbaa !1289
  %57 = getelementptr inbounds float, float* %4, i64 %51
  %58 = bitcast float* %57 to <8 x float>*
  store <8 x float> %56, <8 x float>* %58, align 32, !tbaa !1286
  %59 = add nsw i64 %28, 24
  %60 = add i32 %36, 24
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds float, float* %7, i64 %61
  %63 = bitcast float* %62 to <8 x float>*
  %64 = load <8 x float>, <8 x float>* %63, align 32, !tbaa !1289
  %65 = getelementptr inbounds float, float* %4, i64 %59
  %66 = bitcast float* %65 to <8 x float>*
  store <8 x float> %64, <8 x float>* %66, align 32, !tbaa !1286
  %67 = add nsw i64 %28, 32
  %68 = add i32 %36, 32
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to <8 x float>*
  %72 = load <8 x float>, <8 x float>* %71, align 32, !tbaa !1289
  %73 = getelementptr inbounds float, float* %4, i64 %67
  %74 = bitcast float* %73 to <8 x float>*
  store <8 x float> %72, <8 x float>* %74, align 32, !tbaa !1286
  %75 = add nsw i64 %28, 40
  %76 = add i32 %36, 40
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds float, float* %7, i64 %77
  %79 = bitcast float* %78 to <8 x float>*
  %80 = load <8 x float>, <8 x float>* %79, align 32, !tbaa !1289
  %81 = getelementptr inbounds float, float* %4, i64 %75
  %82 = bitcast float* %81 to <8 x float>*
  store <8 x float> %80, <8 x float>* %82, align 32, !tbaa !1286
  %83 = add nsw i64 %28, 48
  %84 = add i32 %36, 48
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds float, float* %7, i64 %85
  %87 = bitcast float* %86 to <8 x float>*
  %88 = load <8 x float>, <8 x float>* %87, align 32, !tbaa !1289
  %89 = getelementptr inbounds float, float* %4, i64 %83
  %90 = bitcast float* %89 to <8 x float>*
  store <8 x float> %88, <8 x float>* %90, align 32, !tbaa !1286
  %91 = add nsw i64 %28, 56
  %92 = add i32 %36, 56
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = bitcast float* %94 to <8 x float>*
  %96 = load <8 x float>, <8 x float>* %95, align 32, !tbaa !1289
  %97 = getelementptr inbounds float, float* %4, i64 %91
  %98 = bitcast float* %97 to <8 x float>*
  store <8 x float> %96, <8 x float>* %98, align 32, !tbaa !1286
  %99 = add nsw i64 %28, 64
  %100 = add i32 %36, 64
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = bitcast float* %102 to <8 x float>*
  %104 = load <8 x float>, <8 x float>* %103, align 32, !tbaa !1289
  %105 = getelementptr inbounds float, float* %4, i64 %99
  %106 = bitcast float* %105 to <8 x float>*
  store <8 x float> %104, <8 x float>* %106, align 32, !tbaa !1286
  %107 = add nsw i64 %28, 72
  %108 = add i32 %36, 72
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to <8 x float>*
  %112 = load <8 x float>, <8 x float>* %111, align 32, !tbaa !1289
  %113 = getelementptr inbounds float, float* %4, i64 %107
  %114 = bitcast float* %113 to <8 x float>*
  store <8 x float> %112, <8 x float>* %114, align 32, !tbaa !1286
  %115 = add nsw i64 %28, 80
  %116 = add i32 %36, 80
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %7, i64 %117
  %119 = bitcast float* %118 to <8 x float>*
  %120 = load <8 x float>, <8 x float>* %119, align 32, !tbaa !1289
  %121 = getelementptr inbounds float, float* %4, i64 %115
  %122 = bitcast float* %121 to <8 x float>*
  store <8 x float> %120, <8 x float>* %122, align 32, !tbaa !1286
  %123 = add nsw i64 %28, 88
  %124 = add i32 %36, 88
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = bitcast float* %126 to <8 x float>*
  %128 = load <8 x float>, <8 x float>* %127, align 32, !tbaa !1289
  %129 = getelementptr inbounds float, float* %4, i64 %123
  %130 = bitcast float* %129 to <8 x float>*
  store <8 x float> %128, <8 x float>* %130, align 32, !tbaa !1286
  %131 = add nsw i64 %28, 96
  %132 = add i32 %36, 96
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds float, float* %7, i64 %133
  %135 = bitcast float* %134 to <8 x float>*
  %136 = load <8 x float>, <8 x float>* %135, align 32, !tbaa !1289
  %137 = getelementptr inbounds float, float* %4, i64 %131
  %138 = bitcast float* %137 to <8 x float>*
  store <8 x float> %136, <8 x float>* %138, align 32, !tbaa !1286
  %139 = add nsw i64 %28, 104
  %140 = add i32 %36, 104
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to <8 x float>*
  %144 = load <8 x float>, <8 x float>* %143, align 32, !tbaa !1289
  %145 = getelementptr inbounds float, float* %4, i64 %139
  %146 = bitcast float* %145 to <8 x float>*
  store <8 x float> %144, <8 x float>* %146, align 32, !tbaa !1286
  %147 = add nsw i64 %28, 112
  %148 = add i32 %36, 112
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <8 x float>*
  %152 = load <8 x float>, <8 x float>* %151, align 32, !tbaa !1289
  %153 = getelementptr inbounds float, float* %4, i64 %147
  %154 = bitcast float* %153 to <8 x float>*
  store <8 x float> %152, <8 x float>* %154, align 32, !tbaa !1286
  br label %for_end3
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.162(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 111
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 112
  %21 = select i1 %20, i32 %19, i32 112
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin10.preheader
  %indvars.iv66 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next67, %for_begin10.preheader ]
  %30 = trunc i64 %indvars.iv66 to i32
  %31 = srem i32 %30, 7
  %32 = mul nsw i32 %31, 240
  %33 = sdiv i32 %30, 7
  %34 = mul nsw i32 %33, 73728
  %35 = sext i32 %34 to i64
  %36 = sext i32 %32 to i64
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_begin10.preheader, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end9.2
  %37 = mul nsw i64 %indvars.iv66, 224
  %38 = shl nsw i32 %33, 5
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %13, i64 %39
  %41 = bitcast float* %40 to <32 x float>*
  %42 = load <32 x float>, <32 x float>* %41, align 64, !tbaa !1292
  %43 = fadd <32 x float> %42, %429
  %44 = fcmp ogt <32 x float> %43, zeroinitializer
  %45 = select <32 x i1> %44, <32 x float> %43, <32 x float> zeroinitializer
  %46 = getelementptr inbounds float, float* %10, i64 %37
  %47 = bitcast float* %46 to <32 x float>*
  store <32 x float> %45, <32 x float>* %47, align 64, !tbaa !1295
  %48 = add nsw i64 %37, 32
  %49 = fadd <32 x float> %42, %430
  %50 = fcmp ogt <32 x float> %49, zeroinitializer
  %51 = select <32 x i1> %50, <32 x float> %49, <32 x float> zeroinitializer
  %52 = getelementptr inbounds float, float* %10, i64 %48
  %53 = bitcast float* %52 to <32 x float>*
  store <32 x float> %51, <32 x float>* %53, align 64, !tbaa !1295
  %54 = add nsw i64 %37, 64
  %55 = fadd <32 x float> %42, %431
  %56 = fcmp ogt <32 x float> %55, zeroinitializer
  %57 = select <32 x i1> %56, <32 x float> %55, <32 x float> zeroinitializer
  %58 = getelementptr inbounds float, float* %10, i64 %54
  %59 = bitcast float* %58 to <32 x float>*
  store <32 x float> %57, <32 x float>* %59, align 64, !tbaa !1295
  %60 = add nsw i64 %37, 96
  %61 = fadd <32 x float> %42, %432
  %62 = fcmp ogt <32 x float> %61, zeroinitializer
  %63 = select <32 x i1> %62, <32 x float> %61, <32 x float> zeroinitializer
  %64 = getelementptr inbounds float, float* %10, i64 %60
  %65 = bitcast float* %64 to <32 x float>*
  store <32 x float> %63, <32 x float>* %65, align 64, !tbaa !1295
  %66 = add nsw i64 %37, 128
  %67 = fadd <32 x float> %42, %433
  %68 = fcmp ogt <32 x float> %67, zeroinitializer
  %69 = select <32 x i1> %68, <32 x float> %67, <32 x float> zeroinitializer
  %70 = getelementptr inbounds float, float* %10, i64 %66
  %71 = bitcast float* %70 to <32 x float>*
  store <32 x float> %69, <32 x float>* %71, align 64, !tbaa !1295
  %72 = add nsw i64 %37, 160
  %73 = fadd <32 x float> %42, %434
  %74 = fcmp ogt <32 x float> %73, zeroinitializer
  %75 = select <32 x i1> %74, <32 x float> %73, <32 x float> zeroinitializer
  %76 = getelementptr inbounds float, float* %10, i64 %72
  %77 = bitcast float* %76 to <32 x float>*
  store <32 x float> %75, <32 x float>* %77, align 64, !tbaa !1295
  %78 = add nsw i64 %37, 192
  %79 = fadd <32 x float> %42, %440
  %80 = fcmp ogt <32 x float> %79, zeroinitializer
  %81 = select <32 x i1> %80, <32 x float> %79, <32 x float> zeroinitializer
  %82 = getelementptr inbounds float, float* %10, i64 %78
  %83 = bitcast float* %82 to <32 x float>*
  store <32 x float> %81, <32 x float>* %83, align 64, !tbaa !1295
  %indvars.iv.next67 = add nsw i64 %indvars.iv66, 1
  %84 = icmp slt i64 %indvars.iv.next67, %29
  br i1 %84, label %for_body, label %for_end, !prof !5

for_begin4.preheader:                             ; preds = %for_end9.2, %for_body
  %indvars.iv60 = phi i64 [ 0, %for_body ], [ %indvars.iv.next61, %for_end9.2 ]
  %.lcssa25.lcssa50 = phi <32 x float> [ zeroinitializer, %for_body ], [ %440, %for_end9.2 ]
  %.lcssa23.lcssa48 = phi <32 x float> [ zeroinitializer, %for_body ], [ %434, %for_end9.2 ]
  %.lcssa21.lcssa46 = phi <32 x float> [ zeroinitializer, %for_body ], [ %433, %for_end9.2 ]
  %.lcssa19.lcssa44 = phi <32 x float> [ zeroinitializer, %for_body ], [ %432, %for_end9.2 ]
  %.lcssa17.lcssa43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %431, %for_end9.2 ]
  %.lcssa15.lcssa41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %430, %for_end9.2 ]
  %.lcssa.lcssa39 = phi <32 x float> [ zeroinitializer, %for_body ], [ %429, %for_end9.2 ]
  %85 = mul nuw nsw i64 %indvars.iv60, 1800
  %86 = add nsw i64 %85, %36
  %87 = mul nuw nsw i64 %indvars.iv60, 2304
  %88 = add nsw i64 %87, %35
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body8 ]
  %89 = phi <32 x float> [ %.lcssa25.lcssa50, %for_begin4.preheader ], [ %204, %for_body8 ]
  %90 = phi <32 x float> [ %.lcssa23.lcssa48, %for_begin4.preheader ], [ %198, %for_body8 ]
  %91 = phi <32 x float> [ %.lcssa21.lcssa46, %for_begin4.preheader ], [ %197, %for_body8 ]
  %92 = phi <32 x float> [ %.lcssa19.lcssa44, %for_begin4.preheader ], [ %196, %for_body8 ]
  %93 = phi <32 x float> [ %.lcssa17.lcssa43, %for_begin4.preheader ], [ %195, %for_body8 ]
  %94 = phi <32 x float> [ %.lcssa15.lcssa41, %for_begin4.preheader ], [ %194, %for_body8 ]
  %95 = phi <32 x float> [ %.lcssa.lcssa39, %for_begin4.preheader ], [ %193, %for_body8 ]
  %96 = add nsw i64 %86, %indvars.iv
  %97 = getelementptr inbounds float, float* %4, i64 %96
  %98 = load float, float* %97, align 4, !tbaa !1286
  %99 = insertelement <32 x float> undef, float %98, i32 0
  %100 = shufflevector <32 x float> %99, <32 x float> undef, <32 x i32> zeroinitializer
  %101 = shl nsw i64 %indvars.iv, 5
  %102 = add nsw i64 %88, %101
  %103 = getelementptr inbounds float, float* %7, i64 %102
  %104 = bitcast float* %103 to <32 x float>*
  %105 = load <32 x float>, <32 x float>* %104, align 64, !tbaa !1298
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %100, <32 x float> %105, <32 x float> %95)
  %107 = add nsw i64 %96, 16
  %108 = getelementptr inbounds float, float* %4, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !1286
  %110 = insertelement <32 x float> undef, float %109, i32 0
  %111 = shufflevector <32 x float> %110, <32 x float> undef, <32 x i32> zeroinitializer
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %105, <32 x float> %94)
  %113 = add nsw i64 %96, 32
  %114 = getelementptr inbounds float, float* %4, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !1286
  %116 = insertelement <32 x float> undef, float %115, i32 0
  %117 = shufflevector <32 x float> %116, <32 x float> undef, <32 x i32> zeroinitializer
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %105, <32 x float> %93)
  %119 = add nsw i64 %96, 48
  %120 = getelementptr inbounds float, float* %4, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !1286
  %122 = insertelement <32 x float> undef, float %121, i32 0
  %123 = shufflevector <32 x float> %122, <32 x float> undef, <32 x i32> zeroinitializer
  %124 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %105, <32 x float> %92)
  %125 = add nsw i64 %96, 64
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !1286
  %128 = insertelement <32 x float> undef, float %127, i32 0
  %129 = shufflevector <32 x float> %128, <32 x float> undef, <32 x i32> zeroinitializer
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %105, <32 x float> %91)
  %131 = add nsw i64 %96, 80
  %132 = getelementptr inbounds float, float* %4, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !1286
  %134 = insertelement <32 x float> undef, float %133, i32 0
  %135 = shufflevector <32 x float> %134, <32 x float> undef, <32 x i32> zeroinitializer
  %136 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %135, <32 x float> %105, <32 x float> %90)
  %137 = add nsw i64 %96, 96
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !1286
  %140 = insertelement <32 x float> undef, float %139, i32 0
  %141 = shufflevector <32 x float> %140, <32 x float> undef, <32 x i32> zeroinitializer
  %142 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %141, <32 x float> %105, <32 x float> %89)
  %143 = add nsw i64 %96, 8
  %144 = getelementptr inbounds float, float* %4, i64 %143
  %145 = load float, float* %144, align 4, !tbaa !1286
  %146 = insertelement <32 x float> undef, float %145, i32 0
  %147 = shufflevector <32 x float> %146, <32 x float> undef, <32 x i32> zeroinitializer
  %148 = add nsw i64 %102, 256
  %149 = getelementptr inbounds float, float* %7, i64 %148
  %150 = bitcast float* %149 to <32 x float>*
  %151 = load <32 x float>, <32 x float>* %150, align 64, !tbaa !1298
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %147, <32 x float> %151, <32 x float> %106)
  %153 = add nsw i64 %96, 24
  %154 = getelementptr inbounds float, float* %4, i64 %153
  %155 = load float, float* %154, align 4, !tbaa !1286
  %156 = insertelement <32 x float> undef, float %155, i32 0
  %157 = shufflevector <32 x float> %156, <32 x float> undef, <32 x i32> zeroinitializer
  %158 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %157, <32 x float> %151, <32 x float> %112)
  %159 = add nsw i64 %96, 40
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = load float, float* %160, align 4, !tbaa !1286
  %162 = insertelement <32 x float> undef, float %161, i32 0
  %163 = shufflevector <32 x float> %162, <32 x float> undef, <32 x i32> zeroinitializer
  %164 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %163, <32 x float> %151, <32 x float> %118)
  %165 = add nsw i64 %96, 56
  %166 = getelementptr inbounds float, float* %4, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !1286
  %168 = insertelement <32 x float> undef, float %167, i32 0
  %169 = shufflevector <32 x float> %168, <32 x float> undef, <32 x i32> zeroinitializer
  %170 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %169, <32 x float> %151, <32 x float> %124)
  %171 = add nsw i64 %96, 72
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !1286
  %174 = insertelement <32 x float> undef, float %173, i32 0
  %175 = shufflevector <32 x float> %174, <32 x float> undef, <32 x i32> zeroinitializer
  %176 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %175, <32 x float> %151, <32 x float> %130)
  %177 = add nsw i64 %96, 88
  %178 = getelementptr inbounds float, float* %4, i64 %177
  %179 = load float, float* %178, align 4, !tbaa !1286
  %180 = insertelement <32 x float> undef, float %179, i32 0
  %181 = shufflevector <32 x float> %180, <32 x float> undef, <32 x i32> zeroinitializer
  %182 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %181, <32 x float> %151, <32 x float> %136)
  %183 = add nsw i64 %96, 104
  %184 = getelementptr inbounds float, float* %4, i64 %183
  %185 = load float, float* %184, align 4, !tbaa !1286
  %186 = insertelement <32 x float> undef, float %185, i32 0
  %187 = shufflevector <32 x float> %186, <32 x float> undef, <32 x i32> zeroinitializer
  %188 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %187, <32 x float> %151, <32 x float> %142)
  %189 = add nsw i64 %102, 512
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to <32 x float>*
  %192 = load <32 x float>, <32 x float>* %191, align 64, !tbaa !1298
  %193 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %192, <32 x float> %152)
  %194 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %192, <32 x float> %158)
  %195 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %192, <32 x float> %164)
  %196 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %192, <32 x float> %170)
  %197 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %135, <32 x float> %192, <32 x float> %176)
  %198 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %141, <32 x float> %192, <32 x float> %182)
  %199 = add nsw i64 %96, 112
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !1286
  %202 = insertelement <32 x float> undef, float %201, i32 0
  %203 = shufflevector <32 x float> %202, <32 x float> undef, <32 x i32> zeroinitializer
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %203, <32 x float> %192, <32 x float> %188)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 8
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %205 = add nsw i64 %86, 120
  %206 = add nsw i64 %88, 768
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %207 = phi <32 x float> [ %204, %for_end9 ], [ %322, %for_body8.1 ]
  %208 = phi <32 x float> [ %198, %for_end9 ], [ %316, %for_body8.1 ]
  %209 = phi <32 x float> [ %197, %for_end9 ], [ %315, %for_body8.1 ]
  %210 = phi <32 x float> [ %196, %for_end9 ], [ %314, %for_body8.1 ]
  %211 = phi <32 x float> [ %195, %for_end9 ], [ %313, %for_body8.1 ]
  %212 = phi <32 x float> [ %194, %for_end9 ], [ %312, %for_body8.1 ]
  %213 = phi <32 x float> [ %193, %for_end9 ], [ %311, %for_body8.1 ]
  %214 = add nsw i64 %205, %indvars.iv.1
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !1286
  %217 = insertelement <32 x float> undef, float %216, i32 0
  %218 = shufflevector <32 x float> %217, <32 x float> undef, <32 x i32> zeroinitializer
  %219 = shl nsw i64 %indvars.iv.1, 5
  %220 = add nsw i64 %206, %219
  %221 = getelementptr inbounds float, float* %7, i64 %220
  %222 = bitcast float* %221 to <32 x float>*
  %223 = load <32 x float>, <32 x float>* %222, align 64, !tbaa !1298
  %224 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %223, <32 x float> %213)
  %225 = add nsw i64 %214, 16
  %226 = getelementptr inbounds float, float* %4, i64 %225
  %227 = load float, float* %226, align 4, !tbaa !1286
  %228 = insertelement <32 x float> undef, float %227, i32 0
  %229 = shufflevector <32 x float> %228, <32 x float> undef, <32 x i32> zeroinitializer
  %230 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %229, <32 x float> %223, <32 x float> %212)
  %231 = add nsw i64 %214, 32
  %232 = getelementptr inbounds float, float* %4, i64 %231
  %233 = load float, float* %232, align 4, !tbaa !1286
  %234 = insertelement <32 x float> undef, float %233, i32 0
  %235 = shufflevector <32 x float> %234, <32 x float> undef, <32 x i32> zeroinitializer
  %236 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %235, <32 x float> %223, <32 x float> %211)
  %237 = add nsw i64 %214, 48
  %238 = getelementptr inbounds float, float* %4, i64 %237
  %239 = load float, float* %238, align 4, !tbaa !1286
  %240 = insertelement <32 x float> undef, float %239, i32 0
  %241 = shufflevector <32 x float> %240, <32 x float> undef, <32 x i32> zeroinitializer
  %242 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %241, <32 x float> %223, <32 x float> %210)
  %243 = add nsw i64 %214, 64
  %244 = getelementptr inbounds float, float* %4, i64 %243
  %245 = load float, float* %244, align 4, !tbaa !1286
  %246 = insertelement <32 x float> undef, float %245, i32 0
  %247 = shufflevector <32 x float> %246, <32 x float> undef, <32 x i32> zeroinitializer
  %248 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %247, <32 x float> %223, <32 x float> %209)
  %249 = add nsw i64 %214, 80
  %250 = getelementptr inbounds float, float* %4, i64 %249
  %251 = load float, float* %250, align 4, !tbaa !1286
  %252 = insertelement <32 x float> undef, float %251, i32 0
  %253 = shufflevector <32 x float> %252, <32 x float> undef, <32 x i32> zeroinitializer
  %254 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %253, <32 x float> %223, <32 x float> %208)
  %255 = add nsw i64 %214, 96
  %256 = getelementptr inbounds float, float* %4, i64 %255
  %257 = load float, float* %256, align 4, !tbaa !1286
  %258 = insertelement <32 x float> undef, float %257, i32 0
  %259 = shufflevector <32 x float> %258, <32 x float> undef, <32 x i32> zeroinitializer
  %260 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %259, <32 x float> %223, <32 x float> %207)
  %261 = add nsw i64 %214, 8
  %262 = getelementptr inbounds float, float* %4, i64 %261
  %263 = load float, float* %262, align 4, !tbaa !1286
  %264 = insertelement <32 x float> undef, float %263, i32 0
  %265 = shufflevector <32 x float> %264, <32 x float> undef, <32 x i32> zeroinitializer
  %266 = add nsw i64 %220, 256
  %267 = getelementptr inbounds float, float* %7, i64 %266
  %268 = bitcast float* %267 to <32 x float>*
  %269 = load <32 x float>, <32 x float>* %268, align 64, !tbaa !1298
  %270 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %265, <32 x float> %269, <32 x float> %224)
  %271 = add nsw i64 %214, 24
  %272 = getelementptr inbounds float, float* %4, i64 %271
  %273 = load float, float* %272, align 4, !tbaa !1286
  %274 = insertelement <32 x float> undef, float %273, i32 0
  %275 = shufflevector <32 x float> %274, <32 x float> undef, <32 x i32> zeroinitializer
  %276 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %275, <32 x float> %269, <32 x float> %230)
  %277 = add nsw i64 %214, 40
  %278 = getelementptr inbounds float, float* %4, i64 %277
  %279 = load float, float* %278, align 4, !tbaa !1286
  %280 = insertelement <32 x float> undef, float %279, i32 0
  %281 = shufflevector <32 x float> %280, <32 x float> undef, <32 x i32> zeroinitializer
  %282 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %281, <32 x float> %269, <32 x float> %236)
  %283 = add nsw i64 %214, 56
  %284 = getelementptr inbounds float, float* %4, i64 %283
  %285 = load float, float* %284, align 4, !tbaa !1286
  %286 = insertelement <32 x float> undef, float %285, i32 0
  %287 = shufflevector <32 x float> %286, <32 x float> undef, <32 x i32> zeroinitializer
  %288 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %287, <32 x float> %269, <32 x float> %242)
  %289 = add nsw i64 %214, 72
  %290 = getelementptr inbounds float, float* %4, i64 %289
  %291 = load float, float* %290, align 4, !tbaa !1286
  %292 = insertelement <32 x float> undef, float %291, i32 0
  %293 = shufflevector <32 x float> %292, <32 x float> undef, <32 x i32> zeroinitializer
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %293, <32 x float> %269, <32 x float> %248)
  %295 = add nsw i64 %214, 88
  %296 = getelementptr inbounds float, float* %4, i64 %295
  %297 = load float, float* %296, align 4, !tbaa !1286
  %298 = insertelement <32 x float> undef, float %297, i32 0
  %299 = shufflevector <32 x float> %298, <32 x float> undef, <32 x i32> zeroinitializer
  %300 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %299, <32 x float> %269, <32 x float> %254)
  %301 = add nsw i64 %214, 104
  %302 = getelementptr inbounds float, float* %4, i64 %301
  %303 = load float, float* %302, align 4, !tbaa !1286
  %304 = insertelement <32 x float> undef, float %303, i32 0
  %305 = shufflevector <32 x float> %304, <32 x float> undef, <32 x i32> zeroinitializer
  %306 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %269, <32 x float> %260)
  %307 = add nsw i64 %220, 512
  %308 = getelementptr inbounds float, float* %7, i64 %307
  %309 = bitcast float* %308 to <32 x float>*
  %310 = load <32 x float>, <32 x float>* %309, align 64, !tbaa !1298
  %311 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %229, <32 x float> %310, <32 x float> %270)
  %312 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %235, <32 x float> %310, <32 x float> %276)
  %313 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %241, <32 x float> %310, <32 x float> %282)
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %247, <32 x float> %310, <32 x float> %288)
  %315 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %253, <32 x float> %310, <32 x float> %294)
  %316 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %259, <32 x float> %310, <32 x float> %300)
  %317 = add nsw i64 %214, 112
  %318 = getelementptr inbounds float, float* %4, i64 %317
  %319 = load float, float* %318, align 4, !tbaa !1286
  %320 = insertelement <32 x float> undef, float %319, i32 0
  %321 = shufflevector <32 x float> %320, <32 x float> undef, <32 x i32> zeroinitializer
  %322 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %321, <32 x float> %310, <32 x float> %306)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 8
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %323 = add nsw i64 %86, 240
  %324 = add nsw i64 %88, 1536
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %325 = phi <32 x float> [ %322, %for_end9.1 ], [ %440, %for_body8.2 ]
  %326 = phi <32 x float> [ %316, %for_end9.1 ], [ %434, %for_body8.2 ]
  %327 = phi <32 x float> [ %315, %for_end9.1 ], [ %433, %for_body8.2 ]
  %328 = phi <32 x float> [ %314, %for_end9.1 ], [ %432, %for_body8.2 ]
  %329 = phi <32 x float> [ %313, %for_end9.1 ], [ %431, %for_body8.2 ]
  %330 = phi <32 x float> [ %312, %for_end9.1 ], [ %430, %for_body8.2 ]
  %331 = phi <32 x float> [ %311, %for_end9.1 ], [ %429, %for_body8.2 ]
  %332 = add nsw i64 %323, %indvars.iv.2
  %333 = getelementptr inbounds float, float* %4, i64 %332
  %334 = load float, float* %333, align 4, !tbaa !1286
  %335 = insertelement <32 x float> undef, float %334, i32 0
  %336 = shufflevector <32 x float> %335, <32 x float> undef, <32 x i32> zeroinitializer
  %337 = shl nsw i64 %indvars.iv.2, 5
  %338 = add nsw i64 %324, %337
  %339 = getelementptr inbounds float, float* %7, i64 %338
  %340 = bitcast float* %339 to <32 x float>*
  %341 = load <32 x float>, <32 x float>* %340, align 64, !tbaa !1298
  %342 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %336, <32 x float> %341, <32 x float> %331)
  %343 = add nsw i64 %332, 16
  %344 = getelementptr inbounds float, float* %4, i64 %343
  %345 = load float, float* %344, align 4, !tbaa !1286
  %346 = insertelement <32 x float> undef, float %345, i32 0
  %347 = shufflevector <32 x float> %346, <32 x float> undef, <32 x i32> zeroinitializer
  %348 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %347, <32 x float> %341, <32 x float> %330)
  %349 = add nsw i64 %332, 32
  %350 = getelementptr inbounds float, float* %4, i64 %349
  %351 = load float, float* %350, align 4, !tbaa !1286
  %352 = insertelement <32 x float> undef, float %351, i32 0
  %353 = shufflevector <32 x float> %352, <32 x float> undef, <32 x i32> zeroinitializer
  %354 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %353, <32 x float> %341, <32 x float> %329)
  %355 = add nsw i64 %332, 48
  %356 = getelementptr inbounds float, float* %4, i64 %355
  %357 = load float, float* %356, align 4, !tbaa !1286
  %358 = insertelement <32 x float> undef, float %357, i32 0
  %359 = shufflevector <32 x float> %358, <32 x float> undef, <32 x i32> zeroinitializer
  %360 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %359, <32 x float> %341, <32 x float> %328)
  %361 = add nsw i64 %332, 64
  %362 = getelementptr inbounds float, float* %4, i64 %361
  %363 = load float, float* %362, align 4, !tbaa !1286
  %364 = insertelement <32 x float> undef, float %363, i32 0
  %365 = shufflevector <32 x float> %364, <32 x float> undef, <32 x i32> zeroinitializer
  %366 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %365, <32 x float> %341, <32 x float> %327)
  %367 = add nsw i64 %332, 80
  %368 = getelementptr inbounds float, float* %4, i64 %367
  %369 = load float, float* %368, align 4, !tbaa !1286
  %370 = insertelement <32 x float> undef, float %369, i32 0
  %371 = shufflevector <32 x float> %370, <32 x float> undef, <32 x i32> zeroinitializer
  %372 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %371, <32 x float> %341, <32 x float> %326)
  %373 = add nsw i64 %332, 96
  %374 = getelementptr inbounds float, float* %4, i64 %373
  %375 = load float, float* %374, align 4, !tbaa !1286
  %376 = insertelement <32 x float> undef, float %375, i32 0
  %377 = shufflevector <32 x float> %376, <32 x float> undef, <32 x i32> zeroinitializer
  %378 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %377, <32 x float> %341, <32 x float> %325)
  %379 = add nsw i64 %332, 8
  %380 = getelementptr inbounds float, float* %4, i64 %379
  %381 = load float, float* %380, align 4, !tbaa !1286
  %382 = insertelement <32 x float> undef, float %381, i32 0
  %383 = shufflevector <32 x float> %382, <32 x float> undef, <32 x i32> zeroinitializer
  %384 = add nsw i64 %338, 256
  %385 = getelementptr inbounds float, float* %7, i64 %384
  %386 = bitcast float* %385 to <32 x float>*
  %387 = load <32 x float>, <32 x float>* %386, align 64, !tbaa !1298
  %388 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %383, <32 x float> %387, <32 x float> %342)
  %389 = add nsw i64 %332, 24
  %390 = getelementptr inbounds float, float* %4, i64 %389
  %391 = load float, float* %390, align 4, !tbaa !1286
  %392 = insertelement <32 x float> undef, float %391, i32 0
  %393 = shufflevector <32 x float> %392, <32 x float> undef, <32 x i32> zeroinitializer
  %394 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %387, <32 x float> %348)
  %395 = add nsw i64 %332, 40
  %396 = getelementptr inbounds float, float* %4, i64 %395
  %397 = load float, float* %396, align 4, !tbaa !1286
  %398 = insertelement <32 x float> undef, float %397, i32 0
  %399 = shufflevector <32 x float> %398, <32 x float> undef, <32 x i32> zeroinitializer
  %400 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %387, <32 x float> %354)
  %401 = add nsw i64 %332, 56
  %402 = getelementptr inbounds float, float* %4, i64 %401
  %403 = load float, float* %402, align 4, !tbaa !1286
  %404 = insertelement <32 x float> undef, float %403, i32 0
  %405 = shufflevector <32 x float> %404, <32 x float> undef, <32 x i32> zeroinitializer
  %406 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %387, <32 x float> %360)
  %407 = add nsw i64 %332, 72
  %408 = getelementptr inbounds float, float* %4, i64 %407
  %409 = load float, float* %408, align 4, !tbaa !1286
  %410 = insertelement <32 x float> undef, float %409, i32 0
  %411 = shufflevector <32 x float> %410, <32 x float> undef, <32 x i32> zeroinitializer
  %412 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %411, <32 x float> %387, <32 x float> %366)
  %413 = add nsw i64 %332, 88
  %414 = getelementptr inbounds float, float* %4, i64 %413
  %415 = load float, float* %414, align 4, !tbaa !1286
  %416 = insertelement <32 x float> undef, float %415, i32 0
  %417 = shufflevector <32 x float> %416, <32 x float> undef, <32 x i32> zeroinitializer
  %418 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %417, <32 x float> %387, <32 x float> %372)
  %419 = add nsw i64 %332, 104
  %420 = getelementptr inbounds float, float* %4, i64 %419
  %421 = load float, float* %420, align 4, !tbaa !1286
  %422 = insertelement <32 x float> undef, float %421, i32 0
  %423 = shufflevector <32 x float> %422, <32 x float> undef, <32 x i32> zeroinitializer
  %424 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %423, <32 x float> %387, <32 x float> %378)
  %425 = add nsw i64 %338, 512
  %426 = getelementptr inbounds float, float* %7, i64 %425
  %427 = bitcast float* %426 to <32 x float>*
  %428 = load <32 x float>, <32 x float>* %427, align 64, !tbaa !1298
  %429 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %347, <32 x float> %428, <32 x float> %388)
  %430 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %353, <32 x float> %428, <32 x float> %394)
  %431 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %359, <32 x float> %428, <32 x float> %400)
  %432 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %365, <32 x float> %428, <32 x float> %406)
  %433 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %371, <32 x float> %428, <32 x float> %412)
  %434 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %377, <32 x float> %428, <32 x float> %418)
  %435 = add nsw i64 %332, 112
  %436 = getelementptr inbounds float, float* %4, i64 %435
  %437 = load float, float* %436, align 4, !tbaa !1286
  %438 = insertelement <32 x float> undef, float %437, i32 0
  %439 = shufflevector <32 x float> %438, <32 x float> undef, <32 x i32> zeroinitializer
  %440 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %439, <32 x float> %428, <32 x float> %424)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 8
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  %indvars.iv.next61 = add nuw nsw i64 %indvars.iv60, 1
  %exitcond62 = icmp eq i64 %indvars.iv.next61, 32
  br i1 %exitcond62, label %for_begin10.preheader, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_max_pool2d(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.163, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !1301
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([147 x i8], [147 x i8]* @.str.164, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !1315
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([147 x i8], [147 x i8]* @.str.165, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !1317
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !1331
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 2
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !1333
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 112
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.167, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !1336
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 112
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.168, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !1338
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !1342
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 802816, i32 401408, i32 3584, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !1354
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.169, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !1358
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !1372
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 2
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !1374
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 56
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !1377
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 56
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !1379
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 32
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.172, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !1383
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 200704, i32 100352, i32 1792, i32 32>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !1395
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.173, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_nn_max_pool2d_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_max_pool2d_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %14, align 8
  %3 = getelementptr inbounds %14, %14* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %14, %14* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %14* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.174, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.174(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 111
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 112
  %15 = select i1 %14, i32 %13, i32 112
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 112
  %18 = select i1 %17, i32 %16, i32 112
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 1792
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 56
  %27 = shl nsw i32 %26, 1
  %28 = trunc i64 %indvars.iv10 to i32
  %29 = mul i32 %28, 7168
  %30 = add i32 %29, -3616
  %31 = icmp sgt i32 %26, 0
  %32 = or i32 %27, 1
  %33 = icmp sgt i32 %32, 0
  %34 = icmp sgt i32 %26, -1
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %if_end.8, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %if_end.8 ]
  %35 = shl i64 %indvars.iv, 5
  %36 = add nsw i64 %35, %24
  %37 = getelementptr inbounds float, float* %4, i64 %36
  %38 = bitcast float* %37 to <32 x float>*
  store <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, <32 x float>* %38, align 64, !tbaa !1399
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %39 = shl i32 %indvars.iv.tr, 6
  %40 = add i32 %30, %39
  %41 = icmp ne i64 %indvars.iv, 0
  %42 = and i1 %31, %41
  br i1 %42, label %if_then, label %if_end

for_end3:                                         ; preds = %if_end.8
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %43 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %43, label %for_begin1.preheader, label %for_end, !prof !5

if_then:                                          ; preds = %for_body2
  %44 = sext i32 %40 to i64
  %45 = getelementptr inbounds float, float* %7, i64 %44
  %46 = bitcast float* %45 to <32 x float>*
  %47 = load <32 x float>, <32 x float>* %46, align 64, !tbaa !1402
  br label %if_end

if_end:                                           ; preds = %for_body2, %if_then
  %48 = phi <32 x float> [ %47, %if_then ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %for_body2 ]
  %49 = fcmp olt <32 x float> %48, <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  %50 = select <32 x i1> %49, <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, <32 x float> %48
  br i1 %31, label %if_then.2, label %if_end.2

if_then.2:                                        ; preds = %if_end
  %51 = add i32 %40, 32
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds float, float* %7, i64 %52
  %54 = bitcast float* %53 to <32 x float>*
  %55 = load <32 x float>, <32 x float>* %54, align 64, !tbaa !1402
  %56 = fcmp ogt <32 x float> %50, %55
  %57 = select <32 x i1> %56, <32 x float> %50, <32 x float> %55
  %58 = add i32 %40, 64
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds float, float* %7, i64 %59
  %61 = bitcast float* %60 to <32 x float>*
  %62 = load <32 x float>, <32 x float>* %61, align 64, !tbaa !1402
  br label %if_end.2

if_end.2:                                         ; preds = %if_end, %if_then.2
  %63 = phi <32 x float> [ %57, %if_then.2 ], [ %50, %if_end ]
  %64 = phi <32 x float> [ %62, %if_then.2 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end ]
  %65 = fcmp ogt <32 x float> %63, %64
  %66 = select <32 x i1> %65, <32 x float> %63, <32 x float> %64
  %67 = and i1 %33, %41
  br i1 %67, label %if_then.3, label %if_end.3

if_then.3:                                        ; preds = %if_end.2
  %68 = add i32 %40, 3584
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to <32 x float>*
  %72 = load <32 x float>, <32 x float>* %71, align 64, !tbaa !1402
  br label %if_end.3

if_end.3:                                         ; preds = %if_then.3, %if_end.2
  %73 = phi <32 x float> [ %72, %if_then.3 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.2 ]
  %74 = fcmp ogt <32 x float> %66, %73
  %75 = select <32 x i1> %74, <32 x float> %66, <32 x float> %73
  br i1 %33, label %if_then.5, label %if_end.4

if_end.4:                                         ; preds = %if_end.3
  %76 = fcmp ogt <32 x float> %75, <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  %77 = select <32 x i1> %76, <32 x float> %75, <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  br label %if_end.5

if_then.5:                                        ; preds = %if_end.3
  %78 = add i32 %29, %39
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %7, i64 %79
  %81 = bitcast float* %80 to <32 x float>*
  %82 = load <32 x float>, <32 x float>* %81, align 64, !tbaa !1402
  %83 = fcmp ogt <32 x float> %75, %82
  %84 = select <32 x i1> %83, <32 x float> %75, <32 x float> %82
  %85 = add i32 %40, 3648
  %86 = sext i32 %85 to i64
  %87 = getelementptr inbounds float, float* %7, i64 %86
  %88 = bitcast float* %87 to <32 x float>*
  %89 = load <32 x float>, <32 x float>* %88, align 64, !tbaa !1402
  br label %if_end.5

if_end.5:                                         ; preds = %if_end.4, %if_then.5
  %90 = phi <32 x float> [ %84, %if_then.5 ], [ %77, %if_end.4 ]
  %91 = phi <32 x float> [ %89, %if_then.5 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.4 ]
  %92 = fcmp ogt <32 x float> %90, %91
  %93 = select <32 x i1> %92, <32 x float> %90, <32 x float> %91
  %94 = and i1 %34, %41
  br i1 %94, label %if_then.6, label %if_end.6

if_then.6:                                        ; preds = %if_end.5
  %95 = add i32 %40, 7168
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %7, i64 %96
  %98 = bitcast float* %97 to <32 x float>*
  %99 = load <32 x float>, <32 x float>* %98, align 64, !tbaa !1402
  br label %if_end.6

if_end.6:                                         ; preds = %if_then.6, %if_end.5
  %100 = phi <32 x float> [ %99, %if_then.6 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.5 ]
  %101 = fcmp ogt <32 x float> %93, %100
  %102 = select <32 x i1> %101, <32 x float> %93, <32 x float> %100
  br i1 %34, label %if_then.8, label %if_end.7

if_end.7:                                         ; preds = %if_end.6
  %103 = fcmp ogt <32 x float> %102, <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  %104 = select <32 x i1> %103, <32 x float> %102, <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  br label %if_end.8

if_then.8:                                        ; preds = %if_end.6
  %105 = add i32 %40, 7200
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = bitcast float* %107 to <32 x float>*
  %109 = load <32 x float>, <32 x float>* %108, align 64, !tbaa !1402
  %110 = fcmp ogt <32 x float> %102, %109
  %111 = select <32 x i1> %110, <32 x float> %102, <32 x float> %109
  %112 = add i32 %40, 7232
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to <32 x float>*
  %116 = load <32 x float>, <32 x float>* %115, align 64, !tbaa !1402
  br label %if_end.8

if_end.8:                                         ; preds = %if_end.7, %if_then.8
  %117 = phi <32 x float> [ %111, %if_then.8 ], [ %104, %if_end.7 ]
  %118 = phi <32 x float> [ %116, %if_then.8 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.7 ]
  %119 = fcmp ogt <32 x float> %117, %118
  %120 = select <32 x i1> %119, <32 x float> %117, <32 x float> %118
  store <32 x float> %120, <32 x float>* %38, align 64, !tbaa !1399
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50
}

define dllexport i32 @fused_layout_transform_21(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.175, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !1405
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.176, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !1419
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.177, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !1421
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !1435
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 4
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !1437
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 28
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !1440
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 28
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !1442
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !1446
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 100352, i32 25088, i32 896, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !1458
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !1462
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !1476
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 16
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.180, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !1478
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 28
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.181, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !1481
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 28
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.182, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !1483
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 8
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !1487
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 100352, i32 6272, i32 224, i32 8>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !1499
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.183, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_21_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_21_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %15, align 8
  %3 = getelementptr inbounds %15, %15* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %15, %15* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %15* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.184, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.184(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 447
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 448
  %15 = select i1 %14, i32 %13, i32 448
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 448
  %18 = select i1 %17, i32 %16, i32 448
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv4 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next5, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv4, 224
  %25 = trunc i64 %indvars.iv4 to i32
  %26 = sdiv i32 %25, 28
  %27 = shl nsw i32 %26, 3
  %28 = insertelement <8 x i32> undef, i32 %27, i32 0
  %29 = insertelement <4 x i32> undef, i32 %27, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = or <4 x i32> %30, <i32 1, i32 2, i32 3, i32 4>
  %32 = extractelement <4 x i32> %31, i32 0
  %33 = insertelement <8 x i32> %28, i32 %32, i32 1
  %34 = extractelement <4 x i32> %31, i32 1
  %35 = insertelement <8 x i32> %33, i32 %34, i32 2
  %36 = extractelement <4 x i32> %31, i32 2
  %37 = insertelement <8 x i32> %35, i32 %36, i32 3
  %38 = extractelement <4 x i32> %31, i32 3
  %39 = insertelement <8 x i32> %37, i32 %38, i32 4
  %40 = or i32 %27, 5
  %41 = insertelement <8 x i32> %39, i32 %40, i32 5
  %42 = or i32 %27, 6
  %43 = insertelement <8 x i32> %41, i32 %42, i32 6
  %44 = or i32 %27, 7
  %45 = insertelement <8 x i32> %43, i32 %44, i32 7
  %46 = sdiv <8 x i32> %45, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %47 = mul <8 x i32> %46, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %48 = sub <8 x i32> %45, %47
  %49 = add nsw <8 x i32> %48, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %50 = icmp sgt <8 x i32> %48, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %51 = select <8 x i1> %50, <8 x i32> %48, <8 x i32> %49
  %52 = srem i32 %25, 28
  %53 = mul nsw i32 %52, 896
  %54 = insertelement <8 x i32> undef, i32 %53, i32 0
  %55 = shufflevector <8 x i32> %54, <8 x i32> undef, <8 x i32> zeroinitializer
  %not. = xor <8 x i1> %50, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %56 = sext <8 x i1> %not. to <8 x i32>
  %57 = add nsw <8 x i32> %46, %56
  %58 = mul nsw <8 x i32> %57, <i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088>
  %59 = add <8 x i32> %51, %55
  %60 = add <8 x i32> %59, %58
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body2 ]
  %61 = shl i64 %indvars.iv, 3
  %62 = add nsw i64 %61, %24
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %63 = shl i32 %indvars.iv.tr, 5
  %64 = insertelement <8 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <8 x i32> %64, <8 x i32> undef, <8 x i32> zeroinitializer
  %66 = add <8 x i32> %60, %65
  %67 = extractelement <8 x i32> %66, i64 0
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = load float, float* %69, align 4, !tbaa !1503
  %71 = insertelement <8 x float> undef, float %70, i32 0
  %72 = extractelement <8 x i32> %66, i64 1
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !1503
  %76 = insertelement <8 x float> %71, float %75, i32 1
  %77 = extractelement <8 x i32> %66, i64 2
  %78 = sext i32 %77 to i64
  %79 = getelementptr inbounds float, float* %7, i64 %78
  %80 = load float, float* %79, align 4, !tbaa !1503
  %81 = insertelement <8 x float> %76, float %80, i32 2
  %82 = extractelement <8 x i32> %66, i64 3
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = load float, float* %84, align 4, !tbaa !1503
  %86 = insertelement <8 x float> %81, float %85, i32 3
  %87 = extractelement <8 x i32> %66, i64 4
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !1503
  %91 = insertelement <8 x float> %86, float %90, i32 4
  %92 = extractelement <8 x i32> %66, i64 5
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = load float, float* %94, align 4, !tbaa !1503
  %96 = insertelement <8 x float> %91, float %95, i32 5
  %97 = extractelement <8 x i32> %66, i64 6
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !1503
  %101 = insertelement <8 x float> %96, float %100, i32 6
  %102 = extractelement <8 x i32> %66, i64 7
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %7, i64 %103
  %105 = load float, float* %104, align 4, !tbaa !1503
  %106 = insertelement <8 x float> %101, float %105, i32 7
  %107 = getelementptr inbounds float, float* %4, i64 %62
  %108 = bitcast float* %107 to <8 x float>*
  store <8 x float> %106, <8 x float>* %108, align 32, !tbaa !1506
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 28
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next5 = add nsw i64 %indvars.iv4, 1
  %109 = icmp slt i64 %indvars.iv.next5, %23
  br i1 %109, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_26(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.185, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !1509
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.186, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !1523
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.187, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !1525
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !1539
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 2
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !1541
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 56
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !1544
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 56
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !1546
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !1550
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 200704, i32 100352, i32 1792, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !1562
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.190, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !1566
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !1580
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 8
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.191, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !1582
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 56
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !1585
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 56
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !1587
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 8
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !1591
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 200704, i32 25088, i32 448, i32 8>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !1603
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.192, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_26_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_26_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %16, align 8
  %3 = getelementptr inbounds %16, %16* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %16, %16* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %16* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.193, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.193(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 447
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 448
  %15 = select i1 %14, i32 %13, i32 448
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 448
  %18 = select i1 %17, i32 %16, i32 448
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv4 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next5, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv4, 448
  %25 = trunc i64 %indvars.iv4 to i32
  %26 = sdiv i32 %25, 56
  %27 = shl nsw i32 %26, 3
  %28 = insertelement <8 x i32> undef, i32 %27, i32 0
  %29 = insertelement <4 x i32> undef, i32 %27, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = or <4 x i32> %30, <i32 1, i32 2, i32 3, i32 4>
  %32 = extractelement <4 x i32> %31, i32 0
  %33 = insertelement <8 x i32> %28, i32 %32, i32 1
  %34 = extractelement <4 x i32> %31, i32 1
  %35 = insertelement <8 x i32> %33, i32 %34, i32 2
  %36 = extractelement <4 x i32> %31, i32 2
  %37 = insertelement <8 x i32> %35, i32 %36, i32 3
  %38 = extractelement <4 x i32> %31, i32 3
  %39 = insertelement <8 x i32> %37, i32 %38, i32 4
  %40 = or i32 %27, 5
  %41 = insertelement <8 x i32> %39, i32 %40, i32 5
  %42 = or i32 %27, 6
  %43 = insertelement <8 x i32> %41, i32 %42, i32 6
  %44 = or i32 %27, 7
  %45 = insertelement <8 x i32> %43, i32 %44, i32 7
  %46 = sdiv <8 x i32> %45, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %47 = mul <8 x i32> %46, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %48 = sub <8 x i32> %45, %47
  %49 = add nsw <8 x i32> %48, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %50 = icmp sgt <8 x i32> %48, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %51 = select <8 x i1> %50, <8 x i32> %48, <8 x i32> %49
  %52 = srem i32 %25, 56
  %53 = mul nsw i32 %52, 1792
  %54 = insertelement <8 x i32> undef, i32 %53, i32 0
  %55 = shufflevector <8 x i32> %54, <8 x i32> undef, <8 x i32> zeroinitializer
  %not. = xor <8 x i1> %50, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %56 = sext <8 x i1> %not. to <8 x i32>
  %57 = add nsw <8 x i32> %46, %56
  %58 = mul nsw <8 x i32> %57, <i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352>
  %59 = add <8 x i32> %51, %55
  %60 = add <8 x i32> %59, %58
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body2 ]
  %61 = shl i64 %indvars.iv, 3
  %62 = add nsw i64 %61, %24
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %63 = shl i32 %indvars.iv.tr, 5
  %64 = insertelement <8 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <8 x i32> %64, <8 x i32> undef, <8 x i32> zeroinitializer
  %66 = add <8 x i32> %60, %65
  %67 = extractelement <8 x i32> %66, i64 0
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = load float, float* %69, align 4, !tbaa !1607
  %71 = insertelement <8 x float> undef, float %70, i32 0
  %72 = extractelement <8 x i32> %66, i64 1
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !1607
  %76 = insertelement <8 x float> %71, float %75, i32 1
  %77 = extractelement <8 x i32> %66, i64 2
  %78 = sext i32 %77 to i64
  %79 = getelementptr inbounds float, float* %7, i64 %78
  %80 = load float, float* %79, align 4, !tbaa !1607
  %81 = insertelement <8 x float> %76, float %80, i32 2
  %82 = extractelement <8 x i32> %66, i64 3
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = load float, float* %84, align 4, !tbaa !1607
  %86 = insertelement <8 x float> %81, float %85, i32 3
  %87 = extractelement <8 x i32> %66, i64 4
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !1607
  %91 = insertelement <8 x float> %86, float %90, i32 4
  %92 = extractelement <8 x i32> %66, i64 5
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = load float, float* %94, align 4, !tbaa !1607
  %96 = insertelement <8 x float> %91, float %95, i32 5
  %97 = extractelement <8 x i32> %66, i64 6
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !1607
  %101 = insertelement <8 x float> %96, float %100, i32 6
  %102 = extractelement <8 x i32> %66, i64 7
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %7, i64 %103
  %105 = load float, float* %104, align 4, !tbaa !1607
  %106 = insertelement <8 x float> %101, float %105, i32 7
  %107 = getelementptr inbounds float, float* %4, i64 %62
  %108 = bitcast float* %107 to <8 x float>*
  store <8 x float> %106, <8 x float>* %108, align 32, !tbaa !1610
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next5 = add nsw i64 %indvars.iv4, 1
  %109 = icmp slt i64 %indvars.iv.next5, %23
  br i1 %109, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.194, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !1613
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !1627
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !1630
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.195, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !1632
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.196, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.197, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.198, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !1634
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !1648
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 1
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !1650
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 56
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !1653
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 56
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !1655
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 64
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.199, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !1659
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 200704, i32 200704, i32 3584, i32 64>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !1671
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.200, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !1675
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 2
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.137, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !1689
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 1
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !1691
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 3
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !1694
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 3
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !1696
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 64
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.201, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !1700
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !1702
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 18432, i32 18432, i32 6144, i32 2048>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !1714
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !1718
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([277 x i8], [277 x i8]* @.str.202, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !1720
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !1734
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 2
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.142, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !1736
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !1739
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !1741
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !1745
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 64, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !1757
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([231 x i8], [231 x i8]* @.str.143, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !1761
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !1775
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 2
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.144, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !1777
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 56
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.203, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !1780
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 56
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !1782
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !1786
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 200704, i32 100352, i32 1792, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !1798
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.205, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 861184, i32 2, i32 32)
  %7 = alloca %17, align 8
  %8 = getelementptr inbounds %17, %17* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %17, %17* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %17* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.206, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %18, align 8
  %15 = getelementptr inbounds %18, %18* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %18, %18* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %18, %18* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %18, %18* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %18, %18* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %18* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.207, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.206(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 57
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 58
  %15 = select i1 %14, i32 %13, i32 58
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 58
  %18 = select i1 %17, i32 %16, i32 58
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 58
  %21 = select i1 %20, i32 %16, i32 58
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -3712
  %23 = add i32 %22, -3712
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv6 = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next7, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv6, 3712
  %29 = trunc i64 %indvars.iv6 to i32
  %.off = add i32 %29, -1
  %30 = icmp ult i32 %.off, 56
  %31 = mul i64 %indvars.iv6, 3584
  %32 = add i64 %31, 4294963648
  br i1 %30, label %for_body2.us, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %33 = mul i32 %indvar, 3712
  %34 = add i32 %23, %33
  %35 = sext i32 %34 to i64
  %scevgep = getelementptr float, float* %4, i64 %35
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 14848, i1 false)
  br label %for_end3

for_body2.us:                                     ; preds = %for_begin1.preheader, %if_end.us
  %indvars.iv = phi i64 [ %indvars.iv.next, %if_end.us ], [ 0, %for_begin1.preheader ]
  %36 = shl nsw i64 %indvars.iv, 6
  %37 = add nsw i64 %36, %28
  %38 = trunc i64 %indvars.iv to i32
  switch i32 %38, label %if_then.us [
    i32 57, label %if_end.us
    i32 0, label %if_end.us
  ]

if_then.us:                                       ; preds = %for_body2.us
  %39 = add i64 %32, %36
  %sext = shl i64 %39, 32
  %40 = ashr exact i64 %sext, 32
  %41 = getelementptr inbounds float, float* %7, i64 %40
  %42 = bitcast float* %41 to <64 x float>*
  %43 = load <64 x float>, <64 x float>* %42, align 64, !tbaa !1802
  br label %if_end.us

if_end.us:                                        ; preds = %if_then.us, %for_body2.us, %for_body2.us
  %44 = phi <64 x float> [ %43, %if_then.us ], [ zeroinitializer, %for_body2.us ], [ zeroinitializer, %for_body2.us ]
  %45 = getelementptr inbounds float, float* %4, i64 %37
  %46 = bitcast float* %45 to <64 x float>*
  store <64 x float> %44, <64 x float>* %46, align 64, !tbaa !1805
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 58
  br i1 %exitcond, label %for_end3, label %for_body2.us, !prof !50

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %if_end.us, %for_body2.preheader
  %indvars.iv.next7 = add nsw i64 %indvars.iv6, 1
  %47 = icmp slt i64 %indvars.iv.next7, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %47, label %for_begin1.preheader, label %for_end, !prof !5
}

define private i32 @__tvm_parallel_lambda.207(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = add nsw i32 %20, 111
  %22 = sdiv i32 %21, %20
  %23 = add nsw i32 %0, 1
  %24 = mul nsw i32 %22, %23
  %25 = icmp slt i32 %24, 112
  %26 = select i1 %25, i32 %24, i32 112
  %27 = mul nsw i32 %22, %0
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = icmp slt i32 %29, %26
  br i1 %30, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %31 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %32 = bitcast float* %31 to <32 x float>*
  %33 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %34 = bitcast float* %33 to <32 x float>*
  %35 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %36 = bitcast float* %35 to <32 x float>*
  %37 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %38 = bitcast float* %37 to <32 x float>*
  %39 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %40 = bitcast float* %39 to <32 x float>*
  %41 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %42 = bitcast float* %41 to <32 x float>*
  %43 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end15
  %44 = phi i32 [ %29, %for_body.lr.ph ], [ %244, %for_end15 ]
  %45 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %46 = tail call i8* %45(i32 1, i32 %18, i64 7168, i32 2, i32 32)
  %47 = srem i32 %44, 56
  %48 = sdiv i32 %44, 56
  %49 = mul nsw i32 %48, 18432
  %50 = sext i32 %49 to i64
  %51 = mul nsw i32 %47, 3712
  %52 = sext i32 %51 to i64
  %53 = mul nsw i32 %47, 3712
  %54 = add nsw i32 %53, 3712
  %55 = sext i32 %54 to i64
  %56 = add nsw i64 %50, 6144
  %57 = mul nsw i32 %47, 3712
  %58 = add nsw i32 %57, 7424
  %59 = sext i32 %58 to i64
  %60 = add nsw i64 %50, 12288
  br label %for_body2

for_end:                                          ; preds = %for_end15, %entry
  ret i32 0

for_begin13.preheader:                            ; preds = %for_end9.2
  %61 = mul nsw i32 %44, 1792
  %62 = shl nsw i32 %48, 5
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %15, i64 %63
  %65 = bitcast float* %64 to <32 x float>*
  %66 = load <32 x float>, <32 x float>* %65, align 64, !tbaa !1808
  %67 = bitcast i8* %46 to float*
  br label %for_begin16.preheader

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %68 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %46, i64 %68
  %69 = mul nuw nsw i64 %indvar, 448
  %70 = add nsw i64 %69, %52
  call void @llvm.memset.p0i8.i64(i8* nonnull align 128 %43, i8 0, i64 896, i1 false)
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %71 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %156, %for_body8 ]
  %72 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %150, %for_body8 ]
  %73 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %149, %for_body8 ]
  %74 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %148, %for_body8 ]
  %75 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %147, %for_body8 ]
  %76 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %146, %for_body8 ]
  %77 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %145, %for_body8 ]
  %78 = add nsw i64 %70, %indvars.iv
  %79 = getelementptr inbounds float, float* %6, i64 %78
  %80 = load float, float* %79, align 4, !tbaa !1805
  %81 = insertelement <32 x float> undef, float %80, i32 0
  %82 = shufflevector <32 x float> %81, <32 x float> undef, <32 x i32> zeroinitializer
  %83 = shl nsw i64 %indvars.iv, 5
  %84 = add nsw i64 %83, %50
  %85 = getelementptr inbounds float, float* %9, i64 %84
  %86 = bitcast float* %85 to <32 x float>*
  %87 = load <32 x float>, <32 x float>* %86, align 64, !tbaa !1811
  %88 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %82, <32 x float> %87, <32 x float> %77)
  %89 = add nsw i64 %78, 64
  %90 = getelementptr inbounds float, float* %6, i64 %89
  %91 = load float, float* %90, align 4, !tbaa !1805
  %92 = insertelement <32 x float> undef, float %91, i32 0
  %93 = shufflevector <32 x float> %92, <32 x float> undef, <32 x i32> zeroinitializer
  %94 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %93, <32 x float> %87, <32 x float> %76)
  %95 = add nsw i64 %78, 128
  %96 = getelementptr inbounds float, float* %6, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !1805
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %87, <32 x float> %75)
  %101 = add nsw i64 %78, 192
  %102 = getelementptr inbounds float, float* %6, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !1805
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %87, <32 x float> %74)
  %107 = add nsw i64 %78, 256
  %108 = getelementptr inbounds float, float* %6, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !1805
  %110 = insertelement <32 x float> undef, float %109, i32 0
  %111 = shufflevector <32 x float> %110, <32 x float> undef, <32 x i32> zeroinitializer
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %87, <32 x float> %73)
  %113 = add nsw i64 %78, 320
  %114 = getelementptr inbounds float, float* %6, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !1805
  %116 = insertelement <32 x float> undef, float %115, i32 0
  %117 = shufflevector <32 x float> %116, <32 x float> undef, <32 x i32> zeroinitializer
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %87, <32 x float> %72)
  %119 = add nsw i64 %78, 384
  %120 = getelementptr inbounds float, float* %6, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !1805
  %122 = insertelement <32 x float> undef, float %121, i32 0
  %123 = shufflevector <32 x float> %122, <32 x float> undef, <32 x i32> zeroinitializer
  %124 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %87, <32 x float> %71)
  %125 = add nsw i64 %84, 2048
  %126 = getelementptr inbounds float, float* %9, i64 %125
  %127 = bitcast float* %126 to <32 x float>*
  %128 = load <32 x float>, <32 x float>* %127, align 64, !tbaa !1811
  %129 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %93, <32 x float> %128, <32 x float> %88)
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %128, <32 x float> %94)
  %131 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %128, <32 x float> %100)
  %132 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %128, <32 x float> %106)
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %128, <32 x float> %112)
  %134 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %128, <32 x float> %118)
  %135 = add nsw i64 %78, 448
  %136 = getelementptr inbounds float, float* %6, i64 %135
  %137 = load float, float* %136, align 4, !tbaa !1805
  %138 = insertelement <32 x float> undef, float %137, i32 0
  %139 = shufflevector <32 x float> %138, <32 x float> undef, <32 x i32> zeroinitializer
  %140 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %139, <32 x float> %128, <32 x float> %124)
  %141 = add nsw i64 %84, 4096
  %142 = getelementptr inbounds float, float* %9, i64 %141
  %143 = bitcast float* %142 to <32 x float>*
  %144 = load <32 x float>, <32 x float>* %143, align 64, !tbaa !1811
  %145 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %144, <32 x float> %129)
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %144, <32 x float> %130)
  %147 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %144, <32 x float> %131)
  %148 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %144, <32 x float> %132)
  %149 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %144, <32 x float> %133)
  %150 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %139, <32 x float> %144, <32 x float> %134)
  %151 = add nsw i64 %78, 512
  %152 = getelementptr inbounds float, float* %6, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !1805
  %154 = insertelement <32 x float> undef, float %153, i32 0
  %155 = shufflevector <32 x float> %154, <32 x float> undef, <32 x i32> zeroinitializer
  %156 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %144, <32 x float> %140)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %157 = add nsw i64 %69, %55
  br label %for_body8.1

for_begin16.preheader:                            ; preds = %for_begin16.preheader, %for_begin13.preheader
  %indvars.iv65 = phi i64 [ 0, %for_begin13.preheader ], [ %indvars.iv.next66, %for_begin16.preheader ]
  %158 = mul nuw nsw i64 %indvars.iv65, 224
  %159 = trunc i64 %158 to i32
  %160 = add i32 %61, %159
  %161 = getelementptr inbounds float, float* %67, i64 %158
  %162 = bitcast float* %161 to <32 x float>*
  %163 = load <32 x float>, <32 x float>* %162, align 64, !tbaa !1814
  %164 = fadd <32 x float> %66, %163
  %165 = fcmp ogt <32 x float> %164, zeroinitializer
  %166 = select <32 x i1> %165, <32 x float> %164, <32 x float> zeroinitializer
  %167 = sext i32 %160 to i64
  %168 = getelementptr inbounds float, float* %12, i64 %167
  %169 = bitcast float* %168 to <32 x float>*
  store <32 x float> %166, <32 x float>* %169, align 64, !tbaa !1817
  %170 = add nuw nsw i64 %158, 32
  %171 = trunc i64 %170 to i32
  %172 = add i32 %61, %171
  %173 = getelementptr inbounds float, float* %67, i64 %170
  %174 = bitcast float* %173 to <32 x float>*
  %175 = load <32 x float>, <32 x float>* %174, align 64, !tbaa !1814
  %176 = fadd <32 x float> %66, %175
  %177 = fcmp ogt <32 x float> %176, zeroinitializer
  %178 = select <32 x i1> %177, <32 x float> %176, <32 x float> zeroinitializer
  %179 = sext i32 %172 to i64
  %180 = getelementptr inbounds float, float* %12, i64 %179
  %181 = bitcast float* %180 to <32 x float>*
  store <32 x float> %178, <32 x float>* %181, align 64, !tbaa !1817
  %182 = add nuw nsw i64 %158, 64
  %183 = trunc i64 %182 to i32
  %184 = add i32 %61, %183
  %185 = getelementptr inbounds float, float* %67, i64 %182
  %186 = bitcast float* %185 to <32 x float>*
  %187 = load <32 x float>, <32 x float>* %186, align 64, !tbaa !1814
  %188 = fadd <32 x float> %66, %187
  %189 = fcmp ogt <32 x float> %188, zeroinitializer
  %190 = select <32 x i1> %189, <32 x float> %188, <32 x float> zeroinitializer
  %191 = sext i32 %184 to i64
  %192 = getelementptr inbounds float, float* %12, i64 %191
  %193 = bitcast float* %192 to <32 x float>*
  store <32 x float> %190, <32 x float>* %193, align 64, !tbaa !1817
  %194 = add nuw nsw i64 %158, 96
  %195 = trunc i64 %194 to i32
  %196 = add i32 %61, %195
  %197 = getelementptr inbounds float, float* %67, i64 %194
  %198 = bitcast float* %197 to <32 x float>*
  %199 = load <32 x float>, <32 x float>* %198, align 64, !tbaa !1814
  %200 = fadd <32 x float> %66, %199
  %201 = fcmp ogt <32 x float> %200, zeroinitializer
  %202 = select <32 x i1> %201, <32 x float> %200, <32 x float> zeroinitializer
  %203 = sext i32 %196 to i64
  %204 = getelementptr inbounds float, float* %12, i64 %203
  %205 = bitcast float* %204 to <32 x float>*
  store <32 x float> %202, <32 x float>* %205, align 64, !tbaa !1817
  %206 = add nuw nsw i64 %158, 128
  %207 = trunc i64 %206 to i32
  %208 = add i32 %61, %207
  %209 = getelementptr inbounds float, float* %67, i64 %206
  %210 = bitcast float* %209 to <32 x float>*
  %211 = load <32 x float>, <32 x float>* %210, align 64, !tbaa !1814
  %212 = fadd <32 x float> %66, %211
  %213 = fcmp ogt <32 x float> %212, zeroinitializer
  %214 = select <32 x i1> %213, <32 x float> %212, <32 x float> zeroinitializer
  %215 = sext i32 %208 to i64
  %216 = getelementptr inbounds float, float* %12, i64 %215
  %217 = bitcast float* %216 to <32 x float>*
  store <32 x float> %214, <32 x float>* %217, align 64, !tbaa !1817
  %218 = add nuw nsw i64 %158, 160
  %219 = trunc i64 %218 to i32
  %220 = add i32 %61, %219
  %221 = getelementptr inbounds float, float* %67, i64 %218
  %222 = bitcast float* %221 to <32 x float>*
  %223 = load <32 x float>, <32 x float>* %222, align 64, !tbaa !1814
  %224 = fadd <32 x float> %66, %223
  %225 = fcmp ogt <32 x float> %224, zeroinitializer
  %226 = select <32 x i1> %225, <32 x float> %224, <32 x float> zeroinitializer
  %227 = sext i32 %220 to i64
  %228 = getelementptr inbounds float, float* %12, i64 %227
  %229 = bitcast float* %228 to <32 x float>*
  store <32 x float> %226, <32 x float>* %229, align 64, !tbaa !1817
  %230 = add nuw nsw i64 %158, 192
  %231 = trunc i64 %230 to i32
  %232 = add i32 %61, %231
  %233 = getelementptr inbounds float, float* %67, i64 %230
  %234 = bitcast float* %233 to <32 x float>*
  %235 = load <32 x float>, <32 x float>* %234, align 64, !tbaa !1814
  %236 = fadd <32 x float> %66, %235
  %237 = fcmp ogt <32 x float> %236, zeroinitializer
  %238 = select <32 x i1> %237, <32 x float> %236, <32 x float> zeroinitializer
  %239 = sext i32 %232 to i64
  %240 = getelementptr inbounds float, float* %12, i64 %239
  %241 = bitcast float* %240 to <32 x float>*
  store <32 x float> %238, <32 x float>* %241, align 64, !tbaa !1817
  %indvars.iv.next66 = add nuw nsw i64 %indvars.iv65, 1
  %exitcond67 = icmp eq i64 %indvars.iv.next66, 8
  br i1 %exitcond67, label %for_end15, label %for_begin16.preheader, !prof !50

for_end15:                                        ; preds = %for_begin16.preheader
  %242 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %243 = tail call i32 %242(i32 1, i32 %18, i8* nonnull %46)
  %244 = add nsw i32 %44, 1
  %245 = icmp slt i32 %244, %26
  br i1 %245, label %for_body, label %for_end, !prof !5

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %246 = phi <32 x float> [ %156, %for_end9 ], [ %331, %for_body8.1 ]
  %247 = phi <32 x float> [ %150, %for_end9 ], [ %325, %for_body8.1 ]
  %248 = phi <32 x float> [ %149, %for_end9 ], [ %324, %for_body8.1 ]
  %249 = phi <32 x float> [ %148, %for_end9 ], [ %323, %for_body8.1 ]
  %250 = phi <32 x float> [ %147, %for_end9 ], [ %322, %for_body8.1 ]
  %251 = phi <32 x float> [ %146, %for_end9 ], [ %321, %for_body8.1 ]
  %252 = phi <32 x float> [ %145, %for_end9 ], [ %320, %for_body8.1 ]
  %253 = add nsw i64 %157, %indvars.iv.1
  %254 = getelementptr inbounds float, float* %6, i64 %253
  %255 = load float, float* %254, align 4, !tbaa !1805
  %256 = insertelement <32 x float> undef, float %255, i32 0
  %257 = shufflevector <32 x float> %256, <32 x float> undef, <32 x i32> zeroinitializer
  %258 = shl nsw i64 %indvars.iv.1, 5
  %259 = add nsw i64 %56, %258
  %260 = getelementptr inbounds float, float* %9, i64 %259
  %261 = bitcast float* %260 to <32 x float>*
  %262 = load <32 x float>, <32 x float>* %261, align 64, !tbaa !1811
  %263 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %262, <32 x float> %252)
  %264 = add nsw i64 %253, 64
  %265 = getelementptr inbounds float, float* %6, i64 %264
  %266 = load float, float* %265, align 4, !tbaa !1805
  %267 = insertelement <32 x float> undef, float %266, i32 0
  %268 = shufflevector <32 x float> %267, <32 x float> undef, <32 x i32> zeroinitializer
  %269 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %268, <32 x float> %262, <32 x float> %251)
  %270 = add nsw i64 %253, 128
  %271 = getelementptr inbounds float, float* %6, i64 %270
  %272 = load float, float* %271, align 4, !tbaa !1805
  %273 = insertelement <32 x float> undef, float %272, i32 0
  %274 = shufflevector <32 x float> %273, <32 x float> undef, <32 x i32> zeroinitializer
  %275 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %274, <32 x float> %262, <32 x float> %250)
  %276 = add nsw i64 %253, 192
  %277 = getelementptr inbounds float, float* %6, i64 %276
  %278 = load float, float* %277, align 4, !tbaa !1805
  %279 = insertelement <32 x float> undef, float %278, i32 0
  %280 = shufflevector <32 x float> %279, <32 x float> undef, <32 x i32> zeroinitializer
  %281 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %280, <32 x float> %262, <32 x float> %249)
  %282 = add nsw i64 %253, 256
  %283 = getelementptr inbounds float, float* %6, i64 %282
  %284 = load float, float* %283, align 4, !tbaa !1805
  %285 = insertelement <32 x float> undef, float %284, i32 0
  %286 = shufflevector <32 x float> %285, <32 x float> undef, <32 x i32> zeroinitializer
  %287 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %286, <32 x float> %262, <32 x float> %248)
  %288 = add nsw i64 %253, 320
  %289 = getelementptr inbounds float, float* %6, i64 %288
  %290 = load float, float* %289, align 4, !tbaa !1805
  %291 = insertelement <32 x float> undef, float %290, i32 0
  %292 = shufflevector <32 x float> %291, <32 x float> undef, <32 x i32> zeroinitializer
  %293 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %292, <32 x float> %262, <32 x float> %247)
  %294 = add nsw i64 %253, 384
  %295 = getelementptr inbounds float, float* %6, i64 %294
  %296 = load float, float* %295, align 4, !tbaa !1805
  %297 = insertelement <32 x float> undef, float %296, i32 0
  %298 = shufflevector <32 x float> %297, <32 x float> undef, <32 x i32> zeroinitializer
  %299 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %298, <32 x float> %262, <32 x float> %246)
  %300 = add nsw i64 %259, 2048
  %301 = getelementptr inbounds float, float* %9, i64 %300
  %302 = bitcast float* %301 to <32 x float>*
  %303 = load <32 x float>, <32 x float>* %302, align 64, !tbaa !1811
  %304 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %268, <32 x float> %303, <32 x float> %263)
  %305 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %274, <32 x float> %303, <32 x float> %269)
  %306 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %280, <32 x float> %303, <32 x float> %275)
  %307 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %286, <32 x float> %303, <32 x float> %281)
  %308 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %292, <32 x float> %303, <32 x float> %287)
  %309 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %298, <32 x float> %303, <32 x float> %293)
  %310 = add nsw i64 %253, 448
  %311 = getelementptr inbounds float, float* %6, i64 %310
  %312 = load float, float* %311, align 4, !tbaa !1805
  %313 = insertelement <32 x float> undef, float %312, i32 0
  %314 = shufflevector <32 x float> %313, <32 x float> undef, <32 x i32> zeroinitializer
  %315 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %314, <32 x float> %303, <32 x float> %299)
  %316 = add nsw i64 %259, 4096
  %317 = getelementptr inbounds float, float* %9, i64 %316
  %318 = bitcast float* %317 to <32 x float>*
  %319 = load <32 x float>, <32 x float>* %318, align 64, !tbaa !1811
  %320 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %274, <32 x float> %319, <32 x float> %304)
  %321 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %280, <32 x float> %319, <32 x float> %305)
  %322 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %286, <32 x float> %319, <32 x float> %306)
  %323 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %292, <32 x float> %319, <32 x float> %307)
  %324 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %298, <32 x float> %319, <32 x float> %308)
  %325 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %314, <32 x float> %319, <32 x float> %309)
  %326 = add nsw i64 %253, 512
  %327 = getelementptr inbounds float, float* %6, i64 %326
  %328 = load float, float* %327, align 4, !tbaa !1805
  %329 = insertelement <32 x float> undef, float %328, i32 0
  %330 = shufflevector <32 x float> %329, <32 x float> undef, <32 x i32> zeroinitializer
  %331 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %330, <32 x float> %319, <32 x float> %315)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 64
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %332 = add nsw i64 %69, %59
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %333 = phi <32 x float> [ %331, %for_end9.1 ], [ %418, %for_body8.2 ]
  %334 = phi <32 x float> [ %325, %for_end9.1 ], [ %412, %for_body8.2 ]
  %335 = phi <32 x float> [ %324, %for_end9.1 ], [ %411, %for_body8.2 ]
  %336 = phi <32 x float> [ %323, %for_end9.1 ], [ %410, %for_body8.2 ]
  %337 = phi <32 x float> [ %322, %for_end9.1 ], [ %409, %for_body8.2 ]
  %338 = phi <32 x float> [ %321, %for_end9.1 ], [ %408, %for_body8.2 ]
  %339 = phi <32 x float> [ %320, %for_end9.1 ], [ %407, %for_body8.2 ]
  %340 = add nsw i64 %332, %indvars.iv.2
  %341 = getelementptr inbounds float, float* %6, i64 %340
  %342 = load float, float* %341, align 4, !tbaa !1805
  %343 = insertelement <32 x float> undef, float %342, i32 0
  %344 = shufflevector <32 x float> %343, <32 x float> undef, <32 x i32> zeroinitializer
  %345 = shl nsw i64 %indvars.iv.2, 5
  %346 = add nsw i64 %60, %345
  %347 = getelementptr inbounds float, float* %9, i64 %346
  %348 = bitcast float* %347 to <32 x float>*
  %349 = load <32 x float>, <32 x float>* %348, align 64, !tbaa !1811
  %350 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %344, <32 x float> %349, <32 x float> %339)
  %351 = add nsw i64 %340, 64
  %352 = getelementptr inbounds float, float* %6, i64 %351
  %353 = load float, float* %352, align 4, !tbaa !1805
  %354 = insertelement <32 x float> undef, float %353, i32 0
  %355 = shufflevector <32 x float> %354, <32 x float> undef, <32 x i32> zeroinitializer
  %356 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %355, <32 x float> %349, <32 x float> %338)
  %357 = add nsw i64 %340, 128
  %358 = getelementptr inbounds float, float* %6, i64 %357
  %359 = load float, float* %358, align 4, !tbaa !1805
  %360 = insertelement <32 x float> undef, float %359, i32 0
  %361 = shufflevector <32 x float> %360, <32 x float> undef, <32 x i32> zeroinitializer
  %362 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %361, <32 x float> %349, <32 x float> %337)
  %363 = add nsw i64 %340, 192
  %364 = getelementptr inbounds float, float* %6, i64 %363
  %365 = load float, float* %364, align 4, !tbaa !1805
  %366 = insertelement <32 x float> undef, float %365, i32 0
  %367 = shufflevector <32 x float> %366, <32 x float> undef, <32 x i32> zeroinitializer
  %368 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %367, <32 x float> %349, <32 x float> %336)
  %369 = add nsw i64 %340, 256
  %370 = getelementptr inbounds float, float* %6, i64 %369
  %371 = load float, float* %370, align 4, !tbaa !1805
  %372 = insertelement <32 x float> undef, float %371, i32 0
  %373 = shufflevector <32 x float> %372, <32 x float> undef, <32 x i32> zeroinitializer
  %374 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %373, <32 x float> %349, <32 x float> %335)
  %375 = add nsw i64 %340, 320
  %376 = getelementptr inbounds float, float* %6, i64 %375
  %377 = load float, float* %376, align 4, !tbaa !1805
  %378 = insertelement <32 x float> undef, float %377, i32 0
  %379 = shufflevector <32 x float> %378, <32 x float> undef, <32 x i32> zeroinitializer
  %380 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %379, <32 x float> %349, <32 x float> %334)
  %381 = add nsw i64 %340, 384
  %382 = getelementptr inbounds float, float* %6, i64 %381
  %383 = load float, float* %382, align 4, !tbaa !1805
  %384 = insertelement <32 x float> undef, float %383, i32 0
  %385 = shufflevector <32 x float> %384, <32 x float> undef, <32 x i32> zeroinitializer
  %386 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %385, <32 x float> %349, <32 x float> %333)
  %387 = add nsw i64 %346, 2048
  %388 = getelementptr inbounds float, float* %9, i64 %387
  %389 = bitcast float* %388 to <32 x float>*
  %390 = load <32 x float>, <32 x float>* %389, align 64, !tbaa !1811
  %391 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %355, <32 x float> %390, <32 x float> %350)
  %392 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %361, <32 x float> %390, <32 x float> %356)
  %393 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %367, <32 x float> %390, <32 x float> %362)
  %394 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %373, <32 x float> %390, <32 x float> %368)
  %395 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %379, <32 x float> %390, <32 x float> %374)
  %396 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %385, <32 x float> %390, <32 x float> %380)
  %397 = add nsw i64 %340, 448
  %398 = getelementptr inbounds float, float* %6, i64 %397
  %399 = load float, float* %398, align 4, !tbaa !1805
  %400 = insertelement <32 x float> undef, float %399, i32 0
  %401 = shufflevector <32 x float> %400, <32 x float> undef, <32 x i32> zeroinitializer
  %402 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %401, <32 x float> %390, <32 x float> %386)
  %403 = add nsw i64 %346, 4096
  %404 = getelementptr inbounds float, float* %9, i64 %403
  %405 = bitcast float* %404 to <32 x float>*
  %406 = load <32 x float>, <32 x float>* %405, align 64, !tbaa !1811
  %407 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %361, <32 x float> %406, <32 x float> %391)
  %408 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %367, <32 x float> %406, <32 x float> %392)
  %409 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %373, <32 x float> %406, <32 x float> %393)
  %410 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %379, <32 x float> %406, <32 x float> %394)
  %411 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %385, <32 x float> %406, <32 x float> %395)
  %412 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %401, <32 x float> %406, <32 x float> %396)
  %413 = add nsw i64 %340, 512
  %414 = getelementptr inbounds float, float* %6, i64 %413
  %415 = load float, float* %414, align 4, !tbaa !1805
  %416 = insertelement <32 x float> undef, float %415, i32 0
  %417 = shufflevector <32 x float> %416, <32 x float> undef, <32 x i32> zeroinitializer
  %418 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %417, <32 x float> %406, <32 x float> %402)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 64
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %407, <32 x float>* %.sub, align 128, !tbaa !1820
  store <32 x float> %408, <32 x float>* %32, align 128, !tbaa !1820
  store <32 x float> %409, <32 x float>* %34, align 128, !tbaa !1820
  store <32 x float> %410, <32 x float>* %36, align 128, !tbaa !1820
  store <32 x float> %411, <32 x float>* %38, align 128, !tbaa !1820
  store <32 x float> %412, <32 x float>* %40, align 128, !tbaa !1820
  store <32 x float> %418, <32 x float>* %42, align 128, !tbaa !1820
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %scevgep, i8* nonnull align 128 %4, i64 896, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond61 = icmp eq i64 %indvar.next, 8
  br i1 %exitcond61, label %for_begin13.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_layout_transform_22(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.208, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !1829
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.209, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !1843
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.210, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !1845
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !1859
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 4
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !1861
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 28
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !1864
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 28
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !1866
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !1870
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 100352, i32 25088, i32 896, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !1882
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !1886
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !1900
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 1
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !1902
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 28
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.181, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !1905
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 28
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.182, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !1907
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 128
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !1911
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 100352, i32 100352, i32 3584, i32 128>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !1923
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.211, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_22_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_22_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %19, align 8
  %3 = getelementptr inbounds %19, %19* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %19, %19* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %19* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.212, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.212(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  %27 = insertelement <16 x i32> undef, i32 %26, i32 0
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %28 = shl i64 %indvars.iv7, 7
  %29 = add nsw i64 %28, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %30 = shl i32 %indvars.iv7.tr, 5
  %31 = insertelement <16 x i32> undef, i32 %30, i32 0
  %32 = add <16 x i32> %31, %27
  %33 = shufflevector <16 x i32> %32, <16 x i32> undef, <16 x i32> zeroinitializer
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %34 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %34, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %35 = shl nsw i64 %indvars.iv, 4
  %36 = add nsw i64 %29, %35
  %37 = trunc i64 %35 to i32
  %38 = insertelement <16 x i32> undef, i32 %37, i32 0
  %39 = trunc i64 %35 to i32
  %40 = or i32 %39, 1
  %41 = insertelement <16 x i32> %38, i32 %40, i32 1
  %42 = trunc i64 %35 to i32
  %43 = or i32 %42, 2
  %44 = insertelement <16 x i32> %41, i32 %43, i32 2
  %45 = trunc i64 %35 to i32
  %46 = or i32 %45, 3
  %47 = insertelement <16 x i32> %44, i32 %46, i32 3
  %48 = trunc i64 %35 to i32
  %49 = or i32 %48, 4
  %50 = insertelement <16 x i32> %47, i32 %49, i32 4
  %51 = trunc i64 %35 to i32
  %52 = or i32 %51, 5
  %53 = insertelement <16 x i32> %50, i32 %52, i32 5
  %54 = trunc i64 %35 to i32
  %55 = or i32 %54, 6
  %56 = insertelement <16 x i32> %53, i32 %55, i32 6
  %57 = trunc i64 %35 to i32
  %58 = or i32 %57, 7
  %59 = insertelement <16 x i32> %56, i32 %58, i32 7
  %60 = trunc i64 %35 to i32
  %61 = or i32 %60, 8
  %62 = insertelement <16 x i32> %59, i32 %61, i32 8
  %63 = trunc i64 %35 to i32
  %64 = or i32 %63, 9
  %65 = insertelement <16 x i32> %62, i32 %64, i32 9
  %66 = trunc i64 %35 to i32
  %67 = or i32 %66, 10
  %68 = insertelement <16 x i32> %65, i32 %67, i32 10
  %69 = trunc i64 %35 to i32
  %70 = or i32 %69, 11
  %71 = insertelement <16 x i32> %68, i32 %70, i32 11
  %72 = trunc i64 %35 to i32
  %73 = or i32 %72, 12
  %74 = insertelement <16 x i32> %71, i32 %73, i32 12
  %75 = trunc i64 %35 to i32
  %76 = or i32 %75, 13
  %77 = insertelement <16 x i32> %74, i32 %76, i32 13
  %78 = trunc i64 %35 to i32
  %79 = or i32 %78, 14
  %80 = insertelement <16 x i32> %77, i32 %79, i32 14
  %81 = trunc i64 %35 to i32
  %82 = or i32 %81, 15
  %83 = insertelement <16 x i32> %80, i32 %82, i32 15
  %84 = sdiv <16 x i32> %83, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %85 = mul <16 x i32> %84, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %86 = sub <16 x i32> %83, %85
  %87 = add nsw <16 x i32> %86, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %88 = icmp sgt <16 x i32> %86, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %89 = select <16 x i1> %88, <16 x i32> %86, <16 x i32> %87
  %not. = xor <16 x i1> %88, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %90 = sext <16 x i1> %not. to <16 x i32>
  %91 = add nsw <16 x i32> %84, %90
  %92 = mul nsw <16 x i32> %91, <i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088>
  %93 = add <16 x i32> %33, %89
  %94 = add <16 x i32> %93, %92
  %95 = extractelement <16 x i32> %94, i64 0
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %7, i64 %96
  %98 = load float, float* %97, align 4, !tbaa !1927
  %99 = insertelement <16 x float> undef, float %98, i32 0
  %100 = extractelement <16 x i32> %94, i64 1
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !1927
  %104 = insertelement <16 x float> %99, float %103, i32 1
  %105 = extractelement <16 x i32> %94, i64 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !1927
  %109 = insertelement <16 x float> %104, float %108, i32 2
  %110 = extractelement <16 x i32> %94, i64 3
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = load float, float* %112, align 4, !tbaa !1927
  %114 = insertelement <16 x float> %109, float %113, i32 3
  %115 = extractelement <16 x i32> %94, i64 4
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !1927
  %119 = insertelement <16 x float> %114, float %118, i32 4
  %120 = extractelement <16 x i32> %94, i64 5
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !1927
  %124 = insertelement <16 x float> %119, float %123, i32 5
  %125 = extractelement <16 x i32> %94, i64 6
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float* %7, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !1927
  %129 = insertelement <16 x float> %124, float %128, i32 6
  %130 = extractelement <16 x i32> %94, i64 7
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %7, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !1927
  %134 = insertelement <16 x float> %129, float %133, i32 7
  %135 = extractelement <16 x i32> %94, i64 8
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = load float, float* %137, align 4, !tbaa !1927
  %139 = insertelement <16 x float> %134, float %138, i32 8
  %140 = extractelement <16 x i32> %94, i64 9
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !1927
  %144 = insertelement <16 x float> %139, float %143, i32 9
  %145 = extractelement <16 x i32> %94, i64 10
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !1927
  %149 = insertelement <16 x float> %144, float %148, i32 10
  %150 = extractelement <16 x i32> %94, i64 11
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !1927
  %154 = insertelement <16 x float> %149, float %153, i32 11
  %155 = extractelement <16 x i32> %94, i64 12
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !1927
  %159 = insertelement <16 x float> %154, float %158, i32 12
  %160 = extractelement <16 x i32> %94, i64 13
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = load float, float* %162, align 4, !tbaa !1927
  %164 = insertelement <16 x float> %159, float %163, i32 13
  %165 = extractelement <16 x i32> %94, i64 14
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !1927
  %169 = insertelement <16 x float> %164, float %168, i32 14
  %170 = extractelement <16 x i32> %94, i64 15
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !1927
  %174 = insertelement <16 x float> %169, float %173, i32 15
  %175 = getelementptr inbounds float, float* %4, i64 %36
  %176 = bitcast float* %175 to <16 x float>*
  store <16 x float> %174, <16 x float>* %176, align 64, !tbaa !1930
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 8
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.213, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !1933
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !1947
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !1950
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.214, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !1952
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.215, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.216, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.217, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !1954
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !1968
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 2
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !1970
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 14
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !1973
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 14
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !1975
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 128
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !1979
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 50176, i32 25088, i32 1792, i32 128>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !1991
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.218, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !1995
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 16
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !2009
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 2
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !2011
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 3
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !2014
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 3
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !2016
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 128
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !2020
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 16
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.219, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !2022
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 36864, i32 18432, i32 6144, i32 2048>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !2034
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 16
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !2038
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([277 x i8], [277 x i8]* @.str.220, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !2040
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !2054
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 16
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !2056
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !2059
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !2061
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 16
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.221, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !2065
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 256, i32 16, i32 16, i32 16>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !2077
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.222, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !2081
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !2095
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 16
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !2097
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 14
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.223, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !2100
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 14
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !2102
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 16
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.225, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !2106
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 50176, i32 3136, i32 224, i32 16>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !2118
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 262144, i32 2, i32 32)
  %7 = alloca %20, align 8
  %8 = getelementptr inbounds %20, %20* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %20, %20* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %20* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.227, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %21, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %21, align 8
  %15 = getelementptr inbounds %21, %21* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %21, %21* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %21, %21* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %21, %21* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = bitcast %21* %14 to i8*
  %20 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %21 = call i32 %20(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.228, i8* nonnull %19, i32 0)
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %23 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %24 = call i32 %23(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.227(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 31
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 32
  %15 = select i1 %14, i32 %13, i32 32
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 32
  %18 = select i1 %17, i32 %16, i32 32
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 32
  %21 = select i1 %20, i32 %16, i32 32
  %smax = shl i32 %21, 11
  %22 = xor i32 %smax, -2048
  %23 = sub i32 -2048, %22
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 15
  %30 = mul nuw nsw i32 %29, 1792
  %31 = ashr i32 %28, 4
  %32 = mul nsw i32 %31, 25088
  %33 = add nsw i32 %30, -1920
  %34 = add i32 %33, %32
  switch i32 %29, label %if_end.us.15 [
    i32 15, label %for_begin1.preheader.split
    i32 0, label %for_begin1.preheader.split
  ]

for_begin1.preheader.split:                       ; preds = %for_begin1.preheader, %for_begin1.preheader
  %35 = shl i32 %indvar, 11
  %36 = add i32 %23, %35
  %37 = sext i32 %36 to i64
  %scevgep = getelementptr float, float* %4, i64 %37
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 8192, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_begin1.preheader.split, %if_end.us.15
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %38 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %38, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.15:                                     ; preds = %for_begin1.preheader
  %39 = shl i32 %28, 11
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds float, float* %4, i64 %40
  %42 = bitcast float* %41 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %42, align 64, !tbaa !2122
  %43 = or i64 %40, 128
  %44 = add i32 %34, 128
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = bitcast float* %46 to <128 x float>*
  %48 = load <128 x float>, <128 x float>* %47, align 64, !tbaa !2125
  %49 = getelementptr inbounds float, float* %4, i64 %43
  %50 = bitcast float* %49 to <128 x float>*
  store <128 x float> %48, <128 x float>* %50, align 64, !tbaa !2122
  %51 = or i64 %40, 256
  %52 = add i32 %34, 256
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <128 x float>*
  %56 = load <128 x float>, <128 x float>* %55, align 64, !tbaa !2125
  %57 = getelementptr inbounds float, float* %4, i64 %51
  %58 = bitcast float* %57 to <128 x float>*
  store <128 x float> %56, <128 x float>* %58, align 64, !tbaa !2122
  %59 = or i64 %40, 384
  %60 = add i32 %34, 384
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds float, float* %7, i64 %61
  %63 = bitcast float* %62 to <128 x float>*
  %64 = load <128 x float>, <128 x float>* %63, align 64, !tbaa !2125
  %65 = getelementptr inbounds float, float* %4, i64 %59
  %66 = bitcast float* %65 to <128 x float>*
  store <128 x float> %64, <128 x float>* %66, align 64, !tbaa !2122
  %67 = or i64 %40, 512
  %68 = add i32 %34, 512
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to <128 x float>*
  %72 = load <128 x float>, <128 x float>* %71, align 64, !tbaa !2125
  %73 = getelementptr inbounds float, float* %4, i64 %67
  %74 = bitcast float* %73 to <128 x float>*
  store <128 x float> %72, <128 x float>* %74, align 64, !tbaa !2122
  %75 = or i64 %40, 640
  %76 = add i32 %34, 640
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds float, float* %7, i64 %77
  %79 = bitcast float* %78 to <128 x float>*
  %80 = load <128 x float>, <128 x float>* %79, align 64, !tbaa !2125
  %81 = getelementptr inbounds float, float* %4, i64 %75
  %82 = bitcast float* %81 to <128 x float>*
  store <128 x float> %80, <128 x float>* %82, align 64, !tbaa !2122
  %83 = or i64 %40, 768
  %84 = add i32 %34, 768
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds float, float* %7, i64 %85
  %87 = bitcast float* %86 to <128 x float>*
  %88 = load <128 x float>, <128 x float>* %87, align 64, !tbaa !2125
  %89 = getelementptr inbounds float, float* %4, i64 %83
  %90 = bitcast float* %89 to <128 x float>*
  store <128 x float> %88, <128 x float>* %90, align 64, !tbaa !2122
  %91 = or i64 %40, 896
  %92 = add i32 %34, 896
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = bitcast float* %94 to <128 x float>*
  %96 = load <128 x float>, <128 x float>* %95, align 64, !tbaa !2125
  %97 = getelementptr inbounds float, float* %4, i64 %91
  %98 = bitcast float* %97 to <128 x float>*
  store <128 x float> %96, <128 x float>* %98, align 64, !tbaa !2122
  %99 = or i64 %40, 1024
  %100 = add i32 %34, 1024
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = bitcast float* %102 to <128 x float>*
  %104 = load <128 x float>, <128 x float>* %103, align 64, !tbaa !2125
  %105 = getelementptr inbounds float, float* %4, i64 %99
  %106 = bitcast float* %105 to <128 x float>*
  store <128 x float> %104, <128 x float>* %106, align 64, !tbaa !2122
  %107 = or i64 %40, 1152
  %108 = add i32 %34, 1152
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to <128 x float>*
  %112 = load <128 x float>, <128 x float>* %111, align 64, !tbaa !2125
  %113 = getelementptr inbounds float, float* %4, i64 %107
  %114 = bitcast float* %113 to <128 x float>*
  store <128 x float> %112, <128 x float>* %114, align 64, !tbaa !2122
  %115 = or i64 %40, 1280
  %116 = add i32 %34, 1280
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %7, i64 %117
  %119 = bitcast float* %118 to <128 x float>*
  %120 = load <128 x float>, <128 x float>* %119, align 64, !tbaa !2125
  %121 = getelementptr inbounds float, float* %4, i64 %115
  %122 = bitcast float* %121 to <128 x float>*
  store <128 x float> %120, <128 x float>* %122, align 64, !tbaa !2122
  %123 = or i64 %40, 1408
  %124 = add i32 %34, 1408
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = bitcast float* %126 to <128 x float>*
  %128 = load <128 x float>, <128 x float>* %127, align 64, !tbaa !2125
  %129 = getelementptr inbounds float, float* %4, i64 %123
  %130 = bitcast float* %129 to <128 x float>*
  store <128 x float> %128, <128 x float>* %130, align 64, !tbaa !2122
  %131 = or i64 %40, 1536
  %132 = add i32 %34, 1536
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds float, float* %7, i64 %133
  %135 = bitcast float* %134 to <128 x float>*
  %136 = load <128 x float>, <128 x float>* %135, align 64, !tbaa !2125
  %137 = getelementptr inbounds float, float* %4, i64 %131
  %138 = bitcast float* %137 to <128 x float>*
  store <128 x float> %136, <128 x float>* %138, align 64, !tbaa !2122
  %139 = or i64 %40, 1664
  %140 = add i32 %34, 1664
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to <128 x float>*
  %144 = load <128 x float>, <128 x float>* %143, align 64, !tbaa !2125
  %145 = getelementptr inbounds float, float* %4, i64 %139
  %146 = bitcast float* %145 to <128 x float>*
  store <128 x float> %144, <128 x float>* %146, align 64, !tbaa !2122
  %147 = or i64 %40, 1792
  %148 = add i32 %34, 1792
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <128 x float>*
  %152 = load <128 x float>, <128 x float>* %151, align 64, !tbaa !2125
  %153 = getelementptr inbounds float, float* %4, i64 %147
  %154 = bitcast float* %153 to <128 x float>*
  store <128 x float> %152, <128 x float>* %154, align 64, !tbaa !2122
  %155 = or i64 %40, 1920
  %156 = getelementptr inbounds float, float* %4, i64 %155
  %157 = bitcast float* %156 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %157, align 64, !tbaa !2122
  br label %for_end3
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.228(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 223
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 224
  %21 = select i1 %20, i32 %19, i32 224
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 224
  %24 = select i1 %23, i32 %22, i32 224
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv117 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next118, %for_end6.1 ]
  %30 = trunc i64 %indvars.iv117 to i32
  %31 = srem i32 %30, 14
  %32 = sdiv i32 %30, 14
  %33 = mul nsw i32 %32, 36864
  %34 = sext i32 %33 to i64
  br label %for_begin7.preheader

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_begin7.preheader:                             ; preds = %for_end9, %for_body
  %indvars.iv106 = phi i64 [ 0, %for_body ], [ %indvars.iv.next107, %for_end9 ]
  %.lcssa3966 = phi <16 x float> [ zeroinitializer, %for_body ], [ %188, %for_end9 ]
  %.lcssa3764 = phi <16 x float> [ zeroinitializer, %for_body ], [ %182, %for_end9 ]
  %.lcssa3562 = phi <16 x float> [ zeroinitializer, %for_body ], [ %181, %for_end9 ]
  %.lcssa3360 = phi <16 x float> [ zeroinitializer, %for_body ], [ %180, %for_end9 ]
  %.lcssa3158 = phi <16 x float> [ zeroinitializer, %for_body ], [ %179, %for_end9 ]
  %.lcssa2956 = phi <16 x float> [ zeroinitializer, %for_body ], [ %178, %for_end9 ]
  %.lcssa2754 = phi <16 x float> [ zeroinitializer, %for_body ], [ %177, %for_end9 ]
  %.lcssa2552 = phi <16 x float> [ zeroinitializer, %for_body ], [ %176, %for_end9 ]
  %.lcssa2350 = phi <16 x float> [ zeroinitializer, %for_body ], [ %175, %for_end9 ]
  %.lcssa2148 = phi <16 x float> [ zeroinitializer, %for_body ], [ %174, %for_end9 ]
  %.lcssa1946 = phi <16 x float> [ zeroinitializer, %for_body ], [ %173, %for_end9 ]
  %.lcssa1744 = phi <16 x float> [ zeroinitializer, %for_body ], [ %172, %for_end9 ]
  %.lcssa1543 = phi <16 x float> [ zeroinitializer, %for_body ], [ %171, %for_end9 ]
  %.lcssa41 = phi <16 x float> [ zeroinitializer, %for_body ], [ %170, %for_end9 ]
  %35 = phi i32 [ 0, %for_body ], [ %189, %for_end9 ]
  %reass.add = add nsw i32 %35, %31
  %reass.mul = shl i32 %reass.add, 11
  %36 = mul nuw nsw i64 %indvars.iv106, 6144
  %37 = add nsw i64 %36, %34
  %38 = sext i32 %reass.mul to i64
  br label %for_body8

for_end6:                                         ; preds = %for_end9
  %39 = add nsw i64 %34, 18432
  br label %for_begin7.preheader.1

for_body8:                                        ; preds = %for_body8, %for_begin7.preheader
  %indvars.iv = phi i64 [ 0, %for_begin7.preheader ], [ %indvars.iv.next, %for_body8 ]
  %40 = phi <16 x float> [ %.lcssa3966, %for_begin7.preheader ], [ %188, %for_body8 ]
  %41 = phi <16 x float> [ %.lcssa3764, %for_begin7.preheader ], [ %182, %for_body8 ]
  %42 = phi <16 x float> [ %.lcssa3562, %for_begin7.preheader ], [ %181, %for_body8 ]
  %43 = phi <16 x float> [ %.lcssa3360, %for_begin7.preheader ], [ %180, %for_body8 ]
  %44 = phi <16 x float> [ %.lcssa3158, %for_begin7.preheader ], [ %179, %for_body8 ]
  %45 = phi <16 x float> [ %.lcssa2956, %for_begin7.preheader ], [ %178, %for_body8 ]
  %46 = phi <16 x float> [ %.lcssa2754, %for_begin7.preheader ], [ %177, %for_body8 ]
  %47 = phi <16 x float> [ %.lcssa2552, %for_begin7.preheader ], [ %176, %for_body8 ]
  %48 = phi <16 x float> [ %.lcssa2350, %for_begin7.preheader ], [ %175, %for_body8 ]
  %49 = phi <16 x float> [ %.lcssa2148, %for_begin7.preheader ], [ %174, %for_body8 ]
  %50 = phi <16 x float> [ %.lcssa1946, %for_begin7.preheader ], [ %173, %for_body8 ]
  %51 = phi <16 x float> [ %.lcssa1744, %for_begin7.preheader ], [ %172, %for_body8 ]
  %52 = phi <16 x float> [ %.lcssa1543, %for_begin7.preheader ], [ %171, %for_body8 ]
  %53 = phi <16 x float> [ %.lcssa41, %for_begin7.preheader ], [ %170, %for_body8 ]
  %54 = add nsw i64 %indvars.iv, %38
  %55 = getelementptr inbounds float, float* %4, i64 %54
  %56 = load float, float* %55, align 4, !tbaa !2122
  %57 = insertelement <16 x float> undef, float %56, i32 0
  %58 = shufflevector <16 x float> %57, <16 x float> undef, <16 x i32> zeroinitializer
  %59 = shl nsw i64 %indvars.iv, 4
  %60 = add nsw i64 %37, %59
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = bitcast float* %61 to <16 x float>*
  %63 = load <16 x float>, <16 x float>* %62, align 64, !tbaa !2128
  %64 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %58, <16 x float> %63, <16 x float> %53)
  %65 = add nsw i64 %54, 128
  %66 = getelementptr inbounds float, float* %4, i64 %65
  %67 = load float, float* %66, align 4, !tbaa !2122
  %68 = insertelement <16 x float> undef, float %67, i32 0
  %69 = shufflevector <16 x float> %68, <16 x float> undef, <16 x i32> zeroinitializer
  %70 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %69, <16 x float> %63, <16 x float> %52)
  %71 = add nsw i64 %54, 256
  %72 = getelementptr inbounds float, float* %4, i64 %71
  %73 = load float, float* %72, align 4, !tbaa !2122
  %74 = insertelement <16 x float> undef, float %73, i32 0
  %75 = shufflevector <16 x float> %74, <16 x float> undef, <16 x i32> zeroinitializer
  %76 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %75, <16 x float> %63, <16 x float> %51)
  %77 = add nsw i64 %54, 384
  %78 = getelementptr inbounds float, float* %4, i64 %77
  %79 = load float, float* %78, align 4, !tbaa !2122
  %80 = insertelement <16 x float> undef, float %79, i32 0
  %81 = shufflevector <16 x float> %80, <16 x float> undef, <16 x i32> zeroinitializer
  %82 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %81, <16 x float> %63, <16 x float> %50)
  %83 = add nsw i64 %54, 512
  %84 = getelementptr inbounds float, float* %4, i64 %83
  %85 = load float, float* %84, align 4, !tbaa !2122
  %86 = insertelement <16 x float> undef, float %85, i32 0
  %87 = shufflevector <16 x float> %86, <16 x float> undef, <16 x i32> zeroinitializer
  %88 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %87, <16 x float> %63, <16 x float> %49)
  %89 = add nsw i64 %54, 640
  %90 = getelementptr inbounds float, float* %4, i64 %89
  %91 = load float, float* %90, align 4, !tbaa !2122
  %92 = insertelement <16 x float> undef, float %91, i32 0
  %93 = shufflevector <16 x float> %92, <16 x float> undef, <16 x i32> zeroinitializer
  %94 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %93, <16 x float> %63, <16 x float> %48)
  %95 = add nsw i64 %54, 768
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !2122
  %98 = insertelement <16 x float> undef, float %97, i32 0
  %99 = shufflevector <16 x float> %98, <16 x float> undef, <16 x i32> zeroinitializer
  %100 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %99, <16 x float> %63, <16 x float> %47)
  %101 = add nsw i64 %54, 896
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !2122
  %104 = insertelement <16 x float> undef, float %103, i32 0
  %105 = shufflevector <16 x float> %104, <16 x float> undef, <16 x i32> zeroinitializer
  %106 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %105, <16 x float> %63, <16 x float> %46)
  %107 = add nsw i64 %54, 1024
  %108 = getelementptr inbounds float, float* %4, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !2122
  %110 = insertelement <16 x float> undef, float %109, i32 0
  %111 = shufflevector <16 x float> %110, <16 x float> undef, <16 x i32> zeroinitializer
  %112 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %111, <16 x float> %63, <16 x float> %45)
  %113 = add nsw i64 %54, 1152
  %114 = getelementptr inbounds float, float* %4, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !2122
  %116 = insertelement <16 x float> undef, float %115, i32 0
  %117 = shufflevector <16 x float> %116, <16 x float> undef, <16 x i32> zeroinitializer
  %118 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %117, <16 x float> %63, <16 x float> %44)
  %119 = add nsw i64 %54, 1280
  %120 = getelementptr inbounds float, float* %4, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !2122
  %122 = insertelement <16 x float> undef, float %121, i32 0
  %123 = shufflevector <16 x float> %122, <16 x float> undef, <16 x i32> zeroinitializer
  %124 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %123, <16 x float> %63, <16 x float> %43)
  %125 = add nsw i64 %54, 1408
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !2122
  %128 = insertelement <16 x float> undef, float %127, i32 0
  %129 = shufflevector <16 x float> %128, <16 x float> undef, <16 x i32> zeroinitializer
  %130 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %129, <16 x float> %63, <16 x float> %42)
  %131 = add nsw i64 %54, 1536
  %132 = getelementptr inbounds float, float* %4, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !2122
  %134 = insertelement <16 x float> undef, float %133, i32 0
  %135 = shufflevector <16 x float> %134, <16 x float> undef, <16 x i32> zeroinitializer
  %136 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %135, <16 x float> %63, <16 x float> %41)
  %137 = add nsw i64 %54, 1664
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !2122
  %140 = insertelement <16 x float> undef, float %139, i32 0
  %141 = shufflevector <16 x float> %140, <16 x float> undef, <16 x i32> zeroinitializer
  %142 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %141, <16 x float> %63, <16 x float> %40)
  %143 = add nsw i64 %60, 2048
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <16 x float>*
  %146 = load <16 x float>, <16 x float>* %145, align 64, !tbaa !2128
  %147 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %69, <16 x float> %146, <16 x float> %64)
  %148 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %75, <16 x float> %146, <16 x float> %70)
  %149 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %81, <16 x float> %146, <16 x float> %76)
  %150 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %87, <16 x float> %146, <16 x float> %82)
  %151 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %93, <16 x float> %146, <16 x float> %88)
  %152 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %99, <16 x float> %146, <16 x float> %94)
  %153 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %105, <16 x float> %146, <16 x float> %100)
  %154 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %111, <16 x float> %146, <16 x float> %106)
  %155 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %117, <16 x float> %146, <16 x float> %112)
  %156 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %123, <16 x float> %146, <16 x float> %118)
  %157 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %129, <16 x float> %146, <16 x float> %124)
  %158 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %135, <16 x float> %146, <16 x float> %130)
  %159 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %141, <16 x float> %146, <16 x float> %136)
  %160 = add nsw i64 %54, 1792
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !2122
  %163 = insertelement <16 x float> undef, float %162, i32 0
  %164 = shufflevector <16 x float> %163, <16 x float> undef, <16 x i32> zeroinitializer
  %165 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %164, <16 x float> %146, <16 x float> %142)
  %166 = add nsw i64 %60, 4096
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = bitcast float* %167 to <16 x float>*
  %169 = load <16 x float>, <16 x float>* %168, align 64, !tbaa !2128
  %170 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %75, <16 x float> %169, <16 x float> %147)
  %171 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %81, <16 x float> %169, <16 x float> %148)
  %172 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %87, <16 x float> %169, <16 x float> %149)
  %173 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %93, <16 x float> %169, <16 x float> %150)
  %174 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %99, <16 x float> %169, <16 x float> %151)
  %175 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %105, <16 x float> %169, <16 x float> %152)
  %176 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %111, <16 x float> %169, <16 x float> %153)
  %177 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %117, <16 x float> %169, <16 x float> %154)
  %178 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %123, <16 x float> %169, <16 x float> %155)
  %179 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %129, <16 x float> %169, <16 x float> %156)
  %180 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %135, <16 x float> %169, <16 x float> %157)
  %181 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %141, <16 x float> %169, <16 x float> %158)
  %182 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %164, <16 x float> %169, <16 x float> %159)
  %183 = add nsw i64 %54, 1920
  %184 = getelementptr inbounds float, float* %4, i64 %183
  %185 = load float, float* %184, align 4, !tbaa !2122
  %186 = insertelement <16 x float> undef, float %185, i32 0
  %187 = shufflevector <16 x float> %186, <16 x float> undef, <16 x i32> zeroinitializer
  %188 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %187, <16 x float> %169, <16 x float> %165)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %indvars.iv.next107 = add nuw nsw i64 %indvars.iv106, 1
  %189 = add nuw nsw i32 %35, 1
  %exitcond110 = icmp eq i64 %indvars.iv.next107, 3
  br i1 %exitcond110, label %for_end6, label %for_begin7.preheader, !prof !50

for_begin7.preheader.1:                           ; preds = %for_end9.1, %for_end6
  %indvars.iv106.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next107.1, %for_end9.1 ]
  %.lcssa3966.1 = phi <16 x float> [ %188, %for_end6 ], [ %343, %for_end9.1 ]
  %.lcssa3764.1 = phi <16 x float> [ %182, %for_end6 ], [ %337, %for_end9.1 ]
  %.lcssa3562.1 = phi <16 x float> [ %181, %for_end6 ], [ %336, %for_end9.1 ]
  %.lcssa3360.1 = phi <16 x float> [ %180, %for_end6 ], [ %335, %for_end9.1 ]
  %.lcssa3158.1 = phi <16 x float> [ %179, %for_end6 ], [ %334, %for_end9.1 ]
  %.lcssa2956.1 = phi <16 x float> [ %178, %for_end6 ], [ %333, %for_end9.1 ]
  %.lcssa2754.1 = phi <16 x float> [ %177, %for_end6 ], [ %332, %for_end9.1 ]
  %.lcssa2552.1 = phi <16 x float> [ %176, %for_end6 ], [ %331, %for_end9.1 ]
  %.lcssa2350.1 = phi <16 x float> [ %175, %for_end6 ], [ %330, %for_end9.1 ]
  %.lcssa2148.1 = phi <16 x float> [ %174, %for_end6 ], [ %329, %for_end9.1 ]
  %.lcssa1946.1 = phi <16 x float> [ %173, %for_end6 ], [ %328, %for_end9.1 ]
  %.lcssa1744.1 = phi <16 x float> [ %172, %for_end6 ], [ %327, %for_end9.1 ]
  %.lcssa1543.1 = phi <16 x float> [ %171, %for_end6 ], [ %326, %for_end9.1 ]
  %.lcssa41.1 = phi <16 x float> [ %170, %for_end6 ], [ %325, %for_end9.1 ]
  %190 = phi i32 [ 0, %for_end6 ], [ %344, %for_end9.1 ]
  %reass.add.1 = add nsw i32 %190, %31
  %reass.mul.1 = shl i32 %reass.add.1, 11
  %191 = add nsw i32 %reass.mul.1, 32768
  %192 = mul nuw nsw i64 %indvars.iv106.1, 6144
  %193 = add nsw i64 %39, %192
  %194 = sext i32 %191 to i64
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_begin7.preheader.1
  %indvars.iv.1 = phi i64 [ 0, %for_begin7.preheader.1 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %195 = phi <16 x float> [ %.lcssa3966.1, %for_begin7.preheader.1 ], [ %343, %for_body8.1 ]
  %196 = phi <16 x float> [ %.lcssa3764.1, %for_begin7.preheader.1 ], [ %337, %for_body8.1 ]
  %197 = phi <16 x float> [ %.lcssa3562.1, %for_begin7.preheader.1 ], [ %336, %for_body8.1 ]
  %198 = phi <16 x float> [ %.lcssa3360.1, %for_begin7.preheader.1 ], [ %335, %for_body8.1 ]
  %199 = phi <16 x float> [ %.lcssa3158.1, %for_begin7.preheader.1 ], [ %334, %for_body8.1 ]
  %200 = phi <16 x float> [ %.lcssa2956.1, %for_begin7.preheader.1 ], [ %333, %for_body8.1 ]
  %201 = phi <16 x float> [ %.lcssa2754.1, %for_begin7.preheader.1 ], [ %332, %for_body8.1 ]
  %202 = phi <16 x float> [ %.lcssa2552.1, %for_begin7.preheader.1 ], [ %331, %for_body8.1 ]
  %203 = phi <16 x float> [ %.lcssa2350.1, %for_begin7.preheader.1 ], [ %330, %for_body8.1 ]
  %204 = phi <16 x float> [ %.lcssa2148.1, %for_begin7.preheader.1 ], [ %329, %for_body8.1 ]
  %205 = phi <16 x float> [ %.lcssa1946.1, %for_begin7.preheader.1 ], [ %328, %for_body8.1 ]
  %206 = phi <16 x float> [ %.lcssa1744.1, %for_begin7.preheader.1 ], [ %327, %for_body8.1 ]
  %207 = phi <16 x float> [ %.lcssa1543.1, %for_begin7.preheader.1 ], [ %326, %for_body8.1 ]
  %208 = phi <16 x float> [ %.lcssa41.1, %for_begin7.preheader.1 ], [ %325, %for_body8.1 ]
  %209 = add nsw i64 %indvars.iv.1, %194
  %210 = getelementptr inbounds float, float* %4, i64 %209
  %211 = load float, float* %210, align 4, !tbaa !2122
  %212 = insertelement <16 x float> undef, float %211, i32 0
  %213 = shufflevector <16 x float> %212, <16 x float> undef, <16 x i32> zeroinitializer
  %214 = shl nsw i64 %indvars.iv.1, 4
  %215 = add nsw i64 %193, %214
  %216 = getelementptr inbounds float, float* %7, i64 %215
  %217 = bitcast float* %216 to <16 x float>*
  %218 = load <16 x float>, <16 x float>* %217, align 64, !tbaa !2128
  %219 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %213, <16 x float> %218, <16 x float> %208)
  %220 = add nsw i64 %209, 128
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !2122
  %223 = insertelement <16 x float> undef, float %222, i32 0
  %224 = shufflevector <16 x float> %223, <16 x float> undef, <16 x i32> zeroinitializer
  %225 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %224, <16 x float> %218, <16 x float> %207)
  %226 = add nsw i64 %209, 256
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = load float, float* %227, align 4, !tbaa !2122
  %229 = insertelement <16 x float> undef, float %228, i32 0
  %230 = shufflevector <16 x float> %229, <16 x float> undef, <16 x i32> zeroinitializer
  %231 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %230, <16 x float> %218, <16 x float> %206)
  %232 = add nsw i64 %209, 384
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !2122
  %235 = insertelement <16 x float> undef, float %234, i32 0
  %236 = shufflevector <16 x float> %235, <16 x float> undef, <16 x i32> zeroinitializer
  %237 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %236, <16 x float> %218, <16 x float> %205)
  %238 = add nsw i64 %209, 512
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !2122
  %241 = insertelement <16 x float> undef, float %240, i32 0
  %242 = shufflevector <16 x float> %241, <16 x float> undef, <16 x i32> zeroinitializer
  %243 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %242, <16 x float> %218, <16 x float> %204)
  %244 = add nsw i64 %209, 640
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !2122
  %247 = insertelement <16 x float> undef, float %246, i32 0
  %248 = shufflevector <16 x float> %247, <16 x float> undef, <16 x i32> zeroinitializer
  %249 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %248, <16 x float> %218, <16 x float> %203)
  %250 = add nsw i64 %209, 768
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !2122
  %253 = insertelement <16 x float> undef, float %252, i32 0
  %254 = shufflevector <16 x float> %253, <16 x float> undef, <16 x i32> zeroinitializer
  %255 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %254, <16 x float> %218, <16 x float> %202)
  %256 = add nsw i64 %209, 896
  %257 = getelementptr inbounds float, float* %4, i64 %256
  %258 = load float, float* %257, align 4, !tbaa !2122
  %259 = insertelement <16 x float> undef, float %258, i32 0
  %260 = shufflevector <16 x float> %259, <16 x float> undef, <16 x i32> zeroinitializer
  %261 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %260, <16 x float> %218, <16 x float> %201)
  %262 = add nsw i64 %209, 1024
  %263 = getelementptr inbounds float, float* %4, i64 %262
  %264 = load float, float* %263, align 4, !tbaa !2122
  %265 = insertelement <16 x float> undef, float %264, i32 0
  %266 = shufflevector <16 x float> %265, <16 x float> undef, <16 x i32> zeroinitializer
  %267 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %266, <16 x float> %218, <16 x float> %200)
  %268 = add nsw i64 %209, 1152
  %269 = getelementptr inbounds float, float* %4, i64 %268
  %270 = load float, float* %269, align 4, !tbaa !2122
  %271 = insertelement <16 x float> undef, float %270, i32 0
  %272 = shufflevector <16 x float> %271, <16 x float> undef, <16 x i32> zeroinitializer
  %273 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %272, <16 x float> %218, <16 x float> %199)
  %274 = add nsw i64 %209, 1280
  %275 = getelementptr inbounds float, float* %4, i64 %274
  %276 = load float, float* %275, align 4, !tbaa !2122
  %277 = insertelement <16 x float> undef, float %276, i32 0
  %278 = shufflevector <16 x float> %277, <16 x float> undef, <16 x i32> zeroinitializer
  %279 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %278, <16 x float> %218, <16 x float> %198)
  %280 = add nsw i64 %209, 1408
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !2122
  %283 = insertelement <16 x float> undef, float %282, i32 0
  %284 = shufflevector <16 x float> %283, <16 x float> undef, <16 x i32> zeroinitializer
  %285 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %284, <16 x float> %218, <16 x float> %197)
  %286 = add nsw i64 %209, 1536
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !2122
  %289 = insertelement <16 x float> undef, float %288, i32 0
  %290 = shufflevector <16 x float> %289, <16 x float> undef, <16 x i32> zeroinitializer
  %291 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %290, <16 x float> %218, <16 x float> %196)
  %292 = add nsw i64 %209, 1664
  %293 = getelementptr inbounds float, float* %4, i64 %292
  %294 = load float, float* %293, align 4, !tbaa !2122
  %295 = insertelement <16 x float> undef, float %294, i32 0
  %296 = shufflevector <16 x float> %295, <16 x float> undef, <16 x i32> zeroinitializer
  %297 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %296, <16 x float> %218, <16 x float> %195)
  %298 = add nsw i64 %215, 2048
  %299 = getelementptr inbounds float, float* %7, i64 %298
  %300 = bitcast float* %299 to <16 x float>*
  %301 = load <16 x float>, <16 x float>* %300, align 64, !tbaa !2128
  %302 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %224, <16 x float> %301, <16 x float> %219)
  %303 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %230, <16 x float> %301, <16 x float> %225)
  %304 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %236, <16 x float> %301, <16 x float> %231)
  %305 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %242, <16 x float> %301, <16 x float> %237)
  %306 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %248, <16 x float> %301, <16 x float> %243)
  %307 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %254, <16 x float> %301, <16 x float> %249)
  %308 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %260, <16 x float> %301, <16 x float> %255)
  %309 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %266, <16 x float> %301, <16 x float> %261)
  %310 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %272, <16 x float> %301, <16 x float> %267)
  %311 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %278, <16 x float> %301, <16 x float> %273)
  %312 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %284, <16 x float> %301, <16 x float> %279)
  %313 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %290, <16 x float> %301, <16 x float> %285)
  %314 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %296, <16 x float> %301, <16 x float> %291)
  %315 = add nsw i64 %209, 1792
  %316 = getelementptr inbounds float, float* %4, i64 %315
  %317 = load float, float* %316, align 4, !tbaa !2122
  %318 = insertelement <16 x float> undef, float %317, i32 0
  %319 = shufflevector <16 x float> %318, <16 x float> undef, <16 x i32> zeroinitializer
  %320 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %319, <16 x float> %301, <16 x float> %297)
  %321 = add nsw i64 %215, 4096
  %322 = getelementptr inbounds float, float* %7, i64 %321
  %323 = bitcast float* %322 to <16 x float>*
  %324 = load <16 x float>, <16 x float>* %323, align 64, !tbaa !2128
  %325 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %230, <16 x float> %324, <16 x float> %302)
  %326 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %236, <16 x float> %324, <16 x float> %303)
  %327 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %242, <16 x float> %324, <16 x float> %304)
  %328 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %248, <16 x float> %324, <16 x float> %305)
  %329 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %254, <16 x float> %324, <16 x float> %306)
  %330 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %260, <16 x float> %324, <16 x float> %307)
  %331 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %266, <16 x float> %324, <16 x float> %308)
  %332 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %272, <16 x float> %324, <16 x float> %309)
  %333 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %278, <16 x float> %324, <16 x float> %310)
  %334 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %284, <16 x float> %324, <16 x float> %311)
  %335 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %290, <16 x float> %324, <16 x float> %312)
  %336 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %296, <16 x float> %324, <16 x float> %313)
  %337 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %319, <16 x float> %324, <16 x float> %314)
  %338 = add nsw i64 %209, 1920
  %339 = getelementptr inbounds float, float* %4, i64 %338
  %340 = load float, float* %339, align 4, !tbaa !2122
  %341 = insertelement <16 x float> undef, float %340, i32 0
  %342 = shufflevector <16 x float> %341, <16 x float> undef, <16 x i32> zeroinitializer
  %343 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %342, <16 x float> %324, <16 x float> %320)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %indvars.iv.next107.1 = add nuw nsw i64 %indvars.iv106.1, 1
  %344 = add nuw nsw i32 %190, 1
  %exitcond110.1 = icmp eq i64 %indvars.iv.next107.1, 3
  br i1 %exitcond110.1, label %for_end6.1, label %for_begin7.preheader.1, !prof !50

for_end6.1:                                       ; preds = %for_end9.1
  %345 = mul nsw i64 %indvars.iv117, 224
  %346 = shl nsw i32 %32, 4
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds float, float* %13, i64 %347
  %349 = bitcast float* %348 to <16 x float>*
  %350 = load <16 x float>, <16 x float>* %349, align 64, !tbaa !2131
  %351 = fadd <16 x float> %350, %325
  %352 = fcmp ogt <16 x float> %351, zeroinitializer
  %353 = select <16 x i1> %352, <16 x float> %351, <16 x float> zeroinitializer
  %354 = getelementptr inbounds float, float* %10, i64 %345
  %355 = bitcast float* %354 to <16 x float>*
  store <16 x float> %353, <16 x float>* %355, align 64, !tbaa !2134
  %356 = or i64 %345, 16
  %357 = fadd <16 x float> %350, %326
  %358 = fcmp ogt <16 x float> %357, zeroinitializer
  %359 = select <16 x i1> %358, <16 x float> %357, <16 x float> zeroinitializer
  %360 = getelementptr inbounds float, float* %10, i64 %356
  %361 = bitcast float* %360 to <16 x float>*
  store <16 x float> %359, <16 x float>* %361, align 64, !tbaa !2134
  %362 = add nsw i64 %345, 32
  %363 = fadd <16 x float> %350, %327
  %364 = fcmp ogt <16 x float> %363, zeroinitializer
  %365 = select <16 x i1> %364, <16 x float> %363, <16 x float> zeroinitializer
  %366 = getelementptr inbounds float, float* %10, i64 %362
  %367 = bitcast float* %366 to <16 x float>*
  store <16 x float> %365, <16 x float>* %367, align 64, !tbaa !2134
  %368 = add nsw i64 %345, 48
  %369 = fadd <16 x float> %350, %328
  %370 = fcmp ogt <16 x float> %369, zeroinitializer
  %371 = select <16 x i1> %370, <16 x float> %369, <16 x float> zeroinitializer
  %372 = getelementptr inbounds float, float* %10, i64 %368
  %373 = bitcast float* %372 to <16 x float>*
  store <16 x float> %371, <16 x float>* %373, align 64, !tbaa !2134
  %374 = add nsw i64 %345, 64
  %375 = fadd <16 x float> %350, %329
  %376 = fcmp ogt <16 x float> %375, zeroinitializer
  %377 = select <16 x i1> %376, <16 x float> %375, <16 x float> zeroinitializer
  %378 = getelementptr inbounds float, float* %10, i64 %374
  %379 = bitcast float* %378 to <16 x float>*
  store <16 x float> %377, <16 x float>* %379, align 64, !tbaa !2134
  %380 = add nsw i64 %345, 80
  %381 = fadd <16 x float> %350, %330
  %382 = fcmp ogt <16 x float> %381, zeroinitializer
  %383 = select <16 x i1> %382, <16 x float> %381, <16 x float> zeroinitializer
  %384 = getelementptr inbounds float, float* %10, i64 %380
  %385 = bitcast float* %384 to <16 x float>*
  store <16 x float> %383, <16 x float>* %385, align 64, !tbaa !2134
  %386 = add nsw i64 %345, 96
  %387 = fadd <16 x float> %350, %331
  %388 = fcmp ogt <16 x float> %387, zeroinitializer
  %389 = select <16 x i1> %388, <16 x float> %387, <16 x float> zeroinitializer
  %390 = getelementptr inbounds float, float* %10, i64 %386
  %391 = bitcast float* %390 to <16 x float>*
  store <16 x float> %389, <16 x float>* %391, align 64, !tbaa !2134
  %392 = add nsw i64 %345, 112
  %393 = fadd <16 x float> %350, %332
  %394 = fcmp ogt <16 x float> %393, zeroinitializer
  %395 = select <16 x i1> %394, <16 x float> %393, <16 x float> zeroinitializer
  %396 = getelementptr inbounds float, float* %10, i64 %392
  %397 = bitcast float* %396 to <16 x float>*
  store <16 x float> %395, <16 x float>* %397, align 64, !tbaa !2134
  %398 = add nsw i64 %345, 128
  %399 = fadd <16 x float> %350, %333
  %400 = fcmp ogt <16 x float> %399, zeroinitializer
  %401 = select <16 x i1> %400, <16 x float> %399, <16 x float> zeroinitializer
  %402 = getelementptr inbounds float, float* %10, i64 %398
  %403 = bitcast float* %402 to <16 x float>*
  store <16 x float> %401, <16 x float>* %403, align 64, !tbaa !2134
  %404 = add nsw i64 %345, 144
  %405 = fadd <16 x float> %350, %334
  %406 = fcmp ogt <16 x float> %405, zeroinitializer
  %407 = select <16 x i1> %406, <16 x float> %405, <16 x float> zeroinitializer
  %408 = getelementptr inbounds float, float* %10, i64 %404
  %409 = bitcast float* %408 to <16 x float>*
  store <16 x float> %407, <16 x float>* %409, align 64, !tbaa !2134
  %410 = add nsw i64 %345, 160
  %411 = fadd <16 x float> %350, %335
  %412 = fcmp ogt <16 x float> %411, zeroinitializer
  %413 = select <16 x i1> %412, <16 x float> %411, <16 x float> zeroinitializer
  %414 = getelementptr inbounds float, float* %10, i64 %410
  %415 = bitcast float* %414 to <16 x float>*
  store <16 x float> %413, <16 x float>* %415, align 64, !tbaa !2134
  %416 = add nsw i64 %345, 176
  %417 = fadd <16 x float> %350, %336
  %418 = fcmp ogt <16 x float> %417, zeroinitializer
  %419 = select <16 x i1> %418, <16 x float> %417, <16 x float> zeroinitializer
  %420 = getelementptr inbounds float, float* %10, i64 %416
  %421 = bitcast float* %420 to <16 x float>*
  store <16 x float> %419, <16 x float>* %421, align 64, !tbaa !2134
  %422 = add nsw i64 %345, 192
  %423 = fadd <16 x float> %350, %337
  %424 = fcmp ogt <16 x float> %423, zeroinitializer
  %425 = select <16 x i1> %424, <16 x float> %423, <16 x float> zeroinitializer
  %426 = getelementptr inbounds float, float* %10, i64 %422
  %427 = bitcast float* %426 to <16 x float>*
  store <16 x float> %425, <16 x float>* %427, align 64, !tbaa !2134
  %428 = add nsw i64 %345, 208
  %429 = fadd <16 x float> %350, %343
  %430 = fcmp ogt <16 x float> %429, zeroinitializer
  %431 = select <16 x i1> %430, <16 x float> %429, <16 x float> zeroinitializer
  %432 = getelementptr inbounds float, float* %10, i64 %428
  %433 = bitcast float* %432 to <16 x float>*
  store <16 x float> %431, <16 x float>* %433, align 64, !tbaa !2134
  %indvars.iv.next118 = add nsw i64 %indvars.iv117, 1
  %434 = icmp slt i64 %indvars.iv.next118, %29
  br i1 %434, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_27(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.229, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !2137
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.230, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !2151
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.231, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !2153
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !2167
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 4
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.178, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !2169
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 28
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !2172
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 28
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !2174
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !2178
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 100352, i32 25088, i32 896, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !2190
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.179, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !2194
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !2208
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 2
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !2210
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 28
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.181, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !2213
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 28
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.182, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !2215
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 64
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.201, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !2219
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 100352, i32 50176, i32 1792, i32 64>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !2231
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.232, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_27_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_27_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %22, align 8
  %3 = getelementptr inbounds %22, %22* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %22, %22* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %22* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.233, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.233(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 1792
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 28
  %27 = mul nsw i32 %26, 896
  %28 = insertelement <16 x i32> undef, i32 %27, i32 0
  %29 = sdiv i32 %25, 28
  %30 = mul nsw i32 %29, 50176
  %31 = insertelement <16 x i32> undef, i32 %30, i32 0
  %32 = add <16 x i32> %28, %31
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %33 = shl i64 %indvars.iv7, 6
  %34 = add nsw i64 %33, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %35 = shl i32 %indvars.iv7.tr, 5
  %36 = insertelement <16 x i32> undef, i32 %35, i32 0
  %37 = add <16 x i32> %32, %36
  %38 = shufflevector <16 x i32> %37, <16 x i32> undef, <16 x i32> zeroinitializer
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %39 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %39, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %40 = shl nsw i64 %indvars.iv, 4
  %41 = add nsw i64 %34, %40
  %42 = trunc i64 %40 to i32
  %43 = insertelement <16 x i32> undef, i32 %42, i32 0
  %44 = trunc i64 %40 to i32
  %45 = or i32 %44, 1
  %46 = insertelement <16 x i32> %43, i32 %45, i32 1
  %47 = trunc i64 %40 to i32
  %48 = or i32 %47, 2
  %49 = insertelement <16 x i32> %46, i32 %48, i32 2
  %50 = trunc i64 %40 to i32
  %51 = or i32 %50, 3
  %52 = insertelement <16 x i32> %49, i32 %51, i32 3
  %53 = trunc i64 %40 to i32
  %54 = or i32 %53, 4
  %55 = insertelement <16 x i32> %52, i32 %54, i32 4
  %56 = trunc i64 %40 to i32
  %57 = or i32 %56, 5
  %58 = insertelement <16 x i32> %55, i32 %57, i32 5
  %59 = trunc i64 %40 to i32
  %60 = or i32 %59, 6
  %61 = insertelement <16 x i32> %58, i32 %60, i32 6
  %62 = trunc i64 %40 to i32
  %63 = or i32 %62, 7
  %64 = insertelement <16 x i32> %61, i32 %63, i32 7
  %65 = trunc i64 %40 to i32
  %66 = or i32 %65, 8
  %67 = insertelement <16 x i32> %64, i32 %66, i32 8
  %68 = trunc i64 %40 to i32
  %69 = or i32 %68, 9
  %70 = insertelement <16 x i32> %67, i32 %69, i32 9
  %71 = trunc i64 %40 to i32
  %72 = or i32 %71, 10
  %73 = insertelement <16 x i32> %70, i32 %72, i32 10
  %74 = trunc i64 %40 to i32
  %75 = or i32 %74, 11
  %76 = insertelement <16 x i32> %73, i32 %75, i32 11
  %77 = trunc i64 %40 to i32
  %78 = or i32 %77, 12
  %79 = insertelement <16 x i32> %76, i32 %78, i32 12
  %80 = trunc i64 %40 to i32
  %81 = or i32 %80, 13
  %82 = insertelement <16 x i32> %79, i32 %81, i32 13
  %83 = trunc i64 %40 to i32
  %84 = or i32 %83, 14
  %85 = insertelement <16 x i32> %82, i32 %84, i32 14
  %86 = trunc i64 %40 to i32
  %87 = or i32 %86, 15
  %88 = insertelement <16 x i32> %85, i32 %87, i32 15
  %89 = sdiv <16 x i32> %88, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %90 = mul <16 x i32> %89, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %91 = sub <16 x i32> %88, %90
  %92 = add nsw <16 x i32> %91, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %93 = icmp sgt <16 x i32> %91, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %94 = select <16 x i1> %93, <16 x i32> %91, <16 x i32> %92
  %not. = xor <16 x i1> %93, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %95 = sext <16 x i1> %not. to <16 x i32>
  %96 = add nsw <16 x i32> %89, %95
  %97 = mul nsw <16 x i32> %96, <i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088, i32 25088>
  %98 = add <16 x i32> %38, %94
  %99 = add <16 x i32> %98, %97
  %100 = extractelement <16 x i32> %99, i64 0
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !2235
  %104 = insertelement <16 x float> undef, float %103, i32 0
  %105 = extractelement <16 x i32> %99, i64 1
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !2235
  %109 = insertelement <16 x float> %104, float %108, i32 1
  %110 = extractelement <16 x i32> %99, i64 2
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = load float, float* %112, align 4, !tbaa !2235
  %114 = insertelement <16 x float> %109, float %113, i32 2
  %115 = extractelement <16 x i32> %99, i64 3
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !2235
  %119 = insertelement <16 x float> %114, float %118, i32 3
  %120 = extractelement <16 x i32> %99, i64 4
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !2235
  %124 = insertelement <16 x float> %119, float %123, i32 4
  %125 = extractelement <16 x i32> %99, i64 5
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float* %7, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !2235
  %129 = insertelement <16 x float> %124, float %128, i32 5
  %130 = extractelement <16 x i32> %99, i64 6
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %7, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !2235
  %134 = insertelement <16 x float> %129, float %133, i32 6
  %135 = extractelement <16 x i32> %99, i64 7
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = load float, float* %137, align 4, !tbaa !2235
  %139 = insertelement <16 x float> %134, float %138, i32 7
  %140 = extractelement <16 x i32> %99, i64 8
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !2235
  %144 = insertelement <16 x float> %139, float %143, i32 8
  %145 = extractelement <16 x i32> %99, i64 9
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !2235
  %149 = insertelement <16 x float> %144, float %148, i32 9
  %150 = extractelement <16 x i32> %99, i64 10
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !2235
  %154 = insertelement <16 x float> %149, float %153, i32 10
  %155 = extractelement <16 x i32> %99, i64 11
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !2235
  %159 = insertelement <16 x float> %154, float %158, i32 11
  %160 = extractelement <16 x i32> %99, i64 12
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = load float, float* %162, align 4, !tbaa !2235
  %164 = insertelement <16 x float> %159, float %163, i32 12
  %165 = extractelement <16 x i32> %99, i64 13
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !2235
  %169 = insertelement <16 x float> %164, float %168, i32 13
  %170 = extractelement <16 x i32> %99, i64 14
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !2235
  %174 = insertelement <16 x float> %169, float %173, i32 14
  %175 = extractelement <16 x i32> %99, i64 15
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds float, float* %7, i64 %176
  %178 = load float, float* %177, align 4, !tbaa !2235
  %179 = insertelement <16 x float> %174, float %178, i32 15
  %180 = getelementptr inbounds float, float* %4, i64 %41
  %181 = bitcast float* %180 to <16 x float>*
  store <16 x float> %179, <16 x float>* %181, align 64, !tbaa !2238
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 4
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_17(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.234, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !2241
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.235, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !2255
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.236, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !2257
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !2271
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 16
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !2273
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 7
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !2276
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 7
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.94, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !2278
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !2282
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 25088, i32 1568, i32 224, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !2294
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.237, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !2298
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !2312
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 1
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !2314
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 7
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.138, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !2317
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 7
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.139, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !2319
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 512
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.98, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !2323
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 25088, i32 25088, i32 3584, i32 512>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !2335
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.238, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_17_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_17_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %23, align 8
  %3 = getelementptr inbounds %23, %23* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %23, %23* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %23* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.239, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.239(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 6
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 7
  %15 = select i1 %14, i32 %13, i32 7
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 7
  %18 = select i1 %17, i32 %16, i32 7
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 224
  %27 = insertelement <16 x i32> undef, i32 %26, i32 0
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %28 = shl i64 %indvars.iv7, 9
  %29 = add nsw i64 %28, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %30 = shl i32 %indvars.iv7.tr, 5
  %31 = insertelement <16 x i32> undef, i32 %30, i32 0
  %32 = add <16 x i32> %31, %27
  %33 = shufflevector <16 x i32> %32, <16 x i32> undef, <16 x i32> zeroinitializer
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %34 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %34, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %35 = shl nsw i64 %indvars.iv, 4
  %36 = add nsw i64 %29, %35
  %37 = trunc i64 %35 to i32
  %38 = insertelement <16 x i32> undef, i32 %37, i32 0
  %39 = trunc i64 %35 to i32
  %40 = or i32 %39, 1
  %41 = insertelement <16 x i32> %38, i32 %40, i32 1
  %42 = trunc i64 %35 to i32
  %43 = or i32 %42, 2
  %44 = insertelement <16 x i32> %41, i32 %43, i32 2
  %45 = trunc i64 %35 to i32
  %46 = or i32 %45, 3
  %47 = insertelement <16 x i32> %44, i32 %46, i32 3
  %48 = trunc i64 %35 to i32
  %49 = or i32 %48, 4
  %50 = insertelement <16 x i32> %47, i32 %49, i32 4
  %51 = trunc i64 %35 to i32
  %52 = or i32 %51, 5
  %53 = insertelement <16 x i32> %50, i32 %52, i32 5
  %54 = trunc i64 %35 to i32
  %55 = or i32 %54, 6
  %56 = insertelement <16 x i32> %53, i32 %55, i32 6
  %57 = trunc i64 %35 to i32
  %58 = or i32 %57, 7
  %59 = insertelement <16 x i32> %56, i32 %58, i32 7
  %60 = trunc i64 %35 to i32
  %61 = or i32 %60, 8
  %62 = insertelement <16 x i32> %59, i32 %61, i32 8
  %63 = trunc i64 %35 to i32
  %64 = or i32 %63, 9
  %65 = insertelement <16 x i32> %62, i32 %64, i32 9
  %66 = trunc i64 %35 to i32
  %67 = or i32 %66, 10
  %68 = insertelement <16 x i32> %65, i32 %67, i32 10
  %69 = trunc i64 %35 to i32
  %70 = or i32 %69, 11
  %71 = insertelement <16 x i32> %68, i32 %70, i32 11
  %72 = trunc i64 %35 to i32
  %73 = or i32 %72, 12
  %74 = insertelement <16 x i32> %71, i32 %73, i32 12
  %75 = trunc i64 %35 to i32
  %76 = or i32 %75, 13
  %77 = insertelement <16 x i32> %74, i32 %76, i32 13
  %78 = trunc i64 %35 to i32
  %79 = or i32 %78, 14
  %80 = insertelement <16 x i32> %77, i32 %79, i32 14
  %81 = trunc i64 %35 to i32
  %82 = or i32 %81, 15
  %83 = insertelement <16 x i32> %80, i32 %82, i32 15
  %84 = sdiv <16 x i32> %83, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %85 = mul <16 x i32> %84, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %86 = sub <16 x i32> %83, %85
  %87 = add nsw <16 x i32> %86, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %88 = icmp sgt <16 x i32> %86, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %89 = select <16 x i1> %88, <16 x i32> %86, <16 x i32> %87
  %not. = xor <16 x i1> %88, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %90 = sext <16 x i1> %not. to <16 x i32>
  %91 = add nsw <16 x i32> %84, %90
  %92 = mul nsw <16 x i32> %91, <i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568, i32 1568>
  %93 = add <16 x i32> %33, %89
  %94 = add <16 x i32> %93, %92
  %95 = extractelement <16 x i32> %94, i64 0
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %7, i64 %96
  %98 = load float, float* %97, align 4, !tbaa !2339
  %99 = insertelement <16 x float> undef, float %98, i32 0
  %100 = extractelement <16 x i32> %94, i64 1
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !2339
  %104 = insertelement <16 x float> %99, float %103, i32 1
  %105 = extractelement <16 x i32> %94, i64 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !2339
  %109 = insertelement <16 x float> %104, float %108, i32 2
  %110 = extractelement <16 x i32> %94, i64 3
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = load float, float* %112, align 4, !tbaa !2339
  %114 = insertelement <16 x float> %109, float %113, i32 3
  %115 = extractelement <16 x i32> %94, i64 4
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !2339
  %119 = insertelement <16 x float> %114, float %118, i32 4
  %120 = extractelement <16 x i32> %94, i64 5
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !2339
  %124 = insertelement <16 x float> %119, float %123, i32 5
  %125 = extractelement <16 x i32> %94, i64 6
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float* %7, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !2339
  %129 = insertelement <16 x float> %124, float %128, i32 6
  %130 = extractelement <16 x i32> %94, i64 7
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %7, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !2339
  %134 = insertelement <16 x float> %129, float %133, i32 7
  %135 = extractelement <16 x i32> %94, i64 8
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = load float, float* %137, align 4, !tbaa !2339
  %139 = insertelement <16 x float> %134, float %138, i32 8
  %140 = extractelement <16 x i32> %94, i64 9
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !2339
  %144 = insertelement <16 x float> %139, float %143, i32 9
  %145 = extractelement <16 x i32> %94, i64 10
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !2339
  %149 = insertelement <16 x float> %144, float %148, i32 10
  %150 = extractelement <16 x i32> %94, i64 11
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !2339
  %154 = insertelement <16 x float> %149, float %153, i32 11
  %155 = extractelement <16 x i32> %94, i64 12
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !2339
  %159 = insertelement <16 x float> %154, float %158, i32 12
  %160 = extractelement <16 x i32> %94, i64 13
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = load float, float* %162, align 4, !tbaa !2339
  %164 = insertelement <16 x float> %159, float %163, i32 13
  %165 = extractelement <16 x i32> %94, i64 14
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !2339
  %169 = insertelement <16 x float> %164, float %168, i32 14
  %170 = extractelement <16 x i32> %94, i64 15
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !2339
  %174 = insertelement <16 x float> %169, float %173, i32 15
  %175 = getelementptr inbounds float, float* %4, i64 %36
  %176 = bitcast float* %175 to <16 x float>*
  store <16 x float> %174, <16 x float>* %176, align 64, !tbaa !2342
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 7
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 5
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.240, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !2345
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !2359
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !2362
  %26 = getelementptr inbounds i8, i8* %0, i64 32
  %27 = bitcast i8* %26 to %1**
  %28 = load %1*, %1** %27, align 8
  %29 = getelementptr inbounds i8, i8* %1, i64 16
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !2364
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %33 = load i8*, i8** %32, align 8
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %37 = load i64*, i64** %36, align 8
  %38 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  %54 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %55 = load i8*, i8** %54, align 8
  %56 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %59 = load i64*, i64** %58, align 8
  %60 = getelementptr inbounds %1, %1* %28, i64 0, i32 0
  %61 = load i8*, i8** %60, align 8
  %62 = getelementptr inbounds %1, %1* %28, i64 0, i32 4
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %28, i64 0, i32 5
  %65 = load i64*, i64** %64, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.241, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %67 = getelementptr inbounds i8, i8* %1, i64 4
  %68 = bitcast i8* %67 to i32*
  %69 = load i32, i32* %68, align 4, !tbaa !2368
  switch i32 %69, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.242, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.243, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %72 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %72(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.244, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %31, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.245, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %74 = icmp eq i32 %39, 1
  br i1 %74, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %75 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %75(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %76 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %77 = load i32, i32* %76, align 4
  %78 = icmp eq i32 %77, 5
  br i1 %78, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %80 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %81 = load i16, i16* %80, align 2
  %82 = icmp eq i16 %81, 1
  %83 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %84 = load i8, i8* %83, align 1
  %85 = icmp eq i8 %84, 32
  %86 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %87 = load i8, i8* %86, align 1
  %88 = icmp eq i8 %87, 2
  %89 = and i1 %85, %88
  %90 = and i1 %82, %89
  br i1 %90, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %92 = load i64, i64* %35, align 8, !tbaa !2370
  %93 = trunc i64 %92 to i32
  %94 = icmp eq i32 %93, 1
  br i1 %94, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %96 = getelementptr inbounds i64, i64* %35, i64 1
  %97 = load i64, i64* %96, align 8, !tbaa !2384
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 1
  br i1 %99, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %101 = getelementptr inbounds i64, i64* %35, i64 2
  %102 = load i64, i64* %101, align 8, !tbaa !2386
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 56
  br i1 %104, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %106 = getelementptr inbounds i64, i64* %35, i64 3
  %107 = load i64, i64* %106, align 8, !tbaa !2389
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 56
  br i1 %109, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %111 = getelementptr inbounds i64, i64* %35, i64 4
  %112 = load i64, i64* %111, align 8, !tbaa !2391
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 64
  br i1 %114, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.199, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %116 = icmp eq i64* %37, null
  br i1 %116, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %117 = bitcast i64* %37 to <4 x i64>*
  %118 = load <4 x i64>, <4 x i64>* %117, align 8, !tbaa !2395
  %119 = trunc <4 x i64> %118 to <4 x i32>
  %120 = icmp eq <4 x i32> %119, <i32 200704, i32 200704, i32 3584, i32 64>
  %121 = getelementptr inbounds i64, i64* %37, i64 4
  %122 = load i64, i64* %121, align 8, !tbaa !2407
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 1
  %rdx.shuf143 = shufflevector <4 x i1> %120, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx144 = and <4 x i1> %120, %rdx.shuf143
  %rdx.shuf145 = shufflevector <4 x i1> %bin.rdx144, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx146 = and <4 x i1> %bin.rdx144, %rdx.shuf145
  %125 = extractelement <4 x i1> %bin.rdx146, i32 0
  %126 = and i1 %125, %124
  br i1 %126, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %127 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %128 = load i64, i64* %127, align 8
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.200, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %131 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %131(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %132 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %133 = load i32, i32* %132, align 4
  %134 = icmp eq i32 %133, 6
  br i1 %134, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %136 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %137 = load i16, i16* %136, align 2
  %138 = icmp eq i16 %137, 1
  %139 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %140 = load i8, i8* %139, align 1
  %141 = icmp eq i8 %140, 32
  %142 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %143 = load i8, i8* %142, align 1
  %144 = icmp eq i8 %143, 2
  %145 = and i1 %141, %144
  %146 = and i1 %138, %145
  br i1 %146, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %148 = load i64, i64* %45, align 8, !tbaa !2411
  %149 = trunc i64 %148 to i32
  %150 = icmp eq i32 %149, 2
  br i1 %150, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %151 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %151(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.137, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %152 = getelementptr inbounds i64, i64* %45, i64 1
  %153 = load i64, i64* %152, align 8, !tbaa !2425
  %154 = trunc i64 %153 to i32
  %155 = icmp eq i32 %154, 1
  br i1 %155, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %157 = getelementptr inbounds i64, i64* %45, i64 2
  %158 = load i64, i64* %157, align 8, !tbaa !2427
  %159 = trunc i64 %158 to i32
  %160 = icmp eq i32 %159, 3
  br i1 %160, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %161 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %161(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %162 = getelementptr inbounds i64, i64* %45, i64 3
  %163 = load i64, i64* %162, align 8, !tbaa !2430
  %164 = trunc i64 %163 to i32
  %165 = icmp eq i32 %164, 3
  br i1 %165, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %166 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %166(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %167 = getelementptr inbounds i64, i64* %45, i64 4
  %168 = load i64, i64* %167, align 8, !tbaa !2432
  %169 = trunc i64 %168 to i32
  %170 = icmp eq i32 %169, 64
  br i1 %170, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.201, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %172 = getelementptr inbounds i64, i64* %45, i64 5
  %173 = load i64, i64* %172, align 8, !tbaa !2436
  %174 = trunc i64 %173 to i32
  %175 = icmp eq i32 %174, 32
  br i1 %175, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %176 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %176(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %177 = icmp eq i64* %47, null
  br i1 %177, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %178 = bitcast i64* %47 to <4 x i64>*
  %179 = load <4 x i64>, <4 x i64>* %178, align 8, !tbaa !2438
  %180 = trunc <4 x i64> %179 to <4 x i32>
  %181 = icmp eq <4 x i32> %180, <i32 18432, i32 18432, i32 6144, i32 2048>
  %182 = getelementptr inbounds i64, i64* %47, i64 4
  %183 = load i64, i64* %182, align 8, !tbaa !2450
  %184 = trunc i64 %183 to i32
  %185 = icmp eq i32 %184, 32
  %186 = getelementptr inbounds i64, i64* %47, i64 5
  %187 = load i64, i64* %186, align 8, !tbaa !2454
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  %rdx.shuf139 = shufflevector <4 x i1> %181, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %181, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %190 = extractelement <4 x i1> %bin.rdx142, i32 0
  %191 = and i1 %190, %185
  %192 = and i1 %191, %189
  br i1 %192, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %193 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %194 = load i64, i64* %193, align 8
  %195 = icmp eq i64 %194, 0
  br i1 %195, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([277 x i8], [277 x i8]* @.str.202, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %197 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %197(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %198 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %199 = load i32, i32* %198, align 4
  %200 = icmp eq i32 %199, 1
  br i1 %200, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %201 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %201(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %202 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %203 = load i32, i32* %202, align 4
  %204 = icmp eq i32 %41, %203
  br i1 %204, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %205 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %205(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %206 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %207 = load i32, i32* %206, align 4
  %208 = icmp eq i32 %207, 5
  br i1 %208, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %209 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %209(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %210 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %211 = load i16, i16* %210, align 2
  %212 = icmp eq i16 %211, 1
  %213 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %214 = load i8, i8* %213, align 1
  %215 = icmp eq i8 %214, 32
  %216 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %217 = load i8, i8* %216, align 1
  %218 = icmp eq i8 %217, 2
  %219 = and i1 %215, %218
  %220 = and i1 %212, %219
  br i1 %220, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %222 = load i64, i64* %51, align 8, !tbaa !2456
  %223 = trunc i64 %222 to i32
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %226 = getelementptr inbounds i64, i64* %51, i64 1
  %227 = load i64, i64* %226, align 8, !tbaa !2470
  %228 = trunc i64 %227 to i32
  %229 = icmp eq i32 %228, 2
  br i1 %229, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %230 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %230(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.142, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %231 = getelementptr inbounds i64, i64* %51, i64 2
  %232 = load i64, i64* %231, align 8, !tbaa !2472
  %233 = trunc i64 %232 to i32
  %234 = icmp eq i32 %233, 1
  br i1 %234, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %235 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %235(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %236 = getelementptr inbounds i64, i64* %51, i64 3
  %237 = load i64, i64* %236, align 8, !tbaa !2475
  %238 = trunc i64 %237 to i32
  %239 = icmp eq i32 %238, 1
  br i1 %239, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %240 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %240(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %241 = getelementptr inbounds i64, i64* %51, i64 4
  %242 = load i64, i64* %241, align 8, !tbaa !2477
  %243 = trunc i64 %242 to i32
  %244 = icmp eq i32 %243, 32
  br i1 %244, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %246 = icmp eq i64* %53, null
  br i1 %246, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %247 = bitcast i64* %53 to <4 x i64>*
  %248 = load <4 x i64>, <4 x i64>* %247, align 8, !tbaa !2481
  %249 = trunc <4 x i64> %248 to <4 x i32>
  %250 = icmp eq <4 x i32> %249, <i32 64, i32 32, i32 32, i32 32>
  %251 = getelementptr inbounds i64, i64* %53, i64 4
  %252 = load i64, i64* %251, align 8, !tbaa !2493
  %253 = trunc i64 %252 to i32
  %254 = icmp eq i32 %253, 1
  %rdx.shuf135 = shufflevector <4 x i1> %250, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %250, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %255 = extractelement <4 x i1> %bin.rdx138, i32 0
  %256 = and i1 %255, %254
  br i1 %256, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %257 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %258 = load i64, i64* %257, align 8
  %259 = icmp eq i64 %258, 0
  br i1 %259, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([231 x i8], [231 x i8]* @.str.143, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %262 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %263 = load i32, i32* %262, align 4
  %264 = icmp eq i32 %263, 1
  br i1 %264, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %265 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %265(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %266 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %267 = load i32, i32* %266, align 4
  %268 = icmp eq i32 %41, %267
  br i1 %268, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %269 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %269(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %270 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %271 = load i32, i32* %270, align 4
  %272 = icmp eq i32 %271, 5
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %275 = load i16, i16* %274, align 2
  %276 = icmp eq i16 %275, 1
  %277 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %278 = load i8, i8* %277, align 1
  %279 = icmp eq i8 %278, 32
  %280 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %281 = load i8, i8* %280, align 1
  %282 = icmp eq i8 %281, 2
  %283 = and i1 %279, %282
  %284 = and i1 %276, %283
  br i1 %284, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %285 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %285(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %286 = load i64, i64* %57, align 8, !tbaa !2497
  %287 = trunc i64 %286 to i32
  %288 = icmp eq i32 %287, 1
  br i1 %288, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %289 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %289(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %290 = getelementptr inbounds i64, i64* %57, i64 1
  %291 = load i64, i64* %290, align 8, !tbaa !2511
  %292 = trunc i64 %291 to i32
  %293 = icmp eq i32 %292, 2
  br i1 %293, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %294 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %294(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.144, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %295 = getelementptr inbounds i64, i64* %57, i64 2
  %296 = load i64, i64* %295, align 8, !tbaa !2513
  %297 = trunc i64 %296 to i32
  %298 = icmp eq i32 %297, 56
  br i1 %298, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.203, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %300 = getelementptr inbounds i64, i64* %57, i64 3
  %301 = load i64, i64* %300, align 8, !tbaa !2516
  %302 = trunc i64 %301 to i32
  %303 = icmp eq i32 %302, 56
  br i1 %303, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %304 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %304(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.204, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %305 = getelementptr inbounds i64, i64* %57, i64 4
  %306 = load i64, i64* %305, align 8, !tbaa !2518
  %307 = trunc i64 %306 to i32
  %308 = icmp eq i32 %307, 32
  br i1 %308, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %309 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %309(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %310 = icmp eq i64* %59, null
  br i1 %310, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %311 = bitcast i64* %59 to <4 x i64>*
  %312 = load <4 x i64>, <4 x i64>* %311, align 8, !tbaa !2522
  %313 = trunc <4 x i64> %312 to <4 x i32>
  %314 = icmp eq <4 x i32> %313, <i32 200704, i32 100352, i32 1792, i32 32>
  %315 = getelementptr inbounds i64, i64* %59, i64 4
  %316 = load i64, i64* %315, align 8, !tbaa !2534
  %317 = trunc i64 %316 to i32
  %318 = icmp eq i32 %317, 1
  %rdx.shuf131 = shufflevector <4 x i1> %314, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %314, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %319 = extractelement <4 x i1> %bin.rdx134, i32 0
  %320 = and i1 %319, %318
  br i1 %320, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %321 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %322 = load i64, i64* %321, align 8
  %323 = icmp eq i64 %322, 0
  br i1 %323, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.205, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %325 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %325(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %326 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %327 = load i32, i32* %326, align 4
  %328 = icmp eq i32 %327, 1
  br i1 %328, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %330 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %41, %331
  br i1 %332, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %334 = getelementptr inbounds %1, %1* %28, i64 0, i32 2
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %335, 5
  br i1 %336, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %338 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 2
  %339 = load i16, i16* %338, align 2
  %340 = icmp eq i16 %339, 1
  %341 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 1
  %342 = load i8, i8* %341, align 1
  %343 = icmp eq i8 %342, 32
  %344 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 0
  %345 = load i8, i8* %344, align 1
  %346 = icmp eq i8 %345, 2
  %347 = and i1 %343, %346
  %348 = and i1 %340, %347
  br i1 %348, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %350 = load i64, i64* %63, align 8, !tbaa !2538
  %351 = trunc i64 %350 to i32
  %352 = icmp eq i32 %351, 1
  br i1 %352, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %354 = getelementptr inbounds i64, i64* %63, i64 1
  %355 = load i64, i64* %354, align 8, !tbaa !2552
  %356 = trunc i64 %355 to i32
  %357 = icmp eq i32 %356, 2
  br i1 %357, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %358 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %358(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.246, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %359 = getelementptr inbounds i64, i64* %63, i64 2
  %360 = load i64, i64* %359, align 8, !tbaa !2554
  %361 = trunc i64 %360 to i32
  %362 = icmp eq i32 %361, 56
  br i1 %362, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %363 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %363(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.247, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %364 = getelementptr inbounds i64, i64* %63, i64 3
  %365 = load i64, i64* %364, align 8, !tbaa !2557
  %366 = trunc i64 %365 to i32
  %367 = icmp eq i32 %366, 56
  br i1 %367, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %368 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %368(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.248, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %369 = getelementptr inbounds i64, i64* %63, i64 4
  %370 = load i64, i64* %369, align 8, !tbaa !2559
  %371 = trunc i64 %370 to i32
  %372 = icmp eq i32 %371, 32
  br i1 %372, label %assert_end118, label %assert_fail117, !prof !5

assert_fail117:                                   ; preds = %assert_end116
  %373 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %373(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.80, i64 0, i64 0))
  ret i32 -1

assert_end118:                                    ; preds = %assert_end116
  %374 = icmp eq i64* %65, null
  br i1 %374, label %if_end120, label %if_then119, !prof !50

if_then119:                                       ; preds = %assert_end118
  %375 = bitcast i64* %65 to <4 x i64>*
  %376 = load <4 x i64>, <4 x i64>* %375, align 8, !tbaa !2563
  %377 = trunc <4 x i64> %376 to <4 x i32>
  %378 = icmp eq <4 x i32> %377, <i32 200704, i32 100352, i32 1792, i32 32>
  %379 = getelementptr inbounds i64, i64* %65, i64 4
  %380 = load i64, i64* %379, align 8, !tbaa !2575
  %381 = trunc i64 %380 to i32
  %382 = icmp eq i32 %381, 1
  %rdx.shuf = shufflevector <4 x i1> %378, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %378, %rdx.shuf
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx, %rdx.shuf129
  %383 = extractelement <4 x i1> %bin.rdx130, i32 0
  %384 = and i1 %383, %382
  br i1 %384, label %if_end120, label %assert_fail121, !prof !5

if_end120:                                        ; preds = %assert_end118, %if_then119
  %385 = getelementptr inbounds %1, %1* %28, i64 0, i32 6
  %386 = load i64, i64* %385, align 8
  %387 = icmp eq i64 %386, 0
  br i1 %387, label %assert_end124, label %assert_fail123, !prof !5

assert_fail121:                                   ; preds = %if_then119
  %388 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %388(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.249, i64 0, i64 0))
  ret i32 -1

assert_fail123:                                   ; preds = %if_end120
  %389 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %389(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.82, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %if_end120
  %390 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 0
  %391 = load i32, i32* %390, align 4
  %392 = icmp eq i32 %391, 1
  br i1 %392, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %393 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %393(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.83, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %394 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 1
  %395 = load i32, i32* %394, align 4
  %396 = icmp eq i32 %41, %395
  br i1 %396, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %397 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %397(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %398 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3_compute_(i8* %33, i8* %43, i8* %61, i8* %49, i8* %55, i32 %41)
  ret i32 %398
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 861184, i32 2, i32 32)
  %8 = alloca %24, align 8
  %9 = getelementptr inbounds %24, %24* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %24, %24* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %24* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.250, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %24, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %25, align 8
  %16 = getelementptr inbounds %25, %25* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %25, %25* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %25, %25* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %25, %25* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %25, %25* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = getelementptr inbounds %25, %25* %15, i64 0, i32 5
  store i32 %5, i32* %21, align 8
  %22 = bitcast %25* %15 to i8*
  %23 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %24 = call i32 %23(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.251, i8* nonnull %22, i32 0)
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %26 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %27 = call i32 %26(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.250(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 57
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 58
  %15 = select i1 %14, i32 %13, i32 58
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 58
  %18 = select i1 %17, i32 %16, i32 58
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 58
  %21 = select i1 %20, i32 %16, i32 58
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -3712
  %23 = add i32 %22, -3712
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv6 = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next7, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv6, 3712
  %29 = trunc i64 %indvars.iv6 to i32
  %.off = add i32 %29, -1
  %30 = icmp ult i32 %.off, 56
  %31 = mul i64 %indvars.iv6, 3584
  %32 = add i64 %31, 4294963648
  br i1 %30, label %for_body2.us, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %33 = mul i32 %indvar, 3712
  %34 = add i32 %23, %33
  %35 = sext i32 %34 to i64
  %scevgep = getelementptr float, float* %4, i64 %35
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 14848, i1 false)
  br label %for_end3

for_body2.us:                                     ; preds = %for_begin1.preheader, %if_end.us
  %indvars.iv = phi i64 [ %indvars.iv.next, %if_end.us ], [ 0, %for_begin1.preheader ]
  %36 = shl nsw i64 %indvars.iv, 6
  %37 = add nsw i64 %36, %28
  %38 = trunc i64 %indvars.iv to i32
  switch i32 %38, label %if_then.us [
    i32 57, label %if_end.us
    i32 0, label %if_end.us
  ]

if_then.us:                                       ; preds = %for_body2.us
  %39 = add i64 %32, %36
  %sext = shl i64 %39, 32
  %40 = ashr exact i64 %sext, 32
  %41 = getelementptr inbounds float, float* %7, i64 %40
  %42 = bitcast float* %41 to <64 x float>*
  %43 = load <64 x float>, <64 x float>* %42, align 64, !tbaa !2579
  br label %if_end.us

if_end.us:                                        ; preds = %if_then.us, %for_body2.us, %for_body2.us
  %44 = phi <64 x float> [ %43, %if_then.us ], [ zeroinitializer, %for_body2.us ], [ zeroinitializer, %for_body2.us ]
  %45 = getelementptr inbounds float, float* %4, i64 %37
  %46 = bitcast float* %45 to <64 x float>*
  store <64 x float> %44, <64 x float>* %46, align 64, !tbaa !2582
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 58
  br i1 %exitcond, label %for_end3, label %for_body2.us, !prof !50

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %if_end.us, %for_body2.preheader
  %indvars.iv.next7 = add nsw i64 %indvars.iv6, 1
  %47 = icmp slt i64 %indvars.iv.next7, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %47, label %for_begin1.preheader, label %for_end, !prof !5
}

define private i32 @__tvm_parallel_lambda.251(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to float**
  %18 = load float*, float** %17, align 8
  %19 = getelementptr inbounds i8, i8* %2, i64 40
  %20 = bitcast i8* %19 to i32*
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, 111
  %25 = sdiv i32 %24, %23
  %26 = add nsw i32 %0, 1
  %27 = mul nsw i32 %25, %26
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = mul nsw i32 %25, %0
  %31 = icmp slt i32 %30, 112
  %32 = select i1 %31, i32 %30, i32 112
  %33 = icmp slt i32 %32, %29
  br i1 %33, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %34 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %35 = bitcast float* %34 to <32 x float>*
  %36 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %37 = bitcast float* %36 to <32 x float>*
  %38 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %39 = bitcast float* %38 to <32 x float>*
  %40 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %41 = bitcast float* %40 to <32 x float>*
  %42 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %43 = bitcast float* %42 to <32 x float>*
  %44 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %45 = bitcast float* %44 to <32 x float>*
  %46 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end15
  %47 = phi i32 [ %32, %for_body.lr.ph ], [ %275, %for_end15 ]
  %48 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %49 = tail call i8* %48(i32 1, i32 %21, i64 7168, i32 2, i32 32)
  %50 = srem i32 %47, 56
  %51 = sdiv i32 %47, 56
  %52 = mul nsw i32 %51, 18432
  %53 = sext i32 %52 to i64
  %54 = mul nsw i32 %50, 3712
  %55 = sext i32 %54 to i64
  %56 = mul nsw i32 %50, 3712
  %57 = add nsw i32 %56, 3712
  %58 = sext i32 %57 to i64
  %59 = add nsw i64 %53, 6144
  %60 = mul nsw i32 %50, 3712
  %61 = add nsw i32 %60, 7424
  %62 = sext i32 %61 to i64
  %63 = add nsw i64 %53, 12288
  br label %for_body2

for_end:                                          ; preds = %for_end15, %entry
  ret i32 0

for_begin13.preheader:                            ; preds = %for_end9.2
  %64 = mul nsw i32 %47, 1792
  %65 = shl nsw i32 %51, 5
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds float, float* %15, i64 %66
  %68 = bitcast float* %67 to <32 x float>*
  %69 = load <32 x float>, <32 x float>* %68, align 64, !tbaa !2585
  %70 = bitcast i8* %49 to float*
  br label %for_begin16.preheader

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %71 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %49, i64 %71
  %72 = mul nuw nsw i64 %indvar, 448
  %73 = add nsw i64 %72, %55
  call void @llvm.memset.p0i8.i64(i8* nonnull align 128 %46, i8 0, i64 896, i1 false)
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %74 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %159, %for_body8 ]
  %75 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %153, %for_body8 ]
  %76 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %152, %for_body8 ]
  %77 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %151, %for_body8 ]
  %78 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %150, %for_body8 ]
  %79 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %149, %for_body8 ]
  %80 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %148, %for_body8 ]
  %81 = add nsw i64 %73, %indvars.iv
  %82 = getelementptr inbounds float, float* %6, i64 %81
  %83 = load float, float* %82, align 4, !tbaa !2582
  %84 = insertelement <32 x float> undef, float %83, i32 0
  %85 = shufflevector <32 x float> %84, <32 x float> undef, <32 x i32> zeroinitializer
  %86 = shl nsw i64 %indvars.iv, 5
  %87 = add nsw i64 %86, %53
  %88 = getelementptr inbounds float, float* %9, i64 %87
  %89 = bitcast float* %88 to <32 x float>*
  %90 = load <32 x float>, <32 x float>* %89, align 64, !tbaa !2588
  %91 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %85, <32 x float> %90, <32 x float> %80)
  %92 = add nsw i64 %81, 64
  %93 = getelementptr inbounds float, float* %6, i64 %92
  %94 = load float, float* %93, align 4, !tbaa !2582
  %95 = insertelement <32 x float> undef, float %94, i32 0
  %96 = shufflevector <32 x float> %95, <32 x float> undef, <32 x i32> zeroinitializer
  %97 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %96, <32 x float> %90, <32 x float> %79)
  %98 = add nsw i64 %81, 128
  %99 = getelementptr inbounds float, float* %6, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !2582
  %101 = insertelement <32 x float> undef, float %100, i32 0
  %102 = shufflevector <32 x float> %101, <32 x float> undef, <32 x i32> zeroinitializer
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %102, <32 x float> %90, <32 x float> %78)
  %104 = add nsw i64 %81, 192
  %105 = getelementptr inbounds float, float* %6, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !2582
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %90, <32 x float> %77)
  %110 = add nsw i64 %81, 256
  %111 = getelementptr inbounds float, float* %6, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !2582
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %90, <32 x float> %76)
  %116 = add nsw i64 %81, 320
  %117 = getelementptr inbounds float, float* %6, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !2582
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %90, <32 x float> %75)
  %122 = add nsw i64 %81, 384
  %123 = getelementptr inbounds float, float* %6, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !2582
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %90, <32 x float> %74)
  %128 = add nsw i64 %87, 2048
  %129 = getelementptr inbounds float, float* %9, i64 %128
  %130 = bitcast float* %129 to <32 x float>*
  %131 = load <32 x float>, <32 x float>* %130, align 64, !tbaa !2588
  %132 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %96, <32 x float> %131, <32 x float> %91)
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %102, <32 x float> %131, <32 x float> %97)
  %134 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %131, <32 x float> %103)
  %135 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %131, <32 x float> %109)
  %136 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %131, <32 x float> %115)
  %137 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %131, <32 x float> %121)
  %138 = add nsw i64 %81, 448
  %139 = getelementptr inbounds float, float* %6, i64 %138
  %140 = load float, float* %139, align 4, !tbaa !2582
  %141 = insertelement <32 x float> undef, float %140, i32 0
  %142 = shufflevector <32 x float> %141, <32 x float> undef, <32 x i32> zeroinitializer
  %143 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %142, <32 x float> %131, <32 x float> %127)
  %144 = add nsw i64 %87, 4096
  %145 = getelementptr inbounds float, float* %9, i64 %144
  %146 = bitcast float* %145 to <32 x float>*
  %147 = load <32 x float>, <32 x float>* %146, align 64, !tbaa !2588
  %148 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %102, <32 x float> %147, <32 x float> %132)
  %149 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %147, <32 x float> %133)
  %150 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %147, <32 x float> %134)
  %151 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %147, <32 x float> %135)
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %147, <32 x float> %136)
  %153 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %142, <32 x float> %147, <32 x float> %137)
  %154 = add nsw i64 %81, 512
  %155 = getelementptr inbounds float, float* %6, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !2582
  %157 = insertelement <32 x float> undef, float %156, i32 0
  %158 = shufflevector <32 x float> %157, <32 x float> undef, <32 x i32> zeroinitializer
  %159 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %147, <32 x float> %143)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %160 = add nsw i64 %72, %58
  br label %for_body8.1

for_begin16.preheader:                            ; preds = %for_begin16.preheader, %for_begin13.preheader
  %indvars.iv65 = phi i64 [ 0, %for_begin13.preheader ], [ %indvars.iv.next66, %for_begin16.preheader ]
  %161 = mul nuw nsw i64 %indvars.iv65, 224
  %162 = trunc i64 %161 to i32
  %163 = add i32 %64, %162
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds float, float* %18, i64 %164
  %166 = bitcast float* %165 to <32 x float>*
  %167 = load <32 x float>, <32 x float>* %166, align 64, !tbaa !2591
  %168 = getelementptr inbounds float, float* %70, i64 %161
  %169 = bitcast float* %168 to <32 x float>*
  %170 = load <32 x float>, <32 x float>* %169, align 64, !tbaa !2594
  %171 = fadd <32 x float> %69, %170
  %172 = fadd <32 x float> %167, %171
  %173 = fcmp ogt <32 x float> %172, zeroinitializer
  %174 = select <32 x i1> %173, <32 x float> %172, <32 x float> zeroinitializer
  %175 = getelementptr inbounds float, float* %12, i64 %164
  %176 = bitcast float* %175 to <32 x float>*
  store <32 x float> %174, <32 x float>* %176, align 64, !tbaa !2597
  %177 = add nuw nsw i64 %161, 32
  %178 = trunc i64 %177 to i32
  %179 = add i32 %64, %178
  %180 = sext i32 %179 to i64
  %181 = getelementptr inbounds float, float* %18, i64 %180
  %182 = bitcast float* %181 to <32 x float>*
  %183 = load <32 x float>, <32 x float>* %182, align 64, !tbaa !2591
  %184 = getelementptr inbounds float, float* %70, i64 %177
  %185 = bitcast float* %184 to <32 x float>*
  %186 = load <32 x float>, <32 x float>* %185, align 64, !tbaa !2594
  %187 = fadd <32 x float> %69, %186
  %188 = fadd <32 x float> %183, %187
  %189 = fcmp ogt <32 x float> %188, zeroinitializer
  %190 = select <32 x i1> %189, <32 x float> %188, <32 x float> zeroinitializer
  %191 = getelementptr inbounds float, float* %12, i64 %180
  %192 = bitcast float* %191 to <32 x float>*
  store <32 x float> %190, <32 x float>* %192, align 64, !tbaa !2597
  %193 = add nuw nsw i64 %161, 64
  %194 = trunc i64 %193 to i32
  %195 = add i32 %64, %194
  %196 = sext i32 %195 to i64
  %197 = getelementptr inbounds float, float* %18, i64 %196
  %198 = bitcast float* %197 to <32 x float>*
  %199 = load <32 x float>, <32 x float>* %198, align 64, !tbaa !2591
  %200 = getelementptr inbounds float, float* %70, i64 %193
  %201 = bitcast float* %200 to <32 x float>*
  %202 = load <32 x float>, <32 x float>* %201, align 64, !tbaa !2594
  %203 = fadd <32 x float> %69, %202
  %204 = fadd <32 x float> %199, %203
  %205 = fcmp ogt <32 x float> %204, zeroinitializer
  %206 = select <32 x i1> %205, <32 x float> %204, <32 x float> zeroinitializer
  %207 = getelementptr inbounds float, float* %12, i64 %196
  %208 = bitcast float* %207 to <32 x float>*
  store <32 x float> %206, <32 x float>* %208, align 64, !tbaa !2597
  %209 = add nuw nsw i64 %161, 96
  %210 = trunc i64 %209 to i32
  %211 = add i32 %64, %210
  %212 = sext i32 %211 to i64
  %213 = getelementptr inbounds float, float* %18, i64 %212
  %214 = bitcast float* %213 to <32 x float>*
  %215 = load <32 x float>, <32 x float>* %214, align 64, !tbaa !2591
  %216 = getelementptr inbounds float, float* %70, i64 %209
  %217 = bitcast float* %216 to <32 x float>*
  %218 = load <32 x float>, <32 x float>* %217, align 64, !tbaa !2594
  %219 = fadd <32 x float> %69, %218
  %220 = fadd <32 x float> %215, %219
  %221 = fcmp ogt <32 x float> %220, zeroinitializer
  %222 = select <32 x i1> %221, <32 x float> %220, <32 x float> zeroinitializer
  %223 = getelementptr inbounds float, float* %12, i64 %212
  %224 = bitcast float* %223 to <32 x float>*
  store <32 x float> %222, <32 x float>* %224, align 64, !tbaa !2597
  %225 = add nuw nsw i64 %161, 128
  %226 = trunc i64 %225 to i32
  %227 = add i32 %64, %226
  %228 = sext i32 %227 to i64
  %229 = getelementptr inbounds float, float* %18, i64 %228
  %230 = bitcast float* %229 to <32 x float>*
  %231 = load <32 x float>, <32 x float>* %230, align 64, !tbaa !2591
  %232 = getelementptr inbounds float, float* %70, i64 %225
  %233 = bitcast float* %232 to <32 x float>*
  %234 = load <32 x float>, <32 x float>* %233, align 64, !tbaa !2594
  %235 = fadd <32 x float> %69, %234
  %236 = fadd <32 x float> %231, %235
  %237 = fcmp ogt <32 x float> %236, zeroinitializer
  %238 = select <32 x i1> %237, <32 x float> %236, <32 x float> zeroinitializer
  %239 = getelementptr inbounds float, float* %12, i64 %228
  %240 = bitcast float* %239 to <32 x float>*
  store <32 x float> %238, <32 x float>* %240, align 64, !tbaa !2597
  %241 = add nuw nsw i64 %161, 160
  %242 = trunc i64 %241 to i32
  %243 = add i32 %64, %242
  %244 = sext i32 %243 to i64
  %245 = getelementptr inbounds float, float* %18, i64 %244
  %246 = bitcast float* %245 to <32 x float>*
  %247 = load <32 x float>, <32 x float>* %246, align 64, !tbaa !2591
  %248 = getelementptr inbounds float, float* %70, i64 %241
  %249 = bitcast float* %248 to <32 x float>*
  %250 = load <32 x float>, <32 x float>* %249, align 64, !tbaa !2594
  %251 = fadd <32 x float> %69, %250
  %252 = fadd <32 x float> %247, %251
  %253 = fcmp ogt <32 x float> %252, zeroinitializer
  %254 = select <32 x i1> %253, <32 x float> %252, <32 x float> zeroinitializer
  %255 = getelementptr inbounds float, float* %12, i64 %244
  %256 = bitcast float* %255 to <32 x float>*
  store <32 x float> %254, <32 x float>* %256, align 64, !tbaa !2597
  %257 = add nuw nsw i64 %161, 192
  %258 = trunc i64 %257 to i32
  %259 = add i32 %64, %258
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds float, float* %18, i64 %260
  %262 = bitcast float* %261 to <32 x float>*
  %263 = load <32 x float>, <32 x float>* %262, align 64, !tbaa !2591
  %264 = getelementptr inbounds float, float* %70, i64 %257
  %265 = bitcast float* %264 to <32 x float>*
  %266 = load <32 x float>, <32 x float>* %265, align 64, !tbaa !2594
  %267 = fadd <32 x float> %69, %266
  %268 = fadd <32 x float> %263, %267
  %269 = fcmp ogt <32 x float> %268, zeroinitializer
  %270 = select <32 x i1> %269, <32 x float> %268, <32 x float> zeroinitializer
  %271 = getelementptr inbounds float, float* %12, i64 %260
  %272 = bitcast float* %271 to <32 x float>*
  store <32 x float> %270, <32 x float>* %272, align 64, !tbaa !2597
  %indvars.iv.next66 = add nuw nsw i64 %indvars.iv65, 1
  %exitcond67 = icmp eq i64 %indvars.iv.next66, 8
  br i1 %exitcond67, label %for_end15, label %for_begin16.preheader, !prof !50

for_end15:                                        ; preds = %for_begin16.preheader
  %273 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %274 = tail call i32 %273(i32 1, i32 %21, i8* nonnull %49)
  %275 = add nsw i32 %47, 1
  %276 = icmp slt i32 %275, %29
  br i1 %276, label %for_body, label %for_end, !prof !5

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %277 = phi <32 x float> [ %159, %for_end9 ], [ %362, %for_body8.1 ]
  %278 = phi <32 x float> [ %153, %for_end9 ], [ %356, %for_body8.1 ]
  %279 = phi <32 x float> [ %152, %for_end9 ], [ %355, %for_body8.1 ]
  %280 = phi <32 x float> [ %151, %for_end9 ], [ %354, %for_body8.1 ]
  %281 = phi <32 x float> [ %150, %for_end9 ], [ %353, %for_body8.1 ]
  %282 = phi <32 x float> [ %149, %for_end9 ], [ %352, %for_body8.1 ]
  %283 = phi <32 x float> [ %148, %for_end9 ], [ %351, %for_body8.1 ]
  %284 = add nsw i64 %160, %indvars.iv.1
  %285 = getelementptr inbounds float, float* %6, i64 %284
  %286 = load float, float* %285, align 4, !tbaa !2582
  %287 = insertelement <32 x float> undef, float %286, i32 0
  %288 = shufflevector <32 x float> %287, <32 x float> undef, <32 x i32> zeroinitializer
  %289 = shl nsw i64 %indvars.iv.1, 5
  %290 = add nsw i64 %59, %289
  %291 = getelementptr inbounds float, float* %9, i64 %290
  %292 = bitcast float* %291 to <32 x float>*
  %293 = load <32 x float>, <32 x float>* %292, align 64, !tbaa !2588
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %288, <32 x float> %293, <32 x float> %283)
  %295 = add nsw i64 %284, 64
  %296 = getelementptr inbounds float, float* %6, i64 %295
  %297 = load float, float* %296, align 4, !tbaa !2582
  %298 = insertelement <32 x float> undef, float %297, i32 0
  %299 = shufflevector <32 x float> %298, <32 x float> undef, <32 x i32> zeroinitializer
  %300 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %299, <32 x float> %293, <32 x float> %282)
  %301 = add nsw i64 %284, 128
  %302 = getelementptr inbounds float, float* %6, i64 %301
  %303 = load float, float* %302, align 4, !tbaa !2582
  %304 = insertelement <32 x float> undef, float %303, i32 0
  %305 = shufflevector <32 x float> %304, <32 x float> undef, <32 x i32> zeroinitializer
  %306 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %293, <32 x float> %281)
  %307 = add nsw i64 %284, 192
  %308 = getelementptr inbounds float, float* %6, i64 %307
  %309 = load float, float* %308, align 4, !tbaa !2582
  %310 = insertelement <32 x float> undef, float %309, i32 0
  %311 = shufflevector <32 x float> %310, <32 x float> undef, <32 x i32> zeroinitializer
  %312 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %311, <32 x float> %293, <32 x float> %280)
  %313 = add nsw i64 %284, 256
  %314 = getelementptr inbounds float, float* %6, i64 %313
  %315 = load float, float* %314, align 4, !tbaa !2582
  %316 = insertelement <32 x float> undef, float %315, i32 0
  %317 = shufflevector <32 x float> %316, <32 x float> undef, <32 x i32> zeroinitializer
  %318 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %317, <32 x float> %293, <32 x float> %279)
  %319 = add nsw i64 %284, 320
  %320 = getelementptr inbounds float, float* %6, i64 %319
  %321 = load float, float* %320, align 4, !tbaa !2582
  %322 = insertelement <32 x float> undef, float %321, i32 0
  %323 = shufflevector <32 x float> %322, <32 x float> undef, <32 x i32> zeroinitializer
  %324 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %323, <32 x float> %293, <32 x float> %278)
  %325 = add nsw i64 %284, 384
  %326 = getelementptr inbounds float, float* %6, i64 %325
  %327 = load float, float* %326, align 4, !tbaa !2582
  %328 = insertelement <32 x float> undef, float %327, i32 0
  %329 = shufflevector <32 x float> %328, <32 x float> undef, <32 x i32> zeroinitializer
  %330 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %329, <32 x float> %293, <32 x float> %277)
  %331 = add nsw i64 %290, 2048
  %332 = getelementptr inbounds float, float* %9, i64 %331
  %333 = bitcast float* %332 to <32 x float>*
  %334 = load <32 x float>, <32 x float>* %333, align 64, !tbaa !2588
  %335 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %299, <32 x float> %334, <32 x float> %294)
  %336 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %334, <32 x float> %300)
  %337 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %311, <32 x float> %334, <32 x float> %306)
  %338 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %317, <32 x float> %334, <32 x float> %312)
  %339 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %323, <32 x float> %334, <32 x float> %318)
  %340 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %329, <32 x float> %334, <32 x float> %324)
  %341 = add nsw i64 %284, 448
  %342 = getelementptr inbounds float, float* %6, i64 %341
  %343 = load float, float* %342, align 4, !tbaa !2582
  %344 = insertelement <32 x float> undef, float %343, i32 0
  %345 = shufflevector <32 x float> %344, <32 x float> undef, <32 x i32> zeroinitializer
  %346 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %345, <32 x float> %334, <32 x float> %330)
  %347 = add nsw i64 %290, 4096
  %348 = getelementptr inbounds float, float* %9, i64 %347
  %349 = bitcast float* %348 to <32 x float>*
  %350 = load <32 x float>, <32 x float>* %349, align 64, !tbaa !2588
  %351 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %305, <32 x float> %350, <32 x float> %335)
  %352 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %311, <32 x float> %350, <32 x float> %336)
  %353 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %317, <32 x float> %350, <32 x float> %337)
  %354 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %323, <32 x float> %350, <32 x float> %338)
  %355 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %329, <32 x float> %350, <32 x float> %339)
  %356 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %345, <32 x float> %350, <32 x float> %340)
  %357 = add nsw i64 %284, 512
  %358 = getelementptr inbounds float, float* %6, i64 %357
  %359 = load float, float* %358, align 4, !tbaa !2582
  %360 = insertelement <32 x float> undef, float %359, i32 0
  %361 = shufflevector <32 x float> %360, <32 x float> undef, <32 x i32> zeroinitializer
  %362 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %361, <32 x float> %350, <32 x float> %346)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 64
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %363 = add nsw i64 %72, %62
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %364 = phi <32 x float> [ %362, %for_end9.1 ], [ %449, %for_body8.2 ]
  %365 = phi <32 x float> [ %356, %for_end9.1 ], [ %443, %for_body8.2 ]
  %366 = phi <32 x float> [ %355, %for_end9.1 ], [ %442, %for_body8.2 ]
  %367 = phi <32 x float> [ %354, %for_end9.1 ], [ %441, %for_body8.2 ]
  %368 = phi <32 x float> [ %353, %for_end9.1 ], [ %440, %for_body8.2 ]
  %369 = phi <32 x float> [ %352, %for_end9.1 ], [ %439, %for_body8.2 ]
  %370 = phi <32 x float> [ %351, %for_end9.1 ], [ %438, %for_body8.2 ]
  %371 = add nsw i64 %363, %indvars.iv.2
  %372 = getelementptr inbounds float, float* %6, i64 %371
  %373 = load float, float* %372, align 4, !tbaa !2582
  %374 = insertelement <32 x float> undef, float %373, i32 0
  %375 = shufflevector <32 x float> %374, <32 x float> undef, <32 x i32> zeroinitializer
  %376 = shl nsw i64 %indvars.iv.2, 5
  %377 = add nsw i64 %63, %376
  %378 = getelementptr inbounds float, float* %9, i64 %377
  %379 = bitcast float* %378 to <32 x float>*
  %380 = load <32 x float>, <32 x float>* %379, align 64, !tbaa !2588
  %381 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %375, <32 x float> %380, <32 x float> %370)
  %382 = add nsw i64 %371, 64
  %383 = getelementptr inbounds float, float* %6, i64 %382
  %384 = load float, float* %383, align 4, !tbaa !2582
  %385 = insertelement <32 x float> undef, float %384, i32 0
  %386 = shufflevector <32 x float> %385, <32 x float> undef, <32 x i32> zeroinitializer
  %387 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %386, <32 x float> %380, <32 x float> %369)
  %388 = add nsw i64 %371, 128
  %389 = getelementptr inbounds float, float* %6, i64 %388
  %390 = load float, float* %389, align 4, !tbaa !2582
  %391 = insertelement <32 x float> undef, float %390, i32 0
  %392 = shufflevector <32 x float> %391, <32 x float> undef, <32 x i32> zeroinitializer
  %393 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %392, <32 x float> %380, <32 x float> %368)
  %394 = add nsw i64 %371, 192
  %395 = getelementptr inbounds float, float* %6, i64 %394
  %396 = load float, float* %395, align 4, !tbaa !2582
  %397 = insertelement <32 x float> undef, float %396, i32 0
  %398 = shufflevector <32 x float> %397, <32 x float> undef, <32 x i32> zeroinitializer
  %399 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %398, <32 x float> %380, <32 x float> %367)
  %400 = add nsw i64 %371, 256
  %401 = getelementptr inbounds float, float* %6, i64 %400
  %402 = load float, float* %401, align 4, !tbaa !2582
  %403 = insertelement <32 x float> undef, float %402, i32 0
  %404 = shufflevector <32 x float> %403, <32 x float> undef, <32 x i32> zeroinitializer
  %405 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %404, <32 x float> %380, <32 x float> %366)
  %406 = add nsw i64 %371, 320
  %407 = getelementptr inbounds float, float* %6, i64 %406
  %408 = load float, float* %407, align 4, !tbaa !2582
  %409 = insertelement <32 x float> undef, float %408, i32 0
  %410 = shufflevector <32 x float> %409, <32 x float> undef, <32 x i32> zeroinitializer
  %411 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %410, <32 x float> %380, <32 x float> %365)
  %412 = add nsw i64 %371, 384
  %413 = getelementptr inbounds float, float* %6, i64 %412
  %414 = load float, float* %413, align 4, !tbaa !2582
  %415 = insertelement <32 x float> undef, float %414, i32 0
  %416 = shufflevector <32 x float> %415, <32 x float> undef, <32 x i32> zeroinitializer
  %417 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %416, <32 x float> %380, <32 x float> %364)
  %418 = add nsw i64 %377, 2048
  %419 = getelementptr inbounds float, float* %9, i64 %418
  %420 = bitcast float* %419 to <32 x float>*
  %421 = load <32 x float>, <32 x float>* %420, align 64, !tbaa !2588
  %422 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %386, <32 x float> %421, <32 x float> %381)
  %423 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %392, <32 x float> %421, <32 x float> %387)
  %424 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %398, <32 x float> %421, <32 x float> %393)
  %425 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %404, <32 x float> %421, <32 x float> %399)
  %426 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %410, <32 x float> %421, <32 x float> %405)
  %427 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %416, <32 x float> %421, <32 x float> %411)
  %428 = add nsw i64 %371, 448
  %429 = getelementptr inbounds float, float* %6, i64 %428
  %430 = load float, float* %429, align 4, !tbaa !2582
  %431 = insertelement <32 x float> undef, float %430, i32 0
  %432 = shufflevector <32 x float> %431, <32 x float> undef, <32 x i32> zeroinitializer
  %433 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %432, <32 x float> %421, <32 x float> %417)
  %434 = add nsw i64 %377, 4096
  %435 = getelementptr inbounds float, float* %9, i64 %434
  %436 = bitcast float* %435 to <32 x float>*
  %437 = load <32 x float>, <32 x float>* %436, align 64, !tbaa !2588
  %438 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %392, <32 x float> %437, <32 x float> %422)
  %439 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %398, <32 x float> %437, <32 x float> %423)
  %440 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %404, <32 x float> %437, <32 x float> %424)
  %441 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %410, <32 x float> %437, <32 x float> %425)
  %442 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %416, <32 x float> %437, <32 x float> %426)
  %443 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %432, <32 x float> %437, <32 x float> %427)
  %444 = add nsw i64 %371, 512
  %445 = getelementptr inbounds float, float* %6, i64 %444
  %446 = load float, float* %445, align 4, !tbaa !2582
  %447 = insertelement <32 x float> undef, float %446, i32 0
  %448 = shufflevector <32 x float> %447, <32 x float> undef, <32 x i32> zeroinitializer
  %449 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %448, <32 x float> %437, <32 x float> %433)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 64
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %438, <32 x float>* %.sub, align 128, !tbaa !2600
  store <32 x float> %439, <32 x float>* %35, align 128, !tbaa !2600
  store <32 x float> %440, <32 x float>* %37, align 128, !tbaa !2600
  store <32 x float> %441, <32 x float>* %39, align 128, !tbaa !2600
  store <32 x float> %442, <32 x float>* %41, align 128, !tbaa !2600
  store <32 x float> %443, <32 x float>* %43, align 128, !tbaa !2600
  store <32 x float> %449, <32 x float>* %45, align 128, !tbaa !2600
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %scevgep, i8* nonnull align 128 %4, i64 896, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond61 = icmp eq i64 %indvar.next, 8
  br i1 %exitcond61, label %for_begin13.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_layout_transform_24(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.252, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !2609
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.253, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !2623
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.254, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !2625
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !2639
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 2
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !2641
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 56
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !2644
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 56
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !2646
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !2650
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 200704, i32 100352, i32 1792, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !2662
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.190, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !2666
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !2680
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 1
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !2682
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 56
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.170, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !2685
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 56
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.171, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !2687
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 64
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.201, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !2691
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 200704, i32 200704, i32 3584, i32 64>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !2703
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.255, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_24_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_24_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %26, align 8
  %3 = getelementptr inbounds %26, %26* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %26, %26* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %26* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.256, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.256(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  %27 = insertelement <16 x i32> undef, i32 %26, i32 0
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %28 = shl i64 %indvars.iv7, 6
  %29 = add nsw i64 %28, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %30 = shl i32 %indvars.iv7.tr, 5
  %31 = insertelement <16 x i32> undef, i32 %30, i32 0
  %32 = add <16 x i32> %31, %27
  %33 = shufflevector <16 x i32> %32, <16 x i32> undef, <16 x i32> zeroinitializer
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %34 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %34, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %35 = shl nsw i64 %indvars.iv, 4
  %36 = add nsw i64 %29, %35
  %37 = trunc i64 %35 to i32
  %38 = insertelement <16 x i32> undef, i32 %37, i32 0
  %39 = trunc i64 %35 to i32
  %40 = or i32 %39, 1
  %41 = insertelement <16 x i32> %38, i32 %40, i32 1
  %42 = trunc i64 %35 to i32
  %43 = or i32 %42, 2
  %44 = insertelement <16 x i32> %41, i32 %43, i32 2
  %45 = trunc i64 %35 to i32
  %46 = or i32 %45, 3
  %47 = insertelement <16 x i32> %44, i32 %46, i32 3
  %48 = trunc i64 %35 to i32
  %49 = or i32 %48, 4
  %50 = insertelement <16 x i32> %47, i32 %49, i32 4
  %51 = trunc i64 %35 to i32
  %52 = or i32 %51, 5
  %53 = insertelement <16 x i32> %50, i32 %52, i32 5
  %54 = trunc i64 %35 to i32
  %55 = or i32 %54, 6
  %56 = insertelement <16 x i32> %53, i32 %55, i32 6
  %57 = trunc i64 %35 to i32
  %58 = or i32 %57, 7
  %59 = insertelement <16 x i32> %56, i32 %58, i32 7
  %60 = trunc i64 %35 to i32
  %61 = or i32 %60, 8
  %62 = insertelement <16 x i32> %59, i32 %61, i32 8
  %63 = trunc i64 %35 to i32
  %64 = or i32 %63, 9
  %65 = insertelement <16 x i32> %62, i32 %64, i32 9
  %66 = trunc i64 %35 to i32
  %67 = or i32 %66, 10
  %68 = insertelement <16 x i32> %65, i32 %67, i32 10
  %69 = trunc i64 %35 to i32
  %70 = or i32 %69, 11
  %71 = insertelement <16 x i32> %68, i32 %70, i32 11
  %72 = trunc i64 %35 to i32
  %73 = or i32 %72, 12
  %74 = insertelement <16 x i32> %71, i32 %73, i32 12
  %75 = trunc i64 %35 to i32
  %76 = or i32 %75, 13
  %77 = insertelement <16 x i32> %74, i32 %76, i32 13
  %78 = trunc i64 %35 to i32
  %79 = or i32 %78, 14
  %80 = insertelement <16 x i32> %77, i32 %79, i32 14
  %81 = trunc i64 %35 to i32
  %82 = or i32 %81, 15
  %83 = insertelement <16 x i32> %80, i32 %82, i32 15
  %84 = sdiv <16 x i32> %83, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %85 = mul <16 x i32> %84, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %86 = sub <16 x i32> %83, %85
  %87 = add nsw <16 x i32> %86, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %88 = icmp sgt <16 x i32> %86, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %89 = select <16 x i1> %88, <16 x i32> %86, <16 x i32> %87
  %not. = xor <16 x i1> %88, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %90 = sext <16 x i1> %not. to <16 x i32>
  %91 = add nsw <16 x i32> %84, %90
  %92 = mul nsw <16 x i32> %91, <i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352>
  %93 = add <16 x i32> %33, %89
  %94 = add <16 x i32> %93, %92
  %95 = extractelement <16 x i32> %94, i64 0
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %7, i64 %96
  %98 = load float, float* %97, align 4, !tbaa !2707
  %99 = insertelement <16 x float> undef, float %98, i32 0
  %100 = extractelement <16 x i32> %94, i64 1
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !2707
  %104 = insertelement <16 x float> %99, float %103, i32 1
  %105 = extractelement <16 x i32> %94, i64 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !2707
  %109 = insertelement <16 x float> %104, float %108, i32 2
  %110 = extractelement <16 x i32> %94, i64 3
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = load float, float* %112, align 4, !tbaa !2707
  %114 = insertelement <16 x float> %109, float %113, i32 3
  %115 = extractelement <16 x i32> %94, i64 4
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !2707
  %119 = insertelement <16 x float> %114, float %118, i32 4
  %120 = extractelement <16 x i32> %94, i64 5
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !2707
  %124 = insertelement <16 x float> %119, float %123, i32 5
  %125 = extractelement <16 x i32> %94, i64 6
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float* %7, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !2707
  %129 = insertelement <16 x float> %124, float %128, i32 6
  %130 = extractelement <16 x i32> %94, i64 7
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %7, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !2707
  %134 = insertelement <16 x float> %129, float %133, i32 7
  %135 = extractelement <16 x i32> %94, i64 8
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = load float, float* %137, align 4, !tbaa !2707
  %139 = insertelement <16 x float> %134, float %138, i32 8
  %140 = extractelement <16 x i32> %94, i64 9
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !2707
  %144 = insertelement <16 x float> %139, float %143, i32 9
  %145 = extractelement <16 x i32> %94, i64 10
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !2707
  %149 = insertelement <16 x float> %144, float %148, i32 10
  %150 = extractelement <16 x i32> %94, i64 11
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !2707
  %154 = insertelement <16 x float> %149, float %153, i32 11
  %155 = extractelement <16 x i32> %94, i64 12
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !2707
  %159 = insertelement <16 x float> %154, float %158, i32 12
  %160 = extractelement <16 x i32> %94, i64 13
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = load float, float* %162, align 4, !tbaa !2707
  %164 = insertelement <16 x float> %159, float %163, i32 13
  %165 = extractelement <16 x i32> %94, i64 14
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !2707
  %169 = insertelement <16 x float> %164, float %168, i32 14
  %170 = extractelement <16 x i32> %94, i64 15
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !2707
  %174 = insertelement <16 x float> %169, float %173, i32 15
  %175 = getelementptr inbounds float, float* %4, i64 %36
  %176 = bitcast float* %175 to <16 x float>*
  store <16 x float> %174, <16 x float>* %176, align 64, !tbaa !2710
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 4
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 56
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_layout_transform_23(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.257, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !2713
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.258, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !2727
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.259, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !2729
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !2743
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 2
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !2745
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 28
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !2748
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 28
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !2750
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 64
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.199, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !2754
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 100352, i32 50176, i32 1792, i32 64>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !2766
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.260, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !2770
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !2784
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 1
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !2786
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 28
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.181, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !2789
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 28
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.182, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !2791
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 128
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !2795
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 100352, i32 100352, i32 3584, i32 128>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !2807
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.211, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_23_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_23_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %27, align 8
  %3 = getelementptr inbounds %27, %27* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %27, %27* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %27* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.261, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.261(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  %27 = insertelement <16 x i32> undef, i32 %26, i32 0
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_end6, %for_begin1.preheader
  %indvars.iv7 = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next8, %for_end6 ]
  %28 = shl i64 %indvars.iv7, 7
  %29 = add nsw i64 %28, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %30 = shl i32 %indvars.iv7.tr, 6
  %31 = insertelement <16 x i32> undef, i32 %30, i32 0
  %32 = add <16 x i32> %31, %27
  %33 = shufflevector <16 x i32> %32, <16 x i32> undef, <16 x i32> zeroinitializer
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %34 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %34, label %for_begin1.preheader, label %for_end, !prof !5

for_body5:                                        ; preds = %for_body5, %for_begin4.preheader
  %indvars.iv = phi i64 [ 0, %for_begin4.preheader ], [ %indvars.iv.next, %for_body5 ]
  %35 = shl nsw i64 %indvars.iv, 4
  %36 = add nsw i64 %29, %35
  %37 = trunc i64 %35 to i32
  %38 = insertelement <16 x i32> undef, i32 %37, i32 0
  %39 = trunc i64 %35 to i32
  %40 = or i32 %39, 1
  %41 = insertelement <16 x i32> %38, i32 %40, i32 1
  %42 = trunc i64 %35 to i32
  %43 = or i32 %42, 2
  %44 = insertelement <16 x i32> %41, i32 %43, i32 2
  %45 = trunc i64 %35 to i32
  %46 = or i32 %45, 3
  %47 = insertelement <16 x i32> %44, i32 %46, i32 3
  %48 = trunc i64 %35 to i32
  %49 = or i32 %48, 4
  %50 = insertelement <16 x i32> %47, i32 %49, i32 4
  %51 = trunc i64 %35 to i32
  %52 = or i32 %51, 5
  %53 = insertelement <16 x i32> %50, i32 %52, i32 5
  %54 = trunc i64 %35 to i32
  %55 = or i32 %54, 6
  %56 = insertelement <16 x i32> %53, i32 %55, i32 6
  %57 = trunc i64 %35 to i32
  %58 = or i32 %57, 7
  %59 = insertelement <16 x i32> %56, i32 %58, i32 7
  %60 = trunc i64 %35 to i32
  %61 = or i32 %60, 8
  %62 = insertelement <16 x i32> %59, i32 %61, i32 8
  %63 = trunc i64 %35 to i32
  %64 = or i32 %63, 9
  %65 = insertelement <16 x i32> %62, i32 %64, i32 9
  %66 = trunc i64 %35 to i32
  %67 = or i32 %66, 10
  %68 = insertelement <16 x i32> %65, i32 %67, i32 10
  %69 = trunc i64 %35 to i32
  %70 = or i32 %69, 11
  %71 = insertelement <16 x i32> %68, i32 %70, i32 11
  %72 = trunc i64 %35 to i32
  %73 = or i32 %72, 12
  %74 = insertelement <16 x i32> %71, i32 %73, i32 12
  %75 = trunc i64 %35 to i32
  %76 = or i32 %75, 13
  %77 = insertelement <16 x i32> %74, i32 %76, i32 13
  %78 = trunc i64 %35 to i32
  %79 = or i32 %78, 14
  %80 = insertelement <16 x i32> %77, i32 %79, i32 14
  %81 = trunc i64 %35 to i32
  %82 = or i32 %81, 15
  %83 = insertelement <16 x i32> %80, i32 %82, i32 15
  %84 = sdiv <16 x i32> %83, <i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64>
  %85 = mul <16 x i32> %84, <i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64>
  %86 = sub <16 x i32> %83, %85
  %87 = add nsw <16 x i32> %86, <i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64>
  %88 = icmp sgt <16 x i32> %86, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %89 = select <16 x i1> %88, <16 x i32> %86, <16 x i32> %87
  %not. = xor <16 x i1> %88, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %90 = sext <16 x i1> %not. to <16 x i32>
  %91 = add nsw <16 x i32> %84, %90
  %92 = mul nsw <16 x i32> %91, <i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176, i32 50176>
  %93 = add <16 x i32> %33, %89
  %94 = add <16 x i32> %93, %92
  %95 = extractelement <16 x i32> %94, i64 0
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %7, i64 %96
  %98 = load float, float* %97, align 4, !tbaa !2811
  %99 = insertelement <16 x float> undef, float %98, i32 0
  %100 = extractelement <16 x i32> %94, i64 1
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !2811
  %104 = insertelement <16 x float> %99, float %103, i32 1
  %105 = extractelement <16 x i32> %94, i64 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !2811
  %109 = insertelement <16 x float> %104, float %108, i32 2
  %110 = extractelement <16 x i32> %94, i64 3
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds float, float* %7, i64 %111
  %113 = load float, float* %112, align 4, !tbaa !2811
  %114 = insertelement <16 x float> %109, float %113, i32 3
  %115 = extractelement <16 x i32> %94, i64 4
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds float, float* %7, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !2811
  %119 = insertelement <16 x float> %114, float %118, i32 4
  %120 = extractelement <16 x i32> %94, i64 5
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !2811
  %124 = insertelement <16 x float> %119, float %123, i32 5
  %125 = extractelement <16 x i32> %94, i64 6
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds float, float* %7, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !2811
  %129 = insertelement <16 x float> %124, float %128, i32 6
  %130 = extractelement <16 x i32> %94, i64 7
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds float, float* %7, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !2811
  %134 = insertelement <16 x float> %129, float %133, i32 7
  %135 = extractelement <16 x i32> %94, i64 8
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = load float, float* %137, align 4, !tbaa !2811
  %139 = insertelement <16 x float> %134, float %138, i32 8
  %140 = extractelement <16 x i32> %94, i64 9
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !2811
  %144 = insertelement <16 x float> %139, float %143, i32 9
  %145 = extractelement <16 x i32> %94, i64 10
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !2811
  %149 = insertelement <16 x float> %144, float %148, i32 10
  %150 = extractelement <16 x i32> %94, i64 11
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !2811
  %154 = insertelement <16 x float> %149, float %153, i32 11
  %155 = extractelement <16 x i32> %94, i64 12
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !2811
  %159 = insertelement <16 x float> %154, float %158, i32 12
  %160 = extractelement <16 x i32> %94, i64 13
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = load float, float* %162, align 4, !tbaa !2811
  %164 = insertelement <16 x float> %159, float %163, i32 13
  %165 = extractelement <16 x i32> %94, i64 14
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !2811
  %169 = insertelement <16 x float> %164, float %168, i32 14
  %170 = extractelement <16 x i32> %94, i64 15
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !2811
  %174 = insertelement <16 x float> %169, float %173, i32 15
  %175 = getelementptr inbounds float, float* %4, i64 %36
  %176 = bitcast float* %175 to <16 x float>*
  store <16 x float> %174, <16 x float>* %176, align 64, !tbaa !2814
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 8
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_begin4.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.262, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !2817
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !2831
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !2834
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.263, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !2836
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.264, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.265, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.266, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !2838
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !2852
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 16
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !2854
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 28
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !2857
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 28
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !2859
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 8
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.156, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !2863
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 100352, i32 6272, i32 224, i32 8>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !2875
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.267, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !2879
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 8
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.268, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !2893
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 16
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.180, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !2895
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 3
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !2898
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 3
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !2900
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 8
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !2904
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !2906
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 36864, i32 2304, i32 768, i32 256>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !2918
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !2922
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([274 x i8], [274 x i8]* @.str.269, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !2924
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !2938
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 8
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.270, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !2940
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !2943
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !2945
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !2949
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 256, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !2961
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.271, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !2965
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !2979
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 8
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.272, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !2981
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 14
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.223, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !2984
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 14
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !2986
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !2990
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 50176, i32 6272, i32 448, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !3002
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.273, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 430592, i32 2, i32 32)
  %7 = alloca %28, align 8
  %8 = getelementptr inbounds %28, %28* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %28, %28* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %28* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.274, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %29, align 8
  %15 = getelementptr inbounds %29, %29* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %29, %29* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %29, %29* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %29, %29* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %29, %29* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %29* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.275, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.274(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 463
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 464
  %15 = select i1 %14, i32 %13, i32 464
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 464
  %18 = select i1 %17, i32 %16, i32 464
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 464
  %21 = select i1 %20, i32 %16, i32 464
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -232
  %23 = add i32 %22, -232
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv, 232
  %29 = trunc i64 %indvars.iv to i32
  %30 = srem i32 %29, 29
  %31 = icmp sgt i32 %30, 0
  %32 = mul nsw i32 %30, 224
  %33 = sdiv i32 %29, 29
  %34 = mul nsw i32 %33, 6272
  %35 = add nsw i32 %32, -232
  %36 = add i32 %35, %34
  br i1 %31, label %if_end.us.28, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %37 = mul i32 %indvar, 232
  %38 = add i32 %23, %37
  %39 = sext i32 %38 to i64
  %scevgep = getelementptr float, float* %4, i64 %39
  %scevgep6 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 32 %scevgep6, i8 0, i64 928, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_body2.preheader, %if_end.us.28
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %40 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %40, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.28:                                     ; preds = %for_begin1.preheader
  %41 = getelementptr inbounds float, float* %4, i64 %28
  %42 = bitcast float* %41 to <8 x float>*
  store <8 x float> zeroinitializer, <8 x float>* %42, align 32, !tbaa !3006
  %43 = add nsw i64 %28, 8
  %44 = add i32 %36, 8
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = bitcast float* %46 to <8 x float>*
  %48 = load <8 x float>, <8 x float>* %47, align 32, !tbaa !3009
  %49 = getelementptr inbounds float, float* %4, i64 %43
  %50 = bitcast float* %49 to <8 x float>*
  store <8 x float> %48, <8 x float>* %50, align 32, !tbaa !3006
  %51 = add nsw i64 %28, 16
  %52 = add i32 %36, 16
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <8 x float>*
  %56 = load <8 x float>, <8 x float>* %55, align 32, !tbaa !3009
  %57 = getelementptr inbounds float, float* %4, i64 %51
  %58 = bitcast float* %57 to <8 x float>*
  store <8 x float> %56, <8 x float>* %58, align 32, !tbaa !3006
  %59 = add nsw i64 %28, 24
  %60 = add i32 %36, 24
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds float, float* %7, i64 %61
  %63 = bitcast float* %62 to <8 x float>*
  %64 = load <8 x float>, <8 x float>* %63, align 32, !tbaa !3009
  %65 = getelementptr inbounds float, float* %4, i64 %59
  %66 = bitcast float* %65 to <8 x float>*
  store <8 x float> %64, <8 x float>* %66, align 32, !tbaa !3006
  %67 = add nsw i64 %28, 32
  %68 = add i32 %36, 32
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to <8 x float>*
  %72 = load <8 x float>, <8 x float>* %71, align 32, !tbaa !3009
  %73 = getelementptr inbounds float, float* %4, i64 %67
  %74 = bitcast float* %73 to <8 x float>*
  store <8 x float> %72, <8 x float>* %74, align 32, !tbaa !3006
  %75 = add nsw i64 %28, 40
  %76 = add i32 %36, 40
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds float, float* %7, i64 %77
  %79 = bitcast float* %78 to <8 x float>*
  %80 = load <8 x float>, <8 x float>* %79, align 32, !tbaa !3009
  %81 = getelementptr inbounds float, float* %4, i64 %75
  %82 = bitcast float* %81 to <8 x float>*
  store <8 x float> %80, <8 x float>* %82, align 32, !tbaa !3006
  %83 = add nsw i64 %28, 48
  %84 = add i32 %36, 48
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds float, float* %7, i64 %85
  %87 = bitcast float* %86 to <8 x float>*
  %88 = load <8 x float>, <8 x float>* %87, align 32, !tbaa !3009
  %89 = getelementptr inbounds float, float* %4, i64 %83
  %90 = bitcast float* %89 to <8 x float>*
  store <8 x float> %88, <8 x float>* %90, align 32, !tbaa !3006
  %91 = add nsw i64 %28, 56
  %92 = add i32 %36, 56
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = bitcast float* %94 to <8 x float>*
  %96 = load <8 x float>, <8 x float>* %95, align 32, !tbaa !3009
  %97 = getelementptr inbounds float, float* %4, i64 %91
  %98 = bitcast float* %97 to <8 x float>*
  store <8 x float> %96, <8 x float>* %98, align 32, !tbaa !3006
  %99 = add nsw i64 %28, 64
  %100 = add i32 %36, 64
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = bitcast float* %102 to <8 x float>*
  %104 = load <8 x float>, <8 x float>* %103, align 32, !tbaa !3009
  %105 = getelementptr inbounds float, float* %4, i64 %99
  %106 = bitcast float* %105 to <8 x float>*
  store <8 x float> %104, <8 x float>* %106, align 32, !tbaa !3006
  %107 = add nsw i64 %28, 72
  %108 = add i32 %36, 72
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to <8 x float>*
  %112 = load <8 x float>, <8 x float>* %111, align 32, !tbaa !3009
  %113 = getelementptr inbounds float, float* %4, i64 %107
  %114 = bitcast float* %113 to <8 x float>*
  store <8 x float> %112, <8 x float>* %114, align 32, !tbaa !3006
  %115 = add nsw i64 %28, 80
  %116 = add i32 %36, 80
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %7, i64 %117
  %119 = bitcast float* %118 to <8 x float>*
  %120 = load <8 x float>, <8 x float>* %119, align 32, !tbaa !3009
  %121 = getelementptr inbounds float, float* %4, i64 %115
  %122 = bitcast float* %121 to <8 x float>*
  store <8 x float> %120, <8 x float>* %122, align 32, !tbaa !3006
  %123 = add nsw i64 %28, 88
  %124 = add i32 %36, 88
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = bitcast float* %126 to <8 x float>*
  %128 = load <8 x float>, <8 x float>* %127, align 32, !tbaa !3009
  %129 = getelementptr inbounds float, float* %4, i64 %123
  %130 = bitcast float* %129 to <8 x float>*
  store <8 x float> %128, <8 x float>* %130, align 32, !tbaa !3006
  %131 = add nsw i64 %28, 96
  %132 = add i32 %36, 96
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds float, float* %7, i64 %133
  %135 = bitcast float* %134 to <8 x float>*
  %136 = load <8 x float>, <8 x float>* %135, align 32, !tbaa !3009
  %137 = getelementptr inbounds float, float* %4, i64 %131
  %138 = bitcast float* %137 to <8 x float>*
  store <8 x float> %136, <8 x float>* %138, align 32, !tbaa !3006
  %139 = add nsw i64 %28, 104
  %140 = add i32 %36, 104
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to <8 x float>*
  %144 = load <8 x float>, <8 x float>* %143, align 32, !tbaa !3009
  %145 = getelementptr inbounds float, float* %4, i64 %139
  %146 = bitcast float* %145 to <8 x float>*
  store <8 x float> %144, <8 x float>* %146, align 32, !tbaa !3006
  %147 = add nsw i64 %28, 112
  %148 = add i32 %36, 112
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <8 x float>*
  %152 = load <8 x float>, <8 x float>* %151, align 32, !tbaa !3009
  %153 = getelementptr inbounds float, float* %4, i64 %147
  %154 = bitcast float* %153 to <8 x float>*
  store <8 x float> %152, <8 x float>* %154, align 32, !tbaa !3006
  %155 = add nsw i64 %28, 120
  %156 = add i32 %36, 120
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds float, float* %7, i64 %157
  %159 = bitcast float* %158 to <8 x float>*
  %160 = load <8 x float>, <8 x float>* %159, align 32, !tbaa !3009
  %161 = getelementptr inbounds float, float* %4, i64 %155
  %162 = bitcast float* %161 to <8 x float>*
  store <8 x float> %160, <8 x float>* %162, align 32, !tbaa !3006
  %163 = add nsw i64 %28, 128
  %164 = add i32 %36, 128
  %165 = sext i32 %164 to i64
  %166 = getelementptr inbounds float, float* %7, i64 %165
  %167 = bitcast float* %166 to <8 x float>*
  %168 = load <8 x float>, <8 x float>* %167, align 32, !tbaa !3009
  %169 = getelementptr inbounds float, float* %4, i64 %163
  %170 = bitcast float* %169 to <8 x float>*
  store <8 x float> %168, <8 x float>* %170, align 32, !tbaa !3006
  %171 = add nsw i64 %28, 136
  %172 = add i32 %36, 136
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to <8 x float>*
  %176 = load <8 x float>, <8 x float>* %175, align 32, !tbaa !3009
  %177 = getelementptr inbounds float, float* %4, i64 %171
  %178 = bitcast float* %177 to <8 x float>*
  store <8 x float> %176, <8 x float>* %178, align 32, !tbaa !3006
  %179 = add nsw i64 %28, 144
  %180 = add i32 %36, 144
  %181 = sext i32 %180 to i64
  %182 = getelementptr inbounds float, float* %7, i64 %181
  %183 = bitcast float* %182 to <8 x float>*
  %184 = load <8 x float>, <8 x float>* %183, align 32, !tbaa !3009
  %185 = getelementptr inbounds float, float* %4, i64 %179
  %186 = bitcast float* %185 to <8 x float>*
  store <8 x float> %184, <8 x float>* %186, align 32, !tbaa !3006
  %187 = add nsw i64 %28, 152
  %188 = add i32 %36, 152
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to <8 x float>*
  %192 = load <8 x float>, <8 x float>* %191, align 32, !tbaa !3009
  %193 = getelementptr inbounds float, float* %4, i64 %187
  %194 = bitcast float* %193 to <8 x float>*
  store <8 x float> %192, <8 x float>* %194, align 32, !tbaa !3006
  %195 = add nsw i64 %28, 160
  %196 = add i32 %36, 160
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds float, float* %7, i64 %197
  %199 = bitcast float* %198 to <8 x float>*
  %200 = load <8 x float>, <8 x float>* %199, align 32, !tbaa !3009
  %201 = getelementptr inbounds float, float* %4, i64 %195
  %202 = bitcast float* %201 to <8 x float>*
  store <8 x float> %200, <8 x float>* %202, align 32, !tbaa !3006
  %203 = add nsw i64 %28, 168
  %204 = add i32 %36, 168
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = bitcast float* %206 to <8 x float>*
  %208 = load <8 x float>, <8 x float>* %207, align 32, !tbaa !3009
  %209 = getelementptr inbounds float, float* %4, i64 %203
  %210 = bitcast float* %209 to <8 x float>*
  store <8 x float> %208, <8 x float>* %210, align 32, !tbaa !3006
  %211 = add nsw i64 %28, 176
  %212 = add i32 %36, 176
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %7, i64 %213
  %215 = bitcast float* %214 to <8 x float>*
  %216 = load <8 x float>, <8 x float>* %215, align 32, !tbaa !3009
  %217 = getelementptr inbounds float, float* %4, i64 %211
  %218 = bitcast float* %217 to <8 x float>*
  store <8 x float> %216, <8 x float>* %218, align 32, !tbaa !3006
  %219 = add nsw i64 %28, 184
  %220 = add i32 %36, 184
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds float, float* %7, i64 %221
  %223 = bitcast float* %222 to <8 x float>*
  %224 = load <8 x float>, <8 x float>* %223, align 32, !tbaa !3009
  %225 = getelementptr inbounds float, float* %4, i64 %219
  %226 = bitcast float* %225 to <8 x float>*
  store <8 x float> %224, <8 x float>* %226, align 32, !tbaa !3006
  %227 = add nsw i64 %28, 192
  %228 = add i32 %36, 192
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to <8 x float>*
  %232 = load <8 x float>, <8 x float>* %231, align 32, !tbaa !3009
  %233 = getelementptr inbounds float, float* %4, i64 %227
  %234 = bitcast float* %233 to <8 x float>*
  store <8 x float> %232, <8 x float>* %234, align 32, !tbaa !3006
  %235 = add nsw i64 %28, 200
  %236 = add i32 %36, 200
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds float, float* %7, i64 %237
  %239 = bitcast float* %238 to <8 x float>*
  %240 = load <8 x float>, <8 x float>* %239, align 32, !tbaa !3009
  %241 = getelementptr inbounds float, float* %4, i64 %235
  %242 = bitcast float* %241 to <8 x float>*
  store <8 x float> %240, <8 x float>* %242, align 32, !tbaa !3006
  %243 = add nsw i64 %28, 208
  %244 = add i32 %36, 208
  %245 = sext i32 %244 to i64
  %246 = getelementptr inbounds float, float* %7, i64 %245
  %247 = bitcast float* %246 to <8 x float>*
  %248 = load <8 x float>, <8 x float>* %247, align 32, !tbaa !3009
  %249 = getelementptr inbounds float, float* %4, i64 %243
  %250 = bitcast float* %249 to <8 x float>*
  store <8 x float> %248, <8 x float>* %250, align 32, !tbaa !3006
  %251 = add nsw i64 %28, 216
  %252 = add i32 %36, 216
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds float, float* %7, i64 %253
  %255 = bitcast float* %254 to <8 x float>*
  %256 = load <8 x float>, <8 x float>* %255, align 32, !tbaa !3009
  %257 = getelementptr inbounds float, float* %4, i64 %251
  %258 = bitcast float* %257 to <8 x float>*
  store <8 x float> %256, <8 x float>* %258, align 32, !tbaa !3006
  %259 = add nsw i64 %28, 224
  %260 = add i32 %36, 224
  %261 = sext i32 %260 to i64
  %262 = getelementptr inbounds float, float* %7, i64 %261
  %263 = bitcast float* %262 to <8 x float>*
  %264 = load <8 x float>, <8 x float>* %263, align 32, !tbaa !3009
  %265 = getelementptr inbounds float, float* %4, i64 %259
  %266 = bitcast float* %265 to <8 x float>*
  store <8 x float> %264, <8 x float>* %266, align 32, !tbaa !3006
  br label %for_end3
}

define private i32 @__tvm_parallel_lambda.275(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = add nsw i32 %20, 111
  %22 = sdiv i32 %21, %20
  %23 = add nsw i32 %0, 1
  %24 = mul nsw i32 %22, %23
  %25 = icmp slt i32 %24, 112
  %26 = select i1 %25, i32 %24, i32 112
  %27 = mul nsw i32 %22, %0
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = icmp slt i32 %29, %26
  br i1 %30, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %31 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %32 = bitcast float* %31 to <32 x float>*
  %33 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %34 = bitcast float* %33 to <32 x float>*
  %35 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %36 = bitcast float* %35 to <32 x float>*
  %37 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %38 = bitcast float* %37 to <32 x float>*
  %39 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %40 = bitcast float* %39 to <32 x float>*
  %41 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %42 = bitcast float* %41 to <32 x float>*
  %43 = add i32 %29, 1
  %44 = sext i32 %43 to i64
  %45 = add nsw i64 %44, -1
  %46 = sext i32 %26 to i64
  %47 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin16.preheader
  %indvars.iv86 = phi i64 [ %45, %for_body.lr.ph ], [ %indvars.iv.next87, %for_begin16.preheader ]
  %48 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %49 = tail call i8* %48(i32 1, i32 %18, i64 1792, i32 2, i32 32)
  %50 = trunc i64 %indvars.iv86 to i32
  %51 = srem i32 %50, 14
  %52 = mul nsw i32 %51, 464
  %53 = sdiv i32 %50, 14
  %54 = mul nsw i32 %53, 36864
  %55 = sext i32 %54 to i64
  %56 = sext i32 %52 to i64
  br label %for_body2

for_end:                                          ; preds = %for_begin16.preheader, %entry
  ret i32 0

for_begin16.preheader:                            ; preds = %for_begin13.preheader
  %57 = mul nsw i64 %indvars.iv86, 448
  %58 = shl nsw i32 %53, 5
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds float, float* %15, i64 %59
  %61 = bitcast float* %60 to <32 x float>*
  %62 = load <32 x float>, <32 x float>* %61, align 64, !tbaa !3012
  %63 = bitcast i8* %49 to <32 x float>*
  %64 = load <32 x float>, <32 x float>* %63, align 64, !tbaa !3015
  %65 = fadd <32 x float> %62, %64
  %66 = fcmp ogt <32 x float> %65, zeroinitializer
  %67 = select <32 x i1> %66, <32 x float> %65, <32 x float> zeroinitializer
  %68 = getelementptr inbounds float, float* %12, i64 %57
  %69 = bitcast float* %68 to <32 x float>*
  store <32 x float> %67, <32 x float>* %69, align 64, !tbaa !3018
  %70 = getelementptr inbounds i8, i8* %49, i64 128
  %71 = bitcast i8* %70 to <32 x float>*
  %72 = load <32 x float>, <32 x float>* %71, align 64, !tbaa !3015
  %73 = fadd <32 x float> %62, %72
  %74 = fcmp ogt <32 x float> %73, zeroinitializer
  %75 = select <32 x i1> %74, <32 x float> %73, <32 x float> zeroinitializer
  %76 = mul i64 %indvars.iv86, 1924145348608
  %sext = ashr exact i64 %76, 32
  %77 = or i64 %sext, 32
  %78 = getelementptr inbounds float, float* %12, i64 %77
  %79 = bitcast float* %78 to <32 x float>*
  store <32 x float> %75, <32 x float>* %79, align 64, !tbaa !3018
  %80 = getelementptr inbounds i8, i8* %49, i64 256
  %81 = bitcast i8* %80 to <32 x float>*
  %82 = load <32 x float>, <32 x float>* %81, align 64, !tbaa !3015
  %83 = fadd <32 x float> %62, %82
  %84 = fcmp ogt <32 x float> %83, zeroinitializer
  %85 = select <32 x i1> %84, <32 x float> %83, <32 x float> zeroinitializer
  %86 = mul i64 %indvars.iv86, 1924145348608
  %sext88 = add i64 %86, 274877906944
  %87 = ashr exact i64 %sext88, 32
  %88 = getelementptr inbounds float, float* %12, i64 %87
  %89 = bitcast float* %88 to <32 x float>*
  store <32 x float> %85, <32 x float>* %89, align 64, !tbaa !3018
  %90 = getelementptr inbounds i8, i8* %49, i64 384
  %91 = bitcast i8* %90 to <32 x float>*
  %92 = load <32 x float>, <32 x float>* %91, align 64, !tbaa !3015
  %93 = fadd <32 x float> %62, %92
  %94 = fcmp ogt <32 x float> %93, zeroinitializer
  %95 = select <32 x i1> %94, <32 x float> %93, <32 x float> zeroinitializer
  %96 = mul i64 %indvars.iv86, 1924145348608
  %sext89 = add i64 %96, 412316860416
  %97 = ashr exact i64 %sext89, 32
  %98 = getelementptr inbounds float, float* %12, i64 %97
  %99 = bitcast float* %98 to <32 x float>*
  store <32 x float> %95, <32 x float>* %99, align 64, !tbaa !3018
  %100 = getelementptr inbounds i8, i8* %49, i64 512
  %101 = bitcast i8* %100 to <32 x float>*
  %102 = load <32 x float>, <32 x float>* %101, align 64, !tbaa !3015
  %103 = fadd <32 x float> %62, %102
  %104 = fcmp ogt <32 x float> %103, zeroinitializer
  %105 = select <32 x i1> %104, <32 x float> %103, <32 x float> zeroinitializer
  %106 = mul i64 %indvars.iv86, 1924145348608
  %sext90 = add i64 %106, 549755813888
  %107 = ashr exact i64 %sext90, 32
  %108 = getelementptr inbounds float, float* %12, i64 %107
  %109 = bitcast float* %108 to <32 x float>*
  store <32 x float> %105, <32 x float>* %109, align 64, !tbaa !3018
  %110 = getelementptr inbounds i8, i8* %49, i64 640
  %111 = bitcast i8* %110 to <32 x float>*
  %112 = load <32 x float>, <32 x float>* %111, align 64, !tbaa !3015
  %113 = fadd <32 x float> %62, %112
  %114 = fcmp ogt <32 x float> %113, zeroinitializer
  %115 = select <32 x i1> %114, <32 x float> %113, <32 x float> zeroinitializer
  %116 = mul i64 %indvars.iv86, 1924145348608
  %sext91 = add i64 %116, 687194767360
  %117 = ashr exact i64 %sext91, 32
  %118 = getelementptr inbounds float, float* %12, i64 %117
  %119 = bitcast float* %118 to <32 x float>*
  store <32 x float> %115, <32 x float>* %119, align 64, !tbaa !3018
  %120 = getelementptr inbounds i8, i8* %49, i64 768
  %121 = bitcast i8* %120 to <32 x float>*
  %122 = load <32 x float>, <32 x float>* %121, align 64, !tbaa !3015
  %123 = fadd <32 x float> %62, %122
  %124 = fcmp ogt <32 x float> %123, zeroinitializer
  %125 = select <32 x i1> %124, <32 x float> %123, <32 x float> zeroinitializer
  %126 = mul i64 %indvars.iv86, 1924145348608
  %sext92 = add i64 %126, 824633720832
  %127 = ashr exact i64 %sext92, 32
  %128 = getelementptr inbounds float, float* %12, i64 %127
  %129 = bitcast float* %128 to <32 x float>*
  store <32 x float> %125, <32 x float>* %129, align 64, !tbaa !3018
  %130 = getelementptr inbounds i8, i8* %49, i64 896
  %131 = bitcast i8* %130 to <32 x float>*
  %132 = load <32 x float>, <32 x float>* %131, align 64, !tbaa !3015
  %133 = fadd <32 x float> %62, %132
  %134 = fcmp ogt <32 x float> %133, zeroinitializer
  %135 = select <32 x i1> %134, <32 x float> %133, <32 x float> zeroinitializer
  %136 = mul i64 %indvars.iv86, 1924145348608
  %sext93 = add i64 %136, 962072674304
  %137 = ashr exact i64 %sext93, 32
  %138 = getelementptr inbounds float, float* %12, i64 %137
  %139 = bitcast float* %138 to <32 x float>*
  store <32 x float> %135, <32 x float>* %139, align 64, !tbaa !3018
  %140 = getelementptr inbounds i8, i8* %49, i64 1024
  %141 = bitcast i8* %140 to <32 x float>*
  %142 = load <32 x float>, <32 x float>* %141, align 64, !tbaa !3015
  %143 = fadd <32 x float> %62, %142
  %144 = fcmp ogt <32 x float> %143, zeroinitializer
  %145 = select <32 x i1> %144, <32 x float> %143, <32 x float> zeroinitializer
  %146 = mul i64 %indvars.iv86, 1924145348608
  %sext94 = add i64 %146, 1099511627776
  %147 = ashr exact i64 %sext94, 32
  %148 = getelementptr inbounds float, float* %12, i64 %147
  %149 = bitcast float* %148 to <32 x float>*
  store <32 x float> %145, <32 x float>* %149, align 64, !tbaa !3018
  %150 = getelementptr inbounds i8, i8* %49, i64 1152
  %151 = bitcast i8* %150 to <32 x float>*
  %152 = load <32 x float>, <32 x float>* %151, align 64, !tbaa !3015
  %153 = fadd <32 x float> %62, %152
  %154 = fcmp ogt <32 x float> %153, zeroinitializer
  %155 = select <32 x i1> %154, <32 x float> %153, <32 x float> zeroinitializer
  %156 = mul i64 %indvars.iv86, 1924145348608
  %sext95 = add i64 %156, 1236950581248
  %157 = ashr exact i64 %sext95, 32
  %158 = getelementptr inbounds float, float* %12, i64 %157
  %159 = bitcast float* %158 to <32 x float>*
  store <32 x float> %155, <32 x float>* %159, align 64, !tbaa !3018
  %160 = getelementptr inbounds i8, i8* %49, i64 1280
  %161 = bitcast i8* %160 to <32 x float>*
  %162 = load <32 x float>, <32 x float>* %161, align 64, !tbaa !3015
  %163 = fadd <32 x float> %62, %162
  %164 = fcmp ogt <32 x float> %163, zeroinitializer
  %165 = select <32 x i1> %164, <32 x float> %163, <32 x float> zeroinitializer
  %166 = mul i64 %indvars.iv86, 1924145348608
  %sext96 = add i64 %166, 1374389534720
  %167 = ashr exact i64 %sext96, 32
  %168 = getelementptr inbounds float, float* %12, i64 %167
  %169 = bitcast float* %168 to <32 x float>*
  store <32 x float> %165, <32 x float>* %169, align 64, !tbaa !3018
  %170 = getelementptr inbounds i8, i8* %49, i64 1408
  %171 = bitcast i8* %170 to <32 x float>*
  %172 = load <32 x float>, <32 x float>* %171, align 64, !tbaa !3015
  %173 = fadd <32 x float> %62, %172
  %174 = fcmp ogt <32 x float> %173, zeroinitializer
  %175 = select <32 x i1> %174, <32 x float> %173, <32 x float> zeroinitializer
  %176 = mul i64 %indvars.iv86, 1924145348608
  %sext97 = add i64 %176, 1511828488192
  %177 = ashr exact i64 %sext97, 32
  %178 = getelementptr inbounds float, float* %12, i64 %177
  %179 = bitcast float* %178 to <32 x float>*
  store <32 x float> %175, <32 x float>* %179, align 64, !tbaa !3018
  %180 = getelementptr inbounds i8, i8* %49, i64 1536
  %181 = bitcast i8* %180 to <32 x float>*
  %182 = load <32 x float>, <32 x float>* %181, align 64, !tbaa !3015
  %183 = fadd <32 x float> %62, %182
  %184 = fcmp ogt <32 x float> %183, zeroinitializer
  %185 = select <32 x i1> %184, <32 x float> %183, <32 x float> zeroinitializer
  %186 = mul i64 %indvars.iv86, 1924145348608
  %sext98 = add i64 %186, 1649267441664
  %187 = ashr exact i64 %sext98, 32
  %188 = getelementptr inbounds float, float* %12, i64 %187
  %189 = bitcast float* %188 to <32 x float>*
  store <32 x float> %185, <32 x float>* %189, align 64, !tbaa !3018
  %190 = getelementptr inbounds i8, i8* %49, i64 1664
  %191 = bitcast i8* %190 to <32 x float>*
  %192 = load <32 x float>, <32 x float>* %191, align 64, !tbaa !3015
  %193 = fadd <32 x float> %62, %192
  %194 = fcmp ogt <32 x float> %193, zeroinitializer
  %195 = select <32 x i1> %194, <32 x float> %193, <32 x float> zeroinitializer
  %196 = mul i64 %indvars.iv86, 1924145348608
  %sext99 = add i64 %196, 1786706395136
  %197 = ashr exact i64 %sext99, 32
  %198 = getelementptr inbounds float, float* %12, i64 %197
  %199 = bitcast float* %198 to <32 x float>*
  store <32 x float> %195, <32 x float>* %199, align 64, !tbaa !3018
  %200 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %201 = tail call i32 %200(i32 1, i32 %18, i8* nonnull %49)
  %indvars.iv.next87 = add nsw i64 %indvars.iv86, 1
  %202 = icmp slt i64 %indvars.iv.next87, %46
  br i1 %202, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_begin13.preheader, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_begin13.preheader ]
  %203 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %49, i64 %203
  %204 = mul nuw nsw i64 %indvar, 112
  %205 = add nsw i64 %204, %56
  call void @llvm.memset.p0i8.i64(i8* nonnull align 128 %47, i8 0, i64 896, i1 false)
  br label %for_begin7.preheader

for_begin13.preheader:                            ; preds = %for_end12.2
  store <32 x float> %550, <32 x float>* %.sub, align 128, !tbaa !3021
  store <32 x float> %551, <32 x float>* %32, align 128, !tbaa !3021
  store <32 x float> %552, <32 x float>* %34, align 128, !tbaa !3021
  store <32 x float> %553, <32 x float>* %36, align 128, !tbaa !3021
  store <32 x float> %554, <32 x float>* %38, align 128, !tbaa !3021
  store <32 x float> %555, <32 x float>* %40, align 128, !tbaa !3021
  store <32 x float> %561, <32 x float>* %42, align 128, !tbaa !3021
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %scevgep, i8* nonnull align 128 %4, i64 896, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond79 = icmp eq i64 %indvar.next, 2
  br i1 %exitcond79, label %for_begin16.preheader, label %for_body2, !prof !50

for_begin7.preheader:                             ; preds = %for_end12.2, %for_body2
  %indvars.iv73 = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next74, %for_end12.2 ]
  %.lcssa38.lcssa63 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %561, %for_end12.2 ]
  %.lcssa36.lcssa61 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %555, %for_end12.2 ]
  %.lcssa34.lcssa59 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %554, %for_end12.2 ]
  %.lcssa32.lcssa57 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %553, %for_end12.2 ]
  %.lcssa30.lcssa56 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %552, %for_end12.2 ]
  %.lcssa28.lcssa54 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %551, %for_end12.2 ]
  %.lcssa.lcssa52 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %550, %for_end12.2 ]
  %206 = mul nuw nsw i64 %indvars.iv73, 6728
  %207 = add nsw i64 %205, %206
  %208 = mul nuw nsw i64 %indvars.iv73, 2304
  %209 = add nsw i64 %208, %55
  br label %for_body11

for_body11:                                       ; preds = %for_body11, %for_begin7.preheader
  %indvars.iv = phi i64 [ 0, %for_begin7.preheader ], [ %indvars.iv.next, %for_body11 ]
  %210 = phi <32 x float> [ %.lcssa38.lcssa63, %for_begin7.preheader ], [ %325, %for_body11 ]
  %211 = phi <32 x float> [ %.lcssa36.lcssa61, %for_begin7.preheader ], [ %319, %for_body11 ]
  %212 = phi <32 x float> [ %.lcssa34.lcssa59, %for_begin7.preheader ], [ %318, %for_body11 ]
  %213 = phi <32 x float> [ %.lcssa32.lcssa57, %for_begin7.preheader ], [ %317, %for_body11 ]
  %214 = phi <32 x float> [ %.lcssa30.lcssa56, %for_begin7.preheader ], [ %316, %for_body11 ]
  %215 = phi <32 x float> [ %.lcssa28.lcssa54, %for_begin7.preheader ], [ %315, %for_body11 ]
  %216 = phi <32 x float> [ %.lcssa.lcssa52, %for_begin7.preheader ], [ %314, %for_body11 ]
  %217 = add nsw i64 %207, %indvars.iv
  %218 = getelementptr inbounds float, float* %6, i64 %217
  %219 = load float, float* %218, align 4, !tbaa !3006
  %220 = insertelement <32 x float> undef, float %219, i32 0
  %221 = shufflevector <32 x float> %220, <32 x float> undef, <32 x i32> zeroinitializer
  %222 = shl nsw i64 %indvars.iv, 5
  %223 = add nsw i64 %209, %222
  %224 = getelementptr inbounds float, float* %9, i64 %223
  %225 = bitcast float* %224 to <32 x float>*
  %226 = load <32 x float>, <32 x float>* %225, align 64, !tbaa !3030
  %227 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %221, <32 x float> %226, <32 x float> %216)
  %228 = add nsw i64 %217, 16
  %229 = getelementptr inbounds float, float* %6, i64 %228
  %230 = load float, float* %229, align 4, !tbaa !3006
  %231 = insertelement <32 x float> undef, float %230, i32 0
  %232 = shufflevector <32 x float> %231, <32 x float> undef, <32 x i32> zeroinitializer
  %233 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %232, <32 x float> %226, <32 x float> %215)
  %234 = add nsw i64 %217, 32
  %235 = getelementptr inbounds float, float* %6, i64 %234
  %236 = load float, float* %235, align 4, !tbaa !3006
  %237 = insertelement <32 x float> undef, float %236, i32 0
  %238 = shufflevector <32 x float> %237, <32 x float> undef, <32 x i32> zeroinitializer
  %239 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %238, <32 x float> %226, <32 x float> %214)
  %240 = add nsw i64 %217, 48
  %241 = getelementptr inbounds float, float* %6, i64 %240
  %242 = load float, float* %241, align 4, !tbaa !3006
  %243 = insertelement <32 x float> undef, float %242, i32 0
  %244 = shufflevector <32 x float> %243, <32 x float> undef, <32 x i32> zeroinitializer
  %245 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %244, <32 x float> %226, <32 x float> %213)
  %246 = add nsw i64 %217, 64
  %247 = getelementptr inbounds float, float* %6, i64 %246
  %248 = load float, float* %247, align 4, !tbaa !3006
  %249 = insertelement <32 x float> undef, float %248, i32 0
  %250 = shufflevector <32 x float> %249, <32 x float> undef, <32 x i32> zeroinitializer
  %251 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %250, <32 x float> %226, <32 x float> %212)
  %252 = add nsw i64 %217, 80
  %253 = getelementptr inbounds float, float* %6, i64 %252
  %254 = load float, float* %253, align 4, !tbaa !3006
  %255 = insertelement <32 x float> undef, float %254, i32 0
  %256 = shufflevector <32 x float> %255, <32 x float> undef, <32 x i32> zeroinitializer
  %257 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %256, <32 x float> %226, <32 x float> %211)
  %258 = add nsw i64 %217, 96
  %259 = getelementptr inbounds float, float* %6, i64 %258
  %260 = load float, float* %259, align 4, !tbaa !3006
  %261 = insertelement <32 x float> undef, float %260, i32 0
  %262 = shufflevector <32 x float> %261, <32 x float> undef, <32 x i32> zeroinitializer
  %263 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %262, <32 x float> %226, <32 x float> %210)
  %264 = add nsw i64 %217, 8
  %265 = getelementptr inbounds float, float* %6, i64 %264
  %266 = load float, float* %265, align 4, !tbaa !3006
  %267 = insertelement <32 x float> undef, float %266, i32 0
  %268 = shufflevector <32 x float> %267, <32 x float> undef, <32 x i32> zeroinitializer
  %269 = add nsw i64 %223, 256
  %270 = getelementptr inbounds float, float* %9, i64 %269
  %271 = bitcast float* %270 to <32 x float>*
  %272 = load <32 x float>, <32 x float>* %271, align 64, !tbaa !3030
  %273 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %268, <32 x float> %272, <32 x float> %227)
  %274 = add nsw i64 %217, 24
  %275 = getelementptr inbounds float, float* %6, i64 %274
  %276 = load float, float* %275, align 4, !tbaa !3006
  %277 = insertelement <32 x float> undef, float %276, i32 0
  %278 = shufflevector <32 x float> %277, <32 x float> undef, <32 x i32> zeroinitializer
  %279 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %278, <32 x float> %272, <32 x float> %233)
  %280 = add nsw i64 %217, 40
  %281 = getelementptr inbounds float, float* %6, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !3006
  %283 = insertelement <32 x float> undef, float %282, i32 0
  %284 = shufflevector <32 x float> %283, <32 x float> undef, <32 x i32> zeroinitializer
  %285 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %284, <32 x float> %272, <32 x float> %239)
  %286 = add nsw i64 %217, 56
  %287 = getelementptr inbounds float, float* %6, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !3006
  %289 = insertelement <32 x float> undef, float %288, i32 0
  %290 = shufflevector <32 x float> %289, <32 x float> undef, <32 x i32> zeroinitializer
  %291 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %290, <32 x float> %272, <32 x float> %245)
  %292 = add nsw i64 %217, 72
  %293 = getelementptr inbounds float, float* %6, i64 %292
  %294 = load float, float* %293, align 4, !tbaa !3006
  %295 = insertelement <32 x float> undef, float %294, i32 0
  %296 = shufflevector <32 x float> %295, <32 x float> undef, <32 x i32> zeroinitializer
  %297 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %296, <32 x float> %272, <32 x float> %251)
  %298 = add nsw i64 %217, 88
  %299 = getelementptr inbounds float, float* %6, i64 %298
  %300 = load float, float* %299, align 4, !tbaa !3006
  %301 = insertelement <32 x float> undef, float %300, i32 0
  %302 = shufflevector <32 x float> %301, <32 x float> undef, <32 x i32> zeroinitializer
  %303 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %302, <32 x float> %272, <32 x float> %257)
  %304 = add nsw i64 %217, 104
  %305 = getelementptr inbounds float, float* %6, i64 %304
  %306 = load float, float* %305, align 4, !tbaa !3006
  %307 = insertelement <32 x float> undef, float %306, i32 0
  %308 = shufflevector <32 x float> %307, <32 x float> undef, <32 x i32> zeroinitializer
  %309 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %308, <32 x float> %272, <32 x float> %263)
  %310 = add nsw i64 %223, 512
  %311 = getelementptr inbounds float, float* %9, i64 %310
  %312 = bitcast float* %311 to <32 x float>*
  %313 = load <32 x float>, <32 x float>* %312, align 64, !tbaa !3030
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %232, <32 x float> %313, <32 x float> %273)
  %315 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %238, <32 x float> %313, <32 x float> %279)
  %316 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %244, <32 x float> %313, <32 x float> %285)
  %317 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %250, <32 x float> %313, <32 x float> %291)
  %318 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %256, <32 x float> %313, <32 x float> %297)
  %319 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %262, <32 x float> %313, <32 x float> %303)
  %320 = add nsw i64 %217, 112
  %321 = getelementptr inbounds float, float* %6, i64 %320
  %322 = load float, float* %321, align 4, !tbaa !3006
  %323 = insertelement <32 x float> undef, float %322, i32 0
  %324 = shufflevector <32 x float> %323, <32 x float> undef, <32 x i32> zeroinitializer
  %325 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %324, <32 x float> %313, <32 x float> %309)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 8
  br i1 %exitcond, label %for_end12, label %for_body11, !prof !50

for_end12:                                        ; preds = %for_body11
  %326 = add nsw i64 %207, 232
  %327 = add nsw i64 %209, 768
  br label %for_body11.1

for_body11.1:                                     ; preds = %for_body11.1, %for_end12
  %indvars.iv.1 = phi i64 [ 0, %for_end12 ], [ %indvars.iv.next.1, %for_body11.1 ]
  %328 = phi <32 x float> [ %325, %for_end12 ], [ %443, %for_body11.1 ]
  %329 = phi <32 x float> [ %319, %for_end12 ], [ %437, %for_body11.1 ]
  %330 = phi <32 x float> [ %318, %for_end12 ], [ %436, %for_body11.1 ]
  %331 = phi <32 x float> [ %317, %for_end12 ], [ %435, %for_body11.1 ]
  %332 = phi <32 x float> [ %316, %for_end12 ], [ %434, %for_body11.1 ]
  %333 = phi <32 x float> [ %315, %for_end12 ], [ %433, %for_body11.1 ]
  %334 = phi <32 x float> [ %314, %for_end12 ], [ %432, %for_body11.1 ]
  %335 = add nsw i64 %326, %indvars.iv.1
  %336 = getelementptr inbounds float, float* %6, i64 %335
  %337 = load float, float* %336, align 4, !tbaa !3006
  %338 = insertelement <32 x float> undef, float %337, i32 0
  %339 = shufflevector <32 x float> %338, <32 x float> undef, <32 x i32> zeroinitializer
  %340 = shl nsw i64 %indvars.iv.1, 5
  %341 = add nsw i64 %327, %340
  %342 = getelementptr inbounds float, float* %9, i64 %341
  %343 = bitcast float* %342 to <32 x float>*
  %344 = load <32 x float>, <32 x float>* %343, align 64, !tbaa !3030
  %345 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %339, <32 x float> %344, <32 x float> %334)
  %346 = add nsw i64 %335, 16
  %347 = getelementptr inbounds float, float* %6, i64 %346
  %348 = load float, float* %347, align 4, !tbaa !3006
  %349 = insertelement <32 x float> undef, float %348, i32 0
  %350 = shufflevector <32 x float> %349, <32 x float> undef, <32 x i32> zeroinitializer
  %351 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %350, <32 x float> %344, <32 x float> %333)
  %352 = add nsw i64 %335, 32
  %353 = getelementptr inbounds float, float* %6, i64 %352
  %354 = load float, float* %353, align 4, !tbaa !3006
  %355 = insertelement <32 x float> undef, float %354, i32 0
  %356 = shufflevector <32 x float> %355, <32 x float> undef, <32 x i32> zeroinitializer
  %357 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %356, <32 x float> %344, <32 x float> %332)
  %358 = add nsw i64 %335, 48
  %359 = getelementptr inbounds float, float* %6, i64 %358
  %360 = load float, float* %359, align 4, !tbaa !3006
  %361 = insertelement <32 x float> undef, float %360, i32 0
  %362 = shufflevector <32 x float> %361, <32 x float> undef, <32 x i32> zeroinitializer
  %363 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %362, <32 x float> %344, <32 x float> %331)
  %364 = add nsw i64 %335, 64
  %365 = getelementptr inbounds float, float* %6, i64 %364
  %366 = load float, float* %365, align 4, !tbaa !3006
  %367 = insertelement <32 x float> undef, float %366, i32 0
  %368 = shufflevector <32 x float> %367, <32 x float> undef, <32 x i32> zeroinitializer
  %369 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %368, <32 x float> %344, <32 x float> %330)
  %370 = add nsw i64 %335, 80
  %371 = getelementptr inbounds float, float* %6, i64 %370
  %372 = load float, float* %371, align 4, !tbaa !3006
  %373 = insertelement <32 x float> undef, float %372, i32 0
  %374 = shufflevector <32 x float> %373, <32 x float> undef, <32 x i32> zeroinitializer
  %375 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %374, <32 x float> %344, <32 x float> %329)
  %376 = add nsw i64 %335, 96
  %377 = getelementptr inbounds float, float* %6, i64 %376
  %378 = load float, float* %377, align 4, !tbaa !3006
  %379 = insertelement <32 x float> undef, float %378, i32 0
  %380 = shufflevector <32 x float> %379, <32 x float> undef, <32 x i32> zeroinitializer
  %381 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %380, <32 x float> %344, <32 x float> %328)
  %382 = add nsw i64 %335, 8
  %383 = getelementptr inbounds float, float* %6, i64 %382
  %384 = load float, float* %383, align 4, !tbaa !3006
  %385 = insertelement <32 x float> undef, float %384, i32 0
  %386 = shufflevector <32 x float> %385, <32 x float> undef, <32 x i32> zeroinitializer
  %387 = add nsw i64 %341, 256
  %388 = getelementptr inbounds float, float* %9, i64 %387
  %389 = bitcast float* %388 to <32 x float>*
  %390 = load <32 x float>, <32 x float>* %389, align 64, !tbaa !3030
  %391 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %386, <32 x float> %390, <32 x float> %345)
  %392 = add nsw i64 %335, 24
  %393 = getelementptr inbounds float, float* %6, i64 %392
  %394 = load float, float* %393, align 4, !tbaa !3006
  %395 = insertelement <32 x float> undef, float %394, i32 0
  %396 = shufflevector <32 x float> %395, <32 x float> undef, <32 x i32> zeroinitializer
  %397 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %396, <32 x float> %390, <32 x float> %351)
  %398 = add nsw i64 %335, 40
  %399 = getelementptr inbounds float, float* %6, i64 %398
  %400 = load float, float* %399, align 4, !tbaa !3006
  %401 = insertelement <32 x float> undef, float %400, i32 0
  %402 = shufflevector <32 x float> %401, <32 x float> undef, <32 x i32> zeroinitializer
  %403 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %402, <32 x float> %390, <32 x float> %357)
  %404 = add nsw i64 %335, 56
  %405 = getelementptr inbounds float, float* %6, i64 %404
  %406 = load float, float* %405, align 4, !tbaa !3006
  %407 = insertelement <32 x float> undef, float %406, i32 0
  %408 = shufflevector <32 x float> %407, <32 x float> undef, <32 x i32> zeroinitializer
  %409 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %408, <32 x float> %390, <32 x float> %363)
  %410 = add nsw i64 %335, 72
  %411 = getelementptr inbounds float, float* %6, i64 %410
  %412 = load float, float* %411, align 4, !tbaa !3006
  %413 = insertelement <32 x float> undef, float %412, i32 0
  %414 = shufflevector <32 x float> %413, <32 x float> undef, <32 x i32> zeroinitializer
  %415 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %414, <32 x float> %390, <32 x float> %369)
  %416 = add nsw i64 %335, 88
  %417 = getelementptr inbounds float, float* %6, i64 %416
  %418 = load float, float* %417, align 4, !tbaa !3006
  %419 = insertelement <32 x float> undef, float %418, i32 0
  %420 = shufflevector <32 x float> %419, <32 x float> undef, <32 x i32> zeroinitializer
  %421 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %420, <32 x float> %390, <32 x float> %375)
  %422 = add nsw i64 %335, 104
  %423 = getelementptr inbounds float, float* %6, i64 %422
  %424 = load float, float* %423, align 4, !tbaa !3006
  %425 = insertelement <32 x float> undef, float %424, i32 0
  %426 = shufflevector <32 x float> %425, <32 x float> undef, <32 x i32> zeroinitializer
  %427 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %426, <32 x float> %390, <32 x float> %381)
  %428 = add nsw i64 %341, 512
  %429 = getelementptr inbounds float, float* %9, i64 %428
  %430 = bitcast float* %429 to <32 x float>*
  %431 = load <32 x float>, <32 x float>* %430, align 64, !tbaa !3030
  %432 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %350, <32 x float> %431, <32 x float> %391)
  %433 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %356, <32 x float> %431, <32 x float> %397)
  %434 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %362, <32 x float> %431, <32 x float> %403)
  %435 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %368, <32 x float> %431, <32 x float> %409)
  %436 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %374, <32 x float> %431, <32 x float> %415)
  %437 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %380, <32 x float> %431, <32 x float> %421)
  %438 = add nsw i64 %335, 112
  %439 = getelementptr inbounds float, float* %6, i64 %438
  %440 = load float, float* %439, align 4, !tbaa !3006
  %441 = insertelement <32 x float> undef, float %440, i32 0
  %442 = shufflevector <32 x float> %441, <32 x float> undef, <32 x i32> zeroinitializer
  %443 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %442, <32 x float> %431, <32 x float> %427)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 8
  br i1 %exitcond.1, label %for_end12.1, label %for_body11.1, !prof !50

for_end12.1:                                      ; preds = %for_body11.1
  %444 = add nsw i64 %207, 464
  %445 = add nsw i64 %209, 1536
  br label %for_body11.2

for_body11.2:                                     ; preds = %for_body11.2, %for_end12.1
  %indvars.iv.2 = phi i64 [ 0, %for_end12.1 ], [ %indvars.iv.next.2, %for_body11.2 ]
  %446 = phi <32 x float> [ %443, %for_end12.1 ], [ %561, %for_body11.2 ]
  %447 = phi <32 x float> [ %437, %for_end12.1 ], [ %555, %for_body11.2 ]
  %448 = phi <32 x float> [ %436, %for_end12.1 ], [ %554, %for_body11.2 ]
  %449 = phi <32 x float> [ %435, %for_end12.1 ], [ %553, %for_body11.2 ]
  %450 = phi <32 x float> [ %434, %for_end12.1 ], [ %552, %for_body11.2 ]
  %451 = phi <32 x float> [ %433, %for_end12.1 ], [ %551, %for_body11.2 ]
  %452 = phi <32 x float> [ %432, %for_end12.1 ], [ %550, %for_body11.2 ]
  %453 = add nsw i64 %444, %indvars.iv.2
  %454 = getelementptr inbounds float, float* %6, i64 %453
  %455 = load float, float* %454, align 4, !tbaa !3006
  %456 = insertelement <32 x float> undef, float %455, i32 0
  %457 = shufflevector <32 x float> %456, <32 x float> undef, <32 x i32> zeroinitializer
  %458 = shl nsw i64 %indvars.iv.2, 5
  %459 = add nsw i64 %445, %458
  %460 = getelementptr inbounds float, float* %9, i64 %459
  %461 = bitcast float* %460 to <32 x float>*
  %462 = load <32 x float>, <32 x float>* %461, align 64, !tbaa !3030
  %463 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %457, <32 x float> %462, <32 x float> %452)
  %464 = add nsw i64 %453, 16
  %465 = getelementptr inbounds float, float* %6, i64 %464
  %466 = load float, float* %465, align 4, !tbaa !3006
  %467 = insertelement <32 x float> undef, float %466, i32 0
  %468 = shufflevector <32 x float> %467, <32 x float> undef, <32 x i32> zeroinitializer
  %469 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %462, <32 x float> %451)
  %470 = add nsw i64 %453, 32
  %471 = getelementptr inbounds float, float* %6, i64 %470
  %472 = load float, float* %471, align 4, !tbaa !3006
  %473 = insertelement <32 x float> undef, float %472, i32 0
  %474 = shufflevector <32 x float> %473, <32 x float> undef, <32 x i32> zeroinitializer
  %475 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %462, <32 x float> %450)
  %476 = add nsw i64 %453, 48
  %477 = getelementptr inbounds float, float* %6, i64 %476
  %478 = load float, float* %477, align 4, !tbaa !3006
  %479 = insertelement <32 x float> undef, float %478, i32 0
  %480 = shufflevector <32 x float> %479, <32 x float> undef, <32 x i32> zeroinitializer
  %481 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %462, <32 x float> %449)
  %482 = add nsw i64 %453, 64
  %483 = getelementptr inbounds float, float* %6, i64 %482
  %484 = load float, float* %483, align 4, !tbaa !3006
  %485 = insertelement <32 x float> undef, float %484, i32 0
  %486 = shufflevector <32 x float> %485, <32 x float> undef, <32 x i32> zeroinitializer
  %487 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %462, <32 x float> %448)
  %488 = add nsw i64 %453, 80
  %489 = getelementptr inbounds float, float* %6, i64 %488
  %490 = load float, float* %489, align 4, !tbaa !3006
  %491 = insertelement <32 x float> undef, float %490, i32 0
  %492 = shufflevector <32 x float> %491, <32 x float> undef, <32 x i32> zeroinitializer
  %493 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %462, <32 x float> %447)
  %494 = add nsw i64 %453, 96
  %495 = getelementptr inbounds float, float* %6, i64 %494
  %496 = load float, float* %495, align 4, !tbaa !3006
  %497 = insertelement <32 x float> undef, float %496, i32 0
  %498 = shufflevector <32 x float> %497, <32 x float> undef, <32 x i32> zeroinitializer
  %499 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %498, <32 x float> %462, <32 x float> %446)
  %500 = add nsw i64 %453, 8
  %501 = getelementptr inbounds float, float* %6, i64 %500
  %502 = load float, float* %501, align 4, !tbaa !3006
  %503 = insertelement <32 x float> undef, float %502, i32 0
  %504 = shufflevector <32 x float> %503, <32 x float> undef, <32 x i32> zeroinitializer
  %505 = add nsw i64 %459, 256
  %506 = getelementptr inbounds float, float* %9, i64 %505
  %507 = bitcast float* %506 to <32 x float>*
  %508 = load <32 x float>, <32 x float>* %507, align 64, !tbaa !3030
  %509 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %504, <32 x float> %508, <32 x float> %463)
  %510 = add nsw i64 %453, 24
  %511 = getelementptr inbounds float, float* %6, i64 %510
  %512 = load float, float* %511, align 4, !tbaa !3006
  %513 = insertelement <32 x float> undef, float %512, i32 0
  %514 = shufflevector <32 x float> %513, <32 x float> undef, <32 x i32> zeroinitializer
  %515 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %514, <32 x float> %508, <32 x float> %469)
  %516 = add nsw i64 %453, 40
  %517 = getelementptr inbounds float, float* %6, i64 %516
  %518 = load float, float* %517, align 4, !tbaa !3006
  %519 = insertelement <32 x float> undef, float %518, i32 0
  %520 = shufflevector <32 x float> %519, <32 x float> undef, <32 x i32> zeroinitializer
  %521 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %520, <32 x float> %508, <32 x float> %475)
  %522 = add nsw i64 %453, 56
  %523 = getelementptr inbounds float, float* %6, i64 %522
  %524 = load float, float* %523, align 4, !tbaa !3006
  %525 = insertelement <32 x float> undef, float %524, i32 0
  %526 = shufflevector <32 x float> %525, <32 x float> undef, <32 x i32> zeroinitializer
  %527 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %526, <32 x float> %508, <32 x float> %481)
  %528 = add nsw i64 %453, 72
  %529 = getelementptr inbounds float, float* %6, i64 %528
  %530 = load float, float* %529, align 4, !tbaa !3006
  %531 = insertelement <32 x float> undef, float %530, i32 0
  %532 = shufflevector <32 x float> %531, <32 x float> undef, <32 x i32> zeroinitializer
  %533 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %532, <32 x float> %508, <32 x float> %487)
  %534 = add nsw i64 %453, 88
  %535 = getelementptr inbounds float, float* %6, i64 %534
  %536 = load float, float* %535, align 4, !tbaa !3006
  %537 = insertelement <32 x float> undef, float %536, i32 0
  %538 = shufflevector <32 x float> %537, <32 x float> undef, <32 x i32> zeroinitializer
  %539 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %538, <32 x float> %508, <32 x float> %493)
  %540 = add nsw i64 %453, 104
  %541 = getelementptr inbounds float, float* %6, i64 %540
  %542 = load float, float* %541, align 4, !tbaa !3006
  %543 = insertelement <32 x float> undef, float %542, i32 0
  %544 = shufflevector <32 x float> %543, <32 x float> undef, <32 x i32> zeroinitializer
  %545 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %544, <32 x float> %508, <32 x float> %499)
  %546 = add nsw i64 %459, 512
  %547 = getelementptr inbounds float, float* %9, i64 %546
  %548 = bitcast float* %547 to <32 x float>*
  %549 = load <32 x float>, <32 x float>* %548, align 64, !tbaa !3030
  %550 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %549, <32 x float> %509)
  %551 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %549, <32 x float> %515)
  %552 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %549, <32 x float> %521)
  %553 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %549, <32 x float> %527)
  %554 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %549, <32 x float> %533)
  %555 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %498, <32 x float> %549, <32 x float> %539)
  %556 = add nsw i64 %453, 112
  %557 = getelementptr inbounds float, float* %6, i64 %556
  %558 = load float, float* %557, align 4, !tbaa !3006
  %559 = insertelement <32 x float> undef, float %558, i32 0
  %560 = shufflevector <32 x float> %559, <32 x float> undef, <32 x i32> zeroinitializer
  %561 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %560, <32 x float> %549, <32 x float> %545)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 8
  br i1 %exitcond.2, label %for_end12.2, label %for_body11.2, !prof !50

for_end12.2:                                      ; preds = %for_body11.2
  %indvars.iv.next74 = add nuw nsw i64 %indvars.iv73, 1
  %exitcond75 = icmp eq i64 %indvars.iv.next74, 16
  br i1 %exitcond75, label %for_begin13.preheader, label %for_begin7.preheader, !prof !50
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.276, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !3033
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !3047
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !3050
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.277, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !3052
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.278, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.279, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.280, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !3054
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !3068
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 1
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !3070
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 28
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !3073
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 28
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !3075
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 128
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !3079
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 100352, i32 100352, i32 3584, i32 128>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !3091
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([242 x i8], [242 x i8]* @.str.44, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !3095
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 4
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.46, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !3109
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 1
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !3111
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 3
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !3114
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 3
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !3116
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 128
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !3120
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !3122
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 36864, i32 36864, i32 12288, i32 4096>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !3134
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !3138
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([278 x i8], [278 x i8]* @.str.51, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !3140
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !3154
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 4
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.55, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !3156
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !3159
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !3161
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !3165
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 128, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !3177
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !3181
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !3195
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 4
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !3197
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 28
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !3200
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 28
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !3202
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !3206
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 100352, i32 25088, i32 896, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !3218
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 460800, i32 2, i32 32)
  %7 = alloca %30, align 8
  %8 = getelementptr inbounds %30, %30* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %30, %30* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %30* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.281, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %31, align 8
  %15 = getelementptr inbounds %31, %31* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %31, %31* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %31, %31* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %31, %31* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %31, %31* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %31* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.282, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.281(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 29
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 30
  %15 = select i1 %14, i32 %13, i32 30
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 30
  %18 = select i1 %17, i32 %16, i32 30
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 30
  %21 = select i1 %20, i32 %16, i32 30
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -3840
  %23 = add i32 %22, -3840
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv, 3840
  %29 = trunc i64 %indvars.iv to i32
  %.off = add i32 %29, -1
  %30 = icmp ult i32 %.off, 28
  %31 = trunc i64 %indvars.iv to i32
  %32 = mul i32 %31, 3584
  br i1 %30, label %if_end.us.29, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %33 = mul i32 %indvar, 3840
  %34 = add i32 %23, %33
  %35 = sext i32 %34 to i64
  %scevgep = getelementptr float, float* %4, i64 %35
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 15360, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_body2.preheader, %if_end.us.29
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %36 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %36, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.29:                                     ; preds = %for_begin1.preheader
  %37 = getelementptr inbounds float, float* %4, i64 %28
  %38 = bitcast float* %37 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %38, align 64, !tbaa !3222
  %39 = or i64 %28, 128
  %40 = add i32 %32, -3584
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %7, i64 %41
  %43 = bitcast float* %42 to <128 x float>*
  %44 = load <128 x float>, <128 x float>* %43, align 64, !tbaa !3225
  %45 = getelementptr inbounds float, float* %4, i64 %39
  %46 = bitcast float* %45 to <128 x float>*
  store <128 x float> %44, <128 x float>* %46, align 64, !tbaa !3222
  %47 = add nsw i64 %28, 256
  %48 = add i32 %32, -3456
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to <128 x float>*
  %52 = load <128 x float>, <128 x float>* %51, align 64, !tbaa !3225
  %53 = getelementptr inbounds float, float* %4, i64 %47
  %54 = bitcast float* %53 to <128 x float>*
  store <128 x float> %52, <128 x float>* %54, align 64, !tbaa !3222
  %55 = add nsw i64 %28, 384
  %56 = add i32 %32, -3328
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds float, float* %7, i64 %57
  %59 = bitcast float* %58 to <128 x float>*
  %60 = load <128 x float>, <128 x float>* %59, align 64, !tbaa !3225
  %61 = getelementptr inbounds float, float* %4, i64 %55
  %62 = bitcast float* %61 to <128 x float>*
  store <128 x float> %60, <128 x float>* %62, align 64, !tbaa !3222
  %63 = add nsw i64 %28, 512
  %64 = add i32 %32, -3200
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <128 x float>*
  %68 = load <128 x float>, <128 x float>* %67, align 64, !tbaa !3225
  %69 = getelementptr inbounds float, float* %4, i64 %63
  %70 = bitcast float* %69 to <128 x float>*
  store <128 x float> %68, <128 x float>* %70, align 64, !tbaa !3222
  %71 = add nsw i64 %28, 640
  %72 = add i32 %32, -3072
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = bitcast float* %74 to <128 x float>*
  %76 = load <128 x float>, <128 x float>* %75, align 64, !tbaa !3225
  %77 = getelementptr inbounds float, float* %4, i64 %71
  %78 = bitcast float* %77 to <128 x float>*
  store <128 x float> %76, <128 x float>* %78, align 64, !tbaa !3222
  %79 = add nsw i64 %28, 768
  %80 = add i32 %32, -2944
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <128 x float>*
  %84 = load <128 x float>, <128 x float>* %83, align 64, !tbaa !3225
  %85 = getelementptr inbounds float, float* %4, i64 %79
  %86 = bitcast float* %85 to <128 x float>*
  store <128 x float> %84, <128 x float>* %86, align 64, !tbaa !3222
  %87 = add nsw i64 %28, 896
  %88 = add i32 %32, -2816
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds float, float* %7, i64 %89
  %91 = bitcast float* %90 to <128 x float>*
  %92 = load <128 x float>, <128 x float>* %91, align 64, !tbaa !3225
  %93 = getelementptr inbounds float, float* %4, i64 %87
  %94 = bitcast float* %93 to <128 x float>*
  store <128 x float> %92, <128 x float>* %94, align 64, !tbaa !3222
  %95 = add nsw i64 %28, 1024
  %96 = add i32 %32, -2688
  %97 = sext i32 %96 to i64
  %98 = getelementptr inbounds float, float* %7, i64 %97
  %99 = bitcast float* %98 to <128 x float>*
  %100 = load <128 x float>, <128 x float>* %99, align 64, !tbaa !3225
  %101 = getelementptr inbounds float, float* %4, i64 %95
  %102 = bitcast float* %101 to <128 x float>*
  store <128 x float> %100, <128 x float>* %102, align 64, !tbaa !3222
  %103 = add nsw i64 %28, 1152
  %104 = add i32 %32, -2560
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds float, float* %7, i64 %105
  %107 = bitcast float* %106 to <128 x float>*
  %108 = load <128 x float>, <128 x float>* %107, align 64, !tbaa !3225
  %109 = getelementptr inbounds float, float* %4, i64 %103
  %110 = bitcast float* %109 to <128 x float>*
  store <128 x float> %108, <128 x float>* %110, align 64, !tbaa !3222
  %111 = add nsw i64 %28, 1280
  %112 = add i32 %32, -2432
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to <128 x float>*
  %116 = load <128 x float>, <128 x float>* %115, align 64, !tbaa !3225
  %117 = getelementptr inbounds float, float* %4, i64 %111
  %118 = bitcast float* %117 to <128 x float>*
  store <128 x float> %116, <128 x float>* %118, align 64, !tbaa !3222
  %119 = add nsw i64 %28, 1408
  %120 = add i32 %32, -2304
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds float, float* %7, i64 %121
  %123 = bitcast float* %122 to <128 x float>*
  %124 = load <128 x float>, <128 x float>* %123, align 64, !tbaa !3225
  %125 = getelementptr inbounds float, float* %4, i64 %119
  %126 = bitcast float* %125 to <128 x float>*
  store <128 x float> %124, <128 x float>* %126, align 64, !tbaa !3222
  %127 = add nsw i64 %28, 1536
  %128 = add i32 %32, -2176
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds float, float* %7, i64 %129
  %131 = bitcast float* %130 to <128 x float>*
  %132 = load <128 x float>, <128 x float>* %131, align 64, !tbaa !3225
  %133 = getelementptr inbounds float, float* %4, i64 %127
  %134 = bitcast float* %133 to <128 x float>*
  store <128 x float> %132, <128 x float>* %134, align 64, !tbaa !3222
  %135 = add nsw i64 %28, 1664
  %136 = add i32 %32, -2048
  %137 = sext i32 %136 to i64
  %138 = getelementptr inbounds float, float* %7, i64 %137
  %139 = bitcast float* %138 to <128 x float>*
  %140 = load <128 x float>, <128 x float>* %139, align 64, !tbaa !3225
  %141 = getelementptr inbounds float, float* %4, i64 %135
  %142 = bitcast float* %141 to <128 x float>*
  store <128 x float> %140, <128 x float>* %142, align 64, !tbaa !3222
  %143 = add nsw i64 %28, 1792
  %144 = add i32 %32, -1920
  %145 = sext i32 %144 to i64
  %146 = getelementptr inbounds float, float* %7, i64 %145
  %147 = bitcast float* %146 to <128 x float>*
  %148 = load <128 x float>, <128 x float>* %147, align 64, !tbaa !3225
  %149 = getelementptr inbounds float, float* %4, i64 %143
  %150 = bitcast float* %149 to <128 x float>*
  store <128 x float> %148, <128 x float>* %150, align 64, !tbaa !3222
  %151 = add nsw i64 %28, 1920
  %152 = add i32 %32, -1792
  %153 = sext i32 %152 to i64
  %154 = getelementptr inbounds float, float* %7, i64 %153
  %155 = bitcast float* %154 to <128 x float>*
  %156 = load <128 x float>, <128 x float>* %155, align 64, !tbaa !3225
  %157 = getelementptr inbounds float, float* %4, i64 %151
  %158 = bitcast float* %157 to <128 x float>*
  store <128 x float> %156, <128 x float>* %158, align 64, !tbaa !3222
  %159 = add nsw i64 %28, 2048
  %160 = add i32 %32, -1664
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = bitcast float* %162 to <128 x float>*
  %164 = load <128 x float>, <128 x float>* %163, align 64, !tbaa !3225
  %165 = getelementptr inbounds float, float* %4, i64 %159
  %166 = bitcast float* %165 to <128 x float>*
  store <128 x float> %164, <128 x float>* %166, align 64, !tbaa !3222
  %167 = add nsw i64 %28, 2176
  %168 = add i32 %32, -1536
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to <128 x float>*
  %172 = load <128 x float>, <128 x float>* %171, align 64, !tbaa !3225
  %173 = getelementptr inbounds float, float* %4, i64 %167
  %174 = bitcast float* %173 to <128 x float>*
  store <128 x float> %172, <128 x float>* %174, align 64, !tbaa !3222
  %175 = add nsw i64 %28, 2304
  %176 = add i32 %32, -1408
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds float, float* %7, i64 %177
  %179 = bitcast float* %178 to <128 x float>*
  %180 = load <128 x float>, <128 x float>* %179, align 64, !tbaa !3225
  %181 = getelementptr inbounds float, float* %4, i64 %175
  %182 = bitcast float* %181 to <128 x float>*
  store <128 x float> %180, <128 x float>* %182, align 64, !tbaa !3222
  %183 = add nsw i64 %28, 2432
  %184 = add i32 %32, -1280
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds float, float* %7, i64 %185
  %187 = bitcast float* %186 to <128 x float>*
  %188 = load <128 x float>, <128 x float>* %187, align 64, !tbaa !3225
  %189 = getelementptr inbounds float, float* %4, i64 %183
  %190 = bitcast float* %189 to <128 x float>*
  store <128 x float> %188, <128 x float>* %190, align 64, !tbaa !3222
  %191 = add nsw i64 %28, 2560
  %192 = add i32 %32, -1152
  %193 = sext i32 %192 to i64
  %194 = getelementptr inbounds float, float* %7, i64 %193
  %195 = bitcast float* %194 to <128 x float>*
  %196 = load <128 x float>, <128 x float>* %195, align 64, !tbaa !3225
  %197 = getelementptr inbounds float, float* %4, i64 %191
  %198 = bitcast float* %197 to <128 x float>*
  store <128 x float> %196, <128 x float>* %198, align 64, !tbaa !3222
  %199 = add nsw i64 %28, 2688
  %200 = add i32 %32, -1024
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds float, float* %7, i64 %201
  %203 = bitcast float* %202 to <128 x float>*
  %204 = load <128 x float>, <128 x float>* %203, align 64, !tbaa !3225
  %205 = getelementptr inbounds float, float* %4, i64 %199
  %206 = bitcast float* %205 to <128 x float>*
  store <128 x float> %204, <128 x float>* %206, align 64, !tbaa !3222
  %207 = add nsw i64 %28, 2816
  %208 = add i32 %32, -896
  %209 = sext i32 %208 to i64
  %210 = getelementptr inbounds float, float* %7, i64 %209
  %211 = bitcast float* %210 to <128 x float>*
  %212 = load <128 x float>, <128 x float>* %211, align 64, !tbaa !3225
  %213 = getelementptr inbounds float, float* %4, i64 %207
  %214 = bitcast float* %213 to <128 x float>*
  store <128 x float> %212, <128 x float>* %214, align 64, !tbaa !3222
  %215 = add nsw i64 %28, 2944
  %216 = add i32 %32, -768
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds float, float* %7, i64 %217
  %219 = bitcast float* %218 to <128 x float>*
  %220 = load <128 x float>, <128 x float>* %219, align 64, !tbaa !3225
  %221 = getelementptr inbounds float, float* %4, i64 %215
  %222 = bitcast float* %221 to <128 x float>*
  store <128 x float> %220, <128 x float>* %222, align 64, !tbaa !3222
  %223 = add nsw i64 %28, 3072
  %224 = add i32 %32, -640
  %225 = sext i32 %224 to i64
  %226 = getelementptr inbounds float, float* %7, i64 %225
  %227 = bitcast float* %226 to <128 x float>*
  %228 = load <128 x float>, <128 x float>* %227, align 64, !tbaa !3225
  %229 = getelementptr inbounds float, float* %4, i64 %223
  %230 = bitcast float* %229 to <128 x float>*
  store <128 x float> %228, <128 x float>* %230, align 64, !tbaa !3222
  %231 = add nsw i64 %28, 3200
  %232 = add i32 %32, -512
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <128 x float>*
  %236 = load <128 x float>, <128 x float>* %235, align 64, !tbaa !3225
  %237 = getelementptr inbounds float, float* %4, i64 %231
  %238 = bitcast float* %237 to <128 x float>*
  store <128 x float> %236, <128 x float>* %238, align 64, !tbaa !3222
  %239 = add nsw i64 %28, 3328
  %240 = add i32 %32, -384
  %241 = sext i32 %240 to i64
  %242 = getelementptr inbounds float, float* %7, i64 %241
  %243 = bitcast float* %242 to <128 x float>*
  %244 = load <128 x float>, <128 x float>* %243, align 64, !tbaa !3225
  %245 = getelementptr inbounds float, float* %4, i64 %239
  %246 = bitcast float* %245 to <128 x float>*
  store <128 x float> %244, <128 x float>* %246, align 64, !tbaa !3222
  %247 = add nsw i64 %28, 3456
  %248 = add i32 %32, -256
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds float, float* %7, i64 %249
  %251 = bitcast float* %250 to <128 x float>*
  %252 = load <128 x float>, <128 x float>* %251, align 64, !tbaa !3225
  %253 = getelementptr inbounds float, float* %4, i64 %247
  %254 = bitcast float* %253 to <128 x float>*
  store <128 x float> %252, <128 x float>* %254, align 64, !tbaa !3222
  %255 = add nsw i64 %28, 3584
  %256 = add i32 %32, -128
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds float, float* %7, i64 %257
  %259 = bitcast float* %258 to <128 x float>*
  %260 = load <128 x float>, <128 x float>* %259, align 64, !tbaa !3225
  %261 = getelementptr inbounds float, float* %4, i64 %255
  %262 = bitcast float* %261 to <128 x float>*
  store <128 x float> %260, <128 x float>* %262, align 64, !tbaa !3222
  %263 = add nsw i64 %28, 3712
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = bitcast float* %264 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %265, align 64, !tbaa !3222
  br label %for_end3
}

define private i32 @__tvm_parallel_lambda.282(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = add nsw i32 %20, 111
  %22 = sdiv i32 %21, %20
  %23 = add nsw i32 %0, 1
  %24 = mul nsw i32 %22, %23
  %25 = icmp slt i32 %24, 112
  %26 = select i1 %25, i32 %24, i32 112
  %27 = mul nsw i32 %22, %0
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = icmp slt i32 %29, %26
  br i1 %30, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %31 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %32 = bitcast float* %31 to <32 x float>*
  %33 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %34 = bitcast float* %33 to <32 x float>*
  %35 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %36 = bitcast float* %35 to <32 x float>*
  %37 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %38 = bitcast float* %37 to <32 x float>*
  %39 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %40 = bitcast float* %39 to <32 x float>*
  %41 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %42 = bitcast float* %41 to <32 x float>*
  %43 = add i32 %29, 1
  %44 = sext i32 %43 to i64
  %45 = add nsw i64 %44, -1
  %46 = sext i32 %26 to i64
  %47 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_begin13.preheader
  %indvars.iv68 = phi i64 [ %45, %for_body.lr.ph ], [ %indvars.iv.next69, %for_begin13.preheader ]
  %48 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %49 = tail call i8* %48(i32 1, i32 %18, i64 3584, i32 2, i32 32)
  %50 = trunc i64 %indvars.iv68 to i32
  %51 = srem i32 %50, 28
  %52 = sdiv i32 %50, 28
  %53 = mul nsw i32 %52, 36864
  %54 = sext i32 %53 to i64
  %55 = mul nsw i32 %51, 3840
  %56 = sext i32 %55 to i64
  %57 = mul nsw i32 %51, 3840
  %58 = add nsw i32 %57, 3840
  %59 = sext i32 %58 to i64
  %60 = add nsw i64 %54, 12288
  %61 = mul nsw i32 %51, 3840
  %62 = add nsw i32 %61, 7680
  %63 = sext i32 %62 to i64
  %64 = add nsw i64 %54, 24576
  br label %for_body2

for_end:                                          ; preds = %for_begin13.preheader, %entry
  ret i32 0

for_begin13.preheader:                            ; preds = %for_end9.2
  %65 = mul nsw i64 %indvars.iv68, 896
  %66 = shl nsw i32 %52, 5
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds float, float* %15, i64 %67
  %69 = bitcast float* %68 to <32 x float>*
  %70 = load <32 x float>, <32 x float>* %69, align 64, !tbaa !3228
  %71 = bitcast i8* %49 to <32 x float>*
  %72 = load <32 x float>, <32 x float>* %71, align 64, !tbaa !3231
  %73 = fadd <32 x float> %70, %72
  %74 = fcmp ogt <32 x float> %73, zeroinitializer
  %75 = select <32 x i1> %74, <32 x float> %73, <32 x float> zeroinitializer
  %76 = getelementptr inbounds float, float* %12, i64 %65
  %77 = bitcast float* %76 to <32 x float>*
  store <32 x float> %75, <32 x float>* %77, align 64, !tbaa !3234
  %78 = getelementptr inbounds i8, i8* %49, i64 128
  %79 = bitcast i8* %78 to <32 x float>*
  %80 = load <32 x float>, <32 x float>* %79, align 64, !tbaa !3231
  %81 = fadd <32 x float> %70, %80
  %82 = fcmp ogt <32 x float> %81, zeroinitializer
  %83 = select <32 x i1> %82, <32 x float> %81, <32 x float> zeroinitializer
  %84 = mul i64 %indvars.iv68, 3848290697216
  %sext = ashr exact i64 %84, 32
  %85 = or i64 %sext, 32
  %86 = getelementptr inbounds float, float* %12, i64 %85
  %87 = bitcast float* %86 to <32 x float>*
  store <32 x float> %83, <32 x float>* %87, align 64, !tbaa !3234
  %88 = getelementptr inbounds i8, i8* %49, i64 256
  %89 = bitcast i8* %88 to <32 x float>*
  %90 = load <32 x float>, <32 x float>* %89, align 64, !tbaa !3231
  %91 = fadd <32 x float> %70, %90
  %92 = fcmp ogt <32 x float> %91, zeroinitializer
  %93 = select <32 x i1> %92, <32 x float> %91, <32 x float> zeroinitializer
  %94 = mul i64 %indvars.iv68, 3848290697216
  %sext70 = ashr exact i64 %94, 32
  %95 = or i64 %sext70, 64
  %96 = getelementptr inbounds float, float* %12, i64 %95
  %97 = bitcast float* %96 to <32 x float>*
  store <32 x float> %93, <32 x float>* %97, align 64, !tbaa !3234
  %98 = getelementptr inbounds i8, i8* %49, i64 384
  %99 = bitcast i8* %98 to <32 x float>*
  %100 = load <32 x float>, <32 x float>* %99, align 64, !tbaa !3231
  %101 = fadd <32 x float> %70, %100
  %102 = fcmp ogt <32 x float> %101, zeroinitializer
  %103 = select <32 x i1> %102, <32 x float> %101, <32 x float> zeroinitializer
  %104 = mul i64 %indvars.iv68, 3848290697216
  %sext71 = ashr exact i64 %104, 32
  %105 = or i64 %sext71, 96
  %106 = getelementptr inbounds float, float* %12, i64 %105
  %107 = bitcast float* %106 to <32 x float>*
  store <32 x float> %103, <32 x float>* %107, align 64, !tbaa !3234
  %108 = getelementptr inbounds i8, i8* %49, i64 512
  %109 = bitcast i8* %108 to <32 x float>*
  %110 = load <32 x float>, <32 x float>* %109, align 64, !tbaa !3231
  %111 = fadd <32 x float> %70, %110
  %112 = fcmp ogt <32 x float> %111, zeroinitializer
  %113 = select <32 x i1> %112, <32 x float> %111, <32 x float> zeroinitializer
  %114 = mul i64 %indvars.iv68, 3848290697216
  %sext72 = add i64 %114, 549755813888
  %115 = ashr exact i64 %sext72, 32
  %116 = getelementptr inbounds float, float* %12, i64 %115
  %117 = bitcast float* %116 to <32 x float>*
  store <32 x float> %113, <32 x float>* %117, align 64, !tbaa !3234
  %118 = getelementptr inbounds i8, i8* %49, i64 640
  %119 = bitcast i8* %118 to <32 x float>*
  %120 = load <32 x float>, <32 x float>* %119, align 64, !tbaa !3231
  %121 = fadd <32 x float> %70, %120
  %122 = fcmp ogt <32 x float> %121, zeroinitializer
  %123 = select <32 x i1> %122, <32 x float> %121, <32 x float> zeroinitializer
  %124 = mul i64 %indvars.iv68, 3848290697216
  %sext73 = add i64 %124, 687194767360
  %125 = ashr exact i64 %sext73, 32
  %126 = getelementptr inbounds float, float* %12, i64 %125
  %127 = bitcast float* %126 to <32 x float>*
  store <32 x float> %123, <32 x float>* %127, align 64, !tbaa !3234
  %128 = getelementptr inbounds i8, i8* %49, i64 768
  %129 = bitcast i8* %128 to <32 x float>*
  %130 = load <32 x float>, <32 x float>* %129, align 64, !tbaa !3231
  %131 = fadd <32 x float> %70, %130
  %132 = fcmp ogt <32 x float> %131, zeroinitializer
  %133 = select <32 x i1> %132, <32 x float> %131, <32 x float> zeroinitializer
  %134 = mul i64 %indvars.iv68, 3848290697216
  %sext74 = add i64 %134, 824633720832
  %135 = ashr exact i64 %sext74, 32
  %136 = getelementptr inbounds float, float* %12, i64 %135
  %137 = bitcast float* %136 to <32 x float>*
  store <32 x float> %133, <32 x float>* %137, align 64, !tbaa !3234
  %138 = getelementptr inbounds i8, i8* %49, i64 896
  %139 = bitcast i8* %138 to <32 x float>*
  %140 = load <32 x float>, <32 x float>* %139, align 64, !tbaa !3231
  %141 = fadd <32 x float> %70, %140
  %142 = fcmp ogt <32 x float> %141, zeroinitializer
  %143 = select <32 x i1> %142, <32 x float> %141, <32 x float> zeroinitializer
  %144 = mul i64 %indvars.iv68, 3848290697216
  %sext75 = add i64 %144, 962072674304
  %145 = ashr exact i64 %sext75, 32
  %146 = getelementptr inbounds float, float* %12, i64 %145
  %147 = bitcast float* %146 to <32 x float>*
  store <32 x float> %143, <32 x float>* %147, align 64, !tbaa !3234
  %148 = getelementptr inbounds i8, i8* %49, i64 1024
  %149 = bitcast i8* %148 to <32 x float>*
  %150 = load <32 x float>, <32 x float>* %149, align 64, !tbaa !3231
  %151 = fadd <32 x float> %70, %150
  %152 = fcmp ogt <32 x float> %151, zeroinitializer
  %153 = select <32 x i1> %152, <32 x float> %151, <32 x float> zeroinitializer
  %154 = mul i64 %indvars.iv68, 3848290697216
  %sext76 = add i64 %154, 1099511627776
  %155 = ashr exact i64 %sext76, 32
  %156 = getelementptr inbounds float, float* %12, i64 %155
  %157 = bitcast float* %156 to <32 x float>*
  store <32 x float> %153, <32 x float>* %157, align 64, !tbaa !3234
  %158 = getelementptr inbounds i8, i8* %49, i64 1152
  %159 = bitcast i8* %158 to <32 x float>*
  %160 = load <32 x float>, <32 x float>* %159, align 64, !tbaa !3231
  %161 = fadd <32 x float> %70, %160
  %162 = fcmp ogt <32 x float> %161, zeroinitializer
  %163 = select <32 x i1> %162, <32 x float> %161, <32 x float> zeroinitializer
  %164 = mul i64 %indvars.iv68, 3848290697216
  %sext77 = add i64 %164, 1236950581248
  %165 = ashr exact i64 %sext77, 32
  %166 = getelementptr inbounds float, float* %12, i64 %165
  %167 = bitcast float* %166 to <32 x float>*
  store <32 x float> %163, <32 x float>* %167, align 64, !tbaa !3234
  %168 = getelementptr inbounds i8, i8* %49, i64 1280
  %169 = bitcast i8* %168 to <32 x float>*
  %170 = load <32 x float>, <32 x float>* %169, align 64, !tbaa !3231
  %171 = fadd <32 x float> %70, %170
  %172 = fcmp ogt <32 x float> %171, zeroinitializer
  %173 = select <32 x i1> %172, <32 x float> %171, <32 x float> zeroinitializer
  %174 = mul i64 %indvars.iv68, 3848290697216
  %sext78 = add i64 %174, 1374389534720
  %175 = ashr exact i64 %sext78, 32
  %176 = getelementptr inbounds float, float* %12, i64 %175
  %177 = bitcast float* %176 to <32 x float>*
  store <32 x float> %173, <32 x float>* %177, align 64, !tbaa !3234
  %178 = getelementptr inbounds i8, i8* %49, i64 1408
  %179 = bitcast i8* %178 to <32 x float>*
  %180 = load <32 x float>, <32 x float>* %179, align 64, !tbaa !3231
  %181 = fadd <32 x float> %70, %180
  %182 = fcmp ogt <32 x float> %181, zeroinitializer
  %183 = select <32 x i1> %182, <32 x float> %181, <32 x float> zeroinitializer
  %184 = mul i64 %indvars.iv68, 3848290697216
  %sext79 = add i64 %184, 1511828488192
  %185 = ashr exact i64 %sext79, 32
  %186 = getelementptr inbounds float, float* %12, i64 %185
  %187 = bitcast float* %186 to <32 x float>*
  store <32 x float> %183, <32 x float>* %187, align 64, !tbaa !3234
  %188 = getelementptr inbounds i8, i8* %49, i64 1536
  %189 = bitcast i8* %188 to <32 x float>*
  %190 = load <32 x float>, <32 x float>* %189, align 64, !tbaa !3231
  %191 = fadd <32 x float> %70, %190
  %192 = fcmp ogt <32 x float> %191, zeroinitializer
  %193 = select <32 x i1> %192, <32 x float> %191, <32 x float> zeroinitializer
  %194 = mul i64 %indvars.iv68, 3848290697216
  %sext80 = add i64 %194, 1649267441664
  %195 = ashr exact i64 %sext80, 32
  %196 = getelementptr inbounds float, float* %12, i64 %195
  %197 = bitcast float* %196 to <32 x float>*
  store <32 x float> %193, <32 x float>* %197, align 64, !tbaa !3234
  %198 = getelementptr inbounds i8, i8* %49, i64 1664
  %199 = bitcast i8* %198 to <32 x float>*
  %200 = load <32 x float>, <32 x float>* %199, align 64, !tbaa !3231
  %201 = fadd <32 x float> %70, %200
  %202 = fcmp ogt <32 x float> %201, zeroinitializer
  %203 = select <32 x i1> %202, <32 x float> %201, <32 x float> zeroinitializer
  %204 = mul i64 %indvars.iv68, 3848290697216
  %sext81 = add i64 %204, 1786706395136
  %205 = ashr exact i64 %sext81, 32
  %206 = getelementptr inbounds float, float* %12, i64 %205
  %207 = bitcast float* %206 to <32 x float>*
  store <32 x float> %203, <32 x float>* %207, align 64, !tbaa !3234
  %208 = getelementptr inbounds i8, i8* %49, i64 1792
  %209 = bitcast i8* %208 to <32 x float>*
  %210 = load <32 x float>, <32 x float>* %209, align 64, !tbaa !3231
  %211 = fadd <32 x float> %70, %210
  %212 = fcmp ogt <32 x float> %211, zeroinitializer
  %213 = select <32 x i1> %212, <32 x float> %211, <32 x float> zeroinitializer
  %214 = mul i64 %indvars.iv68, 3848290697216
  %sext82 = add i64 %214, 1924145348608
  %215 = ashr exact i64 %sext82, 32
  %216 = getelementptr inbounds float, float* %12, i64 %215
  %217 = bitcast float* %216 to <32 x float>*
  store <32 x float> %213, <32 x float>* %217, align 64, !tbaa !3234
  %218 = getelementptr inbounds i8, i8* %49, i64 1920
  %219 = bitcast i8* %218 to <32 x float>*
  %220 = load <32 x float>, <32 x float>* %219, align 64, !tbaa !3231
  %221 = fadd <32 x float> %70, %220
  %222 = fcmp ogt <32 x float> %221, zeroinitializer
  %223 = select <32 x i1> %222, <32 x float> %221, <32 x float> zeroinitializer
  %224 = mul i64 %indvars.iv68, 3848290697216
  %sext83 = add i64 %224, 2061584302080
  %225 = ashr exact i64 %sext83, 32
  %226 = getelementptr inbounds float, float* %12, i64 %225
  %227 = bitcast float* %226 to <32 x float>*
  store <32 x float> %223, <32 x float>* %227, align 64, !tbaa !3234
  %228 = getelementptr inbounds i8, i8* %49, i64 2048
  %229 = bitcast i8* %228 to <32 x float>*
  %230 = load <32 x float>, <32 x float>* %229, align 64, !tbaa !3231
  %231 = fadd <32 x float> %70, %230
  %232 = fcmp ogt <32 x float> %231, zeroinitializer
  %233 = select <32 x i1> %232, <32 x float> %231, <32 x float> zeroinitializer
  %234 = mul i64 %indvars.iv68, 3848290697216
  %sext84 = add i64 %234, 2199023255552
  %235 = ashr exact i64 %sext84, 32
  %236 = getelementptr inbounds float, float* %12, i64 %235
  %237 = bitcast float* %236 to <32 x float>*
  store <32 x float> %233, <32 x float>* %237, align 64, !tbaa !3234
  %238 = getelementptr inbounds i8, i8* %49, i64 2176
  %239 = bitcast i8* %238 to <32 x float>*
  %240 = load <32 x float>, <32 x float>* %239, align 64, !tbaa !3231
  %241 = fadd <32 x float> %70, %240
  %242 = fcmp ogt <32 x float> %241, zeroinitializer
  %243 = select <32 x i1> %242, <32 x float> %241, <32 x float> zeroinitializer
  %244 = mul i64 %indvars.iv68, 3848290697216
  %sext85 = add i64 %244, 2336462209024
  %245 = ashr exact i64 %sext85, 32
  %246 = getelementptr inbounds float, float* %12, i64 %245
  %247 = bitcast float* %246 to <32 x float>*
  store <32 x float> %243, <32 x float>* %247, align 64, !tbaa !3234
  %248 = getelementptr inbounds i8, i8* %49, i64 2304
  %249 = bitcast i8* %248 to <32 x float>*
  %250 = load <32 x float>, <32 x float>* %249, align 64, !tbaa !3231
  %251 = fadd <32 x float> %70, %250
  %252 = fcmp ogt <32 x float> %251, zeroinitializer
  %253 = select <32 x i1> %252, <32 x float> %251, <32 x float> zeroinitializer
  %254 = mul i64 %indvars.iv68, 3848290697216
  %sext86 = add i64 %254, 2473901162496
  %255 = ashr exact i64 %sext86, 32
  %256 = getelementptr inbounds float, float* %12, i64 %255
  %257 = bitcast float* %256 to <32 x float>*
  store <32 x float> %253, <32 x float>* %257, align 64, !tbaa !3234
  %258 = getelementptr inbounds i8, i8* %49, i64 2432
  %259 = bitcast i8* %258 to <32 x float>*
  %260 = load <32 x float>, <32 x float>* %259, align 64, !tbaa !3231
  %261 = fadd <32 x float> %70, %260
  %262 = fcmp ogt <32 x float> %261, zeroinitializer
  %263 = select <32 x i1> %262, <32 x float> %261, <32 x float> zeroinitializer
  %264 = mul i64 %indvars.iv68, 3848290697216
  %sext87 = add i64 %264, 2611340115968
  %265 = ashr exact i64 %sext87, 32
  %266 = getelementptr inbounds float, float* %12, i64 %265
  %267 = bitcast float* %266 to <32 x float>*
  store <32 x float> %263, <32 x float>* %267, align 64, !tbaa !3234
  %268 = getelementptr inbounds i8, i8* %49, i64 2560
  %269 = bitcast i8* %268 to <32 x float>*
  %270 = load <32 x float>, <32 x float>* %269, align 64, !tbaa !3231
  %271 = fadd <32 x float> %70, %270
  %272 = fcmp ogt <32 x float> %271, zeroinitializer
  %273 = select <32 x i1> %272, <32 x float> %271, <32 x float> zeroinitializer
  %274 = mul i64 %indvars.iv68, 3848290697216
  %sext88 = add i64 %274, 2748779069440
  %275 = ashr exact i64 %sext88, 32
  %276 = getelementptr inbounds float, float* %12, i64 %275
  %277 = bitcast float* %276 to <32 x float>*
  store <32 x float> %273, <32 x float>* %277, align 64, !tbaa !3234
  %278 = getelementptr inbounds i8, i8* %49, i64 2688
  %279 = bitcast i8* %278 to <32 x float>*
  %280 = load <32 x float>, <32 x float>* %279, align 64, !tbaa !3231
  %281 = fadd <32 x float> %70, %280
  %282 = fcmp ogt <32 x float> %281, zeroinitializer
  %283 = select <32 x i1> %282, <32 x float> %281, <32 x float> zeroinitializer
  %284 = mul i64 %indvars.iv68, 3848290697216
  %sext89 = add i64 %284, 2886218022912
  %285 = ashr exact i64 %sext89, 32
  %286 = getelementptr inbounds float, float* %12, i64 %285
  %287 = bitcast float* %286 to <32 x float>*
  store <32 x float> %283, <32 x float>* %287, align 64, !tbaa !3234
  %288 = getelementptr inbounds i8, i8* %49, i64 2816
  %289 = bitcast i8* %288 to <32 x float>*
  %290 = load <32 x float>, <32 x float>* %289, align 64, !tbaa !3231
  %291 = fadd <32 x float> %70, %290
  %292 = fcmp ogt <32 x float> %291, zeroinitializer
  %293 = select <32 x i1> %292, <32 x float> %291, <32 x float> zeroinitializer
  %294 = mul i64 %indvars.iv68, 3848290697216
  %sext90 = add i64 %294, 3023656976384
  %295 = ashr exact i64 %sext90, 32
  %296 = getelementptr inbounds float, float* %12, i64 %295
  %297 = bitcast float* %296 to <32 x float>*
  store <32 x float> %293, <32 x float>* %297, align 64, !tbaa !3234
  %298 = getelementptr inbounds i8, i8* %49, i64 2944
  %299 = bitcast i8* %298 to <32 x float>*
  %300 = load <32 x float>, <32 x float>* %299, align 64, !tbaa !3231
  %301 = fadd <32 x float> %70, %300
  %302 = fcmp ogt <32 x float> %301, zeroinitializer
  %303 = select <32 x i1> %302, <32 x float> %301, <32 x float> zeroinitializer
  %304 = mul i64 %indvars.iv68, 3848290697216
  %sext91 = add i64 %304, 3161095929856
  %305 = ashr exact i64 %sext91, 32
  %306 = getelementptr inbounds float, float* %12, i64 %305
  %307 = bitcast float* %306 to <32 x float>*
  store <32 x float> %303, <32 x float>* %307, align 64, !tbaa !3234
  %308 = getelementptr inbounds i8, i8* %49, i64 3072
  %309 = bitcast i8* %308 to <32 x float>*
  %310 = load <32 x float>, <32 x float>* %309, align 64, !tbaa !3231
  %311 = fadd <32 x float> %70, %310
  %312 = fcmp ogt <32 x float> %311, zeroinitializer
  %313 = select <32 x i1> %312, <32 x float> %311, <32 x float> zeroinitializer
  %314 = mul i64 %indvars.iv68, 3848290697216
  %sext92 = add i64 %314, 3298534883328
  %315 = ashr exact i64 %sext92, 32
  %316 = getelementptr inbounds float, float* %12, i64 %315
  %317 = bitcast float* %316 to <32 x float>*
  store <32 x float> %313, <32 x float>* %317, align 64, !tbaa !3234
  %318 = getelementptr inbounds i8, i8* %49, i64 3200
  %319 = bitcast i8* %318 to <32 x float>*
  %320 = load <32 x float>, <32 x float>* %319, align 64, !tbaa !3231
  %321 = fadd <32 x float> %70, %320
  %322 = fcmp ogt <32 x float> %321, zeroinitializer
  %323 = select <32 x i1> %322, <32 x float> %321, <32 x float> zeroinitializer
  %324 = mul i64 %indvars.iv68, 3848290697216
  %sext93 = add i64 %324, 3435973836800
  %325 = ashr exact i64 %sext93, 32
  %326 = getelementptr inbounds float, float* %12, i64 %325
  %327 = bitcast float* %326 to <32 x float>*
  store <32 x float> %323, <32 x float>* %327, align 64, !tbaa !3234
  %328 = getelementptr inbounds i8, i8* %49, i64 3328
  %329 = bitcast i8* %328 to <32 x float>*
  %330 = load <32 x float>, <32 x float>* %329, align 64, !tbaa !3231
  %331 = fadd <32 x float> %70, %330
  %332 = fcmp ogt <32 x float> %331, zeroinitializer
  %333 = select <32 x i1> %332, <32 x float> %331, <32 x float> zeroinitializer
  %334 = mul i64 %indvars.iv68, 3848290697216
  %sext94 = add i64 %334, 3573412790272
  %335 = ashr exact i64 %sext94, 32
  %336 = getelementptr inbounds float, float* %12, i64 %335
  %337 = bitcast float* %336 to <32 x float>*
  store <32 x float> %333, <32 x float>* %337, align 64, !tbaa !3234
  %338 = getelementptr inbounds i8, i8* %49, i64 3456
  %339 = bitcast i8* %338 to <32 x float>*
  %340 = load <32 x float>, <32 x float>* %339, align 64, !tbaa !3231
  %341 = fadd <32 x float> %70, %340
  %342 = fcmp ogt <32 x float> %341, zeroinitializer
  %343 = select <32 x i1> %342, <32 x float> %341, <32 x float> zeroinitializer
  %344 = mul i64 %indvars.iv68, 3848290697216
  %sext95 = add i64 %344, 3710851743744
  %345 = ashr exact i64 %sext95, 32
  %346 = getelementptr inbounds float, float* %12, i64 %345
  %347 = bitcast float* %346 to <32 x float>*
  store <32 x float> %343, <32 x float>* %347, align 64, !tbaa !3234
  %348 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %349 = tail call i32 %348(i32 1, i32 %18, i8* nonnull %49)
  %indvars.iv.next69 = add nsw i64 %indvars.iv68, 1
  %350 = icmp slt i64 %indvars.iv.next69, %46
  br i1 %350, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %351 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %49, i64 %351
  %352 = add nsw i64 %351, %56
  call void @llvm.memset.p0i8.i64(i8* nonnull align 128 %47, i8 0, i64 896, i1 false)
  br label %for_body8

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %353 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %438, %for_body8 ]
  %354 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %432, %for_body8 ]
  %355 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %431, %for_body8 ]
  %356 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %430, %for_body8 ]
  %357 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %429, %for_body8 ]
  %358 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %428, %for_body8 ]
  %359 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %427, %for_body8 ]
  %360 = add nsw i64 %352, %indvars.iv
  %361 = getelementptr inbounds float, float* %6, i64 %360
  %362 = load float, float* %361, align 4, !tbaa !3222
  %363 = insertelement <32 x float> undef, float %362, i32 0
  %364 = shufflevector <32 x float> %363, <32 x float> undef, <32 x i32> zeroinitializer
  %365 = shl nsw i64 %indvars.iv, 5
  %366 = add nsw i64 %365, %54
  %367 = getelementptr inbounds float, float* %9, i64 %366
  %368 = bitcast float* %367 to <32 x float>*
  %369 = load <32 x float>, <32 x float>* %368, align 64, !tbaa !3237
  %370 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %364, <32 x float> %369, <32 x float> %359)
  %371 = add nsw i64 %360, 128
  %372 = getelementptr inbounds float, float* %6, i64 %371
  %373 = load float, float* %372, align 4, !tbaa !3222
  %374 = insertelement <32 x float> undef, float %373, i32 0
  %375 = shufflevector <32 x float> %374, <32 x float> undef, <32 x i32> zeroinitializer
  %376 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %375, <32 x float> %369, <32 x float> %358)
  %377 = add nsw i64 %360, 256
  %378 = getelementptr inbounds float, float* %6, i64 %377
  %379 = load float, float* %378, align 4, !tbaa !3222
  %380 = insertelement <32 x float> undef, float %379, i32 0
  %381 = shufflevector <32 x float> %380, <32 x float> undef, <32 x i32> zeroinitializer
  %382 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %369, <32 x float> %357)
  %383 = add nsw i64 %360, 384
  %384 = getelementptr inbounds float, float* %6, i64 %383
  %385 = load float, float* %384, align 4, !tbaa !3222
  %386 = insertelement <32 x float> undef, float %385, i32 0
  %387 = shufflevector <32 x float> %386, <32 x float> undef, <32 x i32> zeroinitializer
  %388 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %387, <32 x float> %369, <32 x float> %356)
  %389 = add nsw i64 %360, 512
  %390 = getelementptr inbounds float, float* %6, i64 %389
  %391 = load float, float* %390, align 4, !tbaa !3222
  %392 = insertelement <32 x float> undef, float %391, i32 0
  %393 = shufflevector <32 x float> %392, <32 x float> undef, <32 x i32> zeroinitializer
  %394 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %369, <32 x float> %355)
  %395 = add nsw i64 %360, 640
  %396 = getelementptr inbounds float, float* %6, i64 %395
  %397 = load float, float* %396, align 4, !tbaa !3222
  %398 = insertelement <32 x float> undef, float %397, i32 0
  %399 = shufflevector <32 x float> %398, <32 x float> undef, <32 x i32> zeroinitializer
  %400 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %369, <32 x float> %354)
  %401 = add nsw i64 %360, 768
  %402 = getelementptr inbounds float, float* %6, i64 %401
  %403 = load float, float* %402, align 4, !tbaa !3222
  %404 = insertelement <32 x float> undef, float %403, i32 0
  %405 = shufflevector <32 x float> %404, <32 x float> undef, <32 x i32> zeroinitializer
  %406 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %369, <32 x float> %353)
  %407 = add nsw i64 %366, 4096
  %408 = getelementptr inbounds float, float* %9, i64 %407
  %409 = bitcast float* %408 to <32 x float>*
  %410 = load <32 x float>, <32 x float>* %409, align 64, !tbaa !3237
  %411 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %375, <32 x float> %410, <32 x float> %370)
  %412 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %410, <32 x float> %376)
  %413 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %387, <32 x float> %410, <32 x float> %382)
  %414 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %410, <32 x float> %388)
  %415 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %410, <32 x float> %394)
  %416 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %410, <32 x float> %400)
  %417 = add nsw i64 %360, 896
  %418 = getelementptr inbounds float, float* %6, i64 %417
  %419 = load float, float* %418, align 4, !tbaa !3222
  %420 = insertelement <32 x float> undef, float %419, i32 0
  %421 = shufflevector <32 x float> %420, <32 x float> undef, <32 x i32> zeroinitializer
  %422 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %410, <32 x float> %406)
  %423 = add nsw i64 %366, 8192
  %424 = getelementptr inbounds float, float* %9, i64 %423
  %425 = bitcast float* %424 to <32 x float>*
  %426 = load <32 x float>, <32 x float>* %425, align 64, !tbaa !3237
  %427 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %426, <32 x float> %411)
  %428 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %387, <32 x float> %426, <32 x float> %412)
  %429 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %426, <32 x float> %413)
  %430 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %426, <32 x float> %414)
  %431 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %426, <32 x float> %415)
  %432 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %426, <32 x float> %416)
  %433 = add nsw i64 %360, 1024
  %434 = getelementptr inbounds float, float* %6, i64 %433
  %435 = load float, float* %434, align 4, !tbaa !3222
  %436 = insertelement <32 x float> undef, float %435, i32 0
  %437 = shufflevector <32 x float> %436, <32 x float> undef, <32 x i32> zeroinitializer
  %438 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %437, <32 x float> %426, <32 x float> %422)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %439 = add nsw i64 %351, %59
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %440 = phi <32 x float> [ %438, %for_end9 ], [ %525, %for_body8.1 ]
  %441 = phi <32 x float> [ %432, %for_end9 ], [ %519, %for_body8.1 ]
  %442 = phi <32 x float> [ %431, %for_end9 ], [ %518, %for_body8.1 ]
  %443 = phi <32 x float> [ %430, %for_end9 ], [ %517, %for_body8.1 ]
  %444 = phi <32 x float> [ %429, %for_end9 ], [ %516, %for_body8.1 ]
  %445 = phi <32 x float> [ %428, %for_end9 ], [ %515, %for_body8.1 ]
  %446 = phi <32 x float> [ %427, %for_end9 ], [ %514, %for_body8.1 ]
  %447 = add nsw i64 %439, %indvars.iv.1
  %448 = getelementptr inbounds float, float* %6, i64 %447
  %449 = load float, float* %448, align 4, !tbaa !3222
  %450 = insertelement <32 x float> undef, float %449, i32 0
  %451 = shufflevector <32 x float> %450, <32 x float> undef, <32 x i32> zeroinitializer
  %452 = shl nsw i64 %indvars.iv.1, 5
  %453 = add nsw i64 %60, %452
  %454 = getelementptr inbounds float, float* %9, i64 %453
  %455 = bitcast float* %454 to <32 x float>*
  %456 = load <32 x float>, <32 x float>* %455, align 64, !tbaa !3237
  %457 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %451, <32 x float> %456, <32 x float> %446)
  %458 = add nsw i64 %447, 128
  %459 = getelementptr inbounds float, float* %6, i64 %458
  %460 = load float, float* %459, align 4, !tbaa !3222
  %461 = insertelement <32 x float> undef, float %460, i32 0
  %462 = shufflevector <32 x float> %461, <32 x float> undef, <32 x i32> zeroinitializer
  %463 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %462, <32 x float> %456, <32 x float> %445)
  %464 = add nsw i64 %447, 256
  %465 = getelementptr inbounds float, float* %6, i64 %464
  %466 = load float, float* %465, align 4, !tbaa !3222
  %467 = insertelement <32 x float> undef, float %466, i32 0
  %468 = shufflevector <32 x float> %467, <32 x float> undef, <32 x i32> zeroinitializer
  %469 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %456, <32 x float> %444)
  %470 = add nsw i64 %447, 384
  %471 = getelementptr inbounds float, float* %6, i64 %470
  %472 = load float, float* %471, align 4, !tbaa !3222
  %473 = insertelement <32 x float> undef, float %472, i32 0
  %474 = shufflevector <32 x float> %473, <32 x float> undef, <32 x i32> zeroinitializer
  %475 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %456, <32 x float> %443)
  %476 = add nsw i64 %447, 512
  %477 = getelementptr inbounds float, float* %6, i64 %476
  %478 = load float, float* %477, align 4, !tbaa !3222
  %479 = insertelement <32 x float> undef, float %478, i32 0
  %480 = shufflevector <32 x float> %479, <32 x float> undef, <32 x i32> zeroinitializer
  %481 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %456, <32 x float> %442)
  %482 = add nsw i64 %447, 640
  %483 = getelementptr inbounds float, float* %6, i64 %482
  %484 = load float, float* %483, align 4, !tbaa !3222
  %485 = insertelement <32 x float> undef, float %484, i32 0
  %486 = shufflevector <32 x float> %485, <32 x float> undef, <32 x i32> zeroinitializer
  %487 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %456, <32 x float> %441)
  %488 = add nsw i64 %447, 768
  %489 = getelementptr inbounds float, float* %6, i64 %488
  %490 = load float, float* %489, align 4, !tbaa !3222
  %491 = insertelement <32 x float> undef, float %490, i32 0
  %492 = shufflevector <32 x float> %491, <32 x float> undef, <32 x i32> zeroinitializer
  %493 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %456, <32 x float> %440)
  %494 = add nsw i64 %453, 4096
  %495 = getelementptr inbounds float, float* %9, i64 %494
  %496 = bitcast float* %495 to <32 x float>*
  %497 = load <32 x float>, <32 x float>* %496, align 64, !tbaa !3237
  %498 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %462, <32 x float> %497, <32 x float> %457)
  %499 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %497, <32 x float> %463)
  %500 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %497, <32 x float> %469)
  %501 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %497, <32 x float> %475)
  %502 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %497, <32 x float> %481)
  %503 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %497, <32 x float> %487)
  %504 = add nsw i64 %447, 896
  %505 = getelementptr inbounds float, float* %6, i64 %504
  %506 = load float, float* %505, align 4, !tbaa !3222
  %507 = insertelement <32 x float> undef, float %506, i32 0
  %508 = shufflevector <32 x float> %507, <32 x float> undef, <32 x i32> zeroinitializer
  %509 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %497, <32 x float> %493)
  %510 = add nsw i64 %453, 8192
  %511 = getelementptr inbounds float, float* %9, i64 %510
  %512 = bitcast float* %511 to <32 x float>*
  %513 = load <32 x float>, <32 x float>* %512, align 64, !tbaa !3237
  %514 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %513, <32 x float> %498)
  %515 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %513, <32 x float> %499)
  %516 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %513, <32 x float> %500)
  %517 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %513, <32 x float> %501)
  %518 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %513, <32 x float> %502)
  %519 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %513, <32 x float> %503)
  %520 = add nsw i64 %447, 1024
  %521 = getelementptr inbounds float, float* %6, i64 %520
  %522 = load float, float* %521, align 4, !tbaa !3222
  %523 = insertelement <32 x float> undef, float %522, i32 0
  %524 = shufflevector <32 x float> %523, <32 x float> undef, <32 x i32> zeroinitializer
  %525 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %524, <32 x float> %513, <32 x float> %509)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %526 = add nsw i64 %351, %63
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %527 = phi <32 x float> [ %525, %for_end9.1 ], [ %612, %for_body8.2 ]
  %528 = phi <32 x float> [ %519, %for_end9.1 ], [ %606, %for_body8.2 ]
  %529 = phi <32 x float> [ %518, %for_end9.1 ], [ %605, %for_body8.2 ]
  %530 = phi <32 x float> [ %517, %for_end9.1 ], [ %604, %for_body8.2 ]
  %531 = phi <32 x float> [ %516, %for_end9.1 ], [ %603, %for_body8.2 ]
  %532 = phi <32 x float> [ %515, %for_end9.1 ], [ %602, %for_body8.2 ]
  %533 = phi <32 x float> [ %514, %for_end9.1 ], [ %601, %for_body8.2 ]
  %534 = add nsw i64 %526, %indvars.iv.2
  %535 = getelementptr inbounds float, float* %6, i64 %534
  %536 = load float, float* %535, align 4, !tbaa !3222
  %537 = insertelement <32 x float> undef, float %536, i32 0
  %538 = shufflevector <32 x float> %537, <32 x float> undef, <32 x i32> zeroinitializer
  %539 = shl nsw i64 %indvars.iv.2, 5
  %540 = add nsw i64 %64, %539
  %541 = getelementptr inbounds float, float* %9, i64 %540
  %542 = bitcast float* %541 to <32 x float>*
  %543 = load <32 x float>, <32 x float>* %542, align 64, !tbaa !3237
  %544 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %538, <32 x float> %543, <32 x float> %533)
  %545 = add nsw i64 %534, 128
  %546 = getelementptr inbounds float, float* %6, i64 %545
  %547 = load float, float* %546, align 4, !tbaa !3222
  %548 = insertelement <32 x float> undef, float %547, i32 0
  %549 = shufflevector <32 x float> %548, <32 x float> undef, <32 x i32> zeroinitializer
  %550 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %549, <32 x float> %543, <32 x float> %532)
  %551 = add nsw i64 %534, 256
  %552 = getelementptr inbounds float, float* %6, i64 %551
  %553 = load float, float* %552, align 4, !tbaa !3222
  %554 = insertelement <32 x float> undef, float %553, i32 0
  %555 = shufflevector <32 x float> %554, <32 x float> undef, <32 x i32> zeroinitializer
  %556 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %555, <32 x float> %543, <32 x float> %531)
  %557 = add nsw i64 %534, 384
  %558 = getelementptr inbounds float, float* %6, i64 %557
  %559 = load float, float* %558, align 4, !tbaa !3222
  %560 = insertelement <32 x float> undef, float %559, i32 0
  %561 = shufflevector <32 x float> %560, <32 x float> undef, <32 x i32> zeroinitializer
  %562 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %561, <32 x float> %543, <32 x float> %530)
  %563 = add nsw i64 %534, 512
  %564 = getelementptr inbounds float, float* %6, i64 %563
  %565 = load float, float* %564, align 4, !tbaa !3222
  %566 = insertelement <32 x float> undef, float %565, i32 0
  %567 = shufflevector <32 x float> %566, <32 x float> undef, <32 x i32> zeroinitializer
  %568 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %567, <32 x float> %543, <32 x float> %529)
  %569 = add nsw i64 %534, 640
  %570 = getelementptr inbounds float, float* %6, i64 %569
  %571 = load float, float* %570, align 4, !tbaa !3222
  %572 = insertelement <32 x float> undef, float %571, i32 0
  %573 = shufflevector <32 x float> %572, <32 x float> undef, <32 x i32> zeroinitializer
  %574 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %573, <32 x float> %543, <32 x float> %528)
  %575 = add nsw i64 %534, 768
  %576 = getelementptr inbounds float, float* %6, i64 %575
  %577 = load float, float* %576, align 4, !tbaa !3222
  %578 = insertelement <32 x float> undef, float %577, i32 0
  %579 = shufflevector <32 x float> %578, <32 x float> undef, <32 x i32> zeroinitializer
  %580 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %579, <32 x float> %543, <32 x float> %527)
  %581 = add nsw i64 %540, 4096
  %582 = getelementptr inbounds float, float* %9, i64 %581
  %583 = bitcast float* %582 to <32 x float>*
  %584 = load <32 x float>, <32 x float>* %583, align 64, !tbaa !3237
  %585 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %549, <32 x float> %584, <32 x float> %544)
  %586 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %555, <32 x float> %584, <32 x float> %550)
  %587 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %561, <32 x float> %584, <32 x float> %556)
  %588 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %567, <32 x float> %584, <32 x float> %562)
  %589 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %573, <32 x float> %584, <32 x float> %568)
  %590 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %579, <32 x float> %584, <32 x float> %574)
  %591 = add nsw i64 %534, 896
  %592 = getelementptr inbounds float, float* %6, i64 %591
  %593 = load float, float* %592, align 4, !tbaa !3222
  %594 = insertelement <32 x float> undef, float %593, i32 0
  %595 = shufflevector <32 x float> %594, <32 x float> undef, <32 x i32> zeroinitializer
  %596 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %584, <32 x float> %580)
  %597 = add nsw i64 %540, 8192
  %598 = getelementptr inbounds float, float* %9, i64 %597
  %599 = bitcast float* %598 to <32 x float>*
  %600 = load <32 x float>, <32 x float>* %599, align 64, !tbaa !3237
  %601 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %555, <32 x float> %600, <32 x float> %585)
  %602 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %561, <32 x float> %600, <32 x float> %586)
  %603 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %567, <32 x float> %600, <32 x float> %587)
  %604 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %573, <32 x float> %600, <32 x float> %588)
  %605 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %579, <32 x float> %600, <32 x float> %589)
  %606 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %600, <32 x float> %590)
  %607 = add nsw i64 %534, 1024
  %608 = getelementptr inbounds float, float* %6, i64 %607
  %609 = load float, float* %608, align 4, !tbaa !3222
  %610 = insertelement <32 x float> undef, float %609, i32 0
  %611 = shufflevector <32 x float> %610, <32 x float> undef, <32 x i32> zeroinitializer
  %612 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %611, <32 x float> %600, <32 x float> %596)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 128
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !50

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %601, <32 x float>* %.sub, align 128, !tbaa !3240
  store <32 x float> %602, <32 x float>* %32, align 128, !tbaa !3240
  store <32 x float> %603, <32 x float>* %34, align 128, !tbaa !3240
  store <32 x float> %604, <32 x float>* %36, align 128, !tbaa !3240
  store <32 x float> %605, <32 x float>* %38, align 128, !tbaa !3240
  store <32 x float> %606, <32 x float>* %40, align 128, !tbaa !3240
  store <32 x float> %612, <32 x float>* %42, align 128, !tbaa !3240
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 64 %scevgep, i8* nonnull align 128 %4, i64 896, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond61 = icmp eq i64 %indvar.next, 4
  br i1 %exitcond61, label %for_begin13.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_nn_adaptive_avg_pool2d(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.283, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !3249
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([156 x i8], [156 x i8]* @.str.284, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !3263
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([156 x i8], [156 x i8]* @.str.285, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !3265
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !3279
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 16
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !3281
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 7
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !3284
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 7
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.94, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !3286
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 32
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !3290
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 25088, i32 1568, i32 224, i32 32>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !3302
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.237, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !3306
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !3320
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 16
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.180, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !3322
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 1
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.286, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !3325
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 1
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.287, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !3327
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 32
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.172, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !3331
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 512, i32 32, i32 32, i32 32>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !3343
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.288, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_nn_adaptive_avg_pool2d_compute_(i8* %15, i8* %25, i32 %23)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_adaptive_avg_pool2d_compute_(i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %3 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %4 = tail call i8* %3(i32 1, i32 %2, i64 2048, i32 2, i32 32)
  %5 = alloca %32, align 8
  %6 = getelementptr inbounds %32, %32* %5, i64 0, i32 0
  store i8* %4, i8** %6, align 8
  %7 = getelementptr inbounds %32, %32* %5, i64 0, i32 1
  store i8* %0, i8** %7, align 8
  %8 = bitcast %32* %5 to i8*
  %9 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %10 = call i32 %9(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.289, i8* nonnull %8, i32 0)
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %10, %entry ], [ 0, %call_end2 ], [ %17, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %12 = alloca %33, align 8
  %13 = getelementptr inbounds %33, %33* %12, i64 0, i32 0
  store i8* %1, i8** %13, align 8
  %14 = getelementptr inbounds %33, %33* %12, i64 0, i32 1
  store i8* %4, i8** %14, align 8
  %15 = bitcast %33* %12 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.290, i8* nonnull %15, i32 0)
  %18 = icmp eq i32 %17, 0
  br i1 %18, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %19 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %20 = call i32 %19(i32 1, i32 %2, i8* %4)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.289(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 15
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 16
  %15 = select i1 %14, i32 %13, i32 16
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 16
  %18 = select i1 %17, i32 %16, i32 16
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv14 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next15, %for_end3 ]
  %24 = trunc i64 %indvars.iv14 to i32
  %25 = shl i32 %24, 5
  %26 = mul nsw i64 %indvars.iv14, 1568
  %27 = sext i32 %25 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body2 ]
  %28 = add nuw nsw i64 %indvars.iv, %27
  %29 = getelementptr inbounds float, float* %4, i64 %28
  store float 0.000000e+00, float* %29, align 4, !tbaa !3347
  %30 = add nsw i64 %indvars.iv, %26
  %31 = getelementptr inbounds float, float* %7, i64 %30
  %32 = load float, float* %31, align 4, !tbaa !3350
  %33 = fadd float %32, 0.000000e+00
  %34 = shl i64 %30, 32
  %sext = add i64 %34, 137438953472
  %35 = ashr exact i64 %sext, 32
  %36 = getelementptr inbounds float, float* %7, i64 %35
  %37 = load float, float* %36, align 4, !tbaa !3350
  %38 = fadd float %37, %33
  %39 = shl i64 %30, 32
  %sext16 = add i64 %39, 274877906944
  %40 = ashr exact i64 %sext16, 32
  %41 = getelementptr inbounds float, float* %7, i64 %40
  %42 = load float, float* %41, align 4, !tbaa !3350
  %43 = fadd float %42, %38
  %44 = shl i64 %30, 32
  %sext17 = add i64 %44, 412316860416
  %45 = ashr exact i64 %sext17, 32
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = load float, float* %46, align 4, !tbaa !3350
  %48 = fadd float %47, %43
  %49 = shl i64 %30, 32
  %sext18 = add i64 %49, 549755813888
  %50 = ashr exact i64 %sext18, 32
  %51 = getelementptr inbounds float, float* %7, i64 %50
  %52 = load float, float* %51, align 4, !tbaa !3350
  %53 = fadd float %52, %48
  %54 = shl i64 %30, 32
  %sext19 = add i64 %54, 687194767360
  %55 = ashr exact i64 %sext19, 32
  %56 = getelementptr inbounds float, float* %7, i64 %55
  %57 = load float, float* %56, align 4, !tbaa !3350
  %58 = fadd float %57, %53
  %59 = shl i64 %30, 32
  %sext20 = add i64 %59, 824633720832
  %60 = ashr exact i64 %sext20, 32
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = load float, float* %61, align 4, !tbaa !3350
  %63 = fadd float %62, %58
  %64 = shl i64 %30, 32
  %sext57 = add i64 %64, 962072674304
  %65 = ashr exact i64 %sext57, 32
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = load float, float* %66, align 4, !tbaa !3350
  %68 = fadd float %67, %63
  %69 = shl i64 %30, 32
  %sext21 = add i64 %69, 1099511627776
  %70 = ashr exact i64 %sext21, 32
  %71 = getelementptr inbounds float, float* %7, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !3350
  %73 = fadd float %72, %68
  %74 = shl i64 %30, 32
  %sext22 = add i64 %74, 1236950581248
  %75 = ashr exact i64 %sext22, 32
  %76 = getelementptr inbounds float, float* %7, i64 %75
  %77 = load float, float* %76, align 4, !tbaa !3350
  %78 = fadd float %77, %73
  %79 = shl i64 %30, 32
  %sext23 = add i64 %79, 1374389534720
  %80 = ashr exact i64 %sext23, 32
  %81 = getelementptr inbounds float, float* %7, i64 %80
  %82 = load float, float* %81, align 4, !tbaa !3350
  %83 = fadd float %82, %78
  %84 = shl i64 %30, 32
  %sext24 = add i64 %84, 1511828488192
  %85 = ashr exact i64 %sext24, 32
  %86 = getelementptr inbounds float, float* %7, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !3350
  %88 = fadd float %87, %83
  %89 = shl i64 %30, 32
  %sext25 = add i64 %89, 1649267441664
  %90 = ashr exact i64 %sext25, 32
  %91 = getelementptr inbounds float, float* %7, i64 %90
  %92 = load float, float* %91, align 4, !tbaa !3350
  %93 = fadd float %92, %88
  %94 = shl i64 %30, 32
  %sext26 = add i64 %94, 1786706395136
  %95 = ashr exact i64 %sext26, 32
  %96 = getelementptr inbounds float, float* %7, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !3350
  %98 = fadd float %97, %93
  %99 = shl i64 %30, 32
  %sext58 = add i64 %99, 1924145348608
  %100 = ashr exact i64 %sext58, 32
  %101 = getelementptr inbounds float, float* %7, i64 %100
  %102 = load float, float* %101, align 4, !tbaa !3350
  %103 = fadd float %102, %98
  %104 = shl i64 %30, 32
  %sext27 = add i64 %104, 2061584302080
  %105 = ashr exact i64 %sext27, 32
  %106 = getelementptr inbounds float, float* %7, i64 %105
  %107 = load float, float* %106, align 4, !tbaa !3350
  %108 = fadd float %107, %103
  %109 = shl i64 %30, 32
  %sext28 = add i64 %109, 2199023255552
  %110 = ashr exact i64 %sext28, 32
  %111 = getelementptr inbounds float, float* %7, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !3350
  %113 = fadd float %112, %108
  %114 = shl i64 %30, 32
  %sext29 = add i64 %114, 2336462209024
  %115 = ashr exact i64 %sext29, 32
  %116 = getelementptr inbounds float, float* %7, i64 %115
  %117 = load float, float* %116, align 4, !tbaa !3350
  %118 = fadd float %117, %113
  %119 = shl i64 %30, 32
  %sext30 = add i64 %119, 2473901162496
  %120 = ashr exact i64 %sext30, 32
  %121 = getelementptr inbounds float, float* %7, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !3350
  %123 = fadd float %122, %118
  %124 = shl i64 %30, 32
  %sext31 = add i64 %124, 2611340115968
  %125 = ashr exact i64 %sext31, 32
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !3350
  %128 = fadd float %127, %123
  %129 = shl i64 %30, 32
  %sext32 = add i64 %129, 2748779069440
  %130 = ashr exact i64 %sext32, 32
  %131 = getelementptr inbounds float, float* %7, i64 %130
  %132 = load float, float* %131, align 4, !tbaa !3350
  %133 = fadd float %132, %128
  %134 = shl i64 %30, 32
  %sext59 = add i64 %134, 2886218022912
  %135 = ashr exact i64 %sext59, 32
  %136 = getelementptr inbounds float, float* %7, i64 %135
  %137 = load float, float* %136, align 4, !tbaa !3350
  %138 = fadd float %137, %133
  %139 = shl i64 %30, 32
  %sext33 = add i64 %139, 3023656976384
  %140 = ashr exact i64 %sext33, 32
  %141 = getelementptr inbounds float, float* %7, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !3350
  %143 = fadd float %142, %138
  %144 = shl i64 %30, 32
  %sext34 = add i64 %144, 3161095929856
  %145 = ashr exact i64 %sext34, 32
  %146 = getelementptr inbounds float, float* %7, i64 %145
  %147 = load float, float* %146, align 4, !tbaa !3350
  %148 = fadd float %147, %143
  %149 = shl i64 %30, 32
  %sext35 = add i64 %149, 3298534883328
  %150 = ashr exact i64 %sext35, 32
  %151 = getelementptr inbounds float, float* %7, i64 %150
  %152 = load float, float* %151, align 4, !tbaa !3350
  %153 = fadd float %152, %148
  %154 = shl i64 %30, 32
  %sext36 = add i64 %154, 3435973836800
  %155 = ashr exact i64 %sext36, 32
  %156 = getelementptr inbounds float, float* %7, i64 %155
  %157 = load float, float* %156, align 4, !tbaa !3350
  %158 = fadd float %157, %153
  %159 = shl i64 %30, 32
  %sext37 = add i64 %159, 3573412790272
  %160 = ashr exact i64 %sext37, 32
  %161 = getelementptr inbounds float, float* %7, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !3350
  %163 = fadd float %162, %158
  %164 = shl i64 %30, 32
  %sext38 = add i64 %164, 3710851743744
  %165 = ashr exact i64 %sext38, 32
  %166 = getelementptr inbounds float, float* %7, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !3350
  %168 = fadd float %167, %163
  %169 = shl i64 %30, 32
  %sext60 = add i64 %169, 3848290697216
  %170 = ashr exact i64 %sext60, 32
  %171 = getelementptr inbounds float, float* %7, i64 %170
  %172 = load float, float* %171, align 4, !tbaa !3350
  %173 = fadd float %172, %168
  %174 = shl i64 %30, 32
  %sext39 = add i64 %174, 3985729650688
  %175 = ashr exact i64 %sext39, 32
  %176 = getelementptr inbounds float, float* %7, i64 %175
  %177 = load float, float* %176, align 4, !tbaa !3350
  %178 = fadd float %177, %173
  %179 = shl i64 %30, 32
  %sext40 = add i64 %179, 4123168604160
  %180 = ashr exact i64 %sext40, 32
  %181 = getelementptr inbounds float, float* %7, i64 %180
  %182 = load float, float* %181, align 4, !tbaa !3350
  %183 = fadd float %182, %178
  %184 = shl i64 %30, 32
  %sext41 = add i64 %184, 4260607557632
  %185 = ashr exact i64 %sext41, 32
  %186 = getelementptr inbounds float, float* %7, i64 %185
  %187 = load float, float* %186, align 4, !tbaa !3350
  %188 = fadd float %187, %183
  %189 = shl i64 %30, 32
  %sext42 = add i64 %189, 4398046511104
  %190 = ashr exact i64 %sext42, 32
  %191 = getelementptr inbounds float, float* %7, i64 %190
  %192 = load float, float* %191, align 4, !tbaa !3350
  %193 = fadd float %192, %188
  %194 = shl i64 %30, 32
  %sext43 = add i64 %194, 4535485464576
  %195 = ashr exact i64 %sext43, 32
  %196 = getelementptr inbounds float, float* %7, i64 %195
  %197 = load float, float* %196, align 4, !tbaa !3350
  %198 = fadd float %197, %193
  %199 = shl i64 %30, 32
  %sext44 = add i64 %199, 4672924418048
  %200 = ashr exact i64 %sext44, 32
  %201 = getelementptr inbounds float, float* %7, i64 %200
  %202 = load float, float* %201, align 4, !tbaa !3350
  %203 = fadd float %202, %198
  %204 = shl i64 %30, 32
  %sext61 = add i64 %204, 4810363371520
  %205 = ashr exact i64 %sext61, 32
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !3350
  %208 = fadd float %207, %203
  %209 = shl i64 %30, 32
  %sext45 = add i64 %209, 4947802324992
  %210 = ashr exact i64 %sext45, 32
  %211 = getelementptr inbounds float, float* %7, i64 %210
  %212 = load float, float* %211, align 4, !tbaa !3350
  %213 = fadd float %212, %208
  %214 = shl i64 %30, 32
  %sext46 = add i64 %214, 5085241278464
  %215 = ashr exact i64 %sext46, 32
  %216 = getelementptr inbounds float, float* %7, i64 %215
  %217 = load float, float* %216, align 4, !tbaa !3350
  %218 = fadd float %217, %213
  %219 = shl i64 %30, 32
  %sext47 = add i64 %219, 5222680231936
  %220 = ashr exact i64 %sext47, 32
  %221 = getelementptr inbounds float, float* %7, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !3350
  %223 = fadd float %222, %218
  %224 = shl i64 %30, 32
  %sext48 = add i64 %224, 5360119185408
  %225 = ashr exact i64 %sext48, 32
  %226 = getelementptr inbounds float, float* %7, i64 %225
  %227 = load float, float* %226, align 4, !tbaa !3350
  %228 = fadd float %227, %223
  %229 = shl i64 %30, 32
  %sext49 = add i64 %229, 5497558138880
  %230 = ashr exact i64 %sext49, 32
  %231 = getelementptr inbounds float, float* %7, i64 %230
  %232 = load float, float* %231, align 4, !tbaa !3350
  %233 = fadd float %232, %228
  %234 = shl i64 %30, 32
  %sext50 = add i64 %234, 5634997092352
  %235 = ashr exact i64 %sext50, 32
  %236 = getelementptr inbounds float, float* %7, i64 %235
  %237 = load float, float* %236, align 4, !tbaa !3350
  %238 = fadd float %237, %233
  %239 = shl i64 %30, 32
  %sext62 = add i64 %239, 5772436045824
  %240 = ashr exact i64 %sext62, 32
  %241 = getelementptr inbounds float, float* %7, i64 %240
  %242 = load float, float* %241, align 4, !tbaa !3350
  %243 = fadd float %242, %238
  %244 = shl i64 %30, 32
  %sext51 = add i64 %244, 5909874999296
  %245 = ashr exact i64 %sext51, 32
  %246 = getelementptr inbounds float, float* %7, i64 %245
  %247 = load float, float* %246, align 4, !tbaa !3350
  %248 = fadd float %247, %243
  %249 = shl i64 %30, 32
  %sext52 = add i64 %249, 6047313952768
  %250 = ashr exact i64 %sext52, 32
  %251 = getelementptr inbounds float, float* %7, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !3350
  %253 = fadd float %252, %248
  %254 = shl i64 %30, 32
  %sext53 = add i64 %254, 6184752906240
  %255 = ashr exact i64 %sext53, 32
  %256 = getelementptr inbounds float, float* %7, i64 %255
  %257 = load float, float* %256, align 4, !tbaa !3350
  %258 = fadd float %257, %253
  %259 = shl i64 %30, 32
  %sext54 = add i64 %259, 6322191859712
  %260 = ashr exact i64 %sext54, 32
  %261 = getelementptr inbounds float, float* %7, i64 %260
  %262 = load float, float* %261, align 4, !tbaa !3350
  %263 = fadd float %262, %258
  %264 = shl i64 %30, 32
  %sext55 = add i64 %264, 6459630813184
  %265 = ashr exact i64 %sext55, 32
  %266 = getelementptr inbounds float, float* %7, i64 %265
  %267 = load float, float* %266, align 4, !tbaa !3350
  %268 = fadd float %267, %263
  %269 = shl i64 %30, 32
  %sext56 = add i64 %269, 6597069766656
  %270 = ashr exact i64 %sext56, 32
  %271 = getelementptr inbounds float, float* %7, i64 %270
  %272 = load float, float* %271, align 4, !tbaa !3350
  %273 = fadd float %272, %268
  store float %273, float* %29, align 4, !tbaa !3347
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next15 = add nsw i64 %indvars.iv14, 1
  %274 = icmp slt i64 %indvars.iv.next15, %23
  br i1 %274, label %for_begin1.preheader, label %for_end, !prof !5
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.290(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 15
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 16
  %15 = select i1 %14, i32 %13, i32 16
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 16
  %18 = select i1 %17, i32 %16, i32 16
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_begin1.preheader ]
  %24 = trunc i64 %indvars.iv to i32
  %25 = shl i32 %24, 5
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds float, float* %7, i64 %26
  %28 = getelementptr inbounds float, float* %4, i64 %26
  %29 = bitcast float* %27 to <4 x float>*
  %30 = load <4 x float>, <4 x float>* %29, align 4, !tbaa !3347
  %31 = fmul <4 x float> %30, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %32 = bitcast float* %28 to <4 x float>*
  store <4 x float> %31, <4 x float>* %32, align 4, !tbaa !3353
  %33 = or i64 %26, 4
  %34 = getelementptr inbounds float, float* %7, i64 %33
  %35 = getelementptr inbounds float, float* %4, i64 %33
  %36 = bitcast float* %34 to <4 x float>*
  %37 = load <4 x float>, <4 x float>* %36, align 4, !tbaa !3347
  %38 = fmul <4 x float> %37, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %39 = bitcast float* %35 to <4 x float>*
  store <4 x float> %38, <4 x float>* %39, align 4, !tbaa !3353
  %40 = or i64 %26, 8
  %41 = getelementptr inbounds float, float* %7, i64 %40
  %42 = getelementptr inbounds float, float* %4, i64 %40
  %43 = bitcast float* %41 to <4 x float>*
  %44 = load <4 x float>, <4 x float>* %43, align 4, !tbaa !3347
  %45 = fmul <4 x float> %44, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %46 = bitcast float* %42 to <4 x float>*
  store <4 x float> %45, <4 x float>* %46, align 4, !tbaa !3353
  %47 = or i64 %26, 12
  %48 = getelementptr inbounds float, float* %7, i64 %47
  %49 = getelementptr inbounds float, float* %4, i64 %47
  %50 = bitcast float* %48 to <4 x float>*
  %51 = load <4 x float>, <4 x float>* %50, align 4, !tbaa !3347
  %52 = fmul <4 x float> %51, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %53 = bitcast float* %49 to <4 x float>*
  store <4 x float> %52, <4 x float>* %53, align 4, !tbaa !3353
  %54 = or i64 %26, 16
  %55 = getelementptr inbounds float, float* %7, i64 %54
  %56 = getelementptr inbounds float, float* %4, i64 %54
  %57 = bitcast float* %55 to <4 x float>*
  %58 = load <4 x float>, <4 x float>* %57, align 4, !tbaa !3347
  %59 = fmul <4 x float> %58, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %60 = bitcast float* %56 to <4 x float>*
  store <4 x float> %59, <4 x float>* %60, align 4, !tbaa !3353
  %61 = or i64 %26, 20
  %62 = getelementptr inbounds float, float* %7, i64 %61
  %63 = getelementptr inbounds float, float* %4, i64 %61
  %64 = bitcast float* %62 to <4 x float>*
  %65 = load <4 x float>, <4 x float>* %64, align 4, !tbaa !3347
  %66 = fmul <4 x float> %65, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %67 = bitcast float* %63 to <4 x float>*
  store <4 x float> %66, <4 x float>* %67, align 4, !tbaa !3353
  %68 = or i64 %26, 24
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = getelementptr inbounds float, float* %4, i64 %68
  %71 = bitcast float* %69 to <4 x float>*
  %72 = load <4 x float>, <4 x float>* %71, align 4, !tbaa !3347
  %73 = fmul <4 x float> %72, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %74 = bitcast float* %70 to <4 x float>*
  store <4 x float> %73, <4 x float>* %74, align 4, !tbaa !3353
  %75 = or i64 %26, 28
  %76 = getelementptr inbounds float, float* %7, i64 %75
  %77 = getelementptr inbounds float, float* %4, i64 %75
  %78 = bitcast float* %76 to <4 x float>*
  %79 = load <4 x float>, <4 x float>* %78, align 4, !tbaa !3347
  %80 = fmul <4 x float> %79, <float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000, float 0x3F94E5E0A0000000>
  %81 = bitcast float* %77 to <4 x float>*
  store <4 x float> %80, <4 x float>* %81, align 4, !tbaa !3353
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %82 = icmp slt i64 %indvars.iv.next, %23
  br i1 %82, label %for_begin1.preheader, label %for_end, !prof !5

for_end:                                          ; preds = %for_begin1.preheader, %entry
  ret i32 0
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_2(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([88 x i8], [88 x i8]* @.str.291, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !3356
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !3370
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !3373
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.292, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !3375
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.293, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.294, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.295, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !3377
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !3391
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 2
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !3393
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 14
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !3396
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 14
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !3398
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 128
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !3402
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 50176, i32 25088, i32 1792, i32 128>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !3414
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.218, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !3418
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 16
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !3432
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 2
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !3434
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 1
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.286, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !3437
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 1
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.287, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !3439
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 128
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !3443
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !3445
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 8192, i32 4096, i32 4096, i32 4096>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !3457
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !3461
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([275 x i8], [275 x i8]* @.str.296, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !3463
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !3477
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 16
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !3479
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !3482
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !3484
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !3488
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 512, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !3500
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.101, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !3504
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !3518
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 16
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !3520
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 7
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !3523
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 7
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.104, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !3525
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !3529
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 25088, i32 1568, i32 224, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !3541
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.105, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_2_compute_(i8* %27, i8* %37, i8* %49, i8* %43)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %4 = alloca %34, align 8
  %5 = getelementptr inbounds %34, %34* %4, i64 0, i32 0
  store i8* %0, i8** %5, align 8
  %6 = getelementptr inbounds %34, %34* %4, i64 0, i32 1
  store i8* %1, i8** %6, align 8
  %7 = getelementptr inbounds %34, %34* %4, i64 0, i32 2
  store i8* %2, i8** %7, align 8
  %8 = getelementptr inbounds %34, %34* %4, i64 0, i32 3
  store i8* %3, i8** %8, align 8
  %9 = bitcast %34* %4 to i8*
  %10 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %11 = call i32 %10(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.297, i8* nonnull %9, i32 0)
  ret i32 %11
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.297(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 111
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 112
  %21 = select i1 %20, i32 %19, i32 112
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv48 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next49, %for_end6.1 ]
  %30 = trunc i64 %indvars.iv48 to i32
  %31 = srem i32 %30, 7
  %32 = mul nsw i32 %31, 3584
  %33 = sdiv i32 %30, 7
  %34 = shl i32 %33, 13
  %35 = sext i32 %32 to i64
  %36 = sext i32 %34 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %37 = phi <32 x float> [ zeroinitializer, %for_body ], [ %90, %for_body5 ]
  %38 = phi <32 x float> [ zeroinitializer, %for_body ], [ %84, %for_body5 ]
  %39 = phi <32 x float> [ zeroinitializer, %for_body ], [ %78, %for_body5 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %72, %for_body5 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %66, %for_body5 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %60, %for_body5 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %54, %for_body5 ]
  %44 = add nsw i64 %indvars.iv, %35
  %45 = getelementptr inbounds float, float* %4, i64 %44
  %46 = load float, float* %45, align 4, !tbaa !3545
  %47 = insertelement <32 x float> undef, float %46, i32 0
  %48 = shufflevector <32 x float> %47, <32 x float> undef, <32 x i32> zeroinitializer
  %49 = shl i64 %indvars.iv, 5
  %50 = add nuw nsw i64 %49, %36
  %51 = getelementptr inbounds float, float* %7, i64 %50
  %52 = bitcast float* %51 to <32 x float>*
  %53 = load <32 x float>, <32 x float>* %52, align 64, !tbaa !3548
  %54 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %48, <32 x float> %53, <32 x float> %43)
  %55 = add nsw i64 %44, 256
  %56 = getelementptr inbounds float, float* %4, i64 %55
  %57 = load float, float* %56, align 4, !tbaa !3545
  %58 = insertelement <32 x float> undef, float %57, i32 0
  %59 = shufflevector <32 x float> %58, <32 x float> undef, <32 x i32> zeroinitializer
  %60 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %59, <32 x float> %53, <32 x float> %42)
  %61 = add nsw i64 %44, 512
  %62 = getelementptr inbounds float, float* %4, i64 %61
  %63 = load float, float* %62, align 4, !tbaa !3545
  %64 = insertelement <32 x float> undef, float %63, i32 0
  %65 = shufflevector <32 x float> %64, <32 x float> undef, <32 x i32> zeroinitializer
  %66 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %53, <32 x float> %41)
  %67 = add nsw i64 %44, 768
  %68 = getelementptr inbounds float, float* %4, i64 %67
  %69 = load float, float* %68, align 4, !tbaa !3545
  %70 = insertelement <32 x float> undef, float %69, i32 0
  %71 = shufflevector <32 x float> %70, <32 x float> undef, <32 x i32> zeroinitializer
  %72 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %53, <32 x float> %40)
  %73 = add nsw i64 %44, 1024
  %74 = getelementptr inbounds float, float* %4, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !3545
  %76 = insertelement <32 x float> undef, float %75, i32 0
  %77 = shufflevector <32 x float> %76, <32 x float> undef, <32 x i32> zeroinitializer
  %78 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %53, <32 x float> %39)
  %79 = add nsw i64 %44, 1280
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !3545
  %82 = insertelement <32 x float> undef, float %81, i32 0
  %83 = shufflevector <32 x float> %82, <32 x float> undef, <32 x i32> zeroinitializer
  %84 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %53, <32 x float> %38)
  %85 = add nsw i64 %44, 1536
  %86 = getelementptr inbounds float, float* %4, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !3545
  %88 = insertelement <32 x float> undef, float %87, i32 0
  %89 = shufflevector <32 x float> %88, <32 x float> undef, <32 x i32> zeroinitializer
  %90 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %53, <32 x float> %37)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %91 = add nsw i64 %35, 25088
  %92 = or i64 %36, 4096
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %93 = phi <32 x float> [ %90, %for_end6 ], [ %146, %for_body5.1 ]
  %94 = phi <32 x float> [ %84, %for_end6 ], [ %140, %for_body5.1 ]
  %95 = phi <32 x float> [ %78, %for_end6 ], [ %134, %for_body5.1 ]
  %96 = phi <32 x float> [ %72, %for_end6 ], [ %128, %for_body5.1 ]
  %97 = phi <32 x float> [ %66, %for_end6 ], [ %122, %for_body5.1 ]
  %98 = phi <32 x float> [ %60, %for_end6 ], [ %116, %for_body5.1 ]
  %99 = phi <32 x float> [ %54, %for_end6 ], [ %110, %for_body5.1 ]
  %100 = add nsw i64 %91, %indvars.iv.1
  %101 = getelementptr inbounds float, float* %4, i64 %100
  %102 = load float, float* %101, align 4, !tbaa !3545
  %103 = insertelement <32 x float> undef, float %102, i32 0
  %104 = shufflevector <32 x float> %103, <32 x float> undef, <32 x i32> zeroinitializer
  %105 = shl i64 %indvars.iv.1, 5
  %106 = add nuw nsw i64 %92, %105
  %107 = getelementptr inbounds float, float* %7, i64 %106
  %108 = bitcast float* %107 to <32 x float>*
  %109 = load <32 x float>, <32 x float>* %108, align 64, !tbaa !3548
  %110 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %104, <32 x float> %109, <32 x float> %99)
  %111 = add nsw i64 %100, 256
  %112 = getelementptr inbounds float, float* %4, i64 %111
  %113 = load float, float* %112, align 4, !tbaa !3545
  %114 = insertelement <32 x float> undef, float %113, i32 0
  %115 = shufflevector <32 x float> %114, <32 x float> undef, <32 x i32> zeroinitializer
  %116 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %115, <32 x float> %109, <32 x float> %98)
  %117 = add nsw i64 %100, 512
  %118 = getelementptr inbounds float, float* %4, i64 %117
  %119 = load float, float* %118, align 4, !tbaa !3545
  %120 = insertelement <32 x float> undef, float %119, i32 0
  %121 = shufflevector <32 x float> %120, <32 x float> undef, <32 x i32> zeroinitializer
  %122 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %121, <32 x float> %109, <32 x float> %97)
  %123 = add nsw i64 %100, 768
  %124 = getelementptr inbounds float, float* %4, i64 %123
  %125 = load float, float* %124, align 4, !tbaa !3545
  %126 = insertelement <32 x float> undef, float %125, i32 0
  %127 = shufflevector <32 x float> %126, <32 x float> undef, <32 x i32> zeroinitializer
  %128 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %127, <32 x float> %109, <32 x float> %96)
  %129 = add nsw i64 %100, 1024
  %130 = getelementptr inbounds float, float* %4, i64 %129
  %131 = load float, float* %130, align 4, !tbaa !3545
  %132 = insertelement <32 x float> undef, float %131, i32 0
  %133 = shufflevector <32 x float> %132, <32 x float> undef, <32 x i32> zeroinitializer
  %134 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %133, <32 x float> %109, <32 x float> %95)
  %135 = add nsw i64 %100, 1280
  %136 = getelementptr inbounds float, float* %4, i64 %135
  %137 = load float, float* %136, align 4, !tbaa !3545
  %138 = insertelement <32 x float> undef, float %137, i32 0
  %139 = shufflevector <32 x float> %138, <32 x float> undef, <32 x i32> zeroinitializer
  %140 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %139, <32 x float> %109, <32 x float> %94)
  %141 = add nsw i64 %100, 1536
  %142 = getelementptr inbounds float, float* %4, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !3545
  %144 = insertelement <32 x float> undef, float %143, i32 0
  %145 = shufflevector <32 x float> %144, <32 x float> undef, <32 x i32> zeroinitializer
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %145, <32 x float> %109, <32 x float> %93)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %147 = mul nsw i64 %indvars.iv48, 224
  %148 = shl nsw i32 %33, 5
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds float, float* %13, i64 %149
  %151 = bitcast float* %150 to <32 x float>*
  %152 = load <32 x float>, <32 x float>* %151, align 64, !tbaa !3551
  %153 = fadd <32 x float> %152, %110
  %154 = getelementptr inbounds float, float* %10, i64 %147
  %155 = bitcast float* %154 to <32 x float>*
  store <32 x float> %153, <32 x float>* %155, align 64, !tbaa !3554
  %156 = add nsw i64 %147, 32
  %157 = fadd <32 x float> %152, %116
  %158 = getelementptr inbounds float, float* %10, i64 %156
  %159 = bitcast float* %158 to <32 x float>*
  store <32 x float> %157, <32 x float>* %159, align 64, !tbaa !3554
  %160 = add nsw i64 %147, 64
  %161 = fadd <32 x float> %152, %122
  %162 = getelementptr inbounds float, float* %10, i64 %160
  %163 = bitcast float* %162 to <32 x float>*
  store <32 x float> %161, <32 x float>* %163, align 64, !tbaa !3554
  %164 = add nsw i64 %147, 96
  %165 = fadd <32 x float> %152, %128
  %166 = getelementptr inbounds float, float* %10, i64 %164
  %167 = bitcast float* %166 to <32 x float>*
  store <32 x float> %165, <32 x float>* %167, align 64, !tbaa !3554
  %168 = add nsw i64 %147, 128
  %169 = fadd <32 x float> %152, %134
  %170 = getelementptr inbounds float, float* %10, i64 %168
  %171 = bitcast float* %170 to <32 x float>*
  store <32 x float> %169, <32 x float>* %171, align 64, !tbaa !3554
  %172 = add nsw i64 %147, 160
  %173 = fadd <32 x float> %152, %140
  %174 = getelementptr inbounds float, float* %10, i64 %172
  %175 = bitcast float* %174 to <32 x float>*
  store <32 x float> %173, <32 x float>* %175, align 64, !tbaa !3554
  %176 = add nsw i64 %147, 192
  %177 = fadd <32 x float> %152, %146
  %178 = getelementptr inbounds float, float* %10, i64 %176
  %179 = bitcast float* %178 to <32 x float>*
  store <32 x float> %177, <32 x float>* %179, align 64, !tbaa !3554
  %indvars.iv.next49 = add nsw i64 %indvars.iv48, 1
  %180 = icmp slt i64 %indvars.iv.next49, %29
  br i1 %180, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_25(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.298, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !3557
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.299, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !3571
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.300, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 4
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.301, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !3573
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !3587
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 3
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.302, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !3589
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 224
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.133, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !3592
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 224
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.134, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = icmp eq i64* %19, null
  br i1 %72, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end18
  %73 = bitcast i64* %19 to <4 x i64>*
  %74 = load <4 x i64>, <4 x i64>* %73, align 8, !tbaa !3594
  %75 = trunc <4 x i64> %74 to <4 x i32>
  %76 = icmp eq <4 x i32> %75, <i32 150528, i32 50176, i32 224, i32 1>
  %rdx.shuf49 = shufflevector <4 x i1> %76, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %76, %rdx.shuf49
  %rdx.shuf51 = shufflevector <4 x i1> %bin.rdx50, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %bin.rdx50, %rdx.shuf51
  %77 = extractelement <4 x i1> %bin.rdx52, i32 0
  br i1 %77, label %if_end, label %assert_fail19, !prof !5

if_end:                                           ; preds = %assert_end18, %if_then
  %78 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %79 = load i64, i64* %78, align 8
  %80 = icmp eq i64 %79, 0
  br i1 %80, label %assert_end22, label %assert_fail21, !prof !5

assert_fail19:                                    ; preds = %if_then
  %81 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %81(i8* getelementptr inbounds ([203 x i8], [203 x i8]* @.str.303, i64 0, i64 0))
  ret i32 -1

assert_fail21:                                    ; preds = %if_end
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %if_end
  %83 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %84 = load i32, i32* %83, align 4
  %85 = icmp eq i32 %84, 5
  br i1 %85, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %86 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %86(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %87 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %88 = load i16, i16* %87, align 2
  %89 = icmp eq i16 %88, 1
  %90 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %91 = load i8, i8* %90, align 1
  %92 = icmp eq i8 %91, 32
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %94 = load i8, i8* %93, align 1
  %95 = icmp eq i8 %94, 2
  %96 = and i1 %92, %95
  %97 = and i1 %89, %96
  br i1 %97, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %98 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %98(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %99 = load i64, i64* %27, align 8, !tbaa !3606
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 1
  br i1 %101, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %103 = getelementptr inbounds i64, i64* %27, i64 1
  %104 = load i64, i64* %103, align 8, !tbaa !3620
  %105 = trunc i64 %104 to i32
  %106 = icmp eq i32 %105, 1
  br i1 %106, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %107 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %107(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %108 = getelementptr inbounds i64, i64* %27, i64 2
  %109 = load i64, i64* %108, align 8, !tbaa !3622
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 224
  br i1 %111, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.304, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %113 = getelementptr inbounds i64, i64* %27, i64 3
  %114 = load i64, i64* %113, align 8, !tbaa !3625
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 224
  br i1 %116, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.305, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %118 = getelementptr inbounds i64, i64* %27, i64 4
  %119 = load i64, i64* %118, align 8, !tbaa !3627
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 3
  br i1 %121, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.140, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %123 = icmp eq i64* %29, null
  br i1 %123, label %if_end38, label %if_then37, !prof !50

if_then37:                                        ; preds = %assert_end36
  %124 = bitcast i64* %29 to <4 x i64>*
  %125 = load <4 x i64>, <4 x i64>* %124, align 8, !tbaa !3631
  %126 = trunc <4 x i64> %125 to <4 x i32>
  %127 = icmp eq <4 x i32> %126, <i32 150528, i32 150528, i32 672, i32 3>
  %128 = getelementptr inbounds i64, i64* %29, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !3643
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 1
  %rdx.shuf = shufflevector <4 x i1> %127, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %127, %rdx.shuf
  %rdx.shuf47 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx48 = and <4 x i1> %bin.rdx, %rdx.shuf47
  %132 = extractelement <4 x i1> %bin.rdx48, i32 0
  %133 = and i1 %132, %131
  br i1 %133, label %if_end38, label %assert_fail39, !prof !5

if_end38:                                         ; preds = %assert_end36, %if_then37
  %134 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %135 = load i64, i64* %134, align 8
  %136 = icmp eq i64 %135, 0
  br i1 %136, label %assert_end42, label %assert_fail41, !prof !5

assert_fail39:                                    ; preds = %if_then37
  %137 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %137(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.306, i64 0, i64 0))
  ret i32 -1

assert_fail41:                                    ; preds = %if_end38
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %if_end38
  %139 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %140 = load i32, i32* %139, align 4
  %141 = icmp eq i32 %140, 1
  br i1 %141, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %142 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %142(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %143 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %144 = load i32, i32* %143, align 4
  %145 = icmp eq i32 %23, %144
  br i1 %145, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %146 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %146(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %147 = tail call fastcc i32 @fused_layout_transform_25_compute_(i8* %25, i8* %15)
  ret i32 %147
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_25_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %35, align 8
  %3 = getelementptr inbounds %35, %35* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %35, %35* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %35* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.307, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.307(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 223
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 224
  %15 = select i1 %14, i32 %13, i32 224
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 224
  %18 = select i1 %17, i32 %16, i32 224
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv4 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next5, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv4, 672
  %25 = mul nsw i64 %indvars.iv4, 224
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body2 ]
  %26 = mul nuw nsw i64 %indvars.iv, 3
  %27 = add nsw i64 %26, %24
  %28 = add nsw i64 %indvars.iv, %25
  %29 = add nsw i64 %28, 50176
  %30 = add nsw i64 %28, 100352
  %31 = getelementptr inbounds float, float* %7, i64 %28
  %32 = load float, float* %31, align 4, !tbaa !3647
  %33 = insertelement <3 x float> undef, float %32, i32 0
  %34 = getelementptr inbounds float, float* %7, i64 %29
  %35 = load float, float* %34, align 4, !tbaa !3647
  %36 = insertelement <3 x float> %33, float %35, i32 1
  %37 = getelementptr inbounds float, float* %7, i64 %30
  %38 = load float, float* %37, align 4, !tbaa !3647
  %39 = insertelement <3 x float> %36, float %38, i32 2
  %40 = getelementptr inbounds float, float* %4, i64 %27
  %41 = bitcast float* %40 to <3 x float>*
  store <3 x float> %39, <3 x float>* %41, align 4, !tbaa !3650
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 224
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next5 = add nsw i64 %indvars.iv4, 1
  %42 = icmp slt i64 %indvars.iv.next5, %23
  br i1 %42, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([94 x i8], [94 x i8]* @.str.308, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !3653
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !3667
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !3670
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([169 x i8], [169 x i8]* @.str.309, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !3672
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([169 x i8], [169 x i8]* @.str.310, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([169 x i8], [169 x i8]* @.str.311, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([169 x i8], [169 x i8]* @.str.312, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !3674
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !3688
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 1
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.40, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !3690
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 7
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.93, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !3693
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 7
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.94, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !3695
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 512
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.95, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !3699
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 25088, i32 25088, i32 3584, i32 512>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !3711
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.96, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !3715
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 16
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !3729
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 1
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.47, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !3731
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 3
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !3734
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 3
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !3736
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 512
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.98, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !3740
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !3742
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 147456, i32 147456, i32 49152, i32 16384>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !3754
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !3758
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([281 x i8], [281 x i8]* @.str.99, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !3760
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !3774
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 16
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !3776
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !3779
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !3781
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !3785
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 512, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !3797
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.101, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !3801
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !3815
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 16
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !3817
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 7
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.103, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !3820
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 7
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.104, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !3822
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !3826
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 25088, i32 1568, i32 224, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !3838
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.105, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 165888, i32 2, i32 32)
  %7 = alloca %36, align 8
  %8 = getelementptr inbounds %36, %36* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %36, %36* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %36* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.313, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %21, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %37, align 8
  %15 = getelementptr inbounds %37, %37* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %37, %37* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %37, %37* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %37, %37* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = bitcast %37* %14 to i8*
  %20 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %21 = call i32 %20(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.314, i8* nonnull %19, i32 0)
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %23 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %24 = call i32 %23(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.313(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 8
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 9
  %15 = select i1 %14, i32 %13, i32 9
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 9
  %18 = select i1 %17, i32 %16, i32 9
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 9
  %21 = select i1 %20, i32 %16, i32 9
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -4608
  %23 = add i32 %22, -4608
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv, 4608
  %29 = trunc i64 %indvars.iv to i32
  %.off = add i32 %29, -1
  %30 = icmp ult i32 %.off, 7
  %31 = trunc i64 %indvars.iv to i32
  %32 = mul i32 %31, 3584
  br i1 %30, label %if_end.us.8, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %33 = mul i32 %indvar, 4608
  %34 = add i32 %23, %33
  %35 = sext i32 %34 to i64
  %scevgep = getelementptr float, float* %4, i64 %35
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 18432, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_body2.preheader, %if_end.us.8
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %36 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %36, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.8:                                      ; preds = %for_begin1.preheader
  %37 = getelementptr inbounds float, float* %4, i64 %28
  %38 = bitcast float* %37 to <512 x float>*
  store <512 x float> zeroinitializer, <512 x float>* %38, align 64, !tbaa !3842
  %39 = add nsw i64 %28, 512
  %40 = add i32 %32, -3584
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %7, i64 %41
  %43 = bitcast float* %42 to <512 x float>*
  %44 = load <512 x float>, <512 x float>* %43, align 64, !tbaa !3845
  %45 = getelementptr inbounds float, float* %4, i64 %39
  %46 = bitcast float* %45 to <512 x float>*
  store <512 x float> %44, <512 x float>* %46, align 64, !tbaa !3842
  %47 = add nsw i64 %28, 1024
  %48 = add i32 %32, -3072
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to <512 x float>*
  %52 = load <512 x float>, <512 x float>* %51, align 64, !tbaa !3845
  %53 = getelementptr inbounds float, float* %4, i64 %47
  %54 = bitcast float* %53 to <512 x float>*
  store <512 x float> %52, <512 x float>* %54, align 64, !tbaa !3842
  %55 = add nsw i64 %28, 1536
  %56 = add i32 %32, -2560
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds float, float* %7, i64 %57
  %59 = bitcast float* %58 to <512 x float>*
  %60 = load <512 x float>, <512 x float>* %59, align 64, !tbaa !3845
  %61 = getelementptr inbounds float, float* %4, i64 %55
  %62 = bitcast float* %61 to <512 x float>*
  store <512 x float> %60, <512 x float>* %62, align 64, !tbaa !3842
  %63 = add nsw i64 %28, 2048
  %64 = add i32 %32, -2048
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <512 x float>*
  %68 = load <512 x float>, <512 x float>* %67, align 64, !tbaa !3845
  %69 = getelementptr inbounds float, float* %4, i64 %63
  %70 = bitcast float* %69 to <512 x float>*
  store <512 x float> %68, <512 x float>* %70, align 64, !tbaa !3842
  %71 = add nsw i64 %28, 2560
  %72 = add i32 %32, -1536
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = bitcast float* %74 to <512 x float>*
  %76 = load <512 x float>, <512 x float>* %75, align 64, !tbaa !3845
  %77 = getelementptr inbounds float, float* %4, i64 %71
  %78 = bitcast float* %77 to <512 x float>*
  store <512 x float> %76, <512 x float>* %78, align 64, !tbaa !3842
  %79 = add nsw i64 %28, 3072
  %80 = add i32 %32, -1024
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <512 x float>*
  %84 = load <512 x float>, <512 x float>* %83, align 64, !tbaa !3845
  %85 = getelementptr inbounds float, float* %4, i64 %79
  %86 = bitcast float* %85 to <512 x float>*
  store <512 x float> %84, <512 x float>* %86, align 64, !tbaa !3842
  %87 = add nsw i64 %28, 3584
  %88 = add i32 %32, -512
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds float, float* %7, i64 %89
  %91 = bitcast float* %90 to <512 x float>*
  %92 = load <512 x float>, <512 x float>* %91, align 64, !tbaa !3845
  %93 = getelementptr inbounds float, float* %4, i64 %87
  %94 = bitcast float* %93 to <512 x float>*
  store <512 x float> %92, <512 x float>* %94, align 64, !tbaa !3842
  %95 = add nsw i64 %28, 4096
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = bitcast float* %96 to <512 x float>*
  store <512 x float> zeroinitializer, <512 x float>* %97, align 64, !tbaa !3842
  br label %for_end3
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.314(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 111
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 112
  %21 = select i1 %20, i32 %19, i32 112
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.2
  %indvars.iv48 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next49, %for_end6.2 ]
  %30 = trunc i64 %indvars.iv48 to i32
  %31 = srem i32 %30, 7
  %32 = sdiv i32 %30, 7
  %33 = mul nsw i32 %32, 147456
  %34 = sext i32 %33 to i64
  %35 = mul nsw i32 %31, 4608
  %36 = sext i32 %35 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.2, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %37 = phi <32 x float> [ zeroinitializer, %for_body ], [ %122, %for_body5 ]
  %38 = phi <32 x float> [ zeroinitializer, %for_body ], [ %116, %for_body5 ]
  %39 = phi <32 x float> [ zeroinitializer, %for_body ], [ %115, %for_body5 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %114, %for_body5 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %113, %for_body5 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %112, %for_body5 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %111, %for_body5 ]
  %44 = add nsw i64 %indvars.iv, %36
  %45 = getelementptr inbounds float, float* %4, i64 %44
  %46 = load float, float* %45, align 4, !tbaa !3842
  %47 = insertelement <32 x float> undef, float %46, i32 0
  %48 = shufflevector <32 x float> %47, <32 x float> undef, <32 x i32> zeroinitializer
  %49 = shl nsw i64 %indvars.iv, 5
  %50 = add nsw i64 %49, %34
  %51 = getelementptr inbounds float, float* %7, i64 %50
  %52 = bitcast float* %51 to <32 x float>*
  %53 = load <32 x float>, <32 x float>* %52, align 64, !tbaa !3848
  %54 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %48, <32 x float> %53, <32 x float> %43)
  %55 = add nsw i64 %44, 512
  %56 = getelementptr inbounds float, float* %4, i64 %55
  %57 = load float, float* %56, align 4, !tbaa !3842
  %58 = insertelement <32 x float> undef, float %57, i32 0
  %59 = shufflevector <32 x float> %58, <32 x float> undef, <32 x i32> zeroinitializer
  %60 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %59, <32 x float> %53, <32 x float> %42)
  %61 = add nsw i64 %44, 1024
  %62 = getelementptr inbounds float, float* %4, i64 %61
  %63 = load float, float* %62, align 4, !tbaa !3842
  %64 = insertelement <32 x float> undef, float %63, i32 0
  %65 = shufflevector <32 x float> %64, <32 x float> undef, <32 x i32> zeroinitializer
  %66 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %53, <32 x float> %41)
  %67 = add nsw i64 %44, 1536
  %68 = getelementptr inbounds float, float* %4, i64 %67
  %69 = load float, float* %68, align 4, !tbaa !3842
  %70 = insertelement <32 x float> undef, float %69, i32 0
  %71 = shufflevector <32 x float> %70, <32 x float> undef, <32 x i32> zeroinitializer
  %72 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %53, <32 x float> %40)
  %73 = add nsw i64 %44, 2048
  %74 = getelementptr inbounds float, float* %4, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !3842
  %76 = insertelement <32 x float> undef, float %75, i32 0
  %77 = shufflevector <32 x float> %76, <32 x float> undef, <32 x i32> zeroinitializer
  %78 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %53, <32 x float> %39)
  %79 = add nsw i64 %44, 2560
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !3842
  %82 = insertelement <32 x float> undef, float %81, i32 0
  %83 = shufflevector <32 x float> %82, <32 x float> undef, <32 x i32> zeroinitializer
  %84 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %53, <32 x float> %38)
  %85 = add nsw i64 %44, 3072
  %86 = getelementptr inbounds float, float* %4, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !3842
  %88 = insertelement <32 x float> undef, float %87, i32 0
  %89 = shufflevector <32 x float> %88, <32 x float> undef, <32 x i32> zeroinitializer
  %90 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %53, <32 x float> %37)
  %91 = add nsw i64 %50, 16384
  %92 = getelementptr inbounds float, float* %7, i64 %91
  %93 = bitcast float* %92 to <32 x float>*
  %94 = load <32 x float>, <32 x float>* %93, align 64, !tbaa !3848
  %95 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %59, <32 x float> %94, <32 x float> %54)
  %96 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %94, <32 x float> %60)
  %97 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %94, <32 x float> %66)
  %98 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %94, <32 x float> %72)
  %99 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %94, <32 x float> %78)
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %94, <32 x float> %84)
  %101 = add nsw i64 %44, 3584
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !3842
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %94, <32 x float> %90)
  %107 = add nsw i64 %50, 32768
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to <32 x float>*
  %110 = load <32 x float>, <32 x float>* %109, align 64, !tbaa !3848
  %111 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %110, <32 x float> %95)
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %110, <32 x float> %96)
  %113 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %110, <32 x float> %97)
  %114 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %110, <32 x float> %98)
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %110, <32 x float> %99)
  %116 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %110, <32 x float> %100)
  %117 = add nsw i64 %44, 4096
  %118 = getelementptr inbounds float, float* %4, i64 %117
  %119 = load float, float* %118, align 4, !tbaa !3842
  %120 = insertelement <32 x float> undef, float %119, i32 0
  %121 = shufflevector <32 x float> %120, <32 x float> undef, <32 x i32> zeroinitializer
  %122 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %121, <32 x float> %110, <32 x float> %106)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %123 = mul nsw i32 %31, 4608
  %124 = add nsw i32 %123, 4608
  %125 = add nsw i64 %34, 49152
  %126 = sext i32 %124 to i64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %127 = phi <32 x float> [ %122, %for_end6 ], [ %212, %for_body5.1 ]
  %128 = phi <32 x float> [ %116, %for_end6 ], [ %206, %for_body5.1 ]
  %129 = phi <32 x float> [ %115, %for_end6 ], [ %205, %for_body5.1 ]
  %130 = phi <32 x float> [ %114, %for_end6 ], [ %204, %for_body5.1 ]
  %131 = phi <32 x float> [ %113, %for_end6 ], [ %203, %for_body5.1 ]
  %132 = phi <32 x float> [ %112, %for_end6 ], [ %202, %for_body5.1 ]
  %133 = phi <32 x float> [ %111, %for_end6 ], [ %201, %for_body5.1 ]
  %134 = add nsw i64 %indvars.iv.1, %126
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !3842
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = shl nsw i64 %indvars.iv.1, 5
  %140 = add nsw i64 %125, %139
  %141 = getelementptr inbounds float, float* %7, i64 %140
  %142 = bitcast float* %141 to <32 x float>*
  %143 = load <32 x float>, <32 x float>* %142, align 64, !tbaa !3848
  %144 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %143, <32 x float> %133)
  %145 = add nsw i64 %134, 512
  %146 = getelementptr inbounds float, float* %4, i64 %145
  %147 = load float, float* %146, align 4, !tbaa !3842
  %148 = insertelement <32 x float> undef, float %147, i32 0
  %149 = shufflevector <32 x float> %148, <32 x float> undef, <32 x i32> zeroinitializer
  %150 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %149, <32 x float> %143, <32 x float> %132)
  %151 = add nsw i64 %134, 1024
  %152 = getelementptr inbounds float, float* %4, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !3842
  %154 = insertelement <32 x float> undef, float %153, i32 0
  %155 = shufflevector <32 x float> %154, <32 x float> undef, <32 x i32> zeroinitializer
  %156 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %143, <32 x float> %131)
  %157 = add nsw i64 %134, 1536
  %158 = getelementptr inbounds float, float* %4, i64 %157
  %159 = load float, float* %158, align 4, !tbaa !3842
  %160 = insertelement <32 x float> undef, float %159, i32 0
  %161 = shufflevector <32 x float> %160, <32 x float> undef, <32 x i32> zeroinitializer
  %162 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %143, <32 x float> %130)
  %163 = add nsw i64 %134, 2048
  %164 = getelementptr inbounds float, float* %4, i64 %163
  %165 = load float, float* %164, align 4, !tbaa !3842
  %166 = insertelement <32 x float> undef, float %165, i32 0
  %167 = shufflevector <32 x float> %166, <32 x float> undef, <32 x i32> zeroinitializer
  %168 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %167, <32 x float> %143, <32 x float> %129)
  %169 = add nsw i64 %134, 2560
  %170 = getelementptr inbounds float, float* %4, i64 %169
  %171 = load float, float* %170, align 4, !tbaa !3842
  %172 = insertelement <32 x float> undef, float %171, i32 0
  %173 = shufflevector <32 x float> %172, <32 x float> undef, <32 x i32> zeroinitializer
  %174 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %173, <32 x float> %143, <32 x float> %128)
  %175 = add nsw i64 %134, 3072
  %176 = getelementptr inbounds float, float* %4, i64 %175
  %177 = load float, float* %176, align 4, !tbaa !3842
  %178 = insertelement <32 x float> undef, float %177, i32 0
  %179 = shufflevector <32 x float> %178, <32 x float> undef, <32 x i32> zeroinitializer
  %180 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %143, <32 x float> %127)
  %181 = add nsw i64 %140, 16384
  %182 = getelementptr inbounds float, float* %7, i64 %181
  %183 = bitcast float* %182 to <32 x float>*
  %184 = load <32 x float>, <32 x float>* %183, align 64, !tbaa !3848
  %185 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %149, <32 x float> %184, <32 x float> %144)
  %186 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %184, <32 x float> %150)
  %187 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %184, <32 x float> %156)
  %188 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %167, <32 x float> %184, <32 x float> %162)
  %189 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %173, <32 x float> %184, <32 x float> %168)
  %190 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %184, <32 x float> %174)
  %191 = add nsw i64 %134, 3584
  %192 = getelementptr inbounds float, float* %4, i64 %191
  %193 = load float, float* %192, align 4, !tbaa !3842
  %194 = insertelement <32 x float> undef, float %193, i32 0
  %195 = shufflevector <32 x float> %194, <32 x float> undef, <32 x i32> zeroinitializer
  %196 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %195, <32 x float> %184, <32 x float> %180)
  %197 = add nsw i64 %140, 32768
  %198 = getelementptr inbounds float, float* %7, i64 %197
  %199 = bitcast float* %198 to <32 x float>*
  %200 = load <32 x float>, <32 x float>* %199, align 64, !tbaa !3848
  %201 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %200, <32 x float> %185)
  %202 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %200, <32 x float> %186)
  %203 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %167, <32 x float> %200, <32 x float> %187)
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %173, <32 x float> %200, <32 x float> %188)
  %205 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %200, <32 x float> %189)
  %206 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %195, <32 x float> %200, <32 x float> %190)
  %207 = add nsw i64 %134, 4096
  %208 = getelementptr inbounds float, float* %4, i64 %207
  %209 = load float, float* %208, align 4, !tbaa !3842
  %210 = insertelement <32 x float> undef, float %209, i32 0
  %211 = shufflevector <32 x float> %210, <32 x float> undef, <32 x i32> zeroinitializer
  %212 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %211, <32 x float> %200, <32 x float> %196)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %213 = mul nsw i32 %31, 4608
  %214 = add nsw i32 %213, 9216
  %215 = add nsw i64 %34, 98304
  %216 = sext i32 %214 to i64
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %217 = phi <32 x float> [ %212, %for_end6.1 ], [ %302, %for_body5.2 ]
  %218 = phi <32 x float> [ %206, %for_end6.1 ], [ %296, %for_body5.2 ]
  %219 = phi <32 x float> [ %205, %for_end6.1 ], [ %295, %for_body5.2 ]
  %220 = phi <32 x float> [ %204, %for_end6.1 ], [ %294, %for_body5.2 ]
  %221 = phi <32 x float> [ %203, %for_end6.1 ], [ %293, %for_body5.2 ]
  %222 = phi <32 x float> [ %202, %for_end6.1 ], [ %292, %for_body5.2 ]
  %223 = phi <32 x float> [ %201, %for_end6.1 ], [ %291, %for_body5.2 ]
  %224 = add nsw i64 %indvars.iv.2, %216
  %225 = getelementptr inbounds float, float* %4, i64 %224
  %226 = load float, float* %225, align 4, !tbaa !3842
  %227 = insertelement <32 x float> undef, float %226, i32 0
  %228 = shufflevector <32 x float> %227, <32 x float> undef, <32 x i32> zeroinitializer
  %229 = shl nsw i64 %indvars.iv.2, 5
  %230 = add nsw i64 %215, %229
  %231 = getelementptr inbounds float, float* %7, i64 %230
  %232 = bitcast float* %231 to <32 x float>*
  %233 = load <32 x float>, <32 x float>* %232, align 64, !tbaa !3848
  %234 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %228, <32 x float> %233, <32 x float> %223)
  %235 = add nsw i64 %224, 512
  %236 = getelementptr inbounds float, float* %4, i64 %235
  %237 = load float, float* %236, align 4, !tbaa !3842
  %238 = insertelement <32 x float> undef, float %237, i32 0
  %239 = shufflevector <32 x float> %238, <32 x float> undef, <32 x i32> zeroinitializer
  %240 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %239, <32 x float> %233, <32 x float> %222)
  %241 = add nsw i64 %224, 1024
  %242 = getelementptr inbounds float, float* %4, i64 %241
  %243 = load float, float* %242, align 4, !tbaa !3842
  %244 = insertelement <32 x float> undef, float %243, i32 0
  %245 = shufflevector <32 x float> %244, <32 x float> undef, <32 x i32> zeroinitializer
  %246 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %245, <32 x float> %233, <32 x float> %221)
  %247 = add nsw i64 %224, 1536
  %248 = getelementptr inbounds float, float* %4, i64 %247
  %249 = load float, float* %248, align 4, !tbaa !3842
  %250 = insertelement <32 x float> undef, float %249, i32 0
  %251 = shufflevector <32 x float> %250, <32 x float> undef, <32 x i32> zeroinitializer
  %252 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %251, <32 x float> %233, <32 x float> %220)
  %253 = add nsw i64 %224, 2048
  %254 = getelementptr inbounds float, float* %4, i64 %253
  %255 = load float, float* %254, align 4, !tbaa !3842
  %256 = insertelement <32 x float> undef, float %255, i32 0
  %257 = shufflevector <32 x float> %256, <32 x float> undef, <32 x i32> zeroinitializer
  %258 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %233, <32 x float> %219)
  %259 = add nsw i64 %224, 2560
  %260 = getelementptr inbounds float, float* %4, i64 %259
  %261 = load float, float* %260, align 4, !tbaa !3842
  %262 = insertelement <32 x float> undef, float %261, i32 0
  %263 = shufflevector <32 x float> %262, <32 x float> undef, <32 x i32> zeroinitializer
  %264 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %263, <32 x float> %233, <32 x float> %218)
  %265 = add nsw i64 %224, 3072
  %266 = getelementptr inbounds float, float* %4, i64 %265
  %267 = load float, float* %266, align 4, !tbaa !3842
  %268 = insertelement <32 x float> undef, float %267, i32 0
  %269 = shufflevector <32 x float> %268, <32 x float> undef, <32 x i32> zeroinitializer
  %270 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %269, <32 x float> %233, <32 x float> %217)
  %271 = add nsw i64 %230, 16384
  %272 = getelementptr inbounds float, float* %7, i64 %271
  %273 = bitcast float* %272 to <32 x float>*
  %274 = load <32 x float>, <32 x float>* %273, align 64, !tbaa !3848
  %275 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %239, <32 x float> %274, <32 x float> %234)
  %276 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %245, <32 x float> %274, <32 x float> %240)
  %277 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %251, <32 x float> %274, <32 x float> %246)
  %278 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %274, <32 x float> %252)
  %279 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %263, <32 x float> %274, <32 x float> %258)
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %269, <32 x float> %274, <32 x float> %264)
  %281 = add nsw i64 %224, 3584
  %282 = getelementptr inbounds float, float* %4, i64 %281
  %283 = load float, float* %282, align 4, !tbaa !3842
  %284 = insertelement <32 x float> undef, float %283, i32 0
  %285 = shufflevector <32 x float> %284, <32 x float> undef, <32 x i32> zeroinitializer
  %286 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %285, <32 x float> %274, <32 x float> %270)
  %287 = add nsw i64 %230, 32768
  %288 = getelementptr inbounds float, float* %7, i64 %287
  %289 = bitcast float* %288 to <32 x float>*
  %290 = load <32 x float>, <32 x float>* %289, align 64, !tbaa !3848
  %291 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %245, <32 x float> %290, <32 x float> %275)
  %292 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %251, <32 x float> %290, <32 x float> %276)
  %293 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %290, <32 x float> %277)
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %263, <32 x float> %290, <32 x float> %278)
  %295 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %269, <32 x float> %290, <32 x float> %279)
  %296 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %285, <32 x float> %290, <32 x float> %280)
  %297 = add nsw i64 %224, 4096
  %298 = getelementptr inbounds float, float* %4, i64 %297
  %299 = load float, float* %298, align 4, !tbaa !3842
  %300 = insertelement <32 x float> undef, float %299, i32 0
  %301 = shufflevector <32 x float> %300, <32 x float> undef, <32 x i32> zeroinitializer
  %302 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %301, <32 x float> %290, <32 x float> %286)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !50

for_end6.2:                                       ; preds = %for_body5.2
  %303 = mul nsw i64 %indvars.iv48, 224
  %304 = shl nsw i32 %32, 5
  %305 = sext i32 %304 to i64
  %306 = getelementptr inbounds float, float* %13, i64 %305
  %307 = bitcast float* %306 to <32 x float>*
  %308 = load <32 x float>, <32 x float>* %307, align 64, !tbaa !3851
  %309 = fadd <32 x float> %308, %291
  %310 = fcmp ogt <32 x float> %309, zeroinitializer
  %311 = select <32 x i1> %310, <32 x float> %309, <32 x float> zeroinitializer
  %312 = getelementptr inbounds float, float* %10, i64 %303
  %313 = bitcast float* %312 to <32 x float>*
  store <32 x float> %311, <32 x float>* %313, align 64, !tbaa !3854
  %314 = add nsw i64 %303, 32
  %315 = fadd <32 x float> %308, %292
  %316 = fcmp ogt <32 x float> %315, zeroinitializer
  %317 = select <32 x i1> %316, <32 x float> %315, <32 x float> zeroinitializer
  %318 = getelementptr inbounds float, float* %10, i64 %314
  %319 = bitcast float* %318 to <32 x float>*
  store <32 x float> %317, <32 x float>* %319, align 64, !tbaa !3854
  %320 = add nsw i64 %303, 64
  %321 = fadd <32 x float> %308, %293
  %322 = fcmp ogt <32 x float> %321, zeroinitializer
  %323 = select <32 x i1> %322, <32 x float> %321, <32 x float> zeroinitializer
  %324 = getelementptr inbounds float, float* %10, i64 %320
  %325 = bitcast float* %324 to <32 x float>*
  store <32 x float> %323, <32 x float>* %325, align 64, !tbaa !3854
  %326 = add nsw i64 %303, 96
  %327 = fadd <32 x float> %308, %294
  %328 = fcmp ogt <32 x float> %327, zeroinitializer
  %329 = select <32 x i1> %328, <32 x float> %327, <32 x float> zeroinitializer
  %330 = getelementptr inbounds float, float* %10, i64 %326
  %331 = bitcast float* %330 to <32 x float>*
  store <32 x float> %329, <32 x float>* %331, align 64, !tbaa !3854
  %332 = add nsw i64 %303, 128
  %333 = fadd <32 x float> %308, %295
  %334 = fcmp ogt <32 x float> %333, zeroinitializer
  %335 = select <32 x i1> %334, <32 x float> %333, <32 x float> zeroinitializer
  %336 = getelementptr inbounds float, float* %10, i64 %332
  %337 = bitcast float* %336 to <32 x float>*
  store <32 x float> %335, <32 x float>* %337, align 64, !tbaa !3854
  %338 = add nsw i64 %303, 160
  %339 = fadd <32 x float> %308, %296
  %340 = fcmp ogt <32 x float> %339, zeroinitializer
  %341 = select <32 x i1> %340, <32 x float> %339, <32 x float> zeroinitializer
  %342 = getelementptr inbounds float, float* %10, i64 %338
  %343 = bitcast float* %342 to <32 x float>*
  store <32 x float> %341, <32 x float>* %343, align 64, !tbaa !3854
  %344 = add nsw i64 %303, 192
  %345 = fadd <32 x float> %308, %302
  %346 = fcmp ogt <32 x float> %345, zeroinitializer
  %347 = select <32 x i1> %346, <32 x float> %345, <32 x float> zeroinitializer
  %348 = getelementptr inbounds float, float* %10, i64 %344
  %349 = bitcast float* %348 to <32 x float>*
  store <32 x float> %347, <32 x float>* %349, align 64, !tbaa !3854
  %indvars.iv.next49 = add nsw i64 %indvars.iv48, 1
  %350 = icmp slt i64 %indvars.iv.next49, %29
  br i1 %350, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.315, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !3857
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !3871
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !3874
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.316, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !3876
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.317, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.318, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([171 x i8], [171 x i8]* @.str.319, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !3878
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !3892
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 2
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !3894
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 56
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !3897
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 56
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !3899
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 32
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.10, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !3903
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 200704, i32 100352, i32 1792, i32 32>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !3915
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([241 x i8], [241 x i8]* @.str.190, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !3919
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 2
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.137, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !3933
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 2
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !3935
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 3
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !3938
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 3
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !3940
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 32
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.172, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !3944
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 64
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.320, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !3946
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 36864, i32 18432, i32 6144, i32 2048>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !3958
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 64
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !3962
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([277 x i8], [277 x i8]* @.str.321, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !3964
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !3978
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 2
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.142, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !3980
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !3983
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !3985
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 64
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.322, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !3989
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 128, i32 64, i32 64, i32 64>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !4001
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.323, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !4005
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !4019
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 2
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.144, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !4021
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 28
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !4024
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 28
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !4026
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 64
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.324, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !4030
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 100352, i32 50176, i32 1792, i32 64>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !4042
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.325, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %6 = tail call i8* %5(i32 1, i32 %4, i64 831744, i32 2, i32 32)
  %7 = alloca %38, align 8
  %8 = getelementptr inbounds %38, %38* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %38, %38* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %38* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.326, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %39, align 8
  %15 = getelementptr inbounds %39, %39* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %39, %39* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %39, %39* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %39, %39* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %39, %39* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %39* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.327, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.326(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 113
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 114
  %15 = select i1 %14, i32 %13, i32 114
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 114
  %18 = select i1 %17, i32 %16, i32 114
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 114
  %21 = select i1 %20, i32 %16, i32 114
  %smax = xor i32 %21, -1
  %22 = mul i32 %smax, -1824
  %23 = add i32 %22, -1824
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv7 = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next8, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = mul nsw i64 %indvars.iv7, 1824
  %29 = trunc i64 %indvars.iv7 to i32
  %30 = srem i32 %29, 57
  %31 = icmp sgt i32 %30, 0
  %32 = mul nsw i32 %30, 1792
  %33 = sdiv i32 %29, 57
  %34 = mul nsw i32 %33, 100352
  %35 = add nsw i32 %32, -1824
  %36 = add i32 %35, %34
  br i1 %31, label %for_body2.us, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_begin1.preheader
  %37 = mul i32 %indvar, 1824
  %38 = add i32 %23, %37
  %39 = sext i32 %38 to i64
  %scevgep = getelementptr float, float* %4, i64 %39
  %scevgep6 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep6, i8 0, i64 7296, i1 false)
  br label %for_end3

for_body2.us:                                     ; preds = %for_begin1.preheader, %if_end.us
  %indvars.iv = phi i64 [ %indvars.iv.next, %if_end.us ], [ 0, %for_begin1.preheader ]
  %40 = shl nsw i64 %indvars.iv, 5
  %41 = add nsw i64 %40, %28
  %42 = icmp eq i64 %indvars.iv, 0
  br i1 %42, label %if_end.us, label %if_then.us

if_then.us:                                       ; preds = %for_body2.us
  %43 = trunc i64 %40 to i32
  %44 = add i32 %36, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = bitcast float* %46 to <32 x float>*
  %48 = load <32 x float>, <32 x float>* %47, align 64, !tbaa !4046
  br label %if_end.us

if_end.us:                                        ; preds = %for_body2.us, %if_then.us
  %49 = phi <32 x float> [ %48, %if_then.us ], [ zeroinitializer, %for_body2.us ]
  %50 = getelementptr inbounds float, float* %4, i64 %41
  %51 = bitcast float* %50 to <32 x float>*
  store <32 x float> %49, <32 x float>* %51, align 64, !tbaa !4049
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 57
  br i1 %exitcond, label %for_end3, label %for_body2.us, !prof !50

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %if_end.us, %for_body2.preheader
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %52 = icmp slt i64 %indvars.iv.next8, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %52, label %for_begin1.preheader, label %for_end, !prof !5
}

define private i32 @__tvm_parallel_lambda.327(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 55
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 56
  %24 = select i1 %23, i32 %22, i32 56
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 56
  %27 = select i1 %26, i32 %25, i32 56
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_begin21.preheader
  %indvars.iv102 = phi i64 [ %31, %for_body.preheader ], [ %indvars.iv.next103, %for_begin21.preheader ]
  %33 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %34 = tail call i8* %33(i32 1, i32 %16, i64 7168, i32 2, i32 32)
  %35 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %36 = tail call i8* %35(i32 1, i32 %16, i64 1024, i32 2, i32 32)
  %37 = bitcast i8* %36 to <64 x float>*
  %38 = getelementptr inbounds i8, i8* %36, i64 256
  %39 = bitcast i8* %38 to <64 x float>*
  %40 = getelementptr inbounds i8, i8* %36, i64 512
  %41 = bitcast i8* %40 to <64 x float>*
  %42 = getelementptr inbounds i8, i8* %36, i64 768
  %43 = bitcast i8* %42 to <64 x float>*
  %44 = trunc i64 %indvars.iv102 to i32
  %45 = srem i32 %44, 28
  %46 = mul nsw i32 %45, 3648
  %47 = sdiv i32 %44, 28
  %48 = mul nsw i32 %47, 36864
  %49 = bitcast i8* %34 to float*
  %50 = sext i32 %48 to i64
  %51 = sext i32 %46 to i64
  br label %for_body4

for_end:                                          ; preds = %for_begin21.preheader, %entry
  ret i32 0

for_begin21.preheader:                            ; preds = %for_begin18.preheader
  %52 = mul nsw i64 %indvars.iv102, 1792
  %53 = shl nsw i32 %47, 6
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds float, float* %13, i64 %54
  %56 = bitcast float* %55 to <64 x float>*
  %57 = load <64 x float>, <64 x float>* %56, align 64, !tbaa !4052
  %58 = bitcast i8* %34 to <64 x float>*
  %59 = load <64 x float>, <64 x float>* %58, align 64, !tbaa !4055
  %60 = fadd <64 x float> %57, %59
  %61 = fcmp ogt <64 x float> %60, zeroinitializer
  %62 = select <64 x i1> %61, <64 x float> %60, <64 x float> zeroinitializer
  %63 = getelementptr inbounds float, float* %10, i64 %52
  %64 = bitcast float* %63 to <64 x float>*
  store <64 x float> %62, <64 x float>* %64, align 64, !tbaa !4058
  %65 = getelementptr inbounds i8, i8* %34, i64 256
  %66 = bitcast i8* %65 to <64 x float>*
  %67 = load <64 x float>, <64 x float>* %66, align 64, !tbaa !4055
  %68 = fadd <64 x float> %57, %67
  %69 = fcmp ogt <64 x float> %68, zeroinitializer
  %70 = select <64 x i1> %69, <64 x float> %68, <64 x float> zeroinitializer
  %71 = mul i64 %indvars.iv102, 7696581394432
  %sext = ashr exact i64 %71, 32
  %72 = or i64 %sext, 64
  %73 = getelementptr inbounds float, float* %10, i64 %72
  %74 = bitcast float* %73 to <64 x float>*
  store <64 x float> %70, <64 x float>* %74, align 64, !tbaa !4058
  %75 = getelementptr inbounds i8, i8* %34, i64 512
  %76 = bitcast i8* %75 to <64 x float>*
  %77 = load <64 x float>, <64 x float>* %76, align 64, !tbaa !4055
  %78 = fadd <64 x float> %57, %77
  %79 = fcmp ogt <64 x float> %78, zeroinitializer
  %80 = select <64 x i1> %79, <64 x float> %78, <64 x float> zeroinitializer
  %81 = mul i64 %indvars.iv102, 7696581394432
  %sext104 = ashr exact i64 %81, 32
  %82 = or i64 %sext104, 128
  %83 = getelementptr inbounds float, float* %10, i64 %82
  %84 = bitcast float* %83 to <64 x float>*
  store <64 x float> %80, <64 x float>* %84, align 64, !tbaa !4058
  %85 = getelementptr inbounds i8, i8* %34, i64 768
  %86 = bitcast i8* %85 to <64 x float>*
  %87 = load <64 x float>, <64 x float>* %86, align 64, !tbaa !4055
  %88 = fadd <64 x float> %57, %87
  %89 = fcmp ogt <64 x float> %88, zeroinitializer
  %90 = select <64 x i1> %89, <64 x float> %88, <64 x float> zeroinitializer
  %91 = mul i64 %indvars.iv102, 7696581394432
  %sext105 = ashr exact i64 %91, 32
  %92 = or i64 %sext105, 192
  %93 = getelementptr inbounds float, float* %10, i64 %92
  %94 = bitcast float* %93 to <64 x float>*
  store <64 x float> %90, <64 x float>* %94, align 64, !tbaa !4058
  %95 = getelementptr inbounds i8, i8* %34, i64 1024
  %96 = bitcast i8* %95 to <64 x float>*
  %97 = load <64 x float>, <64 x float>* %96, align 64, !tbaa !4055
  %98 = fadd <64 x float> %57, %97
  %99 = fcmp ogt <64 x float> %98, zeroinitializer
  %100 = select <64 x i1> %99, <64 x float> %98, <64 x float> zeroinitializer
  %101 = mul i64 %indvars.iv102, 7696581394432
  %sext106 = add i64 %101, 1099511627776
  %102 = ashr exact i64 %sext106, 32
  %103 = getelementptr inbounds float, float* %10, i64 %102
  %104 = bitcast float* %103 to <64 x float>*
  store <64 x float> %100, <64 x float>* %104, align 64, !tbaa !4058
  %105 = getelementptr inbounds i8, i8* %34, i64 1280
  %106 = bitcast i8* %105 to <64 x float>*
  %107 = load <64 x float>, <64 x float>* %106, align 64, !tbaa !4055
  %108 = fadd <64 x float> %57, %107
  %109 = fcmp ogt <64 x float> %108, zeroinitializer
  %110 = select <64 x i1> %109, <64 x float> %108, <64 x float> zeroinitializer
  %111 = mul i64 %indvars.iv102, 7696581394432
  %sext107 = add i64 %111, 1374389534720
  %112 = ashr exact i64 %sext107, 32
  %113 = getelementptr inbounds float, float* %10, i64 %112
  %114 = bitcast float* %113 to <64 x float>*
  store <64 x float> %110, <64 x float>* %114, align 64, !tbaa !4058
  %115 = getelementptr inbounds i8, i8* %34, i64 1536
  %116 = bitcast i8* %115 to <64 x float>*
  %117 = load <64 x float>, <64 x float>* %116, align 64, !tbaa !4055
  %118 = fadd <64 x float> %57, %117
  %119 = fcmp ogt <64 x float> %118, zeroinitializer
  %120 = select <64 x i1> %119, <64 x float> %118, <64 x float> zeroinitializer
  %121 = mul i64 %indvars.iv102, 7696581394432
  %sext108 = add i64 %121, 1649267441664
  %122 = ashr exact i64 %sext108, 32
  %123 = getelementptr inbounds float, float* %10, i64 %122
  %124 = bitcast float* %123 to <64 x float>*
  store <64 x float> %120, <64 x float>* %124, align 64, !tbaa !4058
  %125 = getelementptr inbounds i8, i8* %34, i64 1792
  %126 = bitcast i8* %125 to <64 x float>*
  %127 = load <64 x float>, <64 x float>* %126, align 64, !tbaa !4055
  %128 = fadd <64 x float> %57, %127
  %129 = fcmp ogt <64 x float> %128, zeroinitializer
  %130 = select <64 x i1> %129, <64 x float> %128, <64 x float> zeroinitializer
  %131 = mul i64 %indvars.iv102, 7696581394432
  %sext109 = add i64 %131, 1924145348608
  %132 = ashr exact i64 %sext109, 32
  %133 = getelementptr inbounds float, float* %10, i64 %132
  %134 = bitcast float* %133 to <64 x float>*
  store <64 x float> %130, <64 x float>* %134, align 64, !tbaa !4058
  %135 = getelementptr inbounds i8, i8* %34, i64 2048
  %136 = bitcast i8* %135 to <64 x float>*
  %137 = load <64 x float>, <64 x float>* %136, align 64, !tbaa !4055
  %138 = fadd <64 x float> %57, %137
  %139 = fcmp ogt <64 x float> %138, zeroinitializer
  %140 = select <64 x i1> %139, <64 x float> %138, <64 x float> zeroinitializer
  %141 = mul i64 %indvars.iv102, 7696581394432
  %sext110 = add i64 %141, 2199023255552
  %142 = ashr exact i64 %sext110, 32
  %143 = getelementptr inbounds float, float* %10, i64 %142
  %144 = bitcast float* %143 to <64 x float>*
  store <64 x float> %140, <64 x float>* %144, align 64, !tbaa !4058
  %145 = getelementptr inbounds i8, i8* %34, i64 2304
  %146 = bitcast i8* %145 to <64 x float>*
  %147 = load <64 x float>, <64 x float>* %146, align 64, !tbaa !4055
  %148 = fadd <64 x float> %57, %147
  %149 = fcmp ogt <64 x float> %148, zeroinitializer
  %150 = select <64 x i1> %149, <64 x float> %148, <64 x float> zeroinitializer
  %151 = mul i64 %indvars.iv102, 7696581394432
  %sext111 = add i64 %151, 2473901162496
  %152 = ashr exact i64 %sext111, 32
  %153 = getelementptr inbounds float, float* %10, i64 %152
  %154 = bitcast float* %153 to <64 x float>*
  store <64 x float> %150, <64 x float>* %154, align 64, !tbaa !4058
  %155 = getelementptr inbounds i8, i8* %34, i64 2560
  %156 = bitcast i8* %155 to <64 x float>*
  %157 = load <64 x float>, <64 x float>* %156, align 64, !tbaa !4055
  %158 = fadd <64 x float> %57, %157
  %159 = fcmp ogt <64 x float> %158, zeroinitializer
  %160 = select <64 x i1> %159, <64 x float> %158, <64 x float> zeroinitializer
  %161 = mul i64 %indvars.iv102, 7696581394432
  %sext112 = add i64 %161, 2748779069440
  %162 = ashr exact i64 %sext112, 32
  %163 = getelementptr inbounds float, float* %10, i64 %162
  %164 = bitcast float* %163 to <64 x float>*
  store <64 x float> %160, <64 x float>* %164, align 64, !tbaa !4058
  %165 = getelementptr inbounds i8, i8* %34, i64 2816
  %166 = bitcast i8* %165 to <64 x float>*
  %167 = load <64 x float>, <64 x float>* %166, align 64, !tbaa !4055
  %168 = fadd <64 x float> %57, %167
  %169 = fcmp ogt <64 x float> %168, zeroinitializer
  %170 = select <64 x i1> %169, <64 x float> %168, <64 x float> zeroinitializer
  %171 = mul i64 %indvars.iv102, 7696581394432
  %sext113 = add i64 %171, 3023656976384
  %172 = ashr exact i64 %sext113, 32
  %173 = getelementptr inbounds float, float* %10, i64 %172
  %174 = bitcast float* %173 to <64 x float>*
  store <64 x float> %170, <64 x float>* %174, align 64, !tbaa !4058
  %175 = getelementptr inbounds i8, i8* %34, i64 3072
  %176 = bitcast i8* %175 to <64 x float>*
  %177 = load <64 x float>, <64 x float>* %176, align 64, !tbaa !4055
  %178 = fadd <64 x float> %57, %177
  %179 = fcmp ogt <64 x float> %178, zeroinitializer
  %180 = select <64 x i1> %179, <64 x float> %178, <64 x float> zeroinitializer
  %181 = mul i64 %indvars.iv102, 7696581394432
  %sext114 = add i64 %181, 3298534883328
  %182 = ashr exact i64 %sext114, 32
  %183 = getelementptr inbounds float, float* %10, i64 %182
  %184 = bitcast float* %183 to <64 x float>*
  store <64 x float> %180, <64 x float>* %184, align 64, !tbaa !4058
  %185 = getelementptr inbounds i8, i8* %34, i64 3328
  %186 = bitcast i8* %185 to <64 x float>*
  %187 = load <64 x float>, <64 x float>* %186, align 64, !tbaa !4055
  %188 = fadd <64 x float> %57, %187
  %189 = fcmp ogt <64 x float> %188, zeroinitializer
  %190 = select <64 x i1> %189, <64 x float> %188, <64 x float> zeroinitializer
  %191 = mul i64 %indvars.iv102, 7696581394432
  %sext115 = add i64 %191, 3573412790272
  %192 = ashr exact i64 %sext115, 32
  %193 = getelementptr inbounds float, float* %10, i64 %192
  %194 = bitcast float* %193 to <64 x float>*
  store <64 x float> %190, <64 x float>* %194, align 64, !tbaa !4058
  %195 = getelementptr inbounds i8, i8* %34, i64 3584
  %196 = bitcast i8* %195 to <64 x float>*
  %197 = load <64 x float>, <64 x float>* %196, align 64, !tbaa !4055
  %198 = fadd <64 x float> %57, %197
  %199 = fcmp ogt <64 x float> %198, zeroinitializer
  %200 = select <64 x i1> %199, <64 x float> %198, <64 x float> zeroinitializer
  %201 = mul i64 %indvars.iv102, 7696581394432
  %sext116 = add i64 %201, 3848290697216
  %202 = ashr exact i64 %sext116, 32
  %203 = getelementptr inbounds float, float* %10, i64 %202
  %204 = bitcast float* %203 to <64 x float>*
  store <64 x float> %200, <64 x float>* %204, align 64, !tbaa !4058
  %205 = getelementptr inbounds i8, i8* %34, i64 3840
  %206 = bitcast i8* %205 to <64 x float>*
  %207 = load <64 x float>, <64 x float>* %206, align 64, !tbaa !4055
  %208 = fadd <64 x float> %57, %207
  %209 = fcmp ogt <64 x float> %208, zeroinitializer
  %210 = select <64 x i1> %209, <64 x float> %208, <64 x float> zeroinitializer
  %211 = mul i64 %indvars.iv102, 7696581394432
  %sext117 = add i64 %211, 4123168604160
  %212 = ashr exact i64 %sext117, 32
  %213 = getelementptr inbounds float, float* %10, i64 %212
  %214 = bitcast float* %213 to <64 x float>*
  store <64 x float> %210, <64 x float>* %214, align 64, !tbaa !4058
  %215 = getelementptr inbounds i8, i8* %34, i64 4096
  %216 = bitcast i8* %215 to <64 x float>*
  %217 = load <64 x float>, <64 x float>* %216, align 64, !tbaa !4055
  %218 = fadd <64 x float> %57, %217
  %219 = fcmp ogt <64 x float> %218, zeroinitializer
  %220 = select <64 x i1> %219, <64 x float> %218, <64 x float> zeroinitializer
  %221 = mul i64 %indvars.iv102, 7696581394432
  %sext118 = add i64 %221, 4398046511104
  %222 = ashr exact i64 %sext118, 32
  %223 = getelementptr inbounds float, float* %10, i64 %222
  %224 = bitcast float* %223 to <64 x float>*
  store <64 x float> %220, <64 x float>* %224, align 64, !tbaa !4058
  %225 = getelementptr inbounds i8, i8* %34, i64 4352
  %226 = bitcast i8* %225 to <64 x float>*
  %227 = load <64 x float>, <64 x float>* %226, align 64, !tbaa !4055
  %228 = fadd <64 x float> %57, %227
  %229 = fcmp ogt <64 x float> %228, zeroinitializer
  %230 = select <64 x i1> %229, <64 x float> %228, <64 x float> zeroinitializer
  %231 = mul i64 %indvars.iv102, 7696581394432
  %sext119 = add i64 %231, 4672924418048
  %232 = ashr exact i64 %sext119, 32
  %233 = getelementptr inbounds float, float* %10, i64 %232
  %234 = bitcast float* %233 to <64 x float>*
  store <64 x float> %230, <64 x float>* %234, align 64, !tbaa !4058
  %235 = getelementptr inbounds i8, i8* %34, i64 4608
  %236 = bitcast i8* %235 to <64 x float>*
  %237 = load <64 x float>, <64 x float>* %236, align 64, !tbaa !4055
  %238 = fadd <64 x float> %57, %237
  %239 = fcmp ogt <64 x float> %238, zeroinitializer
  %240 = select <64 x i1> %239, <64 x float> %238, <64 x float> zeroinitializer
  %241 = mul i64 %indvars.iv102, 7696581394432
  %sext120 = add i64 %241, 4947802324992
  %242 = ashr exact i64 %sext120, 32
  %243 = getelementptr inbounds float, float* %10, i64 %242
  %244 = bitcast float* %243 to <64 x float>*
  store <64 x float> %240, <64 x float>* %244, align 64, !tbaa !4058
  %245 = getelementptr inbounds i8, i8* %34, i64 4864
  %246 = bitcast i8* %245 to <64 x float>*
  %247 = load <64 x float>, <64 x float>* %246, align 64, !tbaa !4055
  %248 = fadd <64 x float> %57, %247
  %249 = fcmp ogt <64 x float> %248, zeroinitializer
  %250 = select <64 x i1> %249, <64 x float> %248, <64 x float> zeroinitializer
  %251 = mul i64 %indvars.iv102, 7696581394432
  %sext121 = add i64 %251, 5222680231936
  %252 = ashr exact i64 %sext121, 32
  %253 = getelementptr inbounds float, float* %10, i64 %252
  %254 = bitcast float* %253 to <64 x float>*
  store <64 x float> %250, <64 x float>* %254, align 64, !tbaa !4058
  %255 = getelementptr inbounds i8, i8* %34, i64 5120
  %256 = bitcast i8* %255 to <64 x float>*
  %257 = load <64 x float>, <64 x float>* %256, align 64, !tbaa !4055
  %258 = fadd <64 x float> %57, %257
  %259 = fcmp ogt <64 x float> %258, zeroinitializer
  %260 = select <64 x i1> %259, <64 x float> %258, <64 x float> zeroinitializer
  %261 = mul i64 %indvars.iv102, 7696581394432
  %sext122 = add i64 %261, 5497558138880
  %262 = ashr exact i64 %sext122, 32
  %263 = getelementptr inbounds float, float* %10, i64 %262
  %264 = bitcast float* %263 to <64 x float>*
  store <64 x float> %260, <64 x float>* %264, align 64, !tbaa !4058
  %265 = getelementptr inbounds i8, i8* %34, i64 5376
  %266 = bitcast i8* %265 to <64 x float>*
  %267 = load <64 x float>, <64 x float>* %266, align 64, !tbaa !4055
  %268 = fadd <64 x float> %57, %267
  %269 = fcmp ogt <64 x float> %268, zeroinitializer
  %270 = select <64 x i1> %269, <64 x float> %268, <64 x float> zeroinitializer
  %271 = mul i64 %indvars.iv102, 7696581394432
  %sext123 = add i64 %271, 5772436045824
  %272 = ashr exact i64 %sext123, 32
  %273 = getelementptr inbounds float, float* %10, i64 %272
  %274 = bitcast float* %273 to <64 x float>*
  store <64 x float> %270, <64 x float>* %274, align 64, !tbaa !4058
  %275 = getelementptr inbounds i8, i8* %34, i64 5632
  %276 = bitcast i8* %275 to <64 x float>*
  %277 = load <64 x float>, <64 x float>* %276, align 64, !tbaa !4055
  %278 = fadd <64 x float> %57, %277
  %279 = fcmp ogt <64 x float> %278, zeroinitializer
  %280 = select <64 x i1> %279, <64 x float> %278, <64 x float> zeroinitializer
  %281 = mul i64 %indvars.iv102, 7696581394432
  %sext124 = add i64 %281, 6047313952768
  %282 = ashr exact i64 %sext124, 32
  %283 = getelementptr inbounds float, float* %10, i64 %282
  %284 = bitcast float* %283 to <64 x float>*
  store <64 x float> %280, <64 x float>* %284, align 64, !tbaa !4058
  %285 = getelementptr inbounds i8, i8* %34, i64 5888
  %286 = bitcast i8* %285 to <64 x float>*
  %287 = load <64 x float>, <64 x float>* %286, align 64, !tbaa !4055
  %288 = fadd <64 x float> %57, %287
  %289 = fcmp ogt <64 x float> %288, zeroinitializer
  %290 = select <64 x i1> %289, <64 x float> %288, <64 x float> zeroinitializer
  %291 = mul i64 %indvars.iv102, 7696581394432
  %sext125 = add i64 %291, 6322191859712
  %292 = ashr exact i64 %sext125, 32
  %293 = getelementptr inbounds float, float* %10, i64 %292
  %294 = bitcast float* %293 to <64 x float>*
  store <64 x float> %290, <64 x float>* %294, align 64, !tbaa !4058
  %295 = getelementptr inbounds i8, i8* %34, i64 6144
  %296 = bitcast i8* %295 to <64 x float>*
  %297 = load <64 x float>, <64 x float>* %296, align 64, !tbaa !4055
  %298 = fadd <64 x float> %57, %297
  %299 = fcmp ogt <64 x float> %298, zeroinitializer
  %300 = select <64 x i1> %299, <64 x float> %298, <64 x float> zeroinitializer
  %301 = mul i64 %indvars.iv102, 7696581394432
  %sext126 = add i64 %301, 6597069766656
  %302 = ashr exact i64 %sext126, 32
  %303 = getelementptr inbounds float, float* %10, i64 %302
  %304 = bitcast float* %303 to <64 x float>*
  store <64 x float> %300, <64 x float>* %304, align 64, !tbaa !4058
  %305 = getelementptr inbounds i8, i8* %34, i64 6400
  %306 = bitcast i8* %305 to <64 x float>*
  %307 = load <64 x float>, <64 x float>* %306, align 64, !tbaa !4055
  %308 = fadd <64 x float> %57, %307
  %309 = fcmp ogt <64 x float> %308, zeroinitializer
  %310 = select <64 x i1> %309, <64 x float> %308, <64 x float> zeroinitializer
  %311 = mul i64 %indvars.iv102, 7696581394432
  %sext127 = add i64 %311, 6871947673600
  %312 = ashr exact i64 %sext127, 32
  %313 = getelementptr inbounds float, float* %10, i64 %312
  %314 = bitcast float* %313 to <64 x float>*
  store <64 x float> %310, <64 x float>* %314, align 64, !tbaa !4058
  %315 = getelementptr inbounds i8, i8* %34, i64 6656
  %316 = bitcast i8* %315 to <64 x float>*
  %317 = load <64 x float>, <64 x float>* %316, align 64, !tbaa !4055
  %318 = fadd <64 x float> %57, %317
  %319 = fcmp ogt <64 x float> %318, zeroinitializer
  %320 = select <64 x i1> %319, <64 x float> %318, <64 x float> zeroinitializer
  %321 = mul i64 %indvars.iv102, 7696581394432
  %sext128 = add i64 %321, 7146825580544
  %322 = ashr exact i64 %sext128, 32
  %323 = getelementptr inbounds float, float* %10, i64 %322
  %324 = bitcast float* %323 to <64 x float>*
  store <64 x float> %320, <64 x float>* %324, align 64, !tbaa !4058
  %325 = getelementptr inbounds i8, i8* %34, i64 6912
  %326 = bitcast i8* %325 to <64 x float>*
  %327 = load <64 x float>, <64 x float>* %326, align 64, !tbaa !4055
  %328 = fadd <64 x float> %57, %327
  %329 = fcmp ogt <64 x float> %328, zeroinitializer
  %330 = select <64 x i1> %329, <64 x float> %328, <64 x float> zeroinitializer
  %331 = mul i64 %indvars.iv102, 7696581394432
  %sext129 = add i64 %331, 7421703487488
  %332 = ashr exact i64 %sext129, 32
  %333 = getelementptr inbounds float, float* %10, i64 %332
  %334 = bitcast float* %333 to <64 x float>*
  store <64 x float> %330, <64 x float>* %334, align 64, !tbaa !4058
  %335 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %336 = tail call i32 %335(i32 1, i32 %16, i8* nonnull %36)
  %337 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %338 = tail call i32 %337(i32 1, i32 %16, i8* nonnull %34)
  %indvars.iv.next103 = add nsw i64 %indvars.iv102, 1
  %339 = icmp slt i64 %indvars.iv.next103, %32
  br i1 %339, label %for_body, label %for_end, !prof !5

for_body4:                                        ; preds = %for_begin18.preheader, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_begin18.preheader ]
  %340 = shl i64 %indvar, 8
  %341 = add nsw i64 %340, %51
  call void @llvm.memset.p0i8.i64(i8* align 64 %36, i8 0, i64 1024, i1 false)
  br label %for_begin9.preheader

for_begin18.preheader:                            ; preds = %for_end17.2.2
  store <64 x float> %651, <64 x float>* %37, align 64, !tbaa !4061
  store <64 x float> %657, <64 x float>* %39, align 64, !tbaa !4061
  store <64 x float> %663, <64 x float>* %41, align 64, !tbaa !4061
  store <64 x float> %669, <64 x float>* %43, align 64, !tbaa !4061
  %342 = getelementptr inbounds float, float* %49, i64 %340
  %343 = bitcast float* %342 to <64 x float>*
  store <64 x float> %651, <64 x float>* %343, align 64, !tbaa !4055
  %344 = or i64 %340, 64
  %345 = getelementptr inbounds float, float* %49, i64 %344
  %346 = bitcast float* %345 to <64 x float>*
  store <64 x float> %657, <64 x float>* %346, align 64, !tbaa !4055
  %347 = or i64 %340, 128
  %348 = getelementptr inbounds float, float* %49, i64 %347
  %349 = bitcast float* %348 to <64 x float>*
  store <64 x float> %663, <64 x float>* %349, align 64, !tbaa !4055
  %350 = or i64 %340, 192
  %351 = getelementptr inbounds float, float* %49, i64 %350
  %352 = bitcast float* %351 to <64 x float>*
  store <64 x float> %669, <64 x float>* %352, align 64, !tbaa !4055
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond95 = icmp eq i64 %indvar.next, 7
  br i1 %exitcond95, label %for_begin21.preheader, label %for_body4, !prof !50

for_begin9.preheader:                             ; preds = %for_end17.2.2, %for_body4
  %indvars.iv89 = phi i64 [ 0, %for_body4 ], [ %indvars.iv.next90, %for_end17.2.2 ]
  %.lcssa40.lcssa.lcssa61 = phi <64 x float> [ zeroinitializer, %for_body4 ], [ %669, %for_end17.2.2 ]
  %.lcssa38.lcssa.lcssa60 = phi <64 x float> [ zeroinitializer, %for_body4 ], [ %663, %for_end17.2.2 ]
  %.lcssa36.lcssa.lcssa58 = phi <64 x float> [ zeroinitializer, %for_body4 ], [ %657, %for_end17.2.2 ]
  %.lcssa.lcssa.lcssa56 = phi <64 x float> [ zeroinitializer, %for_body4 ], [ %651, %for_end17.2.2 ]
  %353 = mul nuw nsw i64 %indvars.iv89, 103968
  %354 = add nsw i64 %341, %353
  %355 = mul nuw nsw i64 %indvars.iv89, 18432
  %356 = add nsw i64 %355, %50
  br label %for_body16

for_body16:                                       ; preds = %for_body16, %for_begin9.preheader
  %indvars.iv = phi i64 [ 0, %for_begin9.preheader ], [ %indvars.iv.next, %for_body16 ]
  %357 = phi <64 x float> [ %.lcssa40.lcssa.lcssa61, %for_begin9.preheader ], [ %389, %for_body16 ]
  %358 = phi <64 x float> [ %.lcssa38.lcssa.lcssa60, %for_begin9.preheader ], [ %383, %for_body16 ]
  %359 = phi <64 x float> [ %.lcssa36.lcssa.lcssa58, %for_begin9.preheader ], [ %377, %for_body16 ]
  %360 = phi <64 x float> [ %.lcssa.lcssa.lcssa56, %for_begin9.preheader ], [ %371, %for_body16 ]
  %361 = add nsw i64 %354, %indvars.iv
  %362 = getelementptr inbounds float, float* %4, i64 %361
  %363 = load float, float* %362, align 4, !tbaa !4049
  %364 = insertelement <64 x float> undef, float %363, i32 0
  %365 = shufflevector <64 x float> %364, <64 x float> undef, <64 x i32> zeroinitializer
  %366 = shl i64 %indvars.iv, 6
  %367 = add nsw i64 %356, %366
  %368 = getelementptr inbounds float, float* %7, i64 %367
  %369 = bitcast float* %368 to <64 x float>*
  %370 = load <64 x float>, <64 x float>* %369, align 64, !tbaa !4069
  %371 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %365, <64 x float> %370, <64 x float> %360)
  %372 = add nsw i64 %361, 64
  %373 = getelementptr inbounds float, float* %4, i64 %372
  %374 = load float, float* %373, align 4, !tbaa !4049
  %375 = insertelement <64 x float> undef, float %374, i32 0
  %376 = shufflevector <64 x float> %375, <64 x float> undef, <64 x i32> zeroinitializer
  %377 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %376, <64 x float> %370, <64 x float> %359)
  %378 = add nsw i64 %361, 128
  %379 = getelementptr inbounds float, float* %4, i64 %378
  %380 = load float, float* %379, align 4, !tbaa !4049
  %381 = insertelement <64 x float> undef, float %380, i32 0
  %382 = shufflevector <64 x float> %381, <64 x float> undef, <64 x i32> zeroinitializer
  %383 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %382, <64 x float> %370, <64 x float> %358)
  %384 = add nsw i64 %361, 192
  %385 = getelementptr inbounds float, float* %4, i64 %384
  %386 = load float, float* %385, align 4, !tbaa !4049
  %387 = insertelement <64 x float> undef, float %386, i32 0
  %388 = shufflevector <64 x float> %387, <64 x float> undef, <64 x i32> zeroinitializer
  %389 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %388, <64 x float> %370, <64 x float> %357)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end17, label %for_body16, !prof !50

for_end17:                                        ; preds = %for_body16
  %390 = add nsw i64 %354, 32
  %391 = add nsw i64 %356, 2048
  br label %for_body16.1

for_body16.1:                                     ; preds = %for_body16.1, %for_end17
  %indvars.iv.1 = phi i64 [ 0, %for_end17 ], [ %indvars.iv.next.1, %for_body16.1 ]
  %392 = phi <64 x float> [ %389, %for_end17 ], [ %424, %for_body16.1 ]
  %393 = phi <64 x float> [ %383, %for_end17 ], [ %418, %for_body16.1 ]
  %394 = phi <64 x float> [ %377, %for_end17 ], [ %412, %for_body16.1 ]
  %395 = phi <64 x float> [ %371, %for_end17 ], [ %406, %for_body16.1 ]
  %396 = add nsw i64 %390, %indvars.iv.1
  %397 = getelementptr inbounds float, float* %4, i64 %396
  %398 = load float, float* %397, align 4, !tbaa !4049
  %399 = insertelement <64 x float> undef, float %398, i32 0
  %400 = shufflevector <64 x float> %399, <64 x float> undef, <64 x i32> zeroinitializer
  %401 = shl i64 %indvars.iv.1, 6
  %402 = add nsw i64 %391, %401
  %403 = getelementptr inbounds float, float* %7, i64 %402
  %404 = bitcast float* %403 to <64 x float>*
  %405 = load <64 x float>, <64 x float>* %404, align 64, !tbaa !4069
  %406 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %400, <64 x float> %405, <64 x float> %395)
  %407 = add nsw i64 %396, 64
  %408 = getelementptr inbounds float, float* %4, i64 %407
  %409 = load float, float* %408, align 4, !tbaa !4049
  %410 = insertelement <64 x float> undef, float %409, i32 0
  %411 = shufflevector <64 x float> %410, <64 x float> undef, <64 x i32> zeroinitializer
  %412 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %411, <64 x float> %405, <64 x float> %394)
  %413 = add nsw i64 %396, 128
  %414 = getelementptr inbounds float, float* %4, i64 %413
  %415 = load float, float* %414, align 4, !tbaa !4049
  %416 = insertelement <64 x float> undef, float %415, i32 0
  %417 = shufflevector <64 x float> %416, <64 x float> undef, <64 x i32> zeroinitializer
  %418 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %417, <64 x float> %405, <64 x float> %393)
  %419 = add nsw i64 %396, 192
  %420 = getelementptr inbounds float, float* %4, i64 %419
  %421 = load float, float* %420, align 4, !tbaa !4049
  %422 = insertelement <64 x float> undef, float %421, i32 0
  %423 = shufflevector <64 x float> %422, <64 x float> undef, <64 x i32> zeroinitializer
  %424 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %423, <64 x float> %405, <64 x float> %392)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 32
  br i1 %exitcond.1, label %for_end17.1, label %for_body16.1, !prof !50

for_end17.1:                                      ; preds = %for_body16.1
  %425 = add nsw i64 %354, 64
  %426 = add nsw i64 %356, 4096
  br label %for_body16.2

for_body16.2:                                     ; preds = %for_body16.2, %for_end17.1
  %indvars.iv.2 = phi i64 [ 0, %for_end17.1 ], [ %indvars.iv.next.2, %for_body16.2 ]
  %427 = phi <64 x float> [ %424, %for_end17.1 ], [ %459, %for_body16.2 ]
  %428 = phi <64 x float> [ %418, %for_end17.1 ], [ %453, %for_body16.2 ]
  %429 = phi <64 x float> [ %412, %for_end17.1 ], [ %447, %for_body16.2 ]
  %430 = phi <64 x float> [ %406, %for_end17.1 ], [ %441, %for_body16.2 ]
  %431 = add nsw i64 %425, %indvars.iv.2
  %432 = getelementptr inbounds float, float* %4, i64 %431
  %433 = load float, float* %432, align 4, !tbaa !4049
  %434 = insertelement <64 x float> undef, float %433, i32 0
  %435 = shufflevector <64 x float> %434, <64 x float> undef, <64 x i32> zeroinitializer
  %436 = shl i64 %indvars.iv.2, 6
  %437 = add nsw i64 %426, %436
  %438 = getelementptr inbounds float, float* %7, i64 %437
  %439 = bitcast float* %438 to <64 x float>*
  %440 = load <64 x float>, <64 x float>* %439, align 64, !tbaa !4069
  %441 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %435, <64 x float> %440, <64 x float> %430)
  %442 = add nsw i64 %431, 64
  %443 = getelementptr inbounds float, float* %4, i64 %442
  %444 = load float, float* %443, align 4, !tbaa !4049
  %445 = insertelement <64 x float> undef, float %444, i32 0
  %446 = shufflevector <64 x float> %445, <64 x float> undef, <64 x i32> zeroinitializer
  %447 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %446, <64 x float> %440, <64 x float> %429)
  %448 = add nsw i64 %431, 128
  %449 = getelementptr inbounds float, float* %4, i64 %448
  %450 = load float, float* %449, align 4, !tbaa !4049
  %451 = insertelement <64 x float> undef, float %450, i32 0
  %452 = shufflevector <64 x float> %451, <64 x float> undef, <64 x i32> zeroinitializer
  %453 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %452, <64 x float> %440, <64 x float> %428)
  %454 = add nsw i64 %431, 192
  %455 = getelementptr inbounds float, float* %4, i64 %454
  %456 = load float, float* %455, align 4, !tbaa !4049
  %457 = insertelement <64 x float> undef, float %456, i32 0
  %458 = shufflevector <64 x float> %457, <64 x float> undef, <64 x i32> zeroinitializer
  %459 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %458, <64 x float> %440, <64 x float> %427)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 32
  br i1 %exitcond.2, label %for_end17.2, label %for_body16.2, !prof !50

for_end17.2:                                      ; preds = %for_body16.2
  %460 = add nsw i64 %354, 1824
  %461 = add nsw i64 %356, 6144
  br label %for_body16.174

for_body16.174:                                   ; preds = %for_body16.174, %for_end17.2
  %indvars.iv.171 = phi i64 [ 0, %for_end17.2 ], [ %indvars.iv.next.172, %for_body16.174 ]
  %462 = phi <64 x float> [ %459, %for_end17.2 ], [ %494, %for_body16.174 ]
  %463 = phi <64 x float> [ %453, %for_end17.2 ], [ %488, %for_body16.174 ]
  %464 = phi <64 x float> [ %447, %for_end17.2 ], [ %482, %for_body16.174 ]
  %465 = phi <64 x float> [ %441, %for_end17.2 ], [ %476, %for_body16.174 ]
  %466 = add nsw i64 %460, %indvars.iv.171
  %467 = getelementptr inbounds float, float* %4, i64 %466
  %468 = load float, float* %467, align 4, !tbaa !4049
  %469 = insertelement <64 x float> undef, float %468, i32 0
  %470 = shufflevector <64 x float> %469, <64 x float> undef, <64 x i32> zeroinitializer
  %471 = shl i64 %indvars.iv.171, 6
  %472 = add nsw i64 %461, %471
  %473 = getelementptr inbounds float, float* %7, i64 %472
  %474 = bitcast float* %473 to <64 x float>*
  %475 = load <64 x float>, <64 x float>* %474, align 64, !tbaa !4069
  %476 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %470, <64 x float> %475, <64 x float> %465)
  %477 = add nsw i64 %466, 64
  %478 = getelementptr inbounds float, float* %4, i64 %477
  %479 = load float, float* %478, align 4, !tbaa !4049
  %480 = insertelement <64 x float> undef, float %479, i32 0
  %481 = shufflevector <64 x float> %480, <64 x float> undef, <64 x i32> zeroinitializer
  %482 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %481, <64 x float> %475, <64 x float> %464)
  %483 = add nsw i64 %466, 128
  %484 = getelementptr inbounds float, float* %4, i64 %483
  %485 = load float, float* %484, align 4, !tbaa !4049
  %486 = insertelement <64 x float> undef, float %485, i32 0
  %487 = shufflevector <64 x float> %486, <64 x float> undef, <64 x i32> zeroinitializer
  %488 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %487, <64 x float> %475, <64 x float> %463)
  %489 = add nsw i64 %466, 192
  %490 = getelementptr inbounds float, float* %4, i64 %489
  %491 = load float, float* %490, align 4, !tbaa !4049
  %492 = insertelement <64 x float> undef, float %491, i32 0
  %493 = shufflevector <64 x float> %492, <64 x float> undef, <64 x i32> zeroinitializer
  %494 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %493, <64 x float> %475, <64 x float> %462)
  %indvars.iv.next.172 = add nuw nsw i64 %indvars.iv.171, 1
  %exitcond.173 = icmp eq i64 %indvars.iv.next.172, 32
  br i1 %exitcond.173, label %for_end17.179, label %for_body16.174, !prof !50

for_end17.179:                                    ; preds = %for_body16.174
  %495 = add nsw i64 %354, 1856
  %496 = add nsw i64 %356, 8192
  br label %for_body16.1.1

for_body16.1.1:                                   ; preds = %for_body16.1.1, %for_end17.179
  %indvars.iv.1.1 = phi i64 [ 0, %for_end17.179 ], [ %indvars.iv.next.1.1, %for_body16.1.1 ]
  %497 = phi <64 x float> [ %494, %for_end17.179 ], [ %529, %for_body16.1.1 ]
  %498 = phi <64 x float> [ %488, %for_end17.179 ], [ %523, %for_body16.1.1 ]
  %499 = phi <64 x float> [ %482, %for_end17.179 ], [ %517, %for_body16.1.1 ]
  %500 = phi <64 x float> [ %476, %for_end17.179 ], [ %511, %for_body16.1.1 ]
  %501 = add nsw i64 %495, %indvars.iv.1.1
  %502 = getelementptr inbounds float, float* %4, i64 %501
  %503 = load float, float* %502, align 4, !tbaa !4049
  %504 = insertelement <64 x float> undef, float %503, i32 0
  %505 = shufflevector <64 x float> %504, <64 x float> undef, <64 x i32> zeroinitializer
  %506 = shl i64 %indvars.iv.1.1, 6
  %507 = add nsw i64 %496, %506
  %508 = getelementptr inbounds float, float* %7, i64 %507
  %509 = bitcast float* %508 to <64 x float>*
  %510 = load <64 x float>, <64 x float>* %509, align 64, !tbaa !4069
  %511 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %505, <64 x float> %510, <64 x float> %500)
  %512 = add nsw i64 %501, 64
  %513 = getelementptr inbounds float, float* %4, i64 %512
  %514 = load float, float* %513, align 4, !tbaa !4049
  %515 = insertelement <64 x float> undef, float %514, i32 0
  %516 = shufflevector <64 x float> %515, <64 x float> undef, <64 x i32> zeroinitializer
  %517 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %516, <64 x float> %510, <64 x float> %499)
  %518 = add nsw i64 %501, 128
  %519 = getelementptr inbounds float, float* %4, i64 %518
  %520 = load float, float* %519, align 4, !tbaa !4049
  %521 = insertelement <64 x float> undef, float %520, i32 0
  %522 = shufflevector <64 x float> %521, <64 x float> undef, <64 x i32> zeroinitializer
  %523 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %522, <64 x float> %510, <64 x float> %498)
  %524 = add nsw i64 %501, 192
  %525 = getelementptr inbounds float, float* %4, i64 %524
  %526 = load float, float* %525, align 4, !tbaa !4049
  %527 = insertelement <64 x float> undef, float %526, i32 0
  %528 = shufflevector <64 x float> %527, <64 x float> undef, <64 x i32> zeroinitializer
  %529 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %528, <64 x float> %510, <64 x float> %497)
  %indvars.iv.next.1.1 = add nuw nsw i64 %indvars.iv.1.1, 1
  %exitcond.1.1 = icmp eq i64 %indvars.iv.next.1.1, 32
  br i1 %exitcond.1.1, label %for_end17.1.1, label %for_body16.1.1, !prof !50

for_end17.1.1:                                    ; preds = %for_body16.1.1
  %530 = add nsw i64 %354, 1888
  %531 = add nsw i64 %356, 10240
  br label %for_body16.2.1

for_body16.2.1:                                   ; preds = %for_body16.2.1, %for_end17.1.1
  %indvars.iv.2.1 = phi i64 [ 0, %for_end17.1.1 ], [ %indvars.iv.next.2.1, %for_body16.2.1 ]
  %532 = phi <64 x float> [ %529, %for_end17.1.1 ], [ %564, %for_body16.2.1 ]
  %533 = phi <64 x float> [ %523, %for_end17.1.1 ], [ %558, %for_body16.2.1 ]
  %534 = phi <64 x float> [ %517, %for_end17.1.1 ], [ %552, %for_body16.2.1 ]
  %535 = phi <64 x float> [ %511, %for_end17.1.1 ], [ %546, %for_body16.2.1 ]
  %536 = add nsw i64 %530, %indvars.iv.2.1
  %537 = getelementptr inbounds float, float* %4, i64 %536
  %538 = load float, float* %537, align 4, !tbaa !4049
  %539 = insertelement <64 x float> undef, float %538, i32 0
  %540 = shufflevector <64 x float> %539, <64 x float> undef, <64 x i32> zeroinitializer
  %541 = shl i64 %indvars.iv.2.1, 6
  %542 = add nsw i64 %531, %541
  %543 = getelementptr inbounds float, float* %7, i64 %542
  %544 = bitcast float* %543 to <64 x float>*
  %545 = load <64 x float>, <64 x float>* %544, align 64, !tbaa !4069
  %546 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %540, <64 x float> %545, <64 x float> %535)
  %547 = add nsw i64 %536, 64
  %548 = getelementptr inbounds float, float* %4, i64 %547
  %549 = load float, float* %548, align 4, !tbaa !4049
  %550 = insertelement <64 x float> undef, float %549, i32 0
  %551 = shufflevector <64 x float> %550, <64 x float> undef, <64 x i32> zeroinitializer
  %552 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %551, <64 x float> %545, <64 x float> %534)
  %553 = add nsw i64 %536, 128
  %554 = getelementptr inbounds float, float* %4, i64 %553
  %555 = load float, float* %554, align 4, !tbaa !4049
  %556 = insertelement <64 x float> undef, float %555, i32 0
  %557 = shufflevector <64 x float> %556, <64 x float> undef, <64 x i32> zeroinitializer
  %558 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %557, <64 x float> %545, <64 x float> %533)
  %559 = add nsw i64 %536, 192
  %560 = getelementptr inbounds float, float* %4, i64 %559
  %561 = load float, float* %560, align 4, !tbaa !4049
  %562 = insertelement <64 x float> undef, float %561, i32 0
  %563 = shufflevector <64 x float> %562, <64 x float> undef, <64 x i32> zeroinitializer
  %564 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %563, <64 x float> %545, <64 x float> %532)
  %indvars.iv.next.2.1 = add nuw nsw i64 %indvars.iv.2.1, 1
  %exitcond.2.1 = icmp eq i64 %indvars.iv.next.2.1, 32
  br i1 %exitcond.2.1, label %for_end17.2.1, label %for_body16.2.1, !prof !50

for_end17.2.1:                                    ; preds = %for_body16.2.1
  %565 = add nsw i64 %354, 3648
  %566 = add nsw i64 %356, 12288
  br label %for_body16.283

for_body16.283:                                   ; preds = %for_body16.283, %for_end17.2.1
  %indvars.iv.280 = phi i64 [ 0, %for_end17.2.1 ], [ %indvars.iv.next.281, %for_body16.283 ]
  %567 = phi <64 x float> [ %564, %for_end17.2.1 ], [ %599, %for_body16.283 ]
  %568 = phi <64 x float> [ %558, %for_end17.2.1 ], [ %593, %for_body16.283 ]
  %569 = phi <64 x float> [ %552, %for_end17.2.1 ], [ %587, %for_body16.283 ]
  %570 = phi <64 x float> [ %546, %for_end17.2.1 ], [ %581, %for_body16.283 ]
  %571 = add nsw i64 %565, %indvars.iv.280
  %572 = getelementptr inbounds float, float* %4, i64 %571
  %573 = load float, float* %572, align 4, !tbaa !4049
  %574 = insertelement <64 x float> undef, float %573, i32 0
  %575 = shufflevector <64 x float> %574, <64 x float> undef, <64 x i32> zeroinitializer
  %576 = shl i64 %indvars.iv.280, 6
  %577 = add nsw i64 %566, %576
  %578 = getelementptr inbounds float, float* %7, i64 %577
  %579 = bitcast float* %578 to <64 x float>*
  %580 = load <64 x float>, <64 x float>* %579, align 64, !tbaa !4069
  %581 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %575, <64 x float> %580, <64 x float> %570)
  %582 = add nsw i64 %571, 64
  %583 = getelementptr inbounds float, float* %4, i64 %582
  %584 = load float, float* %583, align 4, !tbaa !4049
  %585 = insertelement <64 x float> undef, float %584, i32 0
  %586 = shufflevector <64 x float> %585, <64 x float> undef, <64 x i32> zeroinitializer
  %587 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %586, <64 x float> %580, <64 x float> %569)
  %588 = add nsw i64 %571, 128
  %589 = getelementptr inbounds float, float* %4, i64 %588
  %590 = load float, float* %589, align 4, !tbaa !4049
  %591 = insertelement <64 x float> undef, float %590, i32 0
  %592 = shufflevector <64 x float> %591, <64 x float> undef, <64 x i32> zeroinitializer
  %593 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %592, <64 x float> %580, <64 x float> %568)
  %594 = add nsw i64 %571, 192
  %595 = getelementptr inbounds float, float* %4, i64 %594
  %596 = load float, float* %595, align 4, !tbaa !4049
  %597 = insertelement <64 x float> undef, float %596, i32 0
  %598 = shufflevector <64 x float> %597, <64 x float> undef, <64 x i32> zeroinitializer
  %599 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %598, <64 x float> %580, <64 x float> %567)
  %indvars.iv.next.281 = add nuw nsw i64 %indvars.iv.280, 1
  %exitcond.282 = icmp eq i64 %indvars.iv.next.281, 32
  br i1 %exitcond.282, label %for_end17.288, label %for_body16.283, !prof !50

for_end17.288:                                    ; preds = %for_body16.283
  %600 = add nsw i64 %354, 3680
  %601 = add nsw i64 %356, 14336
  br label %for_body16.1.2

for_body16.1.2:                                   ; preds = %for_body16.1.2, %for_end17.288
  %indvars.iv.1.2 = phi i64 [ 0, %for_end17.288 ], [ %indvars.iv.next.1.2, %for_body16.1.2 ]
  %602 = phi <64 x float> [ %599, %for_end17.288 ], [ %634, %for_body16.1.2 ]
  %603 = phi <64 x float> [ %593, %for_end17.288 ], [ %628, %for_body16.1.2 ]
  %604 = phi <64 x float> [ %587, %for_end17.288 ], [ %622, %for_body16.1.2 ]
  %605 = phi <64 x float> [ %581, %for_end17.288 ], [ %616, %for_body16.1.2 ]
  %606 = add nsw i64 %600, %indvars.iv.1.2
  %607 = getelementptr inbounds float, float* %4, i64 %606
  %608 = load float, float* %607, align 4, !tbaa !4049
  %609 = insertelement <64 x float> undef, float %608, i32 0
  %610 = shufflevector <64 x float> %609, <64 x float> undef, <64 x i32> zeroinitializer
  %611 = shl i64 %indvars.iv.1.2, 6
  %612 = add nsw i64 %601, %611
  %613 = getelementptr inbounds float, float* %7, i64 %612
  %614 = bitcast float* %613 to <64 x float>*
  %615 = load <64 x float>, <64 x float>* %614, align 64, !tbaa !4069
  %616 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %610, <64 x float> %615, <64 x float> %605)
  %617 = add nsw i64 %606, 64
  %618 = getelementptr inbounds float, float* %4, i64 %617
  %619 = load float, float* %618, align 4, !tbaa !4049
  %620 = insertelement <64 x float> undef, float %619, i32 0
  %621 = shufflevector <64 x float> %620, <64 x float> undef, <64 x i32> zeroinitializer
  %622 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %621, <64 x float> %615, <64 x float> %604)
  %623 = add nsw i64 %606, 128
  %624 = getelementptr inbounds float, float* %4, i64 %623
  %625 = load float, float* %624, align 4, !tbaa !4049
  %626 = insertelement <64 x float> undef, float %625, i32 0
  %627 = shufflevector <64 x float> %626, <64 x float> undef, <64 x i32> zeroinitializer
  %628 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %627, <64 x float> %615, <64 x float> %603)
  %629 = add nsw i64 %606, 192
  %630 = getelementptr inbounds float, float* %4, i64 %629
  %631 = load float, float* %630, align 4, !tbaa !4049
  %632 = insertelement <64 x float> undef, float %631, i32 0
  %633 = shufflevector <64 x float> %632, <64 x float> undef, <64 x i32> zeroinitializer
  %634 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %633, <64 x float> %615, <64 x float> %602)
  %indvars.iv.next.1.2 = add nuw nsw i64 %indvars.iv.1.2, 1
  %exitcond.1.2 = icmp eq i64 %indvars.iv.next.1.2, 32
  br i1 %exitcond.1.2, label %for_end17.1.2, label %for_body16.1.2, !prof !50

for_end17.1.2:                                    ; preds = %for_body16.1.2
  %635 = add nsw i64 %354, 3712
  %636 = add nsw i64 %356, 16384
  br label %for_body16.2.2

for_body16.2.2:                                   ; preds = %for_body16.2.2, %for_end17.1.2
  %indvars.iv.2.2 = phi i64 [ 0, %for_end17.1.2 ], [ %indvars.iv.next.2.2, %for_body16.2.2 ]
  %637 = phi <64 x float> [ %634, %for_end17.1.2 ], [ %669, %for_body16.2.2 ]
  %638 = phi <64 x float> [ %628, %for_end17.1.2 ], [ %663, %for_body16.2.2 ]
  %639 = phi <64 x float> [ %622, %for_end17.1.2 ], [ %657, %for_body16.2.2 ]
  %640 = phi <64 x float> [ %616, %for_end17.1.2 ], [ %651, %for_body16.2.2 ]
  %641 = add nsw i64 %635, %indvars.iv.2.2
  %642 = getelementptr inbounds float, float* %4, i64 %641
  %643 = load float, float* %642, align 4, !tbaa !4049
  %644 = insertelement <64 x float> undef, float %643, i32 0
  %645 = shufflevector <64 x float> %644, <64 x float> undef, <64 x i32> zeroinitializer
  %646 = shl i64 %indvars.iv.2.2, 6
  %647 = add nsw i64 %636, %646
  %648 = getelementptr inbounds float, float* %7, i64 %647
  %649 = bitcast float* %648 to <64 x float>*
  %650 = load <64 x float>, <64 x float>* %649, align 64, !tbaa !4069
  %651 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %645, <64 x float> %650, <64 x float> %640)
  %652 = add nsw i64 %641, 64
  %653 = getelementptr inbounds float, float* %4, i64 %652
  %654 = load float, float* %653, align 4, !tbaa !4049
  %655 = insertelement <64 x float> undef, float %654, i32 0
  %656 = shufflevector <64 x float> %655, <64 x float> undef, <64 x i32> zeroinitializer
  %657 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %656, <64 x float> %650, <64 x float> %639)
  %658 = add nsw i64 %641, 128
  %659 = getelementptr inbounds float, float* %4, i64 %658
  %660 = load float, float* %659, align 4, !tbaa !4049
  %661 = insertelement <64 x float> undef, float %660, i32 0
  %662 = shufflevector <64 x float> %661, <64 x float> undef, <64 x i32> zeroinitializer
  %663 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %662, <64 x float> %650, <64 x float> %638)
  %664 = add nsw i64 %641, 192
  %665 = getelementptr inbounds float, float* %4, i64 %664
  %666 = load float, float* %665, align 4, !tbaa !4049
  %667 = insertelement <64 x float> undef, float %666, i32 0
  %668 = shufflevector <64 x float> %667, <64 x float> undef, <64 x i32> zeroinitializer
  %669 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %668, <64 x float> %650, <64 x float> %637)
  %indvars.iv.next.2.2 = add nuw nsw i64 %indvars.iv.2.2, 1
  %exitcond.2.2 = icmp eq i64 %indvars.iv.next.2.2, 32
  br i1 %exitcond.2.2, label %for_end17.2.2, label %for_body16.2.2, !prof !50

for_end17.2.2:                                    ; preds = %for_body16.2.2
  %indvars.iv.next90 = add nuw nsw i64 %indvars.iv89, 1
  %exitcond91 = icmp eq i64 %indvars.iv.next90, 2
  br i1 %exitcond91, label %for_begin18.preheader, label %for_begin9.preheader, !prof !50
}

; Function Attrs: nounwind readnone speculatable
declare <64 x float> @llvm.fmuladd.v64f32(<64 x float>, <64 x float>, <64 x float>) #3

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_1(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([88 x i8], [88 x i8]* @.str.328, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !4072
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !4086
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !4089
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.329, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !4091
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.330, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.331, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.332, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !4093
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !4107
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 2
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !4109
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 28
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.41, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !4112
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 28
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.42, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !4114
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 64
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.199, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !4118
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 100352, i32 50176, i32 1792, i32 64>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !4130
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.260, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !4134
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 16
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !4148
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 2
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !4150
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 1
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.286, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !4153
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 1
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.287, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !4155
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 64
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.201, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !4159
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 16
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.219, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !4161
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 2048, i32 1024, i32 1024, i32 1024>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !4173
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 16
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !4177
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([275 x i8], [275 x i8]* @.str.333, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !4179
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !4193
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 16
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !4195
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !4198
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !4200
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 16
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.221, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !4204
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 256, i32 16, i32 16, i32 16>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !4216
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.222, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !4220
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !4234
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 16
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !4236
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 14
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.223, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !4239
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 14
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !4241
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 16
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.225, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !4245
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 50176, i32 3136, i32 224, i32 16>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !4257
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_1_compute_(i8* %27, i8* %37, i8* %49, i8* %43)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %4 = alloca %40, align 8
  %5 = getelementptr inbounds %40, %40* %4, i64 0, i32 0
  store i8* %0, i8** %5, align 8
  %6 = getelementptr inbounds %40, %40* %4, i64 0, i32 1
  store i8* %1, i8** %6, align 8
  %7 = getelementptr inbounds %40, %40* %4, i64 0, i32 2
  store i8* %2, i8** %7, align 8
  %8 = getelementptr inbounds %40, %40* %4, i64 0, i32 3
  store i8* %3, i8** %8, align 8
  %9 = bitcast %40* %4 to i8*
  %10 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %11 = call i32 %10(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.334, i8* nonnull %9, i32 0)
  ret i32 %11
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.334(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 223
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 224
  %21 = select i1 %20, i32 %19, i32 224
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 224
  %24 = select i1 %23, i32 %22, i32 224
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv83 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next84, %for_end6.1 ]
  %30 = trunc i64 %indvars.iv83 to i32
  %31 = srem i32 %30, 14
  %32 = mul nsw i32 %31, 3584
  %33 = sdiv i32 %30, 14
  %34 = shl i32 %33, 11
  %35 = sext i32 %32 to i64
  %36 = sext i32 %34 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %37 = phi <16 x float> [ zeroinitializer, %for_body ], [ %139, %for_body5 ]
  %38 = phi <16 x float> [ zeroinitializer, %for_body ], [ %133, %for_body5 ]
  %39 = phi <16 x float> [ zeroinitializer, %for_body ], [ %127, %for_body5 ]
  %40 = phi <16 x float> [ zeroinitializer, %for_body ], [ %121, %for_body5 ]
  %41 = phi <16 x float> [ zeroinitializer, %for_body ], [ %115, %for_body5 ]
  %42 = phi <16 x float> [ zeroinitializer, %for_body ], [ %109, %for_body5 ]
  %43 = phi <16 x float> [ zeroinitializer, %for_body ], [ %103, %for_body5 ]
  %44 = phi <16 x float> [ zeroinitializer, %for_body ], [ %97, %for_body5 ]
  %45 = phi <16 x float> [ zeroinitializer, %for_body ], [ %91, %for_body5 ]
  %46 = phi <16 x float> [ zeroinitializer, %for_body ], [ %85, %for_body5 ]
  %47 = phi <16 x float> [ zeroinitializer, %for_body ], [ %79, %for_body5 ]
  %48 = phi <16 x float> [ zeroinitializer, %for_body ], [ %73, %for_body5 ]
  %49 = phi <16 x float> [ zeroinitializer, %for_body ], [ %67, %for_body5 ]
  %50 = phi <16 x float> [ zeroinitializer, %for_body ], [ %61, %for_body5 ]
  %51 = add nsw i64 %indvars.iv, %35
  %52 = getelementptr inbounds float, float* %4, i64 %51
  %53 = load float, float* %52, align 4, !tbaa !4261
  %54 = insertelement <16 x float> undef, float %53, i32 0
  %55 = shufflevector <16 x float> %54, <16 x float> undef, <16 x i32> zeroinitializer
  %56 = shl i64 %indvars.iv, 4
  %57 = add nuw nsw i64 %56, %36
  %58 = getelementptr inbounds float, float* %7, i64 %57
  %59 = bitcast float* %58 to <16 x float>*
  %60 = load <16 x float>, <16 x float>* %59, align 64, !tbaa !4264
  %61 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %55, <16 x float> %60, <16 x float> %50)
  %62 = add nsw i64 %51, 128
  %63 = getelementptr inbounds float, float* %4, i64 %62
  %64 = load float, float* %63, align 4, !tbaa !4261
  %65 = insertelement <16 x float> undef, float %64, i32 0
  %66 = shufflevector <16 x float> %65, <16 x float> undef, <16 x i32> zeroinitializer
  %67 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %66, <16 x float> %60, <16 x float> %49)
  %68 = add nsw i64 %51, 256
  %69 = getelementptr inbounds float, float* %4, i64 %68
  %70 = load float, float* %69, align 4, !tbaa !4261
  %71 = insertelement <16 x float> undef, float %70, i32 0
  %72 = shufflevector <16 x float> %71, <16 x float> undef, <16 x i32> zeroinitializer
  %73 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %72, <16 x float> %60, <16 x float> %48)
  %74 = add nsw i64 %51, 384
  %75 = getelementptr inbounds float, float* %4, i64 %74
  %76 = load float, float* %75, align 4, !tbaa !4261
  %77 = insertelement <16 x float> undef, float %76, i32 0
  %78 = shufflevector <16 x float> %77, <16 x float> undef, <16 x i32> zeroinitializer
  %79 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %78, <16 x float> %60, <16 x float> %47)
  %80 = add nsw i64 %51, 512
  %81 = getelementptr inbounds float, float* %4, i64 %80
  %82 = load float, float* %81, align 4, !tbaa !4261
  %83 = insertelement <16 x float> undef, float %82, i32 0
  %84 = shufflevector <16 x float> %83, <16 x float> undef, <16 x i32> zeroinitializer
  %85 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %84, <16 x float> %60, <16 x float> %46)
  %86 = add nsw i64 %51, 640
  %87 = getelementptr inbounds float, float* %4, i64 %86
  %88 = load float, float* %87, align 4, !tbaa !4261
  %89 = insertelement <16 x float> undef, float %88, i32 0
  %90 = shufflevector <16 x float> %89, <16 x float> undef, <16 x i32> zeroinitializer
  %91 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %90, <16 x float> %60, <16 x float> %45)
  %92 = add nsw i64 %51, 768
  %93 = getelementptr inbounds float, float* %4, i64 %92
  %94 = load float, float* %93, align 4, !tbaa !4261
  %95 = insertelement <16 x float> undef, float %94, i32 0
  %96 = shufflevector <16 x float> %95, <16 x float> undef, <16 x i32> zeroinitializer
  %97 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %96, <16 x float> %60, <16 x float> %44)
  %98 = add nsw i64 %51, 896
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !4261
  %101 = insertelement <16 x float> undef, float %100, i32 0
  %102 = shufflevector <16 x float> %101, <16 x float> undef, <16 x i32> zeroinitializer
  %103 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %102, <16 x float> %60, <16 x float> %43)
  %104 = add nsw i64 %51, 1024
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !4261
  %107 = insertelement <16 x float> undef, float %106, i32 0
  %108 = shufflevector <16 x float> %107, <16 x float> undef, <16 x i32> zeroinitializer
  %109 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %108, <16 x float> %60, <16 x float> %42)
  %110 = add nsw i64 %51, 1152
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !4261
  %113 = insertelement <16 x float> undef, float %112, i32 0
  %114 = shufflevector <16 x float> %113, <16 x float> undef, <16 x i32> zeroinitializer
  %115 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %114, <16 x float> %60, <16 x float> %41)
  %116 = add nsw i64 %51, 1280
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !4261
  %119 = insertelement <16 x float> undef, float %118, i32 0
  %120 = shufflevector <16 x float> %119, <16 x float> undef, <16 x i32> zeroinitializer
  %121 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %120, <16 x float> %60, <16 x float> %40)
  %122 = add nsw i64 %51, 1408
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !4261
  %125 = insertelement <16 x float> undef, float %124, i32 0
  %126 = shufflevector <16 x float> %125, <16 x float> undef, <16 x i32> zeroinitializer
  %127 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %126, <16 x float> %60, <16 x float> %39)
  %128 = add nsw i64 %51, 1536
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = load float, float* %129, align 4, !tbaa !4261
  %131 = insertelement <16 x float> undef, float %130, i32 0
  %132 = shufflevector <16 x float> %131, <16 x float> undef, <16 x i32> zeroinitializer
  %133 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %132, <16 x float> %60, <16 x float> %38)
  %134 = add nsw i64 %51, 1664
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !4261
  %137 = insertelement <16 x float> undef, float %136, i32 0
  %138 = shufflevector <16 x float> %137, <16 x float> undef, <16 x i32> zeroinitializer
  %139 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %138, <16 x float> %60, <16 x float> %37)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !50

for_end6:                                         ; preds = %for_body5
  %140 = add nsw i64 %35, 50176
  %141 = or i64 %36, 1024
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %142 = phi <16 x float> [ %139, %for_end6 ], [ %244, %for_body5.1 ]
  %143 = phi <16 x float> [ %133, %for_end6 ], [ %238, %for_body5.1 ]
  %144 = phi <16 x float> [ %127, %for_end6 ], [ %232, %for_body5.1 ]
  %145 = phi <16 x float> [ %121, %for_end6 ], [ %226, %for_body5.1 ]
  %146 = phi <16 x float> [ %115, %for_end6 ], [ %220, %for_body5.1 ]
  %147 = phi <16 x float> [ %109, %for_end6 ], [ %214, %for_body5.1 ]
  %148 = phi <16 x float> [ %103, %for_end6 ], [ %208, %for_body5.1 ]
  %149 = phi <16 x float> [ %97, %for_end6 ], [ %202, %for_body5.1 ]
  %150 = phi <16 x float> [ %91, %for_end6 ], [ %196, %for_body5.1 ]
  %151 = phi <16 x float> [ %85, %for_end6 ], [ %190, %for_body5.1 ]
  %152 = phi <16 x float> [ %79, %for_end6 ], [ %184, %for_body5.1 ]
  %153 = phi <16 x float> [ %73, %for_end6 ], [ %178, %for_body5.1 ]
  %154 = phi <16 x float> [ %67, %for_end6 ], [ %172, %for_body5.1 ]
  %155 = phi <16 x float> [ %61, %for_end6 ], [ %166, %for_body5.1 ]
  %156 = add nsw i64 %140, %indvars.iv.1
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !4261
  %159 = insertelement <16 x float> undef, float %158, i32 0
  %160 = shufflevector <16 x float> %159, <16 x float> undef, <16 x i32> zeroinitializer
  %161 = shl i64 %indvars.iv.1, 4
  %162 = add nuw nsw i64 %141, %161
  %163 = getelementptr inbounds float, float* %7, i64 %162
  %164 = bitcast float* %163 to <16 x float>*
  %165 = load <16 x float>, <16 x float>* %164, align 64, !tbaa !4264
  %166 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %160, <16 x float> %165, <16 x float> %155)
  %167 = add nsw i64 %156, 128
  %168 = getelementptr inbounds float, float* %4, i64 %167
  %169 = load float, float* %168, align 4, !tbaa !4261
  %170 = insertelement <16 x float> undef, float %169, i32 0
  %171 = shufflevector <16 x float> %170, <16 x float> undef, <16 x i32> zeroinitializer
  %172 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %171, <16 x float> %165, <16 x float> %154)
  %173 = add nsw i64 %156, 256
  %174 = getelementptr inbounds float, float* %4, i64 %173
  %175 = load float, float* %174, align 4, !tbaa !4261
  %176 = insertelement <16 x float> undef, float %175, i32 0
  %177 = shufflevector <16 x float> %176, <16 x float> undef, <16 x i32> zeroinitializer
  %178 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %177, <16 x float> %165, <16 x float> %153)
  %179 = add nsw i64 %156, 384
  %180 = getelementptr inbounds float, float* %4, i64 %179
  %181 = load float, float* %180, align 4, !tbaa !4261
  %182 = insertelement <16 x float> undef, float %181, i32 0
  %183 = shufflevector <16 x float> %182, <16 x float> undef, <16 x i32> zeroinitializer
  %184 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %183, <16 x float> %165, <16 x float> %152)
  %185 = add nsw i64 %156, 512
  %186 = getelementptr inbounds float, float* %4, i64 %185
  %187 = load float, float* %186, align 4, !tbaa !4261
  %188 = insertelement <16 x float> undef, float %187, i32 0
  %189 = shufflevector <16 x float> %188, <16 x float> undef, <16 x i32> zeroinitializer
  %190 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %189, <16 x float> %165, <16 x float> %151)
  %191 = add nsw i64 %156, 640
  %192 = getelementptr inbounds float, float* %4, i64 %191
  %193 = load float, float* %192, align 4, !tbaa !4261
  %194 = insertelement <16 x float> undef, float %193, i32 0
  %195 = shufflevector <16 x float> %194, <16 x float> undef, <16 x i32> zeroinitializer
  %196 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %195, <16 x float> %165, <16 x float> %150)
  %197 = add nsw i64 %156, 768
  %198 = getelementptr inbounds float, float* %4, i64 %197
  %199 = load float, float* %198, align 4, !tbaa !4261
  %200 = insertelement <16 x float> undef, float %199, i32 0
  %201 = shufflevector <16 x float> %200, <16 x float> undef, <16 x i32> zeroinitializer
  %202 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %201, <16 x float> %165, <16 x float> %149)
  %203 = add nsw i64 %156, 896
  %204 = getelementptr inbounds float, float* %4, i64 %203
  %205 = load float, float* %204, align 4, !tbaa !4261
  %206 = insertelement <16 x float> undef, float %205, i32 0
  %207 = shufflevector <16 x float> %206, <16 x float> undef, <16 x i32> zeroinitializer
  %208 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %207, <16 x float> %165, <16 x float> %148)
  %209 = add nsw i64 %156, 1024
  %210 = getelementptr inbounds float, float* %4, i64 %209
  %211 = load float, float* %210, align 4, !tbaa !4261
  %212 = insertelement <16 x float> undef, float %211, i32 0
  %213 = shufflevector <16 x float> %212, <16 x float> undef, <16 x i32> zeroinitializer
  %214 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %213, <16 x float> %165, <16 x float> %147)
  %215 = add nsw i64 %156, 1152
  %216 = getelementptr inbounds float, float* %4, i64 %215
  %217 = load float, float* %216, align 4, !tbaa !4261
  %218 = insertelement <16 x float> undef, float %217, i32 0
  %219 = shufflevector <16 x float> %218, <16 x float> undef, <16 x i32> zeroinitializer
  %220 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %219, <16 x float> %165, <16 x float> %146)
  %221 = add nsw i64 %156, 1280
  %222 = getelementptr inbounds float, float* %4, i64 %221
  %223 = load float, float* %222, align 4, !tbaa !4261
  %224 = insertelement <16 x float> undef, float %223, i32 0
  %225 = shufflevector <16 x float> %224, <16 x float> undef, <16 x i32> zeroinitializer
  %226 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %225, <16 x float> %165, <16 x float> %145)
  %227 = add nsw i64 %156, 1408
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = load float, float* %228, align 4, !tbaa !4261
  %230 = insertelement <16 x float> undef, float %229, i32 0
  %231 = shufflevector <16 x float> %230, <16 x float> undef, <16 x i32> zeroinitializer
  %232 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %231, <16 x float> %165, <16 x float> %144)
  %233 = add nsw i64 %156, 1536
  %234 = getelementptr inbounds float, float* %4, i64 %233
  %235 = load float, float* %234, align 4, !tbaa !4261
  %236 = insertelement <16 x float> undef, float %235, i32 0
  %237 = shufflevector <16 x float> %236, <16 x float> undef, <16 x i32> zeroinitializer
  %238 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %237, <16 x float> %165, <16 x float> %143)
  %239 = add nsw i64 %156, 1664
  %240 = getelementptr inbounds float, float* %4, i64 %239
  %241 = load float, float* %240, align 4, !tbaa !4261
  %242 = insertelement <16 x float> undef, float %241, i32 0
  %243 = shufflevector <16 x float> %242, <16 x float> undef, <16 x i32> zeroinitializer
  %244 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %243, <16 x float> %165, <16 x float> %142)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 64
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !50

for_end6.1:                                       ; preds = %for_body5.1
  %245 = mul nsw i64 %indvars.iv83, 224
  %246 = shl nsw i32 %33, 4
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds float, float* %13, i64 %247
  %249 = bitcast float* %248 to <16 x float>*
  %250 = load <16 x float>, <16 x float>* %249, align 64, !tbaa !4267
  %251 = fadd <16 x float> %250, %166
  %252 = getelementptr inbounds float, float* %10, i64 %245
  %253 = bitcast float* %252 to <16 x float>*
  store <16 x float> %251, <16 x float>* %253, align 64, !tbaa !4270
  %254 = or i64 %245, 16
  %255 = fadd <16 x float> %250, %172
  %256 = getelementptr inbounds float, float* %10, i64 %254
  %257 = bitcast float* %256 to <16 x float>*
  store <16 x float> %255, <16 x float>* %257, align 64, !tbaa !4270
  %258 = add nsw i64 %245, 32
  %259 = fadd <16 x float> %250, %178
  %260 = getelementptr inbounds float, float* %10, i64 %258
  %261 = bitcast float* %260 to <16 x float>*
  store <16 x float> %259, <16 x float>* %261, align 64, !tbaa !4270
  %262 = add nsw i64 %245, 48
  %263 = fadd <16 x float> %250, %184
  %264 = getelementptr inbounds float, float* %10, i64 %262
  %265 = bitcast float* %264 to <16 x float>*
  store <16 x float> %263, <16 x float>* %265, align 64, !tbaa !4270
  %266 = add nsw i64 %245, 64
  %267 = fadd <16 x float> %250, %190
  %268 = getelementptr inbounds float, float* %10, i64 %266
  %269 = bitcast float* %268 to <16 x float>*
  store <16 x float> %267, <16 x float>* %269, align 64, !tbaa !4270
  %270 = add nsw i64 %245, 80
  %271 = fadd <16 x float> %250, %196
  %272 = getelementptr inbounds float, float* %10, i64 %270
  %273 = bitcast float* %272 to <16 x float>*
  store <16 x float> %271, <16 x float>* %273, align 64, !tbaa !4270
  %274 = add nsw i64 %245, 96
  %275 = fadd <16 x float> %250, %202
  %276 = getelementptr inbounds float, float* %10, i64 %274
  %277 = bitcast float* %276 to <16 x float>*
  store <16 x float> %275, <16 x float>* %277, align 64, !tbaa !4270
  %278 = add nsw i64 %245, 112
  %279 = fadd <16 x float> %250, %208
  %280 = getelementptr inbounds float, float* %10, i64 %278
  %281 = bitcast float* %280 to <16 x float>*
  store <16 x float> %279, <16 x float>* %281, align 64, !tbaa !4270
  %282 = add nsw i64 %245, 128
  %283 = fadd <16 x float> %250, %214
  %284 = getelementptr inbounds float, float* %10, i64 %282
  %285 = bitcast float* %284 to <16 x float>*
  store <16 x float> %283, <16 x float>* %285, align 64, !tbaa !4270
  %286 = add nsw i64 %245, 144
  %287 = fadd <16 x float> %250, %220
  %288 = getelementptr inbounds float, float* %10, i64 %286
  %289 = bitcast float* %288 to <16 x float>*
  store <16 x float> %287, <16 x float>* %289, align 64, !tbaa !4270
  %290 = add nsw i64 %245, 160
  %291 = fadd <16 x float> %250, %226
  %292 = getelementptr inbounds float, float* %10, i64 %290
  %293 = bitcast float* %292 to <16 x float>*
  store <16 x float> %291, <16 x float>* %293, align 64, !tbaa !4270
  %294 = add nsw i64 %245, 176
  %295 = fadd <16 x float> %250, %232
  %296 = getelementptr inbounds float, float* %10, i64 %294
  %297 = bitcast float* %296 to <16 x float>*
  store <16 x float> %295, <16 x float>* %297, align 64, !tbaa !4270
  %298 = add nsw i64 %245, 192
  %299 = fadd <16 x float> %250, %238
  %300 = getelementptr inbounds float, float* %10, i64 %298
  %301 = bitcast float* %300 to <16 x float>*
  store <16 x float> %299, <16 x float>* %301, align 64, !tbaa !4270
  %302 = add nsw i64 %245, 208
  %303 = fadd <16 x float> %250, %244
  %304 = getelementptr inbounds float, float* %10, i64 %302
  %305 = bitcast float* %304 to <16 x float>*
  store <16 x float> %303, <16 x float>* %305, align 64, !tbaa !4270
  %indvars.iv.next84 = add nsw i64 %indvars.iv83, 1
  %306 = icmp slt i64 %indvars.iv.next84, %29
  br i1 %306, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_layout_transform_18(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.335, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !4273
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.336, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !4287
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.337, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !4289
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !4303
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 16
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !4305
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 14
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !4308
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 14
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !4310
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 16
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.338, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !4314
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 50176, i32 3136, i32 224, i32 16>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !4326
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.339, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !4330
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !4344
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 32
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.158, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !4346
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 14
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.17, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !4349
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 14
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.18, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !4351
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 8
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !4355
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 50176, i32 1568, i32 112, i32 8>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !4367
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([236 x i8], [236 x i8]* @.str.340, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_18_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_18_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %41, align 8
  %3 = getelementptr inbounds %41, %41* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %41, %41* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %41* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.341, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.341(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 447
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 448
  %15 = select i1 %14, i32 %13, i32 448
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 448
  %18 = select i1 %17, i32 %16, i32 448
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv4 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next5, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv4, 112
  %25 = trunc i64 %indvars.iv4 to i32
  %26 = sdiv i32 %25, 14
  %27 = shl nsw i32 %26, 3
  %28 = insertelement <8 x i32> undef, i32 %27, i32 0
  %29 = insertelement <4 x i32> undef, i32 %27, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = or <4 x i32> %30, <i32 1, i32 2, i32 3, i32 4>
  %32 = extractelement <4 x i32> %31, i32 0
  %33 = insertelement <8 x i32> %28, i32 %32, i32 1
  %34 = extractelement <4 x i32> %31, i32 1
  %35 = insertelement <8 x i32> %33, i32 %34, i32 2
  %36 = extractelement <4 x i32> %31, i32 2
  %37 = insertelement <8 x i32> %35, i32 %36, i32 3
  %38 = extractelement <4 x i32> %31, i32 3
  %39 = insertelement <8 x i32> %37, i32 %38, i32 4
  %40 = or i32 %27, 5
  %41 = insertelement <8 x i32> %39, i32 %40, i32 5
  %42 = or i32 %27, 6
  %43 = insertelement <8 x i32> %41, i32 %42, i32 6
  %44 = or i32 %27, 7
  %45 = insertelement <8 x i32> %43, i32 %44, i32 7
  %46 = sdiv <8 x i32> %45, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %47 = mul <8 x i32> %46, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %48 = sub <8 x i32> %45, %47
  %49 = add nsw <8 x i32> %48, <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
  %50 = icmp sgt <8 x i32> %48, <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>
  %51 = select <8 x i1> %50, <8 x i32> %48, <8 x i32> %49
  %52 = srem i32 %25, 14
  %53 = mul nsw i32 %52, 224
  %54 = insertelement <8 x i32> undef, i32 %53, i32 0
  %55 = shufflevector <8 x i32> %54, <8 x i32> undef, <8 x i32> zeroinitializer
  %not. = xor <8 x i1> %50, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>
  %56 = sext <8 x i1> %not. to <8 x i32>
  %57 = add nsw <8 x i32> %46, %56
  %58 = mul nsw <8 x i32> %57, <i32 3136, i32 3136, i32 3136, i32 3136, i32 3136, i32 3136, i32 3136, i32 3136>
  %59 = add <8 x i32> %51, %55
  %60 = add <8 x i32> %59, %58
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_body2 ]
  %61 = shl i64 %indvars.iv, 3
  %62 = add nsw i64 %61, %24
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %63 = shl i32 %indvars.iv.tr, 4
  %64 = insertelement <8 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <8 x i32> %64, <8 x i32> undef, <8 x i32> zeroinitializer
  %66 = add <8 x i32> %60, %65
  %67 = extractelement <8 x i32> %66, i64 0
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = load float, float* %69, align 4, !tbaa !4371
  %71 = insertelement <8 x float> undef, float %70, i32 0
  %72 = extractelement <8 x i32> %66, i64 1
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %7, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !4371
  %76 = insertelement <8 x float> %71, float %75, i32 1
  %77 = extractelement <8 x i32> %66, i64 2
  %78 = sext i32 %77 to i64
  %79 = getelementptr inbounds float, float* %7, i64 %78
  %80 = load float, float* %79, align 4, !tbaa !4371
  %81 = insertelement <8 x float> %76, float %80, i32 2
  %82 = extractelement <8 x i32> %66, i64 3
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = load float, float* %84, align 4, !tbaa !4371
  %86 = insertelement <8 x float> %81, float %85, i32 3
  %87 = extractelement <8 x i32> %66, i64 4
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !4371
  %91 = insertelement <8 x float> %86, float %90, i32 4
  %92 = extractelement <8 x i32> %66, i64 5
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = load float, float* %94, align 4, !tbaa !4371
  %96 = insertelement <8 x float> %91, float %95, i32 5
  %97 = extractelement <8 x i32> %66, i64 6
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !4371
  %101 = insertelement <8 x float> %96, float %100, i32 6
  %102 = extractelement <8 x i32> %66, i64 7
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %7, i64 %103
  %105 = load float, float* %104, align 4, !tbaa !4371
  %106 = insertelement <8 x float> %101, float %105, i32 7
  %107 = getelementptr inbounds float, float* %4, i64 %62
  %108 = bitcast float* %107 to <8 x float>*
  store <8 x float> %106, <8 x float>* %108, align 32, !tbaa !4374
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 14
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !50

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next5 = add nsw i64 %indvars.iv4, 1
  %109 = icmp slt i64 %indvars.iv.next5, %23
  br i1 %109, label %for_begin1.preheader, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 5
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.342, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !4377
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !4391
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !4394
  %26 = getelementptr inbounds i8, i8* %0, i64 32
  %27 = bitcast i8* %26 to %1**
  %28 = load %1*, %1** %27, align 8
  %29 = getelementptr inbounds i8, i8* %1, i64 16
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4, !tbaa !4396
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %33 = load i8*, i8** %32, align 8
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %35 = load i64*, i64** %34, align 8
  %36 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %37 = load i64*, i64** %36, align 8
  %38 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  %54 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %55 = load i8*, i8** %54, align 8
  %56 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %57 = load i64*, i64** %56, align 8
  %58 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %59 = load i64*, i64** %58, align 8
  %60 = getelementptr inbounds %1, %1* %28, i64 0, i32 0
  %61 = load i8*, i8** %60, align 8
  %62 = getelementptr inbounds %1, %1* %28, i64 0, i32 4
  %63 = load i64*, i64** %62, align 8
  %64 = getelementptr inbounds %1, %1* %28, i64 0, i32 5
  %65 = load i64*, i64** %64, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.343, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %67 = getelementptr inbounds i8, i8* %1, i64 4
  %68 = bitcast i8* %67 to i32*
  %69 = load i32, i32* %68, align 4, !tbaa !4400
  switch i32 %69, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %70 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %70(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.344, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.345, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %72 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %72(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.346, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  switch i32 %31, label %assert_fail9 [
    i32 13, label %assert_end10
    i32 7, label %assert_end10
    i32 4, label %assert_end10
    i32 3, label %assert_end10
  ]

assert_fail9:                                     ; preds = %assert_end8
  %73 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %73(i8* getelementptr inbounds ([175 x i8], [175 x i8]* @.str.347, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8, %assert_end8, %assert_end8, %assert_end8
  %74 = icmp eq i32 %39, 1
  br i1 %74, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %75 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %75(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %76 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %77 = load i32, i32* %76, align 4
  %78 = icmp eq i32 %77, 5
  br i1 %78, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %79 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %79(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %80 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %81 = load i16, i16* %80, align 2
  %82 = icmp eq i16 %81, 1
  %83 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %84 = load i8, i8* %83, align 1
  %85 = icmp eq i8 %84, 32
  %86 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %87 = load i8, i8* %86, align 1
  %88 = icmp eq i8 %87, 2
  %89 = and i1 %85, %88
  %90 = and i1 %82, %89
  br i1 %90, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %92 = load i64, i64* %35, align 8, !tbaa !4402
  %93 = trunc i64 %92 to i32
  %94 = icmp eq i32 %93, 1
  br i1 %94, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %95 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %95(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %96 = getelementptr inbounds i64, i64* %35, i64 1
  %97 = load i64, i64* %96, align 8, !tbaa !4416
  %98 = trunc i64 %97 to i32
  %99 = icmp eq i32 %98, 2
  br i1 %99, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %100 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %100(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.166, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %101 = getelementptr inbounds i64, i64* %35, i64 2
  %102 = load i64, i64* %101, align 8, !tbaa !4418
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, 14
  br i1 %104, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %105 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %105(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %106 = getelementptr inbounds i64, i64* %35, i64 3
  %107 = load i64, i64* %106, align 8, !tbaa !4421
  %108 = trunc i64 %107 to i32
  %109 = icmp eq i32 %108, 14
  br i1 %109, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %110 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %110(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %111 = getelementptr inbounds i64, i64* %35, i64 4
  %112 = load i64, i64* %111, align 8, !tbaa !4423
  %113 = trunc i64 %112 to i32
  %114 = icmp eq i32 %113, 128
  br i1 %114, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %115 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %115(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.43, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %116 = icmp eq i64* %37, null
  br i1 %116, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end26
  %117 = bitcast i64* %37 to <4 x i64>*
  %118 = load <4 x i64>, <4 x i64>* %117, align 8, !tbaa !4427
  %119 = trunc <4 x i64> %118 to <4 x i32>
  %120 = icmp eq <4 x i32> %119, <i32 50176, i32 25088, i32 1792, i32 128>
  %121 = getelementptr inbounds i64, i64* %37, i64 4
  %122 = load i64, i64* %121, align 8, !tbaa !4439
  %123 = trunc i64 %122 to i32
  %124 = icmp eq i32 %123, 1
  %rdx.shuf143 = shufflevector <4 x i1> %120, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx144 = and <4 x i1> %120, %rdx.shuf143
  %rdx.shuf145 = shufflevector <4 x i1> %bin.rdx144, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx146 = and <4 x i1> %bin.rdx144, %rdx.shuf145
  %125 = extractelement <4 x i1> %bin.rdx146, i32 0
  %126 = and i1 %125, %124
  br i1 %126, label %if_end, label %assert_fail27, !prof !5

if_end:                                           ; preds = %assert_end26, %if_then
  %127 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %128 = load i64, i64* %127, align 8
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %assert_end30, label %assert_fail29, !prof !5

assert_fail27:                                    ; preds = %if_then
  %130 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %130(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.218, i64 0, i64 0))
  ret i32 -1

assert_fail29:                                    ; preds = %if_end
  %131 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %131(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %if_end
  %132 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %133 = load i32, i32* %132, align 4
  %134 = icmp eq i32 %133, 6
  br i1 %134, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %135 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %135(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %136 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %137 = load i16, i16* %136, align 2
  %138 = icmp eq i16 %137, 1
  %139 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %140 = load i8, i8* %139, align 1
  %141 = icmp eq i8 %140, 32
  %142 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %143 = load i8, i8* %142, align 1
  %144 = icmp eq i8 %143, 2
  %145 = and i1 %141, %144
  %146 = and i1 %138, %145
  br i1 %146, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %148 = load i64, i64* %45, align 8, !tbaa !4443
  %149 = trunc i64 %148 to i32
  %150 = icmp eq i32 %149, 16
  br i1 %150, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %151 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %151(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.97, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %152 = getelementptr inbounds i64, i64* %45, i64 1
  %153 = load i64, i64* %152, align 8, !tbaa !4457
  %154 = trunc i64 %153 to i32
  %155 = icmp eq i32 %154, 2
  br i1 %155, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %157 = getelementptr inbounds i64, i64* %45, i64 2
  %158 = load i64, i64* %157, align 8, !tbaa !4459
  %159 = trunc i64 %158 to i32
  %160 = icmp eq i32 %159, 3
  br i1 %160, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %161 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %161(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.48, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %162 = getelementptr inbounds i64, i64* %45, i64 3
  %163 = load i64, i64* %162, align 8, !tbaa !4462
  %164 = trunc i64 %163 to i32
  %165 = icmp eq i32 %164, 3
  br i1 %165, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %166 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %166(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.49, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %167 = getelementptr inbounds i64, i64* %45, i64 4
  %168 = load i64, i64* %167, align 8, !tbaa !4464
  %169 = trunc i64 %168 to i32
  %170 = icmp eq i32 %169, 128
  br i1 %170, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %171 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %171(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %172 = getelementptr inbounds i64, i64* %45, i64 5
  %173 = load i64, i64* %172, align 8, !tbaa !4468
  %174 = trunc i64 %173 to i32
  %175 = icmp eq i32 %174, 16
  br i1 %175, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %176 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %176(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.219, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %177 = icmp eq i64* %47, null
  br i1 %177, label %if_end48, label %if_then47, !prof !50

if_then47:                                        ; preds = %assert_end46
  %178 = bitcast i64* %47 to <4 x i64>*
  %179 = load <4 x i64>, <4 x i64>* %178, align 8, !tbaa !4470
  %180 = trunc <4 x i64> %179 to <4 x i32>
  %181 = icmp eq <4 x i32> %180, <i32 36864, i32 18432, i32 6144, i32 2048>
  %182 = getelementptr inbounds i64, i64* %47, i64 4
  %183 = load i64, i64* %182, align 8, !tbaa !4482
  %184 = trunc i64 %183 to i32
  %185 = icmp eq i32 %184, 16
  %186 = getelementptr inbounds i64, i64* %47, i64 5
  %187 = load i64, i64* %186, align 8, !tbaa !4486
  %188 = trunc i64 %187 to i32
  %189 = icmp eq i32 %188, 1
  %rdx.shuf139 = shufflevector <4 x i1> %181, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx140 = and <4 x i1> %181, %rdx.shuf139
  %rdx.shuf141 = shufflevector <4 x i1> %bin.rdx140, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx142 = and <4 x i1> %bin.rdx140, %rdx.shuf141
  %190 = extractelement <4 x i1> %bin.rdx142, i32 0
  %191 = and i1 %190, %185
  %192 = and i1 %191, %189
  br i1 %192, label %if_end48, label %assert_fail49, !prof !5

if_end48:                                         ; preds = %assert_end46, %if_then47
  %193 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %194 = load i64, i64* %193, align 8
  %195 = icmp eq i64 %194, 0
  br i1 %195, label %assert_end52, label %assert_fail51, !prof !5

assert_fail49:                                    ; preds = %if_then47
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([277 x i8], [277 x i8]* @.str.220, i64 0, i64 0))
  ret i32 -1

assert_fail51:                                    ; preds = %if_end48
  %197 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %197(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %if_end48
  %198 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %199 = load i32, i32* %198, align 4
  %200 = icmp eq i32 %199, 1
  br i1 %200, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %201 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %201(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %202 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %203 = load i32, i32* %202, align 4
  %204 = icmp eq i32 %41, %203
  br i1 %204, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %205 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %205(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %206 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %207 = load i32, i32* %206, align 4
  %208 = icmp eq i32 %207, 5
  br i1 %208, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %209 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %209(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %210 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %211 = load i16, i16* %210, align 2
  %212 = icmp eq i16 %211, 1
  %213 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %214 = load i8, i8* %213, align 1
  %215 = icmp eq i8 %214, 32
  %216 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %217 = load i8, i8* %216, align 1
  %218 = icmp eq i8 %217, 2
  %219 = and i1 %215, %218
  %220 = and i1 %212, %219
  br i1 %220, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %221 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %221(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %222 = load i64, i64* %51, align 8, !tbaa !4488
  %223 = trunc i64 %222 to i32
  %224 = icmp eq i32 %223, 1
  br i1 %224, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %225 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %225(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %226 = getelementptr inbounds i64, i64* %51, i64 1
  %227 = load i64, i64* %226, align 8, !tbaa !4502
  %228 = trunc i64 %227 to i32
  %229 = icmp eq i32 %228, 16
  br i1 %229, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %230 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %230(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.100, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %231 = getelementptr inbounds i64, i64* %51, i64 2
  %232 = load i64, i64* %231, align 8, !tbaa !4504
  %233 = trunc i64 %232 to i32
  %234 = icmp eq i32 %233, 1
  br i1 %234, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %235 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %235(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %236 = getelementptr inbounds i64, i64* %51, i64 3
  %237 = load i64, i64* %236, align 8, !tbaa !4507
  %238 = trunc i64 %237 to i32
  %239 = icmp eq i32 %238, 1
  br i1 %239, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %240 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %240(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %241 = getelementptr inbounds i64, i64* %51, i64 4
  %242 = load i64, i64* %241, align 8, !tbaa !4509
  %243 = trunc i64 %242 to i32
  %244 = icmp eq i32 %243, 16
  br i1 %244, label %assert_end70, label %assert_fail69, !prof !5

assert_fail69:                                    ; preds = %assert_end68
  %245 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %245(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.221, i64 0, i64 0))
  ret i32 -1

assert_end70:                                     ; preds = %assert_end68
  %246 = icmp eq i64* %53, null
  br i1 %246, label %if_end72, label %if_then71, !prof !50

if_then71:                                        ; preds = %assert_end70
  %247 = bitcast i64* %53 to <4 x i64>*
  %248 = load <4 x i64>, <4 x i64>* %247, align 8, !tbaa !4513
  %249 = trunc <4 x i64> %248 to <4 x i32>
  %250 = icmp eq <4 x i32> %249, <i32 256, i32 16, i32 16, i32 16>
  %251 = getelementptr inbounds i64, i64* %53, i64 4
  %252 = load i64, i64* %251, align 8, !tbaa !4525
  %253 = trunc i64 %252 to i32
  %254 = icmp eq i32 %253, 1
  %rdx.shuf135 = shufflevector <4 x i1> %250, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx136 = and <4 x i1> %250, %rdx.shuf135
  %rdx.shuf137 = shufflevector <4 x i1> %bin.rdx136, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx138 = and <4 x i1> %bin.rdx136, %rdx.shuf137
  %255 = extractelement <4 x i1> %bin.rdx138, i32 0
  %256 = and i1 %255, %254
  br i1 %256, label %if_end72, label %assert_fail73, !prof !5

if_end72:                                         ; preds = %assert_end70, %if_then71
  %257 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %258 = load i64, i64* %257, align 8
  %259 = icmp eq i64 %258, 0
  br i1 %259, label %assert_end76, label %assert_fail75, !prof !5

assert_fail73:                                    ; preds = %if_then71
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.222, i64 0, i64 0))
  ret i32 -1

assert_fail75:                                    ; preds = %if_end72
  %261 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %261(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %if_end72
  %262 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %263 = load i32, i32* %262, align 4
  %264 = icmp eq i32 %263, 1
  br i1 %264, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %265 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %265(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %266 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %267 = load i32, i32* %266, align 4
  %268 = icmp eq i32 %41, %267
  br i1 %268, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %269 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %269(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %270 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %271 = load i32, i32* %270, align 4
  %272 = icmp eq i32 %271, 5
  br i1 %272, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %273 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %273(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %274 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %275 = load i16, i16* %274, align 2
  %276 = icmp eq i16 %275, 1
  %277 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %278 = load i8, i8* %277, align 1
  %279 = icmp eq i8 %278, 32
  %280 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %281 = load i8, i8* %280, align 1
  %282 = icmp eq i8 %281, 2
  %283 = and i1 %279, %282
  %284 = and i1 %276, %283
  br i1 %284, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %285 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %285(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %286 = load i64, i64* %57, align 8, !tbaa !4529
  %287 = trunc i64 %286 to i32
  %288 = icmp eq i32 %287, 1
  br i1 %288, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %289 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %289(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %290 = getelementptr inbounds i64, i64* %57, i64 1
  %291 = load i64, i64* %290, align 8, !tbaa !4543
  %292 = trunc i64 %291 to i32
  %293 = icmp eq i32 %292, 16
  br i1 %293, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %294 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %294(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.102, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %295 = getelementptr inbounds i64, i64* %57, i64 2
  %296 = load i64, i64* %295, align 8, !tbaa !4545
  %297 = trunc i64 %296 to i32
  %298 = icmp eq i32 %297, 14
  br i1 %298, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %299 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %299(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.223, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %300 = getelementptr inbounds i64, i64* %57, i64 3
  %301 = load i64, i64* %300, align 8, !tbaa !4548
  %302 = trunc i64 %301 to i32
  %303 = icmp eq i32 %302, 14
  br i1 %303, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %304 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %304(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.224, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %305 = getelementptr inbounds i64, i64* %57, i64 4
  %306 = load i64, i64* %305, align 8, !tbaa !4550
  %307 = trunc i64 %306 to i32
  %308 = icmp eq i32 %307, 16
  br i1 %308, label %assert_end94, label %assert_fail93, !prof !5

assert_fail93:                                    ; preds = %assert_end92
  %309 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %309(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.225, i64 0, i64 0))
  ret i32 -1

assert_end94:                                     ; preds = %assert_end92
  %310 = icmp eq i64* %59, null
  br i1 %310, label %if_end96, label %if_then95, !prof !50

if_then95:                                        ; preds = %assert_end94
  %311 = bitcast i64* %59 to <4 x i64>*
  %312 = load <4 x i64>, <4 x i64>* %311, align 8, !tbaa !4554
  %313 = trunc <4 x i64> %312 to <4 x i32>
  %314 = icmp eq <4 x i32> %313, <i32 50176, i32 3136, i32 224, i32 16>
  %315 = getelementptr inbounds i64, i64* %59, i64 4
  %316 = load i64, i64* %315, align 8, !tbaa !4566
  %317 = trunc i64 %316 to i32
  %318 = icmp eq i32 %317, 1
  %rdx.shuf131 = shufflevector <4 x i1> %314, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx132 = and <4 x i1> %314, %rdx.shuf131
  %rdx.shuf133 = shufflevector <4 x i1> %bin.rdx132, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx134 = and <4 x i1> %bin.rdx132, %rdx.shuf133
  %319 = extractelement <4 x i1> %bin.rdx134, i32 0
  %320 = and i1 %319, %318
  br i1 %320, label %if_end96, label %assert_fail97, !prof !5

if_end96:                                         ; preds = %assert_end94, %if_then95
  %321 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %322 = load i64, i64* %321, align 8
  %323 = icmp eq i64 %322, 0
  br i1 %323, label %assert_end100, label %assert_fail99, !prof !5

assert_fail97:                                    ; preds = %if_then95
  %324 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %324(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.226, i64 0, i64 0))
  ret i32 -1

assert_fail99:                                    ; preds = %if_end96
  %325 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %325(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %if_end96
  %326 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %327 = load i32, i32* %326, align 4
  %328 = icmp eq i32 %327, 1
  br i1 %328, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %329 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %329(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %330 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %331 = load i32, i32* %330, align 4
  %332 = icmp eq i32 %41, %331
  br i1 %332, label %assert_end104, label %assert_fail103, !prof !5

assert_fail103:                                   ; preds = %assert_end102
  %333 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %333(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end104:                                    ; preds = %assert_end102
  %334 = getelementptr inbounds %1, %1* %28, i64 0, i32 2
  %335 = load i32, i32* %334, align 4
  %336 = icmp eq i32 %335, 5
  br i1 %336, label %assert_end106, label %assert_fail105, !prof !5

assert_fail105:                                   ; preds = %assert_end104
  %337 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %337(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.74, i64 0, i64 0))
  ret i32 -1

assert_end106:                                    ; preds = %assert_end104
  %338 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 2
  %339 = load i16, i16* %338, align 2
  %340 = icmp eq i16 %339, 1
  %341 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 1
  %342 = load i8, i8* %341, align 1
  %343 = icmp eq i8 %342, 32
  %344 = getelementptr inbounds %1, %1* %28, i64 0, i32 3, i32 0
  %345 = load i8, i8* %344, align 1
  %346 = icmp eq i8 %345, 2
  %347 = and i1 %343, %346
  %348 = and i1 %340, %347
  br i1 %348, label %assert_end108, label %assert_fail107, !prof !5

assert_fail107:                                   ; preds = %assert_end106
  %349 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %349(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.75, i64 0, i64 0))
  ret i32 -1

assert_end108:                                    ; preds = %assert_end106
  %350 = load i64, i64* %63, align 8, !tbaa !4570
  %351 = trunc i64 %350 to i32
  %352 = icmp eq i32 %351, 1
  br i1 %352, label %assert_end110, label %assert_fail109, !prof !5

assert_fail109:                                   ; preds = %assert_end108
  %353 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %353(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.76, i64 0, i64 0))
  ret i32 -1

assert_end110:                                    ; preds = %assert_end108
  %354 = getelementptr inbounds i64, i64* %63, i64 1
  %355 = load i64, i64* %354, align 8, !tbaa !4584
  %356 = trunc i64 %355 to i32
  %357 = icmp eq i32 %356, 16
  br i1 %357, label %assert_end112, label %assert_fail111, !prof !5

assert_fail111:                                   ; preds = %assert_end110
  %358 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %358(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.106, i64 0, i64 0))
  ret i32 -1

assert_end112:                                    ; preds = %assert_end110
  %359 = getelementptr inbounds i64, i64* %63, i64 2
  %360 = load i64, i64* %359, align 8, !tbaa !4586
  %361 = trunc i64 %360 to i32
  %362 = icmp eq i32 %361, 14
  br i1 %362, label %assert_end114, label %assert_fail113, !prof !5

assert_fail113:                                   ; preds = %assert_end112
  %363 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %363(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.348, i64 0, i64 0))
  ret i32 -1

assert_end114:                                    ; preds = %assert_end112
  %364 = getelementptr inbounds i64, i64* %63, i64 3
  %365 = load i64, i64* %364, align 8, !tbaa !4589
  %366 = trunc i64 %365 to i32
  %367 = icmp eq i32 %366, 14
  br i1 %367, label %assert_end116, label %assert_fail115, !prof !5

assert_fail115:                                   ; preds = %assert_end114
  %368 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %368(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.349, i64 0, i64 0))
  ret i32 -1

assert_end116:                                    ; preds = %assert_end114
  %369 = getelementptr inbounds i64, i64* %63, i64 4
  %370 = load i64, i64* %369, align 8, !tbaa !4591
  %371 = trunc i64 %370 to i32
  %372 = icmp eq i32 %371, 16
  br i1 %372, label %assert_end118, label %assert_fail117, !prof !5

assert_fail117:                                   ; preds = %assert_end116
  %373 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %373(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.350, i64 0, i64 0))
  ret i32 -1

assert_end118:                                    ; preds = %assert_end116
  %374 = icmp eq i64* %65, null
  br i1 %374, label %if_end120, label %if_then119, !prof !50

if_then119:                                       ; preds = %assert_end118
  %375 = bitcast i64* %65 to <4 x i64>*
  %376 = load <4 x i64>, <4 x i64>* %375, align 8, !tbaa !4595
  %377 = trunc <4 x i64> %376 to <4 x i32>
  %378 = icmp eq <4 x i32> %377, <i32 50176, i32 3136, i32 224, i32 16>
  %379 = getelementptr inbounds i64, i64* %65, i64 4
  %380 = load i64, i64* %379, align 8, !tbaa !4607
  %381 = trunc i64 %380 to i32
  %382 = icmp eq i32 %381, 1
  %rdx.shuf = shufflevector <4 x i1> %378, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %378, %rdx.shuf
  %rdx.shuf129 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx130 = and <4 x i1> %bin.rdx, %rdx.shuf129
  %383 = extractelement <4 x i1> %bin.rdx130, i32 0
  %384 = and i1 %383, %382
  br i1 %384, label %if_end120, label %assert_fail121, !prof !5

if_end120:                                        ; preds = %assert_end118, %if_then119
  %385 = getelementptr inbounds %1, %1* %28, i64 0, i32 6
  %386 = load i64, i64* %385, align 8
  %387 = icmp eq i64 %386, 0
  br i1 %387, label %assert_end124, label %assert_fail123, !prof !5

assert_fail121:                                   ; preds = %if_then119
  %388 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %388(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.351, i64 0, i64 0))
  ret i32 -1

assert_fail123:                                   ; preds = %if_end120
  %389 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %389(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.82, i64 0, i64 0))
  ret i32 -1

assert_end124:                                    ; preds = %if_end120
  %390 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 0
  %391 = load i32, i32* %390, align 4
  %392 = icmp eq i32 %391, 1
  br i1 %392, label %assert_end126, label %assert_fail125, !prof !5

assert_fail125:                                   ; preds = %assert_end124
  %393 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %393(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.83, i64 0, i64 0))
  ret i32 -1

assert_end126:                                    ; preds = %assert_end124
  %394 = getelementptr inbounds %1, %1* %28, i64 0, i32 1, i32 1
  %395 = load i32, i32* %394, align 4
  %396 = icmp eq i32 %41, %395
  br i1 %396, label %assert_end128, label %assert_fail127, !prof !5

assert_fail127:                                   ; preds = %assert_end126
  %397 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %397(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.84, i64 0, i64 0))
  ret i32 -1

assert_end128:                                    ; preds = %assert_end126
  %398 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1_compute_(i8* %33, i8* %43, i8* %61, i8* %49, i8* %55, i32 %41)
  ret i32 %398
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %7 = tail call i8* %6(i32 1, i32 %5, i64 262144, i32 2, i32 32)
  %8 = alloca %42, align 8
  %9 = getelementptr inbounds %42, %42* %8, i64 0, i32 0
  store i8* %7, i8** %9, align 8
  %10 = getelementptr inbounds %42, %42* %8, i64 0, i32 1
  store i8* %0, i8** %10, align 8
  %11 = bitcast %42* %8 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.352, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !5

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %call_end2 ], [ %23, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = alloca %43, align 8
  %16 = getelementptr inbounds %43, %43* %15, i64 0, i32 0
  store i8* %7, i8** %16, align 8
  %17 = getelementptr inbounds %43, %43* %15, i64 0, i32 1
  store i8* %1, i8** %17, align 8
  %18 = getelementptr inbounds %43, %43* %15, i64 0, i32 2
  store i8* %2, i8** %18, align 8
  %19 = getelementptr inbounds %43, %43* %15, i64 0, i32 3
  store i8* %3, i8** %19, align 8
  %20 = getelementptr inbounds %43, %43* %15, i64 0, i32 4
  store i8* %4, i8** %20, align 8
  %21 = bitcast %43* %15 to i8*
  %22 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %23 = call i32 %22(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.353, i8* nonnull %21, i32 0)
  %24 = icmp eq i32 %23, 0
  br i1 %24, label %call_end2, label %call_fail, !prof !5

call_end2:                                        ; preds = %call_end
  %25 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %26 = call i32 %25(i32 1, i32 %5, i8* %7)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.352(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 31
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 32
  %15 = select i1 %14, i32 %13, i32 32
  %16 = mul i32 %11, %0
  %17 = icmp slt i32 %16, 32
  %18 = select i1 %17, i32 %16, i32 32
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = icmp slt i32 %16, 32
  %21 = select i1 %20, i32 %16, i32 32
  %smax = shl i32 %21, 11
  %22 = xor i32 %smax, -2048
  %23 = sub i32 -2048, %22
  %24 = add i32 %18, 1
  %25 = sext i32 %24 to i64
  %26 = add nsw i64 %25, -1
  %27 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv = phi i64 [ %26, %for_begin1.preheader.preheader ], [ %indvars.iv.next, %for_end3 ]
  %indvar = phi i32 [ 0, %for_begin1.preheader.preheader ], [ %indvar.next, %for_end3 ]
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 15
  %30 = mul nuw nsw i32 %29, 1792
  %31 = ashr i32 %28, 4
  %32 = mul nsw i32 %31, 25088
  %33 = add nsw i32 %30, -1920
  %34 = add i32 %33, %32
  switch i32 %29, label %if_end.us.15 [
    i32 15, label %for_begin1.preheader.split
    i32 0, label %for_begin1.preheader.split
  ]

for_begin1.preheader.split:                       ; preds = %for_begin1.preheader, %for_begin1.preheader
  %35 = shl i32 %indvar, 11
  %36 = add i32 %23, %35
  %37 = sext i32 %36 to i64
  %scevgep = getelementptr float, float* %4, i64 %37
  %scevgep5 = bitcast float* %scevgep to i8*
  call void @llvm.memset.p0i8.i64(i8* align 64 %scevgep5, i8 0, i64 8192, i1 false)
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_begin1.preheader.split, %if_end.us.15
  %indvars.iv.next = add nsw i64 %indvars.iv, 1
  %38 = icmp slt i64 %indvars.iv.next, %27
  %indvar.next = add nuw i32 %indvar, 1
  br i1 %38, label %for_begin1.preheader, label %for_end, !prof !5

if_end.us.15:                                     ; preds = %for_begin1.preheader
  %39 = shl i32 %28, 11
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds float, float* %4, i64 %40
  %42 = bitcast float* %41 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %42, align 64, !tbaa !4611
  %43 = or i64 %40, 128
  %44 = add i32 %34, 128
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = bitcast float* %46 to <128 x float>*
  %48 = load <128 x float>, <128 x float>* %47, align 64, !tbaa !4614
  %49 = getelementptr inbounds float, float* %4, i64 %43
  %50 = bitcast float* %49 to <128 x float>*
  store <128 x float> %48, <128 x float>* %50, align 64, !tbaa !4611
  %51 = or i64 %40, 256
  %52 = add i32 %34, 256
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <128 x float>*
  %56 = load <128 x float>, <128 x float>* %55, align 64, !tbaa !4614
  %57 = getelementptr inbounds float, float* %4, i64 %51
  %58 = bitcast float* %57 to <128 x float>*
  store <128 x float> %56, <128 x float>* %58, align 64, !tbaa !4611
  %59 = or i64 %40, 384
  %60 = add i32 %34, 384
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds float, float* %7, i64 %61
  %63 = bitcast float* %62 to <128 x float>*
  %64 = load <128 x float>, <128 x float>* %63, align 64, !tbaa !4614
  %65 = getelementptr inbounds float, float* %4, i64 %59
  %66 = bitcast float* %65 to <128 x float>*
  store <128 x float> %64, <128 x float>* %66, align 64, !tbaa !4611
  %67 = or i64 %40, 512
  %68 = add i32 %34, 512
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to <128 x float>*
  %72 = load <128 x float>, <128 x float>* %71, align 64, !tbaa !4614
  %73 = getelementptr inbounds float, float* %4, i64 %67
  %74 = bitcast float* %73 to <128 x float>*
  store <128 x float> %72, <128 x float>* %74, align 64, !tbaa !4611
  %75 = or i64 %40, 640
  %76 = add i32 %34, 640
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds float, float* %7, i64 %77
  %79 = bitcast float* %78 to <128 x float>*
  %80 = load <128 x float>, <128 x float>* %79, align 64, !tbaa !4614
  %81 = getelementptr inbounds float, float* %4, i64 %75
  %82 = bitcast float* %81 to <128 x float>*
  store <128 x float> %80, <128 x float>* %82, align 64, !tbaa !4611
  %83 = or i64 %40, 768
  %84 = add i32 %34, 768
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds float, float* %7, i64 %85
  %87 = bitcast float* %86 to <128 x float>*
  %88 = load <128 x float>, <128 x float>* %87, align 64, !tbaa !4614
  %89 = getelementptr inbounds float, float* %4, i64 %83
  %90 = bitcast float* %89 to <128 x float>*
  store <128 x float> %88, <128 x float>* %90, align 64, !tbaa !4611
  %91 = or i64 %40, 896
  %92 = add i32 %34, 896
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = bitcast float* %94 to <128 x float>*
  %96 = load <128 x float>, <128 x float>* %95, align 64, !tbaa !4614
  %97 = getelementptr inbounds float, float* %4, i64 %91
  %98 = bitcast float* %97 to <128 x float>*
  store <128 x float> %96, <128 x float>* %98, align 64, !tbaa !4611
  %99 = or i64 %40, 1024
  %100 = add i32 %34, 1024
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = bitcast float* %102 to <128 x float>*
  %104 = load <128 x float>, <128 x float>* %103, align 64, !tbaa !4614
  %105 = getelementptr inbounds float, float* %4, i64 %99
  %106 = bitcast float* %105 to <128 x float>*
  store <128 x float> %104, <128 x float>* %106, align 64, !tbaa !4611
  %107 = or i64 %40, 1152
  %108 = add i32 %34, 1152
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to <128 x float>*
  %112 = load <128 x float>, <128 x float>* %111, align 64, !tbaa !4614
  %113 = getelementptr inbounds float, float* %4, i64 %107
  %114 = bitcast float* %113 to <128 x float>*
  store <128 x float> %112, <128 x float>* %114, align 64, !tbaa !4611
  %115 = or i64 %40, 1280
  %116 = add i32 %34, 1280
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %7, i64 %117
  %119 = bitcast float* %118 to <128 x float>*
  %120 = load <128 x float>, <128 x float>* %119, align 64, !tbaa !4614
  %121 = getelementptr inbounds float, float* %4, i64 %115
  %122 = bitcast float* %121 to <128 x float>*
  store <128 x float> %120, <128 x float>* %122, align 64, !tbaa !4611
  %123 = or i64 %40, 1408
  %124 = add i32 %34, 1408
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds float, float* %7, i64 %125
  %127 = bitcast float* %126 to <128 x float>*
  %128 = load <128 x float>, <128 x float>* %127, align 64, !tbaa !4614
  %129 = getelementptr inbounds float, float* %4, i64 %123
  %130 = bitcast float* %129 to <128 x float>*
  store <128 x float> %128, <128 x float>* %130, align 64, !tbaa !4611
  %131 = or i64 %40, 1536
  %132 = add i32 %34, 1536
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds float, float* %7, i64 %133
  %135 = bitcast float* %134 to <128 x float>*
  %136 = load <128 x float>, <128 x float>* %135, align 64, !tbaa !4614
  %137 = getelementptr inbounds float, float* %4, i64 %131
  %138 = bitcast float* %137 to <128 x float>*
  store <128 x float> %136, <128 x float>* %138, align 64, !tbaa !4611
  %139 = or i64 %40, 1664
  %140 = add i32 %34, 1664
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to <128 x float>*
  %144 = load <128 x float>, <128 x float>* %143, align 64, !tbaa !4614
  %145 = getelementptr inbounds float, float* %4, i64 %139
  %146 = bitcast float* %145 to <128 x float>*
  store <128 x float> %144, <128 x float>* %146, align 64, !tbaa !4611
  %147 = or i64 %40, 1792
  %148 = add i32 %34, 1792
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <128 x float>*
  %152 = load <128 x float>, <128 x float>* %151, align 64, !tbaa !4614
  %153 = getelementptr inbounds float, float* %4, i64 %147
  %154 = bitcast float* %153 to <128 x float>*
  store <128 x float> %152, <128 x float>* %154, align 64, !tbaa !4611
  %155 = or i64 %40, 1920
  %156 = getelementptr inbounds float, float* %4, i64 %155
  %157 = bitcast float* %156 to <128 x float>*
  store <128 x float> zeroinitializer, <128 x float>* %157, align 64, !tbaa !4611
  br label %for_end3
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.353(i32, %0* nocapture readonly, i8* nocapture readonly) #4 {
entry:
  %3 = alloca [14 x <16 x float>], align 64
  %.sub = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0
  %4 = bitcast i8* %2 to float**
  %5 = load float*, float** %4, align 8
  %6 = getelementptr inbounds i8, i8* %2, i64 8
  %7 = bitcast i8* %6 to float**
  %8 = load float*, float** %7, align 8
  %9 = getelementptr inbounds i8, i8* %2, i64 16
  %10 = bitcast i8* %9 to float**
  %11 = load float*, float** %10, align 8
  %12 = getelementptr inbounds i8, i8* %2, i64 24
  %13 = bitcast i8* %12 to float**
  %14 = load float*, float** %13, align 8
  %15 = getelementptr inbounds i8, i8* %2, i64 32
  %16 = bitcast i8* %15 to float**
  %17 = load float*, float** %16, align 8
  %18 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %19 = load i32, i32* %18, align 4
  %20 = add nsw i32 %19, 223
  %21 = sdiv i32 %20, %19
  %22 = add nsw i32 %0, 1
  %23 = mul nsw i32 %21, %22
  %24 = icmp slt i32 %23, 224
  %25 = select i1 %24, i32 %23, i32 224
  %26 = mul nsw i32 %21, %0
  %27 = icmp slt i32 %26, 224
  %28 = select i1 %27, i32 %26, i32 224
  %29 = icmp slt i32 %28, %25
  br i1 %29, label %for_body.lr.ph, label %for_end, !prof !5

for_body.lr.ph:                                   ; preds = %entry
  %30 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 16
  %31 = bitcast float* %30 to <16 x float>*
  %32 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 32
  %33 = bitcast float* %32 to <16 x float>*
  %34 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 48
  %35 = bitcast float* %34 to <16 x float>*
  %36 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 64
  %37 = bitcast float* %36 to <16 x float>*
  %38 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 80
  %39 = bitcast float* %38 to <16 x float>*
  %40 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 96
  %41 = bitcast float* %40 to <16 x float>*
  %42 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 112
  %43 = bitcast float* %42 to <16 x float>*
  %44 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 128
  %45 = bitcast float* %44 to <16 x float>*
  %46 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 144
  %47 = bitcast float* %46 to <16 x float>*
  %48 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 160
  %49 = bitcast float* %48 to <16 x float>*
  %50 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 176
  %51 = bitcast float* %50 to <16 x float>*
  %52 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 192
  %53 = bitcast float* %52 to <16 x float>*
  %54 = getelementptr inbounds [14 x <16 x float>], [14 x <16 x float>]* %3, i64 0, i64 0, i64 208
  %55 = bitcast float* %54 to <16 x float>*
  %56 = add i32 %28, 1
  %57 = sext i32 %56 to i64
  %58 = add nsw i64 %57, -1
  %59 = sext i32 %25 to i64
  %60 = bitcast [14 x <16 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv117 = phi i64 [ %58, %for_body.lr.ph ], [ %indvars.iv.next118, %for_end6.1 ]
  %61 = trunc i64 %indvars.iv117 to i32
  %62 = srem i32 %61, 14
  %63 = sdiv i32 %61, 14
  %64 = mul nsw i32 %63, 36864
  %65 = sext i32 %64 to i64
  call void @llvm.memset.p0i8.i64(i8* nonnull align 64 %60, i8 0, i64 896, i1 false)
  br label %for_begin7.preheader

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_begin7.preheader:                             ; preds = %for_end9, %for_body
  %indvars.iv106 = phi i64 [ 0, %for_body ], [ %indvars.iv.next107, %for_end9 ]
  %.lcssa3966 = phi <16 x float> [ zeroinitializer, %for_body ], [ %219, %for_end9 ]
  %.lcssa3764 = phi <16 x float> [ zeroinitializer, %for_body ], [ %213, %for_end9 ]
  %.lcssa3562 = phi <16 x float> [ zeroinitializer, %for_body ], [ %212, %for_end9 ]
  %.lcssa3360 = phi <16 x float> [ zeroinitializer, %for_body ], [ %211, %for_end9 ]
  %.lcssa3158 = phi <16 x float> [ zeroinitializer, %for_body ], [ %210, %for_end9 ]
  %.lcssa2956 = phi <16 x float> [ zeroinitializer, %for_body ], [ %209, %for_end9 ]
  %.lcssa2754 = phi <16 x float> [ zeroinitializer, %for_body ], [ %208, %for_end9 ]
  %.lcssa2552 = phi <16 x float> [ zeroinitializer, %for_body ], [ %207, %for_end9 ]
  %.lcssa2350 = phi <16 x float> [ zeroinitializer, %for_body ], [ %206, %for_end9 ]
  %.lcssa2148 = phi <16 x float> [ zeroinitializer, %for_body ], [ %205, %for_end9 ]
  %.lcssa1946 = phi <16 x float> [ zeroinitializer, %for_body ], [ %204, %for_end9 ]
  %.lcssa1744 = phi <16 x float> [ zeroinitializer, %for_body ], [ %203, %for_end9 ]
  %.lcssa1543 = phi <16 x float> [ zeroinitializer, %for_body ], [ %202, %for_end9 ]
  %.lcssa41 = phi <16 x float> [ zeroinitializer, %for_body ], [ %201, %for_end9 ]
  %66 = phi i32 [ 0, %for_body ], [ %220, %for_end9 ]
  %reass.add = add nsw i32 %66, %62
  %reass.mul = shl i32 %reass.add, 11
  %67 = mul nuw nsw i64 %indvars.iv106, 6144
  %68 = add nsw i64 %67, %65
  %69 = sext i32 %reass.mul to i64
  br label %for_body8

for_end6:                                         ; preds = %for_end9
  %70 = add nsw i64 %65, 18432
  br label %for_begin7.preheader.1

for_body8:                                        ; preds = %for_body8, %for_begin7.preheader
  %indvars.iv = phi i64 [ 0, %for_begin7.preheader ], [ %indvars.iv.next, %for_body8 ]
  %71 = phi <16 x float> [ %.lcssa3966, %for_begin7.preheader ], [ %219, %for_body8 ]
  %72 = phi <16 x float> [ %.lcssa3764, %for_begin7.preheader ], [ %213, %for_body8 ]
  %73 = phi <16 x float> [ %.lcssa3562, %for_begin7.preheader ], [ %212, %for_body8 ]
  %74 = phi <16 x float> [ %.lcssa3360, %for_begin7.preheader ], [ %211, %for_body8 ]
  %75 = phi <16 x float> [ %.lcssa3158, %for_begin7.preheader ], [ %210, %for_body8 ]
  %76 = phi <16 x float> [ %.lcssa2956, %for_begin7.preheader ], [ %209, %for_body8 ]
  %77 = phi <16 x float> [ %.lcssa2754, %for_begin7.preheader ], [ %208, %for_body8 ]
  %78 = phi <16 x float> [ %.lcssa2552, %for_begin7.preheader ], [ %207, %for_body8 ]
  %79 = phi <16 x float> [ %.lcssa2350, %for_begin7.preheader ], [ %206, %for_body8 ]
  %80 = phi <16 x float> [ %.lcssa2148, %for_begin7.preheader ], [ %205, %for_body8 ]
  %81 = phi <16 x float> [ %.lcssa1946, %for_begin7.preheader ], [ %204, %for_body8 ]
  %82 = phi <16 x float> [ %.lcssa1744, %for_begin7.preheader ], [ %203, %for_body8 ]
  %83 = phi <16 x float> [ %.lcssa1543, %for_begin7.preheader ], [ %202, %for_body8 ]
  %84 = phi <16 x float> [ %.lcssa41, %for_begin7.preheader ], [ %201, %for_body8 ]
  %85 = add nsw i64 %indvars.iv, %69
  %86 = getelementptr inbounds float, float* %5, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !4611
  %88 = insertelement <16 x float> undef, float %87, i32 0
  %89 = shufflevector <16 x float> %88, <16 x float> undef, <16 x i32> zeroinitializer
  %90 = shl nsw i64 %indvars.iv, 4
  %91 = add nsw i64 %68, %90
  %92 = getelementptr inbounds float, float* %8, i64 %91
  %93 = bitcast float* %92 to <16 x float>*
  %94 = load <16 x float>, <16 x float>* %93, align 64, !tbaa !4617
  %95 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %89, <16 x float> %94, <16 x float> %84)
  %96 = add nsw i64 %85, 128
  %97 = getelementptr inbounds float, float* %5, i64 %96
  %98 = load float, float* %97, align 4, !tbaa !4611
  %99 = insertelement <16 x float> undef, float %98, i32 0
  %100 = shufflevector <16 x float> %99, <16 x float> undef, <16 x i32> zeroinitializer
  %101 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %100, <16 x float> %94, <16 x float> %83)
  %102 = add nsw i64 %85, 256
  %103 = getelementptr inbounds float, float* %5, i64 %102
  %104 = load float, float* %103, align 4, !tbaa !4611
  %105 = insertelement <16 x float> undef, float %104, i32 0
  %106 = shufflevector <16 x float> %105, <16 x float> undef, <16 x i32> zeroinitializer
  %107 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %106, <16 x float> %94, <16 x float> %82)
  %108 = add nsw i64 %85, 384
  %109 = getelementptr inbounds float, float* %5, i64 %108
  %110 = load float, float* %109, align 4, !tbaa !4611
  %111 = insertelement <16 x float> undef, float %110, i32 0
  %112 = shufflevector <16 x float> %111, <16 x float> undef, <16 x i32> zeroinitializer
  %113 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %112, <16 x float> %94, <16 x float> %81)
  %114 = add nsw i64 %85, 512
  %115 = getelementptr inbounds float, float* %5, i64 %114
  %116 = load float, float* %115, align 4, !tbaa !4611
  %117 = insertelement <16 x float> undef, float %116, i32 0
  %118 = shufflevector <16 x float> %117, <16 x float> undef, <16 x i32> zeroinitializer
  %119 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %118, <16 x float> %94, <16 x float> %80)
  %120 = add nsw i64 %85, 640
  %121 = getelementptr inbounds float, float* %5, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !4611
  %123 = insertelement <16 x float> undef, float %122, i32 0
  %124 = shufflevector <16 x float> %123, <16 x float> undef, <16 x i32> zeroinitializer
  %125 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %124, <16 x float> %94, <16 x float> %79)
  %126 = add nsw i64 %85, 768
  %127 = getelementptr inbounds float, float* %5, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !4611
  %129 = insertelement <16 x float> undef, float %128, i32 0
  %130 = shufflevector <16 x float> %129, <16 x float> undef, <16 x i32> zeroinitializer
  %131 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %130, <16 x float> %94, <16 x float> %78)
  %132 = add nsw i64 %85, 896
  %133 = getelementptr inbounds float, float* %5, i64 %132
  %134 = load float, float* %133, align 4, !tbaa !4611
  %135 = insertelement <16 x float> undef, float %134, i32 0
  %136 = shufflevector <16 x float> %135, <16 x float> undef, <16 x i32> zeroinitializer
  %137 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %136, <16 x float> %94, <16 x float> %77)
  %138 = add nsw i64 %85, 1024
  %139 = getelementptr inbounds float, float* %5, i64 %138
  %140 = load float, float* %139, align 4, !tbaa !4611
  %141 = insertelement <16 x float> undef, float %140, i32 0
  %142 = shufflevector <16 x float> %141, <16 x float> undef, <16 x i32> zeroinitializer
  %143 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %142, <16 x float> %94, <16 x float> %76)
  %144 = add nsw i64 %85, 1152
  %145 = getelementptr inbounds float, float* %5, i64 %144
  %146 = load float, float* %145, align 4, !tbaa !4611
  %147 = insertelement <16 x float> undef, float %146, i32 0
  %148 = shufflevector <16 x float> %147, <16 x float> undef, <16 x i32> zeroinitializer
  %149 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %148, <16 x float> %94, <16 x float> %75)
  %150 = add nsw i64 %85, 1280
  %151 = getelementptr inbounds float, float* %5, i64 %150
  %152 = load float, float* %151, align 4, !tbaa !4611
  %153 = insertelement <16 x float> undef, float %152, i32 0
  %154 = shufflevector <16 x float> %153, <16 x float> undef, <16 x i32> zeroinitializer
  %155 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %154, <16 x float> %94, <16 x float> %74)
  %156 = add nsw i64 %85, 1408
  %157 = getelementptr inbounds float, float* %5, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !4611
  %159 = insertelement <16 x float> undef, float %158, i32 0
  %160 = shufflevector <16 x float> %159, <16 x float> undef, <16 x i32> zeroinitializer
  %161 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %160, <16 x float> %94, <16 x float> %73)
  %162 = add nsw i64 %85, 1536
  %163 = getelementptr inbounds float, float* %5, i64 %162
  %164 = load float, float* %163, align 4, !tbaa !4611
  %165 = insertelement <16 x float> undef, float %164, i32 0
  %166 = shufflevector <16 x float> %165, <16 x float> undef, <16 x i32> zeroinitializer
  %167 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %166, <16 x float> %94, <16 x float> %72)
  %168 = add nsw i64 %85, 1664
  %169 = getelementptr inbounds float, float* %5, i64 %168
  %170 = load float, float* %169, align 4, !tbaa !4611
  %171 = insertelement <16 x float> undef, float %170, i32 0
  %172 = shufflevector <16 x float> %171, <16 x float> undef, <16 x i32> zeroinitializer
  %173 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %172, <16 x float> %94, <16 x float> %71)
  %174 = add nsw i64 %91, 2048
  %175 = getelementptr inbounds float, float* %8, i64 %174
  %176 = bitcast float* %175 to <16 x float>*
  %177 = load <16 x float>, <16 x float>* %176, align 64, !tbaa !4617
  %178 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %100, <16 x float> %177, <16 x float> %95)
  %179 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %106, <16 x float> %177, <16 x float> %101)
  %180 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %112, <16 x float> %177, <16 x float> %107)
  %181 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %118, <16 x float> %177, <16 x float> %113)
  %182 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %124, <16 x float> %177, <16 x float> %119)
  %183 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %130, <16 x float> %177, <16 x float> %125)
  %184 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %136, <16 x float> %177, <16 x float> %131)
  %185 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %142, <16 x float> %177, <16 x float> %137)
  %186 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %148, <16 x float> %177, <16 x float> %143)
  %187 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %154, <16 x float> %177, <16 x float> %149)
  %188 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %160, <16 x float> %177, <16 x float> %155)
  %189 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %166, <16 x float> %177, <16 x float> %161)
  %190 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %172, <16 x float> %177, <16 x float> %167)
  %191 = add nsw i64 %85, 1792
  %192 = getelementptr inbounds float, float* %5, i64 %191
  %193 = load float, float* %192, align 4, !tbaa !4611
  %194 = insertelement <16 x float> undef, float %193, i32 0
  %195 = shufflevector <16 x float> %194, <16 x float> undef, <16 x i32> zeroinitializer
  %196 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %195, <16 x float> %177, <16 x float> %173)
  %197 = add nsw i64 %91, 4096
  %198 = getelementptr inbounds float, float* %8, i64 %197
  %199 = bitcast float* %198 to <16 x float>*
  %200 = load <16 x float>, <16 x float>* %199, align 64, !tbaa !4617
  %201 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %106, <16 x float> %200, <16 x float> %178)
  %202 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %112, <16 x float> %200, <16 x float> %179)
  %203 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %118, <16 x float> %200, <16 x float> %180)
  %204 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %124, <16 x float> %200, <16 x float> %181)
  %205 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %130, <16 x float> %200, <16 x float> %182)
  %206 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %136, <16 x float> %200, <16 x float> %183)
  %207 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %142, <16 x float> %200, <16 x float> %184)
  %208 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %148, <16 x float> %200, <16 x float> %185)
  %209 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %154, <16 x float> %200, <16 x float> %186)
  %210 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %160, <16 x float> %200, <16 x float> %187)
  %211 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %166, <16 x float> %200, <16 x float> %188)
  %212 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %172, <16 x float> %200, <16 x float> %189)
  %213 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %195, <16 x float> %200, <16 x float> %190)
  %214 = add nsw i64 %85, 1920
  %215 = getelementptr inbounds float, float* %5, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !4611
  %217 = insertelement <16 x float> undef, float %216, i32 0
  %218 = shufflevector <16 x float> %217, <16 x float> undef, <16 x i32> zeroinitializer
  %219 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %218, <16 x float> %200, <16 x float> %196)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !50

for_end9:                                         ; preds = %for_body8
  %indvars.iv.next107 = add nuw nsw i64 %indvars.iv106, 1
  %220 = add nuw nsw i32 %66, 1
  %exitcond110 = icmp eq i64 %indvars.iv.next107, 3
  br i1 %exitcond110, label %for_end6, label %for_begin7.preheader, !prof !50

for_begin7.preheader.1:                           ; preds = %for_end9.1, %for_end6
  %indvars.iv106.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next107.1, %for_end9.1 ]
  %.lcssa3966.1 = phi <16 x float> [ %219, %for_end6 ], [ %374, %for_end9.1 ]
  %.lcssa3764.1 = phi <16 x float> [ %213, %for_end6 ], [ %368, %for_end9.1 ]
  %.lcssa3562.1 = phi <16 x float> [ %212, %for_end6 ], [ %367, %for_end9.1 ]
  %.lcssa3360.1 = phi <16 x float> [ %211, %for_end6 ], [ %366, %for_end9.1 ]
  %.lcssa3158.1 = phi <16 x float> [ %210, %for_end6 ], [ %365, %for_end9.1 ]
  %.lcssa2956.1 = phi <16 x float> [ %209, %for_end6 ], [ %364, %for_end9.1 ]
  %.lcssa2754.1 = phi <16 x float> [ %208, %for_end6 ], [ %363, %for_end9.1 ]
  %.lcssa2552.1 = phi <16 x float> [ %207, %for_end6 ], [ %362, %for_end9.1 ]
  %.lcssa2350.1 = phi <16 x float> [ %206, %for_end6 ], [ %361, %for_end9.1 ]
  %.lcssa2148.1 = phi <16 x float> [ %205, %for_end6 ], [ %360, %for_end9.1 ]
  %.lcssa1946.1 = phi <16 x float> [ %204, %for_end6 ], [ %359, %for_end9.1 ]
  %.lcssa1744.1 = phi <16 x float> [ %203, %for_end6 ], [ %358, %for_end9.1 ]
  %.lcssa1543.1 = phi <16 x float> [ %202, %for_end6 ], [ %357, %for_end9.1 ]
  %.lcssa41.1 = phi <16 x float> [ %201, %for_end6 ], [ %356, %for_end9.1 ]
  %221 = phi i32 [ 0, %for_end6 ], [ %375, %for_end9.1 ]
  %reass.add.1 = add nsw i32 %221, %62
  %reass.mul.1 = shl i32 %reass.add.1, 11
  %222 = add nsw i32 %reass.mul.1, 32768
  %223 = mul nuw nsw i64 %indvars.iv106.1, 6144
  %224 = add nsw i64 %70, %223
  %225 = sext i32 %222 to i64
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_begin7.preheader.1
  %indvars.iv.1 = phi i64 [ 0, %for_begin7.preheader.1 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %226 = phi <16 x float> [ %.lcssa3966.1, %for_begin7.preheader.1 ], [ %374, %for_body8.1 ]
  %227 = phi <16 x float> [ %.lcssa3764.1, %for_begin7.preheader.1 ], [ %368, %for_body8.1 ]
  %228 = phi <16 x float> [ %.lcssa3562.1, %for_begin7.preheader.1 ], [ %367, %for_body8.1 ]
  %229 = phi <16 x float> [ %.lcssa3360.1, %for_begin7.preheader.1 ], [ %366, %for_body8.1 ]
  %230 = phi <16 x float> [ %.lcssa3158.1, %for_begin7.preheader.1 ], [ %365, %for_body8.1 ]
  %231 = phi <16 x float> [ %.lcssa2956.1, %for_begin7.preheader.1 ], [ %364, %for_body8.1 ]
  %232 = phi <16 x float> [ %.lcssa2754.1, %for_begin7.preheader.1 ], [ %363, %for_body8.1 ]
  %233 = phi <16 x float> [ %.lcssa2552.1, %for_begin7.preheader.1 ], [ %362, %for_body8.1 ]
  %234 = phi <16 x float> [ %.lcssa2350.1, %for_begin7.preheader.1 ], [ %361, %for_body8.1 ]
  %235 = phi <16 x float> [ %.lcssa2148.1, %for_begin7.preheader.1 ], [ %360, %for_body8.1 ]
  %236 = phi <16 x float> [ %.lcssa1946.1, %for_begin7.preheader.1 ], [ %359, %for_body8.1 ]
  %237 = phi <16 x float> [ %.lcssa1744.1, %for_begin7.preheader.1 ], [ %358, %for_body8.1 ]
  %238 = phi <16 x float> [ %.lcssa1543.1, %for_begin7.preheader.1 ], [ %357, %for_body8.1 ]
  %239 = phi <16 x float> [ %.lcssa41.1, %for_begin7.preheader.1 ], [ %356, %for_body8.1 ]
  %240 = add nsw i64 %indvars.iv.1, %225
  %241 = getelementptr inbounds float, float* %5, i64 %240
  %242 = load float, float* %241, align 4, !tbaa !4611
  %243 = insertelement <16 x float> undef, float %242, i32 0
  %244 = shufflevector <16 x float> %243, <16 x float> undef, <16 x i32> zeroinitializer
  %245 = shl nsw i64 %indvars.iv.1, 4
  %246 = add nsw i64 %224, %245
  %247 = getelementptr inbounds float, float* %8, i64 %246
  %248 = bitcast float* %247 to <16 x float>*
  %249 = load <16 x float>, <16 x float>* %248, align 64, !tbaa !4617
  %250 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %244, <16 x float> %249, <16 x float> %239)
  %251 = add nsw i64 %240, 128
  %252 = getelementptr inbounds float, float* %5, i64 %251
  %253 = load float, float* %252, align 4, !tbaa !4611
  %254 = insertelement <16 x float> undef, float %253, i32 0
  %255 = shufflevector <16 x float> %254, <16 x float> undef, <16 x i32> zeroinitializer
  %256 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %255, <16 x float> %249, <16 x float> %238)
  %257 = add nsw i64 %240, 256
  %258 = getelementptr inbounds float, float* %5, i64 %257
  %259 = load float, float* %258, align 4, !tbaa !4611
  %260 = insertelement <16 x float> undef, float %259, i32 0
  %261 = shufflevector <16 x float> %260, <16 x float> undef, <16 x i32> zeroinitializer
  %262 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %261, <16 x float> %249, <16 x float> %237)
  %263 = add nsw i64 %240, 384
  %264 = getelementptr inbounds float, float* %5, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !4611
  %266 = insertelement <16 x float> undef, float %265, i32 0
  %267 = shufflevector <16 x float> %266, <16 x float> undef, <16 x i32> zeroinitializer
  %268 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %267, <16 x float> %249, <16 x float> %236)
  %269 = add nsw i64 %240, 512
  %270 = getelementptr inbounds float, float* %5, i64 %269
  %271 = load float, float* %270, align 4, !tbaa !4611
  %272 = insertelement <16 x float> undef, float %271, i32 0
  %273 = shufflevector <16 x float> %272, <16 x float> undef, <16 x i32> zeroinitializer
  %274 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %273, <16 x float> %249, <16 x float> %235)
  %275 = add nsw i64 %240, 640
  %276 = getelementptr inbounds float, float* %5, i64 %275
  %277 = load float, float* %276, align 4, !tbaa !4611
  %278 = insertelement <16 x float> undef, float %277, i32 0
  %279 = shufflevector <16 x float> %278, <16 x float> undef, <16 x i32> zeroinitializer
  %280 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %279, <16 x float> %249, <16 x float> %234)
  %281 = add nsw i64 %240, 768
  %282 = getelementptr inbounds float, float* %5, i64 %281
  %283 = load float, float* %282, align 4, !tbaa !4611
  %284 = insertelement <16 x float> undef, float %283, i32 0
  %285 = shufflevector <16 x float> %284, <16 x float> undef, <16 x i32> zeroinitializer
  %286 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %285, <16 x float> %249, <16 x float> %233)
  %287 = add nsw i64 %240, 896
  %288 = getelementptr inbounds float, float* %5, i64 %287
  %289 = load float, float* %288, align 4, !tbaa !4611
  %290 = insertelement <16 x float> undef, float %289, i32 0
  %291 = shufflevector <16 x float> %290, <16 x float> undef, <16 x i32> zeroinitializer
  %292 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %291, <16 x float> %249, <16 x float> %232)
  %293 = add nsw i64 %240, 1024
  %294 = getelementptr inbounds float, float* %5, i64 %293
  %295 = load float, float* %294, align 4, !tbaa !4611
  %296 = insertelement <16 x float> undef, float %295, i32 0
  %297 = shufflevector <16 x float> %296, <16 x float> undef, <16 x i32> zeroinitializer
  %298 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %297, <16 x float> %249, <16 x float> %231)
  %299 = add nsw i64 %240, 1152
  %300 = getelementptr inbounds float, float* %5, i64 %299
  %301 = load float, float* %300, align 4, !tbaa !4611
  %302 = insertelement <16 x float> undef, float %301, i32 0
  %303 = shufflevector <16 x float> %302, <16 x float> undef, <16 x i32> zeroinitializer
  %304 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %303, <16 x float> %249, <16 x float> %230)
  %305 = add nsw i64 %240, 1280
  %306 = getelementptr inbounds float, float* %5, i64 %305
  %307 = load float, float* %306, align 4, !tbaa !4611
  %308 = insertelement <16 x float> undef, float %307, i32 0
  %309 = shufflevector <16 x float> %308, <16 x float> undef, <16 x i32> zeroinitializer
  %310 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %309, <16 x float> %249, <16 x float> %229)
  %311 = add nsw i64 %240, 1408
  %312 = getelementptr inbounds float, float* %5, i64 %311
  %313 = load float, float* %312, align 4, !tbaa !4611
  %314 = insertelement <16 x float> undef, float %313, i32 0
  %315 = shufflevector <16 x float> %314, <16 x float> undef, <16 x i32> zeroinitializer
  %316 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %315, <16 x float> %249, <16 x float> %228)
  %317 = add nsw i64 %240, 1536
  %318 = getelementptr inbounds float, float* %5, i64 %317
  %319 = load float, float* %318, align 4, !tbaa !4611
  %320 = insertelement <16 x float> undef, float %319, i32 0
  %321 = shufflevector <16 x float> %320, <16 x float> undef, <16 x i32> zeroinitializer
  %322 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %321, <16 x float> %249, <16 x float> %227)
  %323 = add nsw i64 %240, 1664
  %324 = getelementptr inbounds float, float* %5, i64 %323
  %325 = load float, float* %324, align 4, !tbaa !4611
  %326 = insertelement <16 x float> undef, float %325, i32 0
  %327 = shufflevector <16 x float> %326, <16 x float> undef, <16 x i32> zeroinitializer
  %328 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %327, <16 x float> %249, <16 x float> %226)
  %329 = add nsw i64 %246, 2048
  %330 = getelementptr inbounds float, float* %8, i64 %329
  %331 = bitcast float* %330 to <16 x float>*
  %332 = load <16 x float>, <16 x float>* %331, align 64, !tbaa !4617
  %333 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %255, <16 x float> %332, <16 x float> %250)
  %334 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %261, <16 x float> %332, <16 x float> %256)
  %335 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %267, <16 x float> %332, <16 x float> %262)
  %336 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %273, <16 x float> %332, <16 x float> %268)
  %337 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %279, <16 x float> %332, <16 x float> %274)
  %338 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %285, <16 x float> %332, <16 x float> %280)
  %339 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %291, <16 x float> %332, <16 x float> %286)
  %340 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %297, <16 x float> %332, <16 x float> %292)
  %341 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %303, <16 x float> %332, <16 x float> %298)
  %342 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %309, <16 x float> %332, <16 x float> %304)
  %343 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %315, <16 x float> %332, <16 x float> %310)
  %344 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %321, <16 x float> %332, <16 x float> %316)
  %345 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %327, <16 x float> %332, <16 x float> %322)
  %346 = add nsw i64 %240, 1792
  %347 = getelementptr inbounds float, float* %5, i64 %346
  %348 = load float, float* %347, align 4, !tbaa !4611
  %349 = insertelement <16 x float> undef, float %348, i32 0
  %350 = shufflevector <16 x float> %349, <16 x float> undef, <16 x i32> zeroinitializer
  %351 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %350, <16 x float> %332, <16 x float> %328)
  %352 = add nsw i64 %246, 4096
  %353 = getelementptr inbounds float, float* %8, i64 %352
  %354 = bitcast float* %353 to <16 x float>*
  %355 = load <16 x float>, <16 x float>* %354, align 64, !tbaa !4617
  %356 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %261, <16 x float> %355, <16 x float> %333)
  %357 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %267, <16 x float> %355, <16 x float> %334)
  %358 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %273, <16 x float> %355, <16 x float> %335)
  %359 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %279, <16 x float> %355, <16 x float> %336)
  %360 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %285, <16 x float> %355, <16 x float> %337)
  %361 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %291, <16 x float> %355, <16 x float> %338)
  %362 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %297, <16 x float> %355, <16 x float> %339)
  %363 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %303, <16 x float> %355, <16 x float> %340)
  %364 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %309, <16 x float> %355, <16 x float> %341)
  %365 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %315, <16 x float> %355, <16 x float> %342)
  %366 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %321, <16 x float> %355, <16 x float> %343)
  %367 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %327, <16 x float> %355, <16 x float> %344)
  %368 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %350, <16 x float> %355, <16 x float> %345)
  %369 = add nsw i64 %240, 1920
  %370 = getelementptr inbounds float, float* %5, i64 %369
  %371 = load float, float* %370, align 4, !tbaa !4611
  %372 = insertelement <16 x float> undef, float %371, i32 0
  %373 = shufflevector <16 x float> %372, <16 x float> undef, <16 x i32> zeroinitializer
  %374 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %373, <16 x float> %355, <16 x float> %351)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !50

for_end9.1:                                       ; preds = %for_body8.1
  %indvars.iv.next107.1 = add nuw nsw i64 %indvars.iv106.1, 1
  %375 = add nuw nsw i32 %221, 1
  %exitcond110.1 = icmp eq i64 %indvars.iv.next107.1, 3
  br i1 %exitcond110.1, label %for_end6.1, label %for_begin7.preheader.1, !prof !50

for_end6.1:                                       ; preds = %for_end9.1
  store <16 x float> %356, <16 x float>* %.sub, align 64, !tbaa !4620
  store <16 x float> %357, <16 x float>* %31, align 64, !tbaa !4620
  store <16 x float> %358, <16 x float>* %33, align 64, !tbaa !4620
  store <16 x float> %359, <16 x float>* %35, align 64, !tbaa !4620
  store <16 x float> %360, <16 x float>* %37, align 64, !tbaa !4620
  store <16 x float> %361, <16 x float>* %39, align 64, !tbaa !4620
  store <16 x float> %362, <16 x float>* %41, align 64, !tbaa !4620
  store <16 x float> %363, <16 x float>* %43, align 64, !tbaa !4620
  store <16 x float> %364, <16 x float>* %45, align 64, !tbaa !4620
  store <16 x float> %365, <16 x float>* %47, align 64, !tbaa !4620
  store <16 x float> %366, <16 x float>* %49, align 64, !tbaa !4620
  store <16 x float> %367, <16 x float>* %51, align 64, !tbaa !4620
  store <16 x float> %368, <16 x float>* %53, align 64, !tbaa !4620
  store <16 x float> %374, <16 x float>* %55, align 64, !tbaa !4620
  %376 = mul nsw i64 %indvars.iv117, 224
  %377 = shl nsw i32 %63, 4
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds float, float* %14, i64 %378
  %380 = bitcast float* %379 to <16 x float>*
  %381 = load <16 x float>, <16 x float>* %380, align 64, !tbaa !4630
  %382 = getelementptr inbounds float, float* %17, i64 %376
  %383 = bitcast float* %382 to <16 x float>*
  %384 = load <16 x float>, <16 x float>* %383, align 64, !tbaa !4633
  %385 = fadd <16 x float> %381, %356
  %386 = fadd <16 x float> %384, %385
  %387 = fcmp ogt <16 x float> %386, zeroinitializer
  %388 = select <16 x i1> %387, <16 x float> %386, <16 x float> zeroinitializer
  %389 = getelementptr inbounds float, float* %11, i64 %376
  %390 = bitcast float* %389 to <16 x float>*
  store <16 x float> %388, <16 x float>* %390, align 64, !tbaa !4636
  %391 = or i64 %376, 16
  %392 = getelementptr inbounds float, float* %17, i64 %391
  %393 = bitcast float* %392 to <16 x float>*
  %394 = load <16 x float>, <16 x float>* %393, align 64, !tbaa !4633
  %395 = fadd <16 x float> %381, %357
  %396 = fadd <16 x float> %394, %395
  %397 = fcmp ogt <16 x float> %396, zeroinitializer
  %398 = select <16 x i1> %397, <16 x float> %396, <16 x float> zeroinitializer
  %399 = getelementptr inbounds float, float* %11, i64 %391
  %400 = bitcast float* %399 to <16 x float>*
  store <16 x float> %398, <16 x float>* %400, align 64, !tbaa !4636
  %401 = add nsw i64 %376, 32
  %402 = getelementptr inbounds float, float* %17, i64 %401
  %403 = bitcast float* %402 to <16 x float>*
  %404 = load <16 x float>, <16 x float>* %403, align 64, !tbaa !4633
  %405 = fadd <16 x float> %381, %358
  %406 = fadd <16 x float> %404, %405
  %407 = fcmp ogt <16 x float> %406, zeroinitializer
  %408 = select <16 x i1> %407, <16 x float> %406, <16 x float> zeroinitializer
  %409 = getelementptr inbounds float, float* %11, i64 %401
  %410 = bitcast float* %409 to <16 x float>*
  store <16 x float> %408, <16 x float>* %410, align 64, !tbaa !4636
  %411 = add nsw i64 %376, 48
  %412 = getelementptr inbounds float, float* %17, i64 %411
  %413 = bitcast float* %412 to <16 x float>*
  %414 = load <16 x float>, <16 x float>* %413, align 64, !tbaa !4633
  %415 = fadd <16 x float> %381, %359
  %416 = fadd <16 x float> %414, %415
  %417 = fcmp ogt <16 x float> %416, zeroinitializer
  %418 = select <16 x i1> %417, <16 x float> %416, <16 x float> zeroinitializer
  %419 = getelementptr inbounds float, float* %11, i64 %411
  %420 = bitcast float* %419 to <16 x float>*
  store <16 x float> %418, <16 x float>* %420, align 64, !tbaa !4636
  %421 = add nsw i64 %376, 64
  %422 = getelementptr inbounds float, float* %17, i64 %421
  %423 = bitcast float* %422 to <16 x float>*
  %424 = load <16 x float>, <16 x float>* %423, align 64, !tbaa !4633
  %425 = fadd <16 x float> %381, %360
  %426 = fadd <16 x float> %424, %425
  %427 = fcmp ogt <16 x float> %426, zeroinitializer
  %428 = select <16 x i1> %427, <16 x float> %426, <16 x float> zeroinitializer
  %429 = getelementptr inbounds float, float* %11, i64 %421
  %430 = bitcast float* %429 to <16 x float>*
  store <16 x float> %428, <16 x float>* %430, align 64, !tbaa !4636
  %431 = add nsw i64 %376, 80
  %432 = getelementptr inbounds float, float* %17, i64 %431
  %433 = bitcast float* %432 to <16 x float>*
  %434 = load <16 x float>, <16 x float>* %433, align 64, !tbaa !4633
  %435 = fadd <16 x float> %381, %361
  %436 = fadd <16 x float> %434, %435
  %437 = fcmp ogt <16 x float> %436, zeroinitializer
  %438 = select <16 x i1> %437, <16 x float> %436, <16 x float> zeroinitializer
  %439 = getelementptr inbounds float, float* %11, i64 %431
  %440 = bitcast float* %439 to <16 x float>*
  store <16 x float> %438, <16 x float>* %440, align 64, !tbaa !4636
  %441 = add nsw i64 %376, 96
  %442 = getelementptr inbounds float, float* %17, i64 %441
  %443 = bitcast float* %442 to <16 x float>*
  %444 = load <16 x float>, <16 x float>* %443, align 64, !tbaa !4633
  %445 = fadd <16 x float> %381, %362
  %446 = fadd <16 x float> %444, %445
  %447 = fcmp ogt <16 x float> %446, zeroinitializer
  %448 = select <16 x i1> %447, <16 x float> %446, <16 x float> zeroinitializer
  %449 = getelementptr inbounds float, float* %11, i64 %441
  %450 = bitcast float* %449 to <16 x float>*
  store <16 x float> %448, <16 x float>* %450, align 64, !tbaa !4636
  %451 = add nsw i64 %376, 112
  %452 = getelementptr inbounds float, float* %17, i64 %451
  %453 = bitcast float* %452 to <16 x float>*
  %454 = load <16 x float>, <16 x float>* %453, align 64, !tbaa !4633
  %455 = fadd <16 x float> %381, %363
  %456 = fadd <16 x float> %454, %455
  %457 = fcmp ogt <16 x float> %456, zeroinitializer
  %458 = select <16 x i1> %457, <16 x float> %456, <16 x float> zeroinitializer
  %459 = getelementptr inbounds float, float* %11, i64 %451
  %460 = bitcast float* %459 to <16 x float>*
  store <16 x float> %458, <16 x float>* %460, align 64, !tbaa !4636
  %461 = add nsw i64 %376, 128
  %462 = getelementptr inbounds float, float* %17, i64 %461
  %463 = bitcast float* %462 to <16 x float>*
  %464 = load <16 x float>, <16 x float>* %463, align 64, !tbaa !4633
  %465 = load <16 x float>, <16 x float>* %45, align 64, !tbaa !4639
  %466 = fadd <16 x float> %381, %465
  %467 = fadd <16 x float> %464, %466
  %468 = fcmp ogt <16 x float> %467, zeroinitializer
  %469 = select <16 x i1> %468, <16 x float> %467, <16 x float> zeroinitializer
  %470 = getelementptr inbounds float, float* %11, i64 %461
  %471 = bitcast float* %470 to <16 x float>*
  store <16 x float> %469, <16 x float>* %471, align 64, !tbaa !4636
  %472 = add nsw i64 %376, 144
  %473 = getelementptr inbounds float, float* %17, i64 %472
  %474 = bitcast float* %473 to <16 x float>*
  %475 = load <16 x float>, <16 x float>* %474, align 64, !tbaa !4633
  %476 = load <16 x float>, <16 x float>* %47, align 64, !tbaa !4639
  %477 = fadd <16 x float> %381, %476
  %478 = fadd <16 x float> %475, %477
  %479 = fcmp ogt <16 x float> %478, zeroinitializer
  %480 = select <16 x i1> %479, <16 x float> %478, <16 x float> zeroinitializer
  %481 = getelementptr inbounds float, float* %11, i64 %472
  %482 = bitcast float* %481 to <16 x float>*
  store <16 x float> %480, <16 x float>* %482, align 64, !tbaa !4636
  %483 = add nsw i64 %376, 160
  %484 = getelementptr inbounds float, float* %17, i64 %483
  %485 = bitcast float* %484 to <16 x float>*
  %486 = load <16 x float>, <16 x float>* %485, align 64, !tbaa !4633
  %487 = load <16 x float>, <16 x float>* %49, align 64, !tbaa !4639
  %488 = fadd <16 x float> %381, %487
  %489 = fadd <16 x float> %486, %488
  %490 = fcmp ogt <16 x float> %489, zeroinitializer
  %491 = select <16 x i1> %490, <16 x float> %489, <16 x float> zeroinitializer
  %492 = getelementptr inbounds float, float* %11, i64 %483
  %493 = bitcast float* %492 to <16 x float>*
  store <16 x float> %491, <16 x float>* %493, align 64, !tbaa !4636
  %494 = add nsw i64 %376, 176
  %495 = getelementptr inbounds float, float* %17, i64 %494
  %496 = bitcast float* %495 to <16 x float>*
  %497 = load <16 x float>, <16 x float>* %496, align 64, !tbaa !4633
  %498 = load <16 x float>, <16 x float>* %51, align 64, !tbaa !4639
  %499 = fadd <16 x float> %381, %498
  %500 = fadd <16 x float> %497, %499
  %501 = fcmp ogt <16 x float> %500, zeroinitializer
  %502 = select <16 x i1> %501, <16 x float> %500, <16 x float> zeroinitializer
  %503 = getelementptr inbounds float, float* %11, i64 %494
  %504 = bitcast float* %503 to <16 x float>*
  store <16 x float> %502, <16 x float>* %504, align 64, !tbaa !4636
  %505 = add nsw i64 %376, 192
  %506 = getelementptr inbounds float, float* %17, i64 %505
  %507 = bitcast float* %506 to <16 x float>*
  %508 = load <16 x float>, <16 x float>* %507, align 64, !tbaa !4633
  %509 = load <16 x float>, <16 x float>* %53, align 64, !tbaa !4639
  %510 = fadd <16 x float> %381, %509
  %511 = fadd <16 x float> %508, %510
  %512 = fcmp ogt <16 x float> %511, zeroinitializer
  %513 = select <16 x i1> %512, <16 x float> %511, <16 x float> zeroinitializer
  %514 = getelementptr inbounds float, float* %11, i64 %505
  %515 = bitcast float* %514 to <16 x float>*
  store <16 x float> %513, <16 x float>* %515, align 64, !tbaa !4636
  %516 = add nsw i64 %376, 208
  %517 = getelementptr inbounds float, float* %17, i64 %516
  %518 = bitcast float* %517 to <16 x float>*
  %519 = load <16 x float>, <16 x float>* %518, align 64, !tbaa !4633
  %520 = load <16 x float>, <16 x float>* %55, align 64, !tbaa !4639
  %521 = fadd <16 x float> %381, %520
  %522 = fadd <16 x float> %519, %521
  %523 = fcmp ogt <16 x float> %522, zeroinitializer
  %524 = select <16 x i1> %523, <16 x float> %522, <16 x float> zeroinitializer
  %525 = getelementptr inbounds float, float* %11, i64 %516
  %526 = bitcast float* %525 to <16 x float>*
  store <16 x float> %524, <16 x float>* %526, align 64, !tbaa !4636
  %indvars.iv.next118 = add nsw i64 %indvars.iv117, 1
  %527 = icmp slt i64 %indvars.iv.next118, %59
  br i1 %527, label %for_body, label %for_end, !prof !5
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 4
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([86 x i8], [86 x i8]* @.str.354, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !4640
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  %15 = bitcast i8* %14 to %1**
  %16 = load %1*, %1** %15, align 8
  %17 = getelementptr inbounds i8, i8* %1, i64 8
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4, !tbaa !4654
  %20 = getelementptr inbounds i8, i8* %0, i64 24
  %21 = bitcast i8* %20 to %1**
  %22 = load %1*, %1** %21, align 8
  %23 = getelementptr inbounds i8, i8* %1, i64 12
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4, !tbaa !4657
  %26 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %27 = load i8*, i8** %26, align 8
  %28 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %29 = load i64*, i64** %28, align 8
  %30 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %31 = load i64*, i64** %30, align 8
  %32 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %39 = load i64*, i64** %38, align 8
  %40 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %41 = load i64*, i64** %40, align 8
  %42 = getelementptr inbounds %1, %1* %16, i64 0, i32 0
  %43 = load i8*, i8** %42, align 8
  %44 = getelementptr inbounds %1, %1* %16, i64 0, i32 4
  %45 = load i64*, i64** %44, align 8
  %46 = getelementptr inbounds %1, %1* %16, i64 0, i32 5
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %1, %1* %22, i64 0, i32 0
  %49 = load i8*, i8** %48, align 8
  %50 = getelementptr inbounds %1, %1* %22, i64 0, i32 4
  %51 = load i64*, i64** %50, align 8
  %52 = getelementptr inbounds %1, %1* %22, i64 0, i32 5
  %53 = load i64*, i64** %52, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %54 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %54(i8* getelementptr inbounds ([161 x i8], [161 x i8]* @.str.355, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %55 = getelementptr inbounds i8, i8* %1, i64 4
  %56 = bitcast i8* %55 to i32*
  %57 = load i32, i32* %56, align 4, !tbaa !4659
  switch i32 %57, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %58 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %58(i8* getelementptr inbounds ([161 x i8], [161 x i8]* @.str.356, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  switch i32 %19, label %assert_fail5 [
    i32 13, label %assert_end6
    i32 7, label %assert_end6
    i32 4, label %assert_end6
    i32 3, label %assert_end6
  ]

assert_fail5:                                     ; preds = %assert_end4
  %59 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %59(i8* getelementptr inbounds ([161 x i8], [161 x i8]* @.str.357, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4, %assert_end4, %assert_end4, %assert_end4
  switch i32 %25, label %assert_fail7 [
    i32 13, label %assert_end8
    i32 7, label %assert_end8
    i32 4, label %assert_end8
    i32 3, label %assert_end8
  ]

assert_fail7:                                     ; preds = %assert_end6
  %60 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %60(i8* getelementptr inbounds ([161 x i8], [161 x i8]* @.str.358, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6, %assert_end6, %assert_end6, %assert_end6
  %61 = icmp eq i32 %33, 1
  br i1 %61, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %62 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %62(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %63 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = icmp eq i32 %64, 5
  br i1 %65, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %67 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %68 = load i16, i16* %67, align 2
  %69 = icmp eq i16 %68, 1
  %70 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %71 = load i8, i8* %70, align 1
  %72 = icmp eq i8 %71, 32
  %73 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %74 = load i8, i8* %73, align 1
  %75 = icmp eq i8 %74, 2
  %76 = and i1 %72, %75
  %77 = and i1 %69, %76
  br i1 %77, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %78 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %78(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %79 = load i64, i64* %29, align 8, !tbaa !4661
  %80 = trunc i64 %79 to i32
  %81 = icmp eq i32 %80, 1
  br i1 %81, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %82 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %82(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %83 = getelementptr inbounds i64, i64* %29, i64 1
  %84 = load i64, i64* %83, align 8, !tbaa !4675
  %85 = trunc i64 %84 to i32
  %86 = icmp eq i32 %85, 8
  br i1 %86, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %87 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %87(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.7, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %88 = getelementptr inbounds i64, i64* %29, i64 2
  %89 = load i64, i64* %88, align 8, !tbaa !4677
  %90 = trunc i64 %89 to i32
  %91 = icmp eq i32 %90, 56
  br i1 %91, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.188, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %93 = getelementptr inbounds i64, i64* %29, i64 3
  %94 = load i64, i64* %93, align 8, !tbaa !4680
  %95 = trunc i64 %94 to i32
  %96 = icmp eq i32 %95, 56
  br i1 %96, label %assert_end22, label %assert_fail21, !prof !5

assert_fail21:                                    ; preds = %assert_end20
  %97 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %97(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.189, i64 0, i64 0))
  ret i32 -1

assert_end22:                                     ; preds = %assert_end20
  %98 = getelementptr inbounds i64, i64* %29, i64 4
  %99 = load i64, i64* %98, align 8, !tbaa !4682
  %100 = trunc i64 %99 to i32
  %101 = icmp eq i32 %100, 8
  br i1 %101, label %assert_end24, label %assert_fail23, !prof !5

assert_fail23:                                    ; preds = %assert_end22
  %102 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %102(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.156, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %assert_end22
  %103 = icmp eq i64* %31, null
  br i1 %103, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end24
  %104 = bitcast i64* %31 to <4 x i64>*
  %105 = load <4 x i64>, <4 x i64>* %104, align 8, !tbaa !4686
  %106 = trunc <4 x i64> %105 to <4 x i32>
  %107 = icmp eq <4 x i32> %106, <i32 200704, i32 25088, i32 448, i32 8>
  %108 = getelementptr inbounds i64, i64* %31, i64 4
  %109 = load i64, i64* %108, align 8, !tbaa !4698
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  %rdx.shuf113 = shufflevector <4 x i1> %107, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx114 = and <4 x i1> %107, %rdx.shuf113
  %rdx.shuf115 = shufflevector <4 x i1> %bin.rdx114, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx116 = and <4 x i1> %bin.rdx114, %rdx.shuf115
  %112 = extractelement <4 x i1> %bin.rdx116, i32 0
  %113 = and i1 %112, %111
  br i1 %113, label %if_end, label %assert_fail25, !prof !5

if_end:                                           ; preds = %assert_end24, %if_then
  %114 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %115 = load i64, i64* %114, align 8
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %assert_end28, label %assert_fail27, !prof !5

assert_fail25:                                    ; preds = %if_then
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([238 x i8], [238 x i8]* @.str.359, i64 0, i64 0))
  ret i32 -1

assert_fail27:                                    ; preds = %if_end
  %118 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %118(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %if_end
  %119 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq i32 %120, 6
  br i1 %121, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.45, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %123 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %124 = load i16, i16* %123, align 2
  %125 = icmp eq i16 %124, 1
  %126 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %127 = load i8, i8* %126, align 1
  %128 = icmp eq i8 %127, 32
  %129 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %130 = load i8, i8* %129, align 1
  %131 = icmp eq i8 %130, 2
  %132 = and i1 %128, %131
  %133 = and i1 %125, %132
  br i1 %133, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %134 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %134(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %135 = load i64, i64* %39, align 8, !tbaa !4702
  %136 = trunc i64 %135 to i32
  %137 = icmp eq i32 %136, 4
  br i1 %137, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %138 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %138(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.46, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %139 = getelementptr inbounds i64, i64* %39, i64 1
  %140 = load i64, i64* %139, align 8, !tbaa !4716
  %141 = trunc i64 %140 to i32
  %142 = icmp eq i32 %141, 8
  br i1 %142, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %143 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %143(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.191, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %144 = getelementptr inbounds i64, i64* %39, i64 2
  %145 = load i64, i64* %144, align 8, !tbaa !4718
  %146 = trunc i64 %145 to i32
  %147 = icmp eq i32 %146, 1
  br i1 %147, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.286, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %149 = getelementptr inbounds i64, i64* %39, i64 3
  %150 = load i64, i64* %149, align 8, !tbaa !4721
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %151, 1
  br i1 %152, label %assert_end40, label %assert_fail39, !prof !5

assert_fail39:                                    ; preds = %assert_end38
  %153 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %153(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.287, i64 0, i64 0))
  ret i32 -1

assert_end40:                                     ; preds = %assert_end38
  %154 = getelementptr inbounds i64, i64* %39, i64 4
  %155 = load i64, i64* %154, align 8, !tbaa !4723
  %156 = trunc i64 %155 to i32
  %157 = icmp eq i32 %156, 8
  br i1 %157, label %assert_end42, label %assert_fail41, !prof !5

assert_fail41:                                    ; preds = %assert_end40
  %158 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %158(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.159, i64 0, i64 0))
  ret i32 -1

assert_end42:                                     ; preds = %assert_end40
  %159 = getelementptr inbounds i64, i64* %39, i64 5
  %160 = load i64, i64* %159, align 8, !tbaa !4727
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %161, 32
  br i1 %162, label %assert_end44, label %assert_fail43, !prof !5

assert_fail43:                                    ; preds = %assert_end42
  %163 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %163(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.50, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %assert_end42
  %164 = icmp eq i64* %41, null
  br i1 %164, label %if_end46, label %if_then45, !prof !50

if_then45:                                        ; preds = %assert_end44
  %165 = bitcast i64* %41 to <4 x i64>*
  %166 = load <4 x i64>, <4 x i64>* %165, align 8, !tbaa !4729
  %167 = trunc <4 x i64> %166 to <4 x i32>
  %168 = icmp eq <4 x i32> %167, <i32 2048, i32 256, i32 256, i32 256>
  %169 = getelementptr inbounds i64, i64* %41, i64 4
  %170 = load i64, i64* %169, align 8, !tbaa !4741
  %171 = trunc i64 %170 to i32
  %172 = icmp eq i32 %171, 32
  %173 = getelementptr inbounds i64, i64* %41, i64 5
  %174 = load i64, i64* %173, align 8, !tbaa !4745
  %175 = trunc i64 %174 to i32
  %176 = icmp eq i32 %175, 1
  %rdx.shuf109 = shufflevector <4 x i1> %168, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx110 = and <4 x i1> %168, %rdx.shuf109
  %rdx.shuf111 = shufflevector <4 x i1> %bin.rdx110, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx112 = and <4 x i1> %bin.rdx110, %rdx.shuf111
  %177 = extractelement <4 x i1> %bin.rdx112, i32 0
  %178 = and i1 %177, %172
  %179 = and i1 %178, %176
  br i1 %179, label %if_end46, label %assert_fail47, !prof !5

if_end46:                                         ; preds = %assert_end44, %if_then45
  %180 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %181 = load i64, i64* %180, align 8
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %assert_end50, label %assert_fail49, !prof !5

assert_fail47:                                    ; preds = %if_then45
  %183 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %183(i8* getelementptr inbounds ([272 x i8], [272 x i8]* @.str.360, i64 0, i64 0))
  ret i32 -1

assert_fail49:                                    ; preds = %if_end46
  %184 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %184(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end50:                                     ; preds = %if_end46
  %185 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %186 = load i32, i32* %185, align 4
  %187 = icmp eq i32 %186, 1
  br i1 %187, label %assert_end52, label %assert_fail51, !prof !5

assert_fail51:                                    ; preds = %assert_end50
  %188 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %188(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end52:                                     ; preds = %assert_end50
  %189 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %190 = load i32, i32* %189, align 4
  %191 = icmp eq i32 %35, %190
  br i1 %191, label %assert_end54, label %assert_fail53, !prof !5

assert_fail53:                                    ; preds = %assert_end52
  %192 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %192(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end54:                                     ; preds = %assert_end52
  %193 = getelementptr inbounds %1, %1* %16, i64 0, i32 2
  %194 = load i32, i32* %193, align 4
  %195 = icmp eq i32 %194, 5
  br i1 %195, label %assert_end56, label %assert_fail55, !prof !5

assert_fail55:                                    ; preds = %assert_end54
  %196 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %196(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.52, i64 0, i64 0))
  ret i32 -1

assert_end56:                                     ; preds = %assert_end54
  %197 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 2
  %198 = load i16, i16* %197, align 2
  %199 = icmp eq i16 %198, 1
  %200 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 1
  %201 = load i8, i8* %200, align 1
  %202 = icmp eq i8 %201, 32
  %203 = getelementptr inbounds %1, %1* %16, i64 0, i32 3, i32 0
  %204 = load i8, i8* %203, align 1
  %205 = icmp eq i8 %204, 2
  %206 = and i1 %202, %205
  %207 = and i1 %199, %206
  br i1 %207, label %assert_end58, label %assert_fail57, !prof !5

assert_fail57:                                    ; preds = %assert_end56
  %208 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %208(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.53, i64 0, i64 0))
  ret i32 -1

assert_end58:                                     ; preds = %assert_end56
  %209 = load i64, i64* %45, align 8, !tbaa !4747
  %210 = trunc i64 %209 to i32
  %211 = icmp eq i32 %210, 1
  br i1 %211, label %assert_end60, label %assert_fail59, !prof !5

assert_fail59:                                    ; preds = %assert_end58
  %212 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %212(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.54, i64 0, i64 0))
  ret i32 -1

assert_end60:                                     ; preds = %assert_end58
  %213 = getelementptr inbounds i64, i64* %45, i64 1
  %214 = load i64, i64* %213, align 8, !tbaa !4761
  %215 = trunc i64 %214 to i32
  %216 = icmp eq i32 %215, 4
  br i1 %216, label %assert_end62, label %assert_fail61, !prof !5

assert_fail61:                                    ; preds = %assert_end60
  %217 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %217(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.55, i64 0, i64 0))
  ret i32 -1

assert_end62:                                     ; preds = %assert_end60
  %218 = getelementptr inbounds i64, i64* %45, i64 2
  %219 = load i64, i64* %218, align 8, !tbaa !4763
  %220 = trunc i64 %219 to i32
  %221 = icmp eq i32 %220, 1
  br i1 %221, label %assert_end64, label %assert_fail63, !prof !5

assert_fail63:                                    ; preds = %assert_end62
  %222 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %222(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.56, i64 0, i64 0))
  ret i32 -1

assert_end64:                                     ; preds = %assert_end62
  %223 = getelementptr inbounds i64, i64* %45, i64 3
  %224 = load i64, i64* %223, align 8, !tbaa !4766
  %225 = trunc i64 %224 to i32
  %226 = icmp eq i32 %225, 1
  br i1 %226, label %assert_end66, label %assert_fail65, !prof !5

assert_fail65:                                    ; preds = %assert_end64
  %227 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %227(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.57, i64 0, i64 0))
  ret i32 -1

assert_end66:                                     ; preds = %assert_end64
  %228 = getelementptr inbounds i64, i64* %45, i64 4
  %229 = load i64, i64* %228, align 8, !tbaa !4768
  %230 = trunc i64 %229 to i32
  %231 = icmp eq i32 %230, 32
  br i1 %231, label %assert_end68, label %assert_fail67, !prof !5

assert_fail67:                                    ; preds = %assert_end66
  %232 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %232(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.58, i64 0, i64 0))
  ret i32 -1

assert_end68:                                     ; preds = %assert_end66
  %233 = icmp eq i64* %47, null
  br i1 %233, label %if_end70, label %if_then69, !prof !50

if_then69:                                        ; preds = %assert_end68
  %234 = bitcast i64* %47 to <4 x i64>*
  %235 = load <4 x i64>, <4 x i64>* %234, align 8, !tbaa !4772
  %236 = trunc <4 x i64> %235 to <4 x i32>
  %237 = icmp eq <4 x i32> %236, <i32 128, i32 32, i32 32, i32 32>
  %238 = getelementptr inbounds i64, i64* %47, i64 4
  %239 = load i64, i64* %238, align 8, !tbaa !4784
  %240 = trunc i64 %239 to i32
  %241 = icmp eq i32 %240, 1
  %rdx.shuf105 = shufflevector <4 x i1> %237, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx106 = and <4 x i1> %237, %rdx.shuf105
  %rdx.shuf107 = shufflevector <4 x i1> %bin.rdx106, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx108 = and <4 x i1> %bin.rdx106, %rdx.shuf107
  %242 = extractelement <4 x i1> %bin.rdx108, i32 0
  %243 = and i1 %242, %241
  br i1 %243, label %if_end70, label %assert_fail71, !prof !5

if_end70:                                         ; preds = %assert_end68, %if_then69
  %244 = getelementptr inbounds %1, %1* %16, i64 0, i32 6
  %245 = load i64, i64* %244, align 8
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %assert_end74, label %assert_fail73, !prof !5

assert_fail71:                                    ; preds = %if_then69
  %247 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %247(i8* getelementptr inbounds ([232 x i8], [232 x i8]* @.str.59, i64 0, i64 0))
  ret i32 -1

assert_fail73:                                    ; preds = %if_end70
  %248 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %248(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.60, i64 0, i64 0))
  ret i32 -1

assert_end74:                                     ; preds = %if_end70
  %249 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = icmp eq i32 %250, 1
  br i1 %251, label %assert_end76, label %assert_fail75, !prof !5

assert_fail75:                                    ; preds = %assert_end74
  %252 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %252(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.61, i64 0, i64 0))
  ret i32 -1

assert_end76:                                     ; preds = %assert_end74
  %253 = getelementptr inbounds %1, %1* %16, i64 0, i32 1, i32 1
  %254 = load i32, i32* %253, align 4
  %255 = icmp eq i32 %35, %254
  br i1 %255, label %assert_end78, label %assert_fail77, !prof !5

assert_fail77:                                    ; preds = %assert_end76
  %256 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %256(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.62, i64 0, i64 0))
  ret i32 -1

assert_end78:                                     ; preds = %assert_end76
  %257 = getelementptr inbounds %1, %1* %22, i64 0, i32 2
  %258 = load i32, i32* %257, align 4
  %259 = icmp eq i32 %258, 5
  br i1 %259, label %assert_end80, label %assert_fail79, !prof !5

assert_fail79:                                    ; preds = %assert_end78
  %260 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %260(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.63, i64 0, i64 0))
  ret i32 -1

assert_end80:                                     ; preds = %assert_end78
  %261 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 2
  %262 = load i16, i16* %261, align 2
  %263 = icmp eq i16 %262, 1
  %264 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 1
  %265 = load i8, i8* %264, align 1
  %266 = icmp eq i8 %265, 32
  %267 = getelementptr inbounds %1, %1* %22, i64 0, i32 3, i32 0
  %268 = load i8, i8* %267, align 1
  %269 = icmp eq i8 %268, 2
  %270 = and i1 %266, %269
  %271 = and i1 %263, %270
  br i1 %271, label %assert_end82, label %assert_fail81, !prof !5

assert_fail81:                                    ; preds = %assert_end80
  %272 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %272(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.64, i64 0, i64 0))
  ret i32 -1

assert_end82:                                     ; preds = %assert_end80
  %273 = load i64, i64* %51, align 8, !tbaa !4788
  %274 = trunc i64 %273 to i32
  %275 = icmp eq i32 %274, 1
  br i1 %275, label %assert_end84, label %assert_fail83, !prof !5

assert_fail83:                                    ; preds = %assert_end82
  %276 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %276(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.65, i64 0, i64 0))
  ret i32 -1

assert_end84:                                     ; preds = %assert_end82
  %277 = getelementptr inbounds i64, i64* %51, i64 1
  %278 = load i64, i64* %277, align 8, !tbaa !4802
  %279 = trunc i64 %278 to i32
  %280 = icmp eq i32 %279, 4
  br i1 %280, label %assert_end86, label %assert_fail85, !prof !5

assert_fail85:                                    ; preds = %assert_end84
  %281 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %281(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.66, i64 0, i64 0))
  ret i32 -1

assert_end86:                                     ; preds = %assert_end84
  %282 = getelementptr inbounds i64, i64* %51, i64 2
  %283 = load i64, i64* %282, align 8, !tbaa !4804
  %284 = trunc i64 %283 to i32
  %285 = icmp eq i32 %284, 28
  br i1 %285, label %assert_end88, label %assert_fail87, !prof !5

assert_fail87:                                    ; preds = %assert_end86
  %286 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %286(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.67, i64 0, i64 0))
  ret i32 -1

assert_end88:                                     ; preds = %assert_end86
  %287 = getelementptr inbounds i64, i64* %51, i64 3
  %288 = load i64, i64* %287, align 8, !tbaa !4807
  %289 = trunc i64 %288 to i32
  %290 = icmp eq i32 %289, 28
  br i1 %290, label %assert_end90, label %assert_fail89, !prof !5

assert_fail89:                                    ; preds = %assert_end88
  %291 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %291(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.68, i64 0, i64 0))
  ret i32 -1

assert_end90:                                     ; preds = %assert_end88
  %292 = getelementptr inbounds i64, i64* %51, i64 4
  %293 = load i64, i64* %292, align 8, !tbaa !4809
  %294 = trunc i64 %293 to i32
  %295 = icmp eq i32 %294, 32
  br i1 %295, label %assert_end92, label %assert_fail91, !prof !5

assert_fail91:                                    ; preds = %assert_end90
  %296 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %296(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.69, i64 0, i64 0))
  ret i32 -1

assert_end92:                                     ; preds = %assert_end90
  %297 = icmp eq i64* %53, null
  br i1 %297, label %if_end94, label %if_then93, !prof !50

if_then93:                                        ; preds = %assert_end92
  %298 = bitcast i64* %53 to <4 x i64>*
  %299 = load <4 x i64>, <4 x i64>* %298, align 8, !tbaa !4813
  %300 = trunc <4 x i64> %299 to <4 x i32>
  %301 = icmp eq <4 x i32> %300, <i32 100352, i32 25088, i32 896, i32 32>
  %302 = getelementptr inbounds i64, i64* %53, i64 4
  %303 = load i64, i64* %302, align 8, !tbaa !4825
  %304 = trunc i64 %303 to i32
  %305 = icmp eq i32 %304, 1
  %rdx.shuf = shufflevector <4 x i1> %301, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %301, %rdx.shuf
  %rdx.shuf103 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx104 = and <4 x i1> %bin.rdx, %rdx.shuf103
  %306 = extractelement <4 x i1> %bin.rdx104, i32 0
  %307 = and i1 %306, %305
  br i1 %307, label %if_end94, label %assert_fail95, !prof !5

if_end94:                                         ; preds = %assert_end92, %if_then93
  %308 = getelementptr inbounds %1, %1* %22, i64 0, i32 6
  %309 = load i64, i64* %308, align 8
  %310 = icmp eq i64 %309, 0
  br i1 %310, label %assert_end98, label %assert_fail97, !prof !5

assert_fail95:                                    ; preds = %if_then93
  %311 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %311(i8* getelementptr inbounds ([239 x i8], [239 x i8]* @.str.70, i64 0, i64 0))
  ret i32 -1

assert_fail97:                                    ; preds = %if_end94
  %312 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %312(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.71, i64 0, i64 0))
  ret i32 -1

assert_end98:                                     ; preds = %if_end94
  %313 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 0
  %314 = load i32, i32* %313, align 4
  %315 = icmp eq i32 %314, 1
  br i1 %315, label %assert_end100, label %assert_fail99, !prof !5

assert_fail99:                                    ; preds = %assert_end98
  %316 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %316(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.72, i64 0, i64 0))
  ret i32 -1

assert_end100:                                    ; preds = %assert_end98
  %317 = getelementptr inbounds %1, %1* %22, i64 0, i32 1, i32 1
  %318 = load i32, i32* %317, align 4
  %319 = icmp eq i32 %35, %318
  br i1 %319, label %assert_end102, label %assert_fail101, !prof !5

assert_fail101:                                   ; preds = %assert_end100
  %320 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %320(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.73, i64 0, i64 0))
  ret i32 -1

assert_end102:                                    ; preds = %assert_end100
  %321 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_compute_(i8* %27, i8* %37, i8* %49, i8* %43, i32 %35)
  ret i32 %321
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = alloca %44, align 8
  %6 = getelementptr inbounds %44, %44* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %44, %44* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %44, %44* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %44, %44* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %44, %44* %5, i64 0, i32 4
  store i32 %4, i32* %10, align 8
  %11 = bitcast %44* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.361, i8* nonnull %11, i32 0)
  ret i32 %13
}

define private i32 @__tvm_parallel_lambda.361(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.preheader, label %for_end, !prof !5

for_body.preheader:                               ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_begin10.preheader
  %indvars.iv46 = phi i64 [ %31, %for_body.preheader ], [ %indvars.iv.next47, %for_begin10.preheader ]
  %33 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !6
  %34 = tail call i8* %33(i32 1, i32 %16, i64 3584, i32 2, i32 32)
  %35 = bitcast i8* %34 to float*
  %36 = trunc i64 %indvars.iv46 to i32
  %37 = srem i32 %36, 28
  %38 = mul nsw i32 %37, 896
  %39 = sdiv i32 %36, 28
  %40 = shl i32 %39, 11
  %41 = sext i32 %40 to i64
  %42 = sext i32 %38 to i64
  br label %for_body2

for_end:                                          ; preds = %for_begin10.preheader, %entry
  ret i32 0

for_begin10.preheader:                            ; preds = %for_end6
  %43 = mul nsw i64 %indvars.iv46, 896
  %44 = shl nsw i32 %39, 5
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %13, i64 %45
  %47 = bitcast float* %46 to <32 x float>*
  %48 = load <32 x float>, <32 x float>* %47, align 64, !tbaa !4829
  %49 = bitcast i8* %34 to <32 x float>*
  %50 = load <32 x float>, <32 x float>* %49, align 64, !tbaa !4832
  %51 = fadd <32 x float> %48, %50
  %52 = getelementptr inbounds float, float* %10, i64 %43
  %53 = bitcast float* %52 to <32 x float>*
  store <32 x float> %51, <32 x float>* %53, align 64, !tbaa !4835
  %54 = getelementptr inbounds i8, i8* %34, i64 128
  %55 = bitcast i8* %54 to <32 x float>*
  %56 = load <32 x float>, <32 x float>* %55, align 64, !tbaa !4832
  %57 = fadd <32 x float> %48, %56
  %58 = mul i64 %indvars.iv46, 3848290697216
  %sext = ashr exact i64 %58, 32
  %59 = or i64 %sext, 32
  %60 = getelementptr inbounds float, float* %10, i64 %59
  %61 = bitcast float* %60 to <32 x float>*
  store <32 x float> %57, <32 x float>* %61, align 64, !tbaa !4835
  %62 = getelementptr inbounds i8, i8* %34, i64 256
  %63 = bitcast i8* %62 to <32 x float>*
  %64 = load <32 x float>, <32 x float>* %63, align 64, !tbaa !4832
  %65 = fadd <32 x float> %48, %64
  %66 = mul i64 %indvars.iv46, 3848290697216
  %sext48 = ashr exact i64 %66, 32
  %67 = or i64 %sext48, 64
  %68 = getelementptr inbounds float, float* %10, i64 %67
  %69 = bitcast float* %68 to <32 x float>*
  store <32 x float> %65, <32 x float>* %69, align 64, !tbaa !4835
  %70 = getelementptr inbounds i8, i8* %34, i64 384
  %71 = bitcast i8* %70 to <32 x float>*
  %72 = load <32 x float>, <32 x float>* %71, align 64, !tbaa !4832
  %73 = fadd <32 x float> %48, %72
  %74 = mul i64 %indvars.iv46, 3848290697216
  %sext49 = ashr exact i64 %74, 32
  %75 = or i64 %sext49, 96
  %76 = getelementptr inbounds float, float* %10, i64 %75
  %77 = bitcast float* %76 to <32 x float>*
  store <32 x float> %73, <32 x float>* %77, align 64, !tbaa !4835
  %78 = getelementptr inbounds i8, i8* %34, i64 512
  %79 = bitcast i8* %78 to <32 x float>*
  %80 = load <32 x float>, <32 x float>* %79, align 64, !tbaa !4832
  %81 = fadd <32 x float> %48, %80
  %82 = mul i64 %indvars.iv46, 3848290697216
  %sext50 = add i64 %82, 549755813888
  %83 = ashr exact i64 %sext50, 32
  %84 = getelementptr inbounds float, float* %10, i64 %83
  %85 = bitcast float* %84 to <32 x float>*
  store <32 x float> %81, <32 x float>* %85, align 64, !tbaa !4835
  %86 = getelementptr inbounds i8, i8* %34, i64 640
  %87 = bitcast i8* %86 to <32 x float>*
  %88 = load <32 x float>, <32 x float>* %87, align 64, !tbaa !4832
  %89 = fadd <32 x float> %48, %88
  %90 = mul i64 %indvars.iv46, 3848290697216
  %sext51 = add i64 %90, 687194767360
  %91 = ashr exact i64 %sext51, 32
  %92 = getelementptr inbounds float, float* %10, i64 %91
  %93 = bitcast float* %92 to <32 x float>*
  store <32 x float> %89, <32 x float>* %93, align 64, !tbaa !4835
  %94 = getelementptr inbounds i8, i8* %34, i64 768
  %95 = bitcast i8* %94 to <32 x float>*
  %96 = load <32 x float>, <32 x float>* %95, align 64, !tbaa !4832
  %97 = fadd <32 x float> %48, %96
  %98 = mul i64 %indvars.iv46, 3848290697216
  %sext52 = add i64 %98, 824633720832
  %99 = ashr exact i64 %sext52, 32
  %100 = getelementptr inbounds float, float* %10, i64 %99
  %101 = bitcast float* %100 to <32 x float>*
  store <32 x float> %97, <32 x float>* %101, align 64, !tbaa !4835
  %102 = getelementptr inbounds i8, i8* %34, i64 896
  %103 = bitcast i8* %102 to <32 x float>*
  %104 = load <32 x float>, <32 x float>* %103, align 64, !tbaa !4832
  %105 = fadd <32 x float> %48, %104
  %106 = mul i64 %indvars.iv46, 3848290697216
  %sext53 = add i64 %106, 962072674304
  %107 = ashr exact i64 %sext53, 32
  %108 = getelementptr inbounds float, float* %10, i64 %107
  %109 = bitcast float* %108 to <32 x float>*
  store <32 x float> %105, <32 x float>* %109, align 64, !tbaa !4835
  %110 = getelementptr inbounds i8, i8* %34, i64 1024
  %111 = bitcast i8* %110 to <32 x float>*
  %112 = load <32 x float>, <32 x float>* %111, align 64, !tbaa !4832
  %113 = fadd <32 x float> %48, %112
  %114 = mul i64 %indvars.iv46, 3848290697216
  %sext54 = add i64 %114, 1099511627776
  %115 = ashr exact i64 %sext54, 32
  %116 = getelementptr inbounds float, float* %10, i64 %115
  %117 = bitcast float* %116 to <32 x float>*
  store <32 x float> %113, <32 x float>* %117, align 64, !tbaa !4835
  %118 = getelementptr inbounds i8, i8* %34, i64 1152
  %119 = bitcast i8* %118 to <32 x float>*
  %120 = load <32 x float>, <32 x float>* %119, align 64, !tbaa !4832
  %121 = fadd <32 x float> %48, %120
  %122 = mul i64 %indvars.iv46, 3848290697216
  %sext55 = add i64 %122, 1236950581248
  %123 = ashr exact i64 %sext55, 32
  %124 = getelementptr inbounds float, float* %10, i64 %123
  %125 = bitcast float* %124 to <32 x float>*
  store <32 x float> %121, <32 x float>* %125, align 64, !tbaa !4835
  %126 = getelementptr inbounds i8, i8* %34, i64 1280
  %127 = bitcast i8* %126 to <32 x float>*
  %128 = load <32 x float>, <32 x float>* %127, align 64, !tbaa !4832
  %129 = fadd <32 x float> %48, %128
  %130 = mul i64 %indvars.iv46, 3848290697216
  %sext56 = add i64 %130, 1374389534720
  %131 = ashr exact i64 %sext56, 32
  %132 = getelementptr inbounds float, float* %10, i64 %131
  %133 = bitcast float* %132 to <32 x float>*
  store <32 x float> %129, <32 x float>* %133, align 64, !tbaa !4835
  %134 = getelementptr inbounds i8, i8* %34, i64 1408
  %135 = bitcast i8* %134 to <32 x float>*
  %136 = load <32 x float>, <32 x float>* %135, align 64, !tbaa !4832
  %137 = fadd <32 x float> %48, %136
  %138 = mul i64 %indvars.iv46, 3848290697216
  %sext57 = add i64 %138, 1511828488192
  %139 = ashr exact i64 %sext57, 32
  %140 = getelementptr inbounds float, float* %10, i64 %139
  %141 = bitcast float* %140 to <32 x float>*
  store <32 x float> %137, <32 x float>* %141, align 64, !tbaa !4835
  %142 = getelementptr inbounds i8, i8* %34, i64 1536
  %143 = bitcast i8* %142 to <32 x float>*
  %144 = load <32 x float>, <32 x float>* %143, align 64, !tbaa !4832
  %145 = fadd <32 x float> %48, %144
  %146 = mul i64 %indvars.iv46, 3848290697216
  %sext58 = add i64 %146, 1649267441664
  %147 = ashr exact i64 %sext58, 32
  %148 = getelementptr inbounds float, float* %10, i64 %147
  %149 = bitcast float* %148 to <32 x float>*
  store <32 x float> %145, <32 x float>* %149, align 64, !tbaa !4835
  %150 = getelementptr inbounds i8, i8* %34, i64 1664
  %151 = bitcast i8* %150 to <32 x float>*
  %152 = load <32 x float>, <32 x float>* %151, align 64, !tbaa !4832
  %153 = fadd <32 x float> %48, %152
  %154 = mul i64 %indvars.iv46, 3848290697216
  %sext59 = add i64 %154, 1786706395136
  %155 = ashr exact i64 %sext59, 32
  %156 = getelementptr inbounds float, float* %10, i64 %155
  %157 = bitcast float* %156 to <32 x float>*
  store <32 x float> %153, <32 x float>* %157, align 64, !tbaa !4835
  %158 = getelementptr inbounds i8, i8* %34, i64 1792
  %159 = bitcast i8* %158 to <32 x float>*
  %160 = load <32 x float>, <32 x float>* %159, align 64, !tbaa !4832
  %161 = fadd <32 x float> %48, %160
  %162 = mul i64 %indvars.iv46, 3848290697216
  %sext60 = add i64 %162, 1924145348608
  %163 = ashr exact i64 %sext60, 32
  %164 = getelementptr inbounds float, float* %10, i64 %163
  %165 = bitcast float* %164 to <32 x float>*
  store <32 x float> %161, <32 x float>* %165, align 64, !tbaa !4835
  %166 = getelementptr inbounds i8, i8* %34, i64 1920
  %167 = bitcast i8* %166 to <32 x float>*
  %168 = load <32 x float>, <32 x float>* %167, align 64, !tbaa !4832
  %169 = fadd <32 x float> %48, %168
  %170 = mul i64 %indvars.iv46, 3848290697216
  %sext61 = add i64 %170, 2061584302080
  %171 = ashr exact i64 %sext61, 32
  %172 = getelementptr inbounds float, float* %10, i64 %171
  %173 = bitcast float* %172 to <32 x float>*
  store <32 x float> %169, <32 x float>* %173, align 64, !tbaa !4835
  %174 = getelementptr inbounds i8, i8* %34, i64 2048
  %175 = bitcast i8* %174 to <32 x float>*
  %176 = load <32 x float>, <32 x float>* %175, align 64, !tbaa !4832
  %177 = fadd <32 x float> %48, %176
  %178 = mul i64 %indvars.iv46, 3848290697216
  %sext62 = add i64 %178, 2199023255552
  %179 = ashr exact i64 %sext62, 32
  %180 = getelementptr inbounds float, float* %10, i64 %179
  %181 = bitcast float* %180 to <32 x float>*
  store <32 x float> %177, <32 x float>* %181, align 64, !tbaa !4835
  %182 = getelementptr inbounds i8, i8* %34, i64 2176
  %183 = bitcast i8* %182 to <32 x float>*
  %184 = load <32 x float>, <32 x float>* %183, align 64, !tbaa !4832
  %185 = fadd <32 x float> %48, %184
  %186 = mul i64 %indvars.iv46, 3848290697216
  %sext63 = add i64 %186, 2336462209024
  %187 = ashr exact i64 %sext63, 32
  %188 = getelementptr inbounds float, float* %10, i64 %187
  %189 = bitcast float* %188 to <32 x float>*
  store <32 x float> %185, <32 x float>* %189, align 64, !tbaa !4835
  %190 = getelementptr inbounds i8, i8* %34, i64 2304
  %191 = bitcast i8* %190 to <32 x float>*
  %192 = load <32 x float>, <32 x float>* %191, align 64, !tbaa !4832
  %193 = fadd <32 x float> %48, %192
  %194 = mul i64 %indvars.iv46, 3848290697216
  %sext64 = add i64 %194, 2473901162496
  %195 = ashr exact i64 %sext64, 32
  %196 = getelementptr inbounds float, float* %10, i64 %195
  %197 = bitcast float* %196 to <32 x float>*
  store <32 x float> %193, <32 x float>* %197, align 64, !tbaa !4835
  %198 = getelementptr inbounds i8, i8* %34, i64 2432
  %199 = bitcast i8* %198 to <32 x float>*
  %200 = load <32 x float>, <32 x float>* %199, align 64, !tbaa !4832
  %201 = fadd <32 x float> %48, %200
  %202 = mul i64 %indvars.iv46, 3848290697216
  %sext65 = add i64 %202, 2611340115968
  %203 = ashr exact i64 %sext65, 32
  %204 = getelementptr inbounds float, float* %10, i64 %203
  %205 = bitcast float* %204 to <32 x float>*
  store <32 x float> %201, <32 x float>* %205, align 64, !tbaa !4835
  %206 = getelementptr inbounds i8, i8* %34, i64 2560
  %207 = bitcast i8* %206 to <32 x float>*
  %208 = load <32 x float>, <32 x float>* %207, align 64, !tbaa !4832
  %209 = fadd <32 x float> %48, %208
  %210 = mul i64 %indvars.iv46, 3848290697216
  %sext66 = add i64 %210, 2748779069440
  %211 = ashr exact i64 %sext66, 32
  %212 = getelementptr inbounds float, float* %10, i64 %211
  %213 = bitcast float* %212 to <32 x float>*
  store <32 x float> %209, <32 x float>* %213, align 64, !tbaa !4835
  %214 = getelementptr inbounds i8, i8* %34, i64 2688
  %215 = bitcast i8* %214 to <32 x float>*
  %216 = load <32 x float>, <32 x float>* %215, align 64, !tbaa !4832
  %217 = fadd <32 x float> %48, %216
  %218 = mul i64 %indvars.iv46, 3848290697216
  %sext67 = add i64 %218, 2886218022912
  %219 = ashr exact i64 %sext67, 32
  %220 = getelementptr inbounds float, float* %10, i64 %219
  %221 = bitcast float* %220 to <32 x float>*
  store <32 x float> %217, <32 x float>* %221, align 64, !tbaa !4835
  %222 = getelementptr inbounds i8, i8* %34, i64 2816
  %223 = bitcast i8* %222 to <32 x float>*
  %224 = load <32 x float>, <32 x float>* %223, align 64, !tbaa !4832
  %225 = fadd <32 x float> %48, %224
  %226 = mul i64 %indvars.iv46, 3848290697216
  %sext68 = add i64 %226, 3023656976384
  %227 = ashr exact i64 %sext68, 32
  %228 = getelementptr inbounds float, float* %10, i64 %227
  %229 = bitcast float* %228 to <32 x float>*
  store <32 x float> %225, <32 x float>* %229, align 64, !tbaa !4835
  %230 = getelementptr inbounds i8, i8* %34, i64 2944
  %231 = bitcast i8* %230 to <32 x float>*
  %232 = load <32 x float>, <32 x float>* %231, align 64, !tbaa !4832
  %233 = fadd <32 x float> %48, %232
  %234 = mul i64 %indvars.iv46, 3848290697216
  %sext69 = add i64 %234, 3161095929856
  %235 = ashr exact i64 %sext69, 32
  %236 = getelementptr inbounds float, float* %10, i64 %235
  %237 = bitcast float* %236 to <32 x float>*
  store <32 x float> %233, <32 x float>* %237, align 64, !tbaa !4835
  %238 = getelementptr inbounds i8, i8* %34, i64 3072
  %239 = bitcast i8* %238 to <32 x float>*
  %240 = load <32 x float>, <32 x float>* %239, align 64, !tbaa !4832
  %241 = fadd <32 x float> %48, %240
  %242 = mul i64 %indvars.iv46, 3848290697216
  %sext70 = add i64 %242, 3298534883328
  %243 = ashr exact i64 %sext70, 32
  %244 = getelementptr inbounds float, float* %10, i64 %243
  %245 = bitcast float* %244 to <32 x float>*
  store <32 x float> %241, <32 x float>* %245, align 64, !tbaa !4835
  %246 = getelementptr inbounds i8, i8* %34, i64 3200
  %247 = bitcast i8* %246 to <32 x float>*
  %248 = load <32 x float>, <32 x float>* %247, align 64, !tbaa !4832
  %249 = fadd <32 x float> %48, %248
  %250 = mul i64 %indvars.iv46, 3848290697216
  %sext71 = add i64 %250, 3435973836800
  %251 = ashr exact i64 %sext71, 32
  %252 = getelementptr inbounds float, float* %10, i64 %251
  %253 = bitcast float* %252 to <32 x float>*
  store <32 x float> %249, <32 x float>* %253, align 64, !tbaa !4835
  %254 = getelementptr inbounds i8, i8* %34, i64 3328
  %255 = bitcast i8* %254 to <32 x float>*
  %256 = load <32 x float>, <32 x float>* %255, align 64, !tbaa !4832
  %257 = fadd <32 x float> %48, %256
  %258 = mul i64 %indvars.iv46, 3848290697216
  %sext72 = add i64 %258, 3573412790272
  %259 = ashr exact i64 %sext72, 32
  %260 = getelementptr inbounds float, float* %10, i64 %259
  %261 = bitcast float* %260 to <32 x float>*
  store <32 x float> %257, <32 x float>* %261, align 64, !tbaa !4835
  %262 = getelementptr inbounds i8, i8* %34, i64 3456
  %263 = bitcast i8* %262 to <32 x float>*
  %264 = load <32 x float>, <32 x float>* %263, align 64, !tbaa !4832
  %265 = fadd <32 x float> %48, %264
  %266 = mul i64 %indvars.iv46, 3848290697216
  %sext73 = add i64 %266, 3710851743744
  %267 = ashr exact i64 %sext73, 32
  %268 = getelementptr inbounds float, float* %10, i64 %267
  %269 = bitcast float* %268 to <32 x float>*
  store <32 x float> %265, <32 x float>* %269, align 64, !tbaa !4835
  %270 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !6
  %271 = tail call i32 %270(i32 1, i32 %16, i8* nonnull %34)
  %indvars.iv.next47 = add nsw i64 %indvars.iv46, 1
  %272 = icmp slt i64 %indvars.iv.next47, %32
  br i1 %272, label %for_body, label %for_end, !prof !5

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv37 = phi i64 [ 0, %for_body ], [ %indvars.iv.next38, %for_end6 ]
  %273 = shl nsw i64 %indvars.iv37, 7
  %274 = getelementptr inbounds float, float* %35, i64 %273
  %275 = bitcast float* %274 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %275, align 64, !tbaa !4832
  %276 = or i64 %273, 32
  %277 = getelementptr inbounds float, float* %35, i64 %276
  %278 = bitcast float* %277 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %278, align 64, !tbaa !4832
  %279 = or i64 %273, 64
  %280 = getelementptr inbounds float, float* %35, i64 %279
  %281 = bitcast float* %280 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %281, align 64, !tbaa !4832
  %282 = or i64 %273, 96
  %283 = getelementptr inbounds float, float* %35, i64 %282
  %284 = bitcast float* %283 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %284, align 64, !tbaa !4832
  %285 = shl i64 %indvars.iv37, 6
  %286 = add nsw i64 %285, %42
  br label %for_begin7.preheader

for_begin7.preheader:                             ; preds = %for_begin7.preheader, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_begin7.preheader ]
  %.lcssa2633 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %512, %for_begin7.preheader ]
  %.lcssa2431 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %506, %for_begin7.preheader ]
  %.lcssa2229 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %500, %for_begin7.preheader ]
  %.lcssa28 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %494, %for_begin7.preheader ]
  %287 = mul nuw nsw i64 %indvars.iv, 25088
  %288 = add nsw i64 %286, %287
  %289 = shl i64 %indvars.iv, 8
  %290 = add nuw nsw i64 %289, %41
  %291 = getelementptr inbounds float, float* %4, i64 %288
  %292 = load float, float* %291, align 4, !tbaa !4838
  %293 = insertelement <32 x float> undef, float %292, i32 0
  %294 = shufflevector <32 x float> %293, <32 x float> undef, <32 x i32> zeroinitializer
  %295 = getelementptr inbounds float, float* %7, i64 %290
  %296 = bitcast float* %295 to <32 x float>*
  %297 = load <32 x float>, <32 x float>* %296, align 64, !tbaa !4841
  %298 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %294, <32 x float> %297, <32 x float> %.lcssa28)
  %299 = or i64 %288, 16
  %300 = getelementptr inbounds float, float* %4, i64 %299
  %301 = load float, float* %300, align 4, !tbaa !4838
  %302 = insertelement <32 x float> undef, float %301, i32 0
  %303 = shufflevector <32 x float> %302, <32 x float> undef, <32 x i32> zeroinitializer
  %304 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %303, <32 x float> %297, <32 x float> %.lcssa2229)
  %305 = or i64 %288, 32
  %306 = getelementptr inbounds float, float* %4, i64 %305
  %307 = load float, float* %306, align 4, !tbaa !4838
  %308 = insertelement <32 x float> undef, float %307, i32 0
  %309 = shufflevector <32 x float> %308, <32 x float> undef, <32 x i32> zeroinitializer
  %310 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %309, <32 x float> %297, <32 x float> %.lcssa2431)
  %311 = or i64 %288, 48
  %312 = getelementptr inbounds float, float* %4, i64 %311
  %313 = load float, float* %312, align 4, !tbaa !4838
  %314 = insertelement <32 x float> undef, float %313, i32 0
  %315 = shufflevector <32 x float> %314, <32 x float> undef, <32 x i32> zeroinitializer
  %316 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %315, <32 x float> %297, <32 x float> %.lcssa2633)
  %317 = or i64 %288, 1
  %318 = getelementptr inbounds float, float* %4, i64 %317
  %319 = load float, float* %318, align 4, !tbaa !4838
  %320 = insertelement <32 x float> undef, float %319, i32 0
  %321 = shufflevector <32 x float> %320, <32 x float> undef, <32 x i32> zeroinitializer
  %322 = or i64 %290, 32
  %323 = getelementptr inbounds float, float* %7, i64 %322
  %324 = bitcast float* %323 to <32 x float>*
  %325 = load <32 x float>, <32 x float>* %324, align 64, !tbaa !4841
  %326 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %321, <32 x float> %325, <32 x float> %298)
  %327 = or i64 %288, 17
  %328 = getelementptr inbounds float, float* %4, i64 %327
  %329 = load float, float* %328, align 4, !tbaa !4838
  %330 = insertelement <32 x float> undef, float %329, i32 0
  %331 = shufflevector <32 x float> %330, <32 x float> undef, <32 x i32> zeroinitializer
  %332 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %331, <32 x float> %325, <32 x float> %304)
  %333 = or i64 %288, 33
  %334 = getelementptr inbounds float, float* %4, i64 %333
  %335 = load float, float* %334, align 4, !tbaa !4838
  %336 = insertelement <32 x float> undef, float %335, i32 0
  %337 = shufflevector <32 x float> %336, <32 x float> undef, <32 x i32> zeroinitializer
  %338 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %337, <32 x float> %325, <32 x float> %310)
  %339 = or i64 %288, 49
  %340 = getelementptr inbounds float, float* %4, i64 %339
  %341 = load float, float* %340, align 4, !tbaa !4838
  %342 = insertelement <32 x float> undef, float %341, i32 0
  %343 = shufflevector <32 x float> %342, <32 x float> undef, <32 x i32> zeroinitializer
  %344 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %343, <32 x float> %325, <32 x float> %316)
  %345 = or i64 %288, 2
  %346 = getelementptr inbounds float, float* %4, i64 %345
  %347 = load float, float* %346, align 4, !tbaa !4838
  %348 = insertelement <32 x float> undef, float %347, i32 0
  %349 = shufflevector <32 x float> %348, <32 x float> undef, <32 x i32> zeroinitializer
  %350 = or i64 %290, 64
  %351 = getelementptr inbounds float, float* %7, i64 %350
  %352 = bitcast float* %351 to <32 x float>*
  %353 = load <32 x float>, <32 x float>* %352, align 64, !tbaa !4841
  %354 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %349, <32 x float> %353, <32 x float> %326)
  %355 = or i64 %288, 18
  %356 = getelementptr inbounds float, float* %4, i64 %355
  %357 = load float, float* %356, align 4, !tbaa !4838
  %358 = insertelement <32 x float> undef, float %357, i32 0
  %359 = shufflevector <32 x float> %358, <32 x float> undef, <32 x i32> zeroinitializer
  %360 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %359, <32 x float> %353, <32 x float> %332)
  %361 = or i64 %288, 34
  %362 = getelementptr inbounds float, float* %4, i64 %361
  %363 = load float, float* %362, align 4, !tbaa !4838
  %364 = insertelement <32 x float> undef, float %363, i32 0
  %365 = shufflevector <32 x float> %364, <32 x float> undef, <32 x i32> zeroinitializer
  %366 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %365, <32 x float> %353, <32 x float> %338)
  %367 = or i64 %288, 50
  %368 = getelementptr inbounds float, float* %4, i64 %367
  %369 = load float, float* %368, align 4, !tbaa !4838
  %370 = insertelement <32 x float> undef, float %369, i32 0
  %371 = shufflevector <32 x float> %370, <32 x float> undef, <32 x i32> zeroinitializer
  %372 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %371, <32 x float> %353, <32 x float> %344)
  %373 = or i64 %288, 3
  %374 = getelementptr inbounds float, float* %4, i64 %373
  %375 = load float, float* %374, align 4, !tbaa !4838
  %376 = insertelement <32 x float> undef, float %375, i32 0
  %377 = shufflevector <32 x float> %376, <32 x float> undef, <32 x i32> zeroinitializer
  %378 = or i64 %290, 96
  %379 = getelementptr inbounds float, float* %7, i64 %378
  %380 = bitcast float* %379 to <32 x float>*
  %381 = load <32 x float>, <32 x float>* %380, align 64, !tbaa !4841
  %382 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %377, <32 x float> %381, <32 x float> %354)
  %383 = or i64 %288, 19
  %384 = getelementptr inbounds float, float* %4, i64 %383
  %385 = load float, float* %384, align 4, !tbaa !4838
  %386 = insertelement <32 x float> undef, float %385, i32 0
  %387 = shufflevector <32 x float> %386, <32 x float> undef, <32 x i32> zeroinitializer
  %388 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %387, <32 x float> %381, <32 x float> %360)
  %389 = or i64 %288, 35
  %390 = getelementptr inbounds float, float* %4, i64 %389
  %391 = load float, float* %390, align 4, !tbaa !4838
  %392 = insertelement <32 x float> undef, float %391, i32 0
  %393 = shufflevector <32 x float> %392, <32 x float> undef, <32 x i32> zeroinitializer
  %394 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %381, <32 x float> %366)
  %395 = or i64 %288, 51
  %396 = getelementptr inbounds float, float* %4, i64 %395
  %397 = load float, float* %396, align 4, !tbaa !4838
  %398 = insertelement <32 x float> undef, float %397, i32 0
  %399 = shufflevector <32 x float> %398, <32 x float> undef, <32 x i32> zeroinitializer
  %400 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %381, <32 x float> %372)
  %401 = or i64 %288, 4
  %402 = getelementptr inbounds float, float* %4, i64 %401
  %403 = load float, float* %402, align 4, !tbaa !4838
  %404 = insertelement <32 x float> undef, float %403, i32 0
  %405 = shufflevector <32 x float> %404, <32 x float> undef, <32 x i32> zeroinitializer
  %406 = or i64 %290, 128
  %407 = getelementptr inbounds float, float* %7, i64 %406
  %408 = bitcast float* %407 to <32 x float>*
  %409 = load <32 x float>, <32 x float>* %408, align 64, !tbaa !4841
  %410 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %409, <32 x float> %382)
  %411 = or i64 %288, 20
  %412 = getelementptr inbounds float, float* %4, i64 %411
  %413 = load float, float* %412, align 4, !tbaa !4838
  %414 = insertelement <32 x float> undef, float %413, i32 0
  %415 = shufflevector <32 x float> %414, <32 x float> undef, <32 x i32> zeroinitializer
  %416 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %415, <32 x float> %409, <32 x float> %388)
  %417 = or i64 %288, 36
  %418 = getelementptr inbounds float, float* %4, i64 %417
  %419 = load float, float* %418, align 4, !tbaa !4838
  %420 = insertelement <32 x float> undef, float %419, i32 0
  %421 = shufflevector <32 x float> %420, <32 x float> undef, <32 x i32> zeroinitializer
  %422 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %409, <32 x float> %394)
  %423 = or i64 %288, 52
  %424 = getelementptr inbounds float, float* %4, i64 %423
  %425 = load float, float* %424, align 4, !tbaa !4838
  %426 = insertelement <32 x float> undef, float %425, i32 0
  %427 = shufflevector <32 x float> %426, <32 x float> undef, <32 x i32> zeroinitializer
  %428 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %427, <32 x float> %409, <32 x float> %400)
  %429 = or i64 %288, 5
  %430 = getelementptr inbounds float, float* %4, i64 %429
  %431 = load float, float* %430, align 4, !tbaa !4838
  %432 = insertelement <32 x float> undef, float %431, i32 0
  %433 = shufflevector <32 x float> %432, <32 x float> undef, <32 x i32> zeroinitializer
  %434 = or i64 %290, 160
  %435 = getelementptr inbounds float, float* %7, i64 %434
  %436 = bitcast float* %435 to <32 x float>*
  %437 = load <32 x float>, <32 x float>* %436, align 64, !tbaa !4841
  %438 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %433, <32 x float> %437, <32 x float> %410)
  %439 = or i64 %288, 21
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = load float, float* %440, align 4, !tbaa !4838
  %442 = insertelement <32 x float> undef, float %441, i32 0
  %443 = shufflevector <32 x float> %442, <32 x float> undef, <32 x i32> zeroinitializer
  %444 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %443, <32 x float> %437, <32 x float> %416)
  %445 = or i64 %288, 37
  %446 = getelementptr inbounds float, float* %4, i64 %445
  %447 = load float, float* %446, align 4, !tbaa !4838
  %448 = insertelement <32 x float> undef, float %447, i32 0
  %449 = shufflevector <32 x float> %448, <32 x float> undef, <32 x i32> zeroinitializer
  %450 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %449, <32 x float> %437, <32 x float> %422)
  %451 = or i64 %288, 53
  %452 = getelementptr inbounds float, float* %4, i64 %451
  %453 = load float, float* %452, align 4, !tbaa !4838
  %454 = insertelement <32 x float> undef, float %453, i32 0
  %455 = shufflevector <32 x float> %454, <32 x float> undef, <32 x i32> zeroinitializer
  %456 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %455, <32 x float> %437, <32 x float> %428)
  %457 = or i64 %288, 6
  %458 = getelementptr inbounds float, float* %4, i64 %457
  %459 = load float, float* %458, align 4, !tbaa !4838
  %460 = insertelement <32 x float> undef, float %459, i32 0
  %461 = shufflevector <32 x float> %460, <32 x float> undef, <32 x i32> zeroinitializer
  %462 = or i64 %290, 192
  %463 = getelementptr inbounds float, float* %7, i64 %462
  %464 = bitcast float* %463 to <32 x float>*
  %465 = load <32 x float>, <32 x float>* %464, align 64, !tbaa !4841
  %466 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %461, <32 x float> %465, <32 x float> %438)
  %467 = or i64 %288, 22
  %468 = getelementptr inbounds float, float* %4, i64 %467
  %469 = load float, float* %468, align 4, !tbaa !4838
  %470 = insertelement <32 x float> undef, float %469, i32 0
  %471 = shufflevector <32 x float> %470, <32 x float> undef, <32 x i32> zeroinitializer
  %472 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %471, <32 x float> %465, <32 x float> %444)
  %473 = or i64 %288, 38
  %474 = getelementptr inbounds float, float* %4, i64 %473
  %475 = load float, float* %474, align 4, !tbaa !4838
  %476 = insertelement <32 x float> undef, float %475, i32 0
  %477 = shufflevector <32 x float> %476, <32 x float> undef, <32 x i32> zeroinitializer
  %478 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %477, <32 x float> %465, <32 x float> %450)
  %479 = or i64 %288, 54
  %480 = getelementptr inbounds float, float* %4, i64 %479
  %481 = load float, float* %480, align 4, !tbaa !4838
  %482 = insertelement <32 x float> undef, float %481, i32 0
  %483 = shufflevector <32 x float> %482, <32 x float> undef, <32 x i32> zeroinitializer
  %484 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %483, <32 x float> %465, <32 x float> %456)
  %485 = or i64 %288, 7
  %486 = getelementptr inbounds float, float* %4, i64 %485
  %487 = load float, float* %486, align 4, !tbaa !4838
  %488 = insertelement <32 x float> undef, float %487, i32 0
  %489 = shufflevector <32 x float> %488, <32 x float> undef, <32 x i32> zeroinitializer
  %490 = or i64 %290, 224
  %491 = getelementptr inbounds float, float* %7, i64 %490
  %492 = bitcast float* %491 to <32 x float>*
  %493 = load <32 x float>, <32 x float>* %492, align 64, !tbaa !4841
  %494 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %489, <32 x float> %493, <32 x float> %466)
  %495 = or i64 %288, 23
  %496 = getelementptr inbounds float, float* %4, i64 %495
  %497 = load float, float* %496, align 4, !tbaa !4838
  %498 = insertelement <32 x float> undef, float %497, i32 0
  %499 = shufflevector <32 x float> %498, <32 x float> undef, <32 x i32> zeroinitializer
  %500 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %499, <32 x float> %493, <32 x float> %472)
  %501 = or i64 %288, 39
  %502 = getelementptr inbounds float, float* %4, i64 %501
  %503 = load float, float* %502, align 4, !tbaa !4838
  %504 = insertelement <32 x float> undef, float %503, i32 0
  %505 = shufflevector <32 x float> %504, <32 x float> undef, <32 x i32> zeroinitializer
  %506 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %505, <32 x float> %493, <32 x float> %478)
  %507 = or i64 %288, 55
  %508 = getelementptr inbounds float, float* %4, i64 %507
  %509 = load float, float* %508, align 4, !tbaa !4838
  %510 = insertelement <32 x float> undef, float %509, i32 0
  %511 = shufflevector <32 x float> %510, <32 x float> undef, <32 x i32> zeroinitializer
  %512 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %511, <32 x float> %493, <32 x float> %484)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 8
  br i1 %exitcond, label %for_end6, label %for_begin7.preheader, !prof !50

for_end6:                                         ; preds = %for_begin7.preheader
  store <32 x float> %494, <32 x float>* %275, align 64, !tbaa !4832
  store <32 x float> %500, <32 x float>* %278, align 64, !tbaa !4832
  store <32 x float> %506, <32 x float>* %281, align 64, !tbaa !4832
  store <32 x float> %512, <32 x float>* %284, align 64, !tbaa !4832
  %indvars.iv.next38 = add nuw nsw i64 %indvars.iv37, 1
  %exitcond39 = icmp eq i64 %indvars.iv.next38, 7
  br i1 %exitcond39, label %for_begin10.preheader, label %for_body2, !prof !50
}

define dllexport i32 @fused_layout_transform_19(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %5 = icmp eq i32 %2, 2
  br i1 %5, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %6 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %6(i8* getelementptr inbounds ([78 x i8], [78 x i8]* @.str.362, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %7 = bitcast i8* %0 to %1**
  %8 = load %1*, %1** %7, align 8
  %9 = bitcast i8* %1 to i32*
  %10 = load i32, i32* %9, align 4, !tbaa !4844
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to %1**
  %13 = load %1*, %1** %12, align 8
  %14 = getelementptr inbounds %1, %1* %8, i64 0, i32 0
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds %1, %1* %8, i64 0, i32 4
  %17 = load i64*, i64** %16, align 8
  %18 = getelementptr inbounds %1, %1* %8, i64 0, i32 5
  %19 = load i64*, i64** %18, align 8
  %20 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %1, %1* %8, i64 0, i32 1, i32 1
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %1, %1* %13, i64 0, i32 0
  %25 = load i8*, i8** %24, align 8
  %26 = getelementptr inbounds %1, %1* %13, i64 0, i32 4
  %27 = load i64*, i64** %26, align 8
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 5
  %29 = load i64*, i64** %28, align 8
  switch i32 %10, label %assert_fail1 [
    i32 13, label %assert_end2
    i32 7, label %assert_end2
    i32 4, label %assert_end2
    i32 3, label %assert_end2
  ]

assert_fail1:                                     ; preds = %assert_end
  %30 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %30(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.363, i64 0, i64 0))
  ret i32 -1

assert_end2:                                      ; preds = %assert_end, %assert_end, %assert_end, %assert_end
  %31 = getelementptr inbounds i8, i8* %1, i64 4
  %32 = bitcast i8* %31 to i32*
  %33 = load i32, i32* %32, align 4, !tbaa !4858
  switch i32 %33, label %assert_fail3 [
    i32 13, label %assert_end4
    i32 7, label %assert_end4
    i32 4, label %assert_end4
    i32 3, label %assert_end4
  ]

assert_fail3:                                     ; preds = %assert_end2
  %34 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %34(i8* getelementptr inbounds ([153 x i8], [153 x i8]* @.str.364, i64 0, i64 0))
  ret i32 -1

assert_end4:                                      ; preds = %assert_end2, %assert_end2, %assert_end2, %assert_end2
  %35 = icmp eq i32 %21, 1
  br i1 %35, label %assert_end6, label %assert_fail5, !prof !5

assert_fail5:                                     ; preds = %assert_end4
  %36 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %36(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.3, i64 0, i64 0))
  ret i32 -1

assert_end6:                                      ; preds = %assert_end4
  %37 = getelementptr inbounds %1, %1* %8, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 5
  br i1 %39, label %assert_end8, label %assert_fail7, !prof !5

assert_fail7:                                     ; preds = %assert_end6
  %40 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %40(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.4, i64 0, i64 0))
  ret i32 -1

assert_end8:                                      ; preds = %assert_end6
  %41 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 2
  %42 = load i16, i16* %41, align 2
  %43 = icmp eq i16 %42, 1
  %44 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 1
  %45 = load i8, i8* %44, align 1
  %46 = icmp eq i8 %45, 32
  %47 = getelementptr inbounds %1, %1* %8, i64 0, i32 3, i32 0
  %48 = load i8, i8* %47, align 1
  %49 = icmp eq i8 %48, 2
  %50 = and i1 %46, %49
  %51 = and i1 %43, %50
  br i1 %51, label %assert_end10, label %assert_fail9, !prof !5

assert_fail9:                                     ; preds = %assert_end8
  %52 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %52(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.5, i64 0, i64 0))
  ret i32 -1

assert_end10:                                     ; preds = %assert_end8
  %53 = load i64, i64* %17, align 8, !tbaa !4860
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %assert_end12, label %assert_fail11, !prof !5

assert_fail11:                                    ; preds = %assert_end10
  %56 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %56(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.6, i64 0, i64 0))
  ret i32 -1

assert_end12:                                     ; preds = %assert_end10
  %57 = getelementptr inbounds i64, i64* %17, i64 1
  %58 = load i64, i64* %57, align 8, !tbaa !4874
  %59 = trunc i64 %58 to i32
  %60 = icmp eq i32 %59, 16
  br i1 %60, label %assert_end14, label %assert_fail13, !prof !5

assert_fail13:                                    ; preds = %assert_end12
  %61 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %61(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.27, i64 0, i64 0))
  ret i32 -1

assert_end14:                                     ; preds = %assert_end12
  %62 = getelementptr inbounds i64, i64* %17, i64 2
  %63 = load i64, i64* %62, align 8, !tbaa !4876
  %64 = trunc i64 %63 to i32
  %65 = icmp eq i32 %64, 14
  br i1 %65, label %assert_end16, label %assert_fail15, !prof !5

assert_fail15:                                    ; preds = %assert_end14
  %66 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %66(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.8, i64 0, i64 0))
  ret i32 -1

assert_end16:                                     ; preds = %assert_end14
  %67 = getelementptr inbounds i64, i64* %17, i64 3
  %68 = load i64, i64* %67, align 8, !tbaa !4879
  %69 = trunc i64 %68 to i32
  %70 = icmp eq i32 %69, 14
  br i1 %70, label %assert_end18, label %assert_fail17, !prof !5

assert_fail17:                                    ; preds = %assert_end16
  %71 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %71(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.9, i64 0, i64 0))
  ret i32 -1

assert_end18:                                     ; preds = %assert_end16
  %72 = getelementptr inbounds i64, i64* %17, i64 4
  %73 = load i64, i64* %72, align 8, !tbaa !4881
  %74 = trunc i64 %73 to i32
  %75 = icmp eq i32 %74, 16
  br i1 %75, label %assert_end20, label %assert_fail19, !prof !5

assert_fail19:                                    ; preds = %assert_end18
  %76 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %76(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.338, i64 0, i64 0))
  ret i32 -1

assert_end20:                                     ; preds = %assert_end18
  %77 = icmp eq i64* %19, null
  br i1 %77, label %if_end, label %if_then, !prof !50

if_then:                                          ; preds = %assert_end20
  %78 = bitcast i64* %19 to <4 x i64>*
  %79 = load <4 x i64>, <4 x i64>* %78, align 8, !tbaa !4885
  %80 = trunc <4 x i64> %79 to <4 x i32>
  %81 = icmp eq <4 x i32> %80, <i32 50176, i32 3136, i32 224, i32 16>
  %82 = getelementptr inbounds i64, i64* %19, i64 4
  %83 = load i64, i64* %82, align 8, !tbaa !4897
  %84 = trunc i64 %83 to i32
  %85 = icmp eq i32 %84, 1
  %rdx.shuf51 = shufflevector <4 x i1> %81, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx52 = and <4 x i1> %81, %rdx.shuf51
  %rdx.shuf53 = shufflevector <4 x i1> %bin.rdx52, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx54 = and <4 x i1> %bin.rdx52, %rdx.shuf53
  %86 = extractelement <4 x i1> %bin.rdx54, i32 0
  %87 = and i1 %86, %85
  br i1 %87, label %if_end, label %assert_fail21, !prof !5

if_end:                                           ; preds = %assert_end20, %if_then
  %88 = getelementptr inbounds %1, %1* %8, i64 0, i32 6
  %89 = load i64, i64* %88, align 8
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %assert_end24, label %assert_fail23, !prof !5

assert_fail21:                                    ; preds = %if_then
  %91 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %91(i8* getelementptr inbounds ([237 x i8], [237 x i8]* @.str.339, i64 0, i64 0))
  ret i32 -1

assert_fail23:                                    ; preds = %if_end
  %92 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %92(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.12, i64 0, i64 0))
  ret i32 -1

assert_end24:                                     ; preds = %if_end
  %93 = getelementptr inbounds %1, %1* %13, i64 0, i32 2
  %94 = load i32, i32* %93, align 4
  %95 = icmp eq i32 %94, 5
  br i1 %95, label %assert_end26, label %assert_fail25, !prof !5

assert_fail25:                                    ; preds = %assert_end24
  %96 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %96(i8* getelementptr inbounds ([81 x i8], [81 x i8]* @.str.13, i64 0, i64 0))
  ret i32 -1

assert_end26:                                     ; preds = %assert_end24
  %97 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 2
  %98 = load i16, i16* %97, align 2
  %99 = icmp eq i16 %98, 1
  %100 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 1
  %101 = load i8, i8* %100, align 1
  %102 = icmp eq i8 %101, 32
  %103 = getelementptr inbounds %1, %1* %13, i64 0, i32 3, i32 0
  %104 = load i8, i8* %103, align 1
  %105 = icmp eq i8 %104, 2
  %106 = and i1 %102, %105
  %107 = and i1 %99, %106
  br i1 %107, label %assert_end28, label %assert_fail27, !prof !5

assert_fail27:                                    ; preds = %assert_end26
  %108 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %108(i8* getelementptr inbounds ([186 x i8], [186 x i8]* @.str.14, i64 0, i64 0))
  ret i32 -1

assert_end28:                                     ; preds = %assert_end26
  %109 = load i64, i64* %27, align 8, !tbaa !4901
  %110 = trunc i64 %109 to i32
  %111 = icmp eq i32 %110, 1
  br i1 %111, label %assert_end30, label %assert_fail29, !prof !5

assert_fail29:                                    ; preds = %assert_end28
  %112 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %112(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.15, i64 0, i64 0))
  ret i32 -1

assert_end30:                                     ; preds = %assert_end28
  %113 = getelementptr inbounds i64, i64* %27, i64 1
  %114 = load i64, i64* %113, align 8, !tbaa !4915
  %115 = trunc i64 %114 to i32
  %116 = icmp eq i32 %115, 2
  br i1 %116, label %assert_end32, label %assert_fail31, !prof !5

assert_fail31:                                    ; preds = %assert_end30
  %117 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %117(i8* getelementptr inbounds ([95 x i8], [95 x i8]* @.str.16, i64 0, i64 0))
  ret i32 -1

assert_end32:                                     ; preds = %assert_end30
  %118 = getelementptr inbounds i64, i64* %27, i64 2
  %119 = load i64, i64* %118, align 8, !tbaa !4917
  %120 = trunc i64 %119 to i32
  %121 = icmp eq i32 %120, 14
  br i1 %121, label %assert_end34, label %assert_fail33, !prof !5

assert_fail33:                                    ; preds = %assert_end32
  %122 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %122(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.17, i64 0, i64 0))
  ret i32 -1

assert_end34:                                     ; preds = %assert_end32
  %123 = getelementptr inbounds i64, i64* %27, i64 3
  %124 = load i64, i64* %123, align 8, !tbaa !4920
  %125 = trunc i64 %124 to i32
  %126 = icmp eq i32 %125, 14
  br i1 %126, label %assert_end36, label %assert_fail35, !prof !5

assert_fail35:                                    ; preds = %assert_end34
  %127 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %127(i8* getelementptr inbounds ([96 x i8], [96 x i8]* @.str.18, i64 0, i64 0))
  ret i32 -1

assert_end36:                                     ; preds = %assert_end34
  %128 = getelementptr inbounds i64, i64* %27, i64 4
  %129 = load i64, i64* %128, align 8, !tbaa !4922
  %130 = trunc i64 %129 to i32
  %131 = icmp eq i32 %130, 128
  br i1 %131, label %assert_end38, label %assert_fail37, !prof !5

assert_fail37:                                    ; preds = %assert_end36
  %132 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %132(i8* getelementptr inbounds ([97 x i8], [97 x i8]* @.str.19, i64 0, i64 0))
  ret i32 -1

assert_end38:                                     ; preds = %assert_end36
  %133 = icmp eq i64* %29, null
  br i1 %133, label %if_end40, label %if_then39, !prof !50

if_then39:                                        ; preds = %assert_end38
  %134 = bitcast i64* %29 to <4 x i64>*
  %135 = load <4 x i64>, <4 x i64>* %134, align 8, !tbaa !4926
  %136 = trunc <4 x i64> %135 to <4 x i32>
  %137 = icmp eq <4 x i32> %136, <i32 50176, i32 25088, i32 1792, i32 128>
  %138 = getelementptr inbounds i64, i64* %29, i64 4
  %139 = load i64, i64* %138, align 8, !tbaa !4938
  %140 = trunc i64 %139 to i32
  %141 = icmp eq i32 %140, 1
  %rdx.shuf = shufflevector <4 x i1> %137, <4 x i1> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %bin.rdx = and <4 x i1> %137, %rdx.shuf
  %rdx.shuf49 = shufflevector <4 x i1> %bin.rdx, <4 x i1> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %bin.rdx50 = and <4 x i1> %bin.rdx, %rdx.shuf49
  %142 = extractelement <4 x i1> %bin.rdx50, i32 0
  %143 = and i1 %142, %141
  br i1 %143, label %if_end40, label %assert_fail41, !prof !5

if_end40:                                         ; preds = %assert_end38, %if_then39
  %144 = getelementptr inbounds %1, %1* %13, i64 0, i32 6
  %145 = load i64, i64* %144, align 8
  %146 = icmp eq i64 %145, 0
  br i1 %146, label %assert_end44, label %assert_fail43, !prof !5

assert_fail41:                                    ; preds = %if_then39
  %147 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %147(i8* getelementptr inbounds ([240 x i8], [240 x i8]* @.str.20, i64 0, i64 0))
  ret i32 -1

assert_fail43:                                    ; preds = %if_end40
  %148 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %148(i8* getelementptr inbounds ([112 x i8], [112 x i8]* @.str.21, i64 0, i64 0))
  ret i32 -1

assert_end44:                                     ; preds = %if_end40
  %149 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = icmp eq i32 %150, 1
  br i1 %151, label %assert_end46, label %assert_fail45, !prof !5

assert_fail45:                                    ; preds = %assert_end44
  %152 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %152(i8* getelementptr inbounds ([105 x i8], [105 x i8]* @.str.22, i64 0, i64 0))
  ret i32 -1

assert_end46:                                     ; preds = %assert_end44
  %153 = getelementptr inbounds %1, %1* %13, i64 0, i32 1, i32 1
  %154 = load i32, i32* %153, align 4
  %155 = icmp eq i32 %23, %154
  br i1 %155, label %assert_end48, label %assert_fail47, !prof !5

assert_fail47:                                    ; preds = %assert_end46
  %156 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %156(i8* getelementptr inbounds ([107 x i8], [107 x i8]* @.str.23, i64 0, i64 0))
  ret i32 -1

assert_end48:                                     ; preds = %assert_end46
  %157 = tail call fastcc i32 @fused_layout_transform_19_compute_(i8* %25, i8* %15)
  ret i32 %157
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_19_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %45, align 8
  %3 = getelementptr inbounds %45, %45* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %45, %45* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %45* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !6
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.365, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.365(i32, %0* nocapture readonly, i8* nocapture readonly) #1 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_begin1.preheader.preheader, label %for_end, !prof !5

for_begin1.preheader.preheader:                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_begin1.preheader

for_begin1.preheader:                             ; preds = %for_begin1.preheader.preheader, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_begin1.preheader.preheader ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 1792
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = srem i32 %25, 14
  %27 = mul nsw i32 %26, 224
  %28 = sdiv i32 %25, 14
  %29 = mul nsw i32 %28, 25088
  %30 = add i32 %27, %29
  br label %for_begin4.preheader

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_begin4.preheader:                             ; preds = %for_begin4.preheader, %for_begin1.preheader
  %indvars.iv = phi i64 [ 0, %for_begin1.preheader ], [ %indvars.iv.next, %for_begin4.preheader ]
  %31 = shl i64 %indvars.iv, 7
  %32 = add nsw i64 %31, %24
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %33 = shl i32 %indvars.iv.tr, 4
  %34 = add i32 %30, %33
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds float, float* %7, i64 %35
  %37 = bitcast float* %36 to <16 x float>*
  %38 = load <16 x float>, <16 x float>* %37, align 64, !tbaa !4942
  %39 = getelementptr inbounds float, float* %4, i64 %32
  %40 = bitcast float* %39 to <16 x float>*
  store <16 x float> %38, <16 x float>* %40, align 64, !tbaa !4945
  %41 = or i64 %32, 16
  %42 = add i32 %34, 3136
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds float, float* %7, i64 %43
  %45 = bitcast float* %44 to <16 x float>*
  %46 = load <16 x float>, <16 x float>* %45, align 64, !tbaa !4942
  %47 = getelementptr inbounds float, float* %4, i64 %41
  %48 = bitcast float* %47 to <16 x float>*
  store <16 x float> %46, <16 x float>* %48, align 64, !tbaa !4945
  %49 = or i64 %32, 32
  %50 = add i32 %34, 6272
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds float, float* %7, i64 %51
  %53 = bitcast float* %52 to <16 x float>*
  %54 = load <16 x float>, <16 x float>* %53, align 64, !tbaa !4942
  %55 = getelementptr inbounds float, float* %4, i64 %49
  %56 = bitcast float* %55 to <16 x float>*
  store <16 x float> %54, <16 x float>* %56, align 64, !tbaa !4945
  %57 = or i64 %32, 48
  %58 = add i32 %34, 9408
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds float, float* %7, i64 %59
  %61 = bitcast float* %60 to <16 x float>*
  %62 = load <16 x float>, <16 x float>* %61, align 64, !tbaa !4942
  %63 = getelementptr inbounds float, float* %4, i64 %57
  %64 = bitcast float* %63 to <16 x float>*
  store <16 x float> %62, <16 x float>* %64, align 64, !tbaa !4945
  %65 = or i64 %32, 64
  %66 = add i32 %34, 12544
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds float, float* %7, i64 %67
  %69 = bitcast float* %68 to <16 x float>*
  %70 = load <16 x float>, <16 x float>* %69, align 64, !tbaa !4942
  %71 = getelementptr inbounds float, float* %4, i64 %65
  %72 = bitcast float* %71 to <16 x float>*
  store <16 x float> %70, <16 x float>* %72, align 64, !tbaa !4945
  %73 = or i64 %32, 80
  %74 = add i32 %34, 15680
  %75 = sext i32 %74 to i64
  %76 = getelementptr inbounds float, float* %7, i64 %75
  %77 = bitcast float* %76 to <16 x float>*
  %78 = load <16 x float>, <16 x float>* %77, align 64, !tbaa !4942
  %79 = getelementptr inbounds float, float* %4, i64 %73
  %80 = bitcast float* %79 to <16 x float>*
  store <16 x float> %78, <16 x float>* %80, align 64, !tbaa !4945
  %81 = or i64 %32, 96
  %82 = add i32 %34, 18816
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = bitcast float* %84 to <16 x float>*
  %86 = load <16 x float>, <16 x float>* %85, align 64, !tbaa !4942
  %87 = getelementptr inbounds float, float* %4, i64 %81
  %88 = bitcast float* %87 to <16 x float>*
  store <16 x float> %86, <16 x float>* %88, align 64, !tbaa !4945
  %89 = or i64 %32, 112
  %90 = add i32 %34, 21952
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds float, float* %7, i64 %91
  %93 = bitcast float* %92 to <16 x float>*
  %94 = load <16 x float>, <16 x float>* %93, align 64, !tbaa !4942
  %95 = getelementptr inbounds float, float* %4, i64 %89
  %96 = bitcast float* %95 to <16 x float>*
  store <16 x float> %94, <16 x float>* %96, align 64, !tbaa !4945
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 14
  br i1 %exitcond, label %for_end3, label %for_begin4.preheader, !prof !50

for_end3:                                         ; preds = %for_begin4.preheader
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %97 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %97, label %for_begin1.preheader, label %for_end, !prof !5
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1) #5

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1) #5

attributes #0 = { noinline }
attributes #1 = { norecurse nounwind }
attributes #2 = { noinline norecurse nounwind }
attributes #3 = { nounwind readnone speculatable }
attributes #4 = { nounwind }
attributes #5 = { argmemonly nounwind }

!llvm.dbg.cu = !{!0}
!llvm.module.flags = !{!3, !4}

!0 = distinct !DICompileUnit(language: DW_LANG_C, file: !1, producer: "TVM", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !2, dwoId: 1)
!1 = !DIFile(filename: "model.tvm", directory: "/tmp/")
!2 = !{}
!3 = !{i32 2, !"tvm_target", !"llvm"}
!4 = !{i32 4, !"Debug Info Version", i32 3}
!5 = !{!"branch_weights", i32 1048576, i32 1}
!6 = !{!7, !7, i64 0}
!7 = !{!"ctx_ptr", !8, i64 0}
!8 = !{!"tvm-tbaa"}
!9 = !{!10, !10, i64 0}
!10 = !{!"0x5646c1ee3050.w1.b0", !11, i64 0}
!11 = !{!"0x5646c1ee3050.w2.b0", !12, i64 0}
!12 = !{!"0x5646c1ee3050.w4.b0", !13, i64 0}
!13 = !{!"0x5646c1ee3050.w8.b0", !14, i64 0}
!14 = !{!"0x5646c1ee3050.w16.b0", !15, i64 0}
!15 = !{!"0x5646c1ee3050.w32.b0", !16, i64 0}
!16 = !{!"0x5646c1ee3050.w64.b0", !17, i64 0}
!17 = !{!"0x5646c1ee3050.w128.b0", !18, i64 0}
!18 = !{!"0x5646c1ee3050.w256.b0", !19, i64 0}
!19 = !{!"0x5646c1ee3050.w512.b0", !20, i64 0}
!20 = !{!"0x5646c1ee3050.w1024.b0", !21, i64 0}
!21 = !{!"int32", !22, i64 0}
!22 = !{!"0x5646c1ee3050", !8, i64 0}
!23 = !{!24, !24, i64 0}
!24 = !{!"0x5646c1ee3050.w1.b1", !11, i64 0}
!25 = !{!26, !26, i64 0}
!26 = !{!"0x5646c1f2f500.w1.b0", !27, i64 0}
!27 = !{!"0x5646c1f2f500.w2.b0", !28, i64 0}
!28 = !{!"0x5646c1f2f500.w4.b0", !29, i64 0}
!29 = !{!"0x5646c1f2f500.w8.b0", !30, i64 0}
!30 = !{!"0x5646c1f2f500.w16.b0", !31, i64 0}
!31 = !{!"0x5646c1f2f500.w32.b0", !32, i64 0}
!32 = !{!"0x5646c1f2f500.w64.b0", !33, i64 0}
!33 = !{!"0x5646c1f2f500.w128.b0", !34, i64 0}
!34 = !{!"0x5646c1f2f500.w256.b0", !35, i64 0}
!35 = !{!"0x5646c1f2f500.w512.b0", !36, i64 0}
!36 = !{!"0x5646c1f2f500.w1024.b0", !37, i64 0}
!37 = !{!"int64", !38, i64 0}
!38 = !{!"0x5646c1f2f500", !8, i64 0}
!39 = !{!40, !40, i64 0}
!40 = !{!"0x5646c1f2f500.w1.b1", !27, i64 0}
!41 = !{!42, !42, i64 0}
!42 = !{!"0x5646c1f2f500.w1.b2", !43, i64 0}
!43 = !{!"0x5646c1f2f500.w2.b2", !28, i64 0}
!44 = !{!45, !45, i64 0}
!45 = !{!"0x5646c1f2f500.w1.b3", !43, i64 0}
!46 = !{!47, !47, i64 0}
!47 = !{!"0x5646c1f2f500.w1.b4", !48, i64 0}
!48 = !{!"0x5646c1f2f500.w2.b4", !49, i64 0}
!49 = !{!"0x5646c1f2f500.w4.b4", !29, i64 0}
!50 = !{!"branch_weights", i32 1, i32 1048576}
!51 = !{!52, !52, i64 0}
!52 = !{!"0x5646c1f2f7e0.w4.b0", !53, i64 0}
!53 = !{!"0x5646c1f2f7e0.w8.b0", !54, i64 0}
!54 = !{!"0x5646c1f2f7e0.w16.b0", !55, i64 0}
!55 = !{!"0x5646c1f2f7e0.w32.b0", !56, i64 0}
!56 = !{!"0x5646c1f2f7e0.w64.b0", !57, i64 0}
!57 = !{!"0x5646c1f2f7e0.w128.b0", !58, i64 0}
!58 = !{!"0x5646c1f2f7e0.w256.b0", !59, i64 0}
!59 = !{!"0x5646c1f2f7e0.w512.b0", !60, i64 0}
!60 = !{!"0x5646c1f2f7e0.w1024.b0", !61, i64 0}
!61 = !{!"int64", !62, i64 0}
!62 = !{!"0x5646c1f2f7e0", !8, i64 0}
!63 = !{!64, !64, i64 0}
!64 = !{!"0x5646c1f2f7e0.w1.b4", !65, i64 0}
!65 = !{!"0x5646c1f2f7e0.w2.b4", !66, i64 0}
!66 = !{!"0x5646c1f2f7e0.w4.b4", !53, i64 0}
!67 = !{!68, !68, i64 0}
!68 = !{!"0x5646c1f2fa30.w1.b0", !69, i64 0}
!69 = !{!"0x5646c1f2fa30.w2.b0", !70, i64 0}
!70 = !{!"0x5646c1f2fa30.w4.b0", !71, i64 0}
!71 = !{!"0x5646c1f2fa30.w8.b0", !72, i64 0}
!72 = !{!"0x5646c1f2fa30.w16.b0", !73, i64 0}
!73 = !{!"0x5646c1f2fa30.w32.b0", !74, i64 0}
!74 = !{!"0x5646c1f2fa30.w64.b0", !75, i64 0}
!75 = !{!"0x5646c1f2fa30.w128.b0", !76, i64 0}
!76 = !{!"0x5646c1f2fa30.w256.b0", !77, i64 0}
!77 = !{!"0x5646c1f2fa30.w512.b0", !78, i64 0}
!78 = !{!"0x5646c1f2fa30.w1024.b0", !79, i64 0}
!79 = !{!"int64", !80, i64 0}
!80 = !{!"0x5646c1f2fa30", !8, i64 0}
!81 = !{!82, !82, i64 0}
!82 = !{!"0x5646c1f2fa30.w1.b1", !69, i64 0}
!83 = !{!84, !84, i64 0}
!84 = !{!"0x5646c1f2fa30.w1.b2", !85, i64 0}
!85 = !{!"0x5646c1f2fa30.w2.b2", !70, i64 0}
!86 = !{!87, !87, i64 0}
!87 = !{!"0x5646c1f2fa30.w1.b3", !85, i64 0}
!88 = !{!89, !89, i64 0}
!89 = !{!"0x5646c1f2fa30.w1.b4", !90, i64 0}
!90 = !{!"0x5646c1f2fa30.w2.b4", !91, i64 0}
!91 = !{!"0x5646c1f2fa30.w4.b4", !71, i64 0}
!92 = !{!93, !93, i64 0}
!93 = !{!"0x5646c1f2f6a0.w4.b0", !94, i64 0}
!94 = !{!"0x5646c1f2f6a0.w8.b0", !95, i64 0}
!95 = !{!"0x5646c1f2f6a0.w16.b0", !96, i64 0}
!96 = !{!"0x5646c1f2f6a0.w32.b0", !97, i64 0}
!97 = !{!"0x5646c1f2f6a0.w64.b0", !98, i64 0}
!98 = !{!"0x5646c1f2f6a0.w128.b0", !99, i64 0}
!99 = !{!"0x5646c1f2f6a0.w256.b0", !100, i64 0}
!100 = !{!"0x5646c1f2f6a0.w512.b0", !101, i64 0}
!101 = !{!"0x5646c1f2f6a0.w1024.b0", !102, i64 0}
!102 = !{!"int64", !103, i64 0}
!103 = !{!"0x5646c1f2f6a0", !8, i64 0}
!104 = !{!105, !105, i64 0}
!105 = !{!"0x5646c1f2f6a0.w1.b4", !106, i64 0}
!106 = !{!"0x5646c1f2f6a0.w2.b4", !107, i64 0}
!107 = !{!"0x5646c1f2f6a0.w4.b4", !94, i64 0}
!108 = !{!109, !109, i64 0}
!109 = !{!"float32", !110, i64 0}
!110 = !{!"0x5646c1ee35b0", !8, i64 0}
!111 = !{!112, !112, i64 0}
!112 = !{!"float32", !113, i64 0}
!113 = !{!"0x5646bcbb3360", !8, i64 0}
!114 = !{!115, !115, i64 0}
!115 = !{!"0x5646bd6d5bf0.w1.b0", !116, i64 0}
!116 = !{!"0x5646bd6d5bf0.w2.b0", !117, i64 0}
!117 = !{!"0x5646bd6d5bf0.w4.b0", !118, i64 0}
!118 = !{!"0x5646bd6d5bf0.w8.b0", !119, i64 0}
!119 = !{!"0x5646bd6d5bf0.w16.b0", !120, i64 0}
!120 = !{!"0x5646bd6d5bf0.w32.b0", !121, i64 0}
!121 = !{!"0x5646bd6d5bf0.w64.b0", !122, i64 0}
!122 = !{!"0x5646bd6d5bf0.w128.b0", !123, i64 0}
!123 = !{!"0x5646bd6d5bf0.w256.b0", !124, i64 0}
!124 = !{!"0x5646bd6d5bf0.w512.b0", !125, i64 0}
!125 = !{!"0x5646bd6d5bf0.w1024.b0", !126, i64 0}
!126 = !{!"int32", !127, i64 0}
!127 = !{!"0x5646bd6d5bf0", !8, i64 0}
!128 = !{!129, !129, i64 0}
!129 = !{!"0x5646bd6d5bf0.w1.b1", !116, i64 0}
!130 = !{!131, !131, i64 0}
!131 = !{!"0x5646c1e86660.w1.b0", !132, i64 0}
!132 = !{!"0x5646c1e86660.w2.b0", !133, i64 0}
!133 = !{!"0x5646c1e86660.w4.b0", !134, i64 0}
!134 = !{!"0x5646c1e86660.w8.b0", !135, i64 0}
!135 = !{!"0x5646c1e86660.w16.b0", !136, i64 0}
!136 = !{!"0x5646c1e86660.w32.b0", !137, i64 0}
!137 = !{!"0x5646c1e86660.w64.b0", !138, i64 0}
!138 = !{!"0x5646c1e86660.w128.b0", !139, i64 0}
!139 = !{!"0x5646c1e86660.w256.b0", !140, i64 0}
!140 = !{!"0x5646c1e86660.w512.b0", !141, i64 0}
!141 = !{!"0x5646c1e86660.w1024.b0", !142, i64 0}
!142 = !{!"int64", !143, i64 0}
!143 = !{!"0x5646c1e86660", !8, i64 0}
!144 = !{!145, !145, i64 0}
!145 = !{!"0x5646c1e86660.w1.b1", !132, i64 0}
!146 = !{!147, !147, i64 0}
!147 = !{!"0x5646c1e86660.w1.b2", !148, i64 0}
!148 = !{!"0x5646c1e86660.w2.b2", !133, i64 0}
!149 = !{!150, !150, i64 0}
!150 = !{!"0x5646c1e86660.w1.b3", !148, i64 0}
!151 = !{!152, !152, i64 0}
!152 = !{!"0x5646c1e86660.w1.b4", !153, i64 0}
!153 = !{!"0x5646c1e86660.w2.b4", !154, i64 0}
!154 = !{!"0x5646c1e86660.w4.b4", !134, i64 0}
!155 = !{!156, !156, i64 0}
!156 = !{!"0x5646bc828f50.w4.b0", !157, i64 0}
!157 = !{!"0x5646bc828f50.w8.b0", !158, i64 0}
!158 = !{!"0x5646bc828f50.w16.b0", !159, i64 0}
!159 = !{!"0x5646bc828f50.w32.b0", !160, i64 0}
!160 = !{!"0x5646bc828f50.w64.b0", !161, i64 0}
!161 = !{!"0x5646bc828f50.w128.b0", !162, i64 0}
!162 = !{!"0x5646bc828f50.w256.b0", !163, i64 0}
!163 = !{!"0x5646bc828f50.w512.b0", !164, i64 0}
!164 = !{!"0x5646bc828f50.w1024.b0", !165, i64 0}
!165 = !{!"int64", !166, i64 0}
!166 = !{!"0x5646bc828f50", !8, i64 0}
!167 = !{!168, !168, i64 0}
!168 = !{!"0x5646bc828f50.w1.b4", !169, i64 0}
!169 = !{!"0x5646bc828f50.w2.b4", !170, i64 0}
!170 = !{!"0x5646bc828f50.w4.b4", !157, i64 0}
!171 = !{!172, !172, i64 0}
!172 = !{!"0x5646bda72970.w1.b0", !173, i64 0}
!173 = !{!"0x5646bda72970.w2.b0", !174, i64 0}
!174 = !{!"0x5646bda72970.w4.b0", !175, i64 0}
!175 = !{!"0x5646bda72970.w8.b0", !176, i64 0}
!176 = !{!"0x5646bda72970.w16.b0", !177, i64 0}
!177 = !{!"0x5646bda72970.w32.b0", !178, i64 0}
!178 = !{!"0x5646bda72970.w64.b0", !179, i64 0}
!179 = !{!"0x5646bda72970.w128.b0", !180, i64 0}
!180 = !{!"0x5646bda72970.w256.b0", !181, i64 0}
!181 = !{!"0x5646bda72970.w512.b0", !182, i64 0}
!182 = !{!"0x5646bda72970.w1024.b0", !183, i64 0}
!183 = !{!"int64", !184, i64 0}
!184 = !{!"0x5646bda72970", !8, i64 0}
!185 = !{!186, !186, i64 0}
!186 = !{!"0x5646bda72970.w1.b1", !173, i64 0}
!187 = !{!188, !188, i64 0}
!188 = !{!"0x5646bd7154c0.w1.b0", !189, i64 0}
!189 = !{!"0x5646bd7154c0.w2.b0", !190, i64 0}
!190 = !{!"0x5646bd7154c0.w4.b0", !191, i64 0}
!191 = !{!"0x5646bd7154c0.w8.b0", !192, i64 0}
!192 = !{!"0x5646bd7154c0.w16.b0", !193, i64 0}
!193 = !{!"0x5646bd7154c0.w32.b0", !194, i64 0}
!194 = !{!"0x5646bd7154c0.w64.b0", !195, i64 0}
!195 = !{!"0x5646bd7154c0.w128.b0", !196, i64 0}
!196 = !{!"0x5646bd7154c0.w256.b0", !197, i64 0}
!197 = !{!"0x5646bd7154c0.w512.b0", !198, i64 0}
!198 = !{!"0x5646bd7154c0.w1024.b0", !199, i64 0}
!199 = !{!"int64", !200, i64 0}
!200 = !{!"0x5646bd7154c0", !8, i64 0}
!201 = !{!202, !202, i64 0}
!202 = !{!"0x5646bd7154c0.w1.b1", !189, i64 0}
!203 = !{!204, !204, i64 0}
!204 = !{!"0x5646bc977ca0.w1.b0", !205, i64 0}
!205 = !{!"0x5646bc977ca0.w2.b0", !206, i64 0}
!206 = !{!"0x5646bc977ca0.w4.b0", !207, i64 0}
!207 = !{!"0x5646bc977ca0.w8.b0", !208, i64 0}
!208 = !{!"0x5646bc977ca0.w16.b0", !209, i64 0}
!209 = !{!"0x5646bc977ca0.w32.b0", !210, i64 0}
!210 = !{!"0x5646bc977ca0.w64.b0", !211, i64 0}
!211 = !{!"0x5646bc977ca0.w128.b0", !212, i64 0}
!212 = !{!"0x5646bc977ca0.w256.b0", !213, i64 0}
!213 = !{!"0x5646bc977ca0.w512.b0", !214, i64 0}
!214 = !{!"0x5646bc977ca0.w1024.b0", !215, i64 0}
!215 = !{!"int32", !216, i64 0}
!216 = !{!"0x5646bc977ca0", !8, i64 0}
!217 = !{!218, !218, i64 0}
!218 = !{!"0x5646bc977ca0.w1.b2", !219, i64 0}
!219 = !{!"0x5646bc977ca0.w2.b2", !206, i64 0}
!220 = !{!221, !221, i64 0}
!221 = !{!"0x5646bc977ca0.w1.b3", !219, i64 0}
!222 = !{!223, !223, i64 0}
!223 = !{!"0x5646bc977ca0.w1.b4", !224, i64 0}
!224 = !{!"0x5646bc977ca0.w2.b4", !225, i64 0}
!225 = !{!"0x5646bc977ca0.w4.b4", !207, i64 0}
!226 = !{!227, !227, i64 0}
!227 = !{!"0x5646bc977ca0.w1.b1", !205, i64 0}
!228 = !{!229, !229, i64 0}
!229 = !{!"0x5646bd4fecc0.w1.b0", !230, i64 0}
!230 = !{!"0x5646bd4fecc0.w2.b0", !231, i64 0}
!231 = !{!"0x5646bd4fecc0.w4.b0", !232, i64 0}
!232 = !{!"0x5646bd4fecc0.w8.b0", !233, i64 0}
!233 = !{!"0x5646bd4fecc0.w16.b0", !234, i64 0}
!234 = !{!"0x5646bd4fecc0.w32.b0", !235, i64 0}
!235 = !{!"0x5646bd4fecc0.w64.b0", !236, i64 0}
!236 = !{!"0x5646bd4fecc0.w128.b0", !237, i64 0}
!237 = !{!"0x5646bd4fecc0.w256.b0", !238, i64 0}
!238 = !{!"0x5646bd4fecc0.w512.b0", !239, i64 0}
!239 = !{!"0x5646bd4fecc0.w1024.b0", !240, i64 0}
!240 = !{!"int64", !241, i64 0}
!241 = !{!"0x5646bd4fecc0", !8, i64 0}
!242 = !{!243, !243, i64 0}
!243 = !{!"0x5646bd4fecc0.w1.b1", !230, i64 0}
!244 = !{!245, !245, i64 0}
!245 = !{!"0x5646bd4fecc0.w1.b2", !246, i64 0}
!246 = !{!"0x5646bd4fecc0.w2.b2", !231, i64 0}
!247 = !{!248, !248, i64 0}
!248 = !{!"0x5646bd4fecc0.w1.b3", !246, i64 0}
!249 = !{!250, !250, i64 0}
!250 = !{!"0x5646bd4fecc0.w1.b4", !251, i64 0}
!251 = !{!"0x5646bd4fecc0.w2.b4", !252, i64 0}
!252 = !{!"0x5646bd4fecc0.w4.b4", !232, i64 0}
!253 = !{!254, !254, i64 0}
!254 = !{!"0x5646bd501a00.w4.b0", !255, i64 0}
!255 = !{!"0x5646bd501a00.w8.b0", !256, i64 0}
!256 = !{!"0x5646bd501a00.w16.b0", !257, i64 0}
!257 = !{!"0x5646bd501a00.w32.b0", !258, i64 0}
!258 = !{!"0x5646bd501a00.w64.b0", !259, i64 0}
!259 = !{!"0x5646bd501a00.w128.b0", !260, i64 0}
!260 = !{!"0x5646bd501a00.w256.b0", !261, i64 0}
!261 = !{!"0x5646bd501a00.w512.b0", !262, i64 0}
!262 = !{!"0x5646bd501a00.w1024.b0", !263, i64 0}
!263 = !{!"int64", !264, i64 0}
!264 = !{!"0x5646bd501a00", !8, i64 0}
!265 = !{!266, !266, i64 0}
!266 = !{!"0x5646bd501a00.w1.b4", !267, i64 0}
!267 = !{!"0x5646bd501a00.w2.b4", !268, i64 0}
!268 = !{!"0x5646bd501a00.w4.b4", !255, i64 0}
!269 = !{!270, !270, i64 0}
!270 = !{!"0x5646bd5033f0.w1.b0", !271, i64 0}
!271 = !{!"0x5646bd5033f0.w2.b0", !272, i64 0}
!272 = !{!"0x5646bd5033f0.w4.b0", !273, i64 0}
!273 = !{!"0x5646bd5033f0.w8.b0", !274, i64 0}
!274 = !{!"0x5646bd5033f0.w16.b0", !275, i64 0}
!275 = !{!"0x5646bd5033f0.w32.b0", !276, i64 0}
!276 = !{!"0x5646bd5033f0.w64.b0", !277, i64 0}
!277 = !{!"0x5646bd5033f0.w128.b0", !278, i64 0}
!278 = !{!"0x5646bd5033f0.w256.b0", !279, i64 0}
!279 = !{!"0x5646bd5033f0.w512.b0", !280, i64 0}
!280 = !{!"0x5646bd5033f0.w1024.b0", !281, i64 0}
!281 = !{!"int64", !282, i64 0}
!282 = !{!"0x5646bd5033f0", !8, i64 0}
!283 = !{!284, !284, i64 0}
!284 = !{!"0x5646bd5033f0.w1.b1", !271, i64 0}
!285 = !{!286, !286, i64 0}
!286 = !{!"0x5646bd5033f0.w1.b2", !287, i64 0}
!287 = !{!"0x5646bd5033f0.w2.b2", !272, i64 0}
!288 = !{!289, !289, i64 0}
!289 = !{!"0x5646bd5033f0.w1.b3", !287, i64 0}
!290 = !{!291, !291, i64 0}
!291 = !{!"0x5646bd5033f0.w1.b4", !292, i64 0}
!292 = !{!"0x5646bd5033f0.w2.b4", !293, i64 0}
!293 = !{!"0x5646bd5033f0.w4.b4", !273, i64 0}
!294 = !{!295, !295, i64 0}
!295 = !{!"0x5646bd5033f0.w1.b5", !292, i64 0}
!296 = !{!297, !297, i64 0}
!297 = !{!"0x5646bd500870.w4.b0", !298, i64 0}
!298 = !{!"0x5646bd500870.w8.b0", !299, i64 0}
!299 = !{!"0x5646bd500870.w16.b0", !300, i64 0}
!300 = !{!"0x5646bd500870.w32.b0", !301, i64 0}
!301 = !{!"0x5646bd500870.w64.b0", !302, i64 0}
!302 = !{!"0x5646bd500870.w128.b0", !303, i64 0}
!303 = !{!"0x5646bd500870.w256.b0", !304, i64 0}
!304 = !{!"0x5646bd500870.w512.b0", !305, i64 0}
!305 = !{!"0x5646bd500870.w1024.b0", !306, i64 0}
!306 = !{!"int64", !307, i64 0}
!307 = !{!"0x5646bd500870", !8, i64 0}
!308 = !{!309, !309, i64 0}
!309 = !{!"0x5646bd500870.w1.b4", !310, i64 0}
!310 = !{!"0x5646bd500870.w2.b4", !311, i64 0}
!311 = !{!"0x5646bd500870.w4.b4", !298, i64 0}
!312 = !{!313, !313, i64 0}
!313 = !{!"0x5646bd500870.w1.b5", !310, i64 0}
!314 = !{!315, !315, i64 0}
!315 = !{!"0x5646bd505f60.w1.b0", !316, i64 0}
!316 = !{!"0x5646bd505f60.w2.b0", !317, i64 0}
!317 = !{!"0x5646bd505f60.w4.b0", !318, i64 0}
!318 = !{!"0x5646bd505f60.w8.b0", !319, i64 0}
!319 = !{!"0x5646bd505f60.w16.b0", !320, i64 0}
!320 = !{!"0x5646bd505f60.w32.b0", !321, i64 0}
!321 = !{!"0x5646bd505f60.w64.b0", !322, i64 0}
!322 = !{!"0x5646bd505f60.w128.b0", !323, i64 0}
!323 = !{!"0x5646bd505f60.w256.b0", !324, i64 0}
!324 = !{!"0x5646bd505f60.w512.b0", !325, i64 0}
!325 = !{!"0x5646bd505f60.w1024.b0", !326, i64 0}
!326 = !{!"int64", !327, i64 0}
!327 = !{!"0x5646bd505f60", !8, i64 0}
!328 = !{!329, !329, i64 0}
!329 = !{!"0x5646bd505f60.w1.b1", !316, i64 0}
!330 = !{!331, !331, i64 0}
!331 = !{!"0x5646bd505f60.w1.b2", !332, i64 0}
!332 = !{!"0x5646bd505f60.w2.b2", !317, i64 0}
!333 = !{!334, !334, i64 0}
!334 = !{!"0x5646bd505f60.w1.b3", !332, i64 0}
!335 = !{!336, !336, i64 0}
!336 = !{!"0x5646bd505f60.w1.b4", !337, i64 0}
!337 = !{!"0x5646bd505f60.w2.b4", !338, i64 0}
!338 = !{!"0x5646bd505f60.w4.b4", !318, i64 0}
!339 = !{!340, !340, i64 0}
!340 = !{!"0x5646bc978ed0.w4.b0", !341, i64 0}
!341 = !{!"0x5646bc978ed0.w8.b0", !342, i64 0}
!342 = !{!"0x5646bc978ed0.w16.b0", !343, i64 0}
!343 = !{!"0x5646bc978ed0.w32.b0", !344, i64 0}
!344 = !{!"0x5646bc978ed0.w64.b0", !345, i64 0}
!345 = !{!"0x5646bc978ed0.w128.b0", !346, i64 0}
!346 = !{!"0x5646bc978ed0.w256.b0", !347, i64 0}
!347 = !{!"0x5646bc978ed0.w512.b0", !348, i64 0}
!348 = !{!"0x5646bc978ed0.w1024.b0", !349, i64 0}
!349 = !{!"int64", !350, i64 0}
!350 = !{!"0x5646bc978ed0", !8, i64 0}
!351 = !{!352, !352, i64 0}
!352 = !{!"0x5646bc978ed0.w1.b4", !353, i64 0}
!353 = !{!"0x5646bc978ed0.w2.b4", !354, i64 0}
!354 = !{!"0x5646bc978ed0.w4.b4", !341, i64 0}
!355 = !{!356, !356, i64 0}
!356 = !{!"0x5646bc97a0f0.w1.b0", !357, i64 0}
!357 = !{!"0x5646bc97a0f0.w2.b0", !358, i64 0}
!358 = !{!"0x5646bc97a0f0.w4.b0", !359, i64 0}
!359 = !{!"0x5646bc97a0f0.w8.b0", !360, i64 0}
!360 = !{!"0x5646bc97a0f0.w16.b0", !361, i64 0}
!361 = !{!"0x5646bc97a0f0.w32.b0", !362, i64 0}
!362 = !{!"0x5646bc97a0f0.w64.b0", !363, i64 0}
!363 = !{!"0x5646bc97a0f0.w128.b0", !364, i64 0}
!364 = !{!"0x5646bc97a0f0.w256.b0", !365, i64 0}
!365 = !{!"0x5646bc97a0f0.w512.b0", !366, i64 0}
!366 = !{!"0x5646bc97a0f0.w1024.b0", !367, i64 0}
!367 = !{!"int64", !368, i64 0}
!368 = !{!"0x5646bc97a0f0", !8, i64 0}
!369 = !{!370, !370, i64 0}
!370 = !{!"0x5646bc97a0f0.w1.b1", !357, i64 0}
!371 = !{!372, !372, i64 0}
!372 = !{!"0x5646bc97a0f0.w1.b2", !373, i64 0}
!373 = !{!"0x5646bc97a0f0.w2.b2", !358, i64 0}
!374 = !{!375, !375, i64 0}
!375 = !{!"0x5646bc97a0f0.w1.b3", !373, i64 0}
!376 = !{!377, !377, i64 0}
!377 = !{!"0x5646bc97a0f0.w1.b4", !378, i64 0}
!378 = !{!"0x5646bc97a0f0.w2.b4", !379, i64 0}
!379 = !{!"0x5646bc97a0f0.w4.b4", !359, i64 0}
!380 = !{!381, !381, i64 0}
!381 = !{!"0x5646bc97a140.w4.b0", !382, i64 0}
!382 = !{!"0x5646bc97a140.w8.b0", !383, i64 0}
!383 = !{!"0x5646bc97a140.w16.b0", !384, i64 0}
!384 = !{!"0x5646bc97a140.w32.b0", !385, i64 0}
!385 = !{!"0x5646bc97a140.w64.b0", !386, i64 0}
!386 = !{!"0x5646bc97a140.w128.b0", !387, i64 0}
!387 = !{!"0x5646bc97a140.w256.b0", !388, i64 0}
!388 = !{!"0x5646bc97a140.w512.b0", !389, i64 0}
!389 = !{!"0x5646bc97a140.w1024.b0", !390, i64 0}
!390 = !{!"int64", !391, i64 0}
!391 = !{!"0x5646bc97a140", !8, i64 0}
!392 = !{!393, !393, i64 0}
!393 = !{!"0x5646bc97a140.w1.b4", !394, i64 0}
!394 = !{!"0x5646bc97a140.w2.b4", !395, i64 0}
!395 = !{!"0x5646bc97a140.w4.b4", !382, i64 0}
!396 = !{!397, !397, i64 0}
!397 = !{!"0x5646bc97b750.w1.b0", !398, i64 0}
!398 = !{!"0x5646bc97b750.w2.b0", !399, i64 0}
!399 = !{!"0x5646bc97b750.w4.b0", !400, i64 0}
!400 = !{!"0x5646bc97b750.w8.b0", !401, i64 0}
!401 = !{!"0x5646bc97b750.w16.b0", !402, i64 0}
!402 = !{!"0x5646bc97b750.w32.b0", !403, i64 0}
!403 = !{!"0x5646bc97b750.w64.b0", !404, i64 0}
!404 = !{!"0x5646bc97b750.w128.b0", !405, i64 0}
!405 = !{!"0x5646bc97b750.w256.b0", !406, i64 0}
!406 = !{!"0x5646bc97b750.w512.b0", !407, i64 0}
!407 = !{!"0x5646bc97b750.w1024.b0", !408, i64 0}
!408 = !{!"int64", !409, i64 0}
!409 = !{!"0x5646bc97b750", !8, i64 0}
!410 = !{!411, !411, i64 0}
!411 = !{!"0x5646bc97b750.w1.b1", !398, i64 0}
!412 = !{!413, !413, i64 0}
!413 = !{!"0x5646bc97b750.w1.b2", !414, i64 0}
!414 = !{!"0x5646bc97b750.w2.b2", !399, i64 0}
!415 = !{!416, !416, i64 0}
!416 = !{!"0x5646bc97b750.w1.b3", !414, i64 0}
!417 = !{!418, !418, i64 0}
!418 = !{!"0x5646bc97b750.w1.b4", !419, i64 0}
!419 = !{!"0x5646bc97b750.w2.b4", !420, i64 0}
!420 = !{!"0x5646bc97b750.w4.b4", !400, i64 0}
!421 = !{!422, !422, i64 0}
!422 = !{!"0x5646bc97cb20.w4.b0", !423, i64 0}
!423 = !{!"0x5646bc97cb20.w8.b0", !424, i64 0}
!424 = !{!"0x5646bc97cb20.w16.b0", !425, i64 0}
!425 = !{!"0x5646bc97cb20.w32.b0", !426, i64 0}
!426 = !{!"0x5646bc97cb20.w64.b0", !427, i64 0}
!427 = !{!"0x5646bc97cb20.w128.b0", !428, i64 0}
!428 = !{!"0x5646bc97cb20.w256.b0", !429, i64 0}
!429 = !{!"0x5646bc97cb20.w512.b0", !430, i64 0}
!430 = !{!"0x5646bc97cb20.w1024.b0", !431, i64 0}
!431 = !{!"int64", !432, i64 0}
!432 = !{!"0x5646bc97cb20", !8, i64 0}
!433 = !{!434, !434, i64 0}
!434 = !{!"0x5646bc97cb20.w1.b4", !435, i64 0}
!435 = !{!"0x5646bc97cb20.w2.b4", !436, i64 0}
!436 = !{!"0x5646bc97cb20.w4.b4", !423, i64 0}
!437 = !{!438, !438, i64 0}
!438 = !{!"float32", !439, i64 0}
!439 = !{!"0x5646bd4fe3b0", !8, i64 0}
!440 = !{!441, !441, i64 0}
!441 = !{!"float32", !442, i64 0}
!442 = !{!"0x5646bd4ffc20", !8, i64 0}
!443 = !{!444, !444, i64 0}
!444 = !{!"float32", !445, i64 0}
!445 = !{!"0x5646bd4ff210", !8, i64 0}
!446 = !{!447, !447, i64 0}
!447 = !{!"float32", !448, i64 0}
!448 = !{!"0x5646bd4ffa30", !8, i64 0}
!449 = !{!450, !450, i64 0}
!450 = !{!"float32", !451, i64 0}
!451 = !{!"0x5646bd4ff350", !8, i64 0}
!452 = !{!453, !453, i64 0}
!453 = !{!"float32", !454, i64 0}
!454 = !{!"0x5646bd4fc6f0", !8, i64 0}
!455 = !{!456, !456, i64 0}
!456 = !{!"float32", !457, i64 0}
!457 = !{!"0x5646bd4ff260", !8, i64 0}
!458 = !{!459, !459, i64 0}
!459 = !{!"0x5646bd4ff7e0.w32.b0", !460, i64 0}
!460 = !{!"0x5646bd4ff7e0.w64.b0", !461, i64 0}
!461 = !{!"0x5646bd4ff7e0.w128.b0", !462, i64 0}
!462 = !{!"0x5646bd4ff7e0.w256.b0", !463, i64 0}
!463 = !{!"0x5646bd4ff7e0.w512.b0", !464, i64 0}
!464 = !{!"0x5646bd4ff7e0.w1024.b0", !465, i64 0}
!465 = !{!"float32", !466, i64 0}
!466 = !{!"0x5646bd4ff7e0", !8, i64 0}
!467 = !{!468, !468, i64 0}
!468 = !{!"0x5646c18eee20.w1.b0", !469, i64 0}
!469 = !{!"0x5646c18eee20.w2.b0", !470, i64 0}
!470 = !{!"0x5646c18eee20.w4.b0", !471, i64 0}
!471 = !{!"0x5646c18eee20.w8.b0", !472, i64 0}
!472 = !{!"0x5646c18eee20.w16.b0", !473, i64 0}
!473 = !{!"0x5646c18eee20.w32.b0", !474, i64 0}
!474 = !{!"0x5646c18eee20.w64.b0", !475, i64 0}
!475 = !{!"0x5646c18eee20.w128.b0", !476, i64 0}
!476 = !{!"0x5646c18eee20.w256.b0", !477, i64 0}
!477 = !{!"0x5646c18eee20.w512.b0", !478, i64 0}
!478 = !{!"0x5646c18eee20.w1024.b0", !479, i64 0}
!479 = !{!"int32", !480, i64 0}
!480 = !{!"0x5646c18eee20", !8, i64 0}
!481 = !{!482, !482, i64 0}
!482 = !{!"0x5646c18eee20.w1.b2", !483, i64 0}
!483 = !{!"0x5646c18eee20.w2.b2", !470, i64 0}
!484 = !{!485, !485, i64 0}
!485 = !{!"0x5646c18eee20.w1.b3", !483, i64 0}
!486 = !{!487, !487, i64 0}
!487 = !{!"0x5646c18eee20.w1.b4", !488, i64 0}
!488 = !{!"0x5646c18eee20.w2.b4", !489, i64 0}
!489 = !{!"0x5646c18eee20.w4.b4", !471, i64 0}
!490 = !{!491, !491, i64 0}
!491 = !{!"0x5646c18eee20.w1.b1", !469, i64 0}
!492 = !{!493, !493, i64 0}
!493 = !{!"0x5646c4119240.w1.b0", !494, i64 0}
!494 = !{!"0x5646c4119240.w2.b0", !495, i64 0}
!495 = !{!"0x5646c4119240.w4.b0", !496, i64 0}
!496 = !{!"0x5646c4119240.w8.b0", !497, i64 0}
!497 = !{!"0x5646c4119240.w16.b0", !498, i64 0}
!498 = !{!"0x5646c4119240.w32.b0", !499, i64 0}
!499 = !{!"0x5646c4119240.w64.b0", !500, i64 0}
!500 = !{!"0x5646c4119240.w128.b0", !501, i64 0}
!501 = !{!"0x5646c4119240.w256.b0", !502, i64 0}
!502 = !{!"0x5646c4119240.w512.b0", !503, i64 0}
!503 = !{!"0x5646c4119240.w1024.b0", !504, i64 0}
!504 = !{!"int64", !505, i64 0}
!505 = !{!"0x5646c4119240", !8, i64 0}
!506 = !{!507, !507, i64 0}
!507 = !{!"0x5646c4119240.w1.b1", !494, i64 0}
!508 = !{!509, !509, i64 0}
!509 = !{!"0x5646c4119240.w1.b2", !510, i64 0}
!510 = !{!"0x5646c4119240.w2.b2", !495, i64 0}
!511 = !{!512, !512, i64 0}
!512 = !{!"0x5646c4119240.w1.b3", !510, i64 0}
!513 = !{!514, !514, i64 0}
!514 = !{!"0x5646c4119240.w1.b4", !515, i64 0}
!515 = !{!"0x5646c4119240.w2.b4", !516, i64 0}
!516 = !{!"0x5646c4119240.w4.b4", !496, i64 0}
!517 = !{!518, !518, i64 0}
!518 = !{!"0x5646c19d3010.w4.b0", !519, i64 0}
!519 = !{!"0x5646c19d3010.w8.b0", !520, i64 0}
!520 = !{!"0x5646c19d3010.w16.b0", !521, i64 0}
!521 = !{!"0x5646c19d3010.w32.b0", !522, i64 0}
!522 = !{!"0x5646c19d3010.w64.b0", !523, i64 0}
!523 = !{!"0x5646c19d3010.w128.b0", !524, i64 0}
!524 = !{!"0x5646c19d3010.w256.b0", !525, i64 0}
!525 = !{!"0x5646c19d3010.w512.b0", !526, i64 0}
!526 = !{!"0x5646c19d3010.w1024.b0", !527, i64 0}
!527 = !{!"int64", !528, i64 0}
!528 = !{!"0x5646c19d3010", !8, i64 0}
!529 = !{!530, !530, i64 0}
!530 = !{!"0x5646c19d3010.w1.b4", !531, i64 0}
!531 = !{!"0x5646c19d3010.w2.b4", !532, i64 0}
!532 = !{!"0x5646c19d3010.w4.b4", !519, i64 0}
!533 = !{!534, !534, i64 0}
!534 = !{!"0x5646c19d30b0.w1.b0", !535, i64 0}
!535 = !{!"0x5646c19d30b0.w2.b0", !536, i64 0}
!536 = !{!"0x5646c19d30b0.w4.b0", !537, i64 0}
!537 = !{!"0x5646c19d30b0.w8.b0", !538, i64 0}
!538 = !{!"0x5646c19d30b0.w16.b0", !539, i64 0}
!539 = !{!"0x5646c19d30b0.w32.b0", !540, i64 0}
!540 = !{!"0x5646c19d30b0.w64.b0", !541, i64 0}
!541 = !{!"0x5646c19d30b0.w128.b0", !542, i64 0}
!542 = !{!"0x5646c19d30b0.w256.b0", !543, i64 0}
!543 = !{!"0x5646c19d30b0.w512.b0", !544, i64 0}
!544 = !{!"0x5646c19d30b0.w1024.b0", !545, i64 0}
!545 = !{!"int64", !546, i64 0}
!546 = !{!"0x5646c19d30b0", !8, i64 0}
!547 = !{!548, !548, i64 0}
!548 = !{!"0x5646c19d30b0.w1.b1", !535, i64 0}
!549 = !{!550, !550, i64 0}
!550 = !{!"0x5646c19d30b0.w1.b2", !551, i64 0}
!551 = !{!"0x5646c19d30b0.w2.b2", !536, i64 0}
!552 = !{!553, !553, i64 0}
!553 = !{!"0x5646c19d30b0.w1.b3", !551, i64 0}
!554 = !{!555, !555, i64 0}
!555 = !{!"0x5646c19d30b0.w1.b4", !556, i64 0}
!556 = !{!"0x5646c19d30b0.w2.b4", !557, i64 0}
!557 = !{!"0x5646c19d30b0.w4.b4", !537, i64 0}
!558 = !{!559, !559, i64 0}
!559 = !{!"0x5646c19d30b0.w1.b5", !556, i64 0}
!560 = !{!561, !561, i64 0}
!561 = !{!"0x5646c19d2fc0.w4.b0", !562, i64 0}
!562 = !{!"0x5646c19d2fc0.w8.b0", !563, i64 0}
!563 = !{!"0x5646c19d2fc0.w16.b0", !564, i64 0}
!564 = !{!"0x5646c19d2fc0.w32.b0", !565, i64 0}
!565 = !{!"0x5646c19d2fc0.w64.b0", !566, i64 0}
!566 = !{!"0x5646c19d2fc0.w128.b0", !567, i64 0}
!567 = !{!"0x5646c19d2fc0.w256.b0", !568, i64 0}
!568 = !{!"0x5646c19d2fc0.w512.b0", !569, i64 0}
!569 = !{!"0x5646c19d2fc0.w1024.b0", !570, i64 0}
!570 = !{!"int64", !571, i64 0}
!571 = !{!"0x5646c19d2fc0", !8, i64 0}
!572 = !{!573, !573, i64 0}
!573 = !{!"0x5646c19d2fc0.w1.b4", !574, i64 0}
!574 = !{!"0x5646c19d2fc0.w2.b4", !575, i64 0}
!575 = !{!"0x5646c19d2fc0.w4.b4", !562, i64 0}
!576 = !{!577, !577, i64 0}
!577 = !{!"0x5646c19d2fc0.w1.b5", !574, i64 0}
!578 = !{!579, !579, i64 0}
!579 = !{!"0x5646c1ac22c0.w1.b0", !580, i64 0}
!580 = !{!"0x5646c1ac22c0.w2.b0", !581, i64 0}
!581 = !{!"0x5646c1ac22c0.w4.b0", !582, i64 0}
!582 = !{!"0x5646c1ac22c0.w8.b0", !583, i64 0}
!583 = !{!"0x5646c1ac22c0.w16.b0", !584, i64 0}
!584 = !{!"0x5646c1ac22c0.w32.b0", !585, i64 0}
!585 = !{!"0x5646c1ac22c0.w64.b0", !586, i64 0}
!586 = !{!"0x5646c1ac22c0.w128.b0", !587, i64 0}
!587 = !{!"0x5646c1ac22c0.w256.b0", !588, i64 0}
!588 = !{!"0x5646c1ac22c0.w512.b0", !589, i64 0}
!589 = !{!"0x5646c1ac22c0.w1024.b0", !590, i64 0}
!590 = !{!"int64", !591, i64 0}
!591 = !{!"0x5646c1ac22c0", !8, i64 0}
!592 = !{!593, !593, i64 0}
!593 = !{!"0x5646c1ac22c0.w1.b1", !580, i64 0}
!594 = !{!595, !595, i64 0}
!595 = !{!"0x5646c1ac22c0.w1.b2", !596, i64 0}
!596 = !{!"0x5646c1ac22c0.w2.b2", !581, i64 0}
!597 = !{!598, !598, i64 0}
!598 = !{!"0x5646c1ac22c0.w1.b3", !596, i64 0}
!599 = !{!600, !600, i64 0}
!600 = !{!"0x5646c1ac22c0.w1.b4", !601, i64 0}
!601 = !{!"0x5646c1ac22c0.w2.b4", !602, i64 0}
!602 = !{!"0x5646c1ac22c0.w4.b4", !582, i64 0}
!603 = !{!604, !604, i64 0}
!604 = !{!"0x5646c1e24840.w4.b0", !605, i64 0}
!605 = !{!"0x5646c1e24840.w8.b0", !606, i64 0}
!606 = !{!"0x5646c1e24840.w16.b0", !607, i64 0}
!607 = !{!"0x5646c1e24840.w32.b0", !608, i64 0}
!608 = !{!"0x5646c1e24840.w64.b0", !609, i64 0}
!609 = !{!"0x5646c1e24840.w128.b0", !610, i64 0}
!610 = !{!"0x5646c1e24840.w256.b0", !611, i64 0}
!611 = !{!"0x5646c1e24840.w512.b0", !612, i64 0}
!612 = !{!"0x5646c1e24840.w1024.b0", !613, i64 0}
!613 = !{!"int64", !614, i64 0}
!614 = !{!"0x5646c1e24840", !8, i64 0}
!615 = !{!616, !616, i64 0}
!616 = !{!"0x5646c1e24840.w1.b4", !617, i64 0}
!617 = !{!"0x5646c1e24840.w2.b4", !618, i64 0}
!618 = !{!"0x5646c1e24840.w4.b4", !605, i64 0}
!619 = !{!620, !620, i64 0}
!620 = !{!"0x5646c1e25210.w1.b0", !621, i64 0}
!621 = !{!"0x5646c1e25210.w2.b0", !622, i64 0}
!622 = !{!"0x5646c1e25210.w4.b0", !623, i64 0}
!623 = !{!"0x5646c1e25210.w8.b0", !624, i64 0}
!624 = !{!"0x5646c1e25210.w16.b0", !625, i64 0}
!625 = !{!"0x5646c1e25210.w32.b0", !626, i64 0}
!626 = !{!"0x5646c1e25210.w64.b0", !627, i64 0}
!627 = !{!"0x5646c1e25210.w128.b0", !628, i64 0}
!628 = !{!"0x5646c1e25210.w256.b0", !629, i64 0}
!629 = !{!"0x5646c1e25210.w512.b0", !630, i64 0}
!630 = !{!"0x5646c1e25210.w1024.b0", !631, i64 0}
!631 = !{!"int64", !632, i64 0}
!632 = !{!"0x5646c1e25210", !8, i64 0}
!633 = !{!634, !634, i64 0}
!634 = !{!"0x5646c1e25210.w1.b1", !621, i64 0}
!635 = !{!636, !636, i64 0}
!636 = !{!"0x5646c1e25210.w1.b2", !637, i64 0}
!637 = !{!"0x5646c1e25210.w2.b2", !622, i64 0}
!638 = !{!639, !639, i64 0}
!639 = !{!"0x5646c1e25210.w1.b3", !637, i64 0}
!640 = !{!641, !641, i64 0}
!641 = !{!"0x5646c1e25210.w1.b4", !642, i64 0}
!642 = !{!"0x5646c1e25210.w2.b4", !643, i64 0}
!643 = !{!"0x5646c1e25210.w4.b4", !623, i64 0}
!644 = !{!645, !645, i64 0}
!645 = !{!"0x5646c1e25260.w4.b0", !646, i64 0}
!646 = !{!"0x5646c1e25260.w8.b0", !647, i64 0}
!647 = !{!"0x5646c1e25260.w16.b0", !648, i64 0}
!648 = !{!"0x5646c1e25260.w32.b0", !649, i64 0}
!649 = !{!"0x5646c1e25260.w64.b0", !650, i64 0}
!650 = !{!"0x5646c1e25260.w128.b0", !651, i64 0}
!651 = !{!"0x5646c1e25260.w256.b0", !652, i64 0}
!652 = !{!"0x5646c1e25260.w512.b0", !653, i64 0}
!653 = !{!"0x5646c1e25260.w1024.b0", !654, i64 0}
!654 = !{!"int64", !655, i64 0}
!655 = !{!"0x5646c1e25260", !8, i64 0}
!656 = !{!657, !657, i64 0}
!657 = !{!"0x5646c1e25260.w1.b4", !658, i64 0}
!658 = !{!"0x5646c1e25260.w2.b4", !659, i64 0}
!659 = !{!"0x5646c1e25260.w4.b4", !646, i64 0}
!660 = !{!661, !661, i64 0}
!661 = !{!"0x5646c411ecd0.w1.b0", !662, i64 0}
!662 = !{!"0x5646c411ecd0.w2.b0", !663, i64 0}
!663 = !{!"0x5646c411ecd0.w4.b0", !664, i64 0}
!664 = !{!"0x5646c411ecd0.w8.b0", !665, i64 0}
!665 = !{!"0x5646c411ecd0.w16.b0", !666, i64 0}
!666 = !{!"0x5646c411ecd0.w32.b0", !667, i64 0}
!667 = !{!"0x5646c411ecd0.w64.b0", !668, i64 0}
!668 = !{!"0x5646c411ecd0.w128.b0", !669, i64 0}
!669 = !{!"0x5646c411ecd0.w256.b0", !670, i64 0}
!670 = !{!"0x5646c411ecd0.w512.b0", !671, i64 0}
!671 = !{!"0x5646c411ecd0.w1024.b0", !672, i64 0}
!672 = !{!"int64", !673, i64 0}
!673 = !{!"0x5646c411ecd0", !8, i64 0}
!674 = !{!675, !675, i64 0}
!675 = !{!"0x5646c411ecd0.w1.b1", !662, i64 0}
!676 = !{!677, !677, i64 0}
!677 = !{!"0x5646c411ecd0.w1.b2", !678, i64 0}
!678 = !{!"0x5646c411ecd0.w2.b2", !663, i64 0}
!679 = !{!680, !680, i64 0}
!680 = !{!"0x5646c411ecd0.w1.b3", !678, i64 0}
!681 = !{!682, !682, i64 0}
!682 = !{!"0x5646c411ecd0.w1.b4", !683, i64 0}
!683 = !{!"0x5646c411ecd0.w2.b4", !684, i64 0}
!684 = !{!"0x5646c411ecd0.w4.b4", !664, i64 0}
!685 = !{!686, !686, i64 0}
!686 = !{!"0x5646c1d42260.w4.b0", !687, i64 0}
!687 = !{!"0x5646c1d42260.w8.b0", !688, i64 0}
!688 = !{!"0x5646c1d42260.w16.b0", !689, i64 0}
!689 = !{!"0x5646c1d42260.w32.b0", !690, i64 0}
!690 = !{!"0x5646c1d42260.w64.b0", !691, i64 0}
!691 = !{!"0x5646c1d42260.w128.b0", !692, i64 0}
!692 = !{!"0x5646c1d42260.w256.b0", !693, i64 0}
!693 = !{!"0x5646c1d42260.w512.b0", !694, i64 0}
!694 = !{!"0x5646c1d42260.w1024.b0", !695, i64 0}
!695 = !{!"int64", !696, i64 0}
!696 = !{!"0x5646c1d42260", !8, i64 0}
!697 = !{!698, !698, i64 0}
!698 = !{!"0x5646c1d42260.w1.b4", !699, i64 0}
!699 = !{!"0x5646c1d42260.w2.b4", !700, i64 0}
!700 = !{!"0x5646c1d42260.w4.b4", !687, i64 0}
!701 = !{!702, !702, i64 0}
!702 = !{!"float32", !703, i64 0}
!703 = !{!"0x5646bbd4a5f0", !8, i64 0}
!704 = !{!705, !705, i64 0}
!705 = !{!"float32", !706, i64 0}
!706 = !{!"0x5646c1f20ed0", !8, i64 0}
!707 = !{!708, !708, i64 0}
!708 = !{!"float32", !709, i64 0}
!709 = !{!"0x5646ba155f20", !8, i64 0}
!710 = !{!711, !711, i64 0}
!711 = !{!"float32", !712, i64 0}
!712 = !{!"0x5646c18ad4b0", !8, i64 0}
!713 = !{!714, !714, i64 0}
!714 = !{!"float32", !715, i64 0}
!715 = !{!"0x5646c4194790", !8, i64 0}
!716 = !{!717, !717, i64 0}
!717 = !{!"float32", !718, i64 0}
!718 = !{!"0x5646bc480e90", !8, i64 0}
!719 = !{!720, !720, i64 0}
!720 = !{!"0x5646c08a8590.w1.b0", !721, i64 0}
!721 = !{!"0x5646c08a8590.w2.b0", !722, i64 0}
!722 = !{!"0x5646c08a8590.w4.b0", !723, i64 0}
!723 = !{!"0x5646c08a8590.w8.b0", !724, i64 0}
!724 = !{!"0x5646c08a8590.w16.b0", !725, i64 0}
!725 = !{!"0x5646c08a8590.w32.b0", !726, i64 0}
!726 = !{!"0x5646c08a8590.w64.b0", !727, i64 0}
!727 = !{!"0x5646c08a8590.w128.b0", !728, i64 0}
!728 = !{!"0x5646c08a8590.w256.b0", !729, i64 0}
!729 = !{!"0x5646c08a8590.w512.b0", !730, i64 0}
!730 = !{!"0x5646c08a8590.w1024.b0", !731, i64 0}
!731 = !{!"int32", !732, i64 0}
!732 = !{!"0x5646c08a8590", !8, i64 0}
!733 = !{!734, !734, i64 0}
!734 = !{!"0x5646c08a8590.w1.b2", !735, i64 0}
!735 = !{!"0x5646c08a8590.w2.b2", !722, i64 0}
!736 = !{!737, !737, i64 0}
!737 = !{!"0x5646c08a8590.w1.b3", !735, i64 0}
!738 = !{!739, !739, i64 0}
!739 = !{!"0x5646c08a8590.w1.b1", !721, i64 0}
!740 = !{!741, !741, i64 0}
!741 = !{!"0x5646bcb2ce10.w1.b0", !742, i64 0}
!742 = !{!"0x5646bcb2ce10.w2.b0", !743, i64 0}
!743 = !{!"0x5646bcb2ce10.w4.b0", !744, i64 0}
!744 = !{!"0x5646bcb2ce10.w8.b0", !745, i64 0}
!745 = !{!"0x5646bcb2ce10.w16.b0", !746, i64 0}
!746 = !{!"0x5646bcb2ce10.w32.b0", !747, i64 0}
!747 = !{!"0x5646bcb2ce10.w64.b0", !748, i64 0}
!748 = !{!"0x5646bcb2ce10.w128.b0", !749, i64 0}
!749 = !{!"0x5646bcb2ce10.w256.b0", !750, i64 0}
!750 = !{!"0x5646bcb2ce10.w512.b0", !751, i64 0}
!751 = !{!"0x5646bcb2ce10.w1024.b0", !752, i64 0}
!752 = !{!"int64", !753, i64 0}
!753 = !{!"0x5646bcb2ce10", !8, i64 0}
!754 = !{!755, !755, i64 0}
!755 = !{!"0x5646bcb2ce10.w1.b1", !742, i64 0}
!756 = !{!757, !757, i64 0}
!757 = !{!"0x5646c1e8b850.w1.b0", !758, i64 0}
!758 = !{!"0x5646c1e8b850.w2.b0", !759, i64 0}
!759 = !{!"0x5646c1e8b850.w4.b0", !760, i64 0}
!760 = !{!"0x5646c1e8b850.w8.b0", !761, i64 0}
!761 = !{!"0x5646c1e8b850.w16.b0", !762, i64 0}
!762 = !{!"0x5646c1e8b850.w32.b0", !763, i64 0}
!763 = !{!"0x5646c1e8b850.w64.b0", !764, i64 0}
!764 = !{!"0x5646c1e8b850.w128.b0", !765, i64 0}
!765 = !{!"0x5646c1e8b850.w256.b0", !766, i64 0}
!766 = !{!"0x5646c1e8b850.w512.b0", !767, i64 0}
!767 = !{!"0x5646c1e8b850.w1024.b0", !768, i64 0}
!768 = !{!"int64", !769, i64 0}
!769 = !{!"0x5646c1e8b850", !8, i64 0}
!770 = !{!771, !771, i64 0}
!771 = !{!"0x5646c1e8b850.w1.b1", !758, i64 0}
!772 = !{!773, !773, i64 0}
!773 = !{!"0x5646bd1fa940.w1.b0", !774, i64 0}
!774 = !{!"0x5646bd1fa940.w2.b0", !775, i64 0}
!775 = !{!"0x5646bd1fa940.w4.b0", !776, i64 0}
!776 = !{!"0x5646bd1fa940.w8.b0", !777, i64 0}
!777 = !{!"0x5646bd1fa940.w16.b0", !778, i64 0}
!778 = !{!"0x5646bd1fa940.w32.b0", !779, i64 0}
!779 = !{!"0x5646bd1fa940.w64.b0", !780, i64 0}
!780 = !{!"0x5646bd1fa940.w128.b0", !781, i64 0}
!781 = !{!"0x5646bd1fa940.w256.b0", !782, i64 0}
!782 = !{!"0x5646bd1fa940.w512.b0", !783, i64 0}
!783 = !{!"0x5646bd1fa940.w1024.b0", !784, i64 0}
!784 = !{!"int64", !785, i64 0}
!785 = !{!"0x5646bd1fa940", !8, i64 0}
!786 = !{!787, !787, i64 0}
!787 = !{!"0x5646bd1fa940.w1.b1", !774, i64 0}
!788 = !{!789, !789, i64 0}
!789 = !{!"0x5646bd6dc810.w1.b0", !790, i64 0}
!790 = !{!"0x5646bd6dc810.w2.b0", !791, i64 0}
!791 = !{!"0x5646bd6dc810.w4.b0", !792, i64 0}
!792 = !{!"0x5646bd6dc810.w8.b0", !793, i64 0}
!793 = !{!"0x5646bd6dc810.w16.b0", !794, i64 0}
!794 = !{!"0x5646bd6dc810.w32.b0", !795, i64 0}
!795 = !{!"0x5646bd6dc810.w64.b0", !796, i64 0}
!796 = !{!"0x5646bd6dc810.w128.b0", !797, i64 0}
!797 = !{!"0x5646bd6dc810.w256.b0", !798, i64 0}
!798 = !{!"0x5646bd6dc810.w512.b0", !799, i64 0}
!799 = !{!"0x5646bd6dc810.w1024.b0", !800, i64 0}
!800 = !{!"int64", !801, i64 0}
!801 = !{!"0x5646bd6dc810", !8, i64 0}
!802 = !{!803, !803, i64 0}
!803 = !{!"0x5646bd6dc810.w1.b1", !790, i64 0}
!804 = !{!805, !805, i64 0}
!805 = !{!"0x5646c0f8c330.w1.b0", !806, i64 0}
!806 = !{!"0x5646c0f8c330.w2.b0", !807, i64 0}
!807 = !{!"0x5646c0f8c330.w4.b0", !808, i64 0}
!808 = !{!"0x5646c0f8c330.w8.b0", !809, i64 0}
!809 = !{!"0x5646c0f8c330.w16.b0", !810, i64 0}
!810 = !{!"0x5646c0f8c330.w32.b0", !811, i64 0}
!811 = !{!"0x5646c0f8c330.w64.b0", !812, i64 0}
!812 = !{!"0x5646c0f8c330.w128.b0", !813, i64 0}
!813 = !{!"0x5646c0f8c330.w256.b0", !814, i64 0}
!814 = !{!"0x5646c0f8c330.w512.b0", !815, i64 0}
!815 = !{!"0x5646c0f8c330.w1024.b0", !816, i64 0}
!816 = !{!"int64", !817, i64 0}
!817 = !{!"0x5646c0f8c330", !8, i64 0}
!818 = !{!819, !819, i64 0}
!819 = !{!"0x5646c1df0ef0.w1.b0", !820, i64 0}
!820 = !{!"0x5646c1df0ef0.w2.b0", !821, i64 0}
!821 = !{!"0x5646c1df0ef0.w4.b0", !822, i64 0}
!822 = !{!"0x5646c1df0ef0.w8.b0", !823, i64 0}
!823 = !{!"0x5646c1df0ef0.w16.b0", !824, i64 0}
!824 = !{!"0x5646c1df0ef0.w32.b0", !825, i64 0}
!825 = !{!"0x5646c1df0ef0.w64.b0", !826, i64 0}
!826 = !{!"0x5646c1df0ef0.w128.b0", !827, i64 0}
!827 = !{!"0x5646c1df0ef0.w256.b0", !828, i64 0}
!828 = !{!"0x5646c1df0ef0.w512.b0", !829, i64 0}
!829 = !{!"0x5646c1df0ef0.w1024.b0", !830, i64 0}
!830 = !{!"int64", !831, i64 0}
!831 = !{!"0x5646c1df0ef0", !8, i64 0}
!832 = !{!833, !833, i64 0}
!833 = !{!"0x5646b8f05790.w1.b0", !834, i64 0}
!834 = !{!"0x5646b8f05790.w2.b0", !835, i64 0}
!835 = !{!"0x5646b8f05790.w4.b0", !836, i64 0}
!836 = !{!"0x5646b8f05790.w8.b0", !837, i64 0}
!837 = !{!"0x5646b8f05790.w16.b0", !838, i64 0}
!838 = !{!"0x5646b8f05790.w32.b0", !839, i64 0}
!839 = !{!"0x5646b8f05790.w64.b0", !840, i64 0}
!840 = !{!"0x5646b8f05790.w128.b0", !841, i64 0}
!841 = !{!"0x5646b8f05790.w256.b0", !842, i64 0}
!842 = !{!"0x5646b8f05790.w512.b0", !843, i64 0}
!843 = !{!"0x5646b8f05790.w1024.b0", !844, i64 0}
!844 = !{!"int64", !845, i64 0}
!845 = !{!"0x5646b8f05790", !8, i64 0}
!846 = !{!847, !847, i64 0}
!847 = !{!"0x5646b8f05790.w1.b1", !834, i64 0}
!848 = !{!849, !849, i64 0}
!849 = !{!"0x5646bdb15830.w1.b0", !850, i64 0}
!850 = !{!"0x5646bdb15830.w2.b0", !851, i64 0}
!851 = !{!"0x5646bdb15830.w4.b0", !852, i64 0}
!852 = !{!"0x5646bdb15830.w8.b0", !853, i64 0}
!853 = !{!"0x5646bdb15830.w16.b0", !854, i64 0}
!854 = !{!"0x5646bdb15830.w32.b0", !855, i64 0}
!855 = !{!"0x5646bdb15830.w64.b0", !856, i64 0}
!856 = !{!"0x5646bdb15830.w128.b0", !857, i64 0}
!857 = !{!"0x5646bdb15830.w256.b0", !858, i64 0}
!858 = !{!"0x5646bdb15830.w512.b0", !859, i64 0}
!859 = !{!"0x5646bdb15830.w1024.b0", !860, i64 0}
!860 = !{!"int64", !861, i64 0}
!861 = !{!"0x5646bdb15830", !8, i64 0}
!862 = !{!863, !863, i64 0}
!863 = !{!"0x5646bdb15830.w1.b1", !850, i64 0}
!864 = !{!865, !865, i64 0}
!865 = !{!"float32", !866, i64 0}
!866 = !{!"0x5646b8e77590", !8, i64 0}
!867 = !{!868, !868, i64 0}
!868 = !{!"float32", !869, i64 0}
!869 = !{!"0x5646c0888ed0", !8, i64 0}
!870 = !{!871, !871, i64 0}
!871 = !{!"float32", !872, i64 0}
!872 = !{!"0x5646c1e502f0", !8, i64 0}
!873 = distinct !{!873, !874}
!874 = !{!"llvm.loop.isvectorized", i32 1}
!875 = !{!876, !876, i64 0}
!876 = !{!"float32", !877, i64 0}
!877 = !{!"0x5646c0a47c80", !8, i64 0}
!878 = !{!879, !879, i64 0}
!879 = !{!"float32", !880, i64 0}
!880 = !{!"0x5646ba17a180", !8, i64 0}
!881 = !{!882, !882, i64 0}
!882 = !{!"0x5646c414a040.w1.b0", !883, i64 0}
!883 = !{!"0x5646c414a040.w2.b0", !884, i64 0}
!884 = !{!"0x5646c414a040.w4.b0", !885, i64 0}
!885 = !{!"0x5646c414a040.w8.b0", !886, i64 0}
!886 = !{!"0x5646c414a040.w16.b0", !887, i64 0}
!887 = !{!"0x5646c414a040.w32.b0", !888, i64 0}
!888 = !{!"0x5646c414a040.w64.b0", !889, i64 0}
!889 = !{!"0x5646c414a040.w128.b0", !890, i64 0}
!890 = !{!"0x5646c414a040.w256.b0", !891, i64 0}
!891 = !{!"0x5646c414a040.w512.b0", !892, i64 0}
!892 = !{!"0x5646c414a040.w1024.b0", !893, i64 0}
!893 = !{!"int32", !894, i64 0}
!894 = !{!"0x5646c414a040", !8, i64 0}
!895 = !{!896, !896, i64 0}
!896 = !{!"0x5646c414a040.w1.b2", !897, i64 0}
!897 = !{!"0x5646c414a040.w2.b2", !884, i64 0}
!898 = !{!899, !899, i64 0}
!899 = !{!"0x5646c414a040.w1.b3", !897, i64 0}
!900 = !{!901, !901, i64 0}
!901 = !{!"0x5646c414a040.w1.b1", !883, i64 0}
!902 = !{!903, !903, i64 0}
!903 = !{!"0x5646bc660e30.w1.b0", !904, i64 0}
!904 = !{!"0x5646bc660e30.w2.b0", !905, i64 0}
!905 = !{!"0x5646bc660e30.w4.b0", !906, i64 0}
!906 = !{!"0x5646bc660e30.w8.b0", !907, i64 0}
!907 = !{!"0x5646bc660e30.w16.b0", !908, i64 0}
!908 = !{!"0x5646bc660e30.w32.b0", !909, i64 0}
!909 = !{!"0x5646bc660e30.w64.b0", !910, i64 0}
!910 = !{!"0x5646bc660e30.w128.b0", !911, i64 0}
!911 = !{!"0x5646bc660e30.w256.b0", !912, i64 0}
!912 = !{!"0x5646bc660e30.w512.b0", !913, i64 0}
!913 = !{!"0x5646bc660e30.w1024.b0", !914, i64 0}
!914 = !{!"int64", !915, i64 0}
!915 = !{!"0x5646bc660e30", !8, i64 0}
!916 = !{!917, !917, i64 0}
!917 = !{!"0x5646bc660e30.w1.b1", !904, i64 0}
!918 = !{!919, !919, i64 0}
!919 = !{!"0x5646bc660e30.w1.b2", !920, i64 0}
!920 = !{!"0x5646bc660e30.w2.b2", !905, i64 0}
!921 = !{!922, !922, i64 0}
!922 = !{!"0x5646bc660e30.w1.b3", !920, i64 0}
!923 = !{!924, !924, i64 0}
!924 = !{!"0x5646bc660e30.w1.b4", !925, i64 0}
!925 = !{!"0x5646bc660e30.w2.b4", !926, i64 0}
!926 = !{!"0x5646bc660e30.w4.b4", !906, i64 0}
!927 = !{!928, !928, i64 0}
!928 = !{!"0x5646bc657dc0.w4.b0", !929, i64 0}
!929 = !{!"0x5646bc657dc0.w8.b0", !930, i64 0}
!930 = !{!"0x5646bc657dc0.w16.b0", !931, i64 0}
!931 = !{!"0x5646bc657dc0.w32.b0", !932, i64 0}
!932 = !{!"0x5646bc657dc0.w64.b0", !933, i64 0}
!933 = !{!"0x5646bc657dc0.w128.b0", !934, i64 0}
!934 = !{!"0x5646bc657dc0.w256.b0", !935, i64 0}
!935 = !{!"0x5646bc657dc0.w512.b0", !936, i64 0}
!936 = !{!"0x5646bc657dc0.w1024.b0", !937, i64 0}
!937 = !{!"int64", !938, i64 0}
!938 = !{!"0x5646bc657dc0", !8, i64 0}
!939 = !{!940, !940, i64 0}
!940 = !{!"0x5646bc657dc0.w1.b4", !941, i64 0}
!941 = !{!"0x5646bc657dc0.w2.b4", !942, i64 0}
!942 = !{!"0x5646bc657dc0.w4.b4", !929, i64 0}
!943 = !{!944, !944, i64 0}
!944 = !{!"0x5646bc65f8a0.w1.b0", !945, i64 0}
!945 = !{!"0x5646bc65f8a0.w2.b0", !946, i64 0}
!946 = !{!"0x5646bc65f8a0.w4.b0", !947, i64 0}
!947 = !{!"0x5646bc65f8a0.w8.b0", !948, i64 0}
!948 = !{!"0x5646bc65f8a0.w16.b0", !949, i64 0}
!949 = !{!"0x5646bc65f8a0.w32.b0", !950, i64 0}
!950 = !{!"0x5646bc65f8a0.w64.b0", !951, i64 0}
!951 = !{!"0x5646bc65f8a0.w128.b0", !952, i64 0}
!952 = !{!"0x5646bc65f8a0.w256.b0", !953, i64 0}
!953 = !{!"0x5646bc65f8a0.w512.b0", !954, i64 0}
!954 = !{!"0x5646bc65f8a0.w1024.b0", !955, i64 0}
!955 = !{!"int64", !956, i64 0}
!956 = !{!"0x5646bc65f8a0", !8, i64 0}
!957 = !{!958, !958, i64 0}
!958 = !{!"0x5646bc65f8a0.w1.b1", !945, i64 0}
!959 = !{!960, !960, i64 0}
!960 = !{!"0x5646bc65f8a0.w1.b2", !961, i64 0}
!961 = !{!"0x5646bc65f8a0.w2.b2", !946, i64 0}
!962 = !{!963, !963, i64 0}
!963 = !{!"0x5646bc65f8a0.w1.b3", !961, i64 0}
!964 = !{!965, !965, i64 0}
!965 = !{!"0x5646bc65f8a0.w1.b4", !966, i64 0}
!966 = !{!"0x5646bc65f8a0.w2.b4", !967, i64 0}
!967 = !{!"0x5646bc65f8a0.w4.b4", !947, i64 0}
!968 = !{!969, !969, i64 0}
!969 = !{!"0x5646bc65f8a0.w1.b5", !966, i64 0}
!970 = !{!971, !971, i64 0}
!971 = !{!"0x5646bc6610f0.w4.b0", !972, i64 0}
!972 = !{!"0x5646bc6610f0.w8.b0", !973, i64 0}
!973 = !{!"0x5646bc6610f0.w16.b0", !974, i64 0}
!974 = !{!"0x5646bc6610f0.w32.b0", !975, i64 0}
!975 = !{!"0x5646bc6610f0.w64.b0", !976, i64 0}
!976 = !{!"0x5646bc6610f0.w128.b0", !977, i64 0}
!977 = !{!"0x5646bc6610f0.w256.b0", !978, i64 0}
!978 = !{!"0x5646bc6610f0.w512.b0", !979, i64 0}
!979 = !{!"0x5646bc6610f0.w1024.b0", !980, i64 0}
!980 = !{!"int64", !981, i64 0}
!981 = !{!"0x5646bc6610f0", !8, i64 0}
!982 = !{!983, !983, i64 0}
!983 = !{!"0x5646bc6610f0.w1.b4", !984, i64 0}
!984 = !{!"0x5646bc6610f0.w2.b4", !985, i64 0}
!985 = !{!"0x5646bc6610f0.w4.b4", !972, i64 0}
!986 = !{!987, !987, i64 0}
!987 = !{!"0x5646bc6610f0.w1.b5", !984, i64 0}
!988 = !{!989, !989, i64 0}
!989 = !{!"0x5646bc661e50.w1.b0", !990, i64 0}
!990 = !{!"0x5646bc661e50.w2.b0", !991, i64 0}
!991 = !{!"0x5646bc661e50.w4.b0", !992, i64 0}
!992 = !{!"0x5646bc661e50.w8.b0", !993, i64 0}
!993 = !{!"0x5646bc661e50.w16.b0", !994, i64 0}
!994 = !{!"0x5646bc661e50.w32.b0", !995, i64 0}
!995 = !{!"0x5646bc661e50.w64.b0", !996, i64 0}
!996 = !{!"0x5646bc661e50.w128.b0", !997, i64 0}
!997 = !{!"0x5646bc661e50.w256.b0", !998, i64 0}
!998 = !{!"0x5646bc661e50.w512.b0", !999, i64 0}
!999 = !{!"0x5646bc661e50.w1024.b0", !1000, i64 0}
!1000 = !{!"int64", !1001, i64 0}
!1001 = !{!"0x5646bc661e50", !8, i64 0}
!1002 = !{!1003, !1003, i64 0}
!1003 = !{!"0x5646bc661e50.w1.b1", !990, i64 0}
!1004 = !{!1005, !1005, i64 0}
!1005 = !{!"0x5646bc661e50.w1.b2", !1006, i64 0}
!1006 = !{!"0x5646bc661e50.w2.b2", !991, i64 0}
!1007 = !{!1008, !1008, i64 0}
!1008 = !{!"0x5646bc661e50.w1.b3", !1006, i64 0}
!1009 = !{!1010, !1010, i64 0}
!1010 = !{!"0x5646bc661e50.w1.b4", !1011, i64 0}
!1011 = !{!"0x5646bc661e50.w2.b4", !1012, i64 0}
!1012 = !{!"0x5646bc661e50.w4.b4", !992, i64 0}
!1013 = !{!1014, !1014, i64 0}
!1014 = !{!"0x5646bc663640.w4.b0", !1015, i64 0}
!1015 = !{!"0x5646bc663640.w8.b0", !1016, i64 0}
!1016 = !{!"0x5646bc663640.w16.b0", !1017, i64 0}
!1017 = !{!"0x5646bc663640.w32.b0", !1018, i64 0}
!1018 = !{!"0x5646bc663640.w64.b0", !1019, i64 0}
!1019 = !{!"0x5646bc663640.w128.b0", !1020, i64 0}
!1020 = !{!"0x5646bc663640.w256.b0", !1021, i64 0}
!1021 = !{!"0x5646bc663640.w512.b0", !1022, i64 0}
!1022 = !{!"0x5646bc663640.w1024.b0", !1023, i64 0}
!1023 = !{!"int64", !1024, i64 0}
!1024 = !{!"0x5646bc663640", !8, i64 0}
!1025 = !{!1026, !1026, i64 0}
!1026 = !{!"0x5646bc663640.w1.b4", !1027, i64 0}
!1027 = !{!"0x5646bc663640.w2.b4", !1028, i64 0}
!1028 = !{!"0x5646bc663640.w4.b4", !1015, i64 0}
!1029 = !{!1030, !1030, i64 0}
!1030 = !{!"0x5646bc664860.w1.b0", !1031, i64 0}
!1031 = !{!"0x5646bc664860.w2.b0", !1032, i64 0}
!1032 = !{!"0x5646bc664860.w4.b0", !1033, i64 0}
!1033 = !{!"0x5646bc664860.w8.b0", !1034, i64 0}
!1034 = !{!"0x5646bc664860.w16.b0", !1035, i64 0}
!1035 = !{!"0x5646bc664860.w32.b0", !1036, i64 0}
!1036 = !{!"0x5646bc664860.w64.b0", !1037, i64 0}
!1037 = !{!"0x5646bc664860.w128.b0", !1038, i64 0}
!1038 = !{!"0x5646bc664860.w256.b0", !1039, i64 0}
!1039 = !{!"0x5646bc664860.w512.b0", !1040, i64 0}
!1040 = !{!"0x5646bc664860.w1024.b0", !1041, i64 0}
!1041 = !{!"int64", !1042, i64 0}
!1042 = !{!"0x5646bc664860", !8, i64 0}
!1043 = !{!1044, !1044, i64 0}
!1044 = !{!"0x5646bc664860.w1.b1", !1031, i64 0}
!1045 = !{!1046, !1046, i64 0}
!1046 = !{!"0x5646bc664860.w1.b2", !1047, i64 0}
!1047 = !{!"0x5646bc664860.w2.b2", !1032, i64 0}
!1048 = !{!1049, !1049, i64 0}
!1049 = !{!"0x5646bc664860.w1.b3", !1047, i64 0}
!1050 = !{!1051, !1051, i64 0}
!1051 = !{!"0x5646bc664860.w1.b4", !1052, i64 0}
!1052 = !{!"0x5646bc664860.w2.b4", !1053, i64 0}
!1053 = !{!"0x5646bc664860.w4.b4", !1033, i64 0}
!1054 = !{!1055, !1055, i64 0}
!1055 = !{!"0x5646bc6648b0.w4.b0", !1056, i64 0}
!1056 = !{!"0x5646bc6648b0.w8.b0", !1057, i64 0}
!1057 = !{!"0x5646bc6648b0.w16.b0", !1058, i64 0}
!1058 = !{!"0x5646bc6648b0.w32.b0", !1059, i64 0}
!1059 = !{!"0x5646bc6648b0.w64.b0", !1060, i64 0}
!1060 = !{!"0x5646bc6648b0.w128.b0", !1061, i64 0}
!1061 = !{!"0x5646bc6648b0.w256.b0", !1062, i64 0}
!1062 = !{!"0x5646bc6648b0.w512.b0", !1063, i64 0}
!1063 = !{!"0x5646bc6648b0.w1024.b0", !1064, i64 0}
!1064 = !{!"int64", !1065, i64 0}
!1065 = !{!"0x5646bc6648b0", !8, i64 0}
!1066 = !{!1067, !1067, i64 0}
!1067 = !{!"0x5646bc6648b0.w1.b4", !1068, i64 0}
!1068 = !{!"0x5646bc6648b0.w2.b4", !1069, i64 0}
!1069 = !{!"0x5646bc6648b0.w4.b4", !1056, i64 0}
!1070 = !{!1071, !1071, i64 0}
!1071 = !{!"float32", !1072, i64 0}
!1072 = !{!"0x5646bc656500", !8, i64 0}
!1073 = !{!1074, !1074, i64 0}
!1074 = !{!"float32", !1075, i64 0}
!1075 = !{!"0x5646bc656310", !8, i64 0}
!1076 = !{!1077, !1077, i64 0}
!1077 = !{!"float32", !1078, i64 0}
!1078 = !{!"0x5646bc6558d0", !8, i64 0}
!1079 = !{!1080, !1080, i64 0}
!1080 = !{!"0x5646c41554f0.w32.b0", !1081, i64 0}
!1081 = !{!"0x5646c41554f0.w64.b0", !1082, i64 0}
!1082 = !{!"0x5646c41554f0.w128.b0", !1083, i64 0}
!1083 = !{!"0x5646c41554f0.w256.b0", !1084, i64 0}
!1084 = !{!"0x5646c41554f0.w512.b0", !1085, i64 0}
!1085 = !{!"0x5646c41554f0.w1024.b0", !1086, i64 0}
!1086 = !{!"float32", !1087, i64 0}
!1087 = !{!"0x5646c41554f0", !8, i64 0}
!1088 = !{!1089, !1089, i64 0}
!1089 = !{!"float32", !1090, i64 0}
!1090 = !{!"0x5646bc654ea0", !8, i64 0}
!1091 = !{!1092, !1092, i64 0}
!1092 = !{!"float32", !1093, i64 0}
!1093 = !{!"0x5646bc655a10", !8, i64 0}
!1094 = !{!1095, !1095, i64 0}
!1095 = !{!"float32", !1096, i64 0}
!1096 = !{!"0x5646bc655f70", !8, i64 0}
!1097 = !{!1098, !1098, i64 0}
!1098 = !{!"0x5646c411d540.w1.b0", !1099, i64 0}
!1099 = !{!"0x5646c411d540.w2.b0", !1100, i64 0}
!1100 = !{!"0x5646c411d540.w4.b0", !1101, i64 0}
!1101 = !{!"0x5646c411d540.w8.b0", !1102, i64 0}
!1102 = !{!"0x5646c411d540.w16.b0", !1103, i64 0}
!1103 = !{!"0x5646c411d540.w32.b0", !1104, i64 0}
!1104 = !{!"0x5646c411d540.w64.b0", !1105, i64 0}
!1105 = !{!"0x5646c411d540.w128.b0", !1106, i64 0}
!1106 = !{!"0x5646c411d540.w256.b0", !1107, i64 0}
!1107 = !{!"0x5646c411d540.w512.b0", !1108, i64 0}
!1108 = !{!"0x5646c411d540.w1024.b0", !1109, i64 0}
!1109 = !{!"int32", !1110, i64 0}
!1110 = !{!"0x5646c411d540", !8, i64 0}
!1111 = !{!1112, !1112, i64 0}
!1112 = !{!"0x5646c411d540.w1.b2", !1113, i64 0}
!1113 = !{!"0x5646c411d540.w2.b2", !1100, i64 0}
!1114 = !{!1115, !1115, i64 0}
!1115 = !{!"0x5646c411d540.w1.b3", !1113, i64 0}
!1116 = !{!1117, !1117, i64 0}
!1117 = !{!"0x5646c411d540.w1.b1", !1099, i64 0}
!1118 = !{!1119, !1119, i64 0}
!1119 = !{!"0x5646c1ed67c0.w1.b0", !1120, i64 0}
!1120 = !{!"0x5646c1ed67c0.w2.b0", !1121, i64 0}
!1121 = !{!"0x5646c1ed67c0.w4.b0", !1122, i64 0}
!1122 = !{!"0x5646c1ed67c0.w8.b0", !1123, i64 0}
!1123 = !{!"0x5646c1ed67c0.w16.b0", !1124, i64 0}
!1124 = !{!"0x5646c1ed67c0.w32.b0", !1125, i64 0}
!1125 = !{!"0x5646c1ed67c0.w64.b0", !1126, i64 0}
!1126 = !{!"0x5646c1ed67c0.w128.b0", !1127, i64 0}
!1127 = !{!"0x5646c1ed67c0.w256.b0", !1128, i64 0}
!1128 = !{!"0x5646c1ed67c0.w512.b0", !1129, i64 0}
!1129 = !{!"0x5646c1ed67c0.w1024.b0", !1130, i64 0}
!1130 = !{!"int64", !1131, i64 0}
!1131 = !{!"0x5646c1ed67c0", !8, i64 0}
!1132 = !{!1133, !1133, i64 0}
!1133 = !{!"0x5646c1ed67c0.w1.b1", !1120, i64 0}
!1134 = !{!1135, !1135, i64 0}
!1135 = !{!"0x5646c1ed67c0.w1.b2", !1136, i64 0}
!1136 = !{!"0x5646c1ed67c0.w2.b2", !1121, i64 0}
!1137 = !{!1138, !1138, i64 0}
!1138 = !{!"0x5646c1ed67c0.w1.b3", !1136, i64 0}
!1139 = !{!1140, !1140, i64 0}
!1140 = !{!"0x5646c1ed67c0.w1.b4", !1141, i64 0}
!1141 = !{!"0x5646c1ed67c0.w2.b4", !1142, i64 0}
!1142 = !{!"0x5646c1ed67c0.w4.b4", !1122, i64 0}
!1143 = !{!1144, !1144, i64 0}
!1144 = !{!"0x5646c1ed68c0.w4.b0", !1145, i64 0}
!1145 = !{!"0x5646c1ed68c0.w8.b0", !1146, i64 0}
!1146 = !{!"0x5646c1ed68c0.w16.b0", !1147, i64 0}
!1147 = !{!"0x5646c1ed68c0.w32.b0", !1148, i64 0}
!1148 = !{!"0x5646c1ed68c0.w64.b0", !1149, i64 0}
!1149 = !{!"0x5646c1ed68c0.w128.b0", !1150, i64 0}
!1150 = !{!"0x5646c1ed68c0.w256.b0", !1151, i64 0}
!1151 = !{!"0x5646c1ed68c0.w512.b0", !1152, i64 0}
!1152 = !{!"0x5646c1ed68c0.w1024.b0", !1153, i64 0}
!1153 = !{!"int64", !1154, i64 0}
!1154 = !{!"0x5646c1ed68c0", !8, i64 0}
!1155 = !{!1156, !1156, i64 0}
!1156 = !{!"0x5646c1ed68c0.w1.b4", !1157, i64 0}
!1157 = !{!"0x5646c1ed68c0.w2.b4", !1158, i64 0}
!1158 = !{!"0x5646c1ed68c0.w4.b4", !1145, i64 0}
!1159 = !{!1160, !1160, i64 0}
!1160 = !{!"0x5646c1ed6960.w1.b0", !1161, i64 0}
!1161 = !{!"0x5646c1ed6960.w2.b0", !1162, i64 0}
!1162 = !{!"0x5646c1ed6960.w4.b0", !1163, i64 0}
!1163 = !{!"0x5646c1ed6960.w8.b0", !1164, i64 0}
!1164 = !{!"0x5646c1ed6960.w16.b0", !1165, i64 0}
!1165 = !{!"0x5646c1ed6960.w32.b0", !1166, i64 0}
!1166 = !{!"0x5646c1ed6960.w64.b0", !1167, i64 0}
!1167 = !{!"0x5646c1ed6960.w128.b0", !1168, i64 0}
!1168 = !{!"0x5646c1ed6960.w256.b0", !1169, i64 0}
!1169 = !{!"0x5646c1ed6960.w512.b0", !1170, i64 0}
!1170 = !{!"0x5646c1ed6960.w1024.b0", !1171, i64 0}
!1171 = !{!"int64", !1172, i64 0}
!1172 = !{!"0x5646c1ed6960", !8, i64 0}
!1173 = !{!1174, !1174, i64 0}
!1174 = !{!"0x5646c1ed6960.w1.b1", !1161, i64 0}
!1175 = !{!1176, !1176, i64 0}
!1176 = !{!"0x5646c1ed6960.w1.b2", !1177, i64 0}
!1177 = !{!"0x5646c1ed6960.w2.b2", !1162, i64 0}
!1178 = !{!1179, !1179, i64 0}
!1179 = !{!"0x5646c1ed6960.w1.b3", !1177, i64 0}
!1180 = !{!1181, !1181, i64 0}
!1181 = !{!"0x5646c1ed6960.w1.b4", !1182, i64 0}
!1182 = !{!"0x5646c1ed6960.w2.b4", !1183, i64 0}
!1183 = !{!"0x5646c1ed6960.w4.b4", !1163, i64 0}
!1184 = !{!1185, !1185, i64 0}
!1185 = !{!"0x5646c1ed6960.w1.b5", !1182, i64 0}
!1186 = !{!1187, !1187, i64 0}
!1187 = !{!"0x5646c1ed6870.w4.b0", !1188, i64 0}
!1188 = !{!"0x5646c1ed6870.w8.b0", !1189, i64 0}
!1189 = !{!"0x5646c1ed6870.w16.b0", !1190, i64 0}
!1190 = !{!"0x5646c1ed6870.w32.b0", !1191, i64 0}
!1191 = !{!"0x5646c1ed6870.w64.b0", !1192, i64 0}
!1192 = !{!"0x5646c1ed6870.w128.b0", !1193, i64 0}
!1193 = !{!"0x5646c1ed6870.w256.b0", !1194, i64 0}
!1194 = !{!"0x5646c1ed6870.w512.b0", !1195, i64 0}
!1195 = !{!"0x5646c1ed6870.w1024.b0", !1196, i64 0}
!1196 = !{!"int64", !1197, i64 0}
!1197 = !{!"0x5646c1ed6870", !8, i64 0}
!1198 = !{!1199, !1199, i64 0}
!1199 = !{!"0x5646c1ed6870.w1.b4", !1200, i64 0}
!1200 = !{!"0x5646c1ed6870.w2.b4", !1201, i64 0}
!1201 = !{!"0x5646c1ed6870.w4.b4", !1188, i64 0}
!1202 = !{!1203, !1203, i64 0}
!1203 = !{!"0x5646c1ed6870.w1.b5", !1200, i64 0}
!1204 = !{!1205, !1205, i64 0}
!1205 = !{!"0x5646c1ed6fd0.w1.b0", !1206, i64 0}
!1206 = !{!"0x5646c1ed6fd0.w2.b0", !1207, i64 0}
!1207 = !{!"0x5646c1ed6fd0.w4.b0", !1208, i64 0}
!1208 = !{!"0x5646c1ed6fd0.w8.b0", !1209, i64 0}
!1209 = !{!"0x5646c1ed6fd0.w16.b0", !1210, i64 0}
!1210 = !{!"0x5646c1ed6fd0.w32.b0", !1211, i64 0}
!1211 = !{!"0x5646c1ed6fd0.w64.b0", !1212, i64 0}
!1212 = !{!"0x5646c1ed6fd0.w128.b0", !1213, i64 0}
!1213 = !{!"0x5646c1ed6fd0.w256.b0", !1214, i64 0}
!1214 = !{!"0x5646c1ed6fd0.w512.b0", !1215, i64 0}
!1215 = !{!"0x5646c1ed6fd0.w1024.b0", !1216, i64 0}
!1216 = !{!"int64", !1217, i64 0}
!1217 = !{!"0x5646c1ed6fd0", !8, i64 0}
!1218 = !{!1219, !1219, i64 0}
!1219 = !{!"0x5646c1ed6fd0.w1.b1", !1206, i64 0}
!1220 = !{!1221, !1221, i64 0}
!1221 = !{!"0x5646c1ed6fd0.w1.b2", !1222, i64 0}
!1222 = !{!"0x5646c1ed6fd0.w2.b2", !1207, i64 0}
!1223 = !{!1224, !1224, i64 0}
!1224 = !{!"0x5646c1ed6fd0.w1.b3", !1222, i64 0}
!1225 = !{!1226, !1226, i64 0}
!1226 = !{!"0x5646c1ed6fd0.w1.b4", !1227, i64 0}
!1227 = !{!"0x5646c1ed6fd0.w2.b4", !1228, i64 0}
!1228 = !{!"0x5646c1ed6fd0.w4.b4", !1208, i64 0}
!1229 = !{!1230, !1230, i64 0}
!1230 = !{!"0x5646c1ed7d30.w4.b0", !1231, i64 0}
!1231 = !{!"0x5646c1ed7d30.w8.b0", !1232, i64 0}
!1232 = !{!"0x5646c1ed7d30.w16.b0", !1233, i64 0}
!1233 = !{!"0x5646c1ed7d30.w32.b0", !1234, i64 0}
!1234 = !{!"0x5646c1ed7d30.w64.b0", !1235, i64 0}
!1235 = !{!"0x5646c1ed7d30.w128.b0", !1236, i64 0}
!1236 = !{!"0x5646c1ed7d30.w256.b0", !1237, i64 0}
!1237 = !{!"0x5646c1ed7d30.w512.b0", !1238, i64 0}
!1238 = !{!"0x5646c1ed7d30.w1024.b0", !1239, i64 0}
!1239 = !{!"int64", !1240, i64 0}
!1240 = !{!"0x5646c1ed7d30", !8, i64 0}
!1241 = !{!1242, !1242, i64 0}
!1242 = !{!"0x5646c1ed7d30.w1.b4", !1243, i64 0}
!1243 = !{!"0x5646c1ed7d30.w2.b4", !1244, i64 0}
!1244 = !{!"0x5646c1ed7d30.w4.b4", !1231, i64 0}
!1245 = !{!1246, !1246, i64 0}
!1246 = !{!"0x5646c1d3d680.w1.b0", !1247, i64 0}
!1247 = !{!"0x5646c1d3d680.w2.b0", !1248, i64 0}
!1248 = !{!"0x5646c1d3d680.w4.b0", !1249, i64 0}
!1249 = !{!"0x5646c1d3d680.w8.b0", !1250, i64 0}
!1250 = !{!"0x5646c1d3d680.w16.b0", !1251, i64 0}
!1251 = !{!"0x5646c1d3d680.w32.b0", !1252, i64 0}
!1252 = !{!"0x5646c1d3d680.w64.b0", !1253, i64 0}
!1253 = !{!"0x5646c1d3d680.w128.b0", !1254, i64 0}
!1254 = !{!"0x5646c1d3d680.w256.b0", !1255, i64 0}
!1255 = !{!"0x5646c1d3d680.w512.b0", !1256, i64 0}
!1256 = !{!"0x5646c1d3d680.w1024.b0", !1257, i64 0}
!1257 = !{!"int64", !1258, i64 0}
!1258 = !{!"0x5646c1d3d680", !8, i64 0}
!1259 = !{!1260, !1260, i64 0}
!1260 = !{!"0x5646c1d3d680.w1.b1", !1247, i64 0}
!1261 = !{!1262, !1262, i64 0}
!1262 = !{!"0x5646c1d3d680.w1.b2", !1263, i64 0}
!1263 = !{!"0x5646c1d3d680.w2.b2", !1248, i64 0}
!1264 = !{!1265, !1265, i64 0}
!1265 = !{!"0x5646c1d3d680.w1.b3", !1263, i64 0}
!1266 = !{!1267, !1267, i64 0}
!1267 = !{!"0x5646c1d3d680.w1.b4", !1268, i64 0}
!1268 = !{!"0x5646c1d3d680.w2.b4", !1269, i64 0}
!1269 = !{!"0x5646c1d3d680.w4.b4", !1249, i64 0}
!1270 = !{!1271, !1271, i64 0}
!1271 = !{!"0x5646c1d3d6d0.w4.b0", !1272, i64 0}
!1272 = !{!"0x5646c1d3d6d0.w8.b0", !1273, i64 0}
!1273 = !{!"0x5646c1d3d6d0.w16.b0", !1274, i64 0}
!1274 = !{!"0x5646c1d3d6d0.w32.b0", !1275, i64 0}
!1275 = !{!"0x5646c1d3d6d0.w64.b0", !1276, i64 0}
!1276 = !{!"0x5646c1d3d6d0.w128.b0", !1277, i64 0}
!1277 = !{!"0x5646c1d3d6d0.w256.b0", !1278, i64 0}
!1278 = !{!"0x5646c1d3d6d0.w512.b0", !1279, i64 0}
!1279 = !{!"0x5646c1d3d6d0.w1024.b0", !1280, i64 0}
!1280 = !{!"int64", !1281, i64 0}
!1281 = !{!"0x5646c1d3d6d0", !8, i64 0}
!1282 = !{!1283, !1283, i64 0}
!1283 = !{!"0x5646c1d3d6d0.w1.b4", !1284, i64 0}
!1284 = !{!"0x5646c1d3d6d0.w2.b4", !1285, i64 0}
!1285 = !{!"0x5646c1d3d6d0.w4.b4", !1272, i64 0}
!1286 = !{!1287, !1287, i64 0}
!1287 = !{!"float32", !1288, i64 0}
!1288 = !{!"0x5646c1ea2fa0", !8, i64 0}
!1289 = !{!1290, !1290, i64 0}
!1290 = !{!"float32", !1291, i64 0}
!1291 = !{!"0x5646c1e29c60", !8, i64 0}
!1292 = !{!1293, !1293, i64 0}
!1293 = !{!"float32", !1294, i64 0}
!1294 = !{!"0x5646c411d210", !8, i64 0}
!1295 = !{!1296, !1296, i64 0}
!1296 = !{!"float32", !1297, i64 0}
!1297 = !{!"0x5646c1ea2dc0", !8, i64 0}
!1298 = !{!1299, !1299, i64 0}
!1299 = !{!"float32", !1300, i64 0}
!1300 = !{!"0x5646c1e296a0", !8, i64 0}
!1301 = !{!1302, !1302, i64 0}
!1302 = !{!"0x5646c414bc90.w1.b0", !1303, i64 0}
!1303 = !{!"0x5646c414bc90.w2.b0", !1304, i64 0}
!1304 = !{!"0x5646c414bc90.w4.b0", !1305, i64 0}
!1305 = !{!"0x5646c414bc90.w8.b0", !1306, i64 0}
!1306 = !{!"0x5646c414bc90.w16.b0", !1307, i64 0}
!1307 = !{!"0x5646c414bc90.w32.b0", !1308, i64 0}
!1308 = !{!"0x5646c414bc90.w64.b0", !1309, i64 0}
!1309 = !{!"0x5646c414bc90.w128.b0", !1310, i64 0}
!1310 = !{!"0x5646c414bc90.w256.b0", !1311, i64 0}
!1311 = !{!"0x5646c414bc90.w512.b0", !1312, i64 0}
!1312 = !{!"0x5646c414bc90.w1024.b0", !1313, i64 0}
!1313 = !{!"int32", !1314, i64 0}
!1314 = !{!"0x5646c414bc90", !8, i64 0}
!1315 = !{!1316, !1316, i64 0}
!1316 = !{!"0x5646c414bc90.w1.b1", !1303, i64 0}
!1317 = !{!1318, !1318, i64 0}
!1318 = !{!"0x5646c414c8f0.w1.b0", !1319, i64 0}
!1319 = !{!"0x5646c414c8f0.w2.b0", !1320, i64 0}
!1320 = !{!"0x5646c414c8f0.w4.b0", !1321, i64 0}
!1321 = !{!"0x5646c414c8f0.w8.b0", !1322, i64 0}
!1322 = !{!"0x5646c414c8f0.w16.b0", !1323, i64 0}
!1323 = !{!"0x5646c414c8f0.w32.b0", !1324, i64 0}
!1324 = !{!"0x5646c414c8f0.w64.b0", !1325, i64 0}
!1325 = !{!"0x5646c414c8f0.w128.b0", !1326, i64 0}
!1326 = !{!"0x5646c414c8f0.w256.b0", !1327, i64 0}
!1327 = !{!"0x5646c414c8f0.w512.b0", !1328, i64 0}
!1328 = !{!"0x5646c414c8f0.w1024.b0", !1329, i64 0}
!1329 = !{!"int64", !1330, i64 0}
!1330 = !{!"0x5646c414c8f0", !8, i64 0}
!1331 = !{!1332, !1332, i64 0}
!1332 = !{!"0x5646c414c8f0.w1.b1", !1319, i64 0}
!1333 = !{!1334, !1334, i64 0}
!1334 = !{!"0x5646c414c8f0.w1.b2", !1335, i64 0}
!1335 = !{!"0x5646c414c8f0.w2.b2", !1320, i64 0}
!1336 = !{!1337, !1337, i64 0}
!1337 = !{!"0x5646c414c8f0.w1.b3", !1335, i64 0}
!1338 = !{!1339, !1339, i64 0}
!1339 = !{!"0x5646c414c8f0.w1.b4", !1340, i64 0}
!1340 = !{!"0x5646c414c8f0.w2.b4", !1341, i64 0}
!1341 = !{!"0x5646c414c8f0.w4.b4", !1321, i64 0}
!1342 = !{!1343, !1343, i64 0}
!1343 = !{!"0x5646c414cac0.w4.b0", !1344, i64 0}
!1344 = !{!"0x5646c414cac0.w8.b0", !1345, i64 0}
!1345 = !{!"0x5646c414cac0.w16.b0", !1346, i64 0}
!1346 = !{!"0x5646c414cac0.w32.b0", !1347, i64 0}
!1347 = !{!"0x5646c414cac0.w64.b0", !1348, i64 0}
!1348 = !{!"0x5646c414cac0.w128.b0", !1349, i64 0}
!1349 = !{!"0x5646c414cac0.w256.b0", !1350, i64 0}
!1350 = !{!"0x5646c414cac0.w512.b0", !1351, i64 0}
!1351 = !{!"0x5646c414cac0.w1024.b0", !1352, i64 0}
!1352 = !{!"int64", !1353, i64 0}
!1353 = !{!"0x5646c414cac0", !8, i64 0}
!1354 = !{!1355, !1355, i64 0}
!1355 = !{!"0x5646c414cac0.w1.b4", !1356, i64 0}
!1356 = !{!"0x5646c414cac0.w2.b4", !1357, i64 0}
!1357 = !{!"0x5646c414cac0.w4.b4", !1344, i64 0}
!1358 = !{!1359, !1359, i64 0}
!1359 = !{!"0x5646c414cd10.w1.b0", !1360, i64 0}
!1360 = !{!"0x5646c414cd10.w2.b0", !1361, i64 0}
!1361 = !{!"0x5646c414cd10.w4.b0", !1362, i64 0}
!1362 = !{!"0x5646c414cd10.w8.b0", !1363, i64 0}
!1363 = !{!"0x5646c414cd10.w16.b0", !1364, i64 0}
!1364 = !{!"0x5646c414cd10.w32.b0", !1365, i64 0}
!1365 = !{!"0x5646c414cd10.w64.b0", !1366, i64 0}
!1366 = !{!"0x5646c414cd10.w128.b0", !1367, i64 0}
!1367 = !{!"0x5646c414cd10.w256.b0", !1368, i64 0}
!1368 = !{!"0x5646c414cd10.w512.b0", !1369, i64 0}
!1369 = !{!"0x5646c414cd10.w1024.b0", !1370, i64 0}
!1370 = !{!"int64", !1371, i64 0}
!1371 = !{!"0x5646c414cd10", !8, i64 0}
!1372 = !{!1373, !1373, i64 0}
!1373 = !{!"0x5646c414cd10.w1.b1", !1360, i64 0}
!1374 = !{!1375, !1375, i64 0}
!1375 = !{!"0x5646c414cd10.w1.b2", !1376, i64 0}
!1376 = !{!"0x5646c414cd10.w2.b2", !1361, i64 0}
!1377 = !{!1378, !1378, i64 0}
!1378 = !{!"0x5646c414cd10.w1.b3", !1376, i64 0}
!1379 = !{!1380, !1380, i64 0}
!1380 = !{!"0x5646c414cd10.w1.b4", !1381, i64 0}
!1381 = !{!"0x5646c414cd10.w2.b4", !1382, i64 0}
!1382 = !{!"0x5646c414cd10.w4.b4", !1362, i64 0}
!1383 = !{!1384, !1384, i64 0}
!1384 = !{!"0x5646c414c940.w4.b0", !1385, i64 0}
!1385 = !{!"0x5646c414c940.w8.b0", !1386, i64 0}
!1386 = !{!"0x5646c414c940.w16.b0", !1387, i64 0}
!1387 = !{!"0x5646c414c940.w32.b0", !1388, i64 0}
!1388 = !{!"0x5646c414c940.w64.b0", !1389, i64 0}
!1389 = !{!"0x5646c414c940.w128.b0", !1390, i64 0}
!1390 = !{!"0x5646c414c940.w256.b0", !1391, i64 0}
!1391 = !{!"0x5646c414c940.w512.b0", !1392, i64 0}
!1392 = !{!"0x5646c414c940.w1024.b0", !1393, i64 0}
!1393 = !{!"int64", !1394, i64 0}
!1394 = !{!"0x5646c414c940", !8, i64 0}
!1395 = !{!1396, !1396, i64 0}
!1396 = !{!"0x5646c414c940.w1.b4", !1397, i64 0}
!1397 = !{!"0x5646c414c940.w2.b4", !1398, i64 0}
!1398 = !{!"0x5646c414c940.w4.b4", !1385, i64 0}
!1399 = !{!1400, !1400, i64 0}
!1400 = !{!"float32", !1401, i64 0}
!1401 = !{!"0x5646c4148ec0", !8, i64 0}
!1402 = !{!1403, !1403, i64 0}
!1403 = !{!"float32", !1404, i64 0}
!1404 = !{!"0x5646c4149020", !8, i64 0}
!1405 = !{!1406, !1406, i64 0}
!1406 = !{!"0x5646bd4f0290.w1.b0", !1407, i64 0}
!1407 = !{!"0x5646bd4f0290.w2.b0", !1408, i64 0}
!1408 = !{!"0x5646bd4f0290.w4.b0", !1409, i64 0}
!1409 = !{!"0x5646bd4f0290.w8.b0", !1410, i64 0}
!1410 = !{!"0x5646bd4f0290.w16.b0", !1411, i64 0}
!1411 = !{!"0x5646bd4f0290.w32.b0", !1412, i64 0}
!1412 = !{!"0x5646bd4f0290.w64.b0", !1413, i64 0}
!1413 = !{!"0x5646bd4f0290.w128.b0", !1414, i64 0}
!1414 = !{!"0x5646bd4f0290.w256.b0", !1415, i64 0}
!1415 = !{!"0x5646bd4f0290.w512.b0", !1416, i64 0}
!1416 = !{!"0x5646bd4f0290.w1024.b0", !1417, i64 0}
!1417 = !{!"int32", !1418, i64 0}
!1418 = !{!"0x5646bd4f0290", !8, i64 0}
!1419 = !{!1420, !1420, i64 0}
!1420 = !{!"0x5646bd4f0290.w1.b1", !1407, i64 0}
!1421 = !{!1422, !1422, i64 0}
!1422 = !{!"0x5646bd4f1560.w1.b0", !1423, i64 0}
!1423 = !{!"0x5646bd4f1560.w2.b0", !1424, i64 0}
!1424 = !{!"0x5646bd4f1560.w4.b0", !1425, i64 0}
!1425 = !{!"0x5646bd4f1560.w8.b0", !1426, i64 0}
!1426 = !{!"0x5646bd4f1560.w16.b0", !1427, i64 0}
!1427 = !{!"0x5646bd4f1560.w32.b0", !1428, i64 0}
!1428 = !{!"0x5646bd4f1560.w64.b0", !1429, i64 0}
!1429 = !{!"0x5646bd4f1560.w128.b0", !1430, i64 0}
!1430 = !{!"0x5646bd4f1560.w256.b0", !1431, i64 0}
!1431 = !{!"0x5646bd4f1560.w512.b0", !1432, i64 0}
!1432 = !{!"0x5646bd4f1560.w1024.b0", !1433, i64 0}
!1433 = !{!"int64", !1434, i64 0}
!1434 = !{!"0x5646bd4f1560", !8, i64 0}
!1435 = !{!1436, !1436, i64 0}
!1436 = !{!"0x5646bd4f1560.w1.b1", !1423, i64 0}
!1437 = !{!1438, !1438, i64 0}
!1438 = !{!"0x5646bd4f1560.w1.b2", !1439, i64 0}
!1439 = !{!"0x5646bd4f1560.w2.b2", !1424, i64 0}
!1440 = !{!1441, !1441, i64 0}
!1441 = !{!"0x5646bd4f1560.w1.b3", !1439, i64 0}
!1442 = !{!1443, !1443, i64 0}
!1443 = !{!"0x5646bd4f1560.w1.b4", !1444, i64 0}
!1444 = !{!"0x5646bd4f1560.w2.b4", !1445, i64 0}
!1445 = !{!"0x5646bd4f1560.w4.b4", !1425, i64 0}
!1446 = !{!1447, !1447, i64 0}
!1447 = !{!"0x5646bd4f18e0.w4.b0", !1448, i64 0}
!1448 = !{!"0x5646bd4f18e0.w8.b0", !1449, i64 0}
!1449 = !{!"0x5646bd4f18e0.w16.b0", !1450, i64 0}
!1450 = !{!"0x5646bd4f18e0.w32.b0", !1451, i64 0}
!1451 = !{!"0x5646bd4f18e0.w64.b0", !1452, i64 0}
!1452 = !{!"0x5646bd4f18e0.w128.b0", !1453, i64 0}
!1453 = !{!"0x5646bd4f18e0.w256.b0", !1454, i64 0}
!1454 = !{!"0x5646bd4f18e0.w512.b0", !1455, i64 0}
!1455 = !{!"0x5646bd4f18e0.w1024.b0", !1456, i64 0}
!1456 = !{!"int64", !1457, i64 0}
!1457 = !{!"0x5646bd4f18e0", !8, i64 0}
!1458 = !{!1459, !1459, i64 0}
!1459 = !{!"0x5646bd4f18e0.w1.b4", !1460, i64 0}
!1460 = !{!"0x5646bd4f18e0.w2.b4", !1461, i64 0}
!1461 = !{!"0x5646bd4f18e0.w4.b4", !1448, i64 0}
!1462 = !{!1463, !1463, i64 0}
!1463 = !{!"0x5646bd4f1b30.w1.b0", !1464, i64 0}
!1464 = !{!"0x5646bd4f1b30.w2.b0", !1465, i64 0}
!1465 = !{!"0x5646bd4f1b30.w4.b0", !1466, i64 0}
!1466 = !{!"0x5646bd4f1b30.w8.b0", !1467, i64 0}
!1467 = !{!"0x5646bd4f1b30.w16.b0", !1468, i64 0}
!1468 = !{!"0x5646bd4f1b30.w32.b0", !1469, i64 0}
!1469 = !{!"0x5646bd4f1b30.w64.b0", !1470, i64 0}
!1470 = !{!"0x5646bd4f1b30.w128.b0", !1471, i64 0}
!1471 = !{!"0x5646bd4f1b30.w256.b0", !1472, i64 0}
!1472 = !{!"0x5646bd4f1b30.w512.b0", !1473, i64 0}
!1473 = !{!"0x5646bd4f1b30.w1024.b0", !1474, i64 0}
!1474 = !{!"int64", !1475, i64 0}
!1475 = !{!"0x5646bd4f1b30", !8, i64 0}
!1476 = !{!1477, !1477, i64 0}
!1477 = !{!"0x5646bd4f1b30.w1.b1", !1464, i64 0}
!1478 = !{!1479, !1479, i64 0}
!1479 = !{!"0x5646bd4f1b30.w1.b2", !1480, i64 0}
!1480 = !{!"0x5646bd4f1b30.w2.b2", !1465, i64 0}
!1481 = !{!1482, !1482, i64 0}
!1482 = !{!"0x5646bd4f1b30.w1.b3", !1480, i64 0}
!1483 = !{!1484, !1484, i64 0}
!1484 = !{!"0x5646bd4f1b30.w1.b4", !1485, i64 0}
!1485 = !{!"0x5646bd4f1b30.w2.b4", !1486, i64 0}
!1486 = !{!"0x5646bd4f1b30.w4.b4", !1466, i64 0}
!1487 = !{!1488, !1488, i64 0}
!1488 = !{!"0x5646bd4f1760.w4.b0", !1489, i64 0}
!1489 = !{!"0x5646bd4f1760.w8.b0", !1490, i64 0}
!1490 = !{!"0x5646bd4f1760.w16.b0", !1491, i64 0}
!1491 = !{!"0x5646bd4f1760.w32.b0", !1492, i64 0}
!1492 = !{!"0x5646bd4f1760.w64.b0", !1493, i64 0}
!1493 = !{!"0x5646bd4f1760.w128.b0", !1494, i64 0}
!1494 = !{!"0x5646bd4f1760.w256.b0", !1495, i64 0}
!1495 = !{!"0x5646bd4f1760.w512.b0", !1496, i64 0}
!1496 = !{!"0x5646bd4f1760.w1024.b0", !1497, i64 0}
!1497 = !{!"int64", !1498, i64 0}
!1498 = !{!"0x5646bd4f1760", !8, i64 0}
!1499 = !{!1500, !1500, i64 0}
!1500 = !{!"0x5646bd4f1760.w1.b4", !1501, i64 0}
!1501 = !{!"0x5646bd4f1760.w2.b4", !1502, i64 0}
!1502 = !{!"0x5646bd4f1760.w4.b4", !1489, i64 0}
!1503 = !{!1504, !1504, i64 0}
!1504 = !{!"float32", !1505, i64 0}
!1505 = !{!"0x5646bd4e8a70", !8, i64 0}
!1506 = !{!1507, !1507, i64 0}
!1507 = !{!"float32", !1508, i64 0}
!1508 = !{!"0x5646c416c450", !8, i64 0}
!1509 = !{!1510, !1510, i64 0}
!1510 = !{!"0x5646bd2acf70.w1.b0", !1511, i64 0}
!1511 = !{!"0x5646bd2acf70.w2.b0", !1512, i64 0}
!1512 = !{!"0x5646bd2acf70.w4.b0", !1513, i64 0}
!1513 = !{!"0x5646bd2acf70.w8.b0", !1514, i64 0}
!1514 = !{!"0x5646bd2acf70.w16.b0", !1515, i64 0}
!1515 = !{!"0x5646bd2acf70.w32.b0", !1516, i64 0}
!1516 = !{!"0x5646bd2acf70.w64.b0", !1517, i64 0}
!1517 = !{!"0x5646bd2acf70.w128.b0", !1518, i64 0}
!1518 = !{!"0x5646bd2acf70.w256.b0", !1519, i64 0}
!1519 = !{!"0x5646bd2acf70.w512.b0", !1520, i64 0}
!1520 = !{!"0x5646bd2acf70.w1024.b0", !1521, i64 0}
!1521 = !{!"int32", !1522, i64 0}
!1522 = !{!"0x5646bd2acf70", !8, i64 0}
!1523 = !{!1524, !1524, i64 0}
!1524 = !{!"0x5646bd2acf70.w1.b1", !1511, i64 0}
!1525 = !{!1526, !1526, i64 0}
!1526 = !{!"0x5646bc693200.w1.b0", !1527, i64 0}
!1527 = !{!"0x5646bc693200.w2.b0", !1528, i64 0}
!1528 = !{!"0x5646bc693200.w4.b0", !1529, i64 0}
!1529 = !{!"0x5646bc693200.w8.b0", !1530, i64 0}
!1530 = !{!"0x5646bc693200.w16.b0", !1531, i64 0}
!1531 = !{!"0x5646bc693200.w32.b0", !1532, i64 0}
!1532 = !{!"0x5646bc693200.w64.b0", !1533, i64 0}
!1533 = !{!"0x5646bc693200.w128.b0", !1534, i64 0}
!1534 = !{!"0x5646bc693200.w256.b0", !1535, i64 0}
!1535 = !{!"0x5646bc693200.w512.b0", !1536, i64 0}
!1536 = !{!"0x5646bc693200.w1024.b0", !1537, i64 0}
!1537 = !{!"int64", !1538, i64 0}
!1538 = !{!"0x5646bc693200", !8, i64 0}
!1539 = !{!1540, !1540, i64 0}
!1540 = !{!"0x5646bc693200.w1.b1", !1527, i64 0}
!1541 = !{!1542, !1542, i64 0}
!1542 = !{!"0x5646bc693200.w1.b2", !1543, i64 0}
!1543 = !{!"0x5646bc693200.w2.b2", !1528, i64 0}
!1544 = !{!1545, !1545, i64 0}
!1545 = !{!"0x5646bc693200.w1.b3", !1543, i64 0}
!1546 = !{!1547, !1547, i64 0}
!1547 = !{!"0x5646bc693200.w1.b4", !1548, i64 0}
!1548 = !{!"0x5646bc693200.w2.b4", !1549, i64 0}
!1549 = !{!"0x5646bc693200.w4.b4", !1529, i64 0}
!1550 = !{!1551, !1551, i64 0}
!1551 = !{!"0x5646bc693580.w4.b0", !1552, i64 0}
!1552 = !{!"0x5646bc693580.w8.b0", !1553, i64 0}
!1553 = !{!"0x5646bc693580.w16.b0", !1554, i64 0}
!1554 = !{!"0x5646bc693580.w32.b0", !1555, i64 0}
!1555 = !{!"0x5646bc693580.w64.b0", !1556, i64 0}
!1556 = !{!"0x5646bc693580.w128.b0", !1557, i64 0}
!1557 = !{!"0x5646bc693580.w256.b0", !1558, i64 0}
!1558 = !{!"0x5646bc693580.w512.b0", !1559, i64 0}
!1559 = !{!"0x5646bc693580.w1024.b0", !1560, i64 0}
!1560 = !{!"int64", !1561, i64 0}
!1561 = !{!"0x5646bc693580", !8, i64 0}
!1562 = !{!1563, !1563, i64 0}
!1563 = !{!"0x5646bc693580.w1.b4", !1564, i64 0}
!1564 = !{!"0x5646bc693580.w2.b4", !1565, i64 0}
!1565 = !{!"0x5646bc693580.w4.b4", !1552, i64 0}
!1566 = !{!1567, !1567, i64 0}
!1567 = !{!"0x5646bc6937d0.w1.b0", !1568, i64 0}
!1568 = !{!"0x5646bc6937d0.w2.b0", !1569, i64 0}
!1569 = !{!"0x5646bc6937d0.w4.b0", !1570, i64 0}
!1570 = !{!"0x5646bc6937d0.w8.b0", !1571, i64 0}
!1571 = !{!"0x5646bc6937d0.w16.b0", !1572, i64 0}
!1572 = !{!"0x5646bc6937d0.w32.b0", !1573, i64 0}
!1573 = !{!"0x5646bc6937d0.w64.b0", !1574, i64 0}
!1574 = !{!"0x5646bc6937d0.w128.b0", !1575, i64 0}
!1575 = !{!"0x5646bc6937d0.w256.b0", !1576, i64 0}
!1576 = !{!"0x5646bc6937d0.w512.b0", !1577, i64 0}
!1577 = !{!"0x5646bc6937d0.w1024.b0", !1578, i64 0}
!1578 = !{!"int64", !1579, i64 0}
!1579 = !{!"0x5646bc6937d0", !8, i64 0}
!1580 = !{!1581, !1581, i64 0}
!1581 = !{!"0x5646bc6937d0.w1.b1", !1568, i64 0}
!1582 = !{!1583, !1583, i64 0}
!1583 = !{!"0x5646bc6937d0.w1.b2", !1584, i64 0}
!1584 = !{!"0x5646bc6937d0.w2.b2", !1569, i64 0}
!1585 = !{!1586, !1586, i64 0}
!1586 = !{!"0x5646bc6937d0.w1.b3", !1584, i64 0}
!1587 = !{!1588, !1588, i64 0}
!1588 = !{!"0x5646bc6937d0.w1.b4", !1589, i64 0}
!1589 = !{!"0x5646bc6937d0.w2.b4", !1590, i64 0}
!1590 = !{!"0x5646bc6937d0.w4.b4", !1570, i64 0}
!1591 = !{!1592, !1592, i64 0}
!1592 = !{!"0x5646bc693400.w4.b0", !1593, i64 0}
!1593 = !{!"0x5646bc693400.w8.b0", !1594, i64 0}
!1594 = !{!"0x5646bc693400.w16.b0", !1595, i64 0}
!1595 = !{!"0x5646bc693400.w32.b0", !1596, i64 0}
!1596 = !{!"0x5646bc693400.w64.b0", !1597, i64 0}
!1597 = !{!"0x5646bc693400.w128.b0", !1598, i64 0}
!1598 = !{!"0x5646bc693400.w256.b0", !1599, i64 0}
!1599 = !{!"0x5646bc693400.w512.b0", !1600, i64 0}
!1600 = !{!"0x5646bc693400.w1024.b0", !1601, i64 0}
!1601 = !{!"int64", !1602, i64 0}
!1602 = !{!"0x5646bc693400", !8, i64 0}
!1603 = !{!1604, !1604, i64 0}
!1604 = !{!"0x5646bc693400.w1.b4", !1605, i64 0}
!1605 = !{!"0x5646bc693400.w2.b4", !1606, i64 0}
!1606 = !{!"0x5646bc693400.w4.b4", !1593, i64 0}
!1607 = !{!1608, !1608, i64 0}
!1608 = !{!"float32", !1609, i64 0}
!1609 = !{!"0x5646bc68a1b0", !8, i64 0}
!1610 = !{!1611, !1611, i64 0}
!1611 = !{!"float32", !1612, i64 0}
!1612 = !{!"0x5646bc68c1a0", !8, i64 0}
!1613 = !{!1614, !1614, i64 0}
!1614 = !{!"0x5646c413fb50.w1.b0", !1615, i64 0}
!1615 = !{!"0x5646c413fb50.w2.b0", !1616, i64 0}
!1616 = !{!"0x5646c413fb50.w4.b0", !1617, i64 0}
!1617 = !{!"0x5646c413fb50.w8.b0", !1618, i64 0}
!1618 = !{!"0x5646c413fb50.w16.b0", !1619, i64 0}
!1619 = !{!"0x5646c413fb50.w32.b0", !1620, i64 0}
!1620 = !{!"0x5646c413fb50.w64.b0", !1621, i64 0}
!1621 = !{!"0x5646c413fb50.w128.b0", !1622, i64 0}
!1622 = !{!"0x5646c413fb50.w256.b0", !1623, i64 0}
!1623 = !{!"0x5646c413fb50.w512.b0", !1624, i64 0}
!1624 = !{!"0x5646c413fb50.w1024.b0", !1625, i64 0}
!1625 = !{!"int32", !1626, i64 0}
!1626 = !{!"0x5646c413fb50", !8, i64 0}
!1627 = !{!1628, !1628, i64 0}
!1628 = !{!"0x5646c413fb50.w1.b2", !1629, i64 0}
!1629 = !{!"0x5646c413fb50.w2.b2", !1616, i64 0}
!1630 = !{!1631, !1631, i64 0}
!1631 = !{!"0x5646c413fb50.w1.b3", !1629, i64 0}
!1632 = !{!1633, !1633, i64 0}
!1633 = !{!"0x5646c413fb50.w1.b1", !1615, i64 0}
!1634 = !{!1635, !1635, i64 0}
!1635 = !{!"0x5646c412e6b0.w1.b0", !1636, i64 0}
!1636 = !{!"0x5646c412e6b0.w2.b0", !1637, i64 0}
!1637 = !{!"0x5646c412e6b0.w4.b0", !1638, i64 0}
!1638 = !{!"0x5646c412e6b0.w8.b0", !1639, i64 0}
!1639 = !{!"0x5646c412e6b0.w16.b0", !1640, i64 0}
!1640 = !{!"0x5646c412e6b0.w32.b0", !1641, i64 0}
!1641 = !{!"0x5646c412e6b0.w64.b0", !1642, i64 0}
!1642 = !{!"0x5646c412e6b0.w128.b0", !1643, i64 0}
!1643 = !{!"0x5646c412e6b0.w256.b0", !1644, i64 0}
!1644 = !{!"0x5646c412e6b0.w512.b0", !1645, i64 0}
!1645 = !{!"0x5646c412e6b0.w1024.b0", !1646, i64 0}
!1646 = !{!"int64", !1647, i64 0}
!1647 = !{!"0x5646c412e6b0", !8, i64 0}
!1648 = !{!1649, !1649, i64 0}
!1649 = !{!"0x5646c412e6b0.w1.b1", !1636, i64 0}
!1650 = !{!1651, !1651, i64 0}
!1651 = !{!"0x5646c412e6b0.w1.b2", !1652, i64 0}
!1652 = !{!"0x5646c412e6b0.w2.b2", !1637, i64 0}
!1653 = !{!1654, !1654, i64 0}
!1654 = !{!"0x5646c412e6b0.w1.b3", !1652, i64 0}
!1655 = !{!1656, !1656, i64 0}
!1656 = !{!"0x5646c412e6b0.w1.b4", !1657, i64 0}
!1657 = !{!"0x5646c412e6b0.w2.b4", !1658, i64 0}
!1658 = !{!"0x5646c412e6b0.w4.b4", !1638, i64 0}
!1659 = !{!1660, !1660, i64 0}
!1660 = !{!"0x5646c4132740.w4.b0", !1661, i64 0}
!1661 = !{!"0x5646c4132740.w8.b0", !1662, i64 0}
!1662 = !{!"0x5646c4132740.w16.b0", !1663, i64 0}
!1663 = !{!"0x5646c4132740.w32.b0", !1664, i64 0}
!1664 = !{!"0x5646c4132740.w64.b0", !1665, i64 0}
!1665 = !{!"0x5646c4132740.w128.b0", !1666, i64 0}
!1666 = !{!"0x5646c4132740.w256.b0", !1667, i64 0}
!1667 = !{!"0x5646c4132740.w512.b0", !1668, i64 0}
!1668 = !{!"0x5646c4132740.w1024.b0", !1669, i64 0}
!1669 = !{!"int64", !1670, i64 0}
!1670 = !{!"0x5646c4132740", !8, i64 0}
!1671 = !{!1672, !1672, i64 0}
!1672 = !{!"0x5646c4132740.w1.b4", !1673, i64 0}
!1673 = !{!"0x5646c4132740.w2.b4", !1674, i64 0}
!1674 = !{!"0x5646c4132740.w4.b4", !1661, i64 0}
!1675 = !{!1676, !1676, i64 0}
!1676 = !{!"0x5646c412dec0.w1.b0", !1677, i64 0}
!1677 = !{!"0x5646c412dec0.w2.b0", !1678, i64 0}
!1678 = !{!"0x5646c412dec0.w4.b0", !1679, i64 0}
!1679 = !{!"0x5646c412dec0.w8.b0", !1680, i64 0}
!1680 = !{!"0x5646c412dec0.w16.b0", !1681, i64 0}
!1681 = !{!"0x5646c412dec0.w32.b0", !1682, i64 0}
!1682 = !{!"0x5646c412dec0.w64.b0", !1683, i64 0}
!1683 = !{!"0x5646c412dec0.w128.b0", !1684, i64 0}
!1684 = !{!"0x5646c412dec0.w256.b0", !1685, i64 0}
!1685 = !{!"0x5646c412dec0.w512.b0", !1686, i64 0}
!1686 = !{!"0x5646c412dec0.w1024.b0", !1687, i64 0}
!1687 = !{!"int64", !1688, i64 0}
!1688 = !{!"0x5646c412dec0", !8, i64 0}
!1689 = !{!1690, !1690, i64 0}
!1690 = !{!"0x5646c412dec0.w1.b1", !1677, i64 0}
!1691 = !{!1692, !1692, i64 0}
!1692 = !{!"0x5646c412dec0.w1.b2", !1693, i64 0}
!1693 = !{!"0x5646c412dec0.w2.b2", !1678, i64 0}
!1694 = !{!1695, !1695, i64 0}
!1695 = !{!"0x5646c412dec0.w1.b3", !1693, i64 0}
!1696 = !{!1697, !1697, i64 0}
!1697 = !{!"0x5646c412dec0.w1.b4", !1698, i64 0}
!1698 = !{!"0x5646c412dec0.w2.b4", !1699, i64 0}
!1699 = !{!"0x5646c412dec0.w4.b4", !1679, i64 0}
!1700 = !{!1701, !1701, i64 0}
!1701 = !{!"0x5646c412dec0.w1.b5", !1698, i64 0}
!1702 = !{!1703, !1703, i64 0}
!1703 = !{!"0x5646c4131310.w4.b0", !1704, i64 0}
!1704 = !{!"0x5646c4131310.w8.b0", !1705, i64 0}
!1705 = !{!"0x5646c4131310.w16.b0", !1706, i64 0}
!1706 = !{!"0x5646c4131310.w32.b0", !1707, i64 0}
!1707 = !{!"0x5646c4131310.w64.b0", !1708, i64 0}
!1708 = !{!"0x5646c4131310.w128.b0", !1709, i64 0}
!1709 = !{!"0x5646c4131310.w256.b0", !1710, i64 0}
!1710 = !{!"0x5646c4131310.w512.b0", !1711, i64 0}
!1711 = !{!"0x5646c4131310.w1024.b0", !1712, i64 0}
!1712 = !{!"int64", !1713, i64 0}
!1713 = !{!"0x5646c4131310", !8, i64 0}
!1714 = !{!1715, !1715, i64 0}
!1715 = !{!"0x5646c4131310.w1.b4", !1716, i64 0}
!1716 = !{!"0x5646c4131310.w2.b4", !1717, i64 0}
!1717 = !{!"0x5646c4131310.w4.b4", !1704, i64 0}
!1718 = !{!1719, !1719, i64 0}
!1719 = !{!"0x5646c4131310.w1.b5", !1716, i64 0}
!1720 = !{!1721, !1721, i64 0}
!1721 = !{!"0x5646c4134350.w1.b0", !1722, i64 0}
!1722 = !{!"0x5646c4134350.w2.b0", !1723, i64 0}
!1723 = !{!"0x5646c4134350.w4.b0", !1724, i64 0}
!1724 = !{!"0x5646c4134350.w8.b0", !1725, i64 0}
!1725 = !{!"0x5646c4134350.w16.b0", !1726, i64 0}
!1726 = !{!"0x5646c4134350.w32.b0", !1727, i64 0}
!1727 = !{!"0x5646c4134350.w64.b0", !1728, i64 0}
!1728 = !{!"0x5646c4134350.w128.b0", !1729, i64 0}
!1729 = !{!"0x5646c4134350.w256.b0", !1730, i64 0}
!1730 = !{!"0x5646c4134350.w512.b0", !1731, i64 0}
!1731 = !{!"0x5646c4134350.w1024.b0", !1732, i64 0}
!1732 = !{!"int64", !1733, i64 0}
!1733 = !{!"0x5646c4134350", !8, i64 0}
!1734 = !{!1735, !1735, i64 0}
!1735 = !{!"0x5646c4134350.w1.b1", !1722, i64 0}
!1736 = !{!1737, !1737, i64 0}
!1737 = !{!"0x5646c4134350.w1.b2", !1738, i64 0}
!1738 = !{!"0x5646c4134350.w2.b2", !1723, i64 0}
!1739 = !{!1740, !1740, i64 0}
!1740 = !{!"0x5646c4134350.w1.b3", !1738, i64 0}
!1741 = !{!1742, !1742, i64 0}
!1742 = !{!"0x5646c4134350.w1.b4", !1743, i64 0}
!1743 = !{!"0x5646c4134350.w2.b4", !1744, i64 0}
!1744 = !{!"0x5646c4134350.w4.b4", !1724, i64 0}
!1745 = !{!1746, !1746, i64 0}
!1746 = !{!"0x5646c4140b70.w4.b0", !1747, i64 0}
!1747 = !{!"0x5646c4140b70.w8.b0", !1748, i64 0}
!1748 = !{!"0x5646c4140b70.w16.b0", !1749, i64 0}
!1749 = !{!"0x5646c4140b70.w32.b0", !1750, i64 0}
!1750 = !{!"0x5646c4140b70.w64.b0", !1751, i64 0}
!1751 = !{!"0x5646c4140b70.w128.b0", !1752, i64 0}
!1752 = !{!"0x5646c4140b70.w256.b0", !1753, i64 0}
!1753 = !{!"0x5646c4140b70.w512.b0", !1754, i64 0}
!1754 = !{!"0x5646c4140b70.w1024.b0", !1755, i64 0}
!1755 = !{!"int64", !1756, i64 0}
!1756 = !{!"0x5646c4140b70", !8, i64 0}
!1757 = !{!1758, !1758, i64 0}
!1758 = !{!"0x5646c4140b70.w1.b4", !1759, i64 0}
!1759 = !{!"0x5646c4140b70.w2.b4", !1760, i64 0}
!1760 = !{!"0x5646c4140b70.w4.b4", !1747, i64 0}
!1761 = !{!1762, !1762, i64 0}
!1762 = !{!"0x5646c4141d90.w1.b0", !1763, i64 0}
!1763 = !{!"0x5646c4141d90.w2.b0", !1764, i64 0}
!1764 = !{!"0x5646c4141d90.w4.b0", !1765, i64 0}
!1765 = !{!"0x5646c4141d90.w8.b0", !1766, i64 0}
!1766 = !{!"0x5646c4141d90.w16.b0", !1767, i64 0}
!1767 = !{!"0x5646c4141d90.w32.b0", !1768, i64 0}
!1768 = !{!"0x5646c4141d90.w64.b0", !1769, i64 0}
!1769 = !{!"0x5646c4141d90.w128.b0", !1770, i64 0}
!1770 = !{!"0x5646c4141d90.w256.b0", !1771, i64 0}
!1771 = !{!"0x5646c4141d90.w512.b0", !1772, i64 0}
!1772 = !{!"0x5646c4141d90.w1024.b0", !1773, i64 0}
!1773 = !{!"int64", !1774, i64 0}
!1774 = !{!"0x5646c4141d90", !8, i64 0}
!1775 = !{!1776, !1776, i64 0}
!1776 = !{!"0x5646c4141d90.w1.b1", !1763, i64 0}
!1777 = !{!1778, !1778, i64 0}
!1778 = !{!"0x5646c4141d90.w1.b2", !1779, i64 0}
!1779 = !{!"0x5646c4141d90.w2.b2", !1764, i64 0}
!1780 = !{!1781, !1781, i64 0}
!1781 = !{!"0x5646c4141d90.w1.b3", !1779, i64 0}
!1782 = !{!1783, !1783, i64 0}
!1783 = !{!"0x5646c4141d90.w1.b4", !1784, i64 0}
!1784 = !{!"0x5646c4141d90.w2.b4", !1785, i64 0}
!1785 = !{!"0x5646c4141d90.w4.b4", !1765, i64 0}
!1786 = !{!1787, !1787, i64 0}
!1787 = !{!"0x5646c4141de0.w4.b0", !1788, i64 0}
!1788 = !{!"0x5646c4141de0.w8.b0", !1789, i64 0}
!1789 = !{!"0x5646c4141de0.w16.b0", !1790, i64 0}
!1790 = !{!"0x5646c4141de0.w32.b0", !1791, i64 0}
!1791 = !{!"0x5646c4141de0.w64.b0", !1792, i64 0}
!1792 = !{!"0x5646c4141de0.w128.b0", !1793, i64 0}
!1793 = !{!"0x5646c4141de0.w256.b0", !1794, i64 0}
!1794 = !{!"0x5646c4141de0.w512.b0", !1795, i64 0}
!1795 = !{!"0x5646c4141de0.w1024.b0", !1796, i64 0}
!1796 = !{!"int64", !1797, i64 0}
!1797 = !{!"0x5646c4141de0", !8, i64 0}
!1798 = !{!1799, !1799, i64 0}
!1799 = !{!"0x5646c4141de0.w1.b4", !1800, i64 0}
!1800 = !{!"0x5646c4141de0.w2.b4", !1801, i64 0}
!1801 = !{!"0x5646c4141de0.w4.b4", !1788, i64 0}
!1802 = !{!1803, !1803, i64 0}
!1803 = !{!"float32", !1804, i64 0}
!1804 = !{!"0x5646c412e280", !8, i64 0}
!1805 = !{!1806, !1806, i64 0}
!1806 = !{!"float32", !1807, i64 0}
!1807 = !{!"0x5646c412d780", !8, i64 0}
!1808 = !{!1809, !1809, i64 0}
!1809 = !{!"float32", !1810, i64 0}
!1810 = !{!"0x5646c412dbf0", !8, i64 0}
!1811 = !{!1812, !1812, i64 0}
!1812 = !{!"float32", !1813, i64 0}
!1813 = !{!"0x5646c412d950", !8, i64 0}
!1814 = !{!1815, !1815, i64 0}
!1815 = !{!"float32", !1816, i64 0}
!1816 = !{!"0x5646c412d730", !8, i64 0}
!1817 = !{!1818, !1818, i64 0}
!1818 = !{!"float32", !1819, i64 0}
!1819 = !{!"0x5646c412d5a0", !8, i64 0}
!1820 = !{!1821, !1821, i64 0}
!1821 = !{!"0x5646bc8e7440.w32.b0", !1822, i64 0}
!1822 = !{!"0x5646bc8e7440.w64.b0", !1823, i64 0}
!1823 = !{!"0x5646bc8e7440.w128.b0", !1824, i64 0}
!1824 = !{!"0x5646bc8e7440.w256.b0", !1825, i64 0}
!1825 = !{!"0x5646bc8e7440.w512.b0", !1826, i64 0}
!1826 = !{!"0x5646bc8e7440.w1024.b0", !1827, i64 0}
!1827 = !{!"float32", !1828, i64 0}
!1828 = !{!"0x5646bc8e7440", !8, i64 0}
!1829 = !{!1830, !1830, i64 0}
!1830 = !{!"0x5646bd4ff420.w1.b0", !1831, i64 0}
!1831 = !{!"0x5646bd4ff420.w2.b0", !1832, i64 0}
!1832 = !{!"0x5646bd4ff420.w4.b0", !1833, i64 0}
!1833 = !{!"0x5646bd4ff420.w8.b0", !1834, i64 0}
!1834 = !{!"0x5646bd4ff420.w16.b0", !1835, i64 0}
!1835 = !{!"0x5646bd4ff420.w32.b0", !1836, i64 0}
!1836 = !{!"0x5646bd4ff420.w64.b0", !1837, i64 0}
!1837 = !{!"0x5646bd4ff420.w128.b0", !1838, i64 0}
!1838 = !{!"0x5646bd4ff420.w256.b0", !1839, i64 0}
!1839 = !{!"0x5646bd4ff420.w512.b0", !1840, i64 0}
!1840 = !{!"0x5646bd4ff420.w1024.b0", !1841, i64 0}
!1841 = !{!"int32", !1842, i64 0}
!1842 = !{!"0x5646bd4ff420", !8, i64 0}
!1843 = !{!1844, !1844, i64 0}
!1844 = !{!"0x5646bd4ff420.w1.b1", !1831, i64 0}
!1845 = !{!1846, !1846, i64 0}
!1846 = !{!"0x5646bc9846b0.w1.b0", !1847, i64 0}
!1847 = !{!"0x5646bc9846b0.w2.b0", !1848, i64 0}
!1848 = !{!"0x5646bc9846b0.w4.b0", !1849, i64 0}
!1849 = !{!"0x5646bc9846b0.w8.b0", !1850, i64 0}
!1850 = !{!"0x5646bc9846b0.w16.b0", !1851, i64 0}
!1851 = !{!"0x5646bc9846b0.w32.b0", !1852, i64 0}
!1852 = !{!"0x5646bc9846b0.w64.b0", !1853, i64 0}
!1853 = !{!"0x5646bc9846b0.w128.b0", !1854, i64 0}
!1854 = !{!"0x5646bc9846b0.w256.b0", !1855, i64 0}
!1855 = !{!"0x5646bc9846b0.w512.b0", !1856, i64 0}
!1856 = !{!"0x5646bc9846b0.w1024.b0", !1857, i64 0}
!1857 = !{!"int64", !1858, i64 0}
!1858 = !{!"0x5646bc9846b0", !8, i64 0}
!1859 = !{!1860, !1860, i64 0}
!1860 = !{!"0x5646bc9846b0.w1.b1", !1847, i64 0}
!1861 = !{!1862, !1862, i64 0}
!1862 = !{!"0x5646bc9846b0.w1.b2", !1863, i64 0}
!1863 = !{!"0x5646bc9846b0.w2.b2", !1848, i64 0}
!1864 = !{!1865, !1865, i64 0}
!1865 = !{!"0x5646bc9846b0.w1.b3", !1863, i64 0}
!1866 = !{!1867, !1867, i64 0}
!1867 = !{!"0x5646bc9846b0.w1.b4", !1868, i64 0}
!1868 = !{!"0x5646bc9846b0.w2.b4", !1869, i64 0}
!1869 = !{!"0x5646bc9846b0.w4.b4", !1849, i64 0}
!1870 = !{!1871, !1871, i64 0}
!1871 = !{!"0x5646bc9849d0.w4.b0", !1872, i64 0}
!1872 = !{!"0x5646bc9849d0.w8.b0", !1873, i64 0}
!1873 = !{!"0x5646bc9849d0.w16.b0", !1874, i64 0}
!1874 = !{!"0x5646bc9849d0.w32.b0", !1875, i64 0}
!1875 = !{!"0x5646bc9849d0.w64.b0", !1876, i64 0}
!1876 = !{!"0x5646bc9849d0.w128.b0", !1877, i64 0}
!1877 = !{!"0x5646bc9849d0.w256.b0", !1878, i64 0}
!1878 = !{!"0x5646bc9849d0.w512.b0", !1879, i64 0}
!1879 = !{!"0x5646bc9849d0.w1024.b0", !1880, i64 0}
!1880 = !{!"int64", !1881, i64 0}
!1881 = !{!"0x5646bc9849d0", !8, i64 0}
!1882 = !{!1883, !1883, i64 0}
!1883 = !{!"0x5646bc9849d0.w1.b4", !1884, i64 0}
!1884 = !{!"0x5646bc9849d0.w2.b4", !1885, i64 0}
!1885 = !{!"0x5646bc9849d0.w4.b4", !1872, i64 0}
!1886 = !{!1887, !1887, i64 0}
!1887 = !{!"0x5646bc984c20.w1.b0", !1888, i64 0}
!1888 = !{!"0x5646bc984c20.w2.b0", !1889, i64 0}
!1889 = !{!"0x5646bc984c20.w4.b0", !1890, i64 0}
!1890 = !{!"0x5646bc984c20.w8.b0", !1891, i64 0}
!1891 = !{!"0x5646bc984c20.w16.b0", !1892, i64 0}
!1892 = !{!"0x5646bc984c20.w32.b0", !1893, i64 0}
!1893 = !{!"0x5646bc984c20.w64.b0", !1894, i64 0}
!1894 = !{!"0x5646bc984c20.w128.b0", !1895, i64 0}
!1895 = !{!"0x5646bc984c20.w256.b0", !1896, i64 0}
!1896 = !{!"0x5646bc984c20.w512.b0", !1897, i64 0}
!1897 = !{!"0x5646bc984c20.w1024.b0", !1898, i64 0}
!1898 = !{!"int64", !1899, i64 0}
!1899 = !{!"0x5646bc984c20", !8, i64 0}
!1900 = !{!1901, !1901, i64 0}
!1901 = !{!"0x5646bc984c20.w1.b1", !1888, i64 0}
!1902 = !{!1903, !1903, i64 0}
!1903 = !{!"0x5646bc984c20.w1.b2", !1904, i64 0}
!1904 = !{!"0x5646bc984c20.w2.b2", !1889, i64 0}
!1905 = !{!1906, !1906, i64 0}
!1906 = !{!"0x5646bc984c20.w1.b3", !1904, i64 0}
!1907 = !{!1908, !1908, i64 0}
!1908 = !{!"0x5646bc984c20.w1.b4", !1909, i64 0}
!1909 = !{!"0x5646bc984c20.w2.b4", !1910, i64 0}
!1910 = !{!"0x5646bc984c20.w4.b4", !1890, i64 0}
!1911 = !{!1912, !1912, i64 0}
!1912 = !{!"0x5646bc984850.w4.b0", !1913, i64 0}
!1913 = !{!"0x5646bc984850.w8.b0", !1914, i64 0}
!1914 = !{!"0x5646bc984850.w16.b0", !1915, i64 0}
!1915 = !{!"0x5646bc984850.w32.b0", !1916, i64 0}
!1916 = !{!"0x5646bc984850.w64.b0", !1917, i64 0}
!1917 = !{!"0x5646bc984850.w128.b0", !1918, i64 0}
!1918 = !{!"0x5646bc984850.w256.b0", !1919, i64 0}
!1919 = !{!"0x5646bc984850.w512.b0", !1920, i64 0}
!1920 = !{!"0x5646bc984850.w1024.b0", !1921, i64 0}
!1921 = !{!"int64", !1922, i64 0}
!1922 = !{!"0x5646bc984850", !8, i64 0}
!1923 = !{!1924, !1924, i64 0}
!1924 = !{!"0x5646bc984850.w1.b4", !1925, i64 0}
!1925 = !{!"0x5646bc984850.w2.b4", !1926, i64 0}
!1926 = !{!"0x5646bc984850.w4.b4", !1913, i64 0}
!1927 = !{!1928, !1928, i64 0}
!1928 = !{!"float32", !1929, i64 0}
!1929 = !{!"0x5646c1ef4450", !8, i64 0}
!1930 = !{!1931, !1931, i64 0}
!1931 = !{!"float32", !1932, i64 0}
!1932 = !{!"0x5646c1eef7f0", !8, i64 0}
!1933 = !{!1934, !1934, i64 0}
!1934 = !{!"0x5646bcbb2c80.w1.b0", !1935, i64 0}
!1935 = !{!"0x5646bcbb2c80.w2.b0", !1936, i64 0}
!1936 = !{!"0x5646bcbb2c80.w4.b0", !1937, i64 0}
!1937 = !{!"0x5646bcbb2c80.w8.b0", !1938, i64 0}
!1938 = !{!"0x5646bcbb2c80.w16.b0", !1939, i64 0}
!1939 = !{!"0x5646bcbb2c80.w32.b0", !1940, i64 0}
!1940 = !{!"0x5646bcbb2c80.w64.b0", !1941, i64 0}
!1941 = !{!"0x5646bcbb2c80.w128.b0", !1942, i64 0}
!1942 = !{!"0x5646bcbb2c80.w256.b0", !1943, i64 0}
!1943 = !{!"0x5646bcbb2c80.w512.b0", !1944, i64 0}
!1944 = !{!"0x5646bcbb2c80.w1024.b0", !1945, i64 0}
!1945 = !{!"int32", !1946, i64 0}
!1946 = !{!"0x5646bcbb2c80", !8, i64 0}
!1947 = !{!1948, !1948, i64 0}
!1948 = !{!"0x5646bcbb2c80.w1.b2", !1949, i64 0}
!1949 = !{!"0x5646bcbb2c80.w2.b2", !1936, i64 0}
!1950 = !{!1951, !1951, i64 0}
!1951 = !{!"0x5646bcbb2c80.w1.b3", !1949, i64 0}
!1952 = !{!1953, !1953, i64 0}
!1953 = !{!"0x5646bcbb2c80.w1.b1", !1935, i64 0}
!1954 = !{!1955, !1955, i64 0}
!1955 = !{!"0x5646c1f2a5f0.w1.b0", !1956, i64 0}
!1956 = !{!"0x5646c1f2a5f0.w2.b0", !1957, i64 0}
!1957 = !{!"0x5646c1f2a5f0.w4.b0", !1958, i64 0}
!1958 = !{!"0x5646c1f2a5f0.w8.b0", !1959, i64 0}
!1959 = !{!"0x5646c1f2a5f0.w16.b0", !1960, i64 0}
!1960 = !{!"0x5646c1f2a5f0.w32.b0", !1961, i64 0}
!1961 = !{!"0x5646c1f2a5f0.w64.b0", !1962, i64 0}
!1962 = !{!"0x5646c1f2a5f0.w128.b0", !1963, i64 0}
!1963 = !{!"0x5646c1f2a5f0.w256.b0", !1964, i64 0}
!1964 = !{!"0x5646c1f2a5f0.w512.b0", !1965, i64 0}
!1965 = !{!"0x5646c1f2a5f0.w1024.b0", !1966, i64 0}
!1966 = !{!"int64", !1967, i64 0}
!1967 = !{!"0x5646c1f2a5f0", !8, i64 0}
!1968 = !{!1969, !1969, i64 0}
!1969 = !{!"0x5646c1f2a5f0.w1.b1", !1956, i64 0}
!1970 = !{!1971, !1971, i64 0}
!1971 = !{!"0x5646c1f2a5f0.w1.b2", !1972, i64 0}
!1972 = !{!"0x5646c1f2a5f0.w2.b2", !1957, i64 0}
!1973 = !{!1974, !1974, i64 0}
!1974 = !{!"0x5646c1f2a5f0.w1.b3", !1972, i64 0}
!1975 = !{!1976, !1976, i64 0}
!1976 = !{!"0x5646c1f2a5f0.w1.b4", !1977, i64 0}
!1977 = !{!"0x5646c1f2a5f0.w2.b4", !1978, i64 0}
!1978 = !{!"0x5646c1f2a5f0.w4.b4", !1958, i64 0}
!1979 = !{!1980, !1980, i64 0}
!1980 = !{!"0x5646c1f2a6f0.w4.b0", !1981, i64 0}
!1981 = !{!"0x5646c1f2a6f0.w8.b0", !1982, i64 0}
!1982 = !{!"0x5646c1f2a6f0.w16.b0", !1983, i64 0}
!1983 = !{!"0x5646c1f2a6f0.w32.b0", !1984, i64 0}
!1984 = !{!"0x5646c1f2a6f0.w64.b0", !1985, i64 0}
!1985 = !{!"0x5646c1f2a6f0.w128.b0", !1986, i64 0}
!1986 = !{!"0x5646c1f2a6f0.w256.b0", !1987, i64 0}
!1987 = !{!"0x5646c1f2a6f0.w512.b0", !1988, i64 0}
!1988 = !{!"0x5646c1f2a6f0.w1024.b0", !1989, i64 0}
!1989 = !{!"int64", !1990, i64 0}
!1990 = !{!"0x5646c1f2a6f0", !8, i64 0}
!1991 = !{!1992, !1992, i64 0}
!1992 = !{!"0x5646c1f2a6f0.w1.b4", !1993, i64 0}
!1993 = !{!"0x5646c1f2a6f0.w2.b4", !1994, i64 0}
!1994 = !{!"0x5646c1f2a6f0.w4.b4", !1981, i64 0}
!1995 = !{!1996, !1996, i64 0}
!1996 = !{!"0x5646c1f2a790.w1.b0", !1997, i64 0}
!1997 = !{!"0x5646c1f2a790.w2.b0", !1998, i64 0}
!1998 = !{!"0x5646c1f2a790.w4.b0", !1999, i64 0}
!1999 = !{!"0x5646c1f2a790.w8.b0", !2000, i64 0}
!2000 = !{!"0x5646c1f2a790.w16.b0", !2001, i64 0}
!2001 = !{!"0x5646c1f2a790.w32.b0", !2002, i64 0}
!2002 = !{!"0x5646c1f2a790.w64.b0", !2003, i64 0}
!2003 = !{!"0x5646c1f2a790.w128.b0", !2004, i64 0}
!2004 = !{!"0x5646c1f2a790.w256.b0", !2005, i64 0}
!2005 = !{!"0x5646c1f2a790.w512.b0", !2006, i64 0}
!2006 = !{!"0x5646c1f2a790.w1024.b0", !2007, i64 0}
!2007 = !{!"int64", !2008, i64 0}
!2008 = !{!"0x5646c1f2a790", !8, i64 0}
!2009 = !{!2010, !2010, i64 0}
!2010 = !{!"0x5646c1f2a790.w1.b1", !1997, i64 0}
!2011 = !{!2012, !2012, i64 0}
!2012 = !{!"0x5646c1f2a790.w1.b2", !2013, i64 0}
!2013 = !{!"0x5646c1f2a790.w2.b2", !1998, i64 0}
!2014 = !{!2015, !2015, i64 0}
!2015 = !{!"0x5646c1f2a790.w1.b3", !2013, i64 0}
!2016 = !{!2017, !2017, i64 0}
!2017 = !{!"0x5646c1f2a790.w1.b4", !2018, i64 0}
!2018 = !{!"0x5646c1f2a790.w2.b4", !2019, i64 0}
!2019 = !{!"0x5646c1f2a790.w4.b4", !1999, i64 0}
!2020 = !{!2021, !2021, i64 0}
!2021 = !{!"0x5646c1f2a790.w1.b5", !2018, i64 0}
!2022 = !{!2023, !2023, i64 0}
!2023 = !{!"0x5646c1f2a6a0.w4.b0", !2024, i64 0}
!2024 = !{!"0x5646c1f2a6a0.w8.b0", !2025, i64 0}
!2025 = !{!"0x5646c1f2a6a0.w16.b0", !2026, i64 0}
!2026 = !{!"0x5646c1f2a6a0.w32.b0", !2027, i64 0}
!2027 = !{!"0x5646c1f2a6a0.w64.b0", !2028, i64 0}
!2028 = !{!"0x5646c1f2a6a0.w128.b0", !2029, i64 0}
!2029 = !{!"0x5646c1f2a6a0.w256.b0", !2030, i64 0}
!2030 = !{!"0x5646c1f2a6a0.w512.b0", !2031, i64 0}
!2031 = !{!"0x5646c1f2a6a0.w1024.b0", !2032, i64 0}
!2032 = !{!"int64", !2033, i64 0}
!2033 = !{!"0x5646c1f2a6a0", !8, i64 0}
!2034 = !{!2035, !2035, i64 0}
!2035 = !{!"0x5646c1f2a6a0.w1.b4", !2036, i64 0}
!2036 = !{!"0x5646c1f2a6a0.w2.b4", !2037, i64 0}
!2037 = !{!"0x5646c1f2a6a0.w4.b4", !2024, i64 0}
!2038 = !{!2039, !2039, i64 0}
!2039 = !{!"0x5646c1f2a6a0.w1.b5", !2036, i64 0}
!2040 = !{!2041, !2041, i64 0}
!2041 = !{!"0x5646c1f2ace0.w1.b0", !2042, i64 0}
!2042 = !{!"0x5646c1f2ace0.w2.b0", !2043, i64 0}
!2043 = !{!"0x5646c1f2ace0.w4.b0", !2044, i64 0}
!2044 = !{!"0x5646c1f2ace0.w8.b0", !2045, i64 0}
!2045 = !{!"0x5646c1f2ace0.w16.b0", !2046, i64 0}
!2046 = !{!"0x5646c1f2ace0.w32.b0", !2047, i64 0}
!2047 = !{!"0x5646c1f2ace0.w64.b0", !2048, i64 0}
!2048 = !{!"0x5646c1f2ace0.w128.b0", !2049, i64 0}
!2049 = !{!"0x5646c1f2ace0.w256.b0", !2050, i64 0}
!2050 = !{!"0x5646c1f2ace0.w512.b0", !2051, i64 0}
!2051 = !{!"0x5646c1f2ace0.w1024.b0", !2052, i64 0}
!2052 = !{!"int64", !2053, i64 0}
!2053 = !{!"0x5646c1f2ace0", !8, i64 0}
!2054 = !{!2055, !2055, i64 0}
!2055 = !{!"0x5646c1f2ace0.w1.b1", !2042, i64 0}
!2056 = !{!2057, !2057, i64 0}
!2057 = !{!"0x5646c1f2ace0.w1.b2", !2058, i64 0}
!2058 = !{!"0x5646c1f2ace0.w2.b2", !2043, i64 0}
!2059 = !{!2060, !2060, i64 0}
!2060 = !{!"0x5646c1f2ace0.w1.b3", !2058, i64 0}
!2061 = !{!2062, !2062, i64 0}
!2062 = !{!"0x5646c1f2ace0.w1.b4", !2063, i64 0}
!2063 = !{!"0x5646c1f2ace0.w2.b4", !2064, i64 0}
!2064 = !{!"0x5646c1f2ace0.w4.b4", !2044, i64 0}
!2065 = !{!2066, !2066, i64 0}
!2066 = !{!"0x5646c1f2aeb0.w4.b0", !2067, i64 0}
!2067 = !{!"0x5646c1f2aeb0.w8.b0", !2068, i64 0}
!2068 = !{!"0x5646c1f2aeb0.w16.b0", !2069, i64 0}
!2069 = !{!"0x5646c1f2aeb0.w32.b0", !2070, i64 0}
!2070 = !{!"0x5646c1f2aeb0.w64.b0", !2071, i64 0}
!2071 = !{!"0x5646c1f2aeb0.w128.b0", !2072, i64 0}
!2072 = !{!"0x5646c1f2aeb0.w256.b0", !2073, i64 0}
!2073 = !{!"0x5646c1f2aeb0.w512.b0", !2074, i64 0}
!2074 = !{!"0x5646c1f2aeb0.w1024.b0", !2075, i64 0}
!2075 = !{!"int64", !2076, i64 0}
!2076 = !{!"0x5646c1f2aeb0", !8, i64 0}
!2077 = !{!2078, !2078, i64 0}
!2078 = !{!"0x5646c1f2aeb0.w1.b4", !2079, i64 0}
!2079 = !{!"0x5646c1f2aeb0.w2.b4", !2080, i64 0}
!2080 = !{!"0x5646c1f2aeb0.w4.b4", !2067, i64 0}
!2081 = !{!2082, !2082, i64 0}
!2082 = !{!"0x5646c1f2b550.w1.b0", !2083, i64 0}
!2083 = !{!"0x5646c1f2b550.w2.b0", !2084, i64 0}
!2084 = !{!"0x5646c1f2b550.w4.b0", !2085, i64 0}
!2085 = !{!"0x5646c1f2b550.w8.b0", !2086, i64 0}
!2086 = !{!"0x5646c1f2b550.w16.b0", !2087, i64 0}
!2087 = !{!"0x5646c1f2b550.w32.b0", !2088, i64 0}
!2088 = !{!"0x5646c1f2b550.w64.b0", !2089, i64 0}
!2089 = !{!"0x5646c1f2b550.w128.b0", !2090, i64 0}
!2090 = !{!"0x5646c1f2b550.w256.b0", !2091, i64 0}
!2091 = !{!"0x5646c1f2b550.w512.b0", !2092, i64 0}
!2092 = !{!"0x5646c1f2b550.w1024.b0", !2093, i64 0}
!2093 = !{!"int64", !2094, i64 0}
!2094 = !{!"0x5646c1f2b550", !8, i64 0}
!2095 = !{!2096, !2096, i64 0}
!2096 = !{!"0x5646c1f2b550.w1.b1", !2083, i64 0}
!2097 = !{!2098, !2098, i64 0}
!2098 = !{!"0x5646c1f2b550.w1.b2", !2099, i64 0}
!2099 = !{!"0x5646c1f2b550.w2.b2", !2084, i64 0}
!2100 = !{!2101, !2101, i64 0}
!2101 = !{!"0x5646c1f2b550.w1.b3", !2099, i64 0}
!2102 = !{!2103, !2103, i64 0}
!2103 = !{!"0x5646c1f2b550.w1.b4", !2104, i64 0}
!2104 = !{!"0x5646c1f2b550.w2.b4", !2105, i64 0}
!2105 = !{!"0x5646c1f2b550.w4.b4", !2085, i64 0}
!2106 = !{!2107, !2107, i64 0}
!2107 = !{!"0x5646c1f2b5a0.w4.b0", !2108, i64 0}
!2108 = !{!"0x5646c1f2b5a0.w8.b0", !2109, i64 0}
!2109 = !{!"0x5646c1f2b5a0.w16.b0", !2110, i64 0}
!2110 = !{!"0x5646c1f2b5a0.w32.b0", !2111, i64 0}
!2111 = !{!"0x5646c1f2b5a0.w64.b0", !2112, i64 0}
!2112 = !{!"0x5646c1f2b5a0.w128.b0", !2113, i64 0}
!2113 = !{!"0x5646c1f2b5a0.w256.b0", !2114, i64 0}
!2114 = !{!"0x5646c1f2b5a0.w512.b0", !2115, i64 0}
!2115 = !{!"0x5646c1f2b5a0.w1024.b0", !2116, i64 0}
!2116 = !{!"int64", !2117, i64 0}
!2117 = !{!"0x5646c1f2b5a0", !8, i64 0}
!2118 = !{!2119, !2119, i64 0}
!2119 = !{!"0x5646c1f2b5a0.w1.b4", !2120, i64 0}
!2120 = !{!"0x5646c1f2b5a0.w2.b4", !2121, i64 0}
!2121 = !{!"0x5646c1f2b5a0.w4.b4", !2108, i64 0}
!2122 = !{!2123, !2123, i64 0}
!2123 = !{!"float32", !2124, i64 0}
!2124 = !{!"0x5646bcbb1c70", !8, i64 0}
!2125 = !{!2126, !2126, i64 0}
!2126 = !{!"float32", !2127, i64 0}
!2127 = !{!"0x5646bcbb3310", !8, i64 0}
!2128 = !{!2129, !2129, i64 0}
!2129 = !{!"float32", !2130, i64 0}
!2130 = !{!"0x5646bcbb28c0", !8, i64 0}
!2131 = !{!2132, !2132, i64 0}
!2132 = !{!"float32", !2133, i64 0}
!2133 = !{!"0x5646bcbb2810", !8, i64 0}
!2134 = !{!2135, !2135, i64 0}
!2135 = !{!"float32", !2136, i64 0}
!2136 = !{!"0x5646bcbb27c0", !8, i64 0}
!2137 = !{!2138, !2138, i64 0}
!2138 = !{!"0x5646c41ce700.w1.b0", !2139, i64 0}
!2139 = !{!"0x5646c41ce700.w2.b0", !2140, i64 0}
!2140 = !{!"0x5646c41ce700.w4.b0", !2141, i64 0}
!2141 = !{!"0x5646c41ce700.w8.b0", !2142, i64 0}
!2142 = !{!"0x5646c41ce700.w16.b0", !2143, i64 0}
!2143 = !{!"0x5646c41ce700.w32.b0", !2144, i64 0}
!2144 = !{!"0x5646c41ce700.w64.b0", !2145, i64 0}
!2145 = !{!"0x5646c41ce700.w128.b0", !2146, i64 0}
!2146 = !{!"0x5646c41ce700.w256.b0", !2147, i64 0}
!2147 = !{!"0x5646c41ce700.w512.b0", !2148, i64 0}
!2148 = !{!"0x5646c41ce700.w1024.b0", !2149, i64 0}
!2149 = !{!"int32", !2150, i64 0}
!2150 = !{!"0x5646c41ce700", !8, i64 0}
!2151 = !{!2152, !2152, i64 0}
!2152 = !{!"0x5646c41ce700.w1.b1", !2139, i64 0}
!2153 = !{!2154, !2154, i64 0}
!2154 = !{!"0x5646c41cfe00.w1.b0", !2155, i64 0}
!2155 = !{!"0x5646c41cfe00.w2.b0", !2156, i64 0}
!2156 = !{!"0x5646c41cfe00.w4.b0", !2157, i64 0}
!2157 = !{!"0x5646c41cfe00.w8.b0", !2158, i64 0}
!2158 = !{!"0x5646c41cfe00.w16.b0", !2159, i64 0}
!2159 = !{!"0x5646c41cfe00.w32.b0", !2160, i64 0}
!2160 = !{!"0x5646c41cfe00.w64.b0", !2161, i64 0}
!2161 = !{!"0x5646c41cfe00.w128.b0", !2162, i64 0}
!2162 = !{!"0x5646c41cfe00.w256.b0", !2163, i64 0}
!2163 = !{!"0x5646c41cfe00.w512.b0", !2164, i64 0}
!2164 = !{!"0x5646c41cfe00.w1024.b0", !2165, i64 0}
!2165 = !{!"int64", !2166, i64 0}
!2166 = !{!"0x5646c41cfe00", !8, i64 0}
!2167 = !{!2168, !2168, i64 0}
!2168 = !{!"0x5646c41cfe00.w1.b1", !2155, i64 0}
!2169 = !{!2170, !2170, i64 0}
!2170 = !{!"0x5646c41cfe00.w1.b2", !2171, i64 0}
!2171 = !{!"0x5646c41cfe00.w2.b2", !2156, i64 0}
!2172 = !{!2173, !2173, i64 0}
!2173 = !{!"0x5646c41cfe00.w1.b3", !2171, i64 0}
!2174 = !{!2175, !2175, i64 0}
!2175 = !{!"0x5646c41cfe00.w1.b4", !2176, i64 0}
!2176 = !{!"0x5646c41cfe00.w2.b4", !2177, i64 0}
!2177 = !{!"0x5646c41cfe00.w4.b4", !2157, i64 0}
!2178 = !{!2179, !2179, i64 0}
!2179 = !{!"0x5646c41d0120.w4.b0", !2180, i64 0}
!2180 = !{!"0x5646c41d0120.w8.b0", !2181, i64 0}
!2181 = !{!"0x5646c41d0120.w16.b0", !2182, i64 0}
!2182 = !{!"0x5646c41d0120.w32.b0", !2183, i64 0}
!2183 = !{!"0x5646c41d0120.w64.b0", !2184, i64 0}
!2184 = !{!"0x5646c41d0120.w128.b0", !2185, i64 0}
!2185 = !{!"0x5646c41d0120.w256.b0", !2186, i64 0}
!2186 = !{!"0x5646c41d0120.w512.b0", !2187, i64 0}
!2187 = !{!"0x5646c41d0120.w1024.b0", !2188, i64 0}
!2188 = !{!"int64", !2189, i64 0}
!2189 = !{!"0x5646c41d0120", !8, i64 0}
!2190 = !{!2191, !2191, i64 0}
!2191 = !{!"0x5646c41d0120.w1.b4", !2192, i64 0}
!2192 = !{!"0x5646c41d0120.w2.b4", !2193, i64 0}
!2193 = !{!"0x5646c41d0120.w4.b4", !2180, i64 0}
!2194 = !{!2195, !2195, i64 0}
!2195 = !{!"0x5646c41d0370.w1.b0", !2196, i64 0}
!2196 = !{!"0x5646c41d0370.w2.b0", !2197, i64 0}
!2197 = !{!"0x5646c41d0370.w4.b0", !2198, i64 0}
!2198 = !{!"0x5646c41d0370.w8.b0", !2199, i64 0}
!2199 = !{!"0x5646c41d0370.w16.b0", !2200, i64 0}
!2200 = !{!"0x5646c41d0370.w32.b0", !2201, i64 0}
!2201 = !{!"0x5646c41d0370.w64.b0", !2202, i64 0}
!2202 = !{!"0x5646c41d0370.w128.b0", !2203, i64 0}
!2203 = !{!"0x5646c41d0370.w256.b0", !2204, i64 0}
!2204 = !{!"0x5646c41d0370.w512.b0", !2205, i64 0}
!2205 = !{!"0x5646c41d0370.w1024.b0", !2206, i64 0}
!2206 = !{!"int64", !2207, i64 0}
!2207 = !{!"0x5646c41d0370", !8, i64 0}
!2208 = !{!2209, !2209, i64 0}
!2209 = !{!"0x5646c41d0370.w1.b1", !2196, i64 0}
!2210 = !{!2211, !2211, i64 0}
!2211 = !{!"0x5646c41d0370.w1.b2", !2212, i64 0}
!2212 = !{!"0x5646c41d0370.w2.b2", !2197, i64 0}
!2213 = !{!2214, !2214, i64 0}
!2214 = !{!"0x5646c41d0370.w1.b3", !2212, i64 0}
!2215 = !{!2216, !2216, i64 0}
!2216 = !{!"0x5646c41d0370.w1.b4", !2217, i64 0}
!2217 = !{!"0x5646c41d0370.w2.b4", !2218, i64 0}
!2218 = !{!"0x5646c41d0370.w4.b4", !2198, i64 0}
!2219 = !{!2220, !2220, i64 0}
!2220 = !{!"0x5646c41d2c50.w4.b0", !2221, i64 0}
!2221 = !{!"0x5646c41d2c50.w8.b0", !2222, i64 0}
!2222 = !{!"0x5646c41d2c50.w16.b0", !2223, i64 0}
!2223 = !{!"0x5646c41d2c50.w32.b0", !2224, i64 0}
!2224 = !{!"0x5646c41d2c50.w64.b0", !2225, i64 0}
!2225 = !{!"0x5646c41d2c50.w128.b0", !2226, i64 0}
!2226 = !{!"0x5646c41d2c50.w256.b0", !2227, i64 0}
!2227 = !{!"0x5646c41d2c50.w512.b0", !2228, i64 0}
!2228 = !{!"0x5646c41d2c50.w1024.b0", !2229, i64 0}
!2229 = !{!"int64", !2230, i64 0}
!2230 = !{!"0x5646c41d2c50", !8, i64 0}
!2231 = !{!2232, !2232, i64 0}
!2232 = !{!"0x5646c41d2c50.w1.b4", !2233, i64 0}
!2233 = !{!"0x5646c41d2c50.w2.b4", !2234, i64 0}
!2234 = !{!"0x5646c41d2c50.w4.b4", !2221, i64 0}
!2235 = !{!2236, !2236, i64 0}
!2236 = !{!"float32", !2237, i64 0}
!2237 = !{!"0x5646c41cae10", !8, i64 0}
!2238 = !{!2239, !2239, i64 0}
!2239 = !{!"float32", !2240, i64 0}
!2240 = !{!"0x5646c41be9b0", !8, i64 0}
!2241 = !{!2242, !2242, i64 0}
!2242 = !{!"0x5646c412bda0.w1.b0", !2243, i64 0}
!2243 = !{!"0x5646c412bda0.w2.b0", !2244, i64 0}
!2244 = !{!"0x5646c412bda0.w4.b0", !2245, i64 0}
!2245 = !{!"0x5646c412bda0.w8.b0", !2246, i64 0}
!2246 = !{!"0x5646c412bda0.w16.b0", !2247, i64 0}
!2247 = !{!"0x5646c412bda0.w32.b0", !2248, i64 0}
!2248 = !{!"0x5646c412bda0.w64.b0", !2249, i64 0}
!2249 = !{!"0x5646c412bda0.w128.b0", !2250, i64 0}
!2250 = !{!"0x5646c412bda0.w256.b0", !2251, i64 0}
!2251 = !{!"0x5646c412bda0.w512.b0", !2252, i64 0}
!2252 = !{!"0x5646c412bda0.w1024.b0", !2253, i64 0}
!2253 = !{!"int32", !2254, i64 0}
!2254 = !{!"0x5646c412bda0", !8, i64 0}
!2255 = !{!2256, !2256, i64 0}
!2256 = !{!"0x5646c412bda0.w1.b1", !2243, i64 0}
!2257 = !{!2258, !2258, i64 0}
!2258 = !{!"0x5646c1eade90.w1.b0", !2259, i64 0}
!2259 = !{!"0x5646c1eade90.w2.b0", !2260, i64 0}
!2260 = !{!"0x5646c1eade90.w4.b0", !2261, i64 0}
!2261 = !{!"0x5646c1eade90.w8.b0", !2262, i64 0}
!2262 = !{!"0x5646c1eade90.w16.b0", !2263, i64 0}
!2263 = !{!"0x5646c1eade90.w32.b0", !2264, i64 0}
!2264 = !{!"0x5646c1eade90.w64.b0", !2265, i64 0}
!2265 = !{!"0x5646c1eade90.w128.b0", !2266, i64 0}
!2266 = !{!"0x5646c1eade90.w256.b0", !2267, i64 0}
!2267 = !{!"0x5646c1eade90.w512.b0", !2268, i64 0}
!2268 = !{!"0x5646c1eade90.w1024.b0", !2269, i64 0}
!2269 = !{!"int64", !2270, i64 0}
!2270 = !{!"0x5646c1eade90", !8, i64 0}
!2271 = !{!2272, !2272, i64 0}
!2272 = !{!"0x5646c1eade90.w1.b1", !2259, i64 0}
!2273 = !{!2274, !2274, i64 0}
!2274 = !{!"0x5646c1eade90.w1.b2", !2275, i64 0}
!2275 = !{!"0x5646c1eade90.w2.b2", !2260, i64 0}
!2276 = !{!2277, !2277, i64 0}
!2277 = !{!"0x5646c1eade90.w1.b3", !2275, i64 0}
!2278 = !{!2279, !2279, i64 0}
!2279 = !{!"0x5646c1eade90.w1.b4", !2280, i64 0}
!2280 = !{!"0x5646c1eade90.w2.b4", !2281, i64 0}
!2281 = !{!"0x5646c1eade90.w4.b4", !2261, i64 0}
!2282 = !{!2283, !2283, i64 0}
!2283 = !{!"0x5646c1eae1b0.w4.b0", !2284, i64 0}
!2284 = !{!"0x5646c1eae1b0.w8.b0", !2285, i64 0}
!2285 = !{!"0x5646c1eae1b0.w16.b0", !2286, i64 0}
!2286 = !{!"0x5646c1eae1b0.w32.b0", !2287, i64 0}
!2287 = !{!"0x5646c1eae1b0.w64.b0", !2288, i64 0}
!2288 = !{!"0x5646c1eae1b0.w128.b0", !2289, i64 0}
!2289 = !{!"0x5646c1eae1b0.w256.b0", !2290, i64 0}
!2290 = !{!"0x5646c1eae1b0.w512.b0", !2291, i64 0}
!2291 = !{!"0x5646c1eae1b0.w1024.b0", !2292, i64 0}
!2292 = !{!"int64", !2293, i64 0}
!2293 = !{!"0x5646c1eae1b0", !8, i64 0}
!2294 = !{!2295, !2295, i64 0}
!2295 = !{!"0x5646c1eae1b0.w1.b4", !2296, i64 0}
!2296 = !{!"0x5646c1eae1b0.w2.b4", !2297, i64 0}
!2297 = !{!"0x5646c1eae1b0.w4.b4", !2284, i64 0}
!2298 = !{!2299, !2299, i64 0}
!2299 = !{!"0x5646c1eae400.w1.b0", !2300, i64 0}
!2300 = !{!"0x5646c1eae400.w2.b0", !2301, i64 0}
!2301 = !{!"0x5646c1eae400.w4.b0", !2302, i64 0}
!2302 = !{!"0x5646c1eae400.w8.b0", !2303, i64 0}
!2303 = !{!"0x5646c1eae400.w16.b0", !2304, i64 0}
!2304 = !{!"0x5646c1eae400.w32.b0", !2305, i64 0}
!2305 = !{!"0x5646c1eae400.w64.b0", !2306, i64 0}
!2306 = !{!"0x5646c1eae400.w128.b0", !2307, i64 0}
!2307 = !{!"0x5646c1eae400.w256.b0", !2308, i64 0}
!2308 = !{!"0x5646c1eae400.w512.b0", !2309, i64 0}
!2309 = !{!"0x5646c1eae400.w1024.b0", !2310, i64 0}
!2310 = !{!"int64", !2311, i64 0}
!2311 = !{!"0x5646c1eae400", !8, i64 0}
!2312 = !{!2313, !2313, i64 0}
!2313 = !{!"0x5646c1eae400.w1.b1", !2300, i64 0}
!2314 = !{!2315, !2315, i64 0}
!2315 = !{!"0x5646c1eae400.w1.b2", !2316, i64 0}
!2316 = !{!"0x5646c1eae400.w2.b2", !2301, i64 0}
!2317 = !{!2318, !2318, i64 0}
!2318 = !{!"0x5646c1eae400.w1.b3", !2316, i64 0}
!2319 = !{!2320, !2320, i64 0}
!2320 = !{!"0x5646c1eae400.w1.b4", !2321, i64 0}
!2321 = !{!"0x5646c1eae400.w2.b4", !2322, i64 0}
!2322 = !{!"0x5646c1eae400.w4.b4", !2302, i64 0}
!2323 = !{!2324, !2324, i64 0}
!2324 = !{!"0x5646c1eae030.w4.b0", !2325, i64 0}
!2325 = !{!"0x5646c1eae030.w8.b0", !2326, i64 0}
!2326 = !{!"0x5646c1eae030.w16.b0", !2327, i64 0}
!2327 = !{!"0x5646c1eae030.w32.b0", !2328, i64 0}
!2328 = !{!"0x5646c1eae030.w64.b0", !2329, i64 0}
!2329 = !{!"0x5646c1eae030.w128.b0", !2330, i64 0}
!2330 = !{!"0x5646c1eae030.w256.b0", !2331, i64 0}
!2331 = !{!"0x5646c1eae030.w512.b0", !2332, i64 0}
!2332 = !{!"0x5646c1eae030.w1024.b0", !2333, i64 0}
!2333 = !{!"int64", !2334, i64 0}
!2334 = !{!"0x5646c1eae030", !8, i64 0}
!2335 = !{!2336, !2336, i64 0}
!2336 = !{!"0x5646c1eae030.w1.b4", !2337, i64 0}
!2337 = !{!"0x5646c1eae030.w2.b4", !2338, i64 0}
!2338 = !{!"0x5646c1eae030.w4.b4", !2325, i64 0}
!2339 = !{!2340, !2340, i64 0}
!2340 = !{!"float32", !2341, i64 0}
!2341 = !{!"0x5646bbe48870", !8, i64 0}
!2342 = !{!2343, !2343, i64 0}
!2343 = !{!"float32", !2344, i64 0}
!2344 = !{!"0x5646c08b7280", !8, i64 0}
!2345 = !{!2346, !2346, i64 0}
!2346 = !{!"0x5646bc8d24c0.w1.b0", !2347, i64 0}
!2347 = !{!"0x5646bc8d24c0.w2.b0", !2348, i64 0}
!2348 = !{!"0x5646bc8d24c0.w4.b0", !2349, i64 0}
!2349 = !{!"0x5646bc8d24c0.w8.b0", !2350, i64 0}
!2350 = !{!"0x5646bc8d24c0.w16.b0", !2351, i64 0}
!2351 = !{!"0x5646bc8d24c0.w32.b0", !2352, i64 0}
!2352 = !{!"0x5646bc8d24c0.w64.b0", !2353, i64 0}
!2353 = !{!"0x5646bc8d24c0.w128.b0", !2354, i64 0}
!2354 = !{!"0x5646bc8d24c0.w256.b0", !2355, i64 0}
!2355 = !{!"0x5646bc8d24c0.w512.b0", !2356, i64 0}
!2356 = !{!"0x5646bc8d24c0.w1024.b0", !2357, i64 0}
!2357 = !{!"int32", !2358, i64 0}
!2358 = !{!"0x5646bc8d24c0", !8, i64 0}
!2359 = !{!2360, !2360, i64 0}
!2360 = !{!"0x5646bc8d24c0.w1.b2", !2361, i64 0}
!2361 = !{!"0x5646bc8d24c0.w2.b2", !2348, i64 0}
!2362 = !{!2363, !2363, i64 0}
!2363 = !{!"0x5646bc8d24c0.w1.b3", !2361, i64 0}
!2364 = !{!2365, !2365, i64 0}
!2365 = !{!"0x5646bc8d24c0.w1.b4", !2366, i64 0}
!2366 = !{!"0x5646bc8d24c0.w2.b4", !2367, i64 0}
!2367 = !{!"0x5646bc8d24c0.w4.b4", !2349, i64 0}
!2368 = !{!2369, !2369, i64 0}
!2369 = !{!"0x5646bc8d24c0.w1.b1", !2347, i64 0}
!2370 = !{!2371, !2371, i64 0}
!2371 = !{!"0x5646bc92fbe0.w1.b0", !2372, i64 0}
!2372 = !{!"0x5646bc92fbe0.w2.b0", !2373, i64 0}
!2373 = !{!"0x5646bc92fbe0.w4.b0", !2374, i64 0}
!2374 = !{!"0x5646bc92fbe0.w8.b0", !2375, i64 0}
!2375 = !{!"0x5646bc92fbe0.w16.b0", !2376, i64 0}
!2376 = !{!"0x5646bc92fbe0.w32.b0", !2377, i64 0}
!2377 = !{!"0x5646bc92fbe0.w64.b0", !2378, i64 0}
!2378 = !{!"0x5646bc92fbe0.w128.b0", !2379, i64 0}
!2379 = !{!"0x5646bc92fbe0.w256.b0", !2380, i64 0}
!2380 = !{!"0x5646bc92fbe0.w512.b0", !2381, i64 0}
!2381 = !{!"0x5646bc92fbe0.w1024.b0", !2382, i64 0}
!2382 = !{!"int64", !2383, i64 0}
!2383 = !{!"0x5646bc92fbe0", !8, i64 0}
!2384 = !{!2385, !2385, i64 0}
!2385 = !{!"0x5646bc92fbe0.w1.b1", !2372, i64 0}
!2386 = !{!2387, !2387, i64 0}
!2387 = !{!"0x5646bc92fbe0.w1.b2", !2388, i64 0}
!2388 = !{!"0x5646bc92fbe0.w2.b2", !2373, i64 0}
!2389 = !{!2390, !2390, i64 0}
!2390 = !{!"0x5646bc92fbe0.w1.b3", !2388, i64 0}
!2391 = !{!2392, !2392, i64 0}
!2392 = !{!"0x5646bc92fbe0.w1.b4", !2393, i64 0}
!2393 = !{!"0x5646bc92fbe0.w2.b4", !2394, i64 0}
!2394 = !{!"0x5646bc92fbe0.w4.b4", !2374, i64 0}
!2395 = !{!2396, !2396, i64 0}
!2396 = !{!"0x5646bc8c6e00.w4.b0", !2397, i64 0}
!2397 = !{!"0x5646bc8c6e00.w8.b0", !2398, i64 0}
!2398 = !{!"0x5646bc8c6e00.w16.b0", !2399, i64 0}
!2399 = !{!"0x5646bc8c6e00.w32.b0", !2400, i64 0}
!2400 = !{!"0x5646bc8c6e00.w64.b0", !2401, i64 0}
!2401 = !{!"0x5646bc8c6e00.w128.b0", !2402, i64 0}
!2402 = !{!"0x5646bc8c6e00.w256.b0", !2403, i64 0}
!2403 = !{!"0x5646bc8c6e00.w512.b0", !2404, i64 0}
!2404 = !{!"0x5646bc8c6e00.w1024.b0", !2405, i64 0}
!2405 = !{!"int64", !2406, i64 0}
!2406 = !{!"0x5646bc8c6e00", !8, i64 0}
!2407 = !{!2408, !2408, i64 0}
!2408 = !{!"0x5646bc8c6e00.w1.b4", !2409, i64 0}
!2409 = !{!"0x5646bc8c6e00.w2.b4", !2410, i64 0}
!2410 = !{!"0x5646bc8c6e00.w4.b4", !2397, i64 0}
!2411 = !{!2412, !2412, i64 0}
!2412 = !{!"0x5646bc92ce50.w1.b0", !2413, i64 0}
!2413 = !{!"0x5646bc92ce50.w2.b0", !2414, i64 0}
!2414 = !{!"0x5646bc92ce50.w4.b0", !2415, i64 0}
!2415 = !{!"0x5646bc92ce50.w8.b0", !2416, i64 0}
!2416 = !{!"0x5646bc92ce50.w16.b0", !2417, i64 0}
!2417 = !{!"0x5646bc92ce50.w32.b0", !2418, i64 0}
!2418 = !{!"0x5646bc92ce50.w64.b0", !2419, i64 0}
!2419 = !{!"0x5646bc92ce50.w128.b0", !2420, i64 0}
!2420 = !{!"0x5646bc92ce50.w256.b0", !2421, i64 0}
!2421 = !{!"0x5646bc92ce50.w512.b0", !2422, i64 0}
!2422 = !{!"0x5646bc92ce50.w1024.b0", !2423, i64 0}
!2423 = !{!"int64", !2424, i64 0}
!2424 = !{!"0x5646bc92ce50", !8, i64 0}
!2425 = !{!2426, !2426, i64 0}
!2426 = !{!"0x5646bc92ce50.w1.b1", !2413, i64 0}
!2427 = !{!2428, !2428, i64 0}
!2428 = !{!"0x5646bc92ce50.w1.b2", !2429, i64 0}
!2429 = !{!"0x5646bc92ce50.w2.b2", !2414, i64 0}
!2430 = !{!2431, !2431, i64 0}
!2431 = !{!"0x5646bc92ce50.w1.b3", !2429, i64 0}
!2432 = !{!2433, !2433, i64 0}
!2433 = !{!"0x5646bc92ce50.w1.b4", !2434, i64 0}
!2434 = !{!"0x5646bc92ce50.w2.b4", !2435, i64 0}
!2435 = !{!"0x5646bc92ce50.w4.b4", !2415, i64 0}
!2436 = !{!2437, !2437, i64 0}
!2437 = !{!"0x5646bc92ce50.w1.b5", !2434, i64 0}
!2438 = !{!2439, !2439, i64 0}
!2439 = !{!"0x5646bc931ab0.w4.b0", !2440, i64 0}
!2440 = !{!"0x5646bc931ab0.w8.b0", !2441, i64 0}
!2441 = !{!"0x5646bc931ab0.w16.b0", !2442, i64 0}
!2442 = !{!"0x5646bc931ab0.w32.b0", !2443, i64 0}
!2443 = !{!"0x5646bc931ab0.w64.b0", !2444, i64 0}
!2444 = !{!"0x5646bc931ab0.w128.b0", !2445, i64 0}
!2445 = !{!"0x5646bc931ab0.w256.b0", !2446, i64 0}
!2446 = !{!"0x5646bc931ab0.w512.b0", !2447, i64 0}
!2447 = !{!"0x5646bc931ab0.w1024.b0", !2448, i64 0}
!2448 = !{!"int64", !2449, i64 0}
!2449 = !{!"0x5646bc931ab0", !8, i64 0}
!2450 = !{!2451, !2451, i64 0}
!2451 = !{!"0x5646bc931ab0.w1.b4", !2452, i64 0}
!2452 = !{!"0x5646bc931ab0.w2.b4", !2453, i64 0}
!2453 = !{!"0x5646bc931ab0.w4.b4", !2440, i64 0}
!2454 = !{!2455, !2455, i64 0}
!2455 = !{!"0x5646bc931ab0.w1.b5", !2452, i64 0}
!2456 = !{!2457, !2457, i64 0}
!2457 = !{!"0x5646bc8c7140.w1.b0", !2458, i64 0}
!2458 = !{!"0x5646bc8c7140.w2.b0", !2459, i64 0}
!2459 = !{!"0x5646bc8c7140.w4.b0", !2460, i64 0}
!2460 = !{!"0x5646bc8c7140.w8.b0", !2461, i64 0}
!2461 = !{!"0x5646bc8c7140.w16.b0", !2462, i64 0}
!2462 = !{!"0x5646bc8c7140.w32.b0", !2463, i64 0}
!2463 = !{!"0x5646bc8c7140.w64.b0", !2464, i64 0}
!2464 = !{!"0x5646bc8c7140.w128.b0", !2465, i64 0}
!2465 = !{!"0x5646bc8c7140.w256.b0", !2466, i64 0}
!2466 = !{!"0x5646bc8c7140.w512.b0", !2467, i64 0}
!2467 = !{!"0x5646bc8c7140.w1024.b0", !2468, i64 0}
!2468 = !{!"int64", !2469, i64 0}
!2469 = !{!"0x5646bc8c7140", !8, i64 0}
!2470 = !{!2471, !2471, i64 0}
!2471 = !{!"0x5646bc8c7140.w1.b1", !2458, i64 0}
!2472 = !{!2473, !2473, i64 0}
!2473 = !{!"0x5646bc8c7140.w1.b2", !2474, i64 0}
!2474 = !{!"0x5646bc8c7140.w2.b2", !2459, i64 0}
!2475 = !{!2476, !2476, i64 0}
!2476 = !{!"0x5646bc8c7140.w1.b3", !2474, i64 0}
!2477 = !{!2478, !2478, i64 0}
!2478 = !{!"0x5646bc8c7140.w1.b4", !2479, i64 0}
!2479 = !{!"0x5646bc8c7140.w2.b4", !2480, i64 0}
!2480 = !{!"0x5646bc8c7140.w4.b4", !2460, i64 0}
!2481 = !{!2482, !2482, i64 0}
!2482 = !{!"0x5646bc8d3770.w4.b0", !2483, i64 0}
!2483 = !{!"0x5646bc8d3770.w8.b0", !2484, i64 0}
!2484 = !{!"0x5646bc8d3770.w16.b0", !2485, i64 0}
!2485 = !{!"0x5646bc8d3770.w32.b0", !2486, i64 0}
!2486 = !{!"0x5646bc8d3770.w64.b0", !2487, i64 0}
!2487 = !{!"0x5646bc8d3770.w128.b0", !2488, i64 0}
!2488 = !{!"0x5646bc8d3770.w256.b0", !2489, i64 0}
!2489 = !{!"0x5646bc8d3770.w512.b0", !2490, i64 0}
!2490 = !{!"0x5646bc8d3770.w1024.b0", !2491, i64 0}
!2491 = !{!"int64", !2492, i64 0}
!2492 = !{!"0x5646bc8d3770", !8, i64 0}
!2493 = !{!2494, !2494, i64 0}
!2494 = !{!"0x5646bc8d3770.w1.b4", !2495, i64 0}
!2495 = !{!"0x5646bc8d3770.w2.b4", !2496, i64 0}
!2496 = !{!"0x5646bc8d3770.w4.b4", !2483, i64 0}
!2497 = !{!2498, !2498, i64 0}
!2498 = !{!"0x5646bc8d4990.w1.b0", !2499, i64 0}
!2499 = !{!"0x5646bc8d4990.w2.b0", !2500, i64 0}
!2500 = !{!"0x5646bc8d4990.w4.b0", !2501, i64 0}
!2501 = !{!"0x5646bc8d4990.w8.b0", !2502, i64 0}
!2502 = !{!"0x5646bc8d4990.w16.b0", !2503, i64 0}
!2503 = !{!"0x5646bc8d4990.w32.b0", !2504, i64 0}
!2504 = !{!"0x5646bc8d4990.w64.b0", !2505, i64 0}
!2505 = !{!"0x5646bc8d4990.w128.b0", !2506, i64 0}
!2506 = !{!"0x5646bc8d4990.w256.b0", !2507, i64 0}
!2507 = !{!"0x5646bc8d4990.w512.b0", !2508, i64 0}
!2508 = !{!"0x5646bc8d4990.w1024.b0", !2509, i64 0}
!2509 = !{!"int64", !2510, i64 0}
!2510 = !{!"0x5646bc8d4990", !8, i64 0}
!2511 = !{!2512, !2512, i64 0}
!2512 = !{!"0x5646bc8d4990.w1.b1", !2499, i64 0}
!2513 = !{!2514, !2514, i64 0}
!2514 = !{!"0x5646bc8d4990.w1.b2", !2515, i64 0}
!2515 = !{!"0x5646bc8d4990.w2.b2", !2500, i64 0}
!2516 = !{!2517, !2517, i64 0}
!2517 = !{!"0x5646bc8d4990.w1.b3", !2515, i64 0}
!2518 = !{!2519, !2519, i64 0}
!2519 = !{!"0x5646bc8d4990.w1.b4", !2520, i64 0}
!2520 = !{!"0x5646bc8d4990.w2.b4", !2521, i64 0}
!2521 = !{!"0x5646bc8d4990.w4.b4", !2501, i64 0}
!2522 = !{!2523, !2523, i64 0}
!2523 = !{!"0x5646bc8d49e0.w4.b0", !2524, i64 0}
!2524 = !{!"0x5646bc8d49e0.w8.b0", !2525, i64 0}
!2525 = !{!"0x5646bc8d49e0.w16.b0", !2526, i64 0}
!2526 = !{!"0x5646bc8d49e0.w32.b0", !2527, i64 0}
!2527 = !{!"0x5646bc8d49e0.w64.b0", !2528, i64 0}
!2528 = !{!"0x5646bc8d49e0.w128.b0", !2529, i64 0}
!2529 = !{!"0x5646bc8d49e0.w256.b0", !2530, i64 0}
!2530 = !{!"0x5646bc8d49e0.w512.b0", !2531, i64 0}
!2531 = !{!"0x5646bc8d49e0.w1024.b0", !2532, i64 0}
!2532 = !{!"int64", !2533, i64 0}
!2533 = !{!"0x5646bc8d49e0", !8, i64 0}
!2534 = !{!2535, !2535, i64 0}
!2535 = !{!"0x5646bc8d49e0.w1.b4", !2536, i64 0}
!2536 = !{!"0x5646bc8d49e0.w2.b4", !2537, i64 0}
!2537 = !{!"0x5646bc8d49e0.w4.b4", !2524, i64 0}
!2538 = !{!2539, !2539, i64 0}
!2539 = !{!"0x5646bc8d5ff0.w1.b0", !2540, i64 0}
!2540 = !{!"0x5646bc8d5ff0.w2.b0", !2541, i64 0}
!2541 = !{!"0x5646bc8d5ff0.w4.b0", !2542, i64 0}
!2542 = !{!"0x5646bc8d5ff0.w8.b0", !2543, i64 0}
!2543 = !{!"0x5646bc8d5ff0.w16.b0", !2544, i64 0}
!2544 = !{!"0x5646bc8d5ff0.w32.b0", !2545, i64 0}
!2545 = !{!"0x5646bc8d5ff0.w64.b0", !2546, i64 0}
!2546 = !{!"0x5646bc8d5ff0.w128.b0", !2547, i64 0}
!2547 = !{!"0x5646bc8d5ff0.w256.b0", !2548, i64 0}
!2548 = !{!"0x5646bc8d5ff0.w512.b0", !2549, i64 0}
!2549 = !{!"0x5646bc8d5ff0.w1024.b0", !2550, i64 0}
!2550 = !{!"int64", !2551, i64 0}
!2551 = !{!"0x5646bc8d5ff0", !8, i64 0}
!2552 = !{!2553, !2553, i64 0}
!2553 = !{!"0x5646bc8d5ff0.w1.b1", !2540, i64 0}
!2554 = !{!2555, !2555, i64 0}
!2555 = !{!"0x5646bc8d5ff0.w1.b2", !2556, i64 0}
!2556 = !{!"0x5646bc8d5ff0.w2.b2", !2541, i64 0}
!2557 = !{!2558, !2558, i64 0}
!2558 = !{!"0x5646bc8d5ff0.w1.b3", !2556, i64 0}
!2559 = !{!2560, !2560, i64 0}
!2560 = !{!"0x5646bc8d5ff0.w1.b4", !2561, i64 0}
!2561 = !{!"0x5646bc8d5ff0.w2.b4", !2562, i64 0}
!2562 = !{!"0x5646bc8d5ff0.w4.b4", !2542, i64 0}
!2563 = !{!2564, !2564, i64 0}
!2564 = !{!"0x5646bc8d73c0.w4.b0", !2565, i64 0}
!2565 = !{!"0x5646bc8d73c0.w8.b0", !2566, i64 0}
!2566 = !{!"0x5646bc8d73c0.w16.b0", !2567, i64 0}
!2567 = !{!"0x5646bc8d73c0.w32.b0", !2568, i64 0}
!2568 = !{!"0x5646bc8d73c0.w64.b0", !2569, i64 0}
!2569 = !{!"0x5646bc8d73c0.w128.b0", !2570, i64 0}
!2570 = !{!"0x5646bc8d73c0.w256.b0", !2571, i64 0}
!2571 = !{!"0x5646bc8d73c0.w512.b0", !2572, i64 0}
!2572 = !{!"0x5646bc8d73c0.w1024.b0", !2573, i64 0}
!2573 = !{!"int64", !2574, i64 0}
!2574 = !{!"0x5646bc8d73c0", !8, i64 0}
!2575 = !{!2576, !2576, i64 0}
!2576 = !{!"0x5646bc8d73c0.w1.b4", !2577, i64 0}
!2577 = !{!"0x5646bc8d73c0.w2.b4", !2578, i64 0}
!2578 = !{!"0x5646bc8d73c0.w4.b4", !2565, i64 0}
!2579 = !{!2580, !2580, i64 0}
!2580 = !{!"float32", !2581, i64 0}
!2581 = !{!"0x5646bc92cbb0", !8, i64 0}
!2582 = !{!2583, !2583, i64 0}
!2583 = !{!"float32", !2584, i64 0}
!2584 = !{!"0x5646bc92c150", !8, i64 0}
!2585 = !{!2586, !2586, i64 0}
!2586 = !{!"float32", !2587, i64 0}
!2587 = !{!"0x5646bc9284a0", !8, i64 0}
!2588 = !{!2589, !2589, i64 0}
!2589 = !{!"float32", !2590, i64 0}
!2590 = !{!"0x5646bc92c5c0", !8, i64 0}
!2591 = !{!2592, !2592, i64 0}
!2592 = !{!"float32", !2593, i64 0}
!2593 = !{!"0x5646bc92c9c0", !8, i64 0}
!2594 = !{!2595, !2595, i64 0}
!2595 = !{!"float32", !2596, i64 0}
!2596 = !{!"0x5646bc92c1f0", !8, i64 0}
!2597 = !{!2598, !2598, i64 0}
!2598 = !{!"float32", !2599, i64 0}
!2599 = !{!"0x5646bc9297b0", !8, i64 0}
!2600 = !{!2601, !2601, i64 0}
!2601 = !{!"0x5646bc92c770.w32.b0", !2602, i64 0}
!2602 = !{!"0x5646bc92c770.w64.b0", !2603, i64 0}
!2603 = !{!"0x5646bc92c770.w128.b0", !2604, i64 0}
!2604 = !{!"0x5646bc92c770.w256.b0", !2605, i64 0}
!2605 = !{!"0x5646bc92c770.w512.b0", !2606, i64 0}
!2606 = !{!"0x5646bc92c770.w1024.b0", !2607, i64 0}
!2607 = !{!"float32", !2608, i64 0}
!2608 = !{!"0x5646bc92c770", !8, i64 0}
!2609 = !{!2610, !2610, i64 0}
!2610 = !{!"0x5646bc9325a0.w1.b0", !2611, i64 0}
!2611 = !{!"0x5646bc9325a0.w2.b0", !2612, i64 0}
!2612 = !{!"0x5646bc9325a0.w4.b0", !2613, i64 0}
!2613 = !{!"0x5646bc9325a0.w8.b0", !2614, i64 0}
!2614 = !{!"0x5646bc9325a0.w16.b0", !2615, i64 0}
!2615 = !{!"0x5646bc9325a0.w32.b0", !2616, i64 0}
!2616 = !{!"0x5646bc9325a0.w64.b0", !2617, i64 0}
!2617 = !{!"0x5646bc9325a0.w128.b0", !2618, i64 0}
!2618 = !{!"0x5646bc9325a0.w256.b0", !2619, i64 0}
!2619 = !{!"0x5646bc9325a0.w512.b0", !2620, i64 0}
!2620 = !{!"0x5646bc9325a0.w1024.b0", !2621, i64 0}
!2621 = !{!"int32", !2622, i64 0}
!2622 = !{!"0x5646bc9325a0", !8, i64 0}
!2623 = !{!2624, !2624, i64 0}
!2624 = !{!"0x5646bc9325a0.w1.b1", !2611, i64 0}
!2625 = !{!2626, !2626, i64 0}
!2626 = !{!"0x5646bc8defe0.w1.b0", !2627, i64 0}
!2627 = !{!"0x5646bc8defe0.w2.b0", !2628, i64 0}
!2628 = !{!"0x5646bc8defe0.w4.b0", !2629, i64 0}
!2629 = !{!"0x5646bc8defe0.w8.b0", !2630, i64 0}
!2630 = !{!"0x5646bc8defe0.w16.b0", !2631, i64 0}
!2631 = !{!"0x5646bc8defe0.w32.b0", !2632, i64 0}
!2632 = !{!"0x5646bc8defe0.w64.b0", !2633, i64 0}
!2633 = !{!"0x5646bc8defe0.w128.b0", !2634, i64 0}
!2634 = !{!"0x5646bc8defe0.w256.b0", !2635, i64 0}
!2635 = !{!"0x5646bc8defe0.w512.b0", !2636, i64 0}
!2636 = !{!"0x5646bc8defe0.w1024.b0", !2637, i64 0}
!2637 = !{!"int64", !2638, i64 0}
!2638 = !{!"0x5646bc8defe0", !8, i64 0}
!2639 = !{!2640, !2640, i64 0}
!2640 = !{!"0x5646bc8defe0.w1.b1", !2627, i64 0}
!2641 = !{!2642, !2642, i64 0}
!2642 = !{!"0x5646bc8defe0.w1.b2", !2643, i64 0}
!2643 = !{!"0x5646bc8defe0.w2.b2", !2628, i64 0}
!2644 = !{!2645, !2645, i64 0}
!2645 = !{!"0x5646bc8defe0.w1.b3", !2643, i64 0}
!2646 = !{!2647, !2647, i64 0}
!2647 = !{!"0x5646bc8defe0.w1.b4", !2648, i64 0}
!2648 = !{!"0x5646bc8defe0.w2.b4", !2649, i64 0}
!2649 = !{!"0x5646bc8defe0.w4.b4", !2629, i64 0}
!2650 = !{!2651, !2651, i64 0}
!2651 = !{!"0x5646bc8df300.w4.b0", !2652, i64 0}
!2652 = !{!"0x5646bc8df300.w8.b0", !2653, i64 0}
!2653 = !{!"0x5646bc8df300.w16.b0", !2654, i64 0}
!2654 = !{!"0x5646bc8df300.w32.b0", !2655, i64 0}
!2655 = !{!"0x5646bc8df300.w64.b0", !2656, i64 0}
!2656 = !{!"0x5646bc8df300.w128.b0", !2657, i64 0}
!2657 = !{!"0x5646bc8df300.w256.b0", !2658, i64 0}
!2658 = !{!"0x5646bc8df300.w512.b0", !2659, i64 0}
!2659 = !{!"0x5646bc8df300.w1024.b0", !2660, i64 0}
!2660 = !{!"int64", !2661, i64 0}
!2661 = !{!"0x5646bc8df300", !8, i64 0}
!2662 = !{!2663, !2663, i64 0}
!2663 = !{!"0x5646bc8df300.w1.b4", !2664, i64 0}
!2664 = !{!"0x5646bc8df300.w2.b4", !2665, i64 0}
!2665 = !{!"0x5646bc8df300.w4.b4", !2652, i64 0}
!2666 = !{!2667, !2667, i64 0}
!2667 = !{!"0x5646bc8df550.w1.b0", !2668, i64 0}
!2668 = !{!"0x5646bc8df550.w2.b0", !2669, i64 0}
!2669 = !{!"0x5646bc8df550.w4.b0", !2670, i64 0}
!2670 = !{!"0x5646bc8df550.w8.b0", !2671, i64 0}
!2671 = !{!"0x5646bc8df550.w16.b0", !2672, i64 0}
!2672 = !{!"0x5646bc8df550.w32.b0", !2673, i64 0}
!2673 = !{!"0x5646bc8df550.w64.b0", !2674, i64 0}
!2674 = !{!"0x5646bc8df550.w128.b0", !2675, i64 0}
!2675 = !{!"0x5646bc8df550.w256.b0", !2676, i64 0}
!2676 = !{!"0x5646bc8df550.w512.b0", !2677, i64 0}
!2677 = !{!"0x5646bc8df550.w1024.b0", !2678, i64 0}
!2678 = !{!"int64", !2679, i64 0}
!2679 = !{!"0x5646bc8df550", !8, i64 0}
!2680 = !{!2681, !2681, i64 0}
!2681 = !{!"0x5646bc8df550.w1.b1", !2668, i64 0}
!2682 = !{!2683, !2683, i64 0}
!2683 = !{!"0x5646bc8df550.w1.b2", !2684, i64 0}
!2684 = !{!"0x5646bc8df550.w2.b2", !2669, i64 0}
!2685 = !{!2686, !2686, i64 0}
!2686 = !{!"0x5646bc8df550.w1.b3", !2684, i64 0}
!2687 = !{!2688, !2688, i64 0}
!2688 = !{!"0x5646bc8df550.w1.b4", !2689, i64 0}
!2689 = !{!"0x5646bc8df550.w2.b4", !2690, i64 0}
!2690 = !{!"0x5646bc8df550.w4.b4", !2670, i64 0}
!2691 = !{!2692, !2692, i64 0}
!2692 = !{!"0x5646bc8df180.w4.b0", !2693, i64 0}
!2693 = !{!"0x5646bc8df180.w8.b0", !2694, i64 0}
!2694 = !{!"0x5646bc8df180.w16.b0", !2695, i64 0}
!2695 = !{!"0x5646bc8df180.w32.b0", !2696, i64 0}
!2696 = !{!"0x5646bc8df180.w64.b0", !2697, i64 0}
!2697 = !{!"0x5646bc8df180.w128.b0", !2698, i64 0}
!2698 = !{!"0x5646bc8df180.w256.b0", !2699, i64 0}
!2699 = !{!"0x5646bc8df180.w512.b0", !2700, i64 0}
!2700 = !{!"0x5646bc8df180.w1024.b0", !2701, i64 0}
!2701 = !{!"int64", !2702, i64 0}
!2702 = !{!"0x5646bc8df180", !8, i64 0}
!2703 = !{!2704, !2704, i64 0}
!2704 = !{!"0x5646bc8df180.w1.b4", !2705, i64 0}
!2705 = !{!"0x5646bc8df180.w2.b4", !2706, i64 0}
!2706 = !{!"0x5646bc8df180.w4.b4", !2693, i64 0}
!2707 = !{!2708, !2708, i64 0}
!2708 = !{!"float32", !2709, i64 0}
!2709 = !{!"0x5646bc925850", !8, i64 0}
!2710 = !{!2711, !2711, i64 0}
!2711 = !{!"float32", !2712, i64 0}
!2712 = !{!"0x5646bc92ca10", !8, i64 0}
!2713 = !{!2714, !2714, i64 0}
!2714 = !{!"0x5646bc9505c0.w1.b0", !2715, i64 0}
!2715 = !{!"0x5646bc9505c0.w2.b0", !2716, i64 0}
!2716 = !{!"0x5646bc9505c0.w4.b0", !2717, i64 0}
!2717 = !{!"0x5646bc9505c0.w8.b0", !2718, i64 0}
!2718 = !{!"0x5646bc9505c0.w16.b0", !2719, i64 0}
!2719 = !{!"0x5646bc9505c0.w32.b0", !2720, i64 0}
!2720 = !{!"0x5646bc9505c0.w64.b0", !2721, i64 0}
!2721 = !{!"0x5646bc9505c0.w128.b0", !2722, i64 0}
!2722 = !{!"0x5646bc9505c0.w256.b0", !2723, i64 0}
!2723 = !{!"0x5646bc9505c0.w512.b0", !2724, i64 0}
!2724 = !{!"0x5646bc9505c0.w1024.b0", !2725, i64 0}
!2725 = !{!"int32", !2726, i64 0}
!2726 = !{!"0x5646bc9505c0", !8, i64 0}
!2727 = !{!2728, !2728, i64 0}
!2728 = !{!"0x5646bc9505c0.w1.b1", !2715, i64 0}
!2729 = !{!2730, !2730, i64 0}
!2730 = !{!"0x5646bc964cf0.w1.b0", !2731, i64 0}
!2731 = !{!"0x5646bc964cf0.w2.b0", !2732, i64 0}
!2732 = !{!"0x5646bc964cf0.w4.b0", !2733, i64 0}
!2733 = !{!"0x5646bc964cf0.w8.b0", !2734, i64 0}
!2734 = !{!"0x5646bc964cf0.w16.b0", !2735, i64 0}
!2735 = !{!"0x5646bc964cf0.w32.b0", !2736, i64 0}
!2736 = !{!"0x5646bc964cf0.w64.b0", !2737, i64 0}
!2737 = !{!"0x5646bc964cf0.w128.b0", !2738, i64 0}
!2738 = !{!"0x5646bc964cf0.w256.b0", !2739, i64 0}
!2739 = !{!"0x5646bc964cf0.w512.b0", !2740, i64 0}
!2740 = !{!"0x5646bc964cf0.w1024.b0", !2741, i64 0}
!2741 = !{!"int64", !2742, i64 0}
!2742 = !{!"0x5646bc964cf0", !8, i64 0}
!2743 = !{!2744, !2744, i64 0}
!2744 = !{!"0x5646bc964cf0.w1.b1", !2731, i64 0}
!2745 = !{!2746, !2746, i64 0}
!2746 = !{!"0x5646bc964cf0.w1.b2", !2747, i64 0}
!2747 = !{!"0x5646bc964cf0.w2.b2", !2732, i64 0}
!2748 = !{!2749, !2749, i64 0}
!2749 = !{!"0x5646bc964cf0.w1.b3", !2747, i64 0}
!2750 = !{!2751, !2751, i64 0}
!2751 = !{!"0x5646bc964cf0.w1.b4", !2752, i64 0}
!2752 = !{!"0x5646bc964cf0.w2.b4", !2753, i64 0}
!2753 = !{!"0x5646bc964cf0.w4.b4", !2733, i64 0}
!2754 = !{!2755, !2755, i64 0}
!2755 = !{!"0x5646bc965010.w4.b0", !2756, i64 0}
!2756 = !{!"0x5646bc965010.w8.b0", !2757, i64 0}
!2757 = !{!"0x5646bc965010.w16.b0", !2758, i64 0}
!2758 = !{!"0x5646bc965010.w32.b0", !2759, i64 0}
!2759 = !{!"0x5646bc965010.w64.b0", !2760, i64 0}
!2760 = !{!"0x5646bc965010.w128.b0", !2761, i64 0}
!2761 = !{!"0x5646bc965010.w256.b0", !2762, i64 0}
!2762 = !{!"0x5646bc965010.w512.b0", !2763, i64 0}
!2763 = !{!"0x5646bc965010.w1024.b0", !2764, i64 0}
!2764 = !{!"int64", !2765, i64 0}
!2765 = !{!"0x5646bc965010", !8, i64 0}
!2766 = !{!2767, !2767, i64 0}
!2767 = !{!"0x5646bc965010.w1.b4", !2768, i64 0}
!2768 = !{!"0x5646bc965010.w2.b4", !2769, i64 0}
!2769 = !{!"0x5646bc965010.w4.b4", !2756, i64 0}
!2770 = !{!2771, !2771, i64 0}
!2771 = !{!"0x5646bc965260.w1.b0", !2772, i64 0}
!2772 = !{!"0x5646bc965260.w2.b0", !2773, i64 0}
!2773 = !{!"0x5646bc965260.w4.b0", !2774, i64 0}
!2774 = !{!"0x5646bc965260.w8.b0", !2775, i64 0}
!2775 = !{!"0x5646bc965260.w16.b0", !2776, i64 0}
!2776 = !{!"0x5646bc965260.w32.b0", !2777, i64 0}
!2777 = !{!"0x5646bc965260.w64.b0", !2778, i64 0}
!2778 = !{!"0x5646bc965260.w128.b0", !2779, i64 0}
!2779 = !{!"0x5646bc965260.w256.b0", !2780, i64 0}
!2780 = !{!"0x5646bc965260.w512.b0", !2781, i64 0}
!2781 = !{!"0x5646bc965260.w1024.b0", !2782, i64 0}
!2782 = !{!"int64", !2783, i64 0}
!2783 = !{!"0x5646bc965260", !8, i64 0}
!2784 = !{!2785, !2785, i64 0}
!2785 = !{!"0x5646bc965260.w1.b1", !2772, i64 0}
!2786 = !{!2787, !2787, i64 0}
!2787 = !{!"0x5646bc965260.w1.b2", !2788, i64 0}
!2788 = !{!"0x5646bc965260.w2.b2", !2773, i64 0}
!2789 = !{!2790, !2790, i64 0}
!2790 = !{!"0x5646bc965260.w1.b3", !2788, i64 0}
!2791 = !{!2792, !2792, i64 0}
!2792 = !{!"0x5646bc965260.w1.b4", !2793, i64 0}
!2793 = !{!"0x5646bc965260.w2.b4", !2794, i64 0}
!2794 = !{!"0x5646bc965260.w4.b4", !2774, i64 0}
!2795 = !{!2796, !2796, i64 0}
!2796 = !{!"0x5646bc964e90.w4.b0", !2797, i64 0}
!2797 = !{!"0x5646bc964e90.w8.b0", !2798, i64 0}
!2798 = !{!"0x5646bc964e90.w16.b0", !2799, i64 0}
!2799 = !{!"0x5646bc964e90.w32.b0", !2800, i64 0}
!2800 = !{!"0x5646bc964e90.w64.b0", !2801, i64 0}
!2801 = !{!"0x5646bc964e90.w128.b0", !2802, i64 0}
!2802 = !{!"0x5646bc964e90.w256.b0", !2803, i64 0}
!2803 = !{!"0x5646bc964e90.w512.b0", !2804, i64 0}
!2804 = !{!"0x5646bc964e90.w1024.b0", !2805, i64 0}
!2805 = !{!"int64", !2806, i64 0}
!2806 = !{!"0x5646bc964e90", !8, i64 0}
!2807 = !{!2808, !2808, i64 0}
!2808 = !{!"0x5646bc964e90.w1.b4", !2809, i64 0}
!2809 = !{!"0x5646bc964e90.w2.b4", !2810, i64 0}
!2810 = !{!"0x5646bc964e90.w4.b4", !2797, i64 0}
!2811 = !{!2812, !2812, i64 0}
!2812 = !{!"float32", !2813, i64 0}
!2813 = !{!"0x5646bc94fc90", !8, i64 0}
!2814 = !{!2815, !2815, i64 0}
!2815 = !{!"float32", !2816, i64 0}
!2816 = !{!"0x5646bc95cbd0", !8, i64 0}
!2817 = !{!2818, !2818, i64 0}
!2818 = !{!"0x5646c1ee9f30.w1.b0", !2819, i64 0}
!2819 = !{!"0x5646c1ee9f30.w2.b0", !2820, i64 0}
!2820 = !{!"0x5646c1ee9f30.w4.b0", !2821, i64 0}
!2821 = !{!"0x5646c1ee9f30.w8.b0", !2822, i64 0}
!2822 = !{!"0x5646c1ee9f30.w16.b0", !2823, i64 0}
!2823 = !{!"0x5646c1ee9f30.w32.b0", !2824, i64 0}
!2824 = !{!"0x5646c1ee9f30.w64.b0", !2825, i64 0}
!2825 = !{!"0x5646c1ee9f30.w128.b0", !2826, i64 0}
!2826 = !{!"0x5646c1ee9f30.w256.b0", !2827, i64 0}
!2827 = !{!"0x5646c1ee9f30.w512.b0", !2828, i64 0}
!2828 = !{!"0x5646c1ee9f30.w1024.b0", !2829, i64 0}
!2829 = !{!"int32", !2830, i64 0}
!2830 = !{!"0x5646c1ee9f30", !8, i64 0}
!2831 = !{!2832, !2832, i64 0}
!2832 = !{!"0x5646c1ee9f30.w1.b2", !2833, i64 0}
!2833 = !{!"0x5646c1ee9f30.w2.b2", !2820, i64 0}
!2834 = !{!2835, !2835, i64 0}
!2835 = !{!"0x5646c1ee9f30.w1.b3", !2833, i64 0}
!2836 = !{!2837, !2837, i64 0}
!2837 = !{!"0x5646c1ee9f30.w1.b1", !2819, i64 0}
!2838 = !{!2839, !2839, i64 0}
!2839 = !{!"0x5646c1ef1bc0.w1.b0", !2840, i64 0}
!2840 = !{!"0x5646c1ef1bc0.w2.b0", !2841, i64 0}
!2841 = !{!"0x5646c1ef1bc0.w4.b0", !2842, i64 0}
!2842 = !{!"0x5646c1ef1bc0.w8.b0", !2843, i64 0}
!2843 = !{!"0x5646c1ef1bc0.w16.b0", !2844, i64 0}
!2844 = !{!"0x5646c1ef1bc0.w32.b0", !2845, i64 0}
!2845 = !{!"0x5646c1ef1bc0.w64.b0", !2846, i64 0}
!2846 = !{!"0x5646c1ef1bc0.w128.b0", !2847, i64 0}
!2847 = !{!"0x5646c1ef1bc0.w256.b0", !2848, i64 0}
!2848 = !{!"0x5646c1ef1bc0.w512.b0", !2849, i64 0}
!2849 = !{!"0x5646c1ef1bc0.w1024.b0", !2850, i64 0}
!2850 = !{!"int64", !2851, i64 0}
!2851 = !{!"0x5646c1ef1bc0", !8, i64 0}
!2852 = !{!2853, !2853, i64 0}
!2853 = !{!"0x5646c1ef1bc0.w1.b1", !2840, i64 0}
!2854 = !{!2855, !2855, i64 0}
!2855 = !{!"0x5646c1ef1bc0.w1.b2", !2856, i64 0}
!2856 = !{!"0x5646c1ef1bc0.w2.b2", !2841, i64 0}
!2857 = !{!2858, !2858, i64 0}
!2858 = !{!"0x5646c1ef1bc0.w1.b3", !2856, i64 0}
!2859 = !{!2860, !2860, i64 0}
!2860 = !{!"0x5646c1ef1bc0.w1.b4", !2861, i64 0}
!2861 = !{!"0x5646c1ef1bc0.w2.b4", !2862, i64 0}
!2862 = !{!"0x5646c1ef1bc0.w4.b4", !2842, i64 0}
!2863 = !{!2864, !2864, i64 0}
!2864 = !{!"0x5646c1ef1710.w4.b0", !2865, i64 0}
!2865 = !{!"0x5646c1ef1710.w8.b0", !2866, i64 0}
!2866 = !{!"0x5646c1ef1710.w16.b0", !2867, i64 0}
!2867 = !{!"0x5646c1ef1710.w32.b0", !2868, i64 0}
!2868 = !{!"0x5646c1ef1710.w64.b0", !2869, i64 0}
!2869 = !{!"0x5646c1ef1710.w128.b0", !2870, i64 0}
!2870 = !{!"0x5646c1ef1710.w256.b0", !2871, i64 0}
!2871 = !{!"0x5646c1ef1710.w512.b0", !2872, i64 0}
!2872 = !{!"0x5646c1ef1710.w1024.b0", !2873, i64 0}
!2873 = !{!"int64", !2874, i64 0}
!2874 = !{!"0x5646c1ef1710", !8, i64 0}
!2875 = !{!2876, !2876, i64 0}
!2876 = !{!"0x5646c1ef1710.w1.b4", !2877, i64 0}
!2877 = !{!"0x5646c1ef1710.w2.b4", !2878, i64 0}
!2878 = !{!"0x5646c1ef1710.w4.b4", !2865, i64 0}
!2879 = !{!2880, !2880, i64 0}
!2880 = !{!"0x5646c1eefe70.w1.b0", !2881, i64 0}
!2881 = !{!"0x5646c1eefe70.w2.b0", !2882, i64 0}
!2882 = !{!"0x5646c1eefe70.w4.b0", !2883, i64 0}
!2883 = !{!"0x5646c1eefe70.w8.b0", !2884, i64 0}
!2884 = !{!"0x5646c1eefe70.w16.b0", !2885, i64 0}
!2885 = !{!"0x5646c1eefe70.w32.b0", !2886, i64 0}
!2886 = !{!"0x5646c1eefe70.w64.b0", !2887, i64 0}
!2887 = !{!"0x5646c1eefe70.w128.b0", !2888, i64 0}
!2888 = !{!"0x5646c1eefe70.w256.b0", !2889, i64 0}
!2889 = !{!"0x5646c1eefe70.w512.b0", !2890, i64 0}
!2890 = !{!"0x5646c1eefe70.w1024.b0", !2891, i64 0}
!2891 = !{!"int64", !2892, i64 0}
!2892 = !{!"0x5646c1eefe70", !8, i64 0}
!2893 = !{!2894, !2894, i64 0}
!2894 = !{!"0x5646c1eefe70.w1.b1", !2881, i64 0}
!2895 = !{!2896, !2896, i64 0}
!2896 = !{!"0x5646c1eefe70.w1.b2", !2897, i64 0}
!2897 = !{!"0x5646c1eefe70.w2.b2", !2882, i64 0}
!2898 = !{!2899, !2899, i64 0}
!2899 = !{!"0x5646c1eefe70.w1.b3", !2897, i64 0}
!2900 = !{!2901, !2901, i64 0}
!2901 = !{!"0x5646c1eefe70.w1.b4", !2902, i64 0}
!2902 = !{!"0x5646c1eefe70.w2.b4", !2903, i64 0}
!2903 = !{!"0x5646c1eefe70.w4.b4", !2883, i64 0}
!2904 = !{!2905, !2905, i64 0}
!2905 = !{!"0x5646c1eefe70.w1.b5", !2902, i64 0}
!2906 = !{!2907, !2907, i64 0}
!2907 = !{!"0x5646c416a700.w4.b0", !2908, i64 0}
!2908 = !{!"0x5646c416a700.w8.b0", !2909, i64 0}
!2909 = !{!"0x5646c416a700.w16.b0", !2910, i64 0}
!2910 = !{!"0x5646c416a700.w32.b0", !2911, i64 0}
!2911 = !{!"0x5646c416a700.w64.b0", !2912, i64 0}
!2912 = !{!"0x5646c416a700.w128.b0", !2913, i64 0}
!2913 = !{!"0x5646c416a700.w256.b0", !2914, i64 0}
!2914 = !{!"0x5646c416a700.w512.b0", !2915, i64 0}
!2915 = !{!"0x5646c416a700.w1024.b0", !2916, i64 0}
!2916 = !{!"int64", !2917, i64 0}
!2917 = !{!"0x5646c416a700", !8, i64 0}
!2918 = !{!2919, !2919, i64 0}
!2919 = !{!"0x5646c416a700.w1.b4", !2920, i64 0}
!2920 = !{!"0x5646c416a700.w2.b4", !2921, i64 0}
!2921 = !{!"0x5646c416a700.w4.b4", !2908, i64 0}
!2922 = !{!2923, !2923, i64 0}
!2923 = !{!"0x5646c416a700.w1.b5", !2920, i64 0}
!2924 = !{!2925, !2925, i64 0}
!2925 = !{!"0x5646c416d120.w1.b0", !2926, i64 0}
!2926 = !{!"0x5646c416d120.w2.b0", !2927, i64 0}
!2927 = !{!"0x5646c416d120.w4.b0", !2928, i64 0}
!2928 = !{!"0x5646c416d120.w8.b0", !2929, i64 0}
!2929 = !{!"0x5646c416d120.w16.b0", !2930, i64 0}
!2930 = !{!"0x5646c416d120.w32.b0", !2931, i64 0}
!2931 = !{!"0x5646c416d120.w64.b0", !2932, i64 0}
!2932 = !{!"0x5646c416d120.w128.b0", !2933, i64 0}
!2933 = !{!"0x5646c416d120.w256.b0", !2934, i64 0}
!2934 = !{!"0x5646c416d120.w512.b0", !2935, i64 0}
!2935 = !{!"0x5646c416d120.w1024.b0", !2936, i64 0}
!2936 = !{!"int64", !2937, i64 0}
!2937 = !{!"0x5646c416d120", !8, i64 0}
!2938 = !{!2939, !2939, i64 0}
!2939 = !{!"0x5646c416d120.w1.b1", !2926, i64 0}
!2940 = !{!2941, !2941, i64 0}
!2941 = !{!"0x5646c416d120.w1.b2", !2942, i64 0}
!2942 = !{!"0x5646c416d120.w2.b2", !2927, i64 0}
!2943 = !{!2944, !2944, i64 0}
!2944 = !{!"0x5646c416d120.w1.b3", !2942, i64 0}
!2945 = !{!2946, !2946, i64 0}
!2946 = !{!"0x5646c416d120.w1.b4", !2947, i64 0}
!2947 = !{!"0x5646c416d120.w2.b4", !2948, i64 0}
!2948 = !{!"0x5646c416d120.w4.b4", !2928, i64 0}
!2949 = !{!2950, !2950, i64 0}
!2950 = !{!"0x5646bd4e8970.w4.b0", !2951, i64 0}
!2951 = !{!"0x5646bd4e8970.w8.b0", !2952, i64 0}
!2952 = !{!"0x5646bd4e8970.w16.b0", !2953, i64 0}
!2953 = !{!"0x5646bd4e8970.w32.b0", !2954, i64 0}
!2954 = !{!"0x5646bd4e8970.w64.b0", !2955, i64 0}
!2955 = !{!"0x5646bd4e8970.w128.b0", !2956, i64 0}
!2956 = !{!"0x5646bd4e8970.w256.b0", !2957, i64 0}
!2957 = !{!"0x5646bd4e8970.w512.b0", !2958, i64 0}
!2958 = !{!"0x5646bd4e8970.w1024.b0", !2959, i64 0}
!2959 = !{!"int64", !2960, i64 0}
!2960 = !{!"0x5646bd4e8970", !8, i64 0}
!2961 = !{!2962, !2962, i64 0}
!2962 = !{!"0x5646bd4e8970.w1.b4", !2963, i64 0}
!2963 = !{!"0x5646bd4e8970.w2.b4", !2964, i64 0}
!2964 = !{!"0x5646bd4e8970.w4.b4", !2951, i64 0}
!2965 = !{!2966, !2966, i64 0}
!2966 = !{!"0x5646bd4e9b90.w1.b0", !2967, i64 0}
!2967 = !{!"0x5646bd4e9b90.w2.b0", !2968, i64 0}
!2968 = !{!"0x5646bd4e9b90.w4.b0", !2969, i64 0}
!2969 = !{!"0x5646bd4e9b90.w8.b0", !2970, i64 0}
!2970 = !{!"0x5646bd4e9b90.w16.b0", !2971, i64 0}
!2971 = !{!"0x5646bd4e9b90.w32.b0", !2972, i64 0}
!2972 = !{!"0x5646bd4e9b90.w64.b0", !2973, i64 0}
!2973 = !{!"0x5646bd4e9b90.w128.b0", !2974, i64 0}
!2974 = !{!"0x5646bd4e9b90.w256.b0", !2975, i64 0}
!2975 = !{!"0x5646bd4e9b90.w512.b0", !2976, i64 0}
!2976 = !{!"0x5646bd4e9b90.w1024.b0", !2977, i64 0}
!2977 = !{!"int64", !2978, i64 0}
!2978 = !{!"0x5646bd4e9b90", !8, i64 0}
!2979 = !{!2980, !2980, i64 0}
!2980 = !{!"0x5646bd4e9b90.w1.b1", !2967, i64 0}
!2981 = !{!2982, !2982, i64 0}
!2982 = !{!"0x5646bd4e9b90.w1.b2", !2983, i64 0}
!2983 = !{!"0x5646bd4e9b90.w2.b2", !2968, i64 0}
!2984 = !{!2985, !2985, i64 0}
!2985 = !{!"0x5646bd4e9b90.w1.b3", !2983, i64 0}
!2986 = !{!2987, !2987, i64 0}
!2987 = !{!"0x5646bd4e9b90.w1.b4", !2988, i64 0}
!2988 = !{!"0x5646bd4e9b90.w2.b4", !2989, i64 0}
!2989 = !{!"0x5646bd4e9b90.w4.b4", !2969, i64 0}
!2990 = !{!2991, !2991, i64 0}
!2991 = !{!"0x5646bd4e9be0.w4.b0", !2992, i64 0}
!2992 = !{!"0x5646bd4e9be0.w8.b0", !2993, i64 0}
!2993 = !{!"0x5646bd4e9be0.w16.b0", !2994, i64 0}
!2994 = !{!"0x5646bd4e9be0.w32.b0", !2995, i64 0}
!2995 = !{!"0x5646bd4e9be0.w64.b0", !2996, i64 0}
!2996 = !{!"0x5646bd4e9be0.w128.b0", !2997, i64 0}
!2997 = !{!"0x5646bd4e9be0.w256.b0", !2998, i64 0}
!2998 = !{!"0x5646bd4e9be0.w512.b0", !2999, i64 0}
!2999 = !{!"0x5646bd4e9be0.w1024.b0", !3000, i64 0}
!3000 = !{!"int64", !3001, i64 0}
!3001 = !{!"0x5646bd4e9be0", !8, i64 0}
!3002 = !{!3003, !3003, i64 0}
!3003 = !{!"0x5646bd4e9be0.w1.b4", !3004, i64 0}
!3004 = !{!"0x5646bd4e9be0.w2.b4", !3005, i64 0}
!3005 = !{!"0x5646bd4e9be0.w4.b4", !2992, i64 0}
!3006 = !{!3007, !3007, i64 0}
!3007 = !{!"float32", !3008, i64 0}
!3008 = !{!"0x5646c1eeeee0", !8, i64 0}
!3009 = !{!3010, !3010, i64 0}
!3010 = !{!"float32", !3011, i64 0}
!3011 = !{!"0x5646c1eef930", !8, i64 0}
!3012 = !{!3013, !3013, i64 0}
!3013 = !{!"float32", !3014, i64 0}
!3014 = !{!"0x5646c1eef000", !8, i64 0}
!3015 = !{!3016, !3016, i64 0}
!3016 = !{!"float32", !3017, i64 0}
!3017 = !{!"0x5646c1eeede0", !8, i64 0}
!3018 = !{!3019, !3019, i64 0}
!3019 = !{!"float32", !3020, i64 0}
!3020 = !{!"0x5646c1eeb170", !8, i64 0}
!3021 = !{!3022, !3022, i64 0}
!3022 = !{!"0x5646c1eef740.w32.b0", !3023, i64 0}
!3023 = !{!"0x5646c1eef740.w64.b0", !3024, i64 0}
!3024 = !{!"0x5646c1eef740.w128.b0", !3025, i64 0}
!3025 = !{!"0x5646c1eef740.w256.b0", !3026, i64 0}
!3026 = !{!"0x5646c1eef740.w512.b0", !3027, i64 0}
!3027 = !{!"0x5646c1eef740.w1024.b0", !3028, i64 0}
!3028 = !{!"float32", !3029, i64 0}
!3029 = !{!"0x5646c1eef740", !8, i64 0}
!3030 = !{!3031, !3031, i64 0}
!3031 = !{!"float32", !3032, i64 0}
!3032 = !{!"0x5646c1eeb1c0", !8, i64 0}
!3033 = !{!3034, !3034, i64 0}
!3034 = !{!"0x5646bc95a440.w1.b0", !3035, i64 0}
!3035 = !{!"0x5646bc95a440.w2.b0", !3036, i64 0}
!3036 = !{!"0x5646bc95a440.w4.b0", !3037, i64 0}
!3037 = !{!"0x5646bc95a440.w8.b0", !3038, i64 0}
!3038 = !{!"0x5646bc95a440.w16.b0", !3039, i64 0}
!3039 = !{!"0x5646bc95a440.w32.b0", !3040, i64 0}
!3040 = !{!"0x5646bc95a440.w64.b0", !3041, i64 0}
!3041 = !{!"0x5646bc95a440.w128.b0", !3042, i64 0}
!3042 = !{!"0x5646bc95a440.w256.b0", !3043, i64 0}
!3043 = !{!"0x5646bc95a440.w512.b0", !3044, i64 0}
!3044 = !{!"0x5646bc95a440.w1024.b0", !3045, i64 0}
!3045 = !{!"int32", !3046, i64 0}
!3046 = !{!"0x5646bc95a440", !8, i64 0}
!3047 = !{!3048, !3048, i64 0}
!3048 = !{!"0x5646bc95a440.w1.b2", !3049, i64 0}
!3049 = !{!"0x5646bc95a440.w2.b2", !3036, i64 0}
!3050 = !{!3051, !3051, i64 0}
!3051 = !{!"0x5646bc95a440.w1.b3", !3049, i64 0}
!3052 = !{!3053, !3053, i64 0}
!3053 = !{!"0x5646bc95a440.w1.b1", !3035, i64 0}
!3054 = !{!3055, !3055, i64 0}
!3055 = !{!"0x5646bc94dd90.w1.b0", !3056, i64 0}
!3056 = !{!"0x5646bc94dd90.w2.b0", !3057, i64 0}
!3057 = !{!"0x5646bc94dd90.w4.b0", !3058, i64 0}
!3058 = !{!"0x5646bc94dd90.w8.b0", !3059, i64 0}
!3059 = !{!"0x5646bc94dd90.w16.b0", !3060, i64 0}
!3060 = !{!"0x5646bc94dd90.w32.b0", !3061, i64 0}
!3061 = !{!"0x5646bc94dd90.w64.b0", !3062, i64 0}
!3062 = !{!"0x5646bc94dd90.w128.b0", !3063, i64 0}
!3063 = !{!"0x5646bc94dd90.w256.b0", !3064, i64 0}
!3064 = !{!"0x5646bc94dd90.w512.b0", !3065, i64 0}
!3065 = !{!"0x5646bc94dd90.w1024.b0", !3066, i64 0}
!3066 = !{!"int64", !3067, i64 0}
!3067 = !{!"0x5646bc94dd90", !8, i64 0}
!3068 = !{!3069, !3069, i64 0}
!3069 = !{!"0x5646bc94dd90.w1.b1", !3056, i64 0}
!3070 = !{!3071, !3071, i64 0}
!3071 = !{!"0x5646bc94dd90.w1.b2", !3072, i64 0}
!3072 = !{!"0x5646bc94dd90.w2.b2", !3057, i64 0}
!3073 = !{!3074, !3074, i64 0}
!3074 = !{!"0x5646bc94dd90.w1.b3", !3072, i64 0}
!3075 = !{!3076, !3076, i64 0}
!3076 = !{!"0x5646bc94dd90.w1.b4", !3077, i64 0}
!3077 = !{!"0x5646bc94dd90.w2.b4", !3078, i64 0}
!3078 = !{!"0x5646bc94dd90.w4.b4", !3058, i64 0}
!3079 = !{!3080, !3080, i64 0}
!3080 = !{!"0x5646bc94a660.w4.b0", !3081, i64 0}
!3081 = !{!"0x5646bc94a660.w8.b0", !3082, i64 0}
!3082 = !{!"0x5646bc94a660.w16.b0", !3083, i64 0}
!3083 = !{!"0x5646bc94a660.w32.b0", !3084, i64 0}
!3084 = !{!"0x5646bc94a660.w64.b0", !3085, i64 0}
!3085 = !{!"0x5646bc94a660.w128.b0", !3086, i64 0}
!3086 = !{!"0x5646bc94a660.w256.b0", !3087, i64 0}
!3087 = !{!"0x5646bc94a660.w512.b0", !3088, i64 0}
!3088 = !{!"0x5646bc94a660.w1024.b0", !3089, i64 0}
!3089 = !{!"int64", !3090, i64 0}
!3090 = !{!"0x5646bc94a660", !8, i64 0}
!3091 = !{!3092, !3092, i64 0}
!3092 = !{!"0x5646bc94a660.w1.b4", !3093, i64 0}
!3093 = !{!"0x5646bc94a660.w2.b4", !3094, i64 0}
!3094 = !{!"0x5646bc94a660.w4.b4", !3081, i64 0}
!3095 = !{!3096, !3096, i64 0}
!3096 = !{!"0x5646bc9493a0.w1.b0", !3097, i64 0}
!3097 = !{!"0x5646bc9493a0.w2.b0", !3098, i64 0}
!3098 = !{!"0x5646bc9493a0.w4.b0", !3099, i64 0}
!3099 = !{!"0x5646bc9493a0.w8.b0", !3100, i64 0}
!3100 = !{!"0x5646bc9493a0.w16.b0", !3101, i64 0}
!3101 = !{!"0x5646bc9493a0.w32.b0", !3102, i64 0}
!3102 = !{!"0x5646bc9493a0.w64.b0", !3103, i64 0}
!3103 = !{!"0x5646bc9493a0.w128.b0", !3104, i64 0}
!3104 = !{!"0x5646bc9493a0.w256.b0", !3105, i64 0}
!3105 = !{!"0x5646bc9493a0.w512.b0", !3106, i64 0}
!3106 = !{!"0x5646bc9493a0.w1024.b0", !3107, i64 0}
!3107 = !{!"int64", !3108, i64 0}
!3108 = !{!"0x5646bc9493a0", !8, i64 0}
!3109 = !{!3110, !3110, i64 0}
!3110 = !{!"0x5646bc9493a0.w1.b1", !3097, i64 0}
!3111 = !{!3112, !3112, i64 0}
!3112 = !{!"0x5646bc9493a0.w1.b2", !3113, i64 0}
!3113 = !{!"0x5646bc9493a0.w2.b2", !3098, i64 0}
!3114 = !{!3115, !3115, i64 0}
!3115 = !{!"0x5646bc9493a0.w1.b3", !3113, i64 0}
!3116 = !{!3117, !3117, i64 0}
!3117 = !{!"0x5646bc9493a0.w1.b4", !3118, i64 0}
!3118 = !{!"0x5646bc9493a0.w2.b4", !3119, i64 0}
!3119 = !{!"0x5646bc9493a0.w4.b4", !3099, i64 0}
!3120 = !{!3121, !3121, i64 0}
!3121 = !{!"0x5646bc9493a0.w1.b5", !3118, i64 0}
!3122 = !{!3123, !3123, i64 0}
!3123 = !{!"0x5646bc950440.w4.b0", !3124, i64 0}
!3124 = !{!"0x5646bc950440.w8.b0", !3125, i64 0}
!3125 = !{!"0x5646bc950440.w16.b0", !3126, i64 0}
!3126 = !{!"0x5646bc950440.w32.b0", !3127, i64 0}
!3127 = !{!"0x5646bc950440.w64.b0", !3128, i64 0}
!3128 = !{!"0x5646bc950440.w128.b0", !3129, i64 0}
!3129 = !{!"0x5646bc950440.w256.b0", !3130, i64 0}
!3130 = !{!"0x5646bc950440.w512.b0", !3131, i64 0}
!3131 = !{!"0x5646bc950440.w1024.b0", !3132, i64 0}
!3132 = !{!"int64", !3133, i64 0}
!3133 = !{!"0x5646bc950440", !8, i64 0}
!3134 = !{!3135, !3135, i64 0}
!3135 = !{!"0x5646bc950440.w1.b4", !3136, i64 0}
!3136 = !{!"0x5646bc950440.w2.b4", !3137, i64 0}
!3137 = !{!"0x5646bc950440.w4.b4", !3124, i64 0}
!3138 = !{!3139, !3139, i64 0}
!3139 = !{!"0x5646bc950440.w1.b5", !3136, i64 0}
!3140 = !{!3141, !3141, i64 0}
!3141 = !{!"0x5646bc98fc30.w1.b0", !3142, i64 0}
!3142 = !{!"0x5646bc98fc30.w2.b0", !3143, i64 0}
!3143 = !{!"0x5646bc98fc30.w4.b0", !3144, i64 0}
!3144 = !{!"0x5646bc98fc30.w8.b0", !3145, i64 0}
!3145 = !{!"0x5646bc98fc30.w16.b0", !3146, i64 0}
!3146 = !{!"0x5646bc98fc30.w32.b0", !3147, i64 0}
!3147 = !{!"0x5646bc98fc30.w64.b0", !3148, i64 0}
!3148 = !{!"0x5646bc98fc30.w128.b0", !3149, i64 0}
!3149 = !{!"0x5646bc98fc30.w256.b0", !3150, i64 0}
!3150 = !{!"0x5646bc98fc30.w512.b0", !3151, i64 0}
!3151 = !{!"0x5646bc98fc30.w1024.b0", !3152, i64 0}
!3152 = !{!"int64", !3153, i64 0}
!3153 = !{!"0x5646bc98fc30", !8, i64 0}
!3154 = !{!3155, !3155, i64 0}
!3155 = !{!"0x5646bc98fc30.w1.b1", !3142, i64 0}
!3156 = !{!3157, !3157, i64 0}
!3157 = !{!"0x5646bc98fc30.w1.b2", !3158, i64 0}
!3158 = !{!"0x5646bc98fc30.w2.b2", !3143, i64 0}
!3159 = !{!3160, !3160, i64 0}
!3160 = !{!"0x5646bc98fc30.w1.b3", !3158, i64 0}
!3161 = !{!3162, !3162, i64 0}
!3162 = !{!"0x5646bc98fc30.w1.b4", !3163, i64 0}
!3163 = !{!"0x5646bc98fc30.w2.b4", !3164, i64 0}
!3164 = !{!"0x5646bc98fc30.w4.b4", !3144, i64 0}
!3165 = !{!3166, !3166, i64 0}
!3166 = !{!"0x5646bc98fc80.w4.b0", !3167, i64 0}
!3167 = !{!"0x5646bc98fc80.w8.b0", !3168, i64 0}
!3168 = !{!"0x5646bc98fc80.w16.b0", !3169, i64 0}
!3169 = !{!"0x5646bc98fc80.w32.b0", !3170, i64 0}
!3170 = !{!"0x5646bc98fc80.w64.b0", !3171, i64 0}
!3171 = !{!"0x5646bc98fc80.w128.b0", !3172, i64 0}
!3172 = !{!"0x5646bc98fc80.w256.b0", !3173, i64 0}
!3173 = !{!"0x5646bc98fc80.w512.b0", !3174, i64 0}
!3174 = !{!"0x5646bc98fc80.w1024.b0", !3175, i64 0}
!3175 = !{!"int64", !3176, i64 0}
!3176 = !{!"0x5646bc98fc80", !8, i64 0}
!3177 = !{!3178, !3178, i64 0}
!3178 = !{!"0x5646bc98fc80.w1.b4", !3179, i64 0}
!3179 = !{!"0x5646bc98fc80.w2.b4", !3180, i64 0}
!3180 = !{!"0x5646bc98fc80.w4.b4", !3167, i64 0}
!3181 = !{!3182, !3182, i64 0}
!3182 = !{!"0x5646bc95c830.w1.b0", !3183, i64 0}
!3183 = !{!"0x5646bc95c830.w2.b0", !3184, i64 0}
!3184 = !{!"0x5646bc95c830.w4.b0", !3185, i64 0}
!3185 = !{!"0x5646bc95c830.w8.b0", !3186, i64 0}
!3186 = !{!"0x5646bc95c830.w16.b0", !3187, i64 0}
!3187 = !{!"0x5646bc95c830.w32.b0", !3188, i64 0}
!3188 = !{!"0x5646bc95c830.w64.b0", !3189, i64 0}
!3189 = !{!"0x5646bc95c830.w128.b0", !3190, i64 0}
!3190 = !{!"0x5646bc95c830.w256.b0", !3191, i64 0}
!3191 = !{!"0x5646bc95c830.w512.b0", !3192, i64 0}
!3192 = !{!"0x5646bc95c830.w1024.b0", !3193, i64 0}
!3193 = !{!"int64", !3194, i64 0}
!3194 = !{!"0x5646bc95c830", !8, i64 0}
!3195 = !{!3196, !3196, i64 0}
!3196 = !{!"0x5646bc95c830.w1.b1", !3183, i64 0}
!3197 = !{!3198, !3198, i64 0}
!3198 = !{!"0x5646bc95c830.w1.b2", !3199, i64 0}
!3199 = !{!"0x5646bc95c830.w2.b2", !3184, i64 0}
!3200 = !{!3201, !3201, i64 0}
!3201 = !{!"0x5646bc95c830.w1.b3", !3199, i64 0}
!3202 = !{!3203, !3203, i64 0}
!3203 = !{!"0x5646bc95c830.w1.b4", !3204, i64 0}
!3204 = !{!"0x5646bc95c830.w2.b4", !3205, i64 0}
!3205 = !{!"0x5646bc95c830.w4.b4", !3185, i64 0}
!3206 = !{!3207, !3207, i64 0}
!3207 = !{!"0x5646bc95c880.w4.b0", !3208, i64 0}
!3208 = !{!"0x5646bc95c880.w8.b0", !3209, i64 0}
!3209 = !{!"0x5646bc95c880.w16.b0", !3210, i64 0}
!3210 = !{!"0x5646bc95c880.w32.b0", !3211, i64 0}
!3211 = !{!"0x5646bc95c880.w64.b0", !3212, i64 0}
!3212 = !{!"0x5646bc95c880.w128.b0", !3213, i64 0}
!3213 = !{!"0x5646bc95c880.w256.b0", !3214, i64 0}
!3214 = !{!"0x5646bc95c880.w512.b0", !3215, i64 0}
!3215 = !{!"0x5646bc95c880.w1024.b0", !3216, i64 0}
!3216 = !{!"int64", !3217, i64 0}
!3217 = !{!"0x5646bc95c880", !8, i64 0}
!3218 = !{!3219, !3219, i64 0}
!3219 = !{!"0x5646bc95c880.w1.b4", !3220, i64 0}
!3220 = !{!"0x5646bc95c880.w2.b4", !3221, i64 0}
!3221 = !{!"0x5646bc95c880.w4.b4", !3208, i64 0}
!3222 = !{!3223, !3223, i64 0}
!3223 = !{!"float32", !3224, i64 0}
!3224 = !{!"0x5646bc990420", !8, i64 0}
!3225 = !{!3226, !3226, i64 0}
!3226 = !{!"float32", !3227, i64 0}
!3227 = !{!"0x5646bc990f70", !8, i64 0}
!3228 = !{!3229, !3229, i64 0}
!3229 = !{!"float32", !3230, i64 0}
!3230 = !{!"0x5646bc9909b0", !8, i64 0}
!3231 = !{!3232, !3232, i64 0}
!3232 = !{!"float32", !3233, i64 0}
!3233 = !{!"0x5646bc990290", !8, i64 0}
!3234 = !{!3235, !3235, i64 0}
!3235 = !{!"float32", !3236, i64 0}
!3236 = !{!"0x5646bc98b610", !8, i64 0}
!3237 = !{!3238, !3238, i64 0}
!3238 = !{!"float32", !3239, i64 0}
!3239 = !{!"0x5646bc990640", !8, i64 0}
!3240 = !{!3241, !3241, i64 0}
!3241 = !{!"0x5646bc98aa70.w32.b0", !3242, i64 0}
!3242 = !{!"0x5646bc98aa70.w64.b0", !3243, i64 0}
!3243 = !{!"0x5646bc98aa70.w128.b0", !3244, i64 0}
!3244 = !{!"0x5646bc98aa70.w256.b0", !3245, i64 0}
!3245 = !{!"0x5646bc98aa70.w512.b0", !3246, i64 0}
!3246 = !{!"0x5646bc98aa70.w1024.b0", !3247, i64 0}
!3247 = !{!"float32", !3248, i64 0}
!3248 = !{!"0x5646bc98aa70", !8, i64 0}
!3249 = !{!3250, !3250, i64 0}
!3250 = !{!"0x5646c087ebe0.w1.b0", !3251, i64 0}
!3251 = !{!"0x5646c087ebe0.w2.b0", !3252, i64 0}
!3252 = !{!"0x5646c087ebe0.w4.b0", !3253, i64 0}
!3253 = !{!"0x5646c087ebe0.w8.b0", !3254, i64 0}
!3254 = !{!"0x5646c087ebe0.w16.b0", !3255, i64 0}
!3255 = !{!"0x5646c087ebe0.w32.b0", !3256, i64 0}
!3256 = !{!"0x5646c087ebe0.w64.b0", !3257, i64 0}
!3257 = !{!"0x5646c087ebe0.w128.b0", !3258, i64 0}
!3258 = !{!"0x5646c087ebe0.w256.b0", !3259, i64 0}
!3259 = !{!"0x5646c087ebe0.w512.b0", !3260, i64 0}
!3260 = !{!"0x5646c087ebe0.w1024.b0", !3261, i64 0}
!3261 = !{!"int32", !3262, i64 0}
!3262 = !{!"0x5646c087ebe0", !8, i64 0}
!3263 = !{!3264, !3264, i64 0}
!3264 = !{!"0x5646c087ebe0.w1.b1", !3251, i64 0}
!3265 = !{!3266, !3266, i64 0}
!3266 = !{!"0x5646bc277dd0.w1.b0", !3267, i64 0}
!3267 = !{!"0x5646bc277dd0.w2.b0", !3268, i64 0}
!3268 = !{!"0x5646bc277dd0.w4.b0", !3269, i64 0}
!3269 = !{!"0x5646bc277dd0.w8.b0", !3270, i64 0}
!3270 = !{!"0x5646bc277dd0.w16.b0", !3271, i64 0}
!3271 = !{!"0x5646bc277dd0.w32.b0", !3272, i64 0}
!3272 = !{!"0x5646bc277dd0.w64.b0", !3273, i64 0}
!3273 = !{!"0x5646bc277dd0.w128.b0", !3274, i64 0}
!3274 = !{!"0x5646bc277dd0.w256.b0", !3275, i64 0}
!3275 = !{!"0x5646bc277dd0.w512.b0", !3276, i64 0}
!3276 = !{!"0x5646bc277dd0.w1024.b0", !3277, i64 0}
!3277 = !{!"int64", !3278, i64 0}
!3278 = !{!"0x5646bc277dd0", !8, i64 0}
!3279 = !{!3280, !3280, i64 0}
!3280 = !{!"0x5646bc277dd0.w1.b1", !3267, i64 0}
!3281 = !{!3282, !3282, i64 0}
!3282 = !{!"0x5646bc277dd0.w1.b2", !3283, i64 0}
!3283 = !{!"0x5646bc277dd0.w2.b2", !3268, i64 0}
!3284 = !{!3285, !3285, i64 0}
!3285 = !{!"0x5646bc277dd0.w1.b3", !3283, i64 0}
!3286 = !{!3287, !3287, i64 0}
!3287 = !{!"0x5646bc277dd0.w1.b4", !3288, i64 0}
!3288 = !{!"0x5646bc277dd0.w2.b4", !3289, i64 0}
!3289 = !{!"0x5646bc277dd0.w4.b4", !3269, i64 0}
!3290 = !{!3291, !3291, i64 0}
!3291 = !{!"0x5646b91a90a0.w4.b0", !3292, i64 0}
!3292 = !{!"0x5646b91a90a0.w8.b0", !3293, i64 0}
!3293 = !{!"0x5646b91a90a0.w16.b0", !3294, i64 0}
!3294 = !{!"0x5646b91a90a0.w32.b0", !3295, i64 0}
!3295 = !{!"0x5646b91a90a0.w64.b0", !3296, i64 0}
!3296 = !{!"0x5646b91a90a0.w128.b0", !3297, i64 0}
!3297 = !{!"0x5646b91a90a0.w256.b0", !3298, i64 0}
!3298 = !{!"0x5646b91a90a0.w512.b0", !3299, i64 0}
!3299 = !{!"0x5646b91a90a0.w1024.b0", !3300, i64 0}
!3300 = !{!"int64", !3301, i64 0}
!3301 = !{!"0x5646b91a90a0", !8, i64 0}
!3302 = !{!3303, !3303, i64 0}
!3303 = !{!"0x5646b91a90a0.w1.b4", !3304, i64 0}
!3304 = !{!"0x5646b91a90a0.w2.b4", !3305, i64 0}
!3305 = !{!"0x5646b91a90a0.w4.b4", !3292, i64 0}
!3306 = !{!3307, !3307, i64 0}
!3307 = !{!"0x5646c08c0050.w1.b0", !3308, i64 0}
!3308 = !{!"0x5646c08c0050.w2.b0", !3309, i64 0}
!3309 = !{!"0x5646c08c0050.w4.b0", !3310, i64 0}
!3310 = !{!"0x5646c08c0050.w8.b0", !3311, i64 0}
!3311 = !{!"0x5646c08c0050.w16.b0", !3312, i64 0}
!3312 = !{!"0x5646c08c0050.w32.b0", !3313, i64 0}
!3313 = !{!"0x5646c08c0050.w64.b0", !3314, i64 0}
!3314 = !{!"0x5646c08c0050.w128.b0", !3315, i64 0}
!3315 = !{!"0x5646c08c0050.w256.b0", !3316, i64 0}
!3316 = !{!"0x5646c08c0050.w512.b0", !3317, i64 0}
!3317 = !{!"0x5646c08c0050.w1024.b0", !3318, i64 0}
!3318 = !{!"int64", !3319, i64 0}
!3319 = !{!"0x5646c08c0050", !8, i64 0}
!3320 = !{!3321, !3321, i64 0}
!3321 = !{!"0x5646c08c0050.w1.b1", !3308, i64 0}
!3322 = !{!3323, !3323, i64 0}
!3323 = !{!"0x5646c08c0050.w1.b2", !3324, i64 0}
!3324 = !{!"0x5646c08c0050.w2.b2", !3309, i64 0}
!3325 = !{!3326, !3326, i64 0}
!3326 = !{!"0x5646c08c0050.w1.b3", !3324, i64 0}
!3327 = !{!3328, !3328, i64 0}
!3328 = !{!"0x5646c08c0050.w1.b4", !3329, i64 0}
!3329 = !{!"0x5646c08c0050.w2.b4", !3330, i64 0}
!3330 = !{!"0x5646c08c0050.w4.b4", !3310, i64 0}
!3331 = !{!3332, !3332, i64 0}
!3332 = !{!"0x5646bd662cc0.w4.b0", !3333, i64 0}
!3333 = !{!"0x5646bd662cc0.w8.b0", !3334, i64 0}
!3334 = !{!"0x5646bd662cc0.w16.b0", !3335, i64 0}
!3335 = !{!"0x5646bd662cc0.w32.b0", !3336, i64 0}
!3336 = !{!"0x5646bd662cc0.w64.b0", !3337, i64 0}
!3337 = !{!"0x5646bd662cc0.w128.b0", !3338, i64 0}
!3338 = !{!"0x5646bd662cc0.w256.b0", !3339, i64 0}
!3339 = !{!"0x5646bd662cc0.w512.b0", !3340, i64 0}
!3340 = !{!"0x5646bd662cc0.w1024.b0", !3341, i64 0}
!3341 = !{!"int64", !3342, i64 0}
!3342 = !{!"0x5646bd662cc0", !8, i64 0}
!3343 = !{!3344, !3344, i64 0}
!3344 = !{!"0x5646bd662cc0.w1.b4", !3345, i64 0}
!3345 = !{!"0x5646bd662cc0.w2.b4", !3346, i64 0}
!3346 = !{!"0x5646bd662cc0.w4.b4", !3333, i64 0}
!3347 = !{!3348, !3348, i64 0}
!3348 = !{!"float32", !3349, i64 0}
!3349 = !{!"0x5646bc442140", !8, i64 0}
!3350 = !{!3351, !3351, i64 0}
!3351 = !{!"float32", !3352, i64 0}
!3352 = !{!"0x5646c0f5c6f0", !8, i64 0}
!3353 = !{!3354, !3354, i64 0}
!3354 = !{!"float32", !3355, i64 0}
!3355 = !{!"0x5646c08a5560", !8, i64 0}
!3356 = !{!3357, !3357, i64 0}
!3357 = !{!"0x5646c41e6130.w1.b0", !3358, i64 0}
!3358 = !{!"0x5646c41e6130.w2.b0", !3359, i64 0}
!3359 = !{!"0x5646c41e6130.w4.b0", !3360, i64 0}
!3360 = !{!"0x5646c41e6130.w8.b0", !3361, i64 0}
!3361 = !{!"0x5646c41e6130.w16.b0", !3362, i64 0}
!3362 = !{!"0x5646c41e6130.w32.b0", !3363, i64 0}
!3363 = !{!"0x5646c41e6130.w64.b0", !3364, i64 0}
!3364 = !{!"0x5646c41e6130.w128.b0", !3365, i64 0}
!3365 = !{!"0x5646c41e6130.w256.b0", !3366, i64 0}
!3366 = !{!"0x5646c41e6130.w512.b0", !3367, i64 0}
!3367 = !{!"0x5646c41e6130.w1024.b0", !3368, i64 0}
!3368 = !{!"int32", !3369, i64 0}
!3369 = !{!"0x5646c41e6130", !8, i64 0}
!3370 = !{!3371, !3371, i64 0}
!3371 = !{!"0x5646c41e6130.w1.b2", !3372, i64 0}
!3372 = !{!"0x5646c41e6130.w2.b2", !3359, i64 0}
!3373 = !{!3374, !3374, i64 0}
!3374 = !{!"0x5646c41e6130.w1.b3", !3372, i64 0}
!3375 = !{!3376, !3376, i64 0}
!3376 = !{!"0x5646c41e6130.w1.b1", !3358, i64 0}
!3377 = !{!3378, !3378, i64 0}
!3378 = !{!"0x5646c41e8900.w1.b0", !3379, i64 0}
!3379 = !{!"0x5646c41e8900.w2.b0", !3380, i64 0}
!3380 = !{!"0x5646c41e8900.w4.b0", !3381, i64 0}
!3381 = !{!"0x5646c41e8900.w8.b0", !3382, i64 0}
!3382 = !{!"0x5646c41e8900.w16.b0", !3383, i64 0}
!3383 = !{!"0x5646c41e8900.w32.b0", !3384, i64 0}
!3384 = !{!"0x5646c41e8900.w64.b0", !3385, i64 0}
!3385 = !{!"0x5646c41e8900.w128.b0", !3386, i64 0}
!3386 = !{!"0x5646c41e8900.w256.b0", !3387, i64 0}
!3387 = !{!"0x5646c41e8900.w512.b0", !3388, i64 0}
!3388 = !{!"0x5646c41e8900.w1024.b0", !3389, i64 0}
!3389 = !{!"int64", !3390, i64 0}
!3390 = !{!"0x5646c41e8900", !8, i64 0}
!3391 = !{!3392, !3392, i64 0}
!3392 = !{!"0x5646c41e8900.w1.b1", !3379, i64 0}
!3393 = !{!3394, !3394, i64 0}
!3394 = !{!"0x5646c41e8900.w1.b2", !3395, i64 0}
!3395 = !{!"0x5646c41e8900.w2.b2", !3380, i64 0}
!3396 = !{!3397, !3397, i64 0}
!3397 = !{!"0x5646c41e8900.w1.b3", !3395, i64 0}
!3398 = !{!3399, !3399, i64 0}
!3399 = !{!"0x5646c41e8900.w1.b4", !3400, i64 0}
!3400 = !{!"0x5646c41e8900.w2.b4", !3401, i64 0}
!3401 = !{!"0x5646c41e8900.w4.b4", !3381, i64 0}
!3402 = !{!3403, !3403, i64 0}
!3403 = !{!"0x5646c41e33c0.w4.b0", !3404, i64 0}
!3404 = !{!"0x5646c41e33c0.w8.b0", !3405, i64 0}
!3405 = !{!"0x5646c41e33c0.w16.b0", !3406, i64 0}
!3406 = !{!"0x5646c41e33c0.w32.b0", !3407, i64 0}
!3407 = !{!"0x5646c41e33c0.w64.b0", !3408, i64 0}
!3408 = !{!"0x5646c41e33c0.w128.b0", !3409, i64 0}
!3409 = !{!"0x5646c41e33c0.w256.b0", !3410, i64 0}
!3410 = !{!"0x5646c41e33c0.w512.b0", !3411, i64 0}
!3411 = !{!"0x5646c41e33c0.w1024.b0", !3412, i64 0}
!3412 = !{!"int64", !3413, i64 0}
!3413 = !{!"0x5646c41e33c0", !8, i64 0}
!3414 = !{!3415, !3415, i64 0}
!3415 = !{!"0x5646c41e33c0.w1.b4", !3416, i64 0}
!3416 = !{!"0x5646c41e33c0.w2.b4", !3417, i64 0}
!3417 = !{!"0x5646c41e33c0.w4.b4", !3404, i64 0}
!3418 = !{!3419, !3419, i64 0}
!3419 = !{!"0x5646c41e8cf0.w1.b0", !3420, i64 0}
!3420 = !{!"0x5646c41e8cf0.w2.b0", !3421, i64 0}
!3421 = !{!"0x5646c41e8cf0.w4.b0", !3422, i64 0}
!3422 = !{!"0x5646c41e8cf0.w8.b0", !3423, i64 0}
!3423 = !{!"0x5646c41e8cf0.w16.b0", !3424, i64 0}
!3424 = !{!"0x5646c41e8cf0.w32.b0", !3425, i64 0}
!3425 = !{!"0x5646c41e8cf0.w64.b0", !3426, i64 0}
!3426 = !{!"0x5646c41e8cf0.w128.b0", !3427, i64 0}
!3427 = !{!"0x5646c41e8cf0.w256.b0", !3428, i64 0}
!3428 = !{!"0x5646c41e8cf0.w512.b0", !3429, i64 0}
!3429 = !{!"0x5646c41e8cf0.w1024.b0", !3430, i64 0}
!3430 = !{!"int64", !3431, i64 0}
!3431 = !{!"0x5646c41e8cf0", !8, i64 0}
!3432 = !{!3433, !3433, i64 0}
!3433 = !{!"0x5646c41e8cf0.w1.b1", !3420, i64 0}
!3434 = !{!3435, !3435, i64 0}
!3435 = !{!"0x5646c41e8cf0.w1.b2", !3436, i64 0}
!3436 = !{!"0x5646c41e8cf0.w2.b2", !3421, i64 0}
!3437 = !{!3438, !3438, i64 0}
!3438 = !{!"0x5646c41e8cf0.w1.b3", !3436, i64 0}
!3439 = !{!3440, !3440, i64 0}
!3440 = !{!"0x5646c41e8cf0.w1.b4", !3441, i64 0}
!3441 = !{!"0x5646c41e8cf0.w2.b4", !3442, i64 0}
!3442 = !{!"0x5646c41e8cf0.w4.b4", !3422, i64 0}
!3443 = !{!3444, !3444, i64 0}
!3444 = !{!"0x5646c41e8cf0.w1.b5", !3441, i64 0}
!3445 = !{!3446, !3446, i64 0}
!3446 = !{!"0x5646c41e3f20.w4.b0", !3447, i64 0}
!3447 = !{!"0x5646c41e3f20.w8.b0", !3448, i64 0}
!3448 = !{!"0x5646c41e3f20.w16.b0", !3449, i64 0}
!3449 = !{!"0x5646c41e3f20.w32.b0", !3450, i64 0}
!3450 = !{!"0x5646c41e3f20.w64.b0", !3451, i64 0}
!3451 = !{!"0x5646c41e3f20.w128.b0", !3452, i64 0}
!3452 = !{!"0x5646c41e3f20.w256.b0", !3453, i64 0}
!3453 = !{!"0x5646c41e3f20.w512.b0", !3454, i64 0}
!3454 = !{!"0x5646c41e3f20.w1024.b0", !3455, i64 0}
!3455 = !{!"int64", !3456, i64 0}
!3456 = !{!"0x5646c41e3f20", !8, i64 0}
!3457 = !{!3458, !3458, i64 0}
!3458 = !{!"0x5646c41e3f20.w1.b4", !3459, i64 0}
!3459 = !{!"0x5646c41e3f20.w2.b4", !3460, i64 0}
!3460 = !{!"0x5646c41e3f20.w4.b4", !3447, i64 0}
!3461 = !{!3462, !3462, i64 0}
!3462 = !{!"0x5646c41e3f20.w1.b5", !3459, i64 0}
!3463 = !{!3464, !3464, i64 0}
!3464 = !{!"0x5646c41ea530.w1.b0", !3465, i64 0}
!3465 = !{!"0x5646c41ea530.w2.b0", !3466, i64 0}
!3466 = !{!"0x5646c41ea530.w4.b0", !3467, i64 0}
!3467 = !{!"0x5646c41ea530.w8.b0", !3468, i64 0}
!3468 = !{!"0x5646c41ea530.w16.b0", !3469, i64 0}
!3469 = !{!"0x5646c41ea530.w32.b0", !3470, i64 0}
!3470 = !{!"0x5646c41ea530.w64.b0", !3471, i64 0}
!3471 = !{!"0x5646c41ea530.w128.b0", !3472, i64 0}
!3472 = !{!"0x5646c41ea530.w256.b0", !3473, i64 0}
!3473 = !{!"0x5646c41ea530.w512.b0", !3474, i64 0}
!3474 = !{!"0x5646c41ea530.w1024.b0", !3475, i64 0}
!3475 = !{!"int64", !3476, i64 0}
!3476 = !{!"0x5646c41ea530", !8, i64 0}
!3477 = !{!3478, !3478, i64 0}
!3478 = !{!"0x5646c41ea530.w1.b1", !3465, i64 0}
!3479 = !{!3480, !3480, i64 0}
!3480 = !{!"0x5646c41ea530.w1.b2", !3481, i64 0}
!3481 = !{!"0x5646c41ea530.w2.b2", !3466, i64 0}
!3482 = !{!3483, !3483, i64 0}
!3483 = !{!"0x5646c41ea530.w1.b3", !3481, i64 0}
!3484 = !{!3485, !3485, i64 0}
!3485 = !{!"0x5646c41ea530.w1.b4", !3486, i64 0}
!3486 = !{!"0x5646c41ea530.w2.b4", !3487, i64 0}
!3487 = !{!"0x5646c41ea530.w4.b4", !3467, i64 0}
!3488 = !{!3489, !3489, i64 0}
!3489 = !{!"0x5646c41ec090.w4.b0", !3490, i64 0}
!3490 = !{!"0x5646c41ec090.w8.b0", !3491, i64 0}
!3491 = !{!"0x5646c41ec090.w16.b0", !3492, i64 0}
!3492 = !{!"0x5646c41ec090.w32.b0", !3493, i64 0}
!3493 = !{!"0x5646c41ec090.w64.b0", !3494, i64 0}
!3494 = !{!"0x5646c41ec090.w128.b0", !3495, i64 0}
!3495 = !{!"0x5646c41ec090.w256.b0", !3496, i64 0}
!3496 = !{!"0x5646c41ec090.w512.b0", !3497, i64 0}
!3497 = !{!"0x5646c41ec090.w1024.b0", !3498, i64 0}
!3498 = !{!"int64", !3499, i64 0}
!3499 = !{!"0x5646c41ec090", !8, i64 0}
!3500 = !{!3501, !3501, i64 0}
!3501 = !{!"0x5646c41ec090.w1.b4", !3502, i64 0}
!3502 = !{!"0x5646c41ec090.w2.b4", !3503, i64 0}
!3503 = !{!"0x5646c41ec090.w4.b4", !3490, i64 0}
!3504 = !{!3505, !3505, i64 0}
!3505 = !{!"0x5646c41ed360.w1.b0", !3506, i64 0}
!3506 = !{!"0x5646c41ed360.w2.b0", !3507, i64 0}
!3507 = !{!"0x5646c41ed360.w4.b0", !3508, i64 0}
!3508 = !{!"0x5646c41ed360.w8.b0", !3509, i64 0}
!3509 = !{!"0x5646c41ed360.w16.b0", !3510, i64 0}
!3510 = !{!"0x5646c41ed360.w32.b0", !3511, i64 0}
!3511 = !{!"0x5646c41ed360.w64.b0", !3512, i64 0}
!3512 = !{!"0x5646c41ed360.w128.b0", !3513, i64 0}
!3513 = !{!"0x5646c41ed360.w256.b0", !3514, i64 0}
!3514 = !{!"0x5646c41ed360.w512.b0", !3515, i64 0}
!3515 = !{!"0x5646c41ed360.w1024.b0", !3516, i64 0}
!3516 = !{!"int64", !3517, i64 0}
!3517 = !{!"0x5646c41ed360", !8, i64 0}
!3518 = !{!3519, !3519, i64 0}
!3519 = !{!"0x5646c41ed360.w1.b1", !3506, i64 0}
!3520 = !{!3521, !3521, i64 0}
!3521 = !{!"0x5646c41ed360.w1.b2", !3522, i64 0}
!3522 = !{!"0x5646c41ed360.w2.b2", !3507, i64 0}
!3523 = !{!3524, !3524, i64 0}
!3524 = !{!"0x5646c41ed360.w1.b3", !3522, i64 0}
!3525 = !{!3526, !3526, i64 0}
!3526 = !{!"0x5646c41ed360.w1.b4", !3527, i64 0}
!3527 = !{!"0x5646c41ed360.w2.b4", !3528, i64 0}
!3528 = !{!"0x5646c41ed360.w4.b4", !3508, i64 0}
!3529 = !{!3530, !3530, i64 0}
!3530 = !{!"0x5646c41ed3b0.w4.b0", !3531, i64 0}
!3531 = !{!"0x5646c41ed3b0.w8.b0", !3532, i64 0}
!3532 = !{!"0x5646c41ed3b0.w16.b0", !3533, i64 0}
!3533 = !{!"0x5646c41ed3b0.w32.b0", !3534, i64 0}
!3534 = !{!"0x5646c41ed3b0.w64.b0", !3535, i64 0}
!3535 = !{!"0x5646c41ed3b0.w128.b0", !3536, i64 0}
!3536 = !{!"0x5646c41ed3b0.w256.b0", !3537, i64 0}
!3537 = !{!"0x5646c41ed3b0.w512.b0", !3538, i64 0}
!3538 = !{!"0x5646c41ed3b0.w1024.b0", !3539, i64 0}
!3539 = !{!"int64", !3540, i64 0}
!3540 = !{!"0x5646c41ed3b0", !8, i64 0}
!3541 = !{!3542, !3542, i64 0}
!3542 = !{!"0x5646c41ed3b0.w1.b4", !3543, i64 0}
!3543 = !{!"0x5646c41ed3b0.w2.b4", !3544, i64 0}
!3544 = !{!"0x5646c41ed3b0.w4.b4", !3531, i64 0}
!3545 = !{!3546, !3546, i64 0}
!3546 = !{!"float32", !3547, i64 0}
!3547 = !{!"0x5646c41e1070", !8, i64 0}
!3548 = !{!3549, !3549, i64 0}
!3549 = !{!"float32", !3550, i64 0}
!3550 = !{!"0x5646c41e0910", !8, i64 0}
!3551 = !{!3552, !3552, i64 0}
!3552 = !{!"float32", !3553, i64 0}
!3553 = !{!"0x5646c41e08c0", !8, i64 0}
!3554 = !{!3555, !3555, i64 0}
!3555 = !{!"float32", !3556, i64 0}
!3556 = !{!"0x5646c41e0760", !8, i64 0}
!3557 = !{!3558, !3558, i64 0}
!3558 = !{!"0x5646bc66ae60.w1.b0", !3559, i64 0}
!3559 = !{!"0x5646bc66ae60.w2.b0", !3560, i64 0}
!3560 = !{!"0x5646bc66ae60.w4.b0", !3561, i64 0}
!3561 = !{!"0x5646bc66ae60.w8.b0", !3562, i64 0}
!3562 = !{!"0x5646bc66ae60.w16.b0", !3563, i64 0}
!3563 = !{!"0x5646bc66ae60.w32.b0", !3564, i64 0}
!3564 = !{!"0x5646bc66ae60.w64.b0", !3565, i64 0}
!3565 = !{!"0x5646bc66ae60.w128.b0", !3566, i64 0}
!3566 = !{!"0x5646bc66ae60.w256.b0", !3567, i64 0}
!3567 = !{!"0x5646bc66ae60.w512.b0", !3568, i64 0}
!3568 = !{!"0x5646bc66ae60.w1024.b0", !3569, i64 0}
!3569 = !{!"int32", !3570, i64 0}
!3570 = !{!"0x5646bc66ae60", !8, i64 0}
!3571 = !{!3572, !3572, i64 0}
!3572 = !{!"0x5646bc66ae60.w1.b1", !3559, i64 0}
!3573 = !{!3574, !3574, i64 0}
!3574 = !{!"0x5646bc66c3f0.w1.b0", !3575, i64 0}
!3575 = !{!"0x5646bc66c3f0.w2.b0", !3576, i64 0}
!3576 = !{!"0x5646bc66c3f0.w4.b0", !3577, i64 0}
!3577 = !{!"0x5646bc66c3f0.w8.b0", !3578, i64 0}
!3578 = !{!"0x5646bc66c3f0.w16.b0", !3579, i64 0}
!3579 = !{!"0x5646bc66c3f0.w32.b0", !3580, i64 0}
!3580 = !{!"0x5646bc66c3f0.w64.b0", !3581, i64 0}
!3581 = !{!"0x5646bc66c3f0.w128.b0", !3582, i64 0}
!3582 = !{!"0x5646bc66c3f0.w256.b0", !3583, i64 0}
!3583 = !{!"0x5646bc66c3f0.w512.b0", !3584, i64 0}
!3584 = !{!"0x5646bc66c3f0.w1024.b0", !3585, i64 0}
!3585 = !{!"int64", !3586, i64 0}
!3586 = !{!"0x5646bc66c3f0", !8, i64 0}
!3587 = !{!3588, !3588, i64 0}
!3588 = !{!"0x5646bc66c3f0.w1.b1", !3575, i64 0}
!3589 = !{!3590, !3590, i64 0}
!3590 = !{!"0x5646bc66c3f0.w1.b2", !3591, i64 0}
!3591 = !{!"0x5646bc66c3f0.w2.b2", !3576, i64 0}
!3592 = !{!3593, !3593, i64 0}
!3593 = !{!"0x5646bc66c3f0.w1.b3", !3591, i64 0}
!3594 = !{!3595, !3595, i64 0}
!3595 = !{!"0x5646bc66c710.w4.b0", !3596, i64 0}
!3596 = !{!"0x5646bc66c710.w8.b0", !3597, i64 0}
!3597 = !{!"0x5646bc66c710.w16.b0", !3598, i64 0}
!3598 = !{!"0x5646bc66c710.w32.b0", !3599, i64 0}
!3599 = !{!"0x5646bc66c710.w64.b0", !3600, i64 0}
!3600 = !{!"0x5646bc66c710.w128.b0", !3601, i64 0}
!3601 = !{!"0x5646bc66c710.w256.b0", !3602, i64 0}
!3602 = !{!"0x5646bc66c710.w512.b0", !3603, i64 0}
!3603 = !{!"0x5646bc66c710.w1024.b0", !3604, i64 0}
!3604 = !{!"int64", !3605, i64 0}
!3605 = !{!"0x5646bc66c710", !8, i64 0}
!3606 = !{!3607, !3607, i64 0}
!3607 = !{!"0x5646bc66c960.w1.b0", !3608, i64 0}
!3608 = !{!"0x5646bc66c960.w2.b0", !3609, i64 0}
!3609 = !{!"0x5646bc66c960.w4.b0", !3610, i64 0}
!3610 = !{!"0x5646bc66c960.w8.b0", !3611, i64 0}
!3611 = !{!"0x5646bc66c960.w16.b0", !3612, i64 0}
!3612 = !{!"0x5646bc66c960.w32.b0", !3613, i64 0}
!3613 = !{!"0x5646bc66c960.w64.b0", !3614, i64 0}
!3614 = !{!"0x5646bc66c960.w128.b0", !3615, i64 0}
!3615 = !{!"0x5646bc66c960.w256.b0", !3616, i64 0}
!3616 = !{!"0x5646bc66c960.w512.b0", !3617, i64 0}
!3617 = !{!"0x5646bc66c960.w1024.b0", !3618, i64 0}
!3618 = !{!"int64", !3619, i64 0}
!3619 = !{!"0x5646bc66c960", !8, i64 0}
!3620 = !{!3621, !3621, i64 0}
!3621 = !{!"0x5646bc66c960.w1.b1", !3608, i64 0}
!3622 = !{!3623, !3623, i64 0}
!3623 = !{!"0x5646bc66c960.w1.b2", !3624, i64 0}
!3624 = !{!"0x5646bc66c960.w2.b2", !3609, i64 0}
!3625 = !{!3626, !3626, i64 0}
!3626 = !{!"0x5646bc66c960.w1.b3", !3624, i64 0}
!3627 = !{!3628, !3628, i64 0}
!3628 = !{!"0x5646bc66c960.w1.b4", !3629, i64 0}
!3629 = !{!"0x5646bc66c960.w2.b4", !3630, i64 0}
!3630 = !{!"0x5646bc66c960.w4.b4", !3610, i64 0}
!3631 = !{!3632, !3632, i64 0}
!3632 = !{!"0x5646bc66c910.w4.b0", !3633, i64 0}
!3633 = !{!"0x5646bc66c910.w8.b0", !3634, i64 0}
!3634 = !{!"0x5646bc66c910.w16.b0", !3635, i64 0}
!3635 = !{!"0x5646bc66c910.w32.b0", !3636, i64 0}
!3636 = !{!"0x5646bc66c910.w64.b0", !3637, i64 0}
!3637 = !{!"0x5646bc66c910.w128.b0", !3638, i64 0}
!3638 = !{!"0x5646bc66c910.w256.b0", !3639, i64 0}
!3639 = !{!"0x5646bc66c910.w512.b0", !3640, i64 0}
!3640 = !{!"0x5646bc66c910.w1024.b0", !3641, i64 0}
!3641 = !{!"int64", !3642, i64 0}
!3642 = !{!"0x5646bc66c910", !8, i64 0}
!3643 = !{!3644, !3644, i64 0}
!3644 = !{!"0x5646bc66c910.w1.b4", !3645, i64 0}
!3645 = !{!"0x5646bc66c910.w2.b4", !3646, i64 0}
!3646 = !{!"0x5646bc66c910.w4.b4", !3633, i64 0}
!3647 = !{!3648, !3648, i64 0}
!3648 = !{!"float32", !3649, i64 0}
!3649 = !{!"0x5646bc65e1a0", !8, i64 0}
!3650 = !{!3651, !3651, i64 0}
!3651 = !{!"float32", !3652, i64 0}
!3652 = !{!"0x5646c414b8a0", !8, i64 0}
!3653 = !{!3654, !3654, i64 0}
!3654 = !{!"0x5646c1e328c0.w1.b0", !3655, i64 0}
!3655 = !{!"0x5646c1e328c0.w2.b0", !3656, i64 0}
!3656 = !{!"0x5646c1e328c0.w4.b0", !3657, i64 0}
!3657 = !{!"0x5646c1e328c0.w8.b0", !3658, i64 0}
!3658 = !{!"0x5646c1e328c0.w16.b0", !3659, i64 0}
!3659 = !{!"0x5646c1e328c0.w32.b0", !3660, i64 0}
!3660 = !{!"0x5646c1e328c0.w64.b0", !3661, i64 0}
!3661 = !{!"0x5646c1e328c0.w128.b0", !3662, i64 0}
!3662 = !{!"0x5646c1e328c0.w256.b0", !3663, i64 0}
!3663 = !{!"0x5646c1e328c0.w512.b0", !3664, i64 0}
!3664 = !{!"0x5646c1e328c0.w1024.b0", !3665, i64 0}
!3665 = !{!"int32", !3666, i64 0}
!3666 = !{!"0x5646c1e328c0", !8, i64 0}
!3667 = !{!3668, !3668, i64 0}
!3668 = !{!"0x5646c1e328c0.w1.b2", !3669, i64 0}
!3669 = !{!"0x5646c1e328c0.w2.b2", !3656, i64 0}
!3670 = !{!3671, !3671, i64 0}
!3671 = !{!"0x5646c1e328c0.w1.b3", !3669, i64 0}
!3672 = !{!3673, !3673, i64 0}
!3673 = !{!"0x5646c1e328c0.w1.b1", !3655, i64 0}
!3674 = !{!3675, !3675, i64 0}
!3675 = !{!"0x5646c1f26570.w1.b0", !3676, i64 0}
!3676 = !{!"0x5646c1f26570.w2.b0", !3677, i64 0}
!3677 = !{!"0x5646c1f26570.w4.b0", !3678, i64 0}
!3678 = !{!"0x5646c1f26570.w8.b0", !3679, i64 0}
!3679 = !{!"0x5646c1f26570.w16.b0", !3680, i64 0}
!3680 = !{!"0x5646c1f26570.w32.b0", !3681, i64 0}
!3681 = !{!"0x5646c1f26570.w64.b0", !3682, i64 0}
!3682 = !{!"0x5646c1f26570.w128.b0", !3683, i64 0}
!3683 = !{!"0x5646c1f26570.w256.b0", !3684, i64 0}
!3684 = !{!"0x5646c1f26570.w512.b0", !3685, i64 0}
!3685 = !{!"0x5646c1f26570.w1024.b0", !3686, i64 0}
!3686 = !{!"int64", !3687, i64 0}
!3687 = !{!"0x5646c1f26570", !8, i64 0}
!3688 = !{!3689, !3689, i64 0}
!3689 = !{!"0x5646c1f26570.w1.b1", !3676, i64 0}
!3690 = !{!3691, !3691, i64 0}
!3691 = !{!"0x5646c1f26570.w1.b2", !3692, i64 0}
!3692 = !{!"0x5646c1f26570.w2.b2", !3677, i64 0}
!3693 = !{!3694, !3694, i64 0}
!3694 = !{!"0x5646c1f26570.w1.b3", !3692, i64 0}
!3695 = !{!3696, !3696, i64 0}
!3696 = !{!"0x5646c1f26570.w1.b4", !3697, i64 0}
!3697 = !{!"0x5646c1f26570.w2.b4", !3698, i64 0}
!3698 = !{!"0x5646c1f26570.w4.b4", !3678, i64 0}
!3699 = !{!3700, !3700, i64 0}
!3700 = !{!"0x5646c1f26670.w4.b0", !3701, i64 0}
!3701 = !{!"0x5646c1f26670.w8.b0", !3702, i64 0}
!3702 = !{!"0x5646c1f26670.w16.b0", !3703, i64 0}
!3703 = !{!"0x5646c1f26670.w32.b0", !3704, i64 0}
!3704 = !{!"0x5646c1f26670.w64.b0", !3705, i64 0}
!3705 = !{!"0x5646c1f26670.w128.b0", !3706, i64 0}
!3706 = !{!"0x5646c1f26670.w256.b0", !3707, i64 0}
!3707 = !{!"0x5646c1f26670.w512.b0", !3708, i64 0}
!3708 = !{!"0x5646c1f26670.w1024.b0", !3709, i64 0}
!3709 = !{!"int64", !3710, i64 0}
!3710 = !{!"0x5646c1f26670", !8, i64 0}
!3711 = !{!3712, !3712, i64 0}
!3712 = !{!"0x5646c1f26670.w1.b4", !3713, i64 0}
!3713 = !{!"0x5646c1f26670.w2.b4", !3714, i64 0}
!3714 = !{!"0x5646c1f26670.w4.b4", !3701, i64 0}
!3715 = !{!3716, !3716, i64 0}
!3716 = !{!"0x5646c1f26710.w1.b0", !3717, i64 0}
!3717 = !{!"0x5646c1f26710.w2.b0", !3718, i64 0}
!3718 = !{!"0x5646c1f26710.w4.b0", !3719, i64 0}
!3719 = !{!"0x5646c1f26710.w8.b0", !3720, i64 0}
!3720 = !{!"0x5646c1f26710.w16.b0", !3721, i64 0}
!3721 = !{!"0x5646c1f26710.w32.b0", !3722, i64 0}
!3722 = !{!"0x5646c1f26710.w64.b0", !3723, i64 0}
!3723 = !{!"0x5646c1f26710.w128.b0", !3724, i64 0}
!3724 = !{!"0x5646c1f26710.w256.b0", !3725, i64 0}
!3725 = !{!"0x5646c1f26710.w512.b0", !3726, i64 0}
!3726 = !{!"0x5646c1f26710.w1024.b0", !3727, i64 0}
!3727 = !{!"int64", !3728, i64 0}
!3728 = !{!"0x5646c1f26710", !8, i64 0}
!3729 = !{!3730, !3730, i64 0}
!3730 = !{!"0x5646c1f26710.w1.b1", !3717, i64 0}
!3731 = !{!3732, !3732, i64 0}
!3732 = !{!"0x5646c1f26710.w1.b2", !3733, i64 0}
!3733 = !{!"0x5646c1f26710.w2.b2", !3718, i64 0}
!3734 = !{!3735, !3735, i64 0}
!3735 = !{!"0x5646c1f26710.w1.b3", !3733, i64 0}
!3736 = !{!3737, !3737, i64 0}
!3737 = !{!"0x5646c1f26710.w1.b4", !3738, i64 0}
!3738 = !{!"0x5646c1f26710.w2.b4", !3739, i64 0}
!3739 = !{!"0x5646c1f26710.w4.b4", !3719, i64 0}
!3740 = !{!3741, !3741, i64 0}
!3741 = !{!"0x5646c1f26710.w1.b5", !3738, i64 0}
!3742 = !{!3743, !3743, i64 0}
!3743 = !{!"0x5646c1f26620.w4.b0", !3744, i64 0}
!3744 = !{!"0x5646c1f26620.w8.b0", !3745, i64 0}
!3745 = !{!"0x5646c1f26620.w16.b0", !3746, i64 0}
!3746 = !{!"0x5646c1f26620.w32.b0", !3747, i64 0}
!3747 = !{!"0x5646c1f26620.w64.b0", !3748, i64 0}
!3748 = !{!"0x5646c1f26620.w128.b0", !3749, i64 0}
!3749 = !{!"0x5646c1f26620.w256.b0", !3750, i64 0}
!3750 = !{!"0x5646c1f26620.w512.b0", !3751, i64 0}
!3751 = !{!"0x5646c1f26620.w1024.b0", !3752, i64 0}
!3752 = !{!"int64", !3753, i64 0}
!3753 = !{!"0x5646c1f26620", !8, i64 0}
!3754 = !{!3755, !3755, i64 0}
!3755 = !{!"0x5646c1f26620.w1.b4", !3756, i64 0}
!3756 = !{!"0x5646c1f26620.w2.b4", !3757, i64 0}
!3757 = !{!"0x5646c1f26620.w4.b4", !3744, i64 0}
!3758 = !{!3759, !3759, i64 0}
!3759 = !{!"0x5646c1f26620.w1.b5", !3756, i64 0}
!3760 = !{!3761, !3761, i64 0}
!3761 = !{!"0x5646c1f26d80.w1.b0", !3762, i64 0}
!3762 = !{!"0x5646c1f26d80.w2.b0", !3763, i64 0}
!3763 = !{!"0x5646c1f26d80.w4.b0", !3764, i64 0}
!3764 = !{!"0x5646c1f26d80.w8.b0", !3765, i64 0}
!3765 = !{!"0x5646c1f26d80.w16.b0", !3766, i64 0}
!3766 = !{!"0x5646c1f26d80.w32.b0", !3767, i64 0}
!3767 = !{!"0x5646c1f26d80.w64.b0", !3768, i64 0}
!3768 = !{!"0x5646c1f26d80.w128.b0", !3769, i64 0}
!3769 = !{!"0x5646c1f26d80.w256.b0", !3770, i64 0}
!3770 = !{!"0x5646c1f26d80.w512.b0", !3771, i64 0}
!3771 = !{!"0x5646c1f26d80.w1024.b0", !3772, i64 0}
!3772 = !{!"int64", !3773, i64 0}
!3773 = !{!"0x5646c1f26d80", !8, i64 0}
!3774 = !{!3775, !3775, i64 0}
!3775 = !{!"0x5646c1f26d80.w1.b1", !3762, i64 0}
!3776 = !{!3777, !3777, i64 0}
!3777 = !{!"0x5646c1f26d80.w1.b2", !3778, i64 0}
!3778 = !{!"0x5646c1f26d80.w2.b2", !3763, i64 0}
!3779 = !{!3780, !3780, i64 0}
!3780 = !{!"0x5646c1f26d80.w1.b3", !3778, i64 0}
!3781 = !{!3782, !3782, i64 0}
!3782 = !{!"0x5646c1f26d80.w1.b4", !3783, i64 0}
!3783 = !{!"0x5646c1f26d80.w2.b4", !3784, i64 0}
!3784 = !{!"0x5646c1f26d80.w4.b4", !3764, i64 0}
!3785 = !{!3786, !3786, i64 0}
!3786 = !{!"0x5646c1f27c60.w4.b0", !3787, i64 0}
!3787 = !{!"0x5646c1f27c60.w8.b0", !3788, i64 0}
!3788 = !{!"0x5646c1f27c60.w16.b0", !3789, i64 0}
!3789 = !{!"0x5646c1f27c60.w32.b0", !3790, i64 0}
!3790 = !{!"0x5646c1f27c60.w64.b0", !3791, i64 0}
!3791 = !{!"0x5646c1f27c60.w128.b0", !3792, i64 0}
!3792 = !{!"0x5646c1f27c60.w256.b0", !3793, i64 0}
!3793 = !{!"0x5646c1f27c60.w512.b0", !3794, i64 0}
!3794 = !{!"0x5646c1f27c60.w1024.b0", !3795, i64 0}
!3795 = !{!"int64", !3796, i64 0}
!3796 = !{!"0x5646c1f27c60", !8, i64 0}
!3797 = !{!3798, !3798, i64 0}
!3798 = !{!"0x5646c1f27c60.w1.b4", !3799, i64 0}
!3799 = !{!"0x5646c1f27c60.w2.b4", !3800, i64 0}
!3800 = !{!"0x5646c1f27c60.w4.b4", !3787, i64 0}
!3801 = !{!3802, !3802, i64 0}
!3802 = !{!"0x5646c1e53030.w1.b0", !3803, i64 0}
!3803 = !{!"0x5646c1e53030.w2.b0", !3804, i64 0}
!3804 = !{!"0x5646c1e53030.w4.b0", !3805, i64 0}
!3805 = !{!"0x5646c1e53030.w8.b0", !3806, i64 0}
!3806 = !{!"0x5646c1e53030.w16.b0", !3807, i64 0}
!3807 = !{!"0x5646c1e53030.w32.b0", !3808, i64 0}
!3808 = !{!"0x5646c1e53030.w64.b0", !3809, i64 0}
!3809 = !{!"0x5646c1e53030.w128.b0", !3810, i64 0}
!3810 = !{!"0x5646c1e53030.w256.b0", !3811, i64 0}
!3811 = !{!"0x5646c1e53030.w512.b0", !3812, i64 0}
!3812 = !{!"0x5646c1e53030.w1024.b0", !3813, i64 0}
!3813 = !{!"int64", !3814, i64 0}
!3814 = !{!"0x5646c1e53030", !8, i64 0}
!3815 = !{!3816, !3816, i64 0}
!3816 = !{!"0x5646c1e53030.w1.b1", !3803, i64 0}
!3817 = !{!3818, !3818, i64 0}
!3818 = !{!"0x5646c1e53030.w1.b2", !3819, i64 0}
!3819 = !{!"0x5646c1e53030.w2.b2", !3804, i64 0}
!3820 = !{!3821, !3821, i64 0}
!3821 = !{!"0x5646c1e53030.w1.b3", !3819, i64 0}
!3822 = !{!3823, !3823, i64 0}
!3823 = !{!"0x5646c1e53030.w1.b4", !3824, i64 0}
!3824 = !{!"0x5646c1e53030.w2.b4", !3825, i64 0}
!3825 = !{!"0x5646c1e53030.w4.b4", !3805, i64 0}
!3826 = !{!3827, !3827, i64 0}
!3827 = !{!"0x5646c1e53080.w4.b0", !3828, i64 0}
!3828 = !{!"0x5646c1e53080.w8.b0", !3829, i64 0}
!3829 = !{!"0x5646c1e53080.w16.b0", !3830, i64 0}
!3830 = !{!"0x5646c1e53080.w32.b0", !3831, i64 0}
!3831 = !{!"0x5646c1e53080.w64.b0", !3832, i64 0}
!3832 = !{!"0x5646c1e53080.w128.b0", !3833, i64 0}
!3833 = !{!"0x5646c1e53080.w256.b0", !3834, i64 0}
!3834 = !{!"0x5646c1e53080.w512.b0", !3835, i64 0}
!3835 = !{!"0x5646c1e53080.w1024.b0", !3836, i64 0}
!3836 = !{!"int64", !3837, i64 0}
!3837 = !{!"0x5646c1e53080", !8, i64 0}
!3838 = !{!3839, !3839, i64 0}
!3839 = !{!"0x5646c1e53080.w1.b4", !3840, i64 0}
!3840 = !{!"0x5646c1e53080.w2.b4", !3841, i64 0}
!3841 = !{!"0x5646c1e53080.w4.b4", !3828, i64 0}
!3842 = !{!3843, !3843, i64 0}
!3843 = !{!"float32", !3844, i64 0}
!3844 = !{!"0x5646c1e20e30", !8, i64 0}
!3845 = !{!3846, !3846, i64 0}
!3846 = !{!"float32", !3847, i64 0}
!3847 = !{!"0x5646c1e21ac0", !8, i64 0}
!3848 = !{!3849, !3849, i64 0}
!3849 = !{!"float32", !3850, i64 0}
!3850 = !{!"0x5646c1e20de0", !8, i64 0}
!3851 = !{!3852, !3852, i64 0}
!3852 = !{!"float32", !3853, i64 0}
!3853 = !{!"0x5646c1e322c0", !8, i64 0}
!3854 = !{!3855, !3855, i64 0}
!3855 = !{!"float32", !3856, i64 0}
!3856 = !{!"0x5646c1e21070", !8, i64 0}
!3857 = !{!3858, !3858, i64 0}
!3858 = !{!"0x5646bc915030.w1.b0", !3859, i64 0}
!3859 = !{!"0x5646bc915030.w2.b0", !3860, i64 0}
!3860 = !{!"0x5646bc915030.w4.b0", !3861, i64 0}
!3861 = !{!"0x5646bc915030.w8.b0", !3862, i64 0}
!3862 = !{!"0x5646bc915030.w16.b0", !3863, i64 0}
!3863 = !{!"0x5646bc915030.w32.b0", !3864, i64 0}
!3864 = !{!"0x5646bc915030.w64.b0", !3865, i64 0}
!3865 = !{!"0x5646bc915030.w128.b0", !3866, i64 0}
!3866 = !{!"0x5646bc915030.w256.b0", !3867, i64 0}
!3867 = !{!"0x5646bc915030.w512.b0", !3868, i64 0}
!3868 = !{!"0x5646bc915030.w1024.b0", !3869, i64 0}
!3869 = !{!"int32", !3870, i64 0}
!3870 = !{!"0x5646bc915030", !8, i64 0}
!3871 = !{!3872, !3872, i64 0}
!3872 = !{!"0x5646bc915030.w1.b2", !3873, i64 0}
!3873 = !{!"0x5646bc915030.w2.b2", !3860, i64 0}
!3874 = !{!3875, !3875, i64 0}
!3875 = !{!"0x5646bc915030.w1.b3", !3873, i64 0}
!3876 = !{!3877, !3877, i64 0}
!3877 = !{!"0x5646bc915030.w1.b1", !3859, i64 0}
!3878 = !{!3879, !3879, i64 0}
!3879 = !{!"0x5646bc91ac70.w1.b0", !3880, i64 0}
!3880 = !{!"0x5646bc91ac70.w2.b0", !3881, i64 0}
!3881 = !{!"0x5646bc91ac70.w4.b0", !3882, i64 0}
!3882 = !{!"0x5646bc91ac70.w8.b0", !3883, i64 0}
!3883 = !{!"0x5646bc91ac70.w16.b0", !3884, i64 0}
!3884 = !{!"0x5646bc91ac70.w32.b0", !3885, i64 0}
!3885 = !{!"0x5646bc91ac70.w64.b0", !3886, i64 0}
!3886 = !{!"0x5646bc91ac70.w128.b0", !3887, i64 0}
!3887 = !{!"0x5646bc91ac70.w256.b0", !3888, i64 0}
!3888 = !{!"0x5646bc91ac70.w512.b0", !3889, i64 0}
!3889 = !{!"0x5646bc91ac70.w1024.b0", !3890, i64 0}
!3890 = !{!"int64", !3891, i64 0}
!3891 = !{!"0x5646bc91ac70", !8, i64 0}
!3892 = !{!3893, !3893, i64 0}
!3893 = !{!"0x5646bc91ac70.w1.b1", !3880, i64 0}
!3894 = !{!3895, !3895, i64 0}
!3895 = !{!"0x5646bc91ac70.w1.b2", !3896, i64 0}
!3896 = !{!"0x5646bc91ac70.w2.b2", !3881, i64 0}
!3897 = !{!3898, !3898, i64 0}
!3898 = !{!"0x5646bc91ac70.w1.b3", !3896, i64 0}
!3899 = !{!3900, !3900, i64 0}
!3900 = !{!"0x5646bc91ac70.w1.b4", !3901, i64 0}
!3901 = !{!"0x5646bc91ac70.w2.b4", !3902, i64 0}
!3902 = !{!"0x5646bc91ac70.w4.b4", !3882, i64 0}
!3903 = !{!3904, !3904, i64 0}
!3904 = !{!"0x5646bc912f80.w4.b0", !3905, i64 0}
!3905 = !{!"0x5646bc912f80.w8.b0", !3906, i64 0}
!3906 = !{!"0x5646bc912f80.w16.b0", !3907, i64 0}
!3907 = !{!"0x5646bc912f80.w32.b0", !3908, i64 0}
!3908 = !{!"0x5646bc912f80.w64.b0", !3909, i64 0}
!3909 = !{!"0x5646bc912f80.w128.b0", !3910, i64 0}
!3910 = !{!"0x5646bc912f80.w256.b0", !3911, i64 0}
!3911 = !{!"0x5646bc912f80.w512.b0", !3912, i64 0}
!3912 = !{!"0x5646bc912f80.w1024.b0", !3913, i64 0}
!3913 = !{!"int64", !3914, i64 0}
!3914 = !{!"0x5646bc912f80", !8, i64 0}
!3915 = !{!3916, !3916, i64 0}
!3916 = !{!"0x5646bc912f80.w1.b4", !3917, i64 0}
!3917 = !{!"0x5646bc912f80.w2.b4", !3918, i64 0}
!3918 = !{!"0x5646bc912f80.w4.b4", !3905, i64 0}
!3919 = !{!3920, !3920, i64 0}
!3920 = !{!"0x5646bc91ae90.w1.b0", !3921, i64 0}
!3921 = !{!"0x5646bc91ae90.w2.b0", !3922, i64 0}
!3922 = !{!"0x5646bc91ae90.w4.b0", !3923, i64 0}
!3923 = !{!"0x5646bc91ae90.w8.b0", !3924, i64 0}
!3924 = !{!"0x5646bc91ae90.w16.b0", !3925, i64 0}
!3925 = !{!"0x5646bc91ae90.w32.b0", !3926, i64 0}
!3926 = !{!"0x5646bc91ae90.w64.b0", !3927, i64 0}
!3927 = !{!"0x5646bc91ae90.w128.b0", !3928, i64 0}
!3928 = !{!"0x5646bc91ae90.w256.b0", !3929, i64 0}
!3929 = !{!"0x5646bc91ae90.w512.b0", !3930, i64 0}
!3930 = !{!"0x5646bc91ae90.w1024.b0", !3931, i64 0}
!3931 = !{!"int64", !3932, i64 0}
!3932 = !{!"0x5646bc91ae90", !8, i64 0}
!3933 = !{!3934, !3934, i64 0}
!3934 = !{!"0x5646bc91ae90.w1.b1", !3921, i64 0}
!3935 = !{!3936, !3936, i64 0}
!3936 = !{!"0x5646bc91ae90.w1.b2", !3937, i64 0}
!3937 = !{!"0x5646bc91ae90.w2.b2", !3922, i64 0}
!3938 = !{!3939, !3939, i64 0}
!3939 = !{!"0x5646bc91ae90.w1.b3", !3937, i64 0}
!3940 = !{!3941, !3941, i64 0}
!3941 = !{!"0x5646bc91ae90.w1.b4", !3942, i64 0}
!3942 = !{!"0x5646bc91ae90.w2.b4", !3943, i64 0}
!3943 = !{!"0x5646bc91ae90.w4.b4", !3923, i64 0}
!3944 = !{!3945, !3945, i64 0}
!3945 = !{!"0x5646bc91ae90.w1.b5", !3942, i64 0}
!3946 = !{!3947, !3947, i64 0}
!3947 = !{!"0x5646bc9173f0.w4.b0", !3948, i64 0}
!3948 = !{!"0x5646bc9173f0.w8.b0", !3949, i64 0}
!3949 = !{!"0x5646bc9173f0.w16.b0", !3950, i64 0}
!3950 = !{!"0x5646bc9173f0.w32.b0", !3951, i64 0}
!3951 = !{!"0x5646bc9173f0.w64.b0", !3952, i64 0}
!3952 = !{!"0x5646bc9173f0.w128.b0", !3953, i64 0}
!3953 = !{!"0x5646bc9173f0.w256.b0", !3954, i64 0}
!3954 = !{!"0x5646bc9173f0.w512.b0", !3955, i64 0}
!3955 = !{!"0x5646bc9173f0.w1024.b0", !3956, i64 0}
!3956 = !{!"int64", !3957, i64 0}
!3957 = !{!"0x5646bc9173f0", !8, i64 0}
!3958 = !{!3959, !3959, i64 0}
!3959 = !{!"0x5646bc9173f0.w1.b4", !3960, i64 0}
!3960 = !{!"0x5646bc9173f0.w2.b4", !3961, i64 0}
!3961 = !{!"0x5646bc9173f0.w4.b4", !3948, i64 0}
!3962 = !{!3963, !3963, i64 0}
!3963 = !{!"0x5646bc9173f0.w1.b5", !3960, i64 0}
!3964 = !{!3965, !3965, i64 0}
!3965 = !{!"0x5646bc91c6d0.w1.b0", !3966, i64 0}
!3966 = !{!"0x5646bc91c6d0.w2.b0", !3967, i64 0}
!3967 = !{!"0x5646bc91c6d0.w4.b0", !3968, i64 0}
!3968 = !{!"0x5646bc91c6d0.w8.b0", !3969, i64 0}
!3969 = !{!"0x5646bc91c6d0.w16.b0", !3970, i64 0}
!3970 = !{!"0x5646bc91c6d0.w32.b0", !3971, i64 0}
!3971 = !{!"0x5646bc91c6d0.w64.b0", !3972, i64 0}
!3972 = !{!"0x5646bc91c6d0.w128.b0", !3973, i64 0}
!3973 = !{!"0x5646bc91c6d0.w256.b0", !3974, i64 0}
!3974 = !{!"0x5646bc91c6d0.w512.b0", !3975, i64 0}
!3975 = !{!"0x5646bc91c6d0.w1024.b0", !3976, i64 0}
!3976 = !{!"int64", !3977, i64 0}
!3977 = !{!"0x5646bc91c6d0", !8, i64 0}
!3978 = !{!3979, !3979, i64 0}
!3979 = !{!"0x5646bc91c6d0.w1.b1", !3966, i64 0}
!3980 = !{!3981, !3981, i64 0}
!3981 = !{!"0x5646bc91c6d0.w1.b2", !3982, i64 0}
!3982 = !{!"0x5646bc91c6d0.w2.b2", !3967, i64 0}
!3983 = !{!3984, !3984, i64 0}
!3984 = !{!"0x5646bc91c6d0.w1.b3", !3982, i64 0}
!3985 = !{!3986, !3986, i64 0}
!3986 = !{!"0x5646bc91c6d0.w1.b4", !3987, i64 0}
!3987 = !{!"0x5646bc91c6d0.w2.b4", !3988, i64 0}
!3988 = !{!"0x5646bc91c6d0.w4.b4", !3968, i64 0}
!3989 = !{!3990, !3990, i64 0}
!3990 = !{!"0x5646bc91e090.w4.b0", !3991, i64 0}
!3991 = !{!"0x5646bc91e090.w8.b0", !3992, i64 0}
!3992 = !{!"0x5646bc91e090.w16.b0", !3993, i64 0}
!3993 = !{!"0x5646bc91e090.w32.b0", !3994, i64 0}
!3994 = !{!"0x5646bc91e090.w64.b0", !3995, i64 0}
!3995 = !{!"0x5646bc91e090.w128.b0", !3996, i64 0}
!3996 = !{!"0x5646bc91e090.w256.b0", !3997, i64 0}
!3997 = !{!"0x5646bc91e090.w512.b0", !3998, i64 0}
!3998 = !{!"0x5646bc91e090.w1024.b0", !3999, i64 0}
!3999 = !{!"int64", !4000, i64 0}
!4000 = !{!"0x5646bc91e090", !8, i64 0}
!4001 = !{!4002, !4002, i64 0}
!4002 = !{!"0x5646bc91e090.w1.b4", !4003, i64 0}
!4003 = !{!"0x5646bc91e090.w2.b4", !4004, i64 0}
!4004 = !{!"0x5646bc91e090.w4.b4", !3991, i64 0}
!4005 = !{!4006, !4006, i64 0}
!4006 = !{!"0x5646bc91f2b0.w1.b0", !4007, i64 0}
!4007 = !{!"0x5646bc91f2b0.w2.b0", !4008, i64 0}
!4008 = !{!"0x5646bc91f2b0.w4.b0", !4009, i64 0}
!4009 = !{!"0x5646bc91f2b0.w8.b0", !4010, i64 0}
!4010 = !{!"0x5646bc91f2b0.w16.b0", !4011, i64 0}
!4011 = !{!"0x5646bc91f2b0.w32.b0", !4012, i64 0}
!4012 = !{!"0x5646bc91f2b0.w64.b0", !4013, i64 0}
!4013 = !{!"0x5646bc91f2b0.w128.b0", !4014, i64 0}
!4014 = !{!"0x5646bc91f2b0.w256.b0", !4015, i64 0}
!4015 = !{!"0x5646bc91f2b0.w512.b0", !4016, i64 0}
!4016 = !{!"0x5646bc91f2b0.w1024.b0", !4017, i64 0}
!4017 = !{!"int64", !4018, i64 0}
!4018 = !{!"0x5646bc91f2b0", !8, i64 0}
!4019 = !{!4020, !4020, i64 0}
!4020 = !{!"0x5646bc91f2b0.w1.b1", !4007, i64 0}
!4021 = !{!4022, !4022, i64 0}
!4022 = !{!"0x5646bc91f2b0.w1.b2", !4023, i64 0}
!4023 = !{!"0x5646bc91f2b0.w2.b2", !4008, i64 0}
!4024 = !{!4025, !4025, i64 0}
!4025 = !{!"0x5646bc91f2b0.w1.b3", !4023, i64 0}
!4026 = !{!4027, !4027, i64 0}
!4027 = !{!"0x5646bc91f2b0.w1.b4", !4028, i64 0}
!4028 = !{!"0x5646bc91f2b0.w2.b4", !4029, i64 0}
!4029 = !{!"0x5646bc91f2b0.w4.b4", !4009, i64 0}
!4030 = !{!4031, !4031, i64 0}
!4031 = !{!"0x5646bc91f300.w4.b0", !4032, i64 0}
!4032 = !{!"0x5646bc91f300.w8.b0", !4033, i64 0}
!4033 = !{!"0x5646bc91f300.w16.b0", !4034, i64 0}
!4034 = !{!"0x5646bc91f300.w32.b0", !4035, i64 0}
!4035 = !{!"0x5646bc91f300.w64.b0", !4036, i64 0}
!4036 = !{!"0x5646bc91f300.w128.b0", !4037, i64 0}
!4037 = !{!"0x5646bc91f300.w256.b0", !4038, i64 0}
!4038 = !{!"0x5646bc91f300.w512.b0", !4039, i64 0}
!4039 = !{!"0x5646bc91f300.w1024.b0", !4040, i64 0}
!4040 = !{!"int64", !4041, i64 0}
!4041 = !{!"0x5646bc91f300", !8, i64 0}
!4042 = !{!4043, !4043, i64 0}
!4043 = !{!"0x5646bc91f300.w1.b4", !4044, i64 0}
!4044 = !{!"0x5646bc91f300.w2.b4", !4045, i64 0}
!4045 = !{!"0x5646bc91f300.w4.b4", !4032, i64 0}
!4046 = !{!4047, !4047, i64 0}
!4047 = !{!"float32", !4048, i64 0}
!4048 = !{!"0x5646bc9129e0", !8, i64 0}
!4049 = !{!4050, !4050, i64 0}
!4050 = !{!"float32", !4051, i64 0}
!4051 = !{!"0x5646bc911db0", !8, i64 0}
!4052 = !{!4053, !4053, i64 0}
!4053 = !{!"float32", !4054, i64 0}
!4054 = !{!"0x5646bc911f40", !8, i64 0}
!4055 = !{!4056, !4056, i64 0}
!4056 = !{!"float32", !4057, i64 0}
!4057 = !{!"0x5646bc911270", !8, i64 0}
!4058 = !{!4059, !4059, i64 0}
!4059 = !{!"float32", !4060, i64 0}
!4060 = !{!"0x5646bc912110", !8, i64 0}
!4061 = !{!4062, !4062, i64 0}
!4062 = !{!"0x5646bc9127f0.w64.b0", !4063, i64 0}
!4063 = !{!"0x5646bc9127f0.w128.b0", !4064, i64 0}
!4064 = !{!"0x5646bc9127f0.w256.b0", !4065, i64 0}
!4065 = !{!"0x5646bc9127f0.w512.b0", !4066, i64 0}
!4066 = !{!"0x5646bc9127f0.w1024.b0", !4067, i64 0}
!4067 = !{!"float32", !4068, i64 0}
!4068 = !{!"0x5646bc9127f0", !8, i64 0}
!4069 = !{!4070, !4070, i64 0}
!4070 = !{!"float32", !4071, i64 0}
!4071 = !{!"0x5646bc911ff0", !8, i64 0}
!4072 = !{!4073, !4073, i64 0}
!4073 = !{!"0x5646c41b8030.w1.b0", !4074, i64 0}
!4074 = !{!"0x5646c41b8030.w2.b0", !4075, i64 0}
!4075 = !{!"0x5646c41b8030.w4.b0", !4076, i64 0}
!4076 = !{!"0x5646c41b8030.w8.b0", !4077, i64 0}
!4077 = !{!"0x5646c41b8030.w16.b0", !4078, i64 0}
!4078 = !{!"0x5646c41b8030.w32.b0", !4079, i64 0}
!4079 = !{!"0x5646c41b8030.w64.b0", !4080, i64 0}
!4080 = !{!"0x5646c41b8030.w128.b0", !4081, i64 0}
!4081 = !{!"0x5646c41b8030.w256.b0", !4082, i64 0}
!4082 = !{!"0x5646c41b8030.w512.b0", !4083, i64 0}
!4083 = !{!"0x5646c41b8030.w1024.b0", !4084, i64 0}
!4084 = !{!"int32", !4085, i64 0}
!4085 = !{!"0x5646c41b8030", !8, i64 0}
!4086 = !{!4087, !4087, i64 0}
!4087 = !{!"0x5646c41b8030.w1.b2", !4088, i64 0}
!4088 = !{!"0x5646c41b8030.w2.b2", !4075, i64 0}
!4089 = !{!4090, !4090, i64 0}
!4090 = !{!"0x5646c41b8030.w1.b3", !4088, i64 0}
!4091 = !{!4092, !4092, i64 0}
!4092 = !{!"0x5646c41b8030.w1.b1", !4074, i64 0}
!4093 = !{!4094, !4094, i64 0}
!4094 = !{!"0x5646c41b8d40.w1.b0", !4095, i64 0}
!4095 = !{!"0x5646c41b8d40.w2.b0", !4096, i64 0}
!4096 = !{!"0x5646c41b8d40.w4.b0", !4097, i64 0}
!4097 = !{!"0x5646c41b8d40.w8.b0", !4098, i64 0}
!4098 = !{!"0x5646c41b8d40.w16.b0", !4099, i64 0}
!4099 = !{!"0x5646c41b8d40.w32.b0", !4100, i64 0}
!4100 = !{!"0x5646c41b8d40.w64.b0", !4101, i64 0}
!4101 = !{!"0x5646c41b8d40.w128.b0", !4102, i64 0}
!4102 = !{!"0x5646c41b8d40.w256.b0", !4103, i64 0}
!4103 = !{!"0x5646c41b8d40.w512.b0", !4104, i64 0}
!4104 = !{!"0x5646c41b8d40.w1024.b0", !4105, i64 0}
!4105 = !{!"int64", !4106, i64 0}
!4106 = !{!"0x5646c41b8d40", !8, i64 0}
!4107 = !{!4108, !4108, i64 0}
!4108 = !{!"0x5646c41b8d40.w1.b1", !4095, i64 0}
!4109 = !{!4110, !4110, i64 0}
!4110 = !{!"0x5646c41b8d40.w1.b2", !4111, i64 0}
!4111 = !{!"0x5646c41b8d40.w2.b2", !4096, i64 0}
!4112 = !{!4113, !4113, i64 0}
!4113 = !{!"0x5646c41b8d40.w1.b3", !4111, i64 0}
!4114 = !{!4115, !4115, i64 0}
!4115 = !{!"0x5646c41b8d40.w1.b4", !4116, i64 0}
!4116 = !{!"0x5646c41b8d40.w2.b4", !4117, i64 0}
!4117 = !{!"0x5646c41b8d40.w4.b4", !4097, i64 0}
!4118 = !{!4119, !4119, i64 0}
!4119 = !{!"0x5646c41ba3f0.w4.b0", !4120, i64 0}
!4120 = !{!"0x5646c41ba3f0.w8.b0", !4121, i64 0}
!4121 = !{!"0x5646c41ba3f0.w16.b0", !4122, i64 0}
!4122 = !{!"0x5646c41ba3f0.w32.b0", !4123, i64 0}
!4123 = !{!"0x5646c41ba3f0.w64.b0", !4124, i64 0}
!4124 = !{!"0x5646c41ba3f0.w128.b0", !4125, i64 0}
!4125 = !{!"0x5646c41ba3f0.w256.b0", !4126, i64 0}
!4126 = !{!"0x5646c41ba3f0.w512.b0", !4127, i64 0}
!4127 = !{!"0x5646c41ba3f0.w1024.b0", !4128, i64 0}
!4128 = !{!"int64", !4129, i64 0}
!4129 = !{!"0x5646c41ba3f0", !8, i64 0}
!4130 = !{!4131, !4131, i64 0}
!4131 = !{!"0x5646c41ba3f0.w1.b4", !4132, i64 0}
!4132 = !{!"0x5646c41ba3f0.w2.b4", !4133, i64 0}
!4133 = !{!"0x5646c41ba3f0.w4.b4", !4120, i64 0}
!4134 = !{!4135, !4135, i64 0}
!4135 = !{!"0x5646c41b95c0.w1.b0", !4136, i64 0}
!4136 = !{!"0x5646c41b95c0.w2.b0", !4137, i64 0}
!4137 = !{!"0x5646c41b95c0.w4.b0", !4138, i64 0}
!4138 = !{!"0x5646c41b95c0.w8.b0", !4139, i64 0}
!4139 = !{!"0x5646c41b95c0.w16.b0", !4140, i64 0}
!4140 = !{!"0x5646c41b95c0.w32.b0", !4141, i64 0}
!4141 = !{!"0x5646c41b95c0.w64.b0", !4142, i64 0}
!4142 = !{!"0x5646c41b95c0.w128.b0", !4143, i64 0}
!4143 = !{!"0x5646c41b95c0.w256.b0", !4144, i64 0}
!4144 = !{!"0x5646c41b95c0.w512.b0", !4145, i64 0}
!4145 = !{!"0x5646c41b95c0.w1024.b0", !4146, i64 0}
!4146 = !{!"int64", !4147, i64 0}
!4147 = !{!"0x5646c41b95c0", !8, i64 0}
!4148 = !{!4149, !4149, i64 0}
!4149 = !{!"0x5646c41b95c0.w1.b1", !4136, i64 0}
!4150 = !{!4151, !4151, i64 0}
!4151 = !{!"0x5646c41b95c0.w1.b2", !4152, i64 0}
!4152 = !{!"0x5646c41b95c0.w2.b2", !4137, i64 0}
!4153 = !{!4154, !4154, i64 0}
!4154 = !{!"0x5646c41b95c0.w1.b3", !4152, i64 0}
!4155 = !{!4156, !4156, i64 0}
!4156 = !{!"0x5646c41b95c0.w1.b4", !4157, i64 0}
!4157 = !{!"0x5646c41b95c0.w2.b4", !4158, i64 0}
!4158 = !{!"0x5646c41b95c0.w4.b4", !4138, i64 0}
!4159 = !{!4160, !4160, i64 0}
!4160 = !{!"0x5646c41b95c0.w1.b5", !4157, i64 0}
!4161 = !{!4162, !4162, i64 0}
!4162 = !{!"0x5646c41ba9b0.w4.b0", !4163, i64 0}
!4163 = !{!"0x5646c41ba9b0.w8.b0", !4164, i64 0}
!4164 = !{!"0x5646c41ba9b0.w16.b0", !4165, i64 0}
!4165 = !{!"0x5646c41ba9b0.w32.b0", !4166, i64 0}
!4166 = !{!"0x5646c41ba9b0.w64.b0", !4167, i64 0}
!4167 = !{!"0x5646c41ba9b0.w128.b0", !4168, i64 0}
!4168 = !{!"0x5646c41ba9b0.w256.b0", !4169, i64 0}
!4169 = !{!"0x5646c41ba9b0.w512.b0", !4170, i64 0}
!4170 = !{!"0x5646c41ba9b0.w1024.b0", !4171, i64 0}
!4171 = !{!"int64", !4172, i64 0}
!4172 = !{!"0x5646c41ba9b0", !8, i64 0}
!4173 = !{!4174, !4174, i64 0}
!4174 = !{!"0x5646c41ba9b0.w1.b4", !4175, i64 0}
!4175 = !{!"0x5646c41ba9b0.w2.b4", !4176, i64 0}
!4176 = !{!"0x5646c41ba9b0.w4.b4", !4163, i64 0}
!4177 = !{!4178, !4178, i64 0}
!4178 = !{!"0x5646c41ba9b0.w1.b5", !4175, i64 0}
!4179 = !{!4180, !4180, i64 0}
!4180 = !{!"0x5646c41c4bb0.w1.b0", !4181, i64 0}
!4181 = !{!"0x5646c41c4bb0.w2.b0", !4182, i64 0}
!4182 = !{!"0x5646c41c4bb0.w4.b0", !4183, i64 0}
!4183 = !{!"0x5646c41c4bb0.w8.b0", !4184, i64 0}
!4184 = !{!"0x5646c41c4bb0.w16.b0", !4185, i64 0}
!4185 = !{!"0x5646c41c4bb0.w32.b0", !4186, i64 0}
!4186 = !{!"0x5646c41c4bb0.w64.b0", !4187, i64 0}
!4187 = !{!"0x5646c41c4bb0.w128.b0", !4188, i64 0}
!4188 = !{!"0x5646c41c4bb0.w256.b0", !4189, i64 0}
!4189 = !{!"0x5646c41c4bb0.w512.b0", !4190, i64 0}
!4190 = !{!"0x5646c41c4bb0.w1024.b0", !4191, i64 0}
!4191 = !{!"int64", !4192, i64 0}
!4192 = !{!"0x5646c41c4bb0", !8, i64 0}
!4193 = !{!4194, !4194, i64 0}
!4194 = !{!"0x5646c41c4bb0.w1.b1", !4181, i64 0}
!4195 = !{!4196, !4196, i64 0}
!4196 = !{!"0x5646c41c4bb0.w1.b2", !4197, i64 0}
!4197 = !{!"0x5646c41c4bb0.w2.b2", !4182, i64 0}
!4198 = !{!4199, !4199, i64 0}
!4199 = !{!"0x5646c41c4bb0.w1.b3", !4197, i64 0}
!4200 = !{!4201, !4201, i64 0}
!4201 = !{!"0x5646c41c4bb0.w1.b4", !4202, i64 0}
!4202 = !{!"0x5646c41c4bb0.w2.b4", !4203, i64 0}
!4203 = !{!"0x5646c41c4bb0.w4.b4", !4183, i64 0}
!4204 = !{!4205, !4205, i64 0}
!4205 = !{!"0x5646c41c6570.w4.b0", !4206, i64 0}
!4206 = !{!"0x5646c41c6570.w8.b0", !4207, i64 0}
!4207 = !{!"0x5646c41c6570.w16.b0", !4208, i64 0}
!4208 = !{!"0x5646c41c6570.w32.b0", !4209, i64 0}
!4209 = !{!"0x5646c41c6570.w64.b0", !4210, i64 0}
!4210 = !{!"0x5646c41c6570.w128.b0", !4211, i64 0}
!4211 = !{!"0x5646c41c6570.w256.b0", !4212, i64 0}
!4212 = !{!"0x5646c41c6570.w512.b0", !4213, i64 0}
!4213 = !{!"0x5646c41c6570.w1024.b0", !4214, i64 0}
!4214 = !{!"int64", !4215, i64 0}
!4215 = !{!"0x5646c41c6570", !8, i64 0}
!4216 = !{!4217, !4217, i64 0}
!4217 = !{!"0x5646c41c6570.w1.b4", !4218, i64 0}
!4218 = !{!"0x5646c41c6570.w2.b4", !4219, i64 0}
!4219 = !{!"0x5646c41c6570.w4.b4", !4206, i64 0}
!4220 = !{!4221, !4221, i64 0}
!4221 = !{!"0x5646c41c7820.w1.b0", !4222, i64 0}
!4222 = !{!"0x5646c41c7820.w2.b0", !4223, i64 0}
!4223 = !{!"0x5646c41c7820.w4.b0", !4224, i64 0}
!4224 = !{!"0x5646c41c7820.w8.b0", !4225, i64 0}
!4225 = !{!"0x5646c41c7820.w16.b0", !4226, i64 0}
!4226 = !{!"0x5646c41c7820.w32.b0", !4227, i64 0}
!4227 = !{!"0x5646c41c7820.w64.b0", !4228, i64 0}
!4228 = !{!"0x5646c41c7820.w128.b0", !4229, i64 0}
!4229 = !{!"0x5646c41c7820.w256.b0", !4230, i64 0}
!4230 = !{!"0x5646c41c7820.w512.b0", !4231, i64 0}
!4231 = !{!"0x5646c41c7820.w1024.b0", !4232, i64 0}
!4232 = !{!"int64", !4233, i64 0}
!4233 = !{!"0x5646c41c7820", !8, i64 0}
!4234 = !{!4235, !4235, i64 0}
!4235 = !{!"0x5646c41c7820.w1.b1", !4222, i64 0}
!4236 = !{!4237, !4237, i64 0}
!4237 = !{!"0x5646c41c7820.w1.b2", !4238, i64 0}
!4238 = !{!"0x5646c41c7820.w2.b2", !4223, i64 0}
!4239 = !{!4240, !4240, i64 0}
!4240 = !{!"0x5646c41c7820.w1.b3", !4238, i64 0}
!4241 = !{!4242, !4242, i64 0}
!4242 = !{!"0x5646c41c7820.w1.b4", !4243, i64 0}
!4243 = !{!"0x5646c41c7820.w2.b4", !4244, i64 0}
!4244 = !{!"0x5646c41c7820.w4.b4", !4224, i64 0}
!4245 = !{!4246, !4246, i64 0}
!4246 = !{!"0x5646c41c7870.w4.b0", !4247, i64 0}
!4247 = !{!"0x5646c41c7870.w8.b0", !4248, i64 0}
!4248 = !{!"0x5646c41c7870.w16.b0", !4249, i64 0}
!4249 = !{!"0x5646c41c7870.w32.b0", !4250, i64 0}
!4250 = !{!"0x5646c41c7870.w64.b0", !4251, i64 0}
!4251 = !{!"0x5646c41c7870.w128.b0", !4252, i64 0}
!4252 = !{!"0x5646c41c7870.w256.b0", !4253, i64 0}
!4253 = !{!"0x5646c41c7870.w512.b0", !4254, i64 0}
!4254 = !{!"0x5646c41c7870.w1024.b0", !4255, i64 0}
!4255 = !{!"int64", !4256, i64 0}
!4256 = !{!"0x5646c41c7870", !8, i64 0}
!4257 = !{!4258, !4258, i64 0}
!4258 = !{!"0x5646c41c7870.w1.b4", !4259, i64 0}
!4259 = !{!"0x5646c41c7870.w2.b4", !4260, i64 0}
!4260 = !{!"0x5646c41c7870.w4.b4", !4247, i64 0}
!4261 = !{!4262, !4262, i64 0}
!4262 = !{!"float32", !4263, i64 0}
!4263 = !{!"0x5646c41b82c0", !8, i64 0}
!4264 = !{!4265, !4265, i64 0}
!4265 = !{!"float32", !4266, i64 0}
!4266 = !{!"0x5646c41b79b0", !8, i64 0}
!4267 = !{!4268, !4268, i64 0}
!4268 = !{!"float32", !4269, i64 0}
!4269 = !{!"0x5646c41b3e70", !8, i64 0}
!4270 = !{!4271, !4271, i64 0}
!4271 = !{!"float32", !4272, i64 0}
!4272 = !{!"0x5646c41b4700", !8, i64 0}
!4273 = !{!4274, !4274, i64 0}
!4274 = !{!"0x5646c1ed7230.w1.b0", !4275, i64 0}
!4275 = !{!"0x5646c1ed7230.w2.b0", !4276, i64 0}
!4276 = !{!"0x5646c1ed7230.w4.b0", !4277, i64 0}
!4277 = !{!"0x5646c1ed7230.w8.b0", !4278, i64 0}
!4278 = !{!"0x5646c1ed7230.w16.b0", !4279, i64 0}
!4279 = !{!"0x5646c1ed7230.w32.b0", !4280, i64 0}
!4280 = !{!"0x5646c1ed7230.w64.b0", !4281, i64 0}
!4281 = !{!"0x5646c1ed7230.w128.b0", !4282, i64 0}
!4282 = !{!"0x5646c1ed7230.w256.b0", !4283, i64 0}
!4283 = !{!"0x5646c1ed7230.w512.b0", !4284, i64 0}
!4284 = !{!"0x5646c1ed7230.w1024.b0", !4285, i64 0}
!4285 = !{!"int32", !4286, i64 0}
!4286 = !{!"0x5646c1ed7230", !8, i64 0}
!4287 = !{!4288, !4288, i64 0}
!4288 = !{!"0x5646c1ed7230.w1.b1", !4275, i64 0}
!4289 = !{!4290, !4290, i64 0}
!4290 = !{!"0x5646c1e72d10.w1.b0", !4291, i64 0}
!4291 = !{!"0x5646c1e72d10.w2.b0", !4292, i64 0}
!4292 = !{!"0x5646c1e72d10.w4.b0", !4293, i64 0}
!4293 = !{!"0x5646c1e72d10.w8.b0", !4294, i64 0}
!4294 = !{!"0x5646c1e72d10.w16.b0", !4295, i64 0}
!4295 = !{!"0x5646c1e72d10.w32.b0", !4296, i64 0}
!4296 = !{!"0x5646c1e72d10.w64.b0", !4297, i64 0}
!4297 = !{!"0x5646c1e72d10.w128.b0", !4298, i64 0}
!4298 = !{!"0x5646c1e72d10.w256.b0", !4299, i64 0}
!4299 = !{!"0x5646c1e72d10.w512.b0", !4300, i64 0}
!4300 = !{!"0x5646c1e72d10.w1024.b0", !4301, i64 0}
!4301 = !{!"int64", !4302, i64 0}
!4302 = !{!"0x5646c1e72d10", !8, i64 0}
!4303 = !{!4304, !4304, i64 0}
!4304 = !{!"0x5646c1e72d10.w1.b1", !4291, i64 0}
!4305 = !{!4306, !4306, i64 0}
!4306 = !{!"0x5646c1e72d10.w1.b2", !4307, i64 0}
!4307 = !{!"0x5646c1e72d10.w2.b2", !4292, i64 0}
!4308 = !{!4309, !4309, i64 0}
!4309 = !{!"0x5646c1e72d10.w1.b3", !4307, i64 0}
!4310 = !{!4311, !4311, i64 0}
!4311 = !{!"0x5646c1e72d10.w1.b4", !4312, i64 0}
!4312 = !{!"0x5646c1e72d10.w2.b4", !4313, i64 0}
!4313 = !{!"0x5646c1e72d10.w4.b4", !4293, i64 0}
!4314 = !{!4315, !4315, i64 0}
!4315 = !{!"0x5646c1e73030.w4.b0", !4316, i64 0}
!4316 = !{!"0x5646c1e73030.w8.b0", !4317, i64 0}
!4317 = !{!"0x5646c1e73030.w16.b0", !4318, i64 0}
!4318 = !{!"0x5646c1e73030.w32.b0", !4319, i64 0}
!4319 = !{!"0x5646c1e73030.w64.b0", !4320, i64 0}
!4320 = !{!"0x5646c1e73030.w128.b0", !4321, i64 0}
!4321 = !{!"0x5646c1e73030.w256.b0", !4322, i64 0}
!4322 = !{!"0x5646c1e73030.w512.b0", !4323, i64 0}
!4323 = !{!"0x5646c1e73030.w1024.b0", !4324, i64 0}
!4324 = !{!"int64", !4325, i64 0}
!4325 = !{!"0x5646c1e73030", !8, i64 0}
!4326 = !{!4327, !4327, i64 0}
!4327 = !{!"0x5646c1e73030.w1.b4", !4328, i64 0}
!4328 = !{!"0x5646c1e73030.w2.b4", !4329, i64 0}
!4329 = !{!"0x5646c1e73030.w4.b4", !4316, i64 0}
!4330 = !{!4331, !4331, i64 0}
!4331 = !{!"0x5646c1e73280.w1.b0", !4332, i64 0}
!4332 = !{!"0x5646c1e73280.w2.b0", !4333, i64 0}
!4333 = !{!"0x5646c1e73280.w4.b0", !4334, i64 0}
!4334 = !{!"0x5646c1e73280.w8.b0", !4335, i64 0}
!4335 = !{!"0x5646c1e73280.w16.b0", !4336, i64 0}
!4336 = !{!"0x5646c1e73280.w32.b0", !4337, i64 0}
!4337 = !{!"0x5646c1e73280.w64.b0", !4338, i64 0}
!4338 = !{!"0x5646c1e73280.w128.b0", !4339, i64 0}
!4339 = !{!"0x5646c1e73280.w256.b0", !4340, i64 0}
!4340 = !{!"0x5646c1e73280.w512.b0", !4341, i64 0}
!4341 = !{!"0x5646c1e73280.w1024.b0", !4342, i64 0}
!4342 = !{!"int64", !4343, i64 0}
!4343 = !{!"0x5646c1e73280", !8, i64 0}
!4344 = !{!4345, !4345, i64 0}
!4345 = !{!"0x5646c1e73280.w1.b1", !4332, i64 0}
!4346 = !{!4347, !4347, i64 0}
!4347 = !{!"0x5646c1e73280.w1.b2", !4348, i64 0}
!4348 = !{!"0x5646c1e73280.w2.b2", !4333, i64 0}
!4349 = !{!4350, !4350, i64 0}
!4350 = !{!"0x5646c1e73280.w1.b3", !4348, i64 0}
!4351 = !{!4352, !4352, i64 0}
!4352 = !{!"0x5646c1e73280.w1.b4", !4353, i64 0}
!4353 = !{!"0x5646c1e73280.w2.b4", !4354, i64 0}
!4354 = !{!"0x5646c1e73280.w4.b4", !4334, i64 0}
!4355 = !{!4356, !4356, i64 0}
!4356 = !{!"0x5646c1e72eb0.w4.b0", !4357, i64 0}
!4357 = !{!"0x5646c1e72eb0.w8.b0", !4358, i64 0}
!4358 = !{!"0x5646c1e72eb0.w16.b0", !4359, i64 0}
!4359 = !{!"0x5646c1e72eb0.w32.b0", !4360, i64 0}
!4360 = !{!"0x5646c1e72eb0.w64.b0", !4361, i64 0}
!4361 = !{!"0x5646c1e72eb0.w128.b0", !4362, i64 0}
!4362 = !{!"0x5646c1e72eb0.w256.b0", !4363, i64 0}
!4363 = !{!"0x5646c1e72eb0.w512.b0", !4364, i64 0}
!4364 = !{!"0x5646c1e72eb0.w1024.b0", !4365, i64 0}
!4365 = !{!"int64", !4366, i64 0}
!4366 = !{!"0x5646c1e72eb0", !8, i64 0}
!4367 = !{!4368, !4368, i64 0}
!4368 = !{!"0x5646c1e72eb0.w1.b4", !4369, i64 0}
!4369 = !{!"0x5646c1e72eb0.w2.b4", !4370, i64 0}
!4370 = !{!"0x5646c1e72eb0.w4.b4", !4357, i64 0}
!4371 = !{!4372, !4372, i64 0}
!4372 = !{!"float32", !4373, i64 0}
!4373 = !{!"0x5646c1f26d30", !8, i64 0}
!4374 = !{!4375, !4375, i64 0}
!4375 = !{!"float32", !4376, i64 0}
!4376 = !{!"0x5646c1a86de0", !8, i64 0}
!4377 = !{!4378, !4378, i64 0}
!4378 = !{!"0x5646c19cb720.w1.b0", !4379, i64 0}
!4379 = !{!"0x5646c19cb720.w2.b0", !4380, i64 0}
!4380 = !{!"0x5646c19cb720.w4.b0", !4381, i64 0}
!4381 = !{!"0x5646c19cb720.w8.b0", !4382, i64 0}
!4382 = !{!"0x5646c19cb720.w16.b0", !4383, i64 0}
!4383 = !{!"0x5646c19cb720.w32.b0", !4384, i64 0}
!4384 = !{!"0x5646c19cb720.w64.b0", !4385, i64 0}
!4385 = !{!"0x5646c19cb720.w128.b0", !4386, i64 0}
!4386 = !{!"0x5646c19cb720.w256.b0", !4387, i64 0}
!4387 = !{!"0x5646c19cb720.w512.b0", !4388, i64 0}
!4388 = !{!"0x5646c19cb720.w1024.b0", !4389, i64 0}
!4389 = !{!"int32", !4390, i64 0}
!4390 = !{!"0x5646c19cb720", !8, i64 0}
!4391 = !{!4392, !4392, i64 0}
!4392 = !{!"0x5646c19cb720.w1.b2", !4393, i64 0}
!4393 = !{!"0x5646c19cb720.w2.b2", !4380, i64 0}
!4394 = !{!4395, !4395, i64 0}
!4395 = !{!"0x5646c19cb720.w1.b3", !4393, i64 0}
!4396 = !{!4397, !4397, i64 0}
!4397 = !{!"0x5646c19cb720.w1.b4", !4398, i64 0}
!4398 = !{!"0x5646c19cb720.w2.b4", !4399, i64 0}
!4399 = !{!"0x5646c19cb720.w4.b4", !4381, i64 0}
!4400 = !{!4401, !4401, i64 0}
!4401 = !{!"0x5646c19cb720.w1.b1", !4379, i64 0}
!4402 = !{!4403, !4403, i64 0}
!4403 = !{!"0x5646c41916d0.w1.b0", !4404, i64 0}
!4404 = !{!"0x5646c41916d0.w2.b0", !4405, i64 0}
!4405 = !{!"0x5646c41916d0.w4.b0", !4406, i64 0}
!4406 = !{!"0x5646c41916d0.w8.b0", !4407, i64 0}
!4407 = !{!"0x5646c41916d0.w16.b0", !4408, i64 0}
!4408 = !{!"0x5646c41916d0.w32.b0", !4409, i64 0}
!4409 = !{!"0x5646c41916d0.w64.b0", !4410, i64 0}
!4410 = !{!"0x5646c41916d0.w128.b0", !4411, i64 0}
!4411 = !{!"0x5646c41916d0.w256.b0", !4412, i64 0}
!4412 = !{!"0x5646c41916d0.w512.b0", !4413, i64 0}
!4413 = !{!"0x5646c41916d0.w1024.b0", !4414, i64 0}
!4414 = !{!"int64", !4415, i64 0}
!4415 = !{!"0x5646c41916d0", !8, i64 0}
!4416 = !{!4417, !4417, i64 0}
!4417 = !{!"0x5646c41916d0.w1.b1", !4404, i64 0}
!4418 = !{!4419, !4419, i64 0}
!4419 = !{!"0x5646c41916d0.w1.b2", !4420, i64 0}
!4420 = !{!"0x5646c41916d0.w2.b2", !4405, i64 0}
!4421 = !{!4422, !4422, i64 0}
!4422 = !{!"0x5646c41916d0.w1.b3", !4420, i64 0}
!4423 = !{!4424, !4424, i64 0}
!4424 = !{!"0x5646c41916d0.w1.b4", !4425, i64 0}
!4425 = !{!"0x5646c41916d0.w2.b4", !4426, i64 0}
!4426 = !{!"0x5646c41916d0.w4.b4", !4406, i64 0}
!4427 = !{!4428, !4428, i64 0}
!4428 = !{!"0x5646c41917d0.w4.b0", !4429, i64 0}
!4429 = !{!"0x5646c41917d0.w8.b0", !4430, i64 0}
!4430 = !{!"0x5646c41917d0.w16.b0", !4431, i64 0}
!4431 = !{!"0x5646c41917d0.w32.b0", !4432, i64 0}
!4432 = !{!"0x5646c41917d0.w64.b0", !4433, i64 0}
!4433 = !{!"0x5646c41917d0.w128.b0", !4434, i64 0}
!4434 = !{!"0x5646c41917d0.w256.b0", !4435, i64 0}
!4435 = !{!"0x5646c41917d0.w512.b0", !4436, i64 0}
!4436 = !{!"0x5646c41917d0.w1024.b0", !4437, i64 0}
!4437 = !{!"int64", !4438, i64 0}
!4438 = !{!"0x5646c41917d0", !8, i64 0}
!4439 = !{!4440, !4440, i64 0}
!4440 = !{!"0x5646c41917d0.w1.b4", !4441, i64 0}
!4441 = !{!"0x5646c41917d0.w2.b4", !4442, i64 0}
!4442 = !{!"0x5646c41917d0.w4.b4", !4429, i64 0}
!4443 = !{!4444, !4444, i64 0}
!4444 = !{!"0x5646c4191870.w1.b0", !4445, i64 0}
!4445 = !{!"0x5646c4191870.w2.b0", !4446, i64 0}
!4446 = !{!"0x5646c4191870.w4.b0", !4447, i64 0}
!4447 = !{!"0x5646c4191870.w8.b0", !4448, i64 0}
!4448 = !{!"0x5646c4191870.w16.b0", !4449, i64 0}
!4449 = !{!"0x5646c4191870.w32.b0", !4450, i64 0}
!4450 = !{!"0x5646c4191870.w64.b0", !4451, i64 0}
!4451 = !{!"0x5646c4191870.w128.b0", !4452, i64 0}
!4452 = !{!"0x5646c4191870.w256.b0", !4453, i64 0}
!4453 = !{!"0x5646c4191870.w512.b0", !4454, i64 0}
!4454 = !{!"0x5646c4191870.w1024.b0", !4455, i64 0}
!4455 = !{!"int64", !4456, i64 0}
!4456 = !{!"0x5646c4191870", !8, i64 0}
!4457 = !{!4458, !4458, i64 0}
!4458 = !{!"0x5646c4191870.w1.b1", !4445, i64 0}
!4459 = !{!4460, !4460, i64 0}
!4460 = !{!"0x5646c4191870.w1.b2", !4461, i64 0}
!4461 = !{!"0x5646c4191870.w2.b2", !4446, i64 0}
!4462 = !{!4463, !4463, i64 0}
!4463 = !{!"0x5646c4191870.w1.b3", !4461, i64 0}
!4464 = !{!4465, !4465, i64 0}
!4465 = !{!"0x5646c4191870.w1.b4", !4466, i64 0}
!4466 = !{!"0x5646c4191870.w2.b4", !4467, i64 0}
!4467 = !{!"0x5646c4191870.w4.b4", !4447, i64 0}
!4468 = !{!4469, !4469, i64 0}
!4469 = !{!"0x5646c4191870.w1.b5", !4466, i64 0}
!4470 = !{!4471, !4471, i64 0}
!4471 = !{!"0x5646c4191780.w4.b0", !4472, i64 0}
!4472 = !{!"0x5646c4191780.w8.b0", !4473, i64 0}
!4473 = !{!"0x5646c4191780.w16.b0", !4474, i64 0}
!4474 = !{!"0x5646c4191780.w32.b0", !4475, i64 0}
!4475 = !{!"0x5646c4191780.w64.b0", !4476, i64 0}
!4476 = !{!"0x5646c4191780.w128.b0", !4477, i64 0}
!4477 = !{!"0x5646c4191780.w256.b0", !4478, i64 0}
!4478 = !{!"0x5646c4191780.w512.b0", !4479, i64 0}
!4479 = !{!"0x5646c4191780.w1024.b0", !4480, i64 0}
!4480 = !{!"int64", !4481, i64 0}
!4481 = !{!"0x5646c4191780", !8, i64 0}
!4482 = !{!4483, !4483, i64 0}
!4483 = !{!"0x5646c4191780.w1.b4", !4484, i64 0}
!4484 = !{!"0x5646c4191780.w2.b4", !4485, i64 0}
!4485 = !{!"0x5646c4191780.w4.b4", !4472, i64 0}
!4486 = !{!4487, !4487, i64 0}
!4487 = !{!"0x5646c4191780.w1.b5", !4484, i64 0}
!4488 = !{!4489, !4489, i64 0}
!4489 = !{!"0x5646c4191dd0.w1.b0", !4490, i64 0}
!4490 = !{!"0x5646c4191dd0.w2.b0", !4491, i64 0}
!4491 = !{!"0x5646c4191dd0.w4.b0", !4492, i64 0}
!4492 = !{!"0x5646c4191dd0.w8.b0", !4493, i64 0}
!4493 = !{!"0x5646c4191dd0.w16.b0", !4494, i64 0}
!4494 = !{!"0x5646c4191dd0.w32.b0", !4495, i64 0}
!4495 = !{!"0x5646c4191dd0.w64.b0", !4496, i64 0}
!4496 = !{!"0x5646c4191dd0.w128.b0", !4497, i64 0}
!4497 = !{!"0x5646c4191dd0.w256.b0", !4498, i64 0}
!4498 = !{!"0x5646c4191dd0.w512.b0", !4499, i64 0}
!4499 = !{!"0x5646c4191dd0.w1024.b0", !4500, i64 0}
!4500 = !{!"int64", !4501, i64 0}
!4501 = !{!"0x5646c4191dd0", !8, i64 0}
!4502 = !{!4503, !4503, i64 0}
!4503 = !{!"0x5646c4191dd0.w1.b1", !4490, i64 0}
!4504 = !{!4505, !4505, i64 0}
!4505 = !{!"0x5646c4191dd0.w1.b2", !4506, i64 0}
!4506 = !{!"0x5646c4191dd0.w2.b2", !4491, i64 0}
!4507 = !{!4508, !4508, i64 0}
!4508 = !{!"0x5646c4191dd0.w1.b3", !4506, i64 0}
!4509 = !{!4510, !4510, i64 0}
!4510 = !{!"0x5646c4191dd0.w1.b4", !4511, i64 0}
!4511 = !{!"0x5646c4191dd0.w2.b4", !4512, i64 0}
!4512 = !{!"0x5646c4191dd0.w4.b4", !4492, i64 0}
!4513 = !{!4514, !4514, i64 0}
!4514 = !{!"0x5646c4191fa0.w4.b0", !4515, i64 0}
!4515 = !{!"0x5646c4191fa0.w8.b0", !4516, i64 0}
!4516 = !{!"0x5646c4191fa0.w16.b0", !4517, i64 0}
!4517 = !{!"0x5646c4191fa0.w32.b0", !4518, i64 0}
!4518 = !{!"0x5646c4191fa0.w64.b0", !4519, i64 0}
!4519 = !{!"0x5646c4191fa0.w128.b0", !4520, i64 0}
!4520 = !{!"0x5646c4191fa0.w256.b0", !4521, i64 0}
!4521 = !{!"0x5646c4191fa0.w512.b0", !4522, i64 0}
!4522 = !{!"0x5646c4191fa0.w1024.b0", !4523, i64 0}
!4523 = !{!"int64", !4524, i64 0}
!4524 = !{!"0x5646c4191fa0", !8, i64 0}
!4525 = !{!4526, !4526, i64 0}
!4526 = !{!"0x5646c4191fa0.w1.b4", !4527, i64 0}
!4527 = !{!"0x5646c4191fa0.w2.b4", !4528, i64 0}
!4528 = !{!"0x5646c4191fa0.w4.b4", !4515, i64 0}
!4529 = !{!4530, !4530, i64 0}
!4530 = !{!"0x5646c4192640.w1.b0", !4531, i64 0}
!4531 = !{!"0x5646c4192640.w2.b0", !4532, i64 0}
!4532 = !{!"0x5646c4192640.w4.b0", !4533, i64 0}
!4533 = !{!"0x5646c4192640.w8.b0", !4534, i64 0}
!4534 = !{!"0x5646c4192640.w16.b0", !4535, i64 0}
!4535 = !{!"0x5646c4192640.w32.b0", !4536, i64 0}
!4536 = !{!"0x5646c4192640.w64.b0", !4537, i64 0}
!4537 = !{!"0x5646c4192640.w128.b0", !4538, i64 0}
!4538 = !{!"0x5646c4192640.w256.b0", !4539, i64 0}
!4539 = !{!"0x5646c4192640.w512.b0", !4540, i64 0}
!4540 = !{!"0x5646c4192640.w1024.b0", !4541, i64 0}
!4541 = !{!"int64", !4542, i64 0}
!4542 = !{!"0x5646c4192640", !8, i64 0}
!4543 = !{!4544, !4544, i64 0}
!4544 = !{!"0x5646c4192640.w1.b1", !4531, i64 0}
!4545 = !{!4546, !4546, i64 0}
!4546 = !{!"0x5646c4192640.w1.b2", !4547, i64 0}
!4547 = !{!"0x5646c4192640.w2.b2", !4532, i64 0}
!4548 = !{!4549, !4549, i64 0}
!4549 = !{!"0x5646c4192640.w1.b3", !4547, i64 0}
!4550 = !{!4551, !4551, i64 0}
!4551 = !{!"0x5646c4192640.w1.b4", !4552, i64 0}
!4552 = !{!"0x5646c4192640.w2.b4", !4553, i64 0}
!4553 = !{!"0x5646c4192640.w4.b4", !4533, i64 0}
!4554 = !{!4555, !4555, i64 0}
!4555 = !{!"0x5646c4192690.w4.b0", !4556, i64 0}
!4556 = !{!"0x5646c4192690.w8.b0", !4557, i64 0}
!4557 = !{!"0x5646c4192690.w16.b0", !4558, i64 0}
!4558 = !{!"0x5646c4192690.w32.b0", !4559, i64 0}
!4559 = !{!"0x5646c4192690.w64.b0", !4560, i64 0}
!4560 = !{!"0x5646c4192690.w128.b0", !4561, i64 0}
!4561 = !{!"0x5646c4192690.w256.b0", !4562, i64 0}
!4562 = !{!"0x5646c4192690.w512.b0", !4563, i64 0}
!4563 = !{!"0x5646c4192690.w1024.b0", !4564, i64 0}
!4564 = !{!"int64", !4565, i64 0}
!4565 = !{!"0x5646c4192690", !8, i64 0}
!4566 = !{!4567, !4567, i64 0}
!4567 = !{!"0x5646c4192690.w1.b4", !4568, i64 0}
!4568 = !{!"0x5646c4192690.w2.b4", !4569, i64 0}
!4569 = !{!"0x5646c4192690.w4.b4", !4556, i64 0}
!4570 = !{!4571, !4571, i64 0}
!4571 = !{!"0x5646c4192790.w1.b0", !4572, i64 0}
!4572 = !{!"0x5646c4192790.w2.b0", !4573, i64 0}
!4573 = !{!"0x5646c4192790.w4.b0", !4574, i64 0}
!4574 = !{!"0x5646c4192790.w8.b0", !4575, i64 0}
!4575 = !{!"0x5646c4192790.w16.b0", !4576, i64 0}
!4576 = !{!"0x5646c4192790.w32.b0", !4577, i64 0}
!4577 = !{!"0x5646c4192790.w64.b0", !4578, i64 0}
!4578 = !{!"0x5646c4192790.w128.b0", !4579, i64 0}
!4579 = !{!"0x5646c4192790.w256.b0", !4580, i64 0}
!4580 = !{!"0x5646c4192790.w512.b0", !4581, i64 0}
!4581 = !{!"0x5646c4192790.w1024.b0", !4582, i64 0}
!4582 = !{!"int64", !4583, i64 0}
!4583 = !{!"0x5646c4192790", !8, i64 0}
!4584 = !{!4585, !4585, i64 0}
!4585 = !{!"0x5646c4192790.w1.b1", !4572, i64 0}
!4586 = !{!4587, !4587, i64 0}
!4587 = !{!"0x5646c4192790.w1.b2", !4588, i64 0}
!4588 = !{!"0x5646c4192790.w2.b2", !4573, i64 0}
!4589 = !{!4590, !4590, i64 0}
!4590 = !{!"0x5646c4192790.w1.b3", !4588, i64 0}
!4591 = !{!4592, !4592, i64 0}
!4592 = !{!"0x5646c4192790.w1.b4", !4593, i64 0}
!4593 = !{!"0x5646c4192790.w2.b4", !4594, i64 0}
!4594 = !{!"0x5646c4192790.w4.b4", !4574, i64 0}
!4595 = !{!4596, !4596, i64 0}
!4596 = !{!"0x5646c41922e0.w4.b0", !4597, i64 0}
!4597 = !{!"0x5646c41922e0.w8.b0", !4598, i64 0}
!4598 = !{!"0x5646c41922e0.w16.b0", !4599, i64 0}
!4599 = !{!"0x5646c41922e0.w32.b0", !4600, i64 0}
!4600 = !{!"0x5646c41922e0.w64.b0", !4601, i64 0}
!4601 = !{!"0x5646c41922e0.w128.b0", !4602, i64 0}
!4602 = !{!"0x5646c41922e0.w256.b0", !4603, i64 0}
!4603 = !{!"0x5646c41922e0.w512.b0", !4604, i64 0}
!4604 = !{!"0x5646c41922e0.w1024.b0", !4605, i64 0}
!4605 = !{!"int64", !4606, i64 0}
!4606 = !{!"0x5646c41922e0", !8, i64 0}
!4607 = !{!4608, !4608, i64 0}
!4608 = !{!"0x5646c41922e0.w1.b4", !4609, i64 0}
!4609 = !{!"0x5646c41922e0.w2.b4", !4610, i64 0}
!4610 = !{!"0x5646c41922e0.w4.b4", !4597, i64 0}
!4611 = !{!4612, !4612, i64 0}
!4612 = !{!"float32", !4613, i64 0}
!4613 = !{!"0x5646c1f20810", !8, i64 0}
!4614 = !{!4615, !4615, i64 0}
!4615 = !{!"float32", !4616, i64 0}
!4616 = !{!"0x5646c1b80870", !8, i64 0}
!4617 = !{!4618, !4618, i64 0}
!4618 = !{!"float32", !4619, i64 0}
!4619 = !{!"0x5646c1ed88b0", !8, i64 0}
!4620 = !{!4621, !4621, i64 0}
!4621 = !{!"0x5646c4217100.w16.b0", !4622, i64 0}
!4622 = !{!"0x5646c4217100.w32.b0", !4623, i64 0}
!4623 = !{!"0x5646c4217100.w64.b0", !4624, i64 0}
!4624 = !{!"0x5646c4217100.w128.b0", !4625, i64 0}
!4625 = !{!"0x5646c4217100.w256.b0", !4626, i64 0}
!4626 = !{!"0x5646c4217100.w512.b0", !4627, i64 0}
!4627 = !{!"0x5646c4217100.w1024.b0", !4628, i64 0}
!4628 = !{!"float32", !4629, i64 0}
!4629 = !{!"0x5646c4217100", !8, i64 0}
!4630 = !{!4631, !4631, i64 0}
!4631 = !{!"float32", !4632, i64 0}
!4632 = !{!"0x5646c1e3ea40", !8, i64 0}
!4633 = !{!4634, !4634, i64 0}
!4634 = !{!"float32", !4635, i64 0}
!4635 = !{!"0x5646c1f206c0", !8, i64 0}
!4636 = !{!4637, !4637, i64 0}
!4637 = !{!"float32", !4638, i64 0}
!4638 = !{!"0x5646c19cb600", !8, i64 0}
!4639 = !{!4628, !4628, i64 0}
!4640 = !{!4641, !4641, i64 0}
!4641 = !{!"0x5646bc684820.w1.b0", !4642, i64 0}
!4642 = !{!"0x5646bc684820.w2.b0", !4643, i64 0}
!4643 = !{!"0x5646bc684820.w4.b0", !4644, i64 0}
!4644 = !{!"0x5646bc684820.w8.b0", !4645, i64 0}
!4645 = !{!"0x5646bc684820.w16.b0", !4646, i64 0}
!4646 = !{!"0x5646bc684820.w32.b0", !4647, i64 0}
!4647 = !{!"0x5646bc684820.w64.b0", !4648, i64 0}
!4648 = !{!"0x5646bc684820.w128.b0", !4649, i64 0}
!4649 = !{!"0x5646bc684820.w256.b0", !4650, i64 0}
!4650 = !{!"0x5646bc684820.w512.b0", !4651, i64 0}
!4651 = !{!"0x5646bc684820.w1024.b0", !4652, i64 0}
!4652 = !{!"int32", !4653, i64 0}
!4653 = !{!"0x5646bc684820", !8, i64 0}
!4654 = !{!4655, !4655, i64 0}
!4655 = !{!"0x5646bc684820.w1.b2", !4656, i64 0}
!4656 = !{!"0x5646bc684820.w2.b2", !4643, i64 0}
!4657 = !{!4658, !4658, i64 0}
!4658 = !{!"0x5646bc684820.w1.b3", !4656, i64 0}
!4659 = !{!4660, !4660, i64 0}
!4660 = !{!"0x5646bc684820.w1.b1", !4642, i64 0}
!4661 = !{!4662, !4662, i64 0}
!4662 = !{!"0x5646bc685300.w1.b0", !4663, i64 0}
!4663 = !{!"0x5646bc685300.w2.b0", !4664, i64 0}
!4664 = !{!"0x5646bc685300.w4.b0", !4665, i64 0}
!4665 = !{!"0x5646bc685300.w8.b0", !4666, i64 0}
!4666 = !{!"0x5646bc685300.w16.b0", !4667, i64 0}
!4667 = !{!"0x5646bc685300.w32.b0", !4668, i64 0}
!4668 = !{!"0x5646bc685300.w64.b0", !4669, i64 0}
!4669 = !{!"0x5646bc685300.w128.b0", !4670, i64 0}
!4670 = !{!"0x5646bc685300.w256.b0", !4671, i64 0}
!4671 = !{!"0x5646bc685300.w512.b0", !4672, i64 0}
!4672 = !{!"0x5646bc685300.w1024.b0", !4673, i64 0}
!4673 = !{!"int64", !4674, i64 0}
!4674 = !{!"0x5646bc685300", !8, i64 0}
!4675 = !{!4676, !4676, i64 0}
!4676 = !{!"0x5646bc685300.w1.b1", !4663, i64 0}
!4677 = !{!4678, !4678, i64 0}
!4678 = !{!"0x5646bc685300.w1.b2", !4679, i64 0}
!4679 = !{!"0x5646bc685300.w2.b2", !4664, i64 0}
!4680 = !{!4681, !4681, i64 0}
!4681 = !{!"0x5646bc685300.w1.b3", !4679, i64 0}
!4682 = !{!4683, !4683, i64 0}
!4683 = !{!"0x5646bc685300.w1.b4", !4684, i64 0}
!4684 = !{!"0x5646bc685300.w2.b4", !4685, i64 0}
!4685 = !{!"0x5646bc685300.w4.b4", !4665, i64 0}
!4686 = !{!4687, !4687, i64 0}
!4687 = !{!"0x5646bc67b600.w4.b0", !4688, i64 0}
!4688 = !{!"0x5646bc67b600.w8.b0", !4689, i64 0}
!4689 = !{!"0x5646bc67b600.w16.b0", !4690, i64 0}
!4690 = !{!"0x5646bc67b600.w32.b0", !4691, i64 0}
!4691 = !{!"0x5646bc67b600.w64.b0", !4692, i64 0}
!4692 = !{!"0x5646bc67b600.w128.b0", !4693, i64 0}
!4693 = !{!"0x5646bc67b600.w256.b0", !4694, i64 0}
!4694 = !{!"0x5646bc67b600.w512.b0", !4695, i64 0}
!4695 = !{!"0x5646bc67b600.w1024.b0", !4696, i64 0}
!4696 = !{!"int64", !4697, i64 0}
!4697 = !{!"0x5646bc67b600", !8, i64 0}
!4698 = !{!4699, !4699, i64 0}
!4699 = !{!"0x5646bc67b600.w1.b4", !4700, i64 0}
!4700 = !{!"0x5646bc67b600.w2.b4", !4701, i64 0}
!4701 = !{!"0x5646bc67b600.w4.b4", !4688, i64 0}
!4702 = !{!4703, !4703, i64 0}
!4703 = !{!"0x5646bc6862c0.w1.b0", !4704, i64 0}
!4704 = !{!"0x5646bc6862c0.w2.b0", !4705, i64 0}
!4705 = !{!"0x5646bc6862c0.w4.b0", !4706, i64 0}
!4706 = !{!"0x5646bc6862c0.w8.b0", !4707, i64 0}
!4707 = !{!"0x5646bc6862c0.w16.b0", !4708, i64 0}
!4708 = !{!"0x5646bc6862c0.w32.b0", !4709, i64 0}
!4709 = !{!"0x5646bc6862c0.w64.b0", !4710, i64 0}
!4710 = !{!"0x5646bc6862c0.w128.b0", !4711, i64 0}
!4711 = !{!"0x5646bc6862c0.w256.b0", !4712, i64 0}
!4712 = !{!"0x5646bc6862c0.w512.b0", !4713, i64 0}
!4713 = !{!"0x5646bc6862c0.w1024.b0", !4714, i64 0}
!4714 = !{!"int64", !4715, i64 0}
!4715 = !{!"0x5646bc6862c0", !8, i64 0}
!4716 = !{!4717, !4717, i64 0}
!4717 = !{!"0x5646bc6862c0.w1.b1", !4704, i64 0}
!4718 = !{!4719, !4719, i64 0}
!4719 = !{!"0x5646bc6862c0.w1.b2", !4720, i64 0}
!4720 = !{!"0x5646bc6862c0.w2.b2", !4705, i64 0}
!4721 = !{!4722, !4722, i64 0}
!4722 = !{!"0x5646bc6862c0.w1.b3", !4720, i64 0}
!4723 = !{!4724, !4724, i64 0}
!4724 = !{!"0x5646bc6862c0.w1.b4", !4725, i64 0}
!4725 = !{!"0x5646bc6862c0.w2.b4", !4726, i64 0}
!4726 = !{!"0x5646bc6862c0.w4.b4", !4706, i64 0}
!4727 = !{!4728, !4728, i64 0}
!4728 = !{!"0x5646bc6862c0.w1.b5", !4725, i64 0}
!4729 = !{!4730, !4730, i64 0}
!4730 = !{!"0x5646bc685500.w4.b0", !4731, i64 0}
!4731 = !{!"0x5646bc685500.w8.b0", !4732, i64 0}
!4732 = !{!"0x5646bc685500.w16.b0", !4733, i64 0}
!4733 = !{!"0x5646bc685500.w32.b0", !4734, i64 0}
!4734 = !{!"0x5646bc685500.w64.b0", !4735, i64 0}
!4735 = !{!"0x5646bc685500.w128.b0", !4736, i64 0}
!4736 = !{!"0x5646bc685500.w256.b0", !4737, i64 0}
!4737 = !{!"0x5646bc685500.w512.b0", !4738, i64 0}
!4738 = !{!"0x5646bc685500.w1024.b0", !4739, i64 0}
!4739 = !{!"int64", !4740, i64 0}
!4740 = !{!"0x5646bc685500", !8, i64 0}
!4741 = !{!4742, !4742, i64 0}
!4742 = !{!"0x5646bc685500.w1.b4", !4743, i64 0}
!4743 = !{!"0x5646bc685500.w2.b4", !4744, i64 0}
!4744 = !{!"0x5646bc685500.w4.b4", !4731, i64 0}
!4745 = !{!4746, !4746, i64 0}
!4746 = !{!"0x5646bc685500.w1.b5", !4743, i64 0}
!4747 = !{!4748, !4748, i64 0}
!4748 = !{!"0x5646bc687ae0.w1.b0", !4749, i64 0}
!4749 = !{!"0x5646bc687ae0.w2.b0", !4750, i64 0}
!4750 = !{!"0x5646bc687ae0.w4.b0", !4751, i64 0}
!4751 = !{!"0x5646bc687ae0.w8.b0", !4752, i64 0}
!4752 = !{!"0x5646bc687ae0.w16.b0", !4753, i64 0}
!4753 = !{!"0x5646bc687ae0.w32.b0", !4754, i64 0}
!4754 = !{!"0x5646bc687ae0.w64.b0", !4755, i64 0}
!4755 = !{!"0x5646bc687ae0.w128.b0", !4756, i64 0}
!4756 = !{!"0x5646bc687ae0.w256.b0", !4757, i64 0}
!4757 = !{!"0x5646bc687ae0.w512.b0", !4758, i64 0}
!4758 = !{!"0x5646bc687ae0.w1024.b0", !4759, i64 0}
!4759 = !{!"int64", !4760, i64 0}
!4760 = !{!"0x5646bc687ae0", !8, i64 0}
!4761 = !{!4762, !4762, i64 0}
!4762 = !{!"0x5646bc687ae0.w1.b1", !4749, i64 0}
!4763 = !{!4764, !4764, i64 0}
!4764 = !{!"0x5646bc687ae0.w1.b2", !4765, i64 0}
!4765 = !{!"0x5646bc687ae0.w2.b2", !4750, i64 0}
!4766 = !{!4767, !4767, i64 0}
!4767 = !{!"0x5646bc687ae0.w1.b3", !4765, i64 0}
!4768 = !{!4769, !4769, i64 0}
!4769 = !{!"0x5646bc687ae0.w1.b4", !4770, i64 0}
!4770 = !{!"0x5646bc687ae0.w2.b4", !4771, i64 0}
!4771 = !{!"0x5646bc687ae0.w4.b4", !4751, i64 0}
!4772 = !{!4773, !4773, i64 0}
!4773 = !{!"0x5646bc6894a0.w4.b0", !4774, i64 0}
!4774 = !{!"0x5646bc6894a0.w8.b0", !4775, i64 0}
!4775 = !{!"0x5646bc6894a0.w16.b0", !4776, i64 0}
!4776 = !{!"0x5646bc6894a0.w32.b0", !4777, i64 0}
!4777 = !{!"0x5646bc6894a0.w64.b0", !4778, i64 0}
!4778 = !{!"0x5646bc6894a0.w128.b0", !4779, i64 0}
!4779 = !{!"0x5646bc6894a0.w256.b0", !4780, i64 0}
!4780 = !{!"0x5646bc6894a0.w512.b0", !4781, i64 0}
!4781 = !{!"0x5646bc6894a0.w1024.b0", !4782, i64 0}
!4782 = !{!"int64", !4783, i64 0}
!4783 = !{!"0x5646bc6894a0", !8, i64 0}
!4784 = !{!4785, !4785, i64 0}
!4785 = !{!"0x5646bc6894a0.w1.b4", !4786, i64 0}
!4786 = !{!"0x5646bc6894a0.w2.b4", !4787, i64 0}
!4787 = !{!"0x5646bc6894a0.w4.b4", !4774, i64 0}
!4788 = !{!4789, !4789, i64 0}
!4789 = !{!"0x5646bc68a760.w1.b0", !4790, i64 0}
!4790 = !{!"0x5646bc68a760.w2.b0", !4791, i64 0}
!4791 = !{!"0x5646bc68a760.w4.b0", !4792, i64 0}
!4792 = !{!"0x5646bc68a760.w8.b0", !4793, i64 0}
!4793 = !{!"0x5646bc68a760.w16.b0", !4794, i64 0}
!4794 = !{!"0x5646bc68a760.w32.b0", !4795, i64 0}
!4795 = !{!"0x5646bc68a760.w64.b0", !4796, i64 0}
!4796 = !{!"0x5646bc68a760.w128.b0", !4797, i64 0}
!4797 = !{!"0x5646bc68a760.w256.b0", !4798, i64 0}
!4798 = !{!"0x5646bc68a760.w512.b0", !4799, i64 0}
!4799 = !{!"0x5646bc68a760.w1024.b0", !4800, i64 0}
!4800 = !{!"int64", !4801, i64 0}
!4801 = !{!"0x5646bc68a760", !8, i64 0}
!4802 = !{!4803, !4803, i64 0}
!4803 = !{!"0x5646bc68a760.w1.b1", !4790, i64 0}
!4804 = !{!4805, !4805, i64 0}
!4805 = !{!"0x5646bc68a760.w1.b2", !4806, i64 0}
!4806 = !{!"0x5646bc68a760.w2.b2", !4791, i64 0}
!4807 = !{!4808, !4808, i64 0}
!4808 = !{!"0x5646bc68a760.w1.b3", !4806, i64 0}
!4809 = !{!4810, !4810, i64 0}
!4810 = !{!"0x5646bc68a760.w1.b4", !4811, i64 0}
!4811 = !{!"0x5646bc68a760.w2.b4", !4812, i64 0}
!4812 = !{!"0x5646bc68a760.w4.b4", !4792, i64 0}
!4813 = !{!4814, !4814, i64 0}
!4814 = !{!"0x5646bc68a7b0.w4.b0", !4815, i64 0}
!4815 = !{!"0x5646bc68a7b0.w8.b0", !4816, i64 0}
!4816 = !{!"0x5646bc68a7b0.w16.b0", !4817, i64 0}
!4817 = !{!"0x5646bc68a7b0.w32.b0", !4818, i64 0}
!4818 = !{!"0x5646bc68a7b0.w64.b0", !4819, i64 0}
!4819 = !{!"0x5646bc68a7b0.w128.b0", !4820, i64 0}
!4820 = !{!"0x5646bc68a7b0.w256.b0", !4821, i64 0}
!4821 = !{!"0x5646bc68a7b0.w512.b0", !4822, i64 0}
!4822 = !{!"0x5646bc68a7b0.w1024.b0", !4823, i64 0}
!4823 = !{!"int64", !4824, i64 0}
!4824 = !{!"0x5646bc68a7b0", !8, i64 0}
!4825 = !{!4826, !4826, i64 0}
!4826 = !{!"0x5646bc68a7b0.w1.b4", !4827, i64 0}
!4827 = !{!"0x5646bc68a7b0.w2.b4", !4828, i64 0}
!4828 = !{!"0x5646bc68a7b0.w4.b4", !4815, i64 0}
!4829 = !{!4830, !4830, i64 0}
!4830 = !{!"float32", !4831, i64 0}
!4831 = !{!"0x5646b8f1bca0", !8, i64 0}
!4832 = !{!4833, !4833, i64 0}
!4833 = !{!"float32", !4834, i64 0}
!4834 = !{!"0x5646bc67e730", !8, i64 0}
!4835 = !{!4836, !4836, i64 0}
!4836 = !{!"float32", !4837, i64 0}
!4837 = !{!"0x5646bc67e470", !8, i64 0}
!4838 = !{!4839, !4839, i64 0}
!4839 = !{!"float32", !4840, i64 0}
!4840 = !{!"0x5646bc67e970", !8, i64 0}
!4841 = !{!4842, !4842, i64 0}
!4842 = !{!"float32", !4843, i64 0}
!4843 = !{!"0x5646bc67b320", !8, i64 0}
!4844 = !{!4845, !4845, i64 0}
!4845 = !{!"0x5646c4192fb0.w1.b0", !4846, i64 0}
!4846 = !{!"0x5646c4192fb0.w2.b0", !4847, i64 0}
!4847 = !{!"0x5646c4192fb0.w4.b0", !4848, i64 0}
!4848 = !{!"0x5646c4192fb0.w8.b0", !4849, i64 0}
!4849 = !{!"0x5646c4192fb0.w16.b0", !4850, i64 0}
!4850 = !{!"0x5646c4192fb0.w32.b0", !4851, i64 0}
!4851 = !{!"0x5646c4192fb0.w64.b0", !4852, i64 0}
!4852 = !{!"0x5646c4192fb0.w128.b0", !4853, i64 0}
!4853 = !{!"0x5646c4192fb0.w256.b0", !4854, i64 0}
!4854 = !{!"0x5646c4192fb0.w512.b0", !4855, i64 0}
!4855 = !{!"0x5646c4192fb0.w1024.b0", !4856, i64 0}
!4856 = !{!"int32", !4857, i64 0}
!4857 = !{!"0x5646c4192fb0", !8, i64 0}
!4858 = !{!4859, !4859, i64 0}
!4859 = !{!"0x5646c4192fb0.w1.b1", !4846, i64 0}
!4860 = !{!4861, !4861, i64 0}
!4861 = !{!"0x5646c4206b50.w1.b0", !4862, i64 0}
!4862 = !{!"0x5646c4206b50.w2.b0", !4863, i64 0}
!4863 = !{!"0x5646c4206b50.w4.b0", !4864, i64 0}
!4864 = !{!"0x5646c4206b50.w8.b0", !4865, i64 0}
!4865 = !{!"0x5646c4206b50.w16.b0", !4866, i64 0}
!4866 = !{!"0x5646c4206b50.w32.b0", !4867, i64 0}
!4867 = !{!"0x5646c4206b50.w64.b0", !4868, i64 0}
!4868 = !{!"0x5646c4206b50.w128.b0", !4869, i64 0}
!4869 = !{!"0x5646c4206b50.w256.b0", !4870, i64 0}
!4870 = !{!"0x5646c4206b50.w512.b0", !4871, i64 0}
!4871 = !{!"0x5646c4206b50.w1024.b0", !4872, i64 0}
!4872 = !{!"int64", !4873, i64 0}
!4873 = !{!"0x5646c4206b50", !8, i64 0}
!4874 = !{!4875, !4875, i64 0}
!4875 = !{!"0x5646c4206b50.w1.b1", !4862, i64 0}
!4876 = !{!4877, !4877, i64 0}
!4877 = !{!"0x5646c4206b50.w1.b2", !4878, i64 0}
!4878 = !{!"0x5646c4206b50.w2.b2", !4863, i64 0}
!4879 = !{!4880, !4880, i64 0}
!4880 = !{!"0x5646c4206b50.w1.b3", !4878, i64 0}
!4881 = !{!4882, !4882, i64 0}
!4882 = !{!"0x5646c4206b50.w1.b4", !4883, i64 0}
!4883 = !{!"0x5646c4206b50.w2.b4", !4884, i64 0}
!4884 = !{!"0x5646c4206b50.w4.b4", !4864, i64 0}
!4885 = !{!4886, !4886, i64 0}
!4886 = !{!"0x5646c4206e30.w4.b0", !4887, i64 0}
!4887 = !{!"0x5646c4206e30.w8.b0", !4888, i64 0}
!4888 = !{!"0x5646c4206e30.w16.b0", !4889, i64 0}
!4889 = !{!"0x5646c4206e30.w32.b0", !4890, i64 0}
!4890 = !{!"0x5646c4206e30.w64.b0", !4891, i64 0}
!4891 = !{!"0x5646c4206e30.w128.b0", !4892, i64 0}
!4892 = !{!"0x5646c4206e30.w256.b0", !4893, i64 0}
!4893 = !{!"0x5646c4206e30.w512.b0", !4894, i64 0}
!4894 = !{!"0x5646c4206e30.w1024.b0", !4895, i64 0}
!4895 = !{!"int64", !4896, i64 0}
!4896 = !{!"0x5646c4206e30", !8, i64 0}
!4897 = !{!4898, !4898, i64 0}
!4898 = !{!"0x5646c4206e30.w1.b4", !4899, i64 0}
!4899 = !{!"0x5646c4206e30.w2.b4", !4900, i64 0}
!4900 = !{!"0x5646c4206e30.w4.b4", !4887, i64 0}
!4901 = !{!4902, !4902, i64 0}
!4902 = !{!"0x5646c4207080.w1.b0", !4903, i64 0}
!4903 = !{!"0x5646c4207080.w2.b0", !4904, i64 0}
!4904 = !{!"0x5646c4207080.w4.b0", !4905, i64 0}
!4905 = !{!"0x5646c4207080.w8.b0", !4906, i64 0}
!4906 = !{!"0x5646c4207080.w16.b0", !4907, i64 0}
!4907 = !{!"0x5646c4207080.w32.b0", !4908, i64 0}
!4908 = !{!"0x5646c4207080.w64.b0", !4909, i64 0}
!4909 = !{!"0x5646c4207080.w128.b0", !4910, i64 0}
!4910 = !{!"0x5646c4207080.w256.b0", !4911, i64 0}
!4911 = !{!"0x5646c4207080.w512.b0", !4912, i64 0}
!4912 = !{!"0x5646c4207080.w1024.b0", !4913, i64 0}
!4913 = !{!"int64", !4914, i64 0}
!4914 = !{!"0x5646c4207080", !8, i64 0}
!4915 = !{!4916, !4916, i64 0}
!4916 = !{!"0x5646c4207080.w1.b1", !4903, i64 0}
!4917 = !{!4918, !4918, i64 0}
!4918 = !{!"0x5646c4207080.w1.b2", !4919, i64 0}
!4919 = !{!"0x5646c4207080.w2.b2", !4904, i64 0}
!4920 = !{!4921, !4921, i64 0}
!4921 = !{!"0x5646c4207080.w1.b3", !4919, i64 0}
!4922 = !{!4923, !4923, i64 0}
!4923 = !{!"0x5646c4207080.w1.b4", !4924, i64 0}
!4924 = !{!"0x5646c4207080.w2.b4", !4925, i64 0}
!4925 = !{!"0x5646c4207080.w4.b4", !4905, i64 0}
!4926 = !{!4927, !4927, i64 0}
!4927 = !{!"0x5646c4206cf0.w4.b0", !4928, i64 0}
!4928 = !{!"0x5646c4206cf0.w8.b0", !4929, i64 0}
!4929 = !{!"0x5646c4206cf0.w16.b0", !4930, i64 0}
!4930 = !{!"0x5646c4206cf0.w32.b0", !4931, i64 0}
!4931 = !{!"0x5646c4206cf0.w64.b0", !4932, i64 0}
!4932 = !{!"0x5646c4206cf0.w128.b0", !4933, i64 0}
!4933 = !{!"0x5646c4206cf0.w256.b0", !4934, i64 0}
!4934 = !{!"0x5646c4206cf0.w512.b0", !4935, i64 0}
!4935 = !{!"0x5646c4206cf0.w1024.b0", !4936, i64 0}
!4936 = !{!"int64", !4937, i64 0}
!4937 = !{!"0x5646c4206cf0", !8, i64 0}
!4938 = !{!4939, !4939, i64 0}
!4939 = !{!"0x5646c4206cf0.w1.b4", !4940, i64 0}
!4940 = !{!"0x5646c4206cf0.w2.b4", !4941, i64 0}
!4941 = !{!"0x5646c4206cf0.w4.b4", !4928, i64 0}
!4942 = !{!4943, !4943, i64 0}
!4943 = !{!"float32", !4944, i64 0}
!4944 = !{!"0x5646c1eb7610", !8, i64 0}
!4945 = !{!4946, !4946, i64 0}
!4946 = !{!"float32", !4947, i64 0}
!4947 = !{!"0x5646c1eb7ec0", !8, i64 0}
